{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_read_only() {\n    let mut fs = MemoryFileSystem::new_read_only();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"test.js\");\n    fs.insert(file_path.into(), *b\"content\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"check\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Do not store the content of the file in the snapshot\n    fs.remove(file_path);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_read_only\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn call_and_post_return(&self, mut store: impl AsContextMut, params: P) -> Result<R> {\n        let result = self.call(&mut store, params)?;\n        self.post_return(&mut store)?;\n        Ok(result)\n    }", "test": "fn integers() -> Result<()> {\n    let component = r#\"\n        (component\n            (core module $m\n                (func (export \"take-i32-100\") (param i32)\n                    local.get 0\n                    i32.const 100\n                    i32.eq\n                    br_if 0\n                    unreachable\n                )\n                (func (export \"take-i64-100\") (param i64)\n                    local.get 0\n                    i64.const 100\n                    i64.eq\n                    br_if 0\n                    unreachable\n                )\n                (func (export \"ret-i32-0\") (result i32) i32.const 0)\n                (func (export \"ret-i64-0\") (result i64) i64.const 0)\n                (func (export \"ret-i32-minus-1\") (result i32) i32.const -1)\n                (func (export \"ret-i64-minus-1\") (result i64) i64.const -1)\n                (func (export \"ret-i32-100000\") (result i32) i32.const 100000)\n            )\n            (core instance $i (instantiate (module $m)))\n            (func (export \"take-u8\") (param \"a\" u8) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-s8\") (param \"a\" s8) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-u16\") (param \"a\" u16) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-s16\") (param \"a\" s16) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-u32\") (param \"a\" u32) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-s32\") (param \"a\" s32) (canon lift (core func $i \"take-i32-100\")))\n            (func (export \"take-u64\") (param \"a\" u64) (canon lift (core func $i \"take-i64-100\")))\n            (func (export \"take-s64\") (param \"a\" s64) (canon lift (core func $i \"take-i64-100\")))\n\n            (func (export \"ret-u8\") (result u8) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-s8\") (result s8) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-u16\") (result u16) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-s16\") (result s16) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-u32\") (result u32) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-s32\") (result s32) (canon lift (core func $i \"ret-i32-0\")))\n            (func (export \"ret-u64\") (result u64) (canon lift (core func $i \"ret-i64-0\")))\n            (func (export \"ret-s64\") (result s64) (canon lift (core func $i \"ret-i64-0\")))\n\n            (func (export \"retm1-u8\") (result u8) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-s8\") (result s8) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-u16\") (result u16) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-s16\") (result s16) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-u32\") (result u32) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-s32\") (result s32) (canon lift (core func $i \"ret-i32-minus-1\")))\n            (func (export \"retm1-u64\") (result u64) (canon lift (core func $i \"ret-i64-minus-1\")))\n            (func (export \"retm1-s64\") (result s64) (canon lift (core func $i \"ret-i64-minus-1\")))\n\n            (func (export \"retbig-u8\") (result u8) (canon lift (core func $i \"ret-i32-100000\")))\n            (func (export \"retbig-s8\") (result s8) (canon lift (core func $i \"ret-i32-100000\")))\n            (func (export \"retbig-u16\") (result u16) (canon lift (core func $i \"ret-i32-100000\")))\n            (func (export \"retbig-s16\") (result s16) (canon lift (core func $i \"ret-i32-100000\")))\n            (func (export \"retbig-u32\") (result u32) (canon lift (core func $i \"ret-i32-100000\")))\n            (func (export \"retbig-s32\") (result s32) (canon lift (core func $i \"ret-i32-100000\")))\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n    let new_instance = |store: &mut Store<()>| Linker::new(&engine).instantiate(store, &component);\n    let instance = new_instance(&mut store)?;\n\n    // Passing in 100 is valid for all primitives\n    instance\n        .get_typed_func::<(u8,), ()>(&mut store, \"take-u8\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(i8,), ()>(&mut store, \"take-s8\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(u16,), ()>(&mut store, \"take-u16\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(i16,), ()>(&mut store, \"take-s16\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(u32,), ()>(&mut store, \"take-u32\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(i32,), ()>(&mut store, \"take-s32\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(u64,), ()>(&mut store, \"take-u64\")?\n        .call_and_post_return(&mut store, (100,))?;\n    instance\n        .get_typed_func::<(i64,), ()>(&mut store, \"take-s64\")?\n        .call_and_post_return(&mut store, (100,))?;\n\n    // This specific wasm instance traps if any value other than 100 is passed\n    new_instance(&mut store)?\n        .get_typed_func::<(u8,), ()>(&mut store, \"take-u8\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(i8,), ()>(&mut store, \"take-s8\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(u16,), ()>(&mut store, \"take-u16\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(i16,), ()>(&mut store, \"take-s16\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(u32,), ()>(&mut store, \"take-u32\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(i32,), ()>(&mut store, \"take-s32\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(u64,), ()>(&mut store, \"take-u64\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n    new_instance(&mut store)?\n        .get_typed_func::<(i64,), ()>(&mut store, \"take-s64\")?\n        .call(&mut store, (101,))\n        .unwrap_err()\n        .downcast::<Trap>()?;\n\n    // Zero can be returned as any integer\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u8,)>(&mut store, \"ret-u8\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i8,)>(&mut store, \"ret-s8\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u16,)>(&mut store, \"ret-u16\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i16,)>(&mut store, \"ret-s16\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u32,)>(&mut store, \"ret-u32\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i32,)>(&mut store, \"ret-s32\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u64,)>(&mut store, \"ret-u64\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i64,)>(&mut store, \"ret-s64\")?\n            .call_and_post_return(&mut store, ())?,\n        (0,)\n    );\n\n    // Returning -1 should reinterpret the bytes as defined by each type.\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u8,)>(&mut store, \"retm1-u8\")?\n            .call_and_post_return(&mut store, ())?,\n        (0xff,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i8,)>(&mut store, \"retm1-s8\")?\n            .call_and_post_return(&mut store, ())?,\n        (-1,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u16,)>(&mut store, \"retm1-u16\")?\n            .call_and_post_return(&mut store, ())?,\n        (0xffff,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i16,)>(&mut store, \"retm1-s16\")?\n            .call_and_post_return(&mut store, ())?,\n        (-1,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u32,)>(&mut store, \"retm1-u32\")?\n            .call_and_post_return(&mut store, ())?,\n        (0xffffffff,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i32,)>(&mut store, \"retm1-s32\")?\n            .call_and_post_return(&mut store, ())?,\n        (-1,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u64,)>(&mut store, \"retm1-u64\")?\n            .call_and_post_return(&mut store, ())?,\n        (0xffffffff_ffffffff,)\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i64,)>(&mut store, \"retm1-s64\")?\n            .call_and_post_return(&mut store, ())?,\n        (-1,)\n    );\n\n    // Returning 100000 should chop off bytes as necessary\n    let ret: u32 = 100000;\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u8,)>(&mut store, \"retbig-u8\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret as u8,),\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i8,)>(&mut store, \"retbig-s8\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret as i8,),\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u16,)>(&mut store, \"retbig-u16\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret as u16,),\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i16,)>(&mut store, \"retbig-s16\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret as i16,),\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (u32,)>(&mut store, \"retbig-u32\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret,),\n    );\n    assert_eq!(\n        instance\n            .get_typed_func::<(), (i32,)>(&mut store, \"retbig-s32\")?\n            .call_and_post_return(&mut store, ())?,\n        (ret as i32,),\n    );\n\n    Ok(())\n}"}
{"code": "fn next (& mut self) -> Option < char > { let next = self . iter . next () ; if let Some (c) = next { if canonical_combining_class (c) != 0 { * self . value . borrow_mut () += 1 ; } } next }", "test": "fn test_cjk_compat_variants() {\n    // These codepoints have singleton decompositions in the canonical\n    // decomposition, and can use standardized variations.\n    let s = \"\\u{2f999}\\u{2f8a6}\";\n\n    // These codepoints have canonical decompositions.\n    let mut nfd_iter = s.chars().nfd();\n    assert_eq!(nfd_iter.next(), Some('\\u{831d}'));\n    assert_eq!(nfd_iter.next(), Some('\\u{6148}'));\n    assert_eq!(nfd_iter.next(), None);\n\n    let mut nfkd_iter = s.chars().nfkd();\n    assert_eq!(nfkd_iter.next(), Some('\\u{831d}'));\n    assert_eq!(nfkd_iter.next(), Some('\\u{6148}'));\n    assert_eq!(nfkd_iter.next(), None);\n\n    let mut nfc_iter = s.chars().nfc();\n    assert_eq!(nfc_iter.next(), Some('\\u{831d}'));\n    assert_eq!(nfc_iter.next(), Some('\\u{6148}'));\n    assert_eq!(nfc_iter.next(), None);\n\n    let mut nfkc_iter = s.chars().nfkc();\n    assert_eq!(nfkc_iter.next(), Some('\\u{831d}'));\n    assert_eq!(nfkc_iter.next(), Some('\\u{6148}'));\n    assert_eq!(nfkc_iter.next(), None);\n\n    // However they also have standardized variants.\n    let mut var_iter = s.chars().cjk_compat_variants();\n    assert_eq!(var_iter.next(), Some('\\u{831d}'));\n    assert_eq!(var_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_iter.next(), Some('\\u{6148}'));\n    assert_eq!(var_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_iter.next(), None);\n\n    // The standardized variants are normalization-stable.\n    let mut var_nfc_iter = s.chars().cjk_compat_variants().nfc();\n    assert_eq!(var_nfc_iter.next(), Some('\\u{831d}'));\n    assert_eq!(var_nfc_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfc_iter.next(), Some('\\u{6148}'));\n    assert_eq!(var_nfc_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfc_iter.next(), None);\n\n    let mut var_nfd_iter = s.chars().cjk_compat_variants().nfd();\n    assert_eq!(var_nfd_iter.next(), Some('\\u{831d}'));\n    assert_eq!(var_nfd_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfd_iter.next(), Some('\\u{6148}'));\n    assert_eq!(var_nfd_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfd_iter.next(), None);\n\n    let mut var_nfkc_iter = s.chars().cjk_compat_variants().nfkc();\n    assert_eq!(var_nfkc_iter.next(), Some('\\u{831d}'));\n    assert_eq!(var_nfkc_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfkc_iter.next(), Some('\\u{6148}'));\n    assert_eq!(var_nfkc_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfkc_iter.next(), None);\n\n    let mut var_nfkd_iter = s.chars().cjk_compat_variants().nfkd();\n    assert_eq!(var_nfkd_iter.next(), Some('\\u{831d}'));\n    assert_eq!(var_nfkd_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfkd_iter.next(), Some('\\u{6148}'));\n    assert_eq!(var_nfkd_iter.next(), Some('\\u{fe00}'));\n    assert_eq!(var_nfkd_iter.next(), None);\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn does_render_owned_for_loop_with_objects() {\n    let mut context = Context::new();\n    let data = json!([\n        {\"id\": 1, \"year\": 2015},\n        {\"id\": 2, \"year\": 2015},\n        {\"id\": 3, \"year\": 2016},\n        {\"id\": 4, \"year\": 2017},\n        {\"id\": 5, \"year\": 2017},\n        {\"id\": 6, \"year\": 2017},\n        {\"id\": 7, \"year\": 2018},\n        {\"id\": 8},\n        {\"id\": 9, \"year\": null},\n    ]);\n    context.insert(\"something\", &data);\n\n    let tpl =\n        r#\"{% for year, things in something | group_by(attribute=\"year\") %}{{year}},{% endfor %}\"#;\n    let expected = \"2015,2016,2017,2018,\";\n    assert_eq!(render_template(tpl, &context).unwrap(), expected);\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_nil() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=nil\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn render<S: Serialize>(&self, ctx: S) -> Result<String, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _render.\n        self._render(Value::from_serializable(&ctx)).map(|x| x.0)\n    }", "test": "fn test_basic() {\n    let env = create_env();\n    let t = env.get_template(\"hello\").unwrap();\n    assert_eq!(t.render(()).unwrap(), \"Hello World!\");\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn test_trap_return_downcast() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let wat = r#\"\n        (module\n        (func $hello (import \"\" \"hello\"))\n        (func (export \"run\") (call $hello))\n        )\n    \"#;\n\n    #[derive(Debug)]\n    struct MyTrap;\n    impl std::fmt::Display for MyTrap {\n        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\n            write!(f, \"my trap\")\n        }\n    }\n    impl std::error::Error for MyTrap {}\n\n    let module = Module::new(store.engine(), wat)?;\n    let hello_type = FuncType::new(None, None);\n    let hello_func = Func::new(&mut store, hello_type, |_, _, _| {\n        Err(anyhow::Error::from(MyTrap))\n    });\n\n    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;\n    let run_func = instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n\n    let e = run_func\n        .call(&mut store, ())\n        .err()\n        .expect(\"error calling function\");\n    let dbg = format!(\"{:?}\", e);\n    println!(\"{}\", dbg);\n\n    assert!(!e.to_string().contains(\"my trap\"));\n    assert!(dbg.contains(\"Caused by:\\n    my trap\"));\n\n    e.downcast_ref::<MyTrap>()\n        .expect(\"error downcasts to MyTrap\");\n    let bt = e\n        .downcast_ref::<WasmBacktrace>()\n        .expect(\"error downcasts to WasmBacktrace\");\n    assert_eq!(bt.frames().len(), 1);\n    println!(\"{:?}\", bt);\n\n    Ok(())\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_compare_and_swap() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n    let record = record;\n\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let current = record;\n    let mut new = current.clone();\n    new.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let new = new;\n\n    let result = io_loop\n        .block_on(client.compare_and_swap(current.clone(), new.clone(), origin.clone()))\n        .expect(\"compare_and_swap failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(new.name().clone(), new.dns_class(), new.record_type()))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result.answers().iter().any(|rr| *rr == new));\n    assert!(!result.answers().iter().any(|rr| *rr == current));\n\n    // check the it fails if tried again.\n    let mut not = new.clone();\n    not.set_data(Some(RData::A(A::new(102, 12, 102, 12))));\n    let not = not;\n\n    let result = io_loop\n        .block_on(client.compare_and_swap(current, not.clone(), origin))\n        .expect(\"compare_and_swap failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXRRSet);\n\n    let result = io_loop\n        .block_on(client.query(new.name().clone(), new.dns_class(), new.record_type()))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result.answers().iter().any(|rr| *rr == new));\n    assert!(!result.answers().iter().any(|rr| *rr == not));\n}"}
{"code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_raw_put_deadline() {\n    let deadline_fp = \"deadline_check_fail\";\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n    let region = cluster.get_region(b\"\");\n    let leader = region.get_peers()[0].clone();\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n\n    let mut put_req = RawPutRequest::default();\n    put_req.set_context(ctx);\n    put_req.key = b\"k3\".to_vec();\n    put_req.value = b\"v3\".to_vec();\n    fail::cfg(deadline_fp, \"return()\").unwrap();\n    let put_resp = client.raw_put(&put_req).unwrap();\n    assert!(put_resp.has_region_error(), \"{:?}\", put_resp);\n    must_get_none(&cluster.get_engine(1), b\"k3\");\n\n    fail::remove(deadline_fp);\n    let put_resp = client.raw_put(&put_req).unwrap();\n    assert!(!put_resp.has_region_error(), \"{:?}\", put_resp);\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_with_uncommitted_conf_change() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(90);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store1 = find_peer(&region, 1).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    cluster.stop_node(3);\n    cluster.stop_node(4);\n    cluster.stop_node(5);\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n\n    // an uncommitted conf-change\n    let cmd = new_change_peer_request(\n        ConfChangeType::RemoveNode,\n        find_peer(&region, 2).unwrap().clone(),\n    );\n    let req = new_admin_request(region.get_id(), region.get_region_epoch(), cmd);\n    cluster\n        .call_command_on_leader(req, Duration::from_millis(10))\n        .unwrap_err();\n\n    // wait election timeout\n    std::thread::sleep(Duration::from_millis(\n        cluster.cfg.raft_store.raft_election_timeout_ticks as u64\n            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n            * 2,\n    ));\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // the uncommitted conf-change is committed successfully after being force\n    // leader\n    cluster\n        .pd_client\n        .must_none_peer(region.get_id(), find_peer(&region, 2).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k2\"), Some(b\"v2\".to_vec()));\n    assert_eq!(cluster.must_get(b\"k3\"), None);\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_short_custom_suffix_hyphen_value() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_custom_suffix_file_a\";\n    let file_b = \"test_install_backup_custom_suffix_file_b\";\n    let suffix = \"-v\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"-b\")\n        .arg(format!(\"--suffix={suffix}\"))\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}{suffix}\")));\n}"}
{"code": "pub fn is_extended_connect_protocol_enabled(&self) -> Option<bool> {\n        self.enable_connect_protocol.map(|val| val != 0)\n    }", "test": "async fn reject_non_authority_target_on_connect_request() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let settings = client.assert_server_handshake().await;\n\n        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));\n\n        client\n            .send_frame(frames::headers(1).request(\"CONNECT\", \"https://bread/baguette\"))\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let mut builder = server::Builder::new();\n\n        builder.enable_connect_protocol();\n\n        let mut srv = builder.handshake::<_, Bytes>(io).await.expect(\"handshake\");\n\n        assert!(srv.next().await.is_none());\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn timeout_in_invoke() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/iloop-invoke.wat\")?;\n    let output = run_wasmtime_for_output(\n        &[\n            \"run\",\n            \"-Wtimeout=1ms\",\n            \"-Ccache=n\",\n            wasm.path().to_str().unwrap(),\n        ],\n        None,\n    )?;\n    assert!(!output.status.success());\n    assert_eq!(output.stdout, b\"\");\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"wasm trap: interrupt\"),\n        \"bad stderr: {}\",\n        stderr\n    );\n    Ok(())\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_target_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"-t\")\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_five_nodes() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store5 = find_peer(&region, 5).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());\n\n    cluster.stop_node(3);\n    cluster.stop_node(4);\n    cluster.stop_node(5);\n\n    // quorum is lost, can't propose command successfully.\n    confirm_quorum_is_lost(&mut cluster, &region);\n\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // remove the peers on failed nodes\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());\n    // forbid writes in force leader state\n    let put = new_put_cmd(b\"k3\", b\"v3\");\n    must_get_error_recovery_in_progress(&mut cluster, &region, put);\n    // forbid reads in force leader state\n    let get = new_get_cmd(b\"k1\");\n    must_get_error_recovery_in_progress(&mut cluster, &region, get);\n    // forbid read index in force leader state\n    let read_index = new_read_index_cmd();\n    must_get_error_recovery_in_progress(&mut cluster, &region, read_index);\n\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k2\"), None);\n    assert_eq!(cluster.must_get(b\"k3\"), None);\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "pub fn s2f(buffer: &[u8]) -> Result<f32, Error> {\n    let len = buffer.len();\n    if len == 0 {\n        return Err(Error::InputTooShort);\n    }\n\n    let mut m10digits = 0;\n    let mut e10digits = 0;\n    let mut dot_index = len;\n    let mut e_index = len;\n    let mut m10 = 0u32;\n    let mut e10 = 0i32;\n    let mut signed_m = false;\n    let mut signed_e = false;\n\n    let mut i = 0;\n    if unsafe { *buffer.get_unchecked(0) } == b'-' {\n        signed_m = true;\n        i += 1;\n    }\n\n    while let Some(c) = buffer.get(i).copied() {\n        if c == b'.' {\n            if dot_index != len {\n                return Err(Error::MalformedInput);\n            }\n            dot_index = i;\n            i += 1;\n            continue;\n        }\n        if c < b'0' || c > b'9' {\n            break;\n        }\n        if m10digits >= 9 {\n            return Err(Error::InputTooLong);\n        }\n        m10 = 10 * m10 + (c - b'0') as u32;\n        if m10 != 0 {\n            m10digits += 1;\n        }\n        i += 1;\n    }\n\n    if let Some(b'e') | Some(b'E') = buffer.get(i) {\n        e_index = i;\n        i += 1;\n        match buffer.get(i) {\n            Some(b'-') => {\n                signed_e = true;\n                i += 1;\n            }\n            Some(b'+') => i += 1,\n            _ => {}\n        }\n        while let Some(c) = buffer.get(i).copied() {\n            if c < b'0' || c > b'9' {\n                return Err(Error::MalformedInput);\n            }\n            if e10digits > 3 {\n                // TODO: Be more lenient. Return +/-Infinity or +/-0 instead.\n                return Err(Error::InputTooLong);\n            }\n            e10 = 10 * e10 + (c - b'0') as i32;\n            if e10 != 0 {\n                e10digits += 1;\n            }\n            i += 1;\n        }\n    }\n\n    if i < len {\n        return Err(Error::MalformedInput);\n    }\n    if signed_e {\n        e10 = -e10;\n    }\n    e10 -= if dot_index < e_index {\n        (e_index - dot_index - 1) as i32\n    } else {\n        0\n    };\n    if m10 == 0 {\n        return Ok(if signed_m { -0.0 } else { 0.0 });\n    }\n\n    if m10digits + e10 <= -46 || m10 == 0 {\n        // Number is less than 1e-46, which should be rounded down to 0; return\n        // +/-0.0.\n        let ieee = (signed_m as u32) << (f2s::FLOAT_EXPONENT_BITS + f2s::FLOAT_MANTISSA_BITS);\n        return Ok(f32::from_bits(ieee));\n    }\n    if m10digits + e10 >= 40 {\n        // Number is larger than 1e+39, which should be rounded to +/-Infinity.\n        let ieee = ((signed_m as u32) << (f2s::FLOAT_EXPONENT_BITS + f2s::FLOAT_MANTISSA_BITS))\n            | (0xff_u32 << f2s::FLOAT_MANTISSA_BITS);\n        return Ok(f32::from_bits(ieee));\n    }\n\n    // Convert to binary float m2 * 2^e2, while retaining information about\n    // whether the conversion was exact (trailing_zeros).\n    let e2: i32;\n    let m2: u32;\n    let mut trailing_zeros: bool;\n    if e10 >= 0 {\n        // The length of m * 10^e in bits is:\n        //   log2(m10 * 10^e10) = log2(m10) + e10 log2(10) = log2(m10) + e10 + e10 * log2(5)\n        //\n        // We want to compute the FLOAT_MANTISSA_BITS + 1 top-most bits (+1 for\n        // the implicit leading one in IEEE format). We therefore choose a\n        // binary output exponent of\n        //   log2(m10 * 10^e10) - (FLOAT_MANTISSA_BITS + 1).\n        //\n        // We use floor(log2(5^e10)) so that we get at least this many bits; better to\n        // have an additional bit than to not have enough bits.\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_add(log2_pow5(e10) as u32)\n            .wrapping_sub(f2s::FLOAT_MANTISSA_BITS + 1) as i32;\n\n        // We now compute [m10 * 10^e10 / 2^e2] = [m10 * 5^e10 / 2^(e2-e10)].\n        // To that end, we use the FLOAT_POW5_SPLIT table.\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_sub(ceil_log2_pow5(e10))\n            .wrapping_add(f2s::FLOAT_POW5_BITCOUNT);\n        debug_assert!(j >= 0);\n        m2 = mul_pow5_div_pow2(m10, e10 as u32, j);\n\n        // We also compute if the result is exact, i.e.,\n        //   [m10 * 10^e10 / 2^e2] == m10 * 10^e10 / 2^e2.\n        // This can only be the case if 2^e2 divides m10 * 10^e10, which in turn\n        // requires that the largest power of 2 that divides m10 + e10 is\n        // greater than e2. If e2 is less than e10, then the result must be\n        // exact. Otherwise we use the existing multiple_of_power_of_2 function.\n        trailing_zeros =\n            e2 < e10 || e2 - e10 < 32 && multiple_of_power_of_2_32(m10, (e2 - e10) as u32);\n    } else {\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_sub(ceil_log2_pow5(-e10) as u32)\n            .wrapping_sub(f2s::FLOAT_MANTISSA_BITS + 1) as i32;\n\n        // We now compute [m10 * 10^e10 / 2^e2] = [m10 / (5^(-e10) 2^(e2-e10))].\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_add(ceil_log2_pow5(-e10))\n            .wrapping_sub(1)\n            .wrapping_add(f2s::FLOAT_POW5_INV_BITCOUNT);\n        m2 = mul_pow5_inv_div_pow2(m10, -e10 as u32, j);\n\n        // We also compute if the result is exact, i.e.,\n        //   [m10 / (5^(-e10) 2^(e2-e10))] == m10 / (5^(-e10) 2^(e2-e10))\n        //\n        // If e2-e10 >= 0, we need to check whether (5^(-e10) 2^(e2-e10))\n        // divides m10, which is the case iff pow5(m10) >= -e10 AND pow2(m10) >=\n        // e2-e10.\n        //\n        // If e2-e10 < 0, we have actually computed [m10 * 2^(e10 e2) /\n        // 5^(-e10)] above, and we need to check whether 5^(-e10) divides (m10 *\n        // 2^(e10-e2)), which is the case iff pow5(m10 * 2^(e10-e2)) = pow5(m10)\n        // >= -e10.\n        trailing_zeros = (e2 < e10\n            || (e2 - e10 < 32 && multiple_of_power_of_2_32(m10, (e2 - e10) as u32)))\n            && multiple_of_power_of_5_32(m10, -e10 as u32);\n    }\n\n    // Compute the final IEEE exponent.\n    let mut ieee_e2 = i32::max(0, e2 + FLOAT_EXPONENT_BIAS as i32 + floor_log2(m2) as i32) as u32;\n\n    if ieee_e2 > 0xfe {\n        // Final IEEE exponent is larger than the maximum representable; return\n        // +/-Infinity.\n        let ieee = ((signed_m as u32) << (f2s::FLOAT_EXPONENT_BITS + f2s::FLOAT_MANTISSA_BITS))\n            | (0xff_u32 << f2s::FLOAT_MANTISSA_BITS);\n        return Ok(f32::from_bits(ieee));\n    }\n\n    // We need to figure out how much we need to shift m2. The tricky part is\n    // that we need to take the final IEEE exponent into account, so we need to\n    // reverse the bias and also special-case the value 0.\n    let shift = if ieee_e2 == 0 { 1 } else { ieee_e2 as i32 }\n        .wrapping_sub(e2)\n        .wrapping_sub(FLOAT_EXPONENT_BIAS as i32)\n        .wrapping_sub(f2s::FLOAT_MANTISSA_BITS as i32);\n    debug_assert!(shift >= 0);\n\n    // We need to round up if the exact value is more than 0.5 above the value\n    // we computed. That's equivalent to checking if the last removed bit was 1\n    // and either the value was not just trailing zeros or the result would\n    // otherwise be odd.\n    //\n    // We need to update trailing_zeros given that we have the exact output\n    // exponent ieee_e2 now.\n    trailing_zeros &= (m2 & ((1_u32 << (shift - 1)) - 1)) == 0;\n    let last_removed_bit = (m2 >> (shift - 1)) & 1;\n    let round_up = last_removed_bit != 0 && (!trailing_zeros || ((m2 >> shift) & 1) != 0);\n\n    let mut ieee_m2 = (m2 >> shift).wrapping_add(round_up as u32);\n    debug_assert!(ieee_m2 <= 1_u32 << (f2s::FLOAT_MANTISSA_BITS + 1));\n    ieee_m2 &= (1_u32 << f2s::FLOAT_MANTISSA_BITS) - 1;\n    if ieee_m2 == 0 && round_up {\n        // Rounding up may overflow the mantissa.\n        // In this case we move a trailing zero of the mantissa into the\n        // exponent.\n        // Due to how the IEEE represents +/-Infinity, we don't need to check\n        // for overflow here.\n        ieee_e2 += 1;\n    }\n    let ieee = ((((signed_m as u32) << f2s::FLOAT_EXPONENT_BITS) | ieee_e2)\n        << f2s::FLOAT_MANTISSA_BITS)\n        | ieee_m2;\n    Ok(f32::from_bits(ieee))\n}", "test": "fn test_min_max() {\n    assert_eq!(1e-45, s2f(b\"1e-45\").unwrap());\n    assert_eq!(f32::MIN_POSITIVE, s2f(b\"1.1754944e-38\").unwrap());\n    assert_eq!(f32::MAX, s2f(b\"3.4028235e+38\").unwrap());\n}"}
{"code": "pub fn load(&self, env: &Environment, key: &str) -> Option<Value> {\n        for frame in self.stack.iter().rev() {\n            // look at locals first\n            if let Some(value) = frame.locals.get(key) {\n                return Some(value.clone());\n            }\n\n            // if we are a loop, check if we are looking up the special loop var.\n            if let Some(ref l) = frame.current_loop {\n                if l.with_loop_var && key == \"loop\" {\n                    return Some(Value::from(l.object.clone()));\n                }\n            }\n\n            // perform a fast lookup.  This one will not produce errors if the\n            // context is undefined or of the wrong type.\n            if let Some(rv) = frame.ctx.get_attr_fast(key) {\n                return Some(rv);\n            }\n        }\n\n        env.get_global(key)\n    }", "test": "fn test_no_leak() {\n    let dropped = Arc::new(AtomicBool::new(false));\n\n    struct X(Arc<AtomicBool>);\n\n    impl StructObject for X {\n        fn get_field(&self, _name: &str) -> Option<Value> {\n            None\n        }\n    }\n\n    impl Drop for X {\n        fn drop(&mut self) {\n            self.0.store(true, std::sync::atomic::Ordering::Relaxed);\n        }\n    }\n\n    let ctx = context! {\n        x => Value::from_struct_object(X(dropped.clone())),\n    };\n    let mut env = Environment::new();\n    env.add_template(\"x\", \"{% macro meh() %}{{ x }}{{ meh }}{% endmacro %}\")\n        .unwrap();\n    let rv = env\n        .render_str(\n            r#\"\n        {%- from 'x' import meh %}\n        {{- meh() }}\n        {%- set closure = x %}\n        {%- macro foo() %}{{ foo }}{{ closure }}{% endmacro %}\n        {{- foo() -}}\n\n        {%- for y in range(3) %}\n            {%- set closure = x %}\n            {%- macro foo() %}{{ foo }}{{ closure }}{% endmacro %}\n            {{- foo() -}}\n        {%- endfor -%}\n    \"#,\n            ctx,\n        )\n        .unwrap();\n\n    assert!(dropped.load(std::sync::atomic::Ordering::Relaxed));\n    assert_eq!(\n        rv,\n        \"{}<macro meh><macro foo>{}<macro foo>{}<macro foo>{}<macro foo>{}\"\n    );\n}"}
{"code": "fn method(s: &str) -> Header<Option<HeaderName>> {\n        Header::Method(Method::from_bytes(s.as_bytes()).unwrap())\n    }", "test": "async fn push_request_with_data() {\n    h2_support::trace_init!();\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        client\n            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))\n            .await;\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"GET\", \"https://example.com/\")\n                    .eos(),\n            )\n            .await;\n        client.recv_frame(frames::headers(1).response(200)).await;\n        client\n            .recv_frame(\n                frames::push_promise(1, 2).request(\"GET\", \"https://http2.akamai.com/style.css\"),\n            )\n            .await;\n        client.recv_frame(frames::headers(2).response(200)).await;\n        client.recv_frame(frames::data(1, &b\"\"[..]).eos()).await;\n        client.recv_frame(frames::data(2, &b\"\\x00\"[..]).eos()).await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n        let (req, mut stream) = srv.next().await.unwrap().unwrap();\n\n        assert_eq!(req.method(), &http::Method::GET);\n\n        // Start response to stream 1\n        let mut s1_tx = {\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            stream.send_response(rsp, false).unwrap()\n        };\n\n        // Promise stream 2, push response headers and send data\n        {\n            let pushed_req = http::Request::builder()\n                .method(\"GET\")\n                .uri(\"https://http2.akamai.com/style.css\")\n                .body(())\n                .unwrap();\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            let mut push_tx = stream\n                .push_request(pushed_req)\n                .unwrap()\n                .send_response(rsp, false)\n                .unwrap();\n            // Make sure nothing can queue our pushed stream before we have the PushPromise sent\n            push_tx.send_data(vec![0; 1].into(), true).unwrap();\n            push_tx.reserve_capacity(1);\n        }\n\n        // End response for stream 1\n        s1_tx.send_data(vec![0; 0].into(), true).unwrap();\n\n        assert!(srv.next().await.is_none());\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn bit_length(x: &[Limb]) -> usize {\n        let bits = mem::size_of::<Limb>() * 8;\n        // Avoid overflowing, calculate via total number of bits\n        // minus leading zero bits.\n        let nlz = leading_zeros(x);\n        bits.checked_mul(x.len())\n            .map_or_else(usize::max_value, |v| v - nlz)\n    }", "test": "fn bit_length_test() {\n    let x = Bigint {\n        data: from_u32(&[0, 0, 0, 1]),\n    };\n    assert_eq!(x.bit_length(), 97);\n\n    let x = Bigint {\n        data: from_u32(&[0, 0, 0, 3]),\n    };\n    assert_eq!(x.bit_length(), 98);\n\n    let x = Bigint {\n        data: from_u32(&[1 << 31]),\n    };\n    assert_eq!(x.bit_length(), 32);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_none() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=none\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(!at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn zlib_decoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::write::ZlibEncoder::new(Vec::new(), flate2::Compression::default());\n    encoder.write_all(original).unwrap();\n    let encoded: Vec<u8> = encoder.finish().unwrap();\n    let mut decoder = flate2::read::ZlibDecoder::new(encoded.as_slice());\n    assert_eq!(decoder.read(&mut []).unwrap(), 0);\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"code": "pub fn as_str(&self) -> &str {\n        match self.0 {\n            Options => \"OPTIONS\",\n            Get => \"GET\",\n            Post => \"POST\",\n            Put => \"PUT\",\n            Delete => \"DELETE\",\n            Head => \"HEAD\",\n            Trace => \"TRACE\",\n            Connect => \"CONNECT\",\n            Patch => \"PATCH\",\n            ExtensionInline(ref inline) => inline.as_str(),\n            ExtensionAllocated(ref allocated) => allocated.as_str(),\n        }\n    }", "test": "fn insert_79_custom_std_headers() {\n    let mut h = HeaderMap::new();\n    let hdrs = custom_std(79);\n\n    for (i, hdr) in hdrs.iter().enumerate() {\n        h.insert(hdr.clone(), hdr.as_str().parse().unwrap());\n\n        for j in 0..(i + 1) {\n            assert_eq!(h[&hdrs[j]], hdrs[j].as_str());\n        }\n\n        for j in (i + 1)..hdrs.len() {\n            assert!(h.get(&hdrs[j]).is_none());\n        }\n    }\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_deadline_3() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = {\n        let engine = tikv::storage::TestEngineBuilder::new().build().unwrap();\n        let cfg = tikv::server::Config {\n            end_point_request_max_handle_duration: tikv_util::config::ReadableDuration::secs(1),\n            ..Default::default()\n        };\n        init_data_with_details(Context::default(), engine, &product, &data, true, &cfg)\n    };\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"kv_cursor_seek\", \"sleep(2000)\").unwrap();\n    fail::cfg(\"copr_batch_initial_size\", \"return(1)\").unwrap();\n    let cop_resp = handle_request(&endpoint, req);\n    let mut resp = SelectResponse::default();\n    resp.merge_from_bytes(cop_resp.get_data()).unwrap();\n\n    assert!(\n        cop_resp.other_error.contains(\"exceeding the deadline\")\n            || resp\n                .get_error()\n                .get_msg()\n                .contains(\"exceeding the deadline\")\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_cymdhms_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_cymdhms_time\";\n\n    ucmd.args(&[\"-t\", \"201501011234.56\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M.%S\", \"201501010000.00\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_hibernate_feature_gate() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.pd_client.reset_version(\"4.0.0\");\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait for hibernation check.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n\n    // Ensure leader won't sleep if cluster version is small.\n    let awakened = Arc::new(AtomicBool::new(false));\n    let filter = Arc::new(AtomicBool::new(true));\n    let a = awakened.clone();\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1)\n            .direction(Direction::Send)\n            .set_msg_callback(Arc::new(move |_| {\n                a.store(true, Ordering::SeqCst);\n            }))\n            .when(filter.clone()),\n    ));\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    assert!(awakened.load(Ordering::SeqCst));\n\n    // Simulating all binaries are upgraded to 5.0.0.\n    cluster.pd_client.reset_version(\"5.0.0\");\n    filter.store(false, Ordering::SeqCst);\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    awakened.store(false, Ordering::SeqCst);\n    filter.store(true, Ordering::SeqCst);\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    // Leader can go to sleep as version requirement is met.\n    assert!(!awakened.load(Ordering::SeqCst));\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_semicolon_number_r() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=r/3\", \"--separator=;\", \"separator_semicolon.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1;4;\");\n    assert_eq!(file_read(&at, \"xab\"), \"2;5;\");\n    assert_eq!(file_read(&at, \"xac\"), \"3;\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_backup() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"-b\")\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_read_on_replica_check_memory_locks() {\n    let count = 3;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.cfg.raft_store.hibernate_regions = false;\n    cluster.run();\n\n    let raw_key = b\"key\";\n    let encoded_key = Key::from_raw(raw_key);\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(raw_key), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let leader_cm = cluster.sim.rl().get_concurrency_manager(leader.get_id());\n\n    let lock = Lock::new(\n        LockType::Put,\n        raw_key.to_vec(),\n        10.into(),\n        20000,\n        None,\n        10.into(),\n        1,\n        20.into(),\n    );\n    let guard = block_on(leader_cm.lock_key(&encoded_key));\n    guard.with_lock(|l| *l = Some(lock.clone()));\n\n    // read on follower\n    let mut follower_peer = None;\n    let mut follower_id = 0;\n    let peers = region.get_peers();\n    for p in peers {\n        if p.get_id() != leader.get_id() {\n            follower_id = p.get_id();\n            follower_peer = Some(p.clone());\n            break;\n        }\n    }\n\n    assert!(follower_peer.is_some());\n    let mut follower_ctx = Context::default();\n    follower_ctx.set_region_id(region.get_id());\n    follower_ctx.set_region_epoch(region.get_region_epoch().clone());\n    follower_ctx.set_peer(follower_peer.as_ref().unwrap().clone());\n    follower_ctx.set_replica_read(true);\n    for use_max_ts in [false, true] {\n        let mut range = KeyRange::default();\n        range.set_start_key(encoded_key.as_encoded().to_vec());\n        let ts = if use_max_ts {\n            Some(TimeStamp::max())\n        } else {\n            Some(100.into())\n        };\n        let follower_snap_ctx = SnapContext {\n            pb_ctx: &follower_ctx,\n            start_ts: ts,\n            key_ranges: vec![range],\n            ..Default::default()\n        };\n        let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();\n        match follower_storage.snapshot(follower_snap_ctx) {\n            Err(Error(box ErrorInner::KeyIsLocked(lock_info))) => {\n                assert_eq!(lock_info, lock.clone().into_lock_info(raw_key.to_vec()))\n            }\n            other => panic!(\"unexpected result: {:?}\", other),\n        }\n    }\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_number_with_io_blksize() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_read = |f| {\n        let mut s = String::new();\n        at.open(f).read_to_string(&mut s).unwrap();\n        s\n    };\n    ucmd.args(&[\"-n\", \"5\", \"asciilowercase.txt\", \"---io-blksize\", \"1024\"])\n        .succeeds();\n    assert_eq!(file_read(\"xaa\"), \"abcde\");\n    assert_eq!(file_read(\"xab\"), \"fghij\");\n    assert_eq!(file_read(\"xac\"), \"klmno\");\n    assert_eq!(file_read(\"xad\"), \"pqrst\");\n    assert_eq!(file_read(\"xae\"), \"uvwxyz\\n\");\n}"}
{"code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn client_complete_io_for_handshake_eof() {\n    let (mut client, _) = make_pair(KeyType::Rsa);\n    let mut input = io::Cursor::new(Vec::new());\n\n    assert!(client.is_handshaking());\n    let err = client\n        .complete_io(&mut input)\n        .unwrap_err();\n    assert_eq!(io::ErrorKind::UnexpectedEof, err.kind());\n}"}
{"code": "pub fn recv(&mut self, peer_msg_buf: &mut Vec<PeerMsg>, batch_size: usize) -> usize {\n        let l = peer_msg_buf.len();\n        for i in l..batch_size {\n            match self.receiver.try_recv() {\n                Ok(msg) => peer_msg_buf.push(msg),\n                Err(e) => {\n                    if let TryRecvError::Disconnected = e {\n                        self.is_stopped = true;\n                    }\n                    return i - l;\n                }\n            }\n        }\n        batch_size - l\n    }", "test": "fn test_snap_wait_apply() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n    cluster.cfg.raft_store.store_io_pool_size = 0;\n\n    cluster.run();\n\n    // write a key to let leader stuck.\n    cluster.must_put(b\"k\", b\"v\");\n    must_get_equal(&cluster.get_engine(1), b\"k\", b\"v\");\n    must_get_equal(&cluster.get_engine(2), b\"k\", b\"v\");\n    must_get_equal(&cluster.get_engine(3), b\"k\", b\"v\");\n\n    // add filter to make leader 1 cannot receive follower append response.\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1)\n            .msg_type(MessageType::MsgAppendResponse)\n            .direction(Direction::Recv),\n    ));\n\n    // make a async put request to let leader has inflight raft log.\n    cluster.async_put(b\"k2\", b\"v2\").unwrap();\n    std::thread::sleep(Duration::from_millis(800));\n\n    let router = cluster.sim.wl().get_router(1).unwrap();\n\n    let (tx, rx) = std::sync::mpsc::sync_channel(1);\n\n    router.broadcast_normal(|| {\n        PeerMsg::SignificantMsg(SignificantMsg::SnapshotRecoveryWaitApply(\n            SnapshotRecoveryWaitApplySyncer::new(1, tx.clone()),\n        ))\n    });\n\n    // we expect recv timeout because the leader peer on store 1 cannot finished the\n    // apply. so the wait apply will timeout.\n    rx.recv_timeout(Duration::from_secs(1)).unwrap_err();\n\n    // clear filter so we can make wait apply finished.\n    cluster.clear_send_filters();\n    std::thread::sleep(Duration::from_millis(800));\n\n    // after clear the filter the leader peer on store 1 can finsihed the wait\n    // apply.\n    let (tx, rx) = std::sync::mpsc::sync_channel(1);\n    router.broadcast_normal(|| {\n        PeerMsg::SignificantMsg(SignificantMsg::SnapshotRecoveryWaitApply(\n            SnapshotRecoveryWaitApplySyncer::new(1, tx.clone()),\n        ))\n    });\n\n    // we expect recv the region id from rx.\n    assert_eq!(rx.recv(), Ok(1));\n}"}
{"code": "pub fn get_state(&self) -> Arc<AtomicCell<DownstreamState>> {\n        self.state.clone()\n    }", "test": "fn test_stale_learner_with_read_index() {\n    let mut cluster = new_server_cluster(0, 4);\n    // Do not rely on pd to remove stale peer\n    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::hours(2);\n    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::minutes(20);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::minutes(10);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n    pd_client.must_add_peer(r1, new_learner_peer(3, 3));\n    cluster.must_put(b\"k1\", b\"v1\");\n    let engine3 = cluster.get_engine(3);\n    must_get_equal(&engine3, b\"k1\", b\"v1\");\n\n    // And then isolate peer on store 3 from leader\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n\n    // Delete the learner\n    pd_client.must_remove_peer(r1, new_learner_peer(3, 3));\n\n    cluster.clear_send_filters();\n\n    // Stale learner should exist\n    must_get_equal(&engine3, b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cf_cmd(\"default\", b\"k1\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(3, 3));\n    request.mut_header().set_replica_read(true);\n    let (cb, _) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(3, request, cb)\n        .unwrap();\n\n    // Stale learner should be destroyed due to interaction between leader\n    must_get_none(&engine3, b\"k1\");\n    let state_key = keys::region_state_key(r1);\n    let state: RegionLocalState = engine3.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();\n    assert_eq!(state.get_state(), PeerState::Tombstone);\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn trap_smoke() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let f = Func::wrap(&mut store, || -> Result<()> { bail!(\"test\") });\n    let err = f.call(&mut store, &[], &mut []).unwrap_err();\n    assert!(err.to_string().contains(\"test\"));\n    Ok(())\n}"}
{"code": "fn item_count(&self) -> usize {\n        4\n    }", "test": "fn test_value_object_interface() {\n    let val = Value::from_seq_object(vec![1u32, 2, 3, 4]);\n    let seq = val.as_seq().unwrap();\n    assert_eq!(seq.item_count(), 4);\n\n    let obj = val.as_object().unwrap();\n    let seq2 = match obj.kind() {\n        ObjectKind::Seq(s) => s,\n        _ => panic!(\"did not expect this\"),\n    };\n    assert_eq!(seq2.item_count(), 4);\n    assert_eq!(obj.to_string(), \"[1, 2, 3, 4]\");\n}"}
{"code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_name_old_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-KILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"code": "pub fn plaintext_bytes_to_read(&self) -> usize {\n        self.plaintext_bytes_to_read\n    }", "test": "fn new_client_returns_initial_io_state() {\n    let (mut client, _) = make_pair(KeyType::Rsa);\n    let io_state = client.process_new_packets().unwrap();\n    println!(\"IoState is Debug {:?}\", io_state);\n    assert_eq!(io_state.plaintext_bytes_to_read(), 0);\n    assert!(!io_state.peer_has_closed());\n    assert!(io_state.tls_bytes_to_write() > 200);\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_inodes() {\n    let ts = TestScenario::new(util_name!());\n\n    ts.ucmd()\n        .arg(\"--summarize\")\n        .arg(\"--inodes\")\n        .succeeds()\n        .stdout_only(\"11\\t.\\n\");\n\n    let result = ts.ucmd().arg(\"--separate-dirs\").arg(\"--inodes\").succeeds();\n\n    #[cfg(target_os = \"windows\")]\n    result.stdout_contains(\"3\\t.\\\\subdir\\\\links\\n\");\n    #[cfg(not(target_os = \"windows\"))]\n    result.stdout_contains(\"3\\t./subdir/links\\n\");\n    result.stdout_contains(\"3\\t.\\n\");\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference =\n            unwrap_or_return!(expected_result(&ts, &[\"--separate-dirs\", \"--inodes\"]));\n        assert_eq!(result.stdout_str(), result_reference.stdout_str());\n    }\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn drop_delayed() -> Result<()> {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let engine = Engine::default();\n    let mut linker = Linker::<()>::new(&engine);\n\n    let a = A;\n    linker.func_wrap(\"\", \"\", move || {\n        let _ = &a;\n    })?;\n\n    assert_eq!(HITS.load(SeqCst), 0);\n\n    let module = Module::new(&engine, &wat::parse_str(r#\"(import \"\" \"\" (func))\"#)?)?;\n\n    let mut store = Store::new(&engine, ());\n    let func = linker.get(&mut store, \"\", \"\").unwrap();\n    Instance::new(&mut store, &module, &[func])?;\n\n    drop(store);\n\n    assert_eq!(HITS.load(SeqCst), 0);\n\n    let mut store = Store::new(&engine, ());\n    let func = linker.get(&mut store, \"\", \"\").unwrap();\n    Instance::new(&mut store, &module, &[func])?;\n\n    drop(store);\n\n    assert_eq!(HITS.load(SeqCst), 0);\n\n    drop(linker);\n\n    assert_eq!(HITS.load(SeqCst), 1);\n\n    Ok(())\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn test_limits_table_only() -> Result<()> {\n    let engine = Engine::default();\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (table (export \"t\") 0 anyfunc))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, StoreLimitsBuilder::new().table_elements(5).build());\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    // Test instance exports and host objects *not* hitting the limit\n    for memory in IntoIterator::into_iter([\n        instance.get_memory(&mut store, \"m\").unwrap(),\n        Memory::new(&mut store, MemoryType::new(0, None))?,\n    ]) {\n        memory.grow(&mut store, 3)?;\n        memory.grow(&mut store, 5)?;\n        memory.grow(&mut store, 2)?;\n        memory.grow(&mut store, 1)?;\n    }\n\n    // Test instance exports and host objects hitting the limit\n    for table in IntoIterator::into_iter([\n        instance.get_table(&mut store, \"t\").unwrap(),\n        Table::new(\n            &mut store,\n            TableType::new(ValType::FuncRef, 0, None),\n            Val::FuncRef(None),\n        )?,\n    ]) {\n        table.grow(&mut store, 2, Val::FuncRef(None))?;\n        table.grow(&mut store, 1, Val::FuncRef(None))?;\n        table.grow(&mut store, 2, Val::FuncRef(None))?;\n\n        assert_eq!(\n            table\n                .grow(&mut store, 1, Val::FuncRef(None))\n                .map_err(|e| e.to_string())\n                .unwrap_err(),\n            \"failed to grow table by `1`\"\n        );\n    }\n\n    Ok(())\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn test_encrypted_checkpoint() {\n    let dir = tempdir();\n    let root_path = dir.path();\n\n    let encryption_cfg = test_util::new_file_security_config(root_path);\n    let key_manager = Arc::new(\n        data_key_manager_from_config(&encryption_cfg, root_path.to_str().unwrap())\n            .unwrap()\n            .unwrap(),\n    );\n\n    let mut db_opts = DbOptions::default();\n    db_opts.set_key_manager(Some(key_manager));\n    let cf_opts: Vec<_> = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();\n\n    let path1 = root_path.join(\"1\").to_str().unwrap().to_owned();\n    let db1 = KvTestEngine::new_kv_engine_opt(&path1, db_opts.clone(), cf_opts.clone()).unwrap();\n    db1.put(b\"foo\", b\"bar\").unwrap();\n    db1.sync().unwrap();\n\n    let path2 = root_path.join(\"2\");\n    let mut checkpointer = db1.new_checkpointer().unwrap();\n    checkpointer.create_at(&path2, None, 0).unwrap();\n    let db2 =\n        KvTestEngine::new_kv_engine_opt(path2.to_str().unwrap(), db_opts.clone(), cf_opts.clone())\n            .unwrap();\n    assert_eq!(\n        db2.get_value_cf(CF_DEFAULT, b\"foo\").unwrap().unwrap(),\n        b\"bar\"\n    );\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_output_mp_repeat() {\n    let output1 = new_ucmd!().arg(\"/\").arg(\"/\").succeeds().stdout_move_str();\n    let output1: Vec<String> = output1\n        .lines()\n        .map(|l| String::from(l.split_once(' ').unwrap().0))\n        .collect();\n    assert_eq!(3, output1.len());\n    assert_eq!(output1[1], output1[2]);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_missing_arguments() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let no_target_dir = \"no-target_dir\";\n\n    scene\n        .ucmd()\n        .fails()\n        .code_is(1)\n        .usage_error(\"missing file operand\");\n\n    scene\n        .ucmd()\n        .arg(\"-D\")\n        .arg(format!(\"-t {no_target_dir}\"))\n        .fails()\n        .usage_error(\"missing file operand\");\n    assert!(!at.dir_exists(no_target_dir));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn fill_externref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::ExternRef, 10, None);\n    let table = Table::new(&mut store, table_ty, Val::ExternRef(None))?;\n\n    for i in 0..10 {\n        assert!(table\n            .get(&mut store, i)\n            .unwrap()\n            .unwrap_externref()\n            .is_none());\n    }\n\n    table.fill(\n        &mut store,\n        2,\n        Val::ExternRef(Some(ExternRef::new(42_usize))),\n        4,\n    )?;\n\n    for i in (0..2).chain(7..10) {\n        assert!(table\n            .get(&mut store, i)\n            .unwrap()\n            .unwrap_externref()\n            .is_none());\n    }\n    for i in 2..6 {\n        assert_eq!(\n            *table\n                .get(&mut store, i)\n                .unwrap()\n                .unwrap_externref()\n                .unwrap()\n                .data()\n                .downcast_ref::<usize>()\n                .unwrap(),\n            42\n        );\n    }\n\n    Ok(())\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_after_put() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &255_usize.to_be_bytes())\n        .unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..255_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n    assert!(\n        db.engine\n            .get_value(&255_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_target_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_ln_target_dir_dir\";\n    let file_a = \"test_ln_target_dir_file_a\";\n    let file_b = \"test_ln_target_dir_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    at.mkdir(dir);\n\n    ucmd.args(&[\"-s\", \"-t\", dir, file_a, file_b])\n        .succeeds()\n        .no_stderr();\n\n    let file_a_link = &format!(\"{dir}/{file_a}\");\n    assert!(at.is_symlink(file_a_link));\n    assert_eq!(at.resolve_link(file_a_link), file_a);\n\n    let file_b_link = &format!(\"{dir}/{file_b}\");\n    assert!(at.is_symlink(file_b_link));\n    assert_eq!(at.resolve_link(file_b_link), file_b);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_never() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=never\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_d_flag() {\n    let ts = TestScenario::new(util_name!());\n\n    let result = ts.ucmd().arg(\"-d1\").succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[\"-d1\"]));\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n    _du_d_flag(result.stdout_str());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_runs_linter_not_formatter_issue_3495() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), INCORRECT_CODE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"ci target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_runs_linter_not_formatter_issue_3495\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn swap_remove(&mut self, index: usize) -> A::Item {\n    assert!(\n      index < self.len(),\n      \"ArrayVec::swap_remove> index {} is out of bounds {}\",\n      index,\n      self.len\n    );\n    if index == self.len() - 1 {\n      self.pop().unwrap()\n    } else {\n      let i = self.pop().unwrap();\n      replace(&mut self[index], i)\n    }\n  }", "test": "fn TinyVec_swap_remove() {\n  let mut tv: TinyVec<[i32; 10]> = Default::default();\n  tv.push(1);\n  tv.push(2);\n  tv.push(3);\n  tv.push(4);\n  assert_eq!(tv.swap_remove(3), 4);\n  assert_eq!(&tv[..], &[1, 2, 3][..]);\n  assert_eq!(tv.swap_remove(0), 1);\n  assert_eq!(&tv[..], &[3, 2][..]);\n  assert_eq!(tv.swap_remove(0), 3);\n  assert_eq!(&tv[..], &[2][..]);\n  assert_eq!(tv.swap_remove(0), 2);\n  assert_eq!(&tv[..], &[][..]);\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_effective_suffix_numeric_last() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\n        \"-n\",\n        \"4\",\n        \"--numeric-suffixes=7\",\n        \"--hex-suffixes=4\",\n        \"-d\",\n        \"-x\",\n        \"--numeric-suffixes=9\",\n        \"threebytes.txt\",\n    ])\n    .succeeds()\n    .no_stdout()\n    .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x10\"), \"b\");\n    assert_eq!(at.read(\"x11\"), \"c\");\n    assert_eq!(at.read(\"x12\"), \"\");\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nl_line_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--line-bytes=4\", \"-t\", \"\\n\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n\")\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\n2\\n\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\n4\\n\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\n\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_remove_existing_same_src_and_dest() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    at.touch(\"a\");\n    at.write(\"a\", \"sample\");\n    ucmd.args(&[\"-sf\", \"a\", \"a\"])\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"'a' and 'a' are the same file\");\n    assert!(at.file_exists(\"a\") && !at.symlink_exists(\"a\"));\n    assert_eq!(at.read(\"a\"), \"sample\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_shred_remove() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_shred_remove_a\";\n    let file_b = \"test_shred_remove_b\";\n\n    // Create file_a and file_b.\n    at.touch(file_a);\n    at.touch(file_b);\n\n    // Shred file_a.\n    scene.ucmd().arg(\"-u\").arg(file_a).succeeds();\n\n    // file_a was deleted, file_b exists.\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "pub(crate) fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.page.memory()[self.value_range.clone()])\n    }", "test": "fn drain_filter_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    let mut table = txn.open_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.drain_filter(start.as_str().., |_, _| true).unwrap()\n    };\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), \"world\");\n    assert!(iter.next().is_none());\n}"}
{"code": "pub fn accept(&self) -> Accept<'_> {\n        Accept {\n            endpoint: self,\n            notify: self.inner.shared.incoming.notified(),\n        }\n    }", "test": "fn stop_during_finish() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive();\n\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    info!(\"stopping and finishing stream\");\n    const ERROR: VarInt = VarInt(42);\n    pair.server_recv(server_ch, s).stop(ERROR).unwrap();\n    pair.drive_server();\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive_client();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Stopped { id, error_code: ERROR })) if id == s\n    );\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_none(),\n            }\n        }\n    }", "test": "fn write_batch_delete() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"aa\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete(b\"a\").unwrap();\n\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n\n    let db = multi_batch_write_engine();\n\n    for i in 0..127_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n    db.engine.put(b\"a\", b\"aa\").unwrap();\n    for i in 127..255_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..255_usize {\n        let k = i.to_be_bytes();\n        wb.delete(&k).unwrap();\n    }\n    wb.delete(b\"a\").unwrap();\n\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n    for i in 0..255_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn stream_id(&self) -> StreamId {\n        self.stream_id\n    }", "test": "async fn read_data_end_stream() {\n    let mut codec = raw_codec! {\n        read => [\n            0, 0, 5, 0, 1, 0, 0, 0, 1,\n            \"hello\",\n        ];\n    };\n\n    let data = poll_frame!(Data, codec);\n    assert_eq!(data.stream_id(), 1);\n    assert_eq!(data.payload(), &b\"hello\"[..]);\n    assert!(data.is_end_stream());\n    assert_closed!(codec);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_underflow_relative_size() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-s-1\", FILE1])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert!(at.file_exists(FILE1));\n    assert!(at.read_bytes(FILE1).is_empty());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_dereferenced_symlink() {\n    let fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"check_rome_test_broken_symlink\");\n    let subdir_path = root_path.join(\"prefix\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(subdir_path).unwrap();\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(root_path.join(\"null\"), root_path.join(\"broken_symlink\")).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_file(\n            root_path.join(\"null\"),\n            root_path.join(\"broken_symlink\")\n        ));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"check\"), root_path.display().to_string().as_str()].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_dereferenced_symlink\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_combined_file_set() {\n    let out = new_ucmd!()\n        .arg(\"-f\")\n        .arg(\"vars.conf.txt\")\n        .arg(\"FOO=bar.alt\")\n        .run()\n        .stdout_move_str();\n\n    assert_eq!(out.lines().filter(|&line| line == \"FOO=bar.alt\").count(), 1);\n}"}
{"code": "pub fn compact(&mut self) -> Result<bool, CompactionError> {\n        // Commit to free up any pending free pages\n        // Use 2-phase commit to avoid any possible security issues. Plus this compaction is going to be so slow that it doesn't matter\n        let mut txn = self.begin_write().map_err(|e| e.into_storage_error())?;\n        if txn.list_persistent_savepoints()?.next().is_some() {\n            return Err(CompactionError::PersistentSavepointExists);\n        }\n        if self\n            .transaction_tracker\n            .lock()\n            .unwrap()\n            .any_savepoint_exists()\n        {\n            return Err(CompactionError::EphemeralSavepointExists);\n        }\n        txn.set_durability(Durability::Paranoid);\n        txn.commit().map_err(|e| e.into_storage_error())?;\n        // Repeat, just in case executing list_persistent_savepoints() created a new table\n        let mut txn = self.begin_write().map_err(|e| e.into_storage_error())?;\n        txn.set_durability(Durability::Paranoid);\n        txn.commit().map_err(|e| e.into_storage_error())?;\n        // There can't be any outstanding transactions because we have a `&mut self`, so all pending free pages\n        // should have been cleared out by the above commit()\n        assert!(self.mem.get_freed_root().is_none());\n\n        let mut compacted = false;\n        // Iteratively compact until no progress is made\n        loop {\n            let mut progress = false;\n\n            let mut txn = self.begin_write().map_err(|e| e.into_storage_error())?;\n            if txn.compact_pages()? {\n                progress = true;\n                txn.commit().map_err(|e| e.into_storage_error())?;\n            } else {\n                txn.abort()?;\n            }\n\n            // Double commit to free up the relocated pages for reuse\n            let mut txn = self.begin_write().map_err(|e| e.into_storage_error())?;\n            txn.set_durability(Durability::Paranoid);\n            txn.commit().map_err(|e| e.into_storage_error())?;\n            assert!(self.mem.get_freed_root().is_none());\n\n            if !progress {\n                break;\n            } else {\n                compacted = true;\n            }\n        }\n\n        Ok(compacted)\n    }", "test": "fn compaction() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let definition: TableDefinition<u32, &[u8]> = TableDefinition::new(\"x\");\n\n    let big_value = vec![0u8; 100 * 1024];\n\n    let txn = db.begin_write().unwrap();\n    {\n        let mut table = txn.open_table(definition).unwrap();\n        // Insert 10MiB of data\n        for i in 0..100 {\n            table.insert(&i, big_value.as_slice()).unwrap();\n        }\n    }\n    txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    {\n        let mut table = txn.open_table(definition).unwrap();\n        // Delete 90% of it\n        for i in 0..90 {\n            table.remove(&i).unwrap();\n        }\n    }\n    txn.commit().unwrap();\n    // Second commit to trigger dynamic compaction\n    let txn = db.begin_write().unwrap();\n    txn.commit().unwrap();\n\n    // The values are > 1 page, so shouldn't get relocated. Therefore there should be a bunch of fragmented space,\n    // since we left the last 100 values in the db.\n    drop(db);\n    let file_size = tmpfile.as_file().metadata().unwrap().len();\n    let mut db = Database::open(tmpfile.path()).unwrap();\n\n    assert!(db.compact().unwrap());\n    drop(db);\n    let file_size2 = tmpfile.as_file().metadata().unwrap().len();\n    assert!(file_size2 < file_size);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_multi_1() {\n    let mut headers = HeaderMap::new();\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 1);\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_into_self_data() {\n    let scene = TestScenario::new(util_name!());\n\n    let at = &scene.fixtures;\n    let sub_dir = \"sub_folder\";\n    let file1 = \"t1.test\";\n    let file2 = \"sub_folder/t2.test\";\n\n    let file1_result_location = \"sub_folder/t1.test\";\n\n    at.mkdir(sub_dir);\n    at.touch(file1);\n    at.touch(file2);\n\n    let result = scene.ucmd().arg(file1).arg(sub_dir).arg(sub_dir).run();\n\n    // sub_dir exists, file1 has been moved, file2 still exists.\n    result.code_is(1);\n\n    assert!(at.dir_exists(sub_dir));\n    assert!(at.file_exists(file1_result_location));\n    assert!(at.file_exists(file2));\n    assert!(!at.file_exists(file1));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_no_clobber() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_no_clobber_file_a\";\n    let file_b = \"test_mv_no_clobber_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"-n\")\n        .arg(file_a)\n        .arg(file_b)\n        .fails()\n        .code_is(1)\n        .stderr_only(format!(\"mv: not replacing '{file_b}'\\n\"));\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "fn len(&self) -> usize {\n        self.buf.len()\n    }", "test": "fn test_debug_region_size() {\n    let (cluster, debug_client, store_id) = must_new_cluster_and_debug_client();\n    let engine = cluster.get_engine(store_id);\n\n    // Put some data.\n    let region_id = 100;\n    let region_state_key = keys::region_state_key(region_id);\n    let mut region = metapb::Region::default();\n    region.set_id(region_id);\n    region.set_start_key(b\"a\".to_vec());\n    region.set_end_key(b\"z\".to_vec());\n    let mut state = RegionLocalState::default();\n    state.set_region(region);\n    engine\n        .put_msg_cf(CF_RAFT, &region_state_key, &state)\n        .unwrap();\n\n    let cfs = vec![CF_DEFAULT, CF_LOCK, CF_WRITE];\n    // At lease 8 bytes for the WRITE cf.\n    let (k, v) = (keys::data_key(b\"kkkk_kkkk\"), b\"v\");\n    for cf in &cfs {\n        engine.put_cf(cf, k.as_slice(), v).unwrap();\n    }\n\n    let mut req = debugpb::RegionSizeRequest::default();\n    req.set_region_id(region_id);\n    req.set_cfs(cfs.iter().map(|s| s.to_string()).collect());\n    let entries: Vec<_> = debug_client\n        .region_size(&req)\n        .unwrap()\n        .take_entries()\n        .into();\n    assert_eq!(entries.len(), 3);\n    for e in entries {\n        cfs.iter().find(|&&c| c == e.cf).unwrap();\n        assert!(e.size > 0);\n    }\n\n    req.set_region_id(region_id + 1);\n    match debug_client.region_size(&req).unwrap_err() {\n        Error::RpcFailure(status) => {\n            assert_eq!(status.code(), RpcStatusCode::NOT_FOUND);\n        }\n        _ => panic!(\"expect NotFound\"),\n    }\n}"}
{"code": "pub const fn encoded_len(bytes_len: usize, padding: bool) -> Option<usize> {\n    let rem = bytes_len % 3;\n\n    let complete_input_chunks = bytes_len / 3;\n    // `let Some(_) = _ else` requires 1.65.0, whereas this messier one works on 1.48\n    let complete_chunk_output =\n        if let Some(complete_chunk_output) = complete_input_chunks.checked_mul(4) {\n            complete_chunk_output\n        } else {\n            return None;\n        };\n\n    if rem > 0 {\n        if padding {\n            complete_chunk_output.checked_add(4)\n        } else {\n            let encoded_rem = match rem {\n                1 => 2,\n                // only other possible remainder is 2\n                // can't use a separate _ => unreachable!() in const fns in ancient rust versions\n                _ => 3,\n            };\n            complete_chunk_output.checked_add(encoded_rem)\n        }\n    } else {\n        Some(complete_chunk_output)\n    }\n}", "test": "fn encoded_len_padded() {\n    assert_eq!(0, encoded_len(0, true).unwrap());\n    assert_eq!(4, encoded_len(1, true).unwrap());\n    assert_eq!(4, encoded_len(2, true).unwrap());\n    assert_eq!(4, encoded_len(3, true).unwrap());\n    assert_eq!(8, encoded_len(4, true).unwrap());\n    assert_eq!(8, encoded_len(5, true).unwrap());\n    assert_eq!(8, encoded_len(6, true).unwrap());\n    assert_eq!(12, encoded_len(7, true).unwrap());\n}"}
{"code": "pub fn parse_sql_statements(&self, sql: &str) -> Result<Vec<Statement>, ParserError> {\n        self.one_of_identical_results(|dialect| {\n            let mut tokenizer = Tokenizer::new(dialect, sql);\n            if let Some(options) = &self.options {\n                tokenizer = tokenizer.with_unescape(options.unescape);\n            }\n            let tokens = tokenizer.tokenize()?;\n            self.new_parser(dialect)\n                .with_tokens(tokens)\n                .parse_statements()\n        })\n        // To fail the `ensure_multiple_dialects_are_tested` test:\n        // Parser::parse_sql(&**self.dialects.first().unwrap(), sql)\n    }", "test": "fn parse_alter_role() {\n    let sql = \"ALTER ROLE old_name WITH NAME = new_name\";\n    assert_eq!(\n        ms().parse_sql_statements(sql).unwrap(),\n        [Statement::AlterRole {\n            name: Ident {\n                value: \"old_name\".into(),\n                quote_style: None\n            },\n            operation: AlterRoleOperation::RenameRole {\n                role_name: Ident {\n                    value: \"new_name\".into(),\n                    quote_style: None\n                }\n            },\n        }]\n    );\n\n    let sql = \"ALTER ROLE role_name ADD MEMBER new_member\";\n    assert_eq!(\n        ms().verified_stmt(sql),\n        Statement::AlterRole {\n            name: Ident {\n                value: \"role_name\".into(),\n                quote_style: None\n            },\n            operation: AlterRoleOperation::AddMember {\n                member_name: Ident {\n                    value: \"new_member\".into(),\n                    quote_style: None\n                }\n            },\n        }\n    );\n\n    let sql = \"ALTER ROLE role_name DROP MEMBER old_member\";\n    assert_eq!(\n        ms().verified_stmt(sql),\n        Statement::AlterRole {\n            name: Ident {\n                value: \"role_name\".into(),\n                quote_style: None\n            },\n            operation: AlterRoleOperation::DropMember {\n                member_name: Ident {\n                    value: \"old_member\".into(),\n                    quote_style: None\n                }\n            },\n        }\n    );\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_datagram_stream_upgrades_on_truncation() {\n    // Lookup to UDP should return a truncated message, then we expect lookup on TCP.\n    // This should occur even though `try_tcp_on_error` is set to false.\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n\n    let mut udp_message = message(query.clone(), vec![], vec![], vec![]);\n    udp_message.set_truncated(true);\n\n    let tcp_message = message(query.clone(), vec![tcp_record.clone()], vec![], vec![]);\n\n    let udp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        Default::default(),\n    );\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver],\n        vec![tcp_nameserver],\n        None,\n        Default::default(),\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], tcp_record);\n}"}
{"code": "pub fn descriptors(&self) -> Vec<String> {\n    self.state().descriptors.clone()\n  }", "test": "fn restore_generates_same_descriptors() {\n  let (mnemonic, descriptors) = {\n    let rpc_server = test_bitcoincore_rpc::spawn();\n\n    let create::Output { mnemonic, .. } = CommandBuilder::new(\"wallet create\")\n      .rpc_server(&rpc_server)\n      .run_and_deserialize_output();\n\n    (mnemonic, rpc_server.descriptors())\n  };\n\n  let rpc_server = test_bitcoincore_rpc::spawn();\n\n  CommandBuilder::new([\"wallet\", \"restore\", &mnemonic.to_string()])\n    .rpc_server(&rpc_server)\n    .run_and_deserialize_output::<Empty>();\n\n  assert_eq!(rpc_server.descriptors(), descriptors);\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn i128_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n\n    let definition: TableDefinition<i128, i128> = TableDefinition::new(\"x\");\n\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        for i in -10..=10 {\n            table.insert(&i, &(i - 1)).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert_eq!(-2, table.get(&-1).unwrap().unwrap().value());\n    let mut iter: Range<i128, i128> = table.range::<i128>(..).unwrap();\n    for i in -11..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i);\n    }\n    assert!(iter.next().is_none());\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_inconsistent_configuration() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n\n    // Ensure leader can sleep if all nodes enable hibernate region.\n    let awakened = Arc::new(AtomicBool::new(false));\n    let filter = Arc::new(AtomicBool::new(true));\n    let a = awakened.clone();\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1)\n            .direction(Direction::Send)\n            .set_msg_callback(Arc::new(move |_| {\n                a.store(true, Ordering::SeqCst);\n            }))\n            .when(filter.clone()),\n    ));\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    assert!(!awakened.load(Ordering::SeqCst));\n\n    // Simulate rolling disable hibernate region in followers\n    filter.store(false, Ordering::SeqCst);\n    cluster.cfg.raft_store.hibernate_regions = false;\n    cluster.stop_node(3);\n    cluster.run_node(3).unwrap();\n    cluster.must_put(b\"k2\", b\"v2\");\n    // In case leader changes.\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    awakened.store(false, Ordering::SeqCst);\n    filter.store(true, Ordering::SeqCst);\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    // Leader should keep awake as peer 3 won't agree to sleep.\n    assert!(awakened.load(Ordering::SeqCst));\n    cluster.reset_leader_of_region(1);\n    assert_eq!(cluster.leader_of_region(1), Some(new_peer(1, 1)));\n\n    // Simulate rolling disable hibernate region in leader\n    cluster.clear_send_filters();\n    cluster.must_transfer_leader(1, new_peer(3, 3));\n    cluster.must_put(b\"k3\", b\"v3\");\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 3\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    awakened.store(false, Ordering::SeqCst);\n    let a = awakened.clone();\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 3)\n            .direction(Direction::Send)\n            .set_msg_callback(Arc::new(move |_| {\n                a.store(true, Ordering::SeqCst);\n            })),\n    ));\n    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);\n    // Leader should keep awake as hibernate region is disabled.\n    assert!(awakened.load(Ordering::SeqCst));\n    cluster.reset_leader_of_region(1);\n    assert_eq!(cluster.leader_of_region(1), Some(new_peer(3, 3)));\n}"}
{"code": "fn is_success() {\n    assert!(status_code(200).is_success());\n    assert!(status_code(299).is_success());\n\n    assert!(!status_code(199).is_success());\n    assert!(!status_code(300).is_success());\n}", "test": "fn is_success() {\n    assert!(status_code(200).is_success());\n    assert!(status_code(299).is_success());\n\n    assert!(!status_code(199).is_success());\n    assert!(!status_code(300).is_success());\n}"}
{"code": "pub fn join(self, rhs: Self) -> Self {\n        let must_return = self.must_return() && rhs.must_return();\n        let explicit = self.may_return_explicit() || rhs.may_return_explicit();\n        let implicit = self.may_return_implicit() || rhs.may_return_implicit();\n\n        Self::create(must_return, explicit, implicit)\n    }", "test": "fn absolute_path() {\n    let f = super::fixture();\n    let resolver = Resolver::new(ResolveOptions {\n        alias: vec![(f.join(\"foo\").to_str().unwrap().to_string(), vec![AliasValue::Ignore])],\n        modules: vec![f.clone().to_str().unwrap().to_string()],\n        ..ResolveOptions::default()\n    });\n    let resolution = resolver.resolve(&f, \"foo/index\");\n    assert_eq!(resolution, Err(ResolveError::Ignored(f.join(\"foo\"))));\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_concurrent_requests_1_conn() {\n    let mut options = ResolverOpts::default();\n\n    // there are two connections, but no concurrency requested\n    options.num_concurrent_reqs = 1;\n\n    // we want to make sure that both udp connections are called\n    //   this will count down to 0 only if both are called.\n    let on_send = OnSendBarrier::new(1);\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n\n    let udp1_nameserver = mock_nameserver_on_send(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        options.clone(),\n        on_send,\n    );\n    let udp2_nameserver = udp1_nameserver.clone();\n\n    let pool = mock_nameserver_pool_on_send(\n        vec![udp2_nameserver, udp1_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    // there's no actual network traffic happening, 1 sec should be plenty\n    //   TODO: for some reason this timeout doesn't work, not clear why...\n    // let future = Timeout::new(future, Duration::from_secs(1));\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"code": "pub const fn decimal() -> u128 {\n        let mut builder = Self::new();\n        builder.mantissa_radix = 10;\n        builder.exponent_base = num::NonZeroU8::new(10);\n        builder.exponent_radix = num::NonZeroU8::new(10);\n        builder.build()\n    }", "test": "fn u128toa_test() {\n    let mut buffer = [b'\\x00'; 48];\n    unsafe {\n        assert_eq!(5u128.decimal(&mut buffer), 1);\n        assert_eq!(&buffer[..1], b\"5\");\n\n        assert_eq!(11u128.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"11\");\n\n        assert_eq!(99u128.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"99\");\n\n        assert_eq!(101u128.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"101\");\n\n        assert_eq!(999u128.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"999\");\n\n        assert_eq!(1001u128.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"1001\");\n\n        assert_eq!(9999u128.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"9999\");\n\n        assert_eq!(10001u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"10001\");\n\n        assert_eq!(65535u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"65535\");\n\n        assert_eq!(99999u128.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"99999\");\n\n        assert_eq!(100001u128.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"100001\");\n\n        assert_eq!(999999u128.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"999999\");\n\n        assert_eq!(1000001u128.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"1000001\");\n\n        assert_eq!(9999999u128.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"9999999\");\n\n        assert_eq!(10000001u128.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"10000001\");\n\n        assert_eq!(99999999u128.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"99999999\");\n\n        assert_eq!(100000001u128.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"100000001\");\n\n        assert_eq!(999999999u128.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"999999999\");\n\n        assert_eq!(1000000001u128.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"1000000001\");\n\n        assert_eq!(9999999999u128.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"9999999999\");\n\n        assert_eq!(10000000001u128.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"10000000001\");\n\n        assert_eq!(99999999999u128.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"99999999999\");\n\n        assert_eq!(100000000001u128.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"100000000001\");\n\n        assert_eq!(999999999999u128.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"999999999999\");\n\n        assert_eq!(1000000000001u128.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"1000000000001\");\n\n        assert_eq!(9999999999999u128.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"9999999999999\");\n\n        assert_eq!(10000000000001u128.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"10000000000001\");\n\n        assert_eq!(99999999999999u128.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"99999999999999\");\n\n        assert_eq!(100000000000001u128.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"100000000000001\");\n\n        assert_eq!(999999999999999u128.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"999999999999999\");\n\n        assert_eq!(1000000000000001u128.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"1000000000000001\");\n\n        assert_eq!(9999999999999999u128.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"9999999999999999\");\n\n        assert_eq!(10000000000000001u128.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"10000000000000001\");\n\n        assert_eq!(99999999999999999u128.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"99999999999999999\");\n\n        assert_eq!(100000000000000001u128.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"100000000000000001\");\n\n        assert_eq!(999999999999999999u128.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"999999999999999999\");\n\n        assert_eq!(1000000000000000001u128.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"1000000000000000001\");\n\n        assert_eq!(9999999999999999999u128.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"9999999999999999999\");\n\n        assert_eq!(10000000000000000001u128.decimal(&mut buffer), 20);\n        assert_eq!(&buffer[..20], b\"10000000000000000001\");\n\n        assert_eq!(999999999999999999999999u128.decimal(&mut buffer), 24);\n        assert_eq!(&buffer[..24], b\"999999999999999999999999\");\n\n        assert_eq!(1000000000000000000000001u128.decimal(&mut buffer), 25);\n        assert_eq!(&buffer[..25], b\"1000000000000000000000001\");\n\n        assert_eq!(66620387370000000000000000000u128.decimal(&mut buffer), 29);\n        assert_eq!(&buffer[..29], b\"66620387370000000000000000000\");\n\n        assert_eq!(99999999999999999999999999999u128.decimal(&mut buffer), 29);\n        assert_eq!(&buffer[..29], b\"99999999999999999999999999999\");\n\n        assert_eq!(100000000000000000000000000001u128.decimal(&mut buffer), 30);\n        assert_eq!(&buffer[..30], b\"100000000000000000000000000001\");\n\n        assert_eq!(9999999999999999999999999999999999u128.decimal(&mut buffer), 34);\n        assert_eq!(&buffer[..34], b\"9999999999999999999999999999999999\");\n\n        assert_eq!(10000000000000000000000000000000001u128.decimal(&mut buffer), 35);\n        assert_eq!(&buffer[..35], b\"10000000000000000000000000000000001\");\n\n        assert_eq!(340282366920938463463374607431768211455u128.decimal(&mut buffer), 39);\n        assert_eq!(&buffer[..39], b\"340282366920938463463374607431768211455\");\n    }\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn handshake_anti_deadlock_probe() {\n    let _guard = subscribe();\n\n    let (cert, key) = big_cert_and_key();\n    let server = server_config_with_cert(cert.clone(), key);\n    let client = client_config_with_certs(vec![cert]);\n    let mut pair = Pair::new(Default::default(), server);\n\n    let client_ch = pair.begin_connect(client);\n    // Client sends initial\n    pair.drive_client();\n    // Server sends first flight, gets blocked on anti-amplification\n    pair.drive_server();\n    // Client acks...\n    pair.drive_client();\n    // ...but it's lost, so the server doesn't get anti-amplification credit from it\n    pair.server.inbound.clear();\n    // Client sends an anti-deadlock probe, and the handshake completes as usual.\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"code": "pub fn eq_case(&self, other: &Self) -> bool {\n        self.cmp_with_f::<CaseSensitive>(other) == Ordering::Equal\n    }", "test": "fn test_query_edns(client: &mut AsyncClient) -> impl Future<Output = ()> {\n    let name = Name::from_ascii(\"WWW.example.com\").unwrap();\n    let mut edns = Edns::new();\n    // garbage subnet value, but lets check\n    edns.options_mut()\n        .insert(EdnsOption::Subnet(\"1.2.0.0/16\".parse().unwrap()));\n\n    // TODO: write builder\n    let mut msg = Message::new();\n    msg.add_query({\n        let mut query = Query::query(name.clone(), RecordType::A);\n        query.set_query_class(DNSClass::IN);\n        query\n    })\n    .set_id(rand::random::<u16>())\n    .set_message_type(MessageType::Query)\n    .set_op_code(OpCode::Query)\n    .set_recursion_desired(true)\n    .set_edns(edns)\n    .extensions_mut()\n    .as_mut()\n    .map(|edns| edns.set_max_payload(1232).set_version(0));\n\n    client\n        .send(msg)\n        .first_answer()\n        .map_ok(move |response| {\n            println!(\"response records: {response:?}\");\n            assert!(response\n                .queries()\n                .first()\n                .expect(\"expected query\")\n                .name()\n                .eq_case(&name));\n\n            let record = &response.answers()[0];\n            assert_eq!(record.name(), &name);\n            assert_eq!(record.record_type(), RecordType::A);\n            assert_eq!(record.dns_class(), DNSClass::IN);\n            assert!(response.extensions().is_some());\n            assert_eq!(\n                response\n                    .extensions()\n                    .as_ref()\n                    .unwrap()\n                    .option(EdnsCode::Subnet)\n                    .unwrap(),\n                &EdnsOption::Subnet(\"1.2.0.0/16\".parse().unwrap())\n            );\n            if let RData::A(ref address) = *record.data().unwrap() {\n                assert_eq!(address, &A::new(93, 184, 216, 34))\n            } else {\n                panic!();\n            }\n        })\n        .map(|r: Result<_, _>| r.expect(\"query failed\"))\n}"}
{"code": "pub fn len(&self) -> usize {\n        match self {\n            Focus::Single(chunk) => chunk.len(),\n            Focus::Full(tree) => tree.len(),\n        }\n    }", "test": "fn test_something() {\n    let data = [];\n    let mut vec = Vector::new();\n    let mut nat = Vec::new();\n    vec.assert_invariants();\n    for action in actions {\n        match action {\n            Action::PushFront(value) => {\n                let len = vec.len();\n                nat.insert(0, value);\n                vec.push_front(value);\n                assert_eq!(len + 1, vec.len());\n            }\n            Action::PushBack(value) => {\n                let len = vec.len();\n                nat.push(value);\n                vec.push_back(value);\n                assert_eq!(len + 1, vec.len());\n            }\n            Action::PopFront => {\n                if vec.is_empty() {\n                    assert_eq!(None, vec.pop_front());\n                } else {\n                    let len = vec.len();\n                    assert_eq!(nat.remove(0), vec.pop_front().unwrap());\n                    assert_eq!(len - 1, vec.len());\n                }\n            }\n            Action::PopBack => {\n                if vec.is_empty() {\n                    assert_eq!(None, vec.pop_back());\n                } else {\n                    let len = vec.len();\n                    assert_eq!(nat.pop(), vec.pop_back());\n                    assert_eq!(len - 1, vec.len());\n                }\n            }\n            Action::Insert(index, value) => {\n                let index = cap_index(vec.len(), index);\n                let len = vec.len();\n                nat.insert(index, value);\n                vec.insert(index, value);\n                assert_eq!(len + 1, vec.len());\n            }\n            Action::Remove(index) => {\n                if vec.is_empty() {\n                    continue;\n                }\n                let index = cap_index(vec.len(), index);\n                let len = vec.len();\n                assert_eq!(nat.remove(index), vec.remove(index));\n                assert_eq!(len - 1, vec.len());\n            }\n            Action::JoinLeft(mut new_nat) => {\n                let mut new_vec = Vector::from_iter(new_nat.iter().cloned());\n                let add_len = new_nat.len();\n                let len = vec.len();\n                new_vec.append(vec);\n                vec = new_vec;\n                new_nat.append(&mut nat);\n                nat = new_nat;\n                assert_eq!(len + add_len, vec.len());\n            }\n            Action::JoinRight(mut new_nat) => {\n                let new_vec = Vector::from_iter(new_nat.iter().cloned());\n                let add_len = new_nat.len();\n                let len = vec.len();\n                vec.append(new_vec);\n                nat.append(&mut new_nat);\n                assert_eq!(len + add_len, vec.len());\n            }\n            Action::SplitLeft(index) => {\n                let index = cap_index(vec.len(), index);\n                let len = vec.len();\n                let vec_right = vec.split_off(index);\n                let nat_right = nat.split_off(index);\n                assert_eq!(index, vec.len());\n                assert_eq!(len - index, vec_right.len());\n                assert_eq!(Vector::from_iter(nat_right.iter().cloned()), vec_right);\n            }\n            Action::SplitRight(index) => {\n                let index = cap_index(vec.len(), index);\n                let len = vec.len();\n                let vec_right = vec.split_off(index);\n                let nat_right = nat.split_off(index);\n                assert_eq!(index, vec.len());\n                assert_eq!(len - index, vec_right.len());\n                assert_eq!(Vector::from_iter(nat.iter().cloned()), vec);\n                vec = vec_right;\n                nat = nat_right;\n            }\n        }\n        vec.assert_invariants();\n        assert_eq!(nat.len(), vec.len());\n        assert_eq!(Vector::from_iter(nat.iter().cloned()), vec);\n    }\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_lt() {\n    // Test iterators that skip single, leading or trailing-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_leading_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"_45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"_45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"_45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"_4__5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"4_5.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"_4__5_.56\");\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_batch_size_limit() {\n    let msg_count = Arc::new(AtomicUsize::new(0));\n    let batch_msg_count = Arc::new(AtomicUsize::new(0));\n    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), true);\n    let (mock_server, port) = create_mock_server(service, 60200, 60300).unwrap();\n\n    let mut raft_client = get_raft_client_by_port(port);\n\n    // `send` should success.\n    for _ in 0..10 {\n        // 5M per RaftMessage.\n        let mut raft_m = RaftMessage::default();\n        for _ in 0..(5 * 1024) {\n            let mut e = Entry::default();\n            e.set_data(vec![b'a'; 1024].into());\n            raft_m.mut_message().mut_entries().push(e);\n        }\n        raft_client.send(raft_m).unwrap();\n    }\n    raft_client.flush();\n\n    check_msg_count(500, &msg_count, 10);\n    // The final received message count should be 10 exactly.\n    drop(raft_client);\n    drop(mock_server);\n    assert_eq!(msg_count.load(Ordering::SeqCst), 10);\n}"}
{"code": "pub fn cie_count(&self) -> usize {\n        self.cies.len()\n    }", "test": "fn test_convert_eh_frame() {\n    // Convert existing section\n    let eh_frame = read_section(\"eh_frame\");\n    let mut eh_frame = read::EhFrame::new(&eh_frame, LittleEndian);\n    // The `.eh_frame` fixture data was created on a 64-bit machine.\n    eh_frame.set_address_size(8);\n    let frames = write::FrameTable::from(&eh_frame, &|address| Some(Address::Constant(address)))\n        .expect(\"Should convert eh_frame information\");\n    assert_eq!(frames.cie_count(), 2);\n    assert_eq!(frames.fde_count(), 3482);\n\n    // Write to new section\n    let mut write_eh_frame = write::EhFrame(EndianVec::new(LittleEndian));\n    frames\n        .write_eh_frame(&mut write_eh_frame)\n        .expect(\"Should write eh_frame information\");\n    let eh_frame = write_eh_frame.slice();\n    assert_eq!(eh_frame.len(), 147144);\n\n    // Convert new section\n    let mut eh_frame = read::EhFrame::new(&eh_frame, LittleEndian);\n    eh_frame.set_address_size(8);\n    let frames = write::FrameTable::from(&eh_frame, &|address| Some(Address::Constant(address)))\n        .expect(\"Should convert eh_frame information\");\n    assert_eq!(frames.cie_count(), 2);\n    assert_eq!(frames.fde_count(), 3482);\n}"}
{"code": "pub fn len(&self) -> usize {\n        match self {\n            Fields::Unit => 0,\n            Fields::Named(f) => f.named.len(),\n            Fields::Unnamed(f) => f.unnamed.len(),\n        }\n    }", "test": "fn test_fn_precedence_in_where_clause() {\n    // This should parse as two separate bounds, `FnOnce() -> i32` and `Send` - not\n    // `FnOnce() -> (i32 + Send)`.\n    let input = quote! {\n        fn f<G>()\n        where\n            G: FnOnce() -> i32 + Send,\n        {\n        }\n    };\n\n    snapshot!(input as ItemFn, @r###\"\n    ItemFn {\n        vis: Visibility::Inherited,\n        sig: Signature {\n            ident: \"f\",\n            generics: Generics {\n                lt_token: Some,\n                params: [\n                    GenericParam::Type(TypeParam {\n                        ident: \"G\",\n                    }),\n                ],\n                gt_token: Some,\n                where_clause: Some(WhereClause {\n                    predicates: [\n                        WherePredicate::Type(PredicateType {\n                            bounded_ty: Type::Path {\n                                path: Path {\n                                    segments: [\n                                        PathSegment {\n                                            ident: \"G\",\n                                        },\n                                    ],\n                                },\n                            },\n                            bounds: [\n                                TypeParamBound::Trait(TraitBound {\n                                    path: Path {\n                                        segments: [\n                                            PathSegment {\n                                                ident: \"FnOnce\",\n                                                arguments: PathArguments::Parenthesized {\n                                                    output: ReturnType::Type(\n                                                        Type::Path {\n                                                            path: Path {\n                                                                segments: [\n                                                                    PathSegment {\n                                                                        ident: \"i32\",\n                                                                    },\n                                                                ],\n                                                            },\n                                                        },\n                                                    ),\n                                                },\n                                            },\n                                        ],\n                                    },\n                                }),\n                                TypeParamBound::Trait(TraitBound {\n                                    path: Path {\n                                        segments: [\n                                            PathSegment {\n                                                ident: \"Send\",\n                                            },\n                                        ],\n                                    },\n                                }),\n                            ],\n                        }),\n                    ],\n                }),\n            },\n            output: ReturnType::Default,\n        },\n        block: Block,\n    }\n    \"###);\n\n    let where_clause = input.sig.generics.where_clause.as_ref().unwrap();\n    assert_eq!(where_clause.predicates.len(), 1);\n\n    let predicate = match &where_clause.predicates[0] {\n        WherePredicate::Type(pred) => pred,\n        _ => panic!(\"wrong predicate kind\"),\n    };\n\n    assert_eq!(predicate.bounds.len(), 2, \"{:#?}\", predicate.bounds);\n\n    let first_bound = &predicate.bounds[0];\n    assert_eq!(quote!(#first_bound).to_string(), \"FnOnce () -> i32\");\n\n    let second_bound = &predicate.bounds[1];\n    assert_eq!(quote!(#second_bound).to_string(), \"Send\");\n}"}
{"code": "pub(crate) fn stdout(mut self, stdout: impl Into<String>) -> Self {\n    self.stdout = stdout.into();\n    self\n  }", "test": "fn junk_is_other() {\n  assert_eq!(stdout(\"refs/tags/asdf\"), \"::set-output name=value::other\\n\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_cymdhm_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_cymdhm_time\";\n\n    ucmd.args(&[\"-t\", \"201501011234\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n}"}
{"code": "pub fn checked_add(self, offset: TextSize) -> Option<TextRange> {\n        Some(TextRange {\n            start: self.start.checked_add(offset)?,\n            end: self.end.checked_add(offset)?,\n        })\n    }", "test": "fn checked_math() {\n    assert_eq!(size(1).checked_add(size(1)), Some(size(2)));\n    assert_eq!(size(1).checked_sub(size(1)), Some(size(0)));\n    assert_eq!(size(1).checked_sub(size(2)), None);\n    assert_eq!(size(!0).checked_add(size(1)), None);\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_older_dest_older() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_none_file1\";\n    let new = \"test_mv_arg_update_none_file2\";\n    let old_content = \"file1 content\\n\";\n    let new_content = \"file2 content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(new)\n        .arg(old)\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(old), new_content);\n}"}
{"code": "fn b<F: Float>(float: F) -> (u64, i32) {\n    let fp = slow::b(float);\n    (fp.mant, fp.exp)\n}", "test": "fn b_test() {\n    assert_eq!(b(1e-45_f32), (1, -149));\n    assert_eq!(b(5e-324_f64), (1, -1074));\n    assert_eq!(b(1e-323_f64), (2, -1074));\n    assert_eq!(b(2e-323_f64), (4, -1074));\n    assert_eq!(b(3e-323_f64), (6, -1074));\n    assert_eq!(b(4e-323_f64), (8, -1074));\n    assert_eq!(b(5e-323_f64), (10, -1074));\n    assert_eq!(b(6e-323_f64), (12, -1074));\n    assert_eq!(b(7e-323_f64), (14, -1074));\n    assert_eq!(b(8e-323_f64), (16, -1074));\n    assert_eq!(b(9e-323_f64), (18, -1074));\n    assert_eq!(b(1_f32), (8388608, -23));\n    assert_eq!(b(1_f64), (4503599627370496, -52));\n    assert_eq!(b(1e38_f32), (9860761, 103));\n    assert_eq!(b(1e308_f64), (5010420900022432, 971));\n}"}
{"code": "fn should_write_to_engine(&self) -> bool {\n        panic!()\n    }", "test": "fn should_write_to_engine_but_whatever() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;\n\n    let mut key = vec![];\n    loop {\n        key.push(b'a');\n        wb.put(&key, b\"\").unwrap();\n        if key.len() <= max_keys {\n            assert!(!wb.should_write_to_engine());\n        }\n        if key.len() > max_keys {\n            assert!(wb.should_write_to_engine());\n        }\n        if key.len() == max_keys * 2 {\n            assert!(wb.should_write_to_engine());\n            wb.write().unwrap();\n            break;\n        }\n    }\n\n    let mut key = vec![];\n    loop {\n        key.push(b'a');\n        assert!(db.engine.get_value(&key).unwrap().is_some());\n        if key.len() == max_keys * 2 {\n            break;\n        }\n    }\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;\n\n    let mut key = vec![];\n\n    loop {\n        key.push(b'a');\n        wb.put(&key, b\"\").unwrap();\n        if key.len() <= max_keys {\n            assert!(!wb.should_write_to_engine());\n        }\n        if key.len() > max_keys {\n            assert!(wb.should_write_to_engine());\n        }\n        if key.len() == max_keys * 2 {\n            assert!(wb.should_write_to_engine());\n            wb.write().unwrap();\n            break;\n        }\n    }\n\n    let mut key = vec![];\n    loop {\n        key.push(b'a');\n        assert!(db.engine.get_value(&key).unwrap().is_some());\n        if key.len() == max_keys * 2 {\n            break;\n        }\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_timeout_abort() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::millis(150);\n    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::millis(100);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::millis(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n    cluster.put(b\"random_key1\", b\"random_val1\").unwrap();\n\n    // Blocks the raft apply process on store 1 entirely.\n    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);\n    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"on_handle_apply_store_1\", move || {\n        let _ = apply_triggered_tx.send(());\n        let _ = apply_released_rx.recv();\n    })\n    .unwrap();\n\n    // Manually makes an update, and wait for the apply to be triggered, to\n    // simulate \"some entries are committed but not applied\" scenario.\n    cluster.put(b\"random_key2\", b\"random_val2\").unwrap();\n    apply_triggered_rx\n        .recv_timeout(Duration::from_secs(1))\n        .unwrap();\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n\n    // Triggers the unsafe recovery store reporting process.\n    let plan = pdpb::RecoveryPlan::default();\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // sleep for a while to trigger timeout\n    fail::cfg(\"unsafe_recovery_state_timeout\", \"return\").unwrap();\n    sleep_ms(200);\n    fail::remove(\"unsafe_recovery_state_timeout\");\n\n    // Unblocks the apply process.\n    drop(apply_released_tx);\n\n    // No store report is sent, cause the plan is aborted.\n    for _ in 0..20 {\n        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);\n        sleep_ms(100);\n    }\n\n    // resend the plan\n    let plan = pdpb::RecoveryPlan::default();\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // Store reports are sent once the entries are applied.\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    fail::remove(\"on_handle_apply_store_1\");\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit2_wasi_snapshot0() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit2_wasi_snapshot0.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 2);\n    Ok(())\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_parse_request_failed() {\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"coprocessor_parse_request\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"unsupported tp\"));\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn dtor_delayed() -> Result<()> {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let mut store = Store::<()>::default();\n    let a = A;\n    let func = Func::wrap(&mut store, move || {\n        let _ = &a;\n    });\n\n    assert_eq!(HITS.load(SeqCst), 0);\n    let wasm = wat::parse_str(r#\"(import \"\" \"\" (func))\"#)?;\n    let module = Module::new(store.engine(), &wasm)?;\n    let _instance = Instance::new(&mut store, &module, &[func.into()])?;\n    assert_eq!(HITS.load(SeqCst), 0);\n    drop(store);\n    assert_eq!(HITS.load(SeqCst), 1);\n    Ok(())\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_lc() {\n    // Test iterators that skip multiple, leading digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_leading_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4__.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5__.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"45__.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"4_5_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"4__5__.56\");\n}"}
{"code": "pub fn name(&self) -> &str {\n        &self.data.file_name\n    }", "test": "fn aes256_encrypted_file() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"data/aes_archive.zip\"));\n    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    let mut file = archive\n        .by_name_decrypt(\"secret_data_256\", PASSWORD)\n        .expect(\"couldn't find file in archive\")\n        .expect(\"invalid password\");\n    assert_eq!(\"secret_data_256\", file.name());\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"couldn't read encrypted and compressed file\");\n    assert_eq!(SECRET_CONTENT, content);\n}"}
{"code": "pub fn swap_remove(&mut self, index: usize) -> A::Item {\n    assert!(\n      index < self.len(),\n      \"ArrayVec::swap_remove> index {} is out of bounds {}\",\n      index,\n      self.len\n    );\n    if index == self.len() - 1 {\n      self.pop().unwrap()\n    } else {\n      let i = self.pop().unwrap();\n      replace(&mut self[index], i)\n    }\n  }", "test": "fn ArrayVec_swap_remove() {\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n  av.push(4);\n  assert_eq!(av.swap_remove(3), 4);\n  assert_eq!(&av[..], &[1, 2, 3][..]);\n  assert_eq!(av.swap_remove(0), 1);\n  assert_eq!(&av[..], &[3, 2][..]);\n  assert_eq!(av.swap_remove(0), 3);\n  assert_eq!(&av[..], &[2][..]);\n  assert_eq!(av.swap_remove(0), 2);\n  assert_eq!(&av[..], &[][..]);\n}"}
{"code": "pub(crate) fn is_informational(&self) -> bool {\n        self.header_block.pseudo.is_informational()\n    }", "test": "async fn reject_informational_status_header_in_request() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let _ = client.assert_server_handshake().await;\n\n        let status_code = 128;\n        assert!(StatusCode::from_u16(status_code)\n            .unwrap()\n            .is_informational());\n\n        client\n            .send_frame(frames::headers(1).response(status_code))\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let builder = server::Builder::new();\n        let mut srv = builder.handshake::<_, Bytes>(io).await.expect(\"handshake\");\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn message_type(&self) -> MessageType {\n        self.message_type\n    }", "test": "async fn test_multiple_cname_additionals() {\n    let example = create_example();\n    let origin = example.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin, Box::new(Arc::new(example)));\n\n    let mut question: Message = Message::new();\n\n    let mut query: Query = Query::new();\n    query.set_name(Name::from_str(\"alias2.example.com.\").unwrap());\n    query.set_query_type(RecordType::A);\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let answers: &[Record] = result.answers();\n    assert_eq!(answers.len(), 1);\n    assert_eq!(answers.first().unwrap().record_type(), RecordType::CNAME);\n    assert_eq!(\n        answers.first().unwrap().data().unwrap(),\n        &RData::CNAME(CNAME(Name::from_str(\"alias.example.com.\").unwrap()))\n    );\n\n    // we should have the intermediate record\n    let additionals: &[Record] = result.additionals();\n    assert!(!additionals.is_empty());\n    assert_eq!(\n        additionals.first().unwrap().record_type(),\n        RecordType::CNAME\n    );\n    assert_eq!(\n        additionals.first().unwrap().data().unwrap(),\n        &RData::CNAME(CNAME(Name::from_str(\"www.example.com.\").unwrap()))\n    );\n\n    // final record should be the actual\n    let additionals: &[Record] = result.additionals();\n    assert!(!additionals.is_empty());\n    assert_eq!(additionals.last().unwrap().record_type(), RecordType::A);\n    assert_eq!(\n        additionals.last().unwrap().data().unwrap(),\n        &RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn handle_ws_for_if_nodes() {\n    let end_ws = WS { left: false, right: true };\n    let ast = vec![\n        Node::Text(\"C \".to_string()),\n        Node::If(\n            If {\n                conditions: vec![\n                    (\n                        WS { left: true, right: true },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                    (\n                        WS { left: true, right: false },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                    (\n                        WS { left: true, right: true },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                ],\n                otherwise: None,\n            },\n            end_ws,\n        ),\n        Node::Text(\"  hey\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::Text(\"C\".to_string()),\n            Node::If(\n                If {\n                    conditions: vec![\n                        (\n                            WS { left: true, right: true },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\"a\".to_string())],\n                        ),\n                        (\n                            WS { left: true, right: false },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\" a\".to_string())],\n                        ),\n                        (\n                            WS { left: true, right: true },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\"a \".to_string())],\n                        ),\n                    ],\n                    otherwise: None,\n                },\n                end_ws,\n            ),\n            Node::Text(\"hey\".to_string()),\n        ]\n    );\n}"}
{"code": "pub fn as_str(&self) -> &str {\n        let offset = (self.0.get() - 100) as usize;\n        let offset = offset * 3;\n\n        // Invariant: self has checked range [100, 999] and CODE_DIGITS is\n        // ASCII-only, of length 900 * 3 = 2700 bytes\n\n        #[cfg(debug_assertions)]\n        { &CODE_DIGITS[offset..offset+3] }\n\n        #[cfg(not(debug_assertions))]\n        unsafe { CODE_DIGITS.get_unchecked(offset..offset+3) }\n    }", "test": "fn insert_all_std_headers() {\n    let mut m = HeaderMap::new();\n\n    for (i, hdr) in STD.iter().enumerate() {\n        m.insert(hdr.clone(), hdr.as_str().parse().unwrap());\n\n        for j in 0..(i + 1) {\n            assert_eq!(m[&STD[j]], STD[j].as_str());\n        }\n\n        if i != 0 {\n            for j in (i + 1)..STD.len() {\n                assert!(\n                    m.get(&STD[j]).is_none(),\n                    \"contained {}; j={}\",\n                    STD[j].as_str(),\n                    j\n                );\n            }\n        }\n    }\n}"}
{"code": "fn get(&self, _: &[u8]) -> Option<&[u8]> {\n        None\n    }", "test": "fn test_txn_create_compaction_filter() {\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n\n    let mut cfg = DbConfig::default();\n    cfg.writecf.disable_auto_compactions = true;\n    cfg.writecf.dynamic_level_bytes = false;\n    let dir = tempfile::TempDir::new().unwrap();\n    let builder = TestEngineBuilder::new().path(dir.path());\n    let mut engine = builder.build_with_cfg(&cfg).unwrap();\n    let raw_engine = engine.get_rocksdb();\n\n    let mut gc_runner = TestGcRunner::new(0);\n    let value = vec![b'v'; 512];\n\n    must_prewrite_put(&mut engine, b\"zkey\", &value, b\"zkey\", 100);\n    must_commit(&mut engine, b\"zkey\", 100, 110);\n\n    gc_runner\n        .safe_point(TimeStamp::new(1).into_inner())\n        .gc(&raw_engine);\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        1\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        1\n    );\n\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n}"}
{"code": "pub async fn wait_proposed(&mut self) -> bool {\n        WaitEvent {\n            event: CmdResChannel::PROPOSED_EVENT,\n            core: &self.core,\n        }\n        .await\n    }", "test": "fn test_write_batch_rollback() {\n    let mut cluster = Cluster::default();\n    let router = &mut cluster.routers[0];\n    let header = Box::new(router.new_request_for(2).take_header());\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key\", b\"value\");\n\n    router.wait_applied_to_current_term(2, Duration::from_secs(3));\n    // Make several entries to batch in apply thread.\n    fail::cfg(\"APPLY_COMMITTED_ENTRIES\", \"pause\").unwrap();\n\n    // Good proposal should be committed.\n    let (msg, mut sub0) = PeerMsg::simple_write(header.clone(), put.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub0.wait_proposed()));\n    assert!(block_on(sub0.wait_committed()));\n\n    // If the write batch is correctly initialized, next write should not contain\n    // last result.\n    put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key1\", b\"value\");\n    let (msg, mut sub1) = PeerMsg::simple_write(header.clone(), put.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub1.wait_proposed()));\n    assert!(block_on(sub1.wait_committed()));\n\n    fail::cfg(\"APPLY_PUT\", \"1*return()\").unwrap();\n    // Wake up and sleep in next committed entry.\n    fail::remove(\"APPLY_COMMITTED_ENTRIES\");\n    // First apply will fail due to aborted. If write batch is initialized\n    // correctly, correct response can be returned.\n    let resp = block_on(sub0.result()).unwrap();\n    assert!(\n        resp.get_header()\n            .get_error()\n            .get_message()\n            .contains(\"aborted\"),\n        \"{:?}\",\n        resp\n    );\n    let resp = block_on(sub1.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    let snap = router.stale_snapshot(2);\n    assert_matches!(snap.get_value(b\"key\"), Ok(None));\n    assert_eq!(snap.get_value(b\"key1\").unwrap().unwrap(), b\"value\");\n\n    fail::cfg(\"APPLY_COMMITTED_ENTRIES\", \"pause\").unwrap();\n\n    // Trigger error again, so an initialized write batch should be rolled back.\n    put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key2\", b\"value\");\n    let (msg, mut sub0) = PeerMsg::simple_write(header.clone(), put.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub0.wait_proposed()));\n    assert!(block_on(sub0.wait_committed()));\n\n    // If the write batch is correctly rollbacked, next write should not contain\n    // last result.\n    put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key3\", b\"value\");\n    let (msg, mut sub1) = PeerMsg::simple_write(header, put.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub1.wait_proposed()));\n    assert!(block_on(sub1.wait_committed()));\n\n    fail::cfg(\"APPLY_PUT\", \"1*return()\").unwrap();\n    fail::remove(\"APPLY_COMMITTED_ENTRIES\");\n    let resp = block_on(sub0.result()).unwrap();\n    assert!(\n        resp.get_header()\n            .get_error()\n            .get_message()\n            .contains(\"aborted\"),\n        \"{:?}\",\n        resp\n    );\n    let resp = block_on(sub1.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    let snap = router.stale_snapshot(2);\n    assert_matches!(snap.get_value(b\"key2\"), Ok(None));\n    assert_eq!(snap.get_value(b\"key3\").unwrap().unwrap(), b\"value\");\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_no_change_to_user() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    for (i, from) in [\"42\", \":42\", \"42:42\"].iter().enumerate() {\n        let file = i.to_string();\n        at.touch(&file);\n        scene\n            .ucmd()\n            .arg(\"-v\")\n            .arg(format!(\"--from={from}\"))\n            .arg(\"43\")\n            .arg(&file)\n            .succeeds()\n            .stdout_only(format!(\"ownership of '{file}' retained as {user_name}\\n\"));\n    }\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_v1_simple_write() {\n    let mut cluster_v2 = test_raftstore_v2::new_node_cluster(1, 2);\n    let mut cluster_v1 = test_raftstore::new_node_cluster(1, 2);\n    cluster_v1.cfg.tikv.raft_store.enable_v2_compatible_learner = true;\n    cluster_v1.pd_client.disable_default_operator();\n    cluster_v2.pd_client.disable_default_operator();\n    let r11 = cluster_v1.run_conf_change();\n    let r21 = cluster_v2.run_conf_change();\n\n    cluster_v1.must_put(b\"k0\", b\"v0\");\n    cluster_v2.must_put(b\"k0\", b\"v0\");\n    cluster_v1\n        .pd_client\n        .must_add_peer(r11, new_learner_peer(2, 10));\n    cluster_v2\n        .pd_client\n        .must_add_peer(r21, new_learner_peer(2, 10));\n    check_key_in_engine(&cluster_v1.get_engine(2), b\"zk0\", b\"v0\");\n    check_key_in_engine(&cluster_v2.get_engine(2), b\"zk0\", b\"v0\");\n    let trans1 = Mutex::new(cluster_v1.sim.read().unwrap().get_router(2).unwrap());\n    let trans2 = Mutex::new(cluster_v2.sim.read().unwrap().get_router(1).unwrap());\n\n    let factory1 = ForwardFactory {\n        node_id: 1,\n        chain_send: Arc::new(move |m| {\n            info!(\"send to trans2\"; \"msg\" => ?m);\n            let _ = trans2.lock().unwrap().send_raft_message(Box::new(m));\n        }),\n    };\n    cluster_v1.add_send_filter(factory1);\n    let factory2 = ForwardFactory {\n        node_id: 2,\n        chain_send: Arc::new(move |m| {\n            info!(\"send to trans1\"; \"msg\" => ?m);\n            let _ = trans1.lock().unwrap().send_raft_message(m);\n        }),\n    };\n    cluster_v2.add_send_filter(factory2);\n    let filter11 = Box::new(\n        RegionPacketFilter::new(r11, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend)\n            .msg_type(MessageType::MsgAppendResponse)\n            .msg_type(MessageType::MsgSnapshot)\n            .msg_type(MessageType::MsgHeartbeat)\n            .msg_type(MessageType::MsgHeartbeatResponse),\n    );\n    cluster_v1.add_recv_filter_on_node(2, filter11);\n\n    cluster_v2.must_put(b\"k1\", b\"v1\");\n    assert_eq!(\n        cluster_v2.must_get(b\"k1\").unwrap(),\n        \"v1\".as_bytes().to_vec()\n    );\n    check_key_in_engine(&cluster_v1.get_engine(2), b\"zk1\", b\"v1\");\n\n    cluster_v1.shutdown();\n    cluster_v2.shutdown();\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nl_number_r() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=r/3\", \"--separator\", \"\\n\", \"fivelines.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\n4\\n\");\n    assert_eq!(file_read(&at, \"xab\"), \"2\\n5\\n\");\n    assert_eq!(file_read(&at, \"xac\"), \"3\\n\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_basic() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&32_usize.to_be_bytes(), &128_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n    for i in 0..32_usize {\n        let x = i.to_be_bytes();\n        assert!(db.engine.get_value(&x).unwrap().is_some());\n    }\n    for i in 32..128_usize {\n        let x = i.to_be_bytes();\n        assert!(db.engine.get_value(&x).unwrap().is_none());\n    }\n    for i in 128..256_usize {\n        let x = i.to_be_bytes();\n        assert!(db.engine.get_value(&x).unwrap().is_some());\n    }\n}"}
{"code": "fn smallest_key(&self) -> &[u8] {\n        panic!()\n    }", "test": "fn external_sst_info_key_values_with_delete() -> Result<()> {\n    let tempdir = tempdir();\n    let sst_path = tempdir\n        .path()\n        .join(\"test-data.sst\")\n        .to_string_lossy()\n        .to_string();\n    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();\n    let mut sst_writer = sst_builder.build(&sst_path)?;\n\n    sst_writer.delete(b\"k1\")?;\n\n    let info = sst_writer.finish()?;\n\n    assert_eq!(b\"k1\", info.smallest_key());\n    assert_eq!(b\"k1\", info.largest_key());\n    assert_eq!(1, info.num_entries());\n\n    let size = fs::metadata(&sst_path).unwrap().len();\n\n    assert_eq!(size, info.file_size());\n\n    Ok(())\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_integer128() {\n    let signed = &[i128::min_value(), -1, 0, 1, i128::max_value()];\n    let unsigned = &[0, 1, u128::max_value()];\n\n    for integer128 in signed {\n        let expected = integer128.to_string();\n        assert_eq!(to_string(integer128).unwrap(), expected);\n        assert_eq!(from_str::<i128>(&expected).unwrap(), *integer128);\n    }\n\n    for integer128 in unsigned {\n        let expected = integer128.to_string();\n        assert_eq!(to_string(integer128).unwrap(), expected);\n        assert_eq!(from_str::<u128>(&expected).unwrap(), *integer128);\n    }\n\n    test_parse_err::<i128>(&[\n        (\n            \"-170141183460469231731687303715884105729\",\n            \"number out of range at line 1 column 40\",\n        ),\n        (\n            \"170141183460469231731687303715884105728\",\n            \"number out of range at line 1 column 39\",\n        ),\n    ]);\n\n    test_parse_err::<u128>(&[\n        (\"-1\", \"number out of range at line 1 column 1\"),\n        (\n            \"340282366920938463463374607431768211456\",\n            \"number out of range at line 1 column 39\",\n        ),\n    ]);\n}"}
{"code": "pub fn bh<F: RawFloat>(float: F) -> ExtendedFloat80 {\n    let fp = b(float);\n    ExtendedFloat80 {\n        mant: (fp.mant << 1) + 1,\n        exp: fp.exp - 1,\n    }\n}", "test": "fn bh_test() {\n    assert_eq!(bh(1e-45_f32), (3, -150));\n    assert_eq!(bh(5e-324_f64), (3, -1075));\n    assert_eq!(bh(1_f32), (16777217, -24));\n    assert_eq!(bh(1_f64), (9007199254740993, -53));\n    assert_eq!(bh(1e38_f32), (19721523, 102));\n    assert_eq!(bh(1e308_f64), (10020841800044865, 970));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_suspend_import() {\n    let (_cluster, ctx, tikv, import) = new_cluster_and_tikv_import_client();\n    let sst_range = (0, 10);\n    let write = |sst_range: (u8, u8)| {\n        let mut meta = new_sst_meta(0, 0);\n        meta.set_region_id(ctx.get_region_id());\n        meta.set_region_epoch(ctx.get_region_epoch().clone());\n\n        let mut keys = vec![];\n        let mut values = vec![];\n        for i in sst_range.0..sst_range.1 {\n            keys.push(vec![i]);\n            values.push(vec![i]);\n        }\n        send_write_sst(&import, &meta, keys, values, 1)\n    };\n    let ingest = |sst_meta: &SstMeta| {\n        let mut ingest = IngestRequest::default();\n        ingest.set_context(ctx.clone());\n        ingest.set_sst(sst_meta.clone());\n        import.ingest(&ingest)\n    };\n    let multi_ingest = |sst_metas: &[SstMeta]| {\n        let mut multi_ingest = MultiIngestRequest::default();\n        multi_ingest.set_context(ctx.clone());\n        multi_ingest.set_ssts(sst_metas.to_vec().into());\n        import.multi_ingest(&multi_ingest)\n    };\n    let suspendctl = |for_time| {\n        let mut req = SuspendImportRpcRequest::default();\n        req.set_caller(\"test_suspend_import\".to_owned());\n        if for_time == 0 {\n            req.set_should_suspend_imports(false);\n        } else {\n            req.set_should_suspend_imports(true);\n            req.set_duration_in_secs(for_time);\n        }\n        req\n    };\n\n    let write_res = write(sst_range).unwrap();\n    assert_eq!(write_res.metas.len(), 1);\n    let sst = write_res.metas[0].clone();\n\n    assert!(\n        !import\n            .suspend_import_rpc(&suspendctl(6000))\n            .unwrap()\n            .already_suspended\n    );\n    let write_res = write(sst_range);\n    write_res.unwrap();\n    let ingest_res = ingest(&sst);\n    assert_to_string_contains!(ingest_res.unwrap_err(), \"Suspended\");\n    let multi_ingest_res = multi_ingest(&[sst.clone()]);\n    assert_to_string_contains!(multi_ingest_res.unwrap_err(), \"Suspended\");\n\n    assert!(\n        import\n            .suspend_import_rpc(&suspendctl(0))\n            .unwrap()\n            .already_suspended\n    );\n\n    let ingest_res = ingest(&sst);\n    assert!(ingest_res.is_ok(), \"{:?} => {:?}\", sst, ingest_res);\n\n    check_ingested_txn_kvs(&tikv, &ctx, sst_range, 2);\n\n    // test timeout.\n    assert!(\n        !import\n            .suspend_import_rpc(&suspendctl(1))\n            .unwrap()\n            .already_suspended\n    );\n    let sst_range = (10, 20);\n    let write_res = write(sst_range);\n    let sst = write_res.unwrap().metas;\n    let res = multi_ingest(&sst);\n    assert_to_string_contains!(res.unwrap_err(), \"Suspended\");\n    std::thread::sleep(Duration::from_secs(1));\n    multi_ingest(&sst).unwrap();\n\n    // check an insane value should be rejected.\n    import\n        .suspend_import_rpc(&suspendctl(u64::MAX - 42))\n        .unwrap_err();\n    let sst_range = (20, 30);\n    let ssts = write(sst_range).unwrap();\n    multi_ingest(ssts.get_metas()).unwrap();\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.header.response_code()\n    }", "test": "fn test_server_unknown_type() {\n    let runtime = Runtime::new().expect(\"failed to create Tokio Runtime\");\n    let addr = SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(127, 0, 0, 1), 0));\n    let udp_socket = runtime.block_on(UdpSocket::bind(&addr)).unwrap();\n\n    let ipaddr = udp_socket.local_addr().unwrap();\n    println!(\"udp_socket on port: {ipaddr}\");\n    let server_continue = Arc::new(AtomicBool::new(true));\n    let server_continue2 = server_continue.clone();\n\n    let server_thread = thread::Builder::new()\n        .name(\"test_server:udp:server\".to_string())\n        .spawn(move || server_thread_udp(runtime, udp_socket, server_continue2))\n        .unwrap();\n\n    let conn = UdpClientConnection::new(ipaddr).unwrap();\n    let client = SyncClient::new(conn);\n    let client_result = client\n        .query(\n            &Name::from_str(\"www.example.com.\").unwrap(),\n            DNSClass::IN,\n            RecordType::Unknown(65535),\n        )\n        .expect(\"query failed for unknown\");\n\n    assert_eq!(client_result.response_code(), ResponseCode::NoError);\n    assert_eq!(\n        client_result.queries().first().unwrap().query_type(),\n        RecordType::Unknown(65535)\n    );\n    assert!(client_result.answers().is_empty());\n    assert!(!client_result.name_servers().is_empty());\n    // SOA should be the first record in the response\n    assert_eq!(\n        client_result\n            .name_servers()\n            .first()\n            .expect(\"no SOA present\")\n            .record_type(),\n        RecordType::SOA\n    );\n\n    server_continue.store(false, Ordering::Relaxed);\n    server_thread.join().unwrap();\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn reserved_capacity_assigned_in_multi_window_updates() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let (response, mut stream) = client.send_request(request, false).unwrap();\n\n        // Consume the capacity\n        let payload = vec![0; frame::DEFAULT_INITIAL_WINDOW_SIZE as usize];\n        stream.send_data(payload.into(), false).unwrap();\n\n        // Reserve more data than we want\n        stream.reserve_capacity(10);\n\n        let mut stream = h2.drive(util::wait_for_capacity(stream, 5)).await;\n        stream.send_data(\"hello\".into(), false).unwrap();\n        stream.send_data(\"world\".into(), true).unwrap();\n\n        let response = h2.drive(response).await.unwrap();\n        assert_eq!(response.status(), StatusCode::NO_CONTENT);\n\n        // Wait for the connection to close\n        h2.await.unwrap();\n    };\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_default_settings!(settings);\n        srv.recv_frame(frames::headers(1).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;\n        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;\n        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;\n        srv.recv_frame(frames::data(1, vec![0u8; 16_383])).await;\n        idle_ms(100).await;\n        // Increase the connection window\n        srv.send_frame(frames::window_update(0, 10)).await;\n        // Incrementally increase the stream window\n        srv.send_frame(frames::window_update(1, 4)).await;\n        idle_ms(50).await;\n        srv.send_frame(frames::window_update(1, 1)).await;\n        // Receive first chunk\n        srv.recv_frame(frames::data(1, \"hello\")).await;\n        srv.send_frame(frames::window_update(1, 5)).await;\n        // Receive second chunk\n        srv.recv_frame(frames::data(1, \"world\").eos()).await;\n        srv.send_frame(frames::headers(1).response(204).eos()).await;\n        /*\n        .recv_frame(frames::data(1, \"hello\").eos())\n        .send_frame(frames::window_update(1, 5))\n        */\n    };\n    join(srv, h2).await;\n}"}
{"code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_node_merge_catch_up_logs_no_need() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 25;\n    cluster.cfg.raft_store.raft_log_gc_threshold = 12;\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(12);\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(100);\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    let peer_on_store1 = find_peer(&region, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    // put some keys to trigger compact raft log\n    for i in 2..20 {\n        cluster.must_put(format!(\"k1{}\", i).as_bytes(), b\"v\");\n    }\n\n    // let the peer of left region on store 3 falls behind.\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(left.get_id(), 3)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    ));\n\n    // make sure the peer is isolated.\n    cluster.must_put(b\"k11\", b\"v11\");\n    must_get_none(&cluster.get_engine(3), b\"k11\");\n\n    // propose merge but not let apply index make progress.\n    fail::cfg(\"apply_after_prepare_merge\", \"pause\").unwrap();\n    pd_client.merge_region(left.get_id(), right.get_id());\n    must_get_none(&cluster.get_engine(3), b\"k11\");\n\n    // wait to trigger compact raft log\n    thread::sleep(Duration::from_millis(100));\n\n    // let source region not merged\n    fail::cfg(\"before_handle_catch_up_logs_for_merge\", \"pause\").unwrap();\n    fail::cfg(\"after_handle_catch_up_logs_for_merge\", \"pause\").unwrap();\n    // due to `before_handle_catch_up_logs_for_merge` failpoint, we already pass\n    // `apply_index < catch_up_logs.merge.get_commit()` so now can let apply\n    // index make progress.\n    fail::remove(\"apply_after_prepare_merge\");\n\n    // make sure all the logs are committed, including the compact command\n    cluster.clear_send_filters();\n    thread::sleep(Duration::from_millis(50));\n\n    // let merge process continue\n    fail::remove(\"before_handle_catch_up_logs_for_merge\");\n    fail::remove(\"after_handle_catch_up_logs_for_merge\");\n    thread::sleep(Duration::from_millis(50));\n\n    // the source region should be merged and the peer should be destroyed.\n    assert!(pd_client.check_merged(left.get_id()));\n    must_get_equal(&cluster.get_engine(3), b\"k11\", b\"v11\");\n    cluster.must_region_not_exist(left.get_id(), 3);\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn option_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<Option<u8>, Option<u32>> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(None, None).unwrap();\n        table.insert(None, Some(0)).unwrap();\n        table.insert(Some(1), Some(1)).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert_eq!(table.get(None).unwrap().unwrap().value(), Some(0));\n    assert_eq!(table.get(Some(1)).unwrap().unwrap().value(), Some(1));\n    let mut iter = table.iter().unwrap();\n    assert_eq!(iter.next().unwrap().unwrap().0.value(), None);\n    assert_eq!(iter.next().unwrap().unwrap().0.value(), Some(1));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.senders.is_empty()\n    }", "test": "fn packet_loss_and_retry_too_low_mtu() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    pair.client_send(client_ch, s).write(b\"hello\").unwrap();\n    pair.drive();\n\n    // Nothing will get past this mtu\n    pair.mtu = 10;\n    pair.client_send(client_ch, s).write(b\" world\").unwrap();\n    pair.drive_client();\n\n    // The packet was dropped\n    assert!(pair.client.outbound.is_empty());\n    assert!(pair.server.inbound.is_empty());\n\n    // Restore the default mtu, so future packets are properly transmitted\n    pair.mtu = DEFAULT_MTU;\n\n    // The lost packet is resent\n    pair.drive();\n    assert!(pair.client.outbound.is_empty());\n\n    let recv = pair.server_recv(server_ch, s);\n    let buf = stream_chunks(recv);\n\n    assert_eq!(buf, b\"hello world\".as_slice());\n}"}
{"code": "fn get_address(&self, store_id: u64) -> Result<String> {\n        let pd_client = Arc::clone(&self.pd_client);\n        let mut s = match pd_client.get_store(store_id) {\n            Ok(s) => s,\n            // `get_store` will filter tombstone store, so here needs to handle\n            // it explicitly.\n            Err(pd_client::Error::StoreTombstone(_)) => {\n                RESOLVE_STORE_COUNTER_STATIC.tombstone.inc();\n                return Err(box_err!(\"store {} has been removed\", store_id));\n            }\n            Err(e) => return Err(box_err!(e)),\n        };\n        let mut group_id = None;\n        let mut state = self.state.lock().unwrap();\n        if state.status().get_mode() == ReplicationMode::DrAutoSync {\n            let state_id = state.status().get_dr_auto_sync().state_id;\n            if state.group.group_id(state_id, store_id).is_none() {\n                group_id = state.group.register_store(store_id, s.take_labels().into());\n            }\n        } else {\n            state.group.backup_store_labels(&mut s);\n        }\n        drop(state);\n        if let Some(group_id) = group_id {\n            self.router.report_resolved(store_id, group_id);\n        }\n        let addr = take_peer_address(&mut s);\n        // In some tests, we use empty address for store first,\n        // so we should ignore here.\n        // TODO: we may remove this check after we refactor the test.\n        if addr.is_empty() {\n            return Err(box_err!(\"invalid empty address for store {}\", store_id));\n        }\n        Ok(addr)\n    }", "test": "fn test_mismatch_store_node() {\n    let count = 3;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n    let node_ids = cluster.get_node_ids();\n    let mut iter = node_ids.iter();\n    let node1_id = *iter.next().unwrap();\n    let node2_id = *iter.next().unwrap();\n    let node3_id = *iter.next().unwrap();\n    let pd_client = cluster.pd_client.clone();\n    must_get_equal(&cluster.get_engine(node1_id), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(node2_id), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(node3_id), b\"k1\", b\"v1\");\n    let node1_addr = pd_client\n        .get_store(node1_id)\n        .unwrap()\n        .get_address()\n        .to_string();\n    let node2_addr = pd_client\n        .get_store(node2_id)\n        .unwrap()\n        .get_address()\n        .to_string();\n    let node3_addr = cluster\n        .pd_client\n        .get_store(node3_id)\n        .unwrap()\n        .get_address()\n        .to_string();\n    cluster.stop_node(node2_id);\n    cluster.stop_node(node3_id);\n    // run node2\n    cluster.cfg.server.addr = node3_addr.clone();\n    cluster.run_node(node2_id).unwrap();\n    let filter = RegionPacketFilter::new(1, node2_id)\n        .direction(Direction::Send)\n        .msg_type(MessageType::MsgRequestPreVote);\n    cluster.add_send_filter(CloneFilterFactory(filter));\n    // run node3\n    cluster.cfg.server.addr = node2_addr.clone();\n    cluster.run_node(node3_id).unwrap();\n    let filter = RegionPacketFilter::new(1, node3_id)\n        .direction(Direction::Send)\n        .msg_type(MessageType::MsgRequestPreVote);\n    cluster.add_send_filter(CloneFilterFactory(filter));\n    sleep_ms(600);\n    fail::cfg(\"mock_store_refresh_interval_secs\", \"return(0)\").unwrap();\n    cluster.must_put(b\"k2\", b\"v2\");\n    assert_eq!(\n        node1_addr,\n        pd_client.get_store(node1_id).unwrap().get_address()\n    );\n    assert_eq!(\n        node3_addr,\n        pd_client.get_store(node2_id).unwrap().get_address()\n    );\n    assert_eq!(\n        node2_addr,\n        cluster.pd_client.get_store(node3_id).unwrap().get_address()\n    );\n    must_get_equal(&cluster.get_engine(node3_id), b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(node2_id), b\"k2\", b\"v2\");\n    fail::remove(\"mock_store_refresh_interval_secs\");\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_creating_leading_dirs_with_single_source_and_target_dir() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let source1 = \"source_file_1\";\n    let target_dir = \"missing_target_dir/\";\n\n    at.touch(source1);\n\n    // installing a single file into a missing directory will fail, when -D is used w/o -t parameter\n    scene\n        .ucmd()\n        .arg(\"-D\")\n        .arg(source1)\n        .arg(at.plus(target_dir))\n        .fails()\n        .stderr_contains(\"missing_target_dir/' is not a directory\");\n\n    assert!(!at.dir_exists(target_dir));\n\n    scene\n        .ucmd()\n        .arg(\"-D\")\n        .arg(source1)\n        .arg(\"-t\")\n        .arg(at.plus(target_dir))\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(format!(\"{target_dir}/{source1}\")));\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_no_permission() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.mkdir_all(SUB_DIR_LINKS);\n\n    ts.ccmd(\"chmod\").arg(\"-r\").arg(SUB_DIR_LINKS).succeeds();\n\n    let result = ts.ucmd().arg(SUB_DIR_LINKS).fails();\n    result.stderr_contains(\"du: cannot read directory 'subdir/links': Permission denied\");\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));\n        if result_reference\n            .stderr_str()\n            .contains(\"du: cannot read directory 'subdir/links': Permission denied\")\n        {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n\n    _du_no_permission(result.stdout_str());\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn vec_vec_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u8, Vec<Vec<&str>>> = TableDefinition::new(\"x\");\n\n    let value = vec![vec![\"hello\", \"world\"], vec![\"this\", \"is\", \"a\", \"test\"]];\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(0, &value).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert_eq!(value, table.get(0).unwrap().unwrap().value());\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String, DeError>\nwhere\n    T: ?Sized + Serialize,\n{\n    let mut buffer = String::new();\n    to_writer(&mut buffer, value)?;\n    Ok(buffer)\n}", "test": "fn issue510() {\n    #[derive(Debug, PartialEq, Serialize, Deserialize)]\n    #[serde(rename = \"ENTRY\")]\n    struct Entry {\n        #[serde(rename = \"CUE_V2\")]\n        cues: Option<Vec<Cue>>,\n    }\n\n    #[derive(Debug, PartialEq, Serialize, Deserialize)]\n    // #[serde_with::serde_as]\n    struct Cue {\n        #[serde(rename = \"@NAME\")]\n        name: String,\n    }\n\n    let data: Entry = from_str(\n        \"\\\n        <ENTRY>\\\n            <CUE_V2 NAME='foo'></CUE_V2>\\\n            <CUE_V2 NAME='bar'></CUE_V2>\\\n        </ENTRY>\\\n    \",\n    )\n    .unwrap();\n\n    assert_eq!(\n        data,\n        Entry {\n            cues: Some(vec![\n                Cue {\n                    name: \"foo\".to_string(),\n                },\n                Cue {\n                    name: \"bar\".to_string(),\n                },\n            ]),\n        }\n    );\n}"}
{"code": "pub fn is_extended_connect_protocol_enabled(&self) -> Option<bool> {\n        self.enable_connect_protocol.map(|val| val != 0)\n    }", "test": "async fn reject_pseudo_protocol_on_non_connect_request() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let settings = client.assert_server_handshake().await;\n\n        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));\n\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"GET\", \"http://bread/baguette\")\n                    .protocol(\"the-bread-protocol\"),\n            )\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let mut builder = server::Builder::new();\n\n        builder.enable_connect_protocol();\n\n        let mut srv = builder.handshake::<_, Bytes>(io).await.expect(\"handshake\");\n\n        assert!(srv.next().await.is_none());\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn decimal_length9(v: u32) -> u32 {\n    // Function precondition: v is not a 10-digit number.\n    // (f2s: 9 digits are sufficient for round-tripping.)\n    debug_assert!(v < 1000000000);\n\n    if v >= 100000000 {\n        9\n    } else if v >= 10000000 {\n        8\n    } else if v >= 1000000 {\n        7\n    } else if v >= 100000 {\n        6\n    } else if v >= 10000 {\n        5\n    } else if v >= 1000 {\n        4\n    } else if v >= 100 {\n        3\n    } else if v >= 10 {\n        2\n    } else {\n        1\n    }\n}", "test": "fn test_decimal_length9() {\n    assert_eq!(1, decimal_length9(0));\n    assert_eq!(1, decimal_length9(1));\n    assert_eq!(1, decimal_length9(9));\n    assert_eq!(2, decimal_length9(10));\n    assert_eq!(2, decimal_length9(99));\n    assert_eq!(3, decimal_length9(100));\n    assert_eq!(3, decimal_length9(999));\n    assert_eq!(9, decimal_length9(999999999));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn read_isolation() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut write_table = write_txn.open_table(STR_TABLE).unwrap();\n        write_table.remove(\"hello\").unwrap();\n        write_table.insert(\"hello2\", \"world2\").unwrap();\n        write_table.insert(\"hello3\", \"world3\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn2 = db.begin_read().unwrap();\n    let table2 = read_txn2.open_table(STR_TABLE).unwrap();\n    assert!(table2.get(\"hello\").unwrap().is_none());\n    assert_eq!(\"world2\", table2.get(\"hello2\").unwrap().unwrap().value());\n    assert_eq!(\"world3\", table2.get(\"hello3\").unwrap().unwrap().value());\n    assert_eq!(table2.len().unwrap(), 2);\n\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    assert!(table.get(\"hello2\").unwrap().is_none());\n    assert!(table.get(\"hello3\").unwrap().is_none());\n    assert_eq!(table.len().unwrap(), 1);\n}"}
{"code": "pub fn to_string(&self) -> Result<String> {\n        let s = match *self {\n            Datum::I64(i) => format!(\"{}\", i),\n            Datum::U64(u) => format!(\"{}\", u),\n            Datum::F64(f) => format!(\"{}\", f),\n            Datum::Bytes(ref bs) => String::from_utf8(bs.to_vec())?,\n            Datum::Time(t) => format!(\"{}\", t),\n            Datum::Dur(ref d) => format!(\"{}\", d),\n            Datum::Dec(ref d) => format!(\"{}\", d),\n            Datum::Json(ref d) => d.to_string(),\n            Datum::Enum(ref e) => e.to_string(),\n            Datum::Set(ref s) => s.to_string(),\n            ref d => return Err(invalid_type!(\"can't convert {} to string\", d)),\n        };\n        Ok(s)\n    }", "test": "fn test_incompatible_version() {\n    let incompatible = Arc::new(Incompatible);\n    let server = MockServer::with_case(1, incompatible);\n    let eps = server.bind_addrs();\n\n    let client = new_client(eps, None);\n\n    let resp = block_on(client.ask_batch_split(metapb::Region::default(), 2));\n    assert_eq!(\n        resp.unwrap_err().to_string(),\n        PdError::Incompatible.to_string()\n    );\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_l() {\n    // Test iterators that skip single, leading-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_leading_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4__.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"_45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5__.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"_45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"_45__.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"_4__5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"4_5_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"_4__5__.56\");\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn non_durable_commit_persistence() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::create(tmpfile.path()).unwrap();\n    let mut txn = db.begin_write().unwrap();\n    txn.set_durability(Durability::None);\n    let pairs = gen_data(100, 16, 20);\n    {\n        let mut table = txn.open_table(SLICE_TABLE).unwrap();\n        for i in 0..ELEMENTS {\n            let (key, value) = &pairs[i % pairs.len()];\n            table.insert(key.as_slice(), value.as_slice()).unwrap();\n        }\n    }\n    txn.commit().unwrap();\n\n    // Check that cleanly closing the database persists the non-durable commit\n    drop(db);\n    let db = Database::create(tmpfile.path()).unwrap();\n    let txn = db.begin_read().unwrap();\n    let table = txn.open_table(SLICE_TABLE).unwrap();\n\n    let mut key_order: Vec<usize> = (0..ELEMENTS).collect();\n    key_order.shuffle(&mut rand::thread_rng());\n\n    {\n        for i in &key_order {\n            let (key, value) = &pairs[*i % pairs.len()];\n            assert_eq!(table.get(key.as_slice()).unwrap().unwrap().value(), value);\n        }\n    }\n}"}
{"code": "pub fn stream_id(&self) -> StreamId {\n        self.stream_id\n    }", "test": "async fn read_push_promise() {\n    let mut codec = raw_codec! {\n        read => [\n            0, 0, 0x5,\n            0x5, 0x4,\n            0, 0, 0, 0x1, // stream id\n            0, 0, 0, 0x2, // promised id\n            0x82, // HPACK :method=\"GET\"\n        ];\n    };\n\n    let pp = poll_frame!(PushPromise, codec);\n    assert_eq!(pp.stream_id(), 1);\n    assert_eq!(pp.promised_id(), 2);\n    assert_eq!(pp.into_parts().0.method, Some(Method::GET));\n\n    assert_closed!(codec);\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u32_pow2_test() {\n    let values: &[u32] = &[\n        0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255, 256,\n        257, 511, 512, 513, 1023, 1024, 1025, 2047, 2048, 2049, 4095, 4096, 4097, 8191, 8192, 8193,\n        16383, 16384, 16385, 32767, 32768, 32769, 65535, 65536, 65537, 131071, 131072, 131073,\n        262143, 262144, 262145, 524287, 524288, 524289, 1048575, 1048576, 1048577, 2097151,\n        2097152, 2097153, 4194303, 4194304, 4194305, 8388607, 8388608, 8388609, 16777215, 16777216,\n        16777217, 33554431, 33554432, 33554433, 67108863, 67108864, 67108865, 134217727, 134217728,\n        134217729, 268435455, 268435456, 268435457, 536870911, 536870912, 536870913, 1073741823,\n        1073741824, 1073741825, 2147483647, 2147483648, 2147483649, 4294967295,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + ser::Serialize,\n{\n    let mut vec = Vec::with_capacity(128);\n    to_writer(&mut vec, value)?;\n    String::from_utf8(vec).map_err(|error| error::new(ErrorImpl::FromUtf8(error)))\n}", "test": "fn test_serialize_nested_enum() {\n    #[derive(Serialize, Debug)]\n    enum Outer {\n        Inner(Inner),\n    }\n    #[derive(Serialize, Debug)]\n    enum Inner {\n        Newtype(usize),\n        Tuple(usize, usize),\n        Struct { x: usize },\n    }\n\n    let expected = \"serializing nested enums in YAML is not supported yet\";\n\n    let e = Outer::Inner(Inner::Newtype(0));\n    let error = serde_yaml::to_string(&e).unwrap_err();\n    assert_eq!(error.to_string(), expected);\n\n    let e = Outer::Inner(Inner::Tuple(0, 0));\n    let error = serde_yaml::to_string(&e).unwrap_err();\n    assert_eq!(error.to_string(), expected);\n\n    let e = Outer::Inner(Inner::Struct { x: 0 });\n    let error = serde_yaml::to_string(&e).unwrap_err();\n    assert_eq!(error.to_string(), expected);\n\n    let e = Value::Tagged(Box::new(TaggedValue {\n        tag: Tag::new(\"Outer\"),\n        value: Value::Tagged(Box::new(TaggedValue {\n            tag: Tag::new(\"Inner\"),\n            value: Value::Null,\n        })),\n    }));\n    let error = serde_yaml::to_string(&e).unwrap_err();\n    assert_eq!(error.to_string(), expected);\n}"}
{"code": "pub fn server_name(&self) -> Option<&str> {\n        self.server_name\n            .as_ref()\n            .map(<DnsName as AsRef<str>>::as_ref)\n    }", "test": "fn server_exposes_offered_sni_smashed_to_lowercase() {\n    // webpki actually does this for us in its DnsName type\n    let kt = KeyType::Rsa;\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(kt, &[version]);\n        let mut client =\n            ClientConnection::new(Arc::new(client_config), dns_name(\"SECOND.TESTServer.com\"))\n                .unwrap();\n        let mut server = ServerConnection::new(Arc::new(make_server_config(kt))).unwrap();\n\n        assert_eq!(None, server.server_name());\n        do_handshake(&mut client, &mut server);\n        assert_eq!(Some(\"second.testserver.com\"), server.server_name());\n    }\n}"}
{"code": "pub fn checked_add(self, offset: TextSize) -> Option<TextRange> {\n        Some(TextRange {\n            start: self.start.checked_add(offset)?,\n            end: self.end.checked_add(offset)?,\n        })\n    }", "test": "fn checked_math() {\n    assert_eq!(size(1).checked_add(size(1)), Some(size(2)));\n    assert_eq!(size(1).checked_sub(size(1)), Some(size(0)));\n    assert_eq!(size(1).checked_sub(size(2)), None);\n    assert_eq!(size(!0).checked_add(size(1)), None);\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn table_growth_failure2() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/table-grow-failure2.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing a table growth failure to be a trap\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), \"statement();\\n\".repeat(80660).as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Do not store the content of the file in the snapshot\n    fs.remove(file_path);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn fetch(&self) -> u32 {\n        self.cached_avg.load(Ordering::Relaxed)\n    }", "test": "fn test_inspected_snapshot() {\n    let mut cluster = new_server_cluster(1, 3);\n    cluster.cfg.prefer_mem = false;\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(20);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(8);\n    cluster.cfg.raft_store.merge_max_log_gap = 3;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.stop_node(3);\n    (0..10).for_each(|_| cluster.must_put(b\"k2\", b\"v2\"));\n    // Sleep for a while to ensure all logs are compacted.\n    sleep_ms(100);\n\n    let stats = cluster\n        .io_rate_limiter\n        .as_ref()\n        .unwrap()\n        .statistics()\n        .unwrap();\n    assert_eq!(stats.fetch(IoType::Replication, IoOp::Read), 0);\n    assert_eq!(stats.fetch(IoType::Replication, IoOp::Write), 0);\n    // Make sure snapshot read hits disk\n    cluster.flush_data();\n    // Let store 3 inform leader to generate a snapshot.\n    cluster.run_node(3).unwrap();\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n    assert_ne!(stats.fetch(IoType::Replication, IoOp::Read), 0);\n    assert_ne!(stats.fetch(IoType::Replication, IoOp::Write), 0);\n\n    pd_client.must_remove_peer(1, new_peer(2, 2));\n    must_get_none(&cluster.get_engine(2), b\"k2\");\n    assert_eq!(stats.fetch(IoType::LoadBalance, IoOp::Read), 0);\n    assert_eq!(stats.fetch(IoType::LoadBalance, IoOp::Write), 0);\n    pd_client.must_add_peer(1, new_peer(2, 2));\n    must_get_equal(&cluster.get_engine(2), b\"k2\", b\"v2\");\n    assert_ne!(stats.fetch(IoType::LoadBalance, IoOp::Read), 0);\n    assert_ne!(stats.fetch(IoType::LoadBalance, IoOp::Write), 0);\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_multiple_obs_lines_within_combined() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let name = \"multiple-obs-lines\";\n    RandomFile::new(at, name).add_lines(400);\n\n    scene\n        .ucmd()\n        .args(&[\"-d5000x\", \"-e200d\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(at, \".\", r\"x\\d\\d$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_when_warmup_range_start_is_larger_than_last_index() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::secs(1000);\n    prevent_from_gc_raft_log(&mut cluster);\n    run_cluster_for_test_warmup_entry_cache(&mut cluster);\n    cluster.pd_client.disable_default_operator();\n\n    let s4 = cluster.add_new_engine();\n\n    // Prevent peer 4 from appending logs, so it's last index should\n    // be really small.\n    let recv_filter_s4 = Box::new(\n        RegionPacketFilter::new(1, s4)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    );\n    cluster.sim.wl().add_recv_filter(s4, recv_filter_s4);\n\n    let (sx, rx) = channel::unbounded();\n    let recv_filter_1 = Box::new(\n        RegionPacketFilter::new(1, 1)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgTransferLeader)\n            .set_msg_callback(Arc::new(move |m| {\n                sx.send(m.get_message().get_from()).unwrap();\n            })),\n    );\n    cluster.sim.wl().add_recv_filter(1, recv_filter_1);\n\n    cluster.pd_client.must_add_peer(1, new_peer(s4, s4));\n    cluster.transfer_leader(1, new_peer(s4, s4));\n    // Store(s4) should ack the transfer leader msg immediately.\n    assert_eq!(rx.recv_timeout(Duration::from_millis(500)).unwrap(), s4);\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_infinity_test() {\n    let mut builder = OptionsBuilder::default();\n    builder =\n        builder.infinity_string(Some(b\"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf\"));\n    assert!(!builder.is_valid());\n    builder = builder.infinity_string(Some(b\"nan\"));\n    assert!(!builder.is_valid());\n    builder = builder.infinity_string(Some(b\"i\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"infi000nity\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.inf_string(Some(b\"i\"));\n    assert!(builder.is_valid());\n    builder = builder.infinity_string(Some(b\"infinity\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.infinity_string(None);\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(None);\n    assert!(builder.is_valid());\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn trap_start_function_import() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let binary = wat::parse_str(\n        r#\"\n            (module $a\n                (import \"\" \"\" (func $foo))\n                (start $foo)\n            )\n        \"#,\n    )?;\n\n    let module = Module::new(store.engine(), &binary)?;\n    let sig = FuncType::new(None, None);\n    let func = Func::new(&mut store, sig, |_, _, _| bail!(\"user trap\"));\n    let err = Instance::new(&mut store, &module, &[func.into()]).unwrap_err();\n    assert!(format!(\"{err:?}\").contains(\"user trap\"));\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_shred_force() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file = \"test_shred_force\";\n\n    // Create file_a.\n    at.touch(file);\n    assert!(at.file_exists(file));\n\n    // Make file_a readonly.\n    at.set_readonly(file);\n\n    // Try shred -u.\n    scene.ucmd().arg(\"-u\").arg(file).run();\n\n    // file_a was not deleted because it is readonly.\n    assert!(at.file_exists(file));\n\n    // Try shred -u -f.\n    scene.ucmd().arg(\"-u\").arg(\"-f\").arg(file).run();\n\n    // file_a was deleted.\n    assert!(!at.file_exists(file));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cmds.len()\n    }", "test": "fn test_backup_and_import() {\n    let mut suite = TestSuite::new(3, 144 * 1024 * 1024, ApiVersion::V1);\n    // 3 version for each key.\n    let key_count = 60;\n    suite.must_kv_put(key_count, 3);\n\n    // Push down backup request.\n    let tmp = Builder::new().tempdir().unwrap();\n    let backup_ts = suite.alloc_ts();\n    let storage_path = make_unique_dir(tmp.path());\n    let rx = suite.backup(\n        vec![],   // start\n        vec![],   // end\n        0.into(), // begin_ts\n        backup_ts,\n        &storage_path,\n    );\n    let resps1 = block_on(rx.collect::<Vec<_>>());\n    // Only leader can handle backup.\n    assert_eq!(resps1.len(), 1);\n    let files1 = resps1[0].files.clone();\n    // Short value is piggybacked in write cf, so we get 1 sst at least.\n    assert!(!resps1[0].get_files().is_empty());\n\n    // Delete all data, there should be no backup files.\n    suite.cluster.must_delete_range_cf(CF_DEFAULT, b\"\", b\"\");\n    suite.cluster.must_delete_range_cf(CF_WRITE, b\"\", b\"\");\n    // Backup file should have same contents.\n    let rx = suite.backup(\n        vec![],   // start\n        vec![],   // end\n        0.into(), // begin_ts\n        backup_ts,\n        &make_unique_dir(tmp.path()),\n    );\n    let resps2 = block_on(rx.collect::<Vec<_>>());\n    assert!(resps2[0].get_files().is_empty(), \"{:?}\", resps2);\n\n    // Use importer to restore backup files.\n    let backend = make_local_backend(&storage_path);\n    let storage = create_storage(&backend, Default::default()).unwrap();\n    let region = suite.cluster.get_region(b\"\");\n    let mut sst_meta = SstMeta::default();\n    sst_meta.region_id = region.get_id();\n    sst_meta.set_region_epoch(region.get_region_epoch().clone());\n    sst_meta.set_uuid(uuid::Uuid::new_v4().as_bytes().to_vec());\n    let mut metas = vec![];\n    for f in files1.clone().into_iter() {\n        let mut reader = storage.read(&f.name);\n        let mut content = vec![];\n        block_on(reader.read_to_end(&mut content)).unwrap();\n        let mut m = sst_meta.clone();\n        m.crc32 = calc_crc32_bytes(&content);\n        m.length = content.len() as _;\n        m.cf_name = name_to_cf(&f.name).to_owned();\n        metas.push((m, content));\n    }\n\n    for (m, c) in &metas {\n        for importer in suite.cluster.sim.rl().importers.values() {\n            let mut f = importer.create(m).unwrap();\n            f.append(c).unwrap();\n            f.finish().unwrap();\n        }\n\n        // Make ingest command.\n        let mut ingest = Request::default();\n        ingest.set_cmd_type(CmdType::IngestSst);\n        ingest.mut_ingest_sst().set_sst(m.clone());\n        let mut header = RaftRequestHeader::default();\n        let leader = suite.context.get_peer().clone();\n        header.set_peer(leader);\n        header.set_region_id(suite.context.get_region_id());\n        header.set_region_epoch(suite.context.get_region_epoch().clone());\n        let mut cmd = RaftCmdRequest::default();\n        cmd.set_header(header);\n        cmd.mut_requests().push(ingest);\n        let resp = suite\n            .cluster\n            .call_command_on_leader(cmd, Duration::from_secs(5))\n            .unwrap();\n        assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    }\n\n    // Backup file should have same contents.\n    let rx = suite.backup(\n        vec![],   // start\n        vec![],   // end\n        0.into(), // begin_ts\n        backup_ts,\n        &make_unique_dir(tmp.path()),\n    );\n    let resps3 = block_on(rx.collect::<Vec<_>>());\n    assert_same_files(files1.into_vec(), resps3[0].files.clone().into_vec());\n\n    suite.stop();\n}"}
{"code": "pub fn insert<'k, 'v>(\n        &mut self,\n        key: impl Borrow<K::SelfType<'k>>,\n        value: impl Borrow<V::SelfType<'v>>,\n    ) -> Result<bool> {\n        let value_bytes = V::as_bytes(value.borrow());\n        let value_bytes_ref = value_bytes.as_ref();\n        if value_bytes_ref.len() > MAX_VALUE_LENGTH {\n            return Err(StorageError::ValueTooLarge(value_bytes_ref.len()));\n        }\n        let key_bytes = K::as_bytes(key.borrow());\n        if key_bytes.as_ref().len() > MAX_VALUE_LENGTH {\n            return Err(StorageError::ValueTooLarge(key_bytes.as_ref().len()));\n        }\n        let get_result = self.tree.get(key.borrow())?;\n        let existed = if get_result.is_some() {\n            #[allow(clippy::unnecessary_unwrap)]\n            let guard = get_result.unwrap();\n            let collection_type = guard.value().collection_type();\n            match collection_type {\n                Inline => {\n                    let leaf_data = guard.value().as_inline();\n                    let accessor = LeafAccessor::new(\n                        leaf_data,\n                        V::fixed_width(),\n                        <() as RedbValue>::fixed_width(),\n                    );\n                    let (position, found) = accessor.position::<V>(value_bytes_ref);\n                    if found {\n                        return Ok(true);\n                    }\n\n                    let new_pairs = accessor.num_pairs() + 1;\n                    let new_pair_bytes =\n                        accessor.length_of_pairs(0, accessor.num_pairs()) + value_bytes_ref.len();\n                    let new_key_bytes =\n                        accessor.length_of_keys(0, accessor.num_pairs()) + value_bytes_ref.len();\n                    let required_inline_bytes =\n                        RawLeafBuilder::required_bytes(new_pairs, new_pair_bytes);\n\n                    if required_inline_bytes < self.mem.get_page_size() / 2 {\n                        let mut data = vec![0; required_inline_bytes];\n                        let mut builder = RawLeafBuilder::new(\n                            &mut data,\n                            new_pairs,\n                            V::fixed_width(),\n                            <() as RedbValue>::fixed_width(),\n                            new_key_bytes,\n                        );\n                        for i in 0..accessor.num_pairs() {\n                            if i == position {\n                                builder.append(\n                                    value_bytes_ref,\n                                    <() as RedbValue>::as_bytes(&()).as_ref(),\n                                );\n                            }\n                            let entry = accessor.entry(i).unwrap();\n                            builder.append(entry.key(), entry.value());\n                        }\n                        if position == accessor.num_pairs() {\n                            builder\n                                .append(value_bytes_ref, <() as RedbValue>::as_bytes(&()).as_ref());\n                        }\n                        drop(builder);\n                        drop(guard);\n                        let inline_data = DynamicCollection::<V>::make_inline_data(&data);\n                        self.tree\n                            .insert(key.borrow(), &DynamicCollection::new(&inline_data))?;\n                    } else {\n                        // convert into a subtree\n                        let mut page = self.mem.allocate(leaf_data.len(), CachePriority::Low)?;\n                        page.memory_mut()[..leaf_data.len()].copy_from_slice(leaf_data);\n                        let page_number = page.get_page_number();\n                        drop(page);\n                        drop(guard);\n\n                        // Don't bother computing the checksum, since we're about to modify the tree\n                        let mut subtree: BtreeMut<'_, V, ()> = BtreeMut::new(\n                            Some((page_number, 0)),\n                            self.mem,\n                            self.freed_pages.clone(),\n                        );\n                        let existed = subtree.insert(value.borrow(), &())?.is_some();\n                        assert_eq!(existed, found);\n                        let (new_root, new_checksum) = subtree.get_root().unwrap();\n                        let subtree_data =\n                            DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                        self.tree\n                            .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n                    }\n\n                    found\n                }\n                Subtree => {\n                    let mut subtree: BtreeMut<'_, V, ()> = BtreeMut::new(\n                        Some(guard.value().as_subtree()),\n                        self.mem,\n                        self.freed_pages.clone(),\n                    );\n                    drop(guard);\n                    let existed = subtree.insert(value.borrow(), &())?.is_some();\n                    let (new_root, new_checksum) = subtree.get_root().unwrap();\n                    let subtree_data =\n                        DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                    self.tree\n                        .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n\n                    existed\n                }\n            }\n        } else {\n            drop(get_result);\n            let required_inline_bytes = RawLeafBuilder::required_bytes(1, value_bytes_ref.len());\n            if required_inline_bytes < self.mem.get_page_size() / 2 {\n                let mut data = vec![0; required_inline_bytes];\n                let mut builder = RawLeafBuilder::new(\n                    &mut data,\n                    1,\n                    V::fixed_width(),\n                    <() as RedbValue>::fixed_width(),\n                    value_bytes_ref.len(),\n                );\n                builder.append(value_bytes_ref, <() as RedbValue>::as_bytes(&()).as_ref());\n                drop(builder);\n                let inline_data = DynamicCollection::<V>::make_inline_data(&data);\n                self.tree\n                    .insert(key.borrow(), &DynamicCollection::new(&inline_data))?;\n            } else {\n                let mut subtree: BtreeMut<'_, V, ()> =\n                    BtreeMut::new(None, self.mem, self.freed_pages.clone());\n                subtree.insert(value.borrow(), &())?;\n                let (new_root, new_checksum) = subtree.get_root().unwrap();\n                let subtree_data =\n                    DynamicCollection::<V>::make_subtree_data(new_root, new_checksum);\n                self.tree\n                    .insert(key.borrow(), &DynamicCollection::new(&subtree_data))?;\n            }\n            false\n        };\n\n        Ok(existed)\n    }", "test": "fn insert() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        assert!(!table.insert(\"hello\", \"world\").unwrap());\n        assert!(!table.insert(\"hello\", \"world2\").unwrap());\n        assert!(table.insert(\"hello\", \"world2\").unwrap());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert_eq!(\n        vec![\"world\".to_string(), \"world2\".to_string()],\n        get_vec(&table, \"hello\")\n    );\n    assert_eq!(table.len().unwrap(), 2);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_to_dir_2args() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let filename = \"test_symlink_to_dir_2args_file\";\n    let from_file = &format!(\"{}/{}\", at.as_string(), filename);\n    let to_dir = \"test_symlink_to_dir_2args_to_dir\";\n    let to_file = &format!(\"{to_dir}/{filename}\");\n\n    at.mkdir(to_dir);\n    at.touch(from_file);\n\n    ucmd.args(&[\"-s\", from_file, to_dir]).succeeds().no_stderr();\n\n    assert!(at.file_exists(to_file));\n    assert!(at.is_symlink(to_file));\n    assert_eq!(at.resolve_link(to_file), filename);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_non_witness_replica_read() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // witness -> nonwitness\n    fail::cfg(\"ignore request snapshot\", \"return\").unwrap();\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);\n    std::thread::sleep(Duration::from_millis(100));\n    // as we ignore request snapshot, so snapshot should still not applied yet\n\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cmd(b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(peer_on_store3.clone());\n    request.mut_header().set_replica_read(true);\n\n    let resp = cluster\n        .read(None, request, Duration::from_millis(100))\n        .unwrap();\n    assert_eq!(\n        resp.get_header().get_error().get_is_witness(),\n        &kvproto::errorpb::IsWitness {\n            region_id: region.get_id(),\n            ..Default::default()\n        }\n    );\n\n    // start requesting snapshot and give enough time for applying snapshot to\n    // complete\n    fail::remove(\"ignore request snapshot\");\n    std::thread::sleep(Duration::from_millis(500));\n\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cmd(b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(peer_on_store3);\n    request.mut_header().set_replica_read(true);\n\n    let resp = cluster\n        .read(None, request, Duration::from_millis(100))\n        .unwrap();\n    assert_eq!(resp.get_header().has_error(), false);\n}"}
{"code": "pub const fn encoded_len(bytes_len: usize, padding: bool) -> Option<usize> {\n    let rem = bytes_len % 3;\n\n    let complete_input_chunks = bytes_len / 3;\n    // `let Some(_) = _ else` requires 1.65.0, whereas this messier one works on 1.48\n    let complete_chunk_output =\n        if let Some(complete_chunk_output) = complete_input_chunks.checked_mul(4) {\n            complete_chunk_output\n        } else {\n            return None;\n        };\n\n    if rem > 0 {\n        if padding {\n            complete_chunk_output.checked_add(4)\n        } else {\n            let encoded_rem = match rem {\n                1 => 2,\n                // only other possible remainder is 2\n                // can't use a separate _ => unreachable!() in const fns in ancient rust versions\n                _ => 3,\n            };\n            complete_chunk_output.checked_add(encoded_rem)\n        }\n    } else {\n        Some(complete_chunk_output)\n    }\n}", "test": "fn encoded_len_unpadded() {\n    assert_eq!(0, encoded_len(0, false).unwrap());\n    assert_eq!(2, encoded_len(1, false).unwrap());\n    assert_eq!(3, encoded_len(2, false).unwrap());\n    assert_eq!(4, encoded_len(3, false).unwrap());\n    assert_eq!(6, encoded_len(4, false).unwrap());\n    assert_eq!(7, encoded_len(5, false).unwrap());\n    assert_eq!(8, encoded_len(6, false).unwrap());\n    assert_eq!(10, encoded_len(7, false).unwrap());\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_hostname_full() {\n    let ls_short_res = new_ucmd!().arg(\"-s\").succeeds();\n    assert!(!ls_short_res.stdout_str().trim().is_empty());\n\n    new_ucmd!()\n        .arg(\"-f\")\n        .succeeds()\n        .stdout_contains(ls_short_res.stdout_str().trim());\n}"}
{"code": "fn should_write_to_engine(&self) -> bool {\n        panic!()\n    }", "test": "fn should_write_to_engine() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;\n\n    let mut key = vec![];\n    loop {\n        key.push(b'a');\n        wb.put(&key, b\"\").unwrap();\n        if key.len() <= max_keys {\n            assert!(!wb.should_write_to_engine());\n        }\n        if key.len() == max_keys + 1 {\n            assert!(wb.should_write_to_engine());\n            wb.write().unwrap();\n            break;\n        }\n    }\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;\n\n    let mut key = vec![];\n    loop {\n        key.push(b'a');\n        wb.put(&key, b\"\").unwrap();\n        if key.len() <= max_keys {\n            assert!(!wb.should_write_to_engine());\n        }\n        if key.len() == max_keys + 1 {\n            assert!(wb.should_write_to_engine());\n            wb.write().unwrap();\n            break;\n        }\n    }\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_exponent_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.exponent(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.exponent(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.exponent(b'^');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_with_dirs_t() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(\"-t\")\n        .arg(TEST_COPY_TO_FOLDER)\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .succeeds();\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cmds.len()\n    }", "test": "fn test_backup_huge_range_and_import() {\n    let mut suite = TestSuite::new(3, 100, ApiVersion::V1);\n    // 3 version for each key.\n    // make sure we will have two batch files\n    let key_count = 1024 * 3 / 2;\n    suite.must_kv_put(key_count, 3);\n\n    // Push down backup request.\n    let tmp = Builder::new().tempdir().unwrap();\n    let backup_ts = suite.alloc_ts();\n    let storage_path = make_unique_dir(tmp.path());\n    let rx = suite.backup(\n        vec![],   // start\n        vec![],   // end\n        0.into(), // begin_ts\n        backup_ts,\n        &storage_path,\n    );\n    let mut resps1 = block_on(rx.collect::<Vec<_>>());\n    resps1.sort_by(|r1, r2| r1.start_key.cmp(&r2.start_key));\n\n    // Only leader can handle backup.\n    // ... But the response may be split into two parts (when meeting huge region).\n    assert_eq!(resps1.len(), 2, \"{:?}\", resps1);\n    let mut files1 = resps1\n        .iter()\n        .flat_map(|x| x.files.iter())\n        .cloned()\n        .collect::<Vec<_>>();\n    // Short value is piggybacked in write cf, so we get 1 sst at least.\n    assert!(!resps1[0].get_files().is_empty());\n\n    // Sort the files for avoiding race conditions. (would this happen?)\n    files1.sort_by(|f1, f2| f1.start_key.cmp(&f2.start_key));\n\n    assert_eq!(resps1[0].start_key, b\"\".to_vec());\n    assert_eq!(resps1[0].end_key, resps1[1].start_key);\n    assert_eq!(resps1[1].end_key, b\"\".to_vec());\n\n    assert_eq!(files1.len(), 2);\n    assert_ne!(files1[0].start_key, files1[0].end_key);\n    assert_ne!(files1[1].start_key, files1[1].end_key);\n    assert_eq!(files1[0].end_key, files1[1].start_key);\n\n    // Use importer to restore backup files.\n    let backend = make_local_backend(&storage_path);\n    let storage = create_storage(&backend, Default::default()).unwrap();\n    let region = suite.cluster.get_region(b\"\");\n    let mut sst_meta = SstMeta::default();\n    sst_meta.region_id = region.get_id();\n    sst_meta.set_region_epoch(region.get_region_epoch().clone());\n    let mut metas = vec![];\n    for f in files1.clone().into_iter() {\n        let mut reader = storage.read(&f.name);\n        let mut content = vec![];\n        block_on(reader.read_to_end(&mut content)).unwrap();\n        let mut m = sst_meta.clone();\n        m.crc32 = calc_crc32_bytes(&content);\n        m.length = content.len() as _;\n        // set different uuid for each file\n        m.set_uuid(uuid::Uuid::new_v4().as_bytes().to_vec());\n        m.cf_name = name_to_cf(&f.name).to_owned();\n        metas.push((m, content));\n    }\n\n    for (m, c) in &metas {\n        for importer in suite.cluster.sim.rl().importers.values() {\n            let mut f = importer.create(m).unwrap();\n            f.append(c).unwrap();\n            f.finish().unwrap();\n        }\n\n        // Make ingest command.\n        let mut ingest = Request::default();\n        ingest.set_cmd_type(CmdType::IngestSst);\n        ingest.mut_ingest_sst().set_sst(m.clone());\n        let mut header = RaftRequestHeader::default();\n        let leader = suite.context.get_peer().clone();\n        header.set_peer(leader);\n        header.set_region_id(suite.context.get_region_id());\n        header.set_region_epoch(suite.context.get_region_epoch().clone());\n        let mut cmd = RaftCmdRequest::default();\n        cmd.set_header(header);\n        cmd.mut_requests().push(ingest);\n        let resp = suite\n            .cluster\n            .call_command_on_leader(cmd, Duration::from_secs(5))\n            .unwrap();\n        assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    }\n\n    // Backup file should have same contents.\n    let rx = suite.backup(\n        vec![],   // start\n        vec![],   // end\n        0.into(), // begin_ts\n        backup_ts,\n        &make_unique_dir(tmp.path()),\n    );\n    let resps3 = block_on(rx.collect::<Vec<_>>());\n    assert_same_files(\n        files1,\n        resps3\n            .iter()\n            .flat_map(|x| x.files.iter())\n            .cloned()\n            .collect(),\n    );\n\n    suite.stop();\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u16_pow2_test() {\n    let values: &[u16] = &[\n        0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255, 256,\n        257, 511, 512, 513, 1023, 1024, 1025, 2047, 2048, 2049, 4095, 4096, 4097, 8191, 8192, 8193,\n        16383, 16384, 16385, 32767, 32768, 32769, 65535,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn store_with_context() -> Result<()> {\n    struct Ctx {\n        called: bool,\n    }\n\n    let engine = Engine::default();\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\"\", \"\", |mut caller: Caller<'_, Ctx>| {\n        caller.data_mut().called = true;\n    })?;\n\n    let mut store = Store::new(&engine, Ctx { called: false });\n\n    let f = linker.get(&mut store, \"\", \"\").unwrap().into_func().unwrap();\n    f.call(&mut store, &[], &mut [])?;\n\n    assert!(store.data().called);\n\n    Ok(())\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_backup_arg_first() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn attributes_empty_ns() {\n    let src = \"<a att1='a' r:att2='b' xmlns:r='urn:example:r' />\";\n\n    let mut r = NsReader::from_str(src);\n    r.trim_text(true);\n\n    let e = match r.read_resolved_event() {\n        Ok((Unbound, Empty(e))) => e,\n        e => panic!(\"Expecting Empty event, got {:?}\", e),\n    };\n\n    let mut attrs = e\n        .attributes()\n        .map(|ar| ar.expect(\"Expecting attribute parsing to succeed.\"))\n        // we don't care about xmlns attributes for this test\n        .filter(|kv| kv.key.as_namespace_binding().is_none())\n        .map(|Attribute { key: name, value }| {\n            let (opt_ns, local_name) = r.resolve_attribute(name);\n            (opt_ns, local_name.into_inner(), value)\n        });\n    assert_eq!(\n        attrs.next(),\n        Some((Unbound, &b\"att1\"[..], Cow::Borrowed(&b\"a\"[..])))\n    );\n    assert_eq!(\n        attrs.next(),\n        Some((\n            Bound(Namespace(b\"urn:example:r\")),\n            &b\"att2\"[..],\n            Cow::Borrowed(&b\"b\"[..])\n        ))\n    );\n    assert_eq!(attrs.next(), None);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_rename_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir1 = \"test_mv_rename_dir\";\n    let dir2 = \"test_mv_rename_dir2\";\n\n    at.mkdir(dir1);\n\n    ucmd.arg(dir1).arg(dir2).succeeds().no_stderr();\n\n    assert!(at.dir_exists(dir2));\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn remove_next_ws_if_single_opening_tag_requires_it() {\n    let ws = WS { left: true, right: true };\n    let ast = vec![\n        Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n        Node::Text(\"  hey\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n            Node::Text(\"hey\".to_string()), // it removed the leading space\n        ]\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn apply_unsafe_with_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    // last line doesn't have code fix\n    let source = \"let a = 4;\ndebugger;\nconsole.log(a);\nfunction f() { arguments; }\n\";\n\n    let expected = \"const a = 4;\nconsole.log(a);\nfunction f() { arguments; }\n\";\n\n    let test1 = Path::new(\"test1.js\");\n    fs.insert(test1.into(), source.as_bytes());\n\n    let test2 = Path::new(\"test2.js\");\n    fs.insert(test2.into(), source.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply-unsafe\"),\n                test1.as_os_str().to_str().unwrap(),\n                test2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(test1)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, expected);\n    drop(file);\n\n    content.clear();\n\n    let mut file = fs\n        .open(test2)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    drop(file);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"apply_unsafe_with_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_numbered_with_numbered() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=numbered\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}.~1~\")));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cols.len()\n    }", "test": "fn test_resize_async_ios_failed_1() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_io_pool_size = 2;\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n\n    // Save current async-io tids before shrinking\n    let org_writers_tids = get_async_writers_tids();\n    assert_eq!(2, org_writers_tids.len());\n    // Request can be handled as usual\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n\n    // Update config, expand from async-mode(async-ios == 2) to\n    // sync-mode(async-ios == 0).\n    {\n        let sim = cluster.sim.rl();\n        let cfg_controller = sim.get_cfg_controller().unwrap();\n\n        let change = {\n            let mut change = HashMap::new();\n            change.insert(\"raftstore.store-io-pool-size\".to_owned(), \"0\".to_owned());\n            change\n        };\n\n        assert!(cfg_controller.update(change).is_err());\n        assert_eq!(\n            cfg_controller.get_current().raft_store.store_io_pool_size,\n            2\n        );\n    }\n    // Save current async-io tids after scaling up, and compared with the\n    // orginial one before scaling up, the thread num should be added up to TWO.\n    let cur_writers_tids = get_async_writers_tids();\n    assert_eq!(cur_writers_tids.len(), org_writers_tids.len());\n\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_resolves_when_using_config_path() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"config/biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"format.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"config/format.json\");\n    fs.insert(\n        format.into(),\n        r#\"{ \"javascript\": { \"formatter\": { \"quoteStyle\": \"single\" } } }\"#,\n    );\n    let lint = Path::new(\"config/linter.json\");\n    fs.insert(lint.into(), r#\"{ \"linter\": { \"enabled\": true } }\"#);\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"check\"),\n                \"--config-path=config/\",\n                test_file.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_resolves_when_using_config_path\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_mock_lookup() {\n    let resp_query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let v4_record = v4_record(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        Ipv4Addr::new(93, 184, 216, 34),\n    );\n    let message = message(resp_query, vec![v4_record], vec![], vec![]);\n    let client: MockClientHandle<_, ResolveError> =\n        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, false),\n    );\n\n    let io_loop = Runtime::new().unwrap();\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        *lookup.iter().next().unwrap(),\n        RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn server_respects_buffer_limit_post_handshake() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n\n    // this test will vary in behaviour depending on the default suites\n    do_handshake(&mut client, &mut server);\n    server.set_buffer_limit(Some(48));\n\n    assert_eq!(\n        server\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        20\n    );\n    assert_eq!(\n        server\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        6\n    );\n\n    transfer(&mut server, &mut client);\n    client.process_new_packets().unwrap();\n\n    check_read(&mut client.reader(), b\"01234567890123456789012345\");\n}"}
{"code": "fn count(&self) -> usize {\n        panic!()\n    }", "test": "fn write_batch_count_2() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    assert_eq!(wb.count(), 0);\n    wb.put(b\"a\", b\"\").unwrap();\n    assert_eq!(wb.count(), 1);\n    wb.delete(b\"a\").unwrap();\n    assert_eq!(wb.count(), 2);\n    wb.delete_range(b\"a\", b\"b\").unwrap();\n    assert_eq!(wb.count(), 3);\n    wb.write().unwrap();\n    assert_eq!(wb.count(), 3);\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    assert_eq!(wb.count(), 0);\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    assert_eq!(wb.count(), 257);\n    wb.delete(b\"a\").unwrap();\n    assert_eq!(wb.count(), 258);\n    wb.delete_range(b\"a\", b\"b\").unwrap();\n    assert_eq!(wb.count(), 259);\n    wb.write().unwrap();\n    assert_eq!(wb.count(), 259);\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_filter_section() {\n    let inputs = vec![\n        (\"{% filter upper %}Hello{% endfilter %}\", \"HELLO\"),\n        (\"{% filter upper %}Hello{% if true %} world{% endif %}{% endfilter %}\", \"HELLO WORLD\"),\n        (\"{% filter upper %}Hello {% for i in range(end=3) %}i{% endfor %}{% endfilter %}\", \"HELLO III\"),\n        (\n            \"{% filter upper %}Hello {% for i in range(end=3) %}{% if i == 1 %}{% break %} {% endif %}i{% endfor %}{% endfilter %}\",\n            \"HELLO I\",\n        ),\n        (\"{% filter title %}Hello {% if true %}{{ 'world' | upper | safe }}{% endif %}{% endfilter %}\", \"Hello World\"),\n        (\"{% filter safe %}{% filter upper %}<Hello>{% endfilter %}{% endfilter%}\", \"<HELLO>\")\n    ];\n\n    let context = Context::new();\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn into_header_name() {\n    let mut m = HeaderMap::new();\n    m.insert(HOST, \"localhost\".parse().unwrap());\n    m.insert(&ACCEPT, \"*/*\".parse().unwrap());\n    m.insert(\"connection\", \"keep-alive\".parse().unwrap());\n\n    m.append(LOCATION, \"/\".parse().unwrap());\n    m.append(&VIA, \"bob\".parse().unwrap());\n    m.append(\"transfer-encoding\", \"chunked\".parse().unwrap());\n\n    assert_eq!(m.len(), 6);\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_read_index_on_replica() {\n    let count = 3;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.run();\n\n    let k1 = b\"k1\";\n    let (k2, v2) = (b\"k2\", b\"v2\");\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(k1), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let mut storage = cluster.sim.rl().storages[&leader.get_id()].clone();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader.clone());\n    let snap_ctx = SnapContext {\n        pb_ctx: &ctx,\n        ..Default::default()\n    };\n\n    // write some data\n    let peers = region.get_peers();\n    assert_none(snap_ctx, &mut storage, k2);\n    must_put(&ctx, &storage, k2, v2);\n\n    // read on follower\n    let mut follower_peer = None;\n    for p in peers {\n        if p.get_id() != leader.get_id() {\n            follower_peer = Some(p.clone());\n            break;\n        }\n    }\n\n    assert!(follower_peer.is_some());\n    ctx.set_peer(follower_peer.as_ref().unwrap().clone());\n    let resp = read_index_on_peer(\n        &mut cluster,\n        follower_peer.unwrap(),\n        region.clone(),\n        false,\n        std::time::Duration::from_secs(5),\n    );\n    assert!(!resp.as_ref().unwrap().get_header().has_error());\n    assert_ne!(\n        resp.unwrap().get_responses()[0]\n            .get_read_index()\n            .get_read_index(),\n        0\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_nested_paths_copy_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file1 = \"source_file\";\n    let dir1 = \"source_dir\";\n    let dir2 = \"target_dir\";\n\n    at.mkdir(dir1);\n    at.mkdir(dir2);\n    at.touch(format!(\"{dir1}/{file1}\"));\n\n    ucmd.arg(format!(\"{dir1}/{file1}\"))\n        .arg(dir2)\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(format!(\"{dir2}/{file1}\")));\n}"}
{"code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn test_escape_basic() {\n    assert_eq!(to_string(&\"\\x07\").unwrap(), \"\\\"\\\\u{7}\\\"\");\n\n    assert_eq!(from_str::<String>(\"\\\"\\\\x07\\\"\").unwrap(), \"\\x07\");\n    assert_eq!(from_str::<String>(\"\\\"\\\\u{7}\\\"\").unwrap(), \"\\x07\");\n\n    assert_eq!(from_str::<char>(\"\\'\\\\x07\\'\").unwrap(), '\\x07');\n    assert_eq!(from_str::<char>(\"\\'\\\\u{7}\\'\").unwrap(), '\\x07');\n}"}
{"code": "pub fn has_0rtt(&self) -> bool {\n        self.zero_rtt_enabled\n    }", "test": "fn zero_rtt_happypath() {\n    let _guard = subscribe();\n    let mut pair = Pair::new(\n        Default::default(),\n        ServerConfig {\n            use_retry: true,\n            ..server_config()\n        },\n    );\n    let config = client_config();\n\n    // Establish normal connection\n    let client_ch = pair.begin_connect(config.clone());\n    pair.drive();\n    pair.server.assert_accept();\n    pair.client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .close(pair.time, VarInt(0), [][..].into());\n    pair.drive();\n\n    pair.client.addr = SocketAddr::new(\n        Ipv6Addr::LOCALHOST.into(),\n        CLIENT_PORTS.lock().unwrap().next().unwrap(),\n    );\n    info!(\"resuming session\");\n    let client_ch = pair.begin_connect(config);\n    assert!(pair.client_conn_mut(client_ch).has_0rtt());\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    const MSG: &[u8] = b\"Hello, 0-RTT!\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected)\n    );\n\n    assert!(pair.client_conn_mut(client_ch).accepted_0rtt());\n    let server_ch = pair.server.assert_accept();\n\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    // We don't currently preserve stream event order wrt. connection events\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Connected)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    let _ = chunks.finalize();\n    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);\n}"}
{"code": "pub fn raw(input: &str, json: &Value) -> Result<Value, JqlRunnerError> {\n    if input.is_empty() {\n        return Err(JqlRunnerError::EmptyQueryError);\n    }\n\n    let tokens = parse(input)?;\n\n    token(&tokens, json)\n}", "test": "fn check_raw_integration() {\n    assert_eq!(\n        raw(r#\"\"a\",\"b\"\"#, &json!({ \"a\": 1, \"b\": 2 })),\n        Ok(json!([1, 2]))\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_custom_backup_suffix_via_env() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let suffix = \"super-suffix-of-the-century\";\n\n    ucmd.arg(\"-b\")\n        .env(\"SIMPLE_BACKUP_SUFFIX\", suffix)\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}{suffix}\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn buffered_server_data_sent() {\n    let server_config = Arc::new(make_server_config(KeyType::Rsa));\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);\n        let (mut client, mut server) =\n            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n\n        assert_eq!(5, server.writer().write(b\"hello\").unwrap());\n\n        do_handshake(&mut client, &mut server);\n        transfer(&mut server, &mut client);\n        client.process_new_packets().unwrap();\n\n        check_read(&mut client.reader(), b\"hello\");\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_tee_append() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let content = \"tee_sample_content\";\n    let file = \"tee_out\";\n\n    at.touch(file);\n    at.write(file, content);\n    assert_eq!(at.read(file), content);\n\n    ucmd.arg(\"-a\")\n        .arg(file)\n        .pipe_in(content)\n        .succeeds()\n        .stdout_is(content);\n    assert!(at.file_exists(file));\n    assert_eq!(at.read(file), content.repeat(2));\n}"}
{"code": "pub fn get_id(&self) -> ConnId {\n        self.id\n    }", "test": "fn test_witness_leader_transfer_out() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n\n    // prevent this peer from applying the switch witness command until it's elected\n    // as the Raft leader\n    fail::cfg(\"before_exec_batch_switch_witness\", \"pause\").unwrap();\n    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();\n    // nonwitness -> witness\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store2.get_id()], vec![true]);\n    // make sure the left peers have applied switch witness cmd\n    std::thread::sleep(Duration::from_millis(500));\n\n    // the other follower is isolated\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    for i in 1..10 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), format!(\"v{}\", i).as_bytes());\n    }\n    // the leader is down\n    cluster.stop_node(1);\n\n    // new leader would help to replicate the logs\n    cluster.clear_send_filters();\n    std::thread::sleep(Duration::from_millis(1000));\n    // make sure the new leader has became to the witness\n    fail::remove(\"before_exec_batch_switch_witness\");\n    std::thread::sleep(Duration::from_millis(500));\n\n    // forbid writes\n    let put = new_put_cmd(b\"k3\", b\"v3\");\n    must_get_error_is_witness(&mut cluster, &region, put);\n    // forbid reads\n    let get = new_get_cmd(b\"k1\");\n    must_get_error_is_witness(&mut cluster, &region, get);\n    // forbid read index\n    let read_index = new_read_index_cmd();\n    must_get_error_is_witness(&mut cluster, &region, read_index);\n\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n\n    cluster.must_transfer_leader(region.get_id(), peer_on_store3);\n    cluster.must_put(b\"k1\", b\"v1\");\n    assert_eq!(\n        cluster.leader_of_region(region.get_id()).unwrap().store_id,\n        nodes[2],\n    );\n    assert_eq!(cluster.must_get(b\"k9\"), Some(b\"v9\".to_vec()));\n}"}
{"code": "pub fn plus<P: AsRef<Path>>(&self, name: P) -> PathBuf {\n        let mut pathbuf = self.subdir.clone();\n        pathbuf.push(name);\n        pathbuf\n    }", "test": "fn valid_context_directory() {\n    let (dir, mut cmd) = at_and_ucmd!();\n    dir.mkdir(\"a\");\n    dir.symlink_dir(\"a\", \"la\");\n\n    let b_path = Path::new(\"a\").join(\"b.txt\");\n    dir.touch(b_path.to_str().unwrap());\n\n    let la_context = get_file_context(dir.plus(\"la\")).unwrap();\n    let b_context = get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap();\n\n    let new_la_context = \"guest_u:object_r:etc_t:s0:c42\";\n\n    cmd.args(&[\"--verbose\", new_la_context])\n        .arg(dir.plus(\"la\"))\n        .succeeds();\n    assert_eq!(get_file_context(dir.plus(\"la\")).unwrap(), la_context);\n    assert_eq!(\n        get_file_context(dir.plus(\"a\")).unwrap().as_deref(),\n        Some(new_la_context)\n    );\n    assert_eq!(\n        get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap(),\n        b_context\n    );\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_raftkv() {\n    let count = 1;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.run();\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(b\"k1\"), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader_id = cluster.leader_of_region(region.get_id()).unwrap();\n    let mut storage = cluster.sim.rl().storages[&leader_id.get_id()].clone();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(region.get_peers()[0].clone());\n    let snap_ctx = SnapContext {\n        pb_ctx: &ctx,\n        ..Default::default()\n    };\n\n    get_put(snap_ctx.clone(), &mut storage);\n    batch(snap_ctx.clone(), &mut storage);\n    seek(snap_ctx.clone(), &mut storage);\n    near_seek(snap_ctx.clone(), &mut storage);\n    cf(snap_ctx, &mut storage);\n    empty_write(&ctx, &storage);\n    wrong_context(&ctx, &storage);\n    // TODO: test multiple node\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "async fn test_axfr_refused() {\n    let mut test = create_test();\n    test.set_allow_axfr(false);\n\n    let origin = test.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin.clone(), Box::new(Arc::new(test)));\n\n    let mut query: Query = Query::new();\n    query.set_name(origin.into());\n    query.set_query_type(RecordType::AXFR);\n\n    let mut question: Message = Message::new();\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.response_code(), ResponseCode::Refused);\n    assert!(result.answers().is_empty());\n    assert!(result.name_servers().is_empty());\n    assert!(result.additionals().is_empty());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_both_date_and_reference() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ref_file = \"test_touch_reference\";\n    let file = \"test_touch_set_both_date_and_reference\";\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501011234\");\n\n    at.touch(ref_file);\n    set_file_times(&at, ref_file, start_of_year, start_of_year);\n    assert!(at.file_exists(ref_file));\n\n    ucmd.args(&[\"-d\", \"Thu Jan 01 12:34:00 2015\", \"-r\", ref_file, file])\n        .succeeds()\n        .no_stderr();\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, start_of_year);\n    assert_eq!(mtime, start_of_year);\n}"}
{"code": "fn is_redirection() {\n    assert!(status_code(300).is_redirection());\n    assert!(status_code(399).is_redirection());\n\n    assert!(!status_code(299).is_redirection());\n    assert!(!status_code(400).is_redirection());\n}", "test": "fn is_redirection() {\n    assert!(status_code(300).is_redirection());\n    assert!(status_code(399).is_redirection());\n\n    assert!(!status_code(299).is_redirection());\n    assert!(!status_code(400).is_redirection());\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_sync_recover_after_apply_snapshot() {\n    let mut cluster = prepare_cluster();\n    configure_for_snapshot(&mut cluster);\n    run_cluster(&mut cluster);\n    let region = cluster.get_region(b\"k1\");\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k2\", b\"v2\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    must_get_none(&cluster.get_engine(1), b\"k2\");\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n\n    // swith to async\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::Async, vec![]);\n    rx.recv_timeout(Duration::from_millis(100)).unwrap();\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 2);\n    assert_eq!(state.state, RegionReplicationState::SimpleMajority);\n\n    // Write some data to trigger snapshot.\n    for i in 10..110 {\n        let key = format!(\"k{}\", i);\n        let value = format!(\"v{}\", i);\n        cluster.must_put_cf(\"default\", key.as_bytes(), value.as_bytes());\n    }\n\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::SyncRecover, vec![]);\n    thread::sleep(Duration::from_millis(100));\n    // Add node 3 back, snapshot will apply\n    cluster.clear_send_filters();\n    cluster.must_transfer_leader(region.get_id(), new_peer(3, 3));\n    must_get_equal(&cluster.get_engine(3), b\"k100\", b\"v100\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 3);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n}"}
{"code": "fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }", "test": "fn test_default_block_size_in_posix_portability_mode() {\n    fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }\n\n    let output = new_ucmd!().arg(\"-P\").succeeds().stdout_move_str();\n    assert_eq!(get_header(&output), \"1024-blocks\");\n\n    let output = new_ucmd!()\n        .arg(\"-P\")\n        .env(\"POSIXLY_CORRECT\", \"1\")\n        .succeeds()\n        .stdout_move_str();\n    assert_eq!(get_header(&output), \"512-blocks\");\n}"}
{"code": "pub fn capacity(&self) -> usize {\n        self.inner.capacity() as usize\n    }", "test": "async fn stream_close_by_trailers_frame_releases_capacity() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let window_size = frame::DEFAULT_INITIAL_WINDOW_SIZE as usize;\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Send request\n        let (resp1, mut s1) = client.send_request(request, false).unwrap();\n\n        // This effectively reserves the entire connection window\n        s1.reserve_capacity(window_size);\n\n        // The capacity should be immediately available as nothing else is\n        // happening on the stream.\n        assert_eq!(s1.capacity(), window_size);\n\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Create a second stream\n        let (resp2, mut s2) = client.send_request(request, false).unwrap();\n\n        // Request capacity\n        s2.reserve_capacity(5);\n\n        // There should be no available capacity (as it is being held up by\n        // the previous stream\n        assert_eq!(s2.capacity(), 0);\n\n        // Closing the previous stream by sending a trailers frame will\n        // release the capacity to s2\n        s1.send_trailers(Default::default()).unwrap();\n\n        // The capacity should be available\n        assert_eq!(s2.capacity(), 5);\n\n        // Send the frame\n        s2.send_data(\"hello\".into(), true).unwrap();\n\n        // Drive both streams to prevent the handles from being dropped\n        // (which will send a RST_STREAM) before the connection is closed.\n        h2.drive(resp1).await.unwrap();\n        h2.drive(resp2).await.unwrap();\n    };\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        // Get the first frame\n        assert_default_settings!(settings);\n        srv.recv_frame(frames::headers(1).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.recv_frame(frames::headers(3).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(3).response(200)).await;\n        srv.recv_frame(frames::headers(1).eos()).await;\n        srv.recv_frame(frames::data(3, &b\"hello\"[..]).eos()).await;\n    };\n    join(srv, h2).await;\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nul_number_r() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=r/3\", \"--separator=\\\\0\", \"separator_nul.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\x004\\0\");\n    assert_eq!(file_read(&at, \"xab\"), \"2\\x005\\0\");\n    assert_eq!(file_read(&at, \"xac\"), \"3\\0\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_early_return_after_exit_joint_state() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Changes the group config to\n    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[1]).unwrap();\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store0.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[0], peer_on_store0.get_id()),\n    );\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store2.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[2], peer_on_store2.get_id()),\n    );\n    // Wait the new learner to be initialized.\n    sleep_ms(100);\n    pd_client.must_joint_confchange(\n        region.get_id(),\n        vec![\n            (\n                ConfChangeType::AddNode,\n                new_peer(nodes[0], peer_on_store0.get_id()),\n            ),\n            (\n                ConfChangeType::AddLearnerNode,\n                new_learner_peer(nodes[1], peer_on_store1.get_id()),\n            ),\n        ],\n    );\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut demoted = true;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n        demoted = region\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        if demoted {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_eq!(demoted, true);\n}"}
{"code": "pub(super) fn req(text: &str) -> VersionReq {\n    VersionReq(crate::util::req(text))\n}", "test": "pub fn test_wildcard() {\n    let err = req_err(\"\");\n    assert_to_string(\n        err,\n        \"unexpected end of input while parsing major version number\",\n    );\n\n    let ref r = req(\"*\");\n    assert_match_all(r, &[\"0.9.1\", \"2.9.0\", \"0.0.9\", \"1.0.1\", \"1.1.1\"]);\n    assert_match_none(r, &[\"1.0.0-pre\"]);\n\n    for s in &[\"x\", \"X\"] {\n        assert_eq!(*r, req(s));\n    }\n\n    let ref r = req(\"1.*\");\n    assert_match_all(r, &[\"1.2.0\", \"1.2.1\", \"1.1.1\", \"1.3.0\"]);\n    assert_match_none(r, &[\"0.0.9\", \"1.2.0-pre\"]);\n\n    for s in &[\"1.x\", \"1.X\", \"1.*.*\"] {\n        assert_eq!(*r, req(s));\n    }\n\n    let ref r = req(\"1.2.*\");\n    assert_match_all(r, &[\"1.2.0\", \"1.2.2\", \"1.2.4\"]);\n    assert_match_none(r, &[\"1.9.0\", \"1.0.9\", \"2.0.1\", \"0.1.3\", \"1.2.2-pre\"]);\n\n    for s in &[\"1.2.x\", \"1.2.X\"] {\n        assert_eq!(*r, req(s));\n    }\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_on_hibernated_follower() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store5 = find_peer(&region, 5).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());\n\n    // wait a while to hibernate\n    std::thread::sleep(Duration::from_millis(\n        cluster.cfg.raft_store.raft_election_timeout_ticks as u64\n            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n            * 3,\n    ));\n\n    cluster.stop_node(3);\n    cluster.stop_node(4);\n    cluster.stop_node(5);\n\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // remove the peers on failed nodes\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k2\"), None);\n    assert_eq!(cluster.must_get(b\"k3\"), None);\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "pub fn guess_syntax() -> OutputFmt {\n    match env::var(\"SHELL\") {\n        Ok(ref s) if !s.is_empty() => {\n            let shell_path: &Path = s.as_ref();\n            if let Some(name) = shell_path.file_name() {\n                if name == \"csh\" || name == \"tcsh\" {\n                    OutputFmt::CShell\n                } else {\n                    OutputFmt::Shell\n                }\n            } else {\n                OutputFmt::Shell\n            }\n        }\n        _ => OutputFmt::Unknown,\n    }\n}", "test": "fn test_shell_syntax() {\n    use std::env;\n    let last = env::var(\"SHELL\");\n    env::set_var(\"SHELL\", \"/path/csh\");\n    assert_eq!(OutputFmt::CShell, guess_syntax());\n    env::set_var(\"SHELL\", \"csh\");\n    assert_eq!(OutputFmt::CShell, guess_syntax());\n    env::set_var(\"SHELL\", \"/path/bash\");\n    assert_eq!(OutputFmt::Shell, guess_syntax());\n    env::set_var(\"SHELL\", \"bash\");\n    assert_eq!(OutputFmt::Shell, guess_syntax());\n    env::set_var(\"SHELL\", \"/asd/bar\");\n    assert_eq!(OutputFmt::Shell, guess_syntax());\n    env::set_var(\"SHELL\", \"foo\");\n    assert_eq!(OutputFmt::Shell, guess_syntax());\n    env::set_var(\"SHELL\", \"\");\n    assert_eq!(OutputFmt::Unknown, guess_syntax());\n    env::remove_var(\"SHELL\");\n    assert_eq!(OutputFmt::Unknown, guess_syntax());\n\n    if let Ok(s) = last {\n        env::set_var(\"SHELL\", s);\n    }\n}"}
{"code": "fn clone(&self) -> Self {\n        let refs = self.refs.fetch_add(1, atomic::Ordering::SeqCst);\n\n        trace!(\n            \"Storage referenced\"; \"original_ref\" => refs\n        );\n\n        Self {\n            engine: self.engine.clone(),\n            sched: self.sched.clone(),\n            read_pool: self.read_pool.clone(),\n            refs: self.refs.clone(),\n            max_key_size: self.max_key_size,\n            concurrency_manager: self.concurrency_manager.clone(),\n            api_version: self.api_version,\n            causal_ts_provider: self.causal_ts_provider.clone(),\n            resource_tag_factory: self.resource_tag_factory.clone(),\n            quota_limiter: self.quota_limiter.clone(),\n            _phantom: PhantomData,\n        }\n    }", "test": "fn test_raft_storage_store_not_match() {\n    let (_cluster, storage, mut ctx) = new_raft_storage();\n\n    let key = Key::from_raw(b\"key\");\n    assert_eq!(storage.get(ctx.clone(), &key, 5).unwrap().0, None);\n    storage\n        .prewrite(\n            ctx.clone(),\n            vec![Mutation::make_put(key.clone(), b\"value\".to_vec())],\n            b\"key\".to_vec(),\n            10,\n        )\n        .unwrap();\n    storage\n        .commit(ctx.clone(), vec![key.clone()], 10, 15)\n        .unwrap();\n    assert_eq!(\n        storage.get(ctx.clone(), &key, 20).unwrap().0.unwrap(),\n        b\"value\".to_vec()\n    );\n\n    // Test store not match.\n    let mut peer = ctx.get_peer().clone();\n    let store_id = peer.get_store_id();\n\n    peer.set_store_id(store_id + 1);\n    ctx.set_peer(peer);\n    storage.get(ctx.clone(), &key, 20).unwrap_err();\n    let res = storage.get(ctx.clone(), &key, 20);\n    if let StorageError(box StorageErrorInner::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n        box KvErrorInner::Request(ref e),\n    ))))) = *res.as_ref().err().unwrap()\n    {\n        assert!(e.has_store_not_match());\n    } else {\n        panic!(\"expect store_not_match, but got {:?}\", res);\n    }\n    storage\n        .batch_get(ctx.clone(), &[key.clone()], 20)\n        .unwrap_err();\n    storage\n        .scan(ctx.clone(), key, None, 1, false, 20)\n        .unwrap_err();\n    storage.scan_locks(ctx, 20, None, None, 100).unwrap_err();\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_recursive() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_recursive_directory\";\n    let file_a = \"test_rm_recursive_directory/test_rm_recursive_file_a\";\n    let file_b = \"test_rm_recursive_directory/test_rm_recursive_file_b\";\n\n    at.mkdir(dir);\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"-r\").arg(dir).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(dir));\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn maximum_diagnostics() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), ERRORS.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    assert_eq!(\n        messages\n            .iter()\n            .filter(|m| m.level == LogLevel::Error)\n            .count(),\n        20_usize\n    );\n\n    assert!(messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Log)\n        .any(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"The number of diagnostics exceeds the number allowed by Biome\")\n                && content.contains(\"Diagnostics not shown\")\n                && content.contains(\"77\")\n        }));\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"maximum_diagnostics\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn escaping_happens_at_the_end() {\n    let inputs = vec![\n        #[cfg(feature = \"builtins\")]\n        (\"{{ url | urlencode | safe }}\", \"https%3A//www.example.org/apples-%26-oranges/\"),\n        (\"{{ '<html>' }}\", \"&lt;html&gt;\"),\n        (\"{{ '<html>' | safe }}\", \"<html>\"),\n        (\"{{ 'hello' | safe | replace(from='h', to='&') }}\", \"&amp;ello\"),\n        (\"{{ 'hello' | replace(from='h', to='&') | safe }}\", \"&ello\"),\n    ];\n\n    for (input, expected) in inputs {\n        let mut context = Context::new();\n        context.insert(\"url\", \"https://www.example.org/apples-&-oranges/\");\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_bootstrap_half_way_failure() {\n    let server = test_pd::Server::new(1);\n    let eps = server.bind_addrs();\n    let pd_client = test_pd::util::new_client(eps, None);\n    let path = TempDir::new().unwrap();\n    let engines = engine_test::new_temp_engine(&path);\n    let bootstrap = || {\n        let logger = slog_global::borrow_global().new(o!());\n        let mut bootstrap = Bootstrap::new(&engines.raft, 0, &pd_client, logger);\n        match bootstrap.bootstrap_store() {\n            Ok(store_id) => {\n                let mut store = Store::default();\n                store.set_id(store_id);\n                bootstrap.bootstrap_first_region(&store, store_id)\n            }\n            Err(e) => Err(e),\n        }\n    };\n\n    // Try to start this node, return after persisted some keys.\n    fail::cfg(\"node_after_bootstrap_store\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_bootstrap_store\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n\n    let ident = engines.raft.get_store_ident().unwrap().unwrap();\n    assert_ne!(ident.get_store_id(), 0);\n\n    // Check whether it can bootstrap cluster successfully.\n    fail::remove(\"node_after_bootstrap_store\");\n    fail::cfg(\"node_after_prepare_bootstrap_cluster\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_prepare_bootstrap_cluster\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));\n\n    fail::remove(\"node_after_prepare_bootstrap_cluster\");\n    fail::cfg(\"node_after_bootstrap_cluster\", \"return\").unwrap();\n    let s = format!(\"{}\", bootstrap().unwrap_err());\n    assert!(s.contains(\"node_after_bootstrap_cluster\"), \"{}\", s);\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));\n\n    // Although aborted by error, rebootstrap should continue.\n    bootstrap().unwrap().unwrap();\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n\n    // Second bootstrap should be noop.\n    assert_eq!(bootstrap().unwrap(), None);\n\n    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));\n}"}
{"code": "pub fn to_string(&self) -> Result<String> {\n        let s = match *self {\n            Datum::I64(i) => format!(\"{}\", i),\n            Datum::U64(u) => format!(\"{}\", u),\n            Datum::F64(f) => format!(\"{}\", f),\n            Datum::Bytes(ref bs) => String::from_utf8(bs.to_vec())?,\n            Datum::Time(t) => format!(\"{}\", t),\n            Datum::Dur(ref d) => format!(\"{}\", d),\n            Datum::Dec(ref d) => format!(\"{}\", d),\n            Datum::Json(ref d) => d.to_string(),\n            Datum::Enum(ref e) => e.to_string(),\n            Datum::Set(ref s) => s.to_string(),\n            ref d => return Err(invalid_type!(\"can't convert {} to string\", d)),\n        };\n        Ok(s)\n    }", "test": "fn test_undetermined_write_err() {\n    let (cluster, leader, ctx) = must_new_cluster_mul(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env)\n        .keepalive_time(Duration::from_millis(500))\n        .keepalive_timeout(Duration::from_millis(500))\n        .connect(&cluster.sim.read().unwrap().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.set_key(b\"k\".to_vec());\n    mutation.set_value(b\"v\".to_vec());\n    fail::cfg(\"applied_cb_return_undetermined_err\", \"return()\").unwrap();\n    let err = try_kv_prewrite_with_impl(\n        &client,\n        ctx,\n        vec![mutation],\n        b\"k\".to_vec(),\n        10,\n        0,\n        false,\n        false,\n    )\n    .unwrap_err();\n    assert_eq!(err.to_string(), \"RpcFailure: 1-CANCELLED CANCELLED\",);\n    fail::remove(\"applied_cb_return_undetermined_err\");\n    // The previous panic hasn't been captured.\n    assert!(std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| drop(cluster))).is_err());\n}"}
{"code": "pub fn to_str<'a, T: 'a>(&self, store: impl Into<StoreContext<'a, T>>) -> Result<Cow<'a, str>> {\n        let store = store.into().0;\n        let memory = self.options.memory(store);\n        self.to_str_from_memory(memory)\n    }", "test": "fn run_wasmtime_simple_wat() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/simple.wat\")?;\n    run_wasmtime(&[\n        \"run\",\n        \"--invoke\",\n        \"simple\",\n        \"-Ccache=n\",\n        wasm.path().to_str().unwrap(),\n        \"4\",\n    ])?;\n    assert_eq!(\n        run_wasmtime(&[\n            \"run\",\n            \"--invoke\",\n            \"get_f32\",\n            \"-Ccache=n\",\n            wasm.path().to_str().unwrap(),\n        ])?,\n        \"100\\n\"\n    );\n    assert_eq!(\n        run_wasmtime(&[\n            \"run\",\n            \"--invoke\",\n            \"get_f64\",\n            \"-Ccache=n\",\n            wasm.path().to_str().unwrap(),\n        ])?,\n        \"100\\n\"\n    );\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_3_others_b() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_3=value 3\".parse().unwrap());\n    headers.insert(VARY, \"*\".parse().unwrap());\n\n    assert_eq!(headers.len(), 6);\n\n    let vary = remove_values(&mut headers, VARY);\n    assert_eq!(vary, Some(\"*\".parse().unwrap()));\n    assert_eq!(headers.len(), 5);\n\n    let via = remove_values(&mut headers, VIA);\n    assert_eq!(via, Some(\"1.1 example.com\".parse().unwrap()));\n    assert_eq!(headers.len(), 3);\n\n    let cookie = remove_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookie, Some(\"cookie_1=value 1\".parse().unwrap()));\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_create() {\n    use hickory_client::rr::rdata::A;\n\n    let (_process, port) = named_process();\n    let socket = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), port);\n    let conn = UdpClientConnection::new(socket).unwrap();\n\n    let client = create_tsig_ready_client(conn);\n    let origin = Name::from_str(\"example.net.\").unwrap();\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.net.\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert_eq!(result.answers()[0], record);\n\n    // trying to create again should error\n    // TODO: it would be cool to make this\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n\n    // will fail if already set and not the same value.\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n\n    let result = client.create(record, origin).expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_by_rdata_multi() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // append a record\n    let mut rrset = RecordSet::with_ttl(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n\n    let record1 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 10)))\n        .clone();\n    let record2 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 11)))\n        .clone();\n    let record3 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 12)))\n        .clone();\n    let record4 = rrset\n        .new_record(&RData::A(A::new(100, 10, 100, 13)))\n        .clone();\n    let rrset = rrset;\n\n    // first check the must_exist option\n    let result = io_loop\n        .block_on(client.delete_by_rdata(rrset.clone(), origin.clone()))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = io_loop\n        .block_on(client.create(rrset, origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // append a record\n    let mut rrset = RecordSet::with_ttl(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n\n    let record1 = rrset.new_record(record1.data().unwrap()).clone();\n    let record3 = rrset.new_record(record3.data().unwrap()).clone();\n    let rrset = rrset;\n\n    let result = io_loop\n        .block_on(client.append(rrset.clone(), origin.clone(), true))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = io_loop\n        .block_on(client.delete_by_rdata(rrset, origin))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(\n            record1.name().clone(),\n            record1.dns_class(),\n            record1.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 2);\n    assert!(!result.answers().iter().any(|rr| *rr == record1));\n    assert!(result.answers().iter().any(|rr| *rr == record2));\n    assert!(!result.answers().iter().any(|rr| *rr == record3));\n    assert!(result.answers().iter().any(|rr| *rr == record4));\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn zlib_encoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::read::ZlibEncoder::new(original, flate2::Compression::default());\n    assert_eq!(encoder.read(&mut []).unwrap(), 0);\n    let mut encoded = Vec::new();\n    encoder.read_to_end(&mut encoded).unwrap();\n    let mut decoder = flate2::read::ZlibDecoder::new(encoded.as_slice());\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_short_hex_suffix_no_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-l\", \"9\", \"-x\", \"onehundredlines.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x00\"), \"00\\n01\\n02\\n03\\n04\\n05\\n06\\n07\\n08\\n\");\n    assert_eq!(at.read(\"x01\"), \"09\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n\");\n    assert_eq!(at.read(\"x02\"), \"18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n\");\n    assert_eq!(at.read(\"x03\"), \"27\\n28\\n29\\n30\\n31\\n32\\n33\\n34\\n35\\n\");\n    assert_eq!(at.read(\"x04\"), \"36\\n37\\n38\\n39\\n40\\n41\\n42\\n43\\n44\\n\");\n    assert_eq!(at.read(\"x05\"), \"45\\n46\\n47\\n48\\n49\\n50\\n51\\n52\\n53\\n\");\n    assert_eq!(at.read(\"x06\"), \"54\\n55\\n56\\n57\\n58\\n59\\n60\\n61\\n62\\n\");\n    assert_eq!(at.read(\"x07\"), \"63\\n64\\n65\\n66\\n67\\n68\\n69\\n70\\n71\\n\");\n    assert_eq!(at.read(\"x08\"), \"72\\n73\\n74\\n75\\n76\\n77\\n78\\n79\\n80\\n\");\n    assert_eq!(at.read(\"x09\"), \"81\\n82\\n83\\n84\\n85\\n86\\n87\\n88\\n89\\n\");\n    assert_eq!(at.read(\"x0a\"), \"90\\n91\\n92\\n93\\n94\\n95\\n96\\n97\\n98\\n\");\n    assert_eq!(at.read(\"x0b\"), \"99\\n\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_default() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_default_file\";\n\n    ucmd.arg(file).succeeds().no_stderr();\n\n    assert!(at.file_exists(file));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.heap.is_empty()\n    }", "test": "pub fn test_reschedule_coprocessor() {\n    let tag = \"tag_coprocessor\";\n\n    let (test_suite, mut store, endpoint) = setup_test_suite();\n    fail::cfg(\"copr_reschedule\", \"return\").unwrap();\n    fail::cfg_callback(\"scanner_next\", || cpu_load(Duration::from_millis(100))).unwrap();\n    defer!({\n        fail::remove(\"scanner_next\");\n        fail::remove(\"copr_reschedule\");\n    });\n\n    let jh = test_suite\n        .rt\n        .spawn(require_cpu_time_not_zero(&test_suite, tag));\n\n    let table = ProductTable::new();\n    let insert = prepare_insert(&mut store, &table);\n    insert.execute();\n    store.commit();\n\n    let mut req = DagSelect::from(&table).build();\n    let mut ctx = Context::default();\n    ctx.set_resource_group_tag(tag.as_bytes().to_vec());\n    req.set_context(ctx);\n    assert!(\n        !block_on(endpoint.parse_and_handle_unary_request(req, None))\n            .consume()\n            .get_data()\n            .is_empty()\n    );\n\n    assert!(block_on(jh).unwrap());\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn checks_incompatible_target() -> Result<()> {\n    let mut target = target_lexicon::Triple::host();\n    target.operating_system = target_lexicon::OperatingSystem::Unknown;\n    match Module::new(\n        &Engine::new(Config::new().target(&target.to_string())?)?,\n        \"(module)\",\n    ) {\n        Ok(_) => unreachable!(),\n        Err(e) => assert!(\n            format!(\"{:?}\", e).contains(\"configuration does not match the host\"),\n            \"bad error: {:?}\",\n            e\n        ),\n    }\n\n    Ok(())\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_inf_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.inf_string(Some(b\"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"nan\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"in00f\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.inf_string(Some(b\"inf\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.inf_string(None);\n    assert!(builder.is_valid());\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn trap_smoke() -> Result<()> {\n    let engine = Engine::default();\n    let mut linker = Linker::<()>::new(&engine);\n    linker.func_wrap(\"\", \"\", || -> Result<()> { bail!(\"test\") })?;\n\n    let mut store = Store::new(&engine, ());\n\n    let f = linker.get(&mut store, \"\", \"\").unwrap().into_func().unwrap();\n\n    let err = f.call(&mut store, &[], &mut []).unwrap_err();\n\n    assert!(err.to_string().contains(\"test\"));\n\n    Ok(())\n}"}
{"code": "pub fn map<I, O1, O2, E, F, G>(mut parser: F, mut f: G) -> impl FnMut(I) -> IResult<I, O2, E>\nwhere\n  F: Parser<I, O1, E>,\n  G: FnMut(O1) -> O2,\n{\n  move |input: I| {\n    let (input, o1) = parser.parse(input)?;\n    Ok((input, f(o1)))\n  }\n}", "test": "fn term_test() {\n  assert_eq!(\n    term(\" 3 *  5   \").map(|(i, x)| (i, format!(\"{:?}\", x))),\n    Ok((\"\", String::from(\"(3 * 5)\")))\n  );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        match self.kind {\n            ErrorKind::None => false,\n            ErrorKind::Str(_) | ErrorKind::Regex(_) => true,\n        }\n    }", "test": "fn disallow_non_utf8() {\n    assert!(regex::Regex::new(r\"(?-u)\\xFF\").is_err());\n    assert!(regex::Regex::new(r\"(?-u).\").is_err());\n    assert!(regex::Regex::new(r\"(?-u)[\\xFF]\").is_err());\n    assert!(regex::Regex::new(r\"(?-u)\u2603\").is_err());\n}\n\n"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn manually_destroy() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t1\" (type $t1 (sub resource)))\n\n                (core module $m\n                  (global $drops (mut i32) i32.const 0)\n                  (global $last-drop (mut i32) i32.const 0)\n\n                  (func (export \"dtor\") (param i32)\n                    (global.set $drops (i32.add (global.get $drops) (i32.const 1)))\n                    (global.set $last-drop (local.get 0))\n                  )\n                  (func (export \"drops\") (result i32) global.get $drops)\n                  (func (export \"last-drop\") (result i32) global.get $last-drop)\n                  (func (export \"pass\") (param i32) (result i32) local.get 0)\n                )\n                (core instance $i (instantiate $m))\n                (type $t2' (resource (rep i32) (dtor (func $i \"dtor\"))))\n                (export $t2 \"t2\" (type $t2'))\n                (core func $ctor (canon resource.new $t2))\n                (func (export \"[constructor]t2\") (param \"rep\" u32) (result (own $t2))\n                  (canon lift (core func $ctor)))\n                (func (export \"[static]t2.drops\") (result u32)\n                  (canon lift (core func $i \"drops\")))\n                (func (export \"[static]t2.last-drop\") (result u32)\n                  (canon lift (core func $i \"last-drop\")))\n\n                (func (export \"t1-pass\") (param \"t\" (own $t1)) (result (own $t1))\n                  (canon lift (core func $i \"pass\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    #[derive(Default)]\n    struct Data {\n        drops: u32,\n        last_drop: Option<u32>,\n    }\n\n    let mut store = Store::new(&engine, Data::default());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t1\", |mut cx, rep| {\n        let data: &mut Data = cx.data_mut();\n        data.drops += 1;\n        data.last_drop = Some(rep);\n        Ok(())\n    })?;\n    let i = linker.instantiate(&mut store, &c)?;\n    let t2_ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, \"[constructor]t2\")?;\n    let t2_drops = i.get_typed_func::<(), (u32,)>(&mut store, \"[static]t2.drops\")?;\n    let t2_last_drop = i.get_typed_func::<(), (u32,)>(&mut store, \"[static]t2.last-drop\")?;\n    let t1_pass = i.get_typed_func::<(Resource<MyType>,), (ResourceAny,)>(&mut store, \"t1-pass\")?;\n\n    // Host resources can be destroyed through `resource_drop`\n    let t1 = Resource::new_own(100);\n    let (t1,) = t1_pass.call(&mut store, (t1,))?;\n    t1_pass.post_return(&mut store)?;\n    assert_eq!(store.data().drops, 0);\n    assert_eq!(store.data().last_drop, None);\n    t1.resource_drop(&mut store)?;\n    assert_eq!(store.data().drops, 1);\n    assert_eq!(store.data().last_drop, Some(100));\n\n    // Guest resources can be destroyed through `resource_drop`\n    let (t2,) = t2_ctor.call(&mut store, (200,))?;\n    t2_ctor.post_return(&mut store)?;\n    assert_eq!(t2_drops.call(&mut store, ())?, (0,));\n    t2_drops.post_return(&mut store)?;\n    assert_eq!(t2_last_drop.call(&mut store, ())?, (0,));\n    t2_last_drop.post_return(&mut store)?;\n    t2.resource_drop(&mut store)?;\n    assert_eq!(t2_drops.call(&mut store, ())?, (1,));\n    t2_drops.post_return(&mut store)?;\n    assert_eq!(t2_last_drop.call(&mut store, ())?, (200,));\n    t2_last_drop.post_return(&mut store)?;\n\n    // Wires weren't crossed to drop more resources\n    assert_eq!(store.data().drops, 1);\n    assert_eq!(store.data().last_drop, Some(100));\n\n    Ok(())\n}"}
{"code": "pub fn get<Q>(&self, key: &Q) -> Option<&Value>\n    where\n        String: Borrow<Q>,\n        Q: ?Sized + Ord + Eq + Hash,\n    {\n        self.map.get(key)\n    }", "test": "fn test_serialize_unsized_value_to_raw_value() {\n    assert_eq!(\n        serde_json::value::to_raw_value(\"foobar\").unwrap().get(),\n        r#\"\"foobar\"\"#,\n    );\n}"}
{"code": "pub fn key_path(&self) -> &Path {\n        Path::new(&self.key_path)\n    }", "test": "fn test_parse_zone_keys() {\n    use hickory_proto::rr::dnssec::Algorithm;\n    use hickory_proto::rr::Name;\n\n    let config = Config::from_toml(\n        \"\n[[zones]]\nzone = \\\"example.com\\\"\nzone_type = \\\"Primary\\\"\nfile = \\\"example.com.zone\\\"\n\n\\\n         [[zones.keys]]\nkey_path = \\\"/path/to/my_ed25519.pem\\\"\nalgorithm = \\\"ED25519\\\"\n\\\n         signer_name = \\\"ns.example.com.\\\"\nis_zone_signing_key = false\nis_zone_update_auth = true\n\n[[zones.keys]]\nkey_path = \\\"/path/to/my_rsa.pem\\\"\nalgorithm = \\\n         \\\"RSASHA256\\\"\nsigner_name = \\\"ns.example.com.\\\"\n\",\n    )\n    .unwrap();\n    assert_eq!(\n        config.get_zones()[0].get_keys()[0].key_path(),\n        Path::new(\"/path/to/my_ed25519.pem\")\n    );\n    assert_eq!(\n        config.get_zones()[0].get_keys()[0].algorithm().unwrap(),\n        Algorithm::ED25519\n    );\n    assert_eq!(\n        config.get_zones()[0].get_keys()[0]\n            .signer_name()\n            .unwrap()\n            .unwrap(),\n        Name::parse(\"ns.example.com.\", None).unwrap()\n    );\n    assert!(!config.get_zones()[0].get_keys()[0].is_zone_signing_key(),);\n    assert!(config.get_zones()[0].get_keys()[0].is_zone_update_auth(),);\n\n    assert_eq!(\n        config.get_zones()[0].get_keys()[1].key_path(),\n        Path::new(\"/path/to/my_rsa.pem\")\n    );\n    assert_eq!(\n        config.get_zones()[0].get_keys()[1].algorithm().unwrap(),\n        Algorithm::RSASHA256\n    );\n    assert_eq!(\n        config.get_zones()[0].get_keys()[1]\n            .signer_name()\n            .unwrap()\n            .unwrap(),\n        Name::parse(\"ns.example.com.\", None).unwrap()\n    );\n    assert!(!config.get_zones()[0].get_keys()[1].is_zone_signing_key(),);\n    assert!(!config.get_zones()[0].get_keys()[1].is_zone_update_auth(),);\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn key_update_simple() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Bi)\n        .expect(\"couldn't open first stream\");\n\n    const MSG1: &[u8] = b\"hello1\";\n    pair.client_send(client_ch, s).write(MSG1).unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG1\n    );\n    let _ = chunks.finalize();\n\n    info!(\"initiating key update\");\n    pair.client_conn_mut(client_ch).initiate_key_update();\n\n    const MSG2: &[u8] = b\"hello2\";\n    pair.client_send(client_ch, s).write(MSG2).unwrap();\n    pair.drive();\n\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), Some(Event::Stream(StreamEvent::Readable { id })) if id == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 6 && chunk.bytes == MSG2\n    );\n    let _ = chunks.finalize();\n\n    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);\n    assert_eq!(pair.server_conn_mut(server_ch).lost_packets(), 0);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_no_create_file_exists() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_no_create_file_exists\";\n\n    at.touch(file);\n    assert!(at.file_exists(file));\n\n    ucmd.arg(\"-c\").arg(file).succeeds().no_stderr();\n\n    assert!(at.file_exists(file));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_one_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_rm_one_file\";\n\n    at.touch(file);\n\n    ucmd.arg(file).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn max_diagnostics_default() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    for i in 0..60 {\n        let file_path = PathBuf::from(format!(\"src/file_{i}.js\"));\n        fs.insert(file_path, UNFORMATTED.as_bytes());\n    }\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), (\"src\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut diagnostic_count = 0;\n    let mut filtered_messages = Vec::new();\n\n    for msg in console.out_buffer {\n        let MarkupBuf(nodes) = &msg.content;\n        let is_diagnostic = nodes.iter().any(|node| {\n            node.content\n                .contains(\"File content differs from formatting output\")\n                || node.content.contains(\"format\")\n                || node.content.contains(\"lint\")\n                || node.content.contains(\"ci\")\n        });\n\n        if is_diagnostic {\n            diagnostic_count += 1;\n        } else {\n            filtered_messages.push(msg);\n        }\n    }\n\n    console.out_buffer = filtered_messages;\n\n    for i in 0..60 {\n        let file_path = format!(\"src/file_{i}.js\");\n        fs.remove(Path::new(&file_path));\n    }\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"max_diagnostics_default\",\n        fs,\n        console,\n        result,\n    ));\n\n    assert_eq!(diagnostic_count, 20);\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn test_limits_memory_only() -> Result<()> {\n    let engine = Engine::default();\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (table (export \"t\") 0 anyfunc))\"#,\n    )?;\n\n    let mut store = Store::new(\n        &engine,\n        StoreLimitsBuilder::new()\n            .memory_size(10 * WASM_PAGE_SIZE)\n            .build(),\n    );\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n\n    let instance = Instance::new(&mut store, &module, &[])?;\n\n    // Test instance exports and host objects hitting the limit\n    for memory in IntoIterator::into_iter([\n        instance.get_memory(&mut store, \"m\").unwrap(),\n        Memory::new(&mut store, MemoryType::new(0, None))?,\n    ]) {\n        memory.grow(&mut store, 3)?;\n        memory.grow(&mut store, 5)?;\n        memory.grow(&mut store, 2)?;\n\n        assert_eq!(\n            memory\n                .grow(&mut store, 1)\n                .map_err(|e| e.to_string())\n                .unwrap_err(),\n            \"failed to grow memory by `1`\"\n        );\n    }\n\n    // Test instance exports and host objects *not* hitting the limit\n    for table in IntoIterator::into_iter([\n        instance.get_table(&mut store, \"t\").unwrap(),\n        Table::new(\n            &mut store,\n            TableType::new(ValType::FuncRef, 0, None),\n            Val::FuncRef(None),\n        )?,\n    ]) {\n        table.grow(&mut store, 2, Val::FuncRef(None))?;\n        table.grow(&mut store, 1, Val::FuncRef(None))?;\n        table.grow(&mut store, 2, Val::FuncRef(None))?;\n        table.grow(&mut store, 1, Val::FuncRef(None))?;\n    }\n\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_multi_0_others() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 0);\n    assert_eq!(headers.len(), 2);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn indent_size_parse_errors_negative() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"--indent-size=-1\"), (\"file.js\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"indent_size_parse_errors_negative\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub(super) fn expect<K>(\n        &mut self,\n        kind: K,\n        context: &'static str,\n        interner: &mut Interner,\n    ) -> ParseResult<Token>\n    where\n        K: Into<TokenKind>,\n    {\n        let next_token = self.next(interner).or_abrupt()?;\n        let kind = kind.into();\n\n        if next_token.kind() == &kind {\n            Ok(next_token)\n        } else {\n            Err(Error::expected(\n                [kind.to_string(interner)],\n                next_token.to_string(interner),\n                next_token.span(),\n                context,\n            ))\n        }\n    }", "test": "fn eph_basic_clone_test() {\n    run_test(|| {\n        let init_gc = Gc::new(String::from(\"bar\"));\n\n        let weak = WeakGc::new(&init_gc);\n\n        let new_gc = weak.upgrade().expect(\"Weak is live\");\n        let new_weak = weak.clone();\n\n        drop(weak);\n        force_collect();\n\n        assert_eq!(*new_gc, *new_weak.upgrade().expect(\"weak should be live\"));\n        assert_eq!(\n            *init_gc,\n            *new_weak.upgrade().expect(\"weak_should be live still\")\n        );\n    });\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_request_in_joint_state() {\n    let mut cluster = new_node_cluster(0, 3);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region_id = cluster.run_conf_change();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n    pd_client.must_add_peer(region_id, new_learner_peer(3, 3));\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Enter joint, now we have C_old(1, 2) and C_new(1, 3)\n    pd_client.must_joint_confchange(\n        region_id,\n        vec![\n            (ConfChangeType::AddLearnerNode, new_learner_peer(2, 2)),\n            (ConfChangeType::AddNode, new_peer(3, 3)),\n        ],\n    );\n\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    // Both new and old configuation have the newest log\n    must_get_equal(&cluster.get_engine(2), b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n\n    let region = cluster.get_region(b\"k1\");\n\n    // Isolated peer 2, so the old configuation can't reach quorum\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    let mut rx = cluster\n        .async_request(put_request(&region, 1, b\"k3\", b\"v3\"))\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    cluster.clear_send_filters();\n\n    // Isolated peer 3, so the new configuation can't reach quorum\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    let mut rx = cluster\n        .async_request(put_request(&region, 1, b\"k4\", b\"v4\"))\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    cluster.clear_send_filters();\n\n    // Leave joint\n    pd_client.must_leave_joint(region_id);\n\n    // Isolated peer 2, but it is not in quorum any more\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    cluster.must_put(b\"k5\", b\"v5\");\n    must_get_equal(&cluster.get_engine(3), b\"k5\", b\"v5\");\n}"}
{"code": "pub(crate) fn module(&self) -> &Arc<Module> {\n        self.runtime_info.module()\n    }", "test": "fn test_unknown_import_error() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let linker = Linker::new(store.engine());\n    let module = Module::new(\n        store.engine(),\n        r#\"(module (import \"unknown-module\" \"unknown-name\" (func)))\"#,\n    )?;\n    let err = linker\n        .instantiate(&mut store, &module)\n        .expect_err(\"should fail\");\n    let unknown_import: UnknownImportError = err.downcast()?;\n    assert_eq!(unknown_import.module(), \"unknown-module\");\n    assert_eq!(unknown_import.name(), \"unknown-name\");\n    unknown_import.ty().unwrap_func();\n    Ok(())\n}"}
{"code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "fn multi_memory_with_imported_memories() -> Result<()> {\n    // This test checks that the base address for the defined memory is correct for the instance\n    // despite the presence of an imported memory.\n\n    let mut pool = crate::small_pool_config();\n    pool.total_memories(2).max_memories_per_module(2);\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    config.wasm_multi_memory(true);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(\n        &engine,\n        r#\"(module (import \"\" \"m1\" (memory 0)) (memory (export \"m2\") 1))\"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n\n    let m1 = Memory::new(&mut store, MemoryType::new(0, None))?;\n    let instance = Instance::new(&mut store, &module, &[m1.into()])?;\n\n    let m2 = instance.get_memory(&mut store, \"m2\").unwrap();\n\n    m2.data_mut(&mut store)[0] = 0x42;\n    assert_eq!(m2.data(&store)[0], 0x42);\n\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n    self.len as usize\n  }", "test": "fn ArrayVec_push_pop() {\n  let mut av: ArrayVec<[i32; 4]> = Default::default();\n  assert_eq!(av.len(), 0);\n  assert_eq!(av.pop(), None);\n\n  av.push(10_i32);\n  assert_eq!(av.len(), 1);\n  assert_eq!(av[0], 10);\n  assert_eq!(av.pop(), Some(10));\n  assert_eq!(av.len(), 0);\n  assert_eq!(av.pop(), None);\n\n  av.push(10);\n  av.push(11);\n  av.push(12);\n  av.push(13);\n  assert_eq!(av[0], 10);\n  assert_eq!(av[1], 11);\n  assert_eq!(av[2], 12);\n  assert_eq!(av[3], 13);\n  assert_eq!(av.len(), 4);\n  assert_eq!(av.pop(), Some(13));\n  assert_eq!(av.len(), 3);\n  assert_eq!(av.pop(), Some(12));\n  assert_eq!(av.len(), 2);\n  assert_eq!(av.pop(), Some(11));\n  assert_eq!(av.len(), 1);\n  assert_eq!(av.pop(), Some(10));\n  assert_eq!(av.len(), 0);\n  assert_eq!(av.pop(), None);\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit126_wasi_snapshot0() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit126_wasi_snapshot0.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 1);\n    assert!(output.stdout.is_empty());\n    assert!(String::from_utf8_lossy(&output.stderr).contains(\"invalid exit status\"));\n    Ok(())\n}"}
{"code": "pub(crate) fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.page.memory()[self.value_range.clone()])\n    }", "test": "fn range_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: MultimapTableDefinition<&str, &str> = MultimapTableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.range::<&str>(start.as_str()..).unwrap()\n    };\n    assert_eq!(\n        iter.next()\n            .unwrap()\n            .unwrap()\n            .1\n            .next()\n            .unwrap()\n            .unwrap()\n            .value(),\n        \"world\"\n    );\n    assert!(iter.next().is_none());\n}"}
{"code": "pub fn exists(&self, module: &str, name: &str) -> bool {\n        self.map\n            .contains_key(&(module.to_string(), name.to_string()))\n    }", "test": "fn test_wasmer_run_works_with_dir() {\n    let temp_dir = tempfile::TempDir::new().unwrap();\n    let qjs_path = temp_dir.path().join(\"qjs.wasm\");\n\n    std::fs::copy(fixtures::qjs(), &qjs_path).unwrap();\n    std::fs::copy(\n        fixtures::qjs_wasmer_toml(),\n        temp_dir.path().join(\"wasmer.toml\"),\n    )\n    .unwrap();\n\n    assert!(temp_dir.path().exists());\n    assert!(temp_dir.path().join(\"wasmer.toml\").exists());\n    assert!(temp_dir.path().join(\"qjs.wasm\").exists());\n\n    // test with \"wasmer qjs.wasm\"\n    Command::new(get_wasmer_path())\n        .arg(temp_dir.path())\n        .arg(\"--\")\n        .arg(\"--quit\")\n        .assert()\n        .success();\n\n    // test again with \"wasmer run qjs.wasm\"\n    Command::new(get_wasmer_path())\n        .arg(\"run\")\n        .arg(temp_dir.path())\n        .arg(\"--\")\n        .arg(\"--quit\")\n        .assert()\n        .success();\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn handle_ws_both_sides_for_macro_definitions() {\n    let start_ws = WS { left: true, right: true };\n    let end_ws = WS { left: true, right: true };\n    let ast = vec![Node::MacroDefinition(\n        start_ws,\n        MacroDefinition {\n            name: \"something\".to_string(),\n            args: HashMap::new(),\n            body: vec![\n                Node::Text(\"\\n  \".to_string()),\n                Node::Text(\"hey\".to_string()),\n                Node::Text(\"  \".to_string()),\n            ],\n        },\n        end_ws,\n    )];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![Node::MacroDefinition(\n            start_ws,\n            MacroDefinition {\n                name: \"something\".to_string(),\n                args: HashMap::new(),\n                body: vec![Node::Text(\"hey\".to_string())],\n            },\n            end_ws,\n        ),]\n    );\n}"}
{"code": "fn is_cluster_bootstrapped(&self) -> Result<bool> {\n        let _timer = PD_REQUEST_HISTOGRAM_VEC\n            .is_cluster_bootstrapped\n            .start_coarse_timer();\n\n        let mut req = pdpb::IsBootstrappedRequest::default();\n        req.set_header(self.header());\n\n        let resp = sync_request(&self.pd_client, LEADER_CHANGE_RETRY, |client, option| {\n            client.is_bootstrapped_opt(&req, option)\n        })?;\n        check_resp_header(resp.get_header())?;\n\n        Ok(resp.get_bootstrapped())\n    }", "test": "fn test_get_tombstone_stores() {\n    let eps_count = 1;\n    let server = MockServer::new(eps_count);\n    let eps = server.bind_addrs();\n    let client = new_client(eps, None);\n\n    let mut all_stores = vec![];\n    let store_id = client.alloc_id().unwrap();\n    let mut store = metapb::Store::default();\n    store.set_id(store_id);\n    let region_id = client.alloc_id().unwrap();\n    let mut region = metapb::Region::default();\n    region.set_id(region_id);\n    client.bootstrap_cluster(store.clone(), region).unwrap();\n\n    all_stores.push(store);\n    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);\n    let s = client.get_all_stores(false).unwrap();\n    assert_eq!(s, all_stores);\n\n    // Add tombstone store.\n    let mut store99 = metapb::Store::default();\n    store99.set_id(99);\n    store99.set_state(metapb::StoreState::Tombstone);\n    server.default_handler().add_store(store99.clone());\n\n    // do not include tombstone.\n    let s = client.get_all_stores(true).unwrap();\n    assert_eq!(s, all_stores);\n\n    all_stores.push(store99.clone());\n    all_stores.sort_by_key(|a| a.get_id());\n    // include tombstone, there should be 2 stores.\n    let mut s = client.get_all_stores(false).unwrap();\n    s.sort_by_key(|a| a.get_id());\n    assert_eq!(s, all_stores);\n\n    // Add another tombstone store.\n    let mut store199 = store99;\n    store199.set_id(199);\n    server.default_handler().add_store(store199.clone());\n\n    all_stores.push(store199);\n    all_stores.sort_by_key(|a| a.get_id());\n    let mut s = client.get_all_stores(false).unwrap();\n    s.sort_by_key(|a| a.get_id());\n    assert_eq!(s, all_stores);\n\n    client.get_store(store_id).unwrap();\n    client.get_store(99).unwrap_err();\n    client.get_store(199).unwrap_err();\n}"}
{"code": "fn is_empty(&self) -> Result<bool> {\n        self.len().map(|x| x == 0)\n    }", "test": "fn is_empty() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        assert!(table.is_empty().unwrap());\n        table.insert(\"hello\", \"world\").unwrap();\n        assert!(!table.is_empty().unwrap());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert!(!table.is_empty().unwrap());\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_by_bytes_short_concatenated_with_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_by_bytes_short_concatenated_with_value\";\n    RandomFile::new(&at, name).add_bytes(10000);\n    ucmd.args(&[\"-b1000\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    for filename in glob.collect() {\n        assert_eq!(glob.directory.metadata(&filename).len(), 1000);\n    }\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_cli_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--files-max-size=16\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_cli_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn memory_growth_failure() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wmemory64\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/memory-grow-failure.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing a memory growth failure to be a trap\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_split_merge() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n    let before = cluster\n        .apply_state(region.get_id(), nodes[2])\n        .get_applied_index();\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k2\", b\"v2\");\n    cluster.must_split(&region, b\"k2\");\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    must_get_none(&cluster.get_engine(3), b\"k2\");\n    // applied index of witness is updated\n    let after = cluster\n        .apply_state(region.get_id(), nodes[2])\n        .get_applied_index();\n    assert!(after - before >= 3);\n\n    // the newly split peer should be witness as well\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k2\");\n    assert_ne!(left.get_id(), right.get_id());\n    assert!(find_peer(&left, nodes[2]).unwrap().is_witness);\n    assert!(find_peer(&right, nodes[2]).unwrap().is_witness);\n\n    // merge\n    pd_client.must_merge(left.get_id(), right.get_id());\n    let after_merge = cluster.get_region(b\"k1\");\n    assert!(find_peer(&after_merge, nodes[2]).unwrap().is_witness);\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    must_get_none(&cluster.get_engine(3), b\"k2\");\n    // epoch of witness is updated\n    assert_eq!(\n        cluster\n            .region_local_state(after_merge.get_id(), nodes[2])\n            .get_region()\n            .get_region_epoch(),\n        after_merge.get_region_epoch()\n    );\n\n    // split again\n    cluster.must_split(&after_merge, b\"k2\");\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k2\");\n    assert!(find_peer(&left, nodes[2]).unwrap().is_witness);\n    assert!(find_peer(&right, nodes[2]).unwrap().is_witness);\n\n    // can't merge with different witness location\n    let peer_on_store3 = find_peer(&left, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        left.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![false],\n    );\n    let left = cluster.get_region(b\"k1\");\n    let req = new_admin_request(\n        left.get_id(),\n        left.get_region_epoch(),\n        new_prepare_merge(right),\n    );\n    let resp = cluster\n        .call_command_on_leader(req, Duration::from_millis(100))\n        .unwrap();\n    assert!(\n        resp.get_header()\n            .get_error()\n            .get_message()\n            .contains(\"peers doesn't match\")\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_non_empty_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_non_empty_dir\";\n    let file_a = &format!(\"{dir}/test_rm_non_empty_file_a\");\n\n    at.mkdir(dir);\n    at.touch(file_a);\n\n    ucmd.arg(\"-d\")\n        .arg(dir)\n        .fails()\n        .stderr_contains(&format!(\"cannot remove '{dir}': Directory not empty\"));\n    assert!(at.file_exists(file_a));\n    assert!(at.dir_exists(dir));\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn wasm_fault_address_reported_by_default() -> Result<()> {\n    let engine = Engine::default();\n    let mut store = Store::new(&engine, ());\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (memory 1)\n                (func $start\n                    i32.const 0xdeadbeef\n                    i32.load\n                    drop)\n                (start $start)\n            )\n        \"#,\n    )?;\n    let err = Instance::new(&mut store, &module, &[]).unwrap_err();\n\n    // NB: at this time there's no programmatic access to the fault address\n    // because it's not always available for load/store traps. Only static\n    // memories on 32-bit have this information, but bounds-checked memories\n    // use manual trapping instructions and otherwise don't have a means of\n    // communicating the faulting address at this time.\n    //\n    // It looks like the exact reported fault address may not be deterministic,\n    // so assert that we have the right error message, but not the exact address.\n    let err = format!(\"{err:?}\");\n    assert!(\n        err.contains(\"memory fault at wasm address \")\n            && err.contains(\" in linear memory of size 0x10000\"),\n        \"bad error: {err}\"\n    );\n    Ok(())\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn format_stdin_with_errors() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"--stdin-file-path\"), (\"mock.js\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"format_stdin_with_errors\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u8_pow2_test() {\n    let values: &[u8] =\n        &[0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "pub fn get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, false)\n    }", "test": "fn test_node_update_localreader_after_removed() {\n    let mut cluster = new_node_cluster(0, 6);\n    let pd_client = cluster.pd_client.clone();\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    let r1 = cluster.run_conf_change();\n\n    // Add 4 peers.\n    for i in 2..6 {\n        pd_client.must_add_peer(r1, new_peer(i, i));\n    }\n\n    // Make sure peer 1 leads the region.\n    cluster.must_transfer_leader(r1, new_peer(1, 1));\n    let (key, value) = (b\"k1\", b\"v1\");\n    cluster.must_put(key, value);\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    // Make sure peer 2 is initialized.\n    let engine_2 = cluster.get_engine(2);\n    must_get_equal(&engine_2, key, value);\n\n    // Pause peer 2 apply worker if it executes AddNode.\n    let add_node_fp = \"apply_on_add_node_1_2\";\n    fail::cfg(add_node_fp, \"pause\").unwrap();\n\n    // Add peer 6.\n    pd_client.must_add_peer(r1, new_peer(6, 6));\n\n    // Isolate peer 2 from rest of the cluster.\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n\n    // Remove peer 2, so it will receive a gc msssage\n    // after max_leader_missing_duration timeout.\n    pd_client.must_remove_peer(r1, new_peer(2, 2));\n    thread::sleep(cluster.cfg.raft_store.max_leader_missing_duration.0 * 2);\n\n    // Continue peer 2 apply worker, so that peer 2 tries to\n    // update region to its read delegate.\n    fail::remove(add_node_fp);\n\n    // Make sure peer 2 is removed in node 2.\n    cluster.must_region_not_exist(r1, 2);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_mode_symbolic() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"target_dir\";\n    let file = \"source_file\";\n    let mode_arg = \"--mode=o+wx\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(file).arg(dir).arg(mode_arg).succeeds().no_stderr();\n\n    let dest_file = &format!(\"{dir}/{file}\");\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(dest_file));\n    let permissions = at.metadata(dest_file).permissions();\n    assert_eq!(0o100_003_u32, PermissionsExt::mode(&permissions));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        match &self.batch {\n            Either::Left(batch) => batch.is_empty(),\n            Either::Right(keys) => keys.is_empty(),\n        }\n    }", "test": "fn test_node_callback_when_destroyed() {\n    let count = 3;\n    let mut cluster = new_node_cluster(0, count);\n    // Increase the election tick to make this test case running reliably.\n    configure_for_lease_read(&mut cluster.cfg, None, Some(50));\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n    let leader = cluster.leader_of_region(1).unwrap();\n    let cc = new_change_peer_request(ConfChangeType::RemoveNode, leader.clone());\n    let epoch = cluster.get_region_epoch(1);\n    let req = new_admin_request(1, &epoch, cc);\n    // so the leader can't commit the conf change yet.\n    let block = Arc::new(AtomicBool::new(true));\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, leader.get_store_id())\n            .msg_type(MessageType::MsgAppendResponse)\n            .direction(Direction::Recv)\n            .when(Arc::clone(&block)),\n    ));\n    let mut filter = LeaseReadFilter::default();\n    filter.take = true;\n    // so the leader can't perform read index.\n    cluster.add_send_filter(CloneFilterFactory(filter.clone()));\n    // it always timeout, no need to wait.\n    let _ = cluster.call_command_on_leader(req, Duration::from_millis(500));\n\n    // To make sure `get` is handled before destroy leader, we must issue\n    // `get` then unblock append responses.\n    let leader_node_id = leader.get_store_id();\n    let get = new_get_cmd(b\"k1\");\n    let mut req = new_request(1, epoch, vec![get], true);\n    req.mut_header().set_peer(leader);\n    let (cb, mut rx) = make_cb(&req);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(leader_node_id, req, cb)\n        .unwrap();\n    // Unblock append responses after we issue the req.\n    block.store(false, Ordering::SeqCst);\n    let resp = rx.recv_timeout(Duration::from_secs(3)).unwrap();\n\n    assert!(\n        !filter.ctx.rl().is_empty(),\n        \"read index should be performed\"\n    );\n    assert!(\n        resp.get_header().get_error().has_region_not_found(),\n        \"{:?}\",\n        resp\n    );\n}"}
{"code": "pub fn is_extended_connect_protocol_enabled(&self) -> Option<bool> {\n        self.enable_connect_protocol.map(|val| val != 0)\n    }", "test": "async fn reject_authority_target_on_extended_connect_request() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let settings = client.assert_server_handshake().await;\n\n        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));\n\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"CONNECT\", \"bread:80\")\n                    .protocol(\"the-bread-protocol\"),\n            )\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let mut builder = server::Builder::new();\n\n        builder.enable_connect_protocol();\n\n        let mut srv = builder.handshake::<_, Bytes>(io).await.expect(\"handshake\");\n\n        assert!(srv.next().await.is_none());\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"code": "fn compute_error64(q: i32, w: u64) -> (i32, u64) {\n    let fp = lemire::compute_error::<f64>(q, w);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error64_test() {\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(compute_error64(0, 9007199254740992), (1065 + f64::INVALID_FP, 9223372036854775808));\n    assert_eq!(compute_error64(0, 9007199254740993), (1065 + f64::INVALID_FP, 9223372036854776832));\n    assert_eq!(compute_error64(0, 9007199254740994), (1065 + f64::INVALID_FP, 9223372036854777856));\n    assert_eq!(compute_error64(0, 9007199254740995), (1065 + f64::INVALID_FP, 9223372036854778880));\n    assert_eq!(compute_error64(0, 9007199254740996), (1065 + f64::INVALID_FP, 9223372036854779904));\n    assert_eq!(\n        compute_error64(0, 18014398509481984),\n        (1066 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error64(0, 18014398509481986),\n        (1066 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error64(0, 18014398509481988),\n        (1066 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error64(0, 18014398509481990),\n        (1066 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error64(0, 18014398509481992),\n        (1066 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test a much closer set of examples.\n    assert_eq!(\n        compute_error64(0, 9007199254740991),\n        (1064 + f64::INVALID_FP, 18446744073709549568)\n    );\n    assert_eq!(\n        compute_error64(0, 9223372036854776831),\n        (1075 + f64::INVALID_FP, 9223372036854776830)\n    );\n    assert_eq!(\n        compute_error64(0, 9223372036854776832),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error64(0, 9223372036854776833),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error64(-42, 9123456727292927),\n        (925 + f64::INVALID_FP, 13021432563531497894)\n    );\n    assert_eq!(\n        compute_error64(-43, 91234567272929275),\n        (925 + f64::INVALID_FP, 13021432563531498606)\n    );\n    assert_eq!(\n        compute_error64(-42, 9123456727292928),\n        (925 + f64::INVALID_FP, 13021432563531499320)\n    );\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(\n        compute_error64(-3, 9007199254740992000),\n        (1065 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error64(-3, 9007199254740993000),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error64(-3, 9007199254740994000),\n        (1065 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error64(-3, 9007199254740995000),\n        (1065 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error64(-3, 9007199254740996000),\n        (1065 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test from errors in atof.\n    assert_eq!(\n        compute_error64(-18, 1000000178813934326),\n        (1012 + f64::INVALID_FP, 9223373686122217470)\n    );\n\n    // Check edge-cases from previous errors.\n    assert_eq!(\n        compute_error64(-342, 2470328229206232720),\n        (-64 + f64::INVALID_FP, 18446744073709551608)\n    );\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.dense.is_empty()\n    }", "test": "fn same_import_names_still_distinct() -> anyhow::Result<()> {\n    const WAT: &str = r#\"\n(module\n  (import \"\" \"\" (func $a (result i32)))\n  (import \"\" \"\" (func $b (result f32)))\n  (func (export \"foo\") (result i32)\n    call $a\n    call $b\n    i32.trunc_f32_u\n    i32.add)\n)\n    \"#;\n\n    let mut store = Store::<()>::default();\n    let module = Module::new(store.engine(), WAT)?;\n\n    let imports = [\n        Func::new(\n            &mut store,\n            FuncType::new(None, Some(ValType::I32)),\n            |_, params, results| {\n                assert!(params.is_empty());\n                assert_eq!(results.len(), 1);\n                results[0] = 1i32.into();\n                Ok(())\n            },\n        )\n        .into(),\n        Func::new(\n            &mut store,\n            FuncType::new(None, Some(ValType::F32)),\n            |_, params, results| {\n                assert!(params.is_empty());\n                assert_eq!(results.len(), 1);\n                results[0] = 2.0f32.into();\n                Ok(())\n            },\n        )\n        .into(),\n    ];\n    let instance = Instance::new(&mut store, &module, &imports)?;\n\n    let func = instance.get_typed_func::<(), i32>(&mut store, \"foo\")?;\n    let result = func.call(&mut store, ())?;\n    assert_eq!(result, 3);\n    Ok(())\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn datagram_unsupported() {\n    let _guard = subscribe();\n    let server = ServerConfig {\n        transport: Arc::new(TransportConfig {\n            datagram_receive_buffer_size: None,\n            ..TransportConfig::default()\n        }),\n        ..server_config()\n    };\n    let mut pair = Pair::new(Default::default(), server);\n    let (client_ch, server_ch) = pair.connect();\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    assert_matches!(pair.client_datagrams(client_ch).max_size(), None);\n\n    match pair.client_datagrams(client_ch).send(Bytes::new()) {\n        Err(SendDatagramError::UnsupportedByPeer) => {}\n        Err(e) => panic!(\"unexpected error: {e}\"),\n        Ok(_) => panic!(\"unexpected success\"),\n    }\n}"}
{"code": "fn compute_error32(q: i32, w: u64) -> (i32, u64) {\n    let fp = lemire::compute_error::<f32>(q, w);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error32_test() {\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(compute_error32(0, 16777216), (111 + f32::INVALID_FP, 9223372036854775808));\n    assert_eq!(compute_error32(0, 16777217), (111 + f32::INVALID_FP, 9223372586610589696));\n    assert_eq!(compute_error32(0, 16777218), (111 + f32::INVALID_FP, 9223373136366403584));\n    assert_eq!(compute_error32(0, 16777219), (111 + f32::INVALID_FP, 9223373686122217472));\n    assert_eq!(compute_error32(0, 16777220), (111 + f32::INVALID_FP, 9223374235878031360));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(\n        compute_error32(-10, 167772160000000000),\n        (111 + f32::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error32(-10, 167772170000000000),\n        (111 + f32::INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error32(-10, 167772180000000000),\n        (111 + f32::INVALID_FP, 9223373136366403584)\n    );\n    // Let's check the lines to see if anything is different in table...\n    assert_eq!(\n        compute_error32(-10, 167772190000000000),\n        (111 + f32::INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error32(-10, 167772200000000000),\n        (111 + f32::INVALID_FP, 9223374235878031360)\n    );\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_batch_get_memory_lock() {\n    let (_cluster, client, ctx) = must_new_cluster_and_kv_client();\n\n    let mut req = BatchGetRequest::default();\n    req.set_context(ctx);\n    req.set_keys(vec![b\"a\".to_vec(), b\"b\".to_vec()].into());\n    req.version = 50;\n\n    fail::cfg(\"raftkv_async_snapshot_err\", \"return\").unwrap();\n    let resp = client.kv_batch_get(&req).unwrap();\n    // the injected error should be returned at both places for backward\n    // compatibility.\n    assert!(!resp.pairs[0].get_error().get_abort().is_empty());\n    assert!(!resp.get_error().get_abort().is_empty());\n    fail::remove(\"raftkv_async_snapshot_err\");\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn does_not_format_if_files_are_listed_in_ignore_option() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(\n        file_path.into(),\n        CONFIG_FORMATTER_AND_FILES_IGNORE.as_bytes(),\n    );\n\n    let file_path_test1 = Path::new(\"test1.js\");\n    fs.insert(file_path_test1.into(), UNFORMATTED.as_bytes());\n\n    let file_path_test2 = Path::new(\"test2.js\");\n    fs.insert(file_path_test2.into(), UNFORMATTED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                file_path_test1.as_os_str().to_str().unwrap(),\n                file_path_test2.as_os_str().to_str().unwrap(),\n                (\"--write\"),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path_test1)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, UNFORMATTED);\n\n    let mut buffer = String::new();\n    fs.open(file_path_test2)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, UNFORMATTED);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"does_not_format_if_files_are_listed_in_ignore_option\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn enum_unit_variant() {\n    let mut key = CacheKeyHasher::new();\n\n    let variant = Enum::Unit;\n    variant.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    variant.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_node_merge_write_data_to_source_region_after_merging() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(100);\n    // For snapshot after merging\n    cluster.cfg.raft_store.merge_max_log_gap = 10;\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(12);\n    cluster.cfg.raft_store.apply_batch_system.max_batch_size = Some(1);\n    cluster.cfg.raft_store.apply_batch_system.pool_size = 2;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k2\", b\"v2\");\n\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    let right_peer_2 = find_peer(&right, 2).cloned().unwrap();\n    assert_eq!(right_peer_2.get_id(), 2);\n\n    // Make sure peer 2 finish split before pause\n    cluster.must_put(b\"k2pause\", b\"vpause\");\n    must_get_equal(&cluster.get_engine(2), b\"k2pause\", b\"vpause\");\n\n    let on_handle_apply_2_fp = \"on_handle_apply_2\";\n    fail::cfg(on_handle_apply_2_fp, \"pause\").unwrap();\n\n    let right_peer_1 = find_peer(&right, 1).cloned().unwrap();\n    cluster.must_transfer_leader(right.get_id(), right_peer_1);\n\n    let left_peer_3 = find_peer(&left, 3).cloned().unwrap();\n    cluster.must_transfer_leader(left.get_id(), left_peer_3.clone());\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    cluster.must_try_merge(left.get_id(), right.get_id());\n\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n\n    fail::remove(schedule_merge_fp);\n\n    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));\n\n    region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    let state1 = cluster.apply_state(region.get_id(), 1);\n    for i in 0..15 {\n        cluster.must_put(format!(\"k2{}\", i).as_bytes(), b\"v2\");\n    }\n    cluster.wait_log_truncated(region.get_id(), 1, state1.get_applied_index());\n    // Ignore this msg to make left region exist.\n    let on_has_merge_target_fp = \"on_has_merge_target\";\n    fail::cfg(on_has_merge_target_fp, \"return\").unwrap();\n\n    cluster.clear_send_filters();\n    // On store 3, now the right region is updated by snapshot not applying logs\n    // so the left region still exist.\n    // Wait for left region to rollback merge (in previous wrong implementation)\n    sleep_ms(200);\n    // Write data to left region\n    let mut new_left = left;\n    let mut epoch = new_left.take_region_epoch();\n    // prepareMerge => conf_ver + 1, version + 1\n    // rollbackMerge => version + 1\n    epoch.set_conf_ver(epoch.get_conf_ver() + 1);\n    epoch.set_version(epoch.get_version() + 2);\n    let mut req = new_request(\n        new_left.get_id(),\n        epoch,\n        vec![new_put_cf_cmd(\"default\", b\"k11\", b\"v11\")],\n        false,\n    );\n    req.mut_header().set_peer(left_peer_3);\n    if let Ok(()) = cluster\n        .sim\n        .rl()\n        .async_command_on_node(3, req, Callback::None)\n    {\n        sleep_ms(200);\n        // The write must not succeed\n        must_get_none(&cluster.get_engine(2), b\"k11\");\n        must_get_none(&cluster.get_engine(3), b\"k11\");\n    }\n\n    fail::remove(on_handle_apply_2_fp);\n}"}
{"code": "fn is_none(&self) -> bool {\n        false\n    }", "test": "fn test_query_with_write_cmd() {\n    let cluster = Cluster::default();\n    let router = &cluster.routers[0];\n    std::thread::sleep(std::time::Duration::from_millis(200));\n    let region_id = 2;\n    let mut req = router.new_request_for(2);\n\n    for write_cmd in [\n        CmdType::Prewrite,\n        CmdType::Delete,\n        CmdType::DeleteRange,\n        CmdType::Put,\n        CmdType::IngestSst,\n    ] {\n        let mut request_inner = Request::default();\n        request_inner.set_cmd_type(write_cmd);\n        req.mut_requests().push(request_inner);\n        let res = router.query(region_id, req.clone()).unwrap();\n        let resp = res.read();\n        assert!(resp.is_none());\n        let error_resp = res.response().unwrap();\n        assert!(error_resp.get_header().has_error());\n        req.clear_requests();\n    }\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_snapshot_failed() {\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"rockskv_async_snapshot\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"snapshot failed\"));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date7() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"2004-01-16 12:00 +0000\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let expected = FileTime::from_unix_time(1_074_254_400, 0);\n\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, expected);\n    assert_eq!(mtime, expected);\n}"}
{"code": "pub fn call(&self, mut ctx: impl AsContextMut, params: Params) -> Result<Results, Trap> {\n        // Note: Cloning an [`Engine`] is intentionally a cheap operation.\n        ctx.as_context().store.engine().clone().execute_func(\n            ctx.as_context_mut(),\n            &self.func,\n            params,\n            <CallResultsTuple<Results>>::default(),\n        )\n    }", "test": "fn dynamic_type_check_works() {\n    let mut store = test_setup();\n    let identity = Func::wrap(&mut store, |value: i32| value);\n    let mut result = Value::I32(0);\n    // Case: Too few inputs given to function.\n    assert_matches!(\n        identity.call(&mut store, &[], core::slice::from_mut(&mut result)),\n        Err(Error::Func(FuncError::MismatchingParameterLen))\n    );\n    // Case: Too many inputs given to function.\n    assert_matches!(\n        identity.call(\n            &mut store,\n            &[Value::I32(0), Value::I32(1)],\n            core::slice::from_mut(&mut result)\n        ),\n        Err(Error::Func(FuncError::MismatchingParameterLen))\n    );\n    // Case: Too few outputs given to function.\n    assert_matches!(\n        identity.call(&mut store, &[Value::I32(0)], &mut [],),\n        Err(Error::Func(FuncError::MismatchingResultLen))\n    );\n    // Case: Too many outputs given to function.\n    assert_matches!(\n        identity.call(\n            &mut store,\n            &[Value::I32(0)],\n            &mut [Value::I32(0), Value::I32(1)],\n        ),\n        Err(Error::Func(FuncError::MismatchingResultLen))\n    );\n    // Case: Mismatching type given as input to function.\n    for input in &[\n        Value::I64(0),\n        Value::F32(0.0.into()),\n        Value::F64(0.0.into()),\n    ] {\n        assert_matches!(\n            identity.call(\n                &mut store,\n                core::slice::from_ref(input),\n                core::slice::from_mut(&mut result)\n            ),\n            Err(Error::Func(FuncError::MismatchingParameterType))\n        );\n    }\n    // Case: Allow for incorrect result type.\n    //\n    // The result type will be overwritten anyways.\n    assert_matches!(\n        identity.call(&mut store, &[Value::I32(0)], &mut [Value::I64(0)]),\n        Ok(_)\n    );\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u8_pow10_test() {\n    let values: &[u8] = &[0, 1, 5, 9, 10, 11, 15, 99, 100, 101, 105];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn preview2_stdin() -> Result<()> {\n    let test = \"tests/all/cli_tests/count-stdin.wat\";\n    let cmd = || -> Result<_> {\n        let mut cmd = get_wasmtime_command()?;\n        cmd.arg(\"--invoke=count\").arg(\"-Spreview2\").arg(test);\n        Ok(cmd)\n    };\n\n    // read empty pipe is ok\n    let output = cmd()?.output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"0\\n\");\n\n    // read itself is ok\n    let file = File::open(test)?;\n    let size = file.metadata()?.len();\n    let output = cmd()?.stdin(File::open(test)?).output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), format!(\"{size}\\n\"));\n\n    // read piped input ok is ok\n    let mut child = cmd()?\n        .stdin(Stdio::piped())\n        .stdout(Stdio::piped())\n        .stderr(Stdio::piped())\n        .spawn()?;\n    let mut stdin = child.stdin.take().unwrap();\n    std::thread::spawn(move || {\n        stdin.write_all(b\"hello\").unwrap();\n    });\n    let output = child.wait_with_output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"5\\n\");\n\n    let count_up_to = |n: usize| -> Result<_> {\n        let mut child = get_wasmtime_command()?\n            .arg(\"--invoke=count-up-to\")\n            .arg(\"-Spreview2\")\n            .arg(test)\n            .arg(n.to_string())\n            .stdin(Stdio::piped())\n            .stdout(Stdio::piped())\n            .stderr(Stdio::piped())\n            .spawn()?;\n        let mut stdin = child.stdin.take().unwrap();\n        let t = std::thread::spawn(move || {\n            let mut written = 0;\n            let bytes = [0; 64 * 1024];\n            loop {\n                written += match stdin.write(&bytes) {\n                    Ok(n) => n,\n                    Err(_) => break written,\n                };\n            }\n        });\n        let output = child.wait_with_output()?;\n        assert!(output.status.success());\n        let written = t.join().unwrap();\n        let read = String::from_utf8_lossy(&output.stdout)\n            .trim()\n            .parse::<usize>()\n            .unwrap();\n        // The test reads in 1000 byte chunks so make sure that it doesn't read\n        // more than 1000 bytes than requested.\n        assert!(read < n + 1000, \"test read too much {read}\");\n        Ok(written)\n    };\n\n    // wasmtime shouldn't eat information that the guest never actually tried to\n    // read.\n    //\n    // NB: this may be a bit flaky. Exactly how much we wrote in the above\n    // helper thread depends on how much the OS buffers for us. For now give\n    // some some slop and assume that OSes are unlikely to buffer more than\n    // that.\n    let slop = 256 * 1024;\n    for amt in [0, 100, 100_000] {\n        let written = count_up_to(amt)?;\n        assert!(written < slop + amt, \"wrote too much {written}\");\n    }\n    Ok(())\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_batch_raft_fallback() {\n    let msg_count = Arc::new(AtomicUsize::new(0));\n    let batch_msg_count = Arc::new(AtomicUsize::new(0));\n    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), false);\n    let (mock_server, port) = create_mock_server(service, 60000, 60100).unwrap();\n\n    let mut raft_client = get_raft_client_by_port(port);\n    (0..100).for_each(|_| {\n        raft_client.send(RaftMessage::default()).unwrap();\n        thread::sleep(time::Duration::from_millis(10));\n        raft_client.flush();\n    });\n\n    assert!(msg_count.load(Ordering::SeqCst) > 0);\n    assert_eq!(batch_msg_count.load(Ordering::SeqCst), 0);\n    drop(mock_server)\n}"}
{"code": "fn read_original(source: &str) -> String {\n    source.to_string().replace(\"\\r\\n\", \"\\n\")\n}", "test": "fn test_sequence_ex2() {\n    let file = include_str!(\"preserve_sequence_ex2.ron\");\n    assert_eq!(read_original(file), make_roundtrip(file));\n}"}
{"code": "pub fn as_str(&self) -> &str {\n        match self.0 {\n            Options => \"OPTIONS\",\n            Get => \"GET\",\n            Post => \"POST\",\n            Put => \"PUT\",\n            Delete => \"DELETE\",\n            Head => \"HEAD\",\n            Trace => \"TRACE\",\n            Connect => \"CONNECT\",\n            Patch => \"PATCH\",\n            ExtensionInline(ref inline) => inline.as_str(),\n            ExtensionAllocated(ref allocated) => allocated.as_str(),\n        }\n    }", "test": "fn drain() {\n    let mut headers = HeaderMap::new();\n\n    // Insert a single value\n    let name: HeaderName = \"hello\".parse().unwrap();\n    headers.insert(name, \"world\".parse().unwrap());\n\n    {\n        let mut iter = headers.drain();\n        let (name, value) = iter.next().unwrap();\n        assert_eq!(name.unwrap().as_str(), \"hello\");\n\n        assert_eq!(value, \"world\");\n\n        assert!(iter.next().is_none());\n    }\n\n    assert!(headers.is_empty());\n\n    // Insert two sequential values\n    headers.insert(\n        \"hello\".parse::<HeaderName>().unwrap(),\n        \"world\".parse().unwrap(),\n    );\n    headers.insert(\n        \"zomg\".parse::<HeaderName>().unwrap(),\n        \"bar\".parse().unwrap(),\n    );\n    headers.append(\n        \"hello\".parse::<HeaderName>().unwrap(),\n        \"world2\".parse().unwrap(),\n    );\n\n    // Drain...\n    {\n        let mut iter = headers.drain();\n\n        let (name, value) = iter.next().unwrap();\n        assert_eq!(name.unwrap().as_str(), \"hello\");\n        assert_eq!(value, \"world\");\n\n        let (name, value) = iter.next().unwrap();\n        assert_eq!(name, None);\n        assert_eq!(value, \"world2\");\n\n        let (name, value) = iter.next().unwrap();\n        assert_eq!(name.unwrap().as_str(), \"zomg\");\n        assert_eq!(value, \"bar\");\n\n        assert!(iter.next().is_none());\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_short_overwrite() {\n    // same as --update=older\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_none_file1\";\n    let new = \"test_mv_arg_update_none_file2\";\n    let old_content = \"file1 content\\n\";\n    let new_content = \"file2 content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(new)\n        .arg(old)\n        .arg(\"-u\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(old), new_content);\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_multiple_of_input_chunk() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"multiple_of_input_chunk\";\n    RandomFile::new(&at, name).add_bytes(16 * 1024);\n    ucmd.args(&[\"-b\", \"8K\", name, \"b\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"b[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 2);\n    for filename in glob.collect() {\n        assert_eq!(glob.directory.metadata(&filename).len(), 8 * 1024);\n    }\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_replica_read() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure the peer_on_store3 has completed applied to witness\n    std::thread::sleep(Duration::from_millis(200));\n\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cmd(b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(peer_on_store3);\n    request.mut_header().set_replica_read(true);\n\n    let resp = cluster\n        .read(None, request, Duration::from_millis(100))\n        .unwrap();\n    assert_eq!(\n        resp.get_header().get_error().get_is_witness(),\n        &kvproto::errorpb::IsWitness {\n            region_id: region.get_id(),\n            ..Default::default()\n        }\n    );\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_ignore_nonempty_no_permissions() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    // We make the *parent* dir read-only to prevent deleting the dir in it.\n    at.mkdir_all(\"dir/ect/ory\");\n    at.touch(\"dir/ect/ory/file\");\n    at.set_mode(\"dir/ect\", 0o555);\n\n    // rmdir should now get a permissions error that it interprets as\n    // a non-empty error.\n    ucmd.arg(\"--ignore-fail-on-non-empty\")\n        .arg(\"dir/ect/ory\")\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(\"dir/ect/ory\"));\n\n    // Politely restore permissions for cleanup\n    at.set_mode(\"dir/ect\", 0o755);\n}"}
{"code": "pub fn stdout(&self) -> &[u8] {\n        &self.stdout\n    }", "test": "fn test_negative_indexing() {\n    let positive_lines_index = new_ucmd!().arg(\"-n\").arg(\"5\").arg(FOOBAR_TXT).run();\n\n    let negative_lines_index = new_ucmd!().arg(\"-n\").arg(\"-5\").arg(FOOBAR_TXT).run();\n\n    let positive_bytes_index = new_ucmd!().arg(\"-c\").arg(\"20\").arg(FOOBAR_TXT).run();\n\n    let negative_bytes_index = new_ucmd!().arg(\"-c\").arg(\"-20\").arg(FOOBAR_TXT).run();\n\n    assert_eq!(positive_lines_index.stdout(), negative_lines_index.stdout());\n    assert_eq!(positive_bytes_index.stdout(), negative_bytes_index.stdout());\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_repeat() {\n    let repeat_limit = 15000;\n    let input_seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    let input = input_seq\n        .iter()\n        .map(ToString::to_string)\n        .collect::<Vec<String>>()\n        .join(\"\\n\");\n\n    let result = new_ucmd!()\n        .arg(\"-r\")\n        .args(&[\"-n\", &repeat_limit.to_string()])\n        .pipe_in(input.as_bytes())\n        .succeeds();\n    result.no_stderr();\n\n    let result_seq: Vec<i32> = result\n        .stdout_str()\n        .split('\\n')\n        .filter(|x| !x.is_empty())\n        .map(|x| x.parse().unwrap())\n        .collect();\n    assert_eq!(\n        result_seq.len(),\n        repeat_limit,\n        \"Output is not repeating forever\"\n    );\n    assert!(\n        result_seq.iter().all(|x| input_seq.contains(x)),\n        \"Output includes element not from input: {:?}\",\n        result_seq\n            .iter()\n            .filter(|x| !input_seq.contains(x))\n            .collect::<Vec<&i32>>()\n    );\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn persistent_savepoint() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let definition: TableDefinition<u32, &str> = TableDefinition::new(\"x\");\n\n    let txn = db.begin_write().unwrap();\n    {\n        let mut table = txn.open_table(definition).unwrap();\n        table.insert(&0, \"hello\").unwrap();\n    }\n    txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    let savepoint_id = txn.persistent_savepoint().unwrap();\n    {\n        let mut table = txn.open_table(definition).unwrap();\n        table.remove(&0).unwrap();\n    }\n    txn.commit().unwrap();\n\n    drop(db);\n    let db = Database::create(tmpfile.path()).unwrap();\n    // Make sure running the GC doesn't invalidate the savepoint\n    let txn = db.begin_write().unwrap();\n    txn.commit().unwrap();\n    let txn = db.begin_write().unwrap();\n    txn.commit().unwrap();\n\n    let mut txn = db.begin_write().unwrap();\n    let savepoint = txn.get_persistent_savepoint(savepoint_id).unwrap();\n\n    txn.restore_savepoint(&savepoint).unwrap();\n    txn.commit().unwrap();\n\n    let txn = db.begin_read().unwrap();\n    let table = txn.open_table(definition).unwrap();\n    assert_eq!(table.get(&0).unwrap().unwrap().value(), \"hello\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_auto_promote_learner() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    // replace one peer with learner\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store0.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[0], peer_on_store0.get_id()),\n    );\n    // Sleep 100 ms to wait for the new learner to be initialized.\n    sleep_ms(100);\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut demoted = true;\n    let mut promoted = false;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n        promoted = region\n            .get_peers()\n            .iter()\n            .find(|peer| peer.get_store_id() == nodes[0])\n            .unwrap()\n            .get_role()\n            == metapb::PeerRole::Voter;\n\n        demoted = region\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        if demoted && promoted {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert!(demoted);\n    assert!(promoted);\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.senders.is_empty()\n    }", "test": "fn key_update_reordered() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Bi)\n        .expect(\"couldn't open first stream\");\n\n    const MSG1: &[u8] = b\"1\";\n    pair.client_send(client_ch, s).write(MSG1).unwrap();\n    pair.client.drive(pair.time, pair.server.addr);\n    assert!(!pair.client.outbound.is_empty());\n    pair.client.delay_outbound();\n\n    pair.client_conn_mut(client_ch).initiate_key_update();\n    info!(\"updated keys\");\n\n    const MSG2: &[u8] = b\"two\";\n    pair.client_send(client_ch, s).write(MSG2).unwrap();\n    pair.client.drive(pair.time, pair.server.addr);\n    pair.client.finish_delay();\n    pair.drive();\n\n    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(true).unwrap();\n    let buf1 = chunks.next(usize::MAX).unwrap().unwrap();\n    assert_matches!(&*buf1.bytes, MSG1);\n    let buf2 = chunks.next(usize::MAX).unwrap().unwrap();\n    assert_eq!(buf2.bytes, MSG2);\n    let _ = chunks.finalize();\n\n    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);\n    assert_eq!(pair.server_conn_mut(server_ch).lost_packets(), 0);\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_t() {\n    // Test iterators that skip single, trailing-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_trailing_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"_45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"__45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"__45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"__45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"_4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"__4__5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"_4_5.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"__4__5_.56\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_ymdhm_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_ymdhm_time\";\n\n    ucmd.args(&[\"-t\", \"1501011234\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_existing() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=existing\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_within_combined_shorts_tailing_suffix_length() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"obs-lines-combined-shorts-tailing-suffix-length\";\n    RandomFile::new(&at, name).add_lines(1000);\n    ucmd.args(&[\"-d200a4\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x\\d\\d\\d\\d$\");\n    assert_eq!(glob.count(), 5);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_switching_replication_mode() {\n    let mut cluster = prepare_cluster();\n    run_cluster(&mut cluster);\n    let region = cluster.get_region(b\"k1\");\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k2\", b\"v2\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    must_get_none(&cluster.get_engine(1), b\"k2\");\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::Async, vec![]);\n    rx.recv_timeout(Duration::from_millis(100)).unwrap();\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 2);\n    assert_eq!(state.state, RegionReplicationState::SimpleMajority);\n\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::SyncRecover, vec![]);\n    thread::sleep(Duration::from_millis(100));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k3\", b\"v3\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    // sync recover should not block write. ref https://github.com/tikv/tikv/issues/14975.\n    assert_eq!(rx.recv_timeout(Duration::from_millis(100)).is_ok(), true);\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 3);\n    assert_eq!(state.state, RegionReplicationState::SimpleMajority);\n\n    cluster.clear_send_filters();\n    must_get_equal(&cluster.get_engine(1), b\"k3\", b\"v3\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 3);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k4\", b\"v4\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    // already enable group commit.\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_decimal_point_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.decimal_point(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.decimal_point(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.decimal_point(b',');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"code": "fn is_none(&self) -> bool {\n        false\n    }", "test": "fn test_detect_deadlock_when_updating_wait_info() {\n    use kvproto::kvrpcpb::PessimisticLockKeyResultType::*;\n    let mut cluster = new_cluster_for_deadlock_test(3);\n\n    let key1 = b\"key1\";\n    let key2 = b\"key2\";\n    let (client, ctx) = build_leader_client(&mut cluster, key1);\n    let client = Arc::new(client);\n\n    fn async_pessimistic_lock(\n        client: Arc<TikvClient>,\n        ctx: Context,\n        key: &[u8],\n        ts: u64,\n    ) -> mpsc::Receiver<PessimisticLockResponse> {\n        let (tx, rx) = mpsc::channel();\n        let key = vec![key.to_vec()];\n        thread::spawn(move || {\n            let resp =\n                kv_pessimistic_lock_resumable(&client, ctx, key, ts, ts, Some(1000), false, false);\n            tx.send(resp).unwrap();\n        });\n        rx\n    }\n\n    // key1: txn 11 and 12 waits for 10\n    // key2: txn 11 waits for 12\n    let resp = kv_pessimistic_lock_resumable(\n        &client,\n        ctx.clone(),\n        vec![key1.to_vec()],\n        10,\n        10,\n        Some(1000),\n        false,\n        false,\n    );\n    assert!(resp.region_error.is_none());\n    assert!(resp.errors.is_empty());\n    assert_eq!(resp.results[0].get_type(), LockResultNormal);\n    let resp = kv_pessimistic_lock_resumable(\n        &client,\n        ctx.clone(),\n        vec![key2.to_vec()],\n        12,\n        12,\n        Some(1000),\n        false,\n        false,\n    );\n    assert!(resp.region_error.is_none());\n    assert!(resp.errors.is_empty());\n    assert_eq!(resp.results[0].get_type(), LockResultNormal);\n    let rx_txn11_k1 = async_pessimistic_lock(client.clone(), ctx.clone(), key1, 11);\n    let rx_txn12_k1 = async_pessimistic_lock(client.clone(), ctx.clone(), key1, 12);\n    let rx_txn11_k2 = async_pessimistic_lock(client.clone(), ctx.clone(), key2, 11);\n    // All blocked.\n    assert_eq!(\n        rx_txn11_k1\n            .recv_timeout(Duration::from_millis(50))\n            .unwrap_err(),\n        RecvTimeoutError::Timeout\n    );\n    assert_eq!(rx_txn12_k1.try_recv().unwrap_err(), TryRecvError::Empty);\n    assert_eq!(rx_txn11_k2.try_recv().unwrap_err(), TryRecvError::Empty);\n\n    // Release lock at ts=10 on key1 so that txn 11 will be granted the lock.\n    must_kv_pessimistic_rollback(&client, ctx.clone(), key1.to_vec(), 10, 10);\n    let resp = rx_txn11_k1\n        .recv_timeout(Duration::from_millis(200))\n        .unwrap();\n    assert!(resp.region_error.is_none());\n    assert!(resp.errors.is_empty());\n    assert_eq!(resp.results[0].get_type(), LockResultNormal);\n    // And then 12 waits for k1 on key1, which forms a deadlock.\n    let resp = rx_txn12_k1\n        .recv_timeout(Duration::from_millis(1000))\n        .unwrap();\n    assert!(resp.region_error.is_none());\n    assert!(resp.errors[0].has_deadlock());\n    assert_eq!(resp.results[0].get_type(), LockResultFailed);\n    // Check correctness of the wait chain.\n    let wait_chain = resp.errors[0].get_deadlock().get_wait_chain();\n    assert_eq!(wait_chain[0].get_txn(), 11);\n    assert_eq!(wait_chain[0].get_wait_for_txn(), 12);\n    assert_eq!(wait_chain[0].get_key(), key2);\n    assert_eq!(wait_chain[1].get_txn(), 12);\n    assert_eq!(wait_chain[1].get_wait_for_txn(), 11);\n    assert_eq!(wait_chain[1].get_key(), key1);\n\n    // Clean up.\n    must_kv_pessimistic_rollback(&client, ctx.clone(), key1.to_vec(), 11, 11);\n    must_kv_pessimistic_rollback(&client, ctx.clone(), key2.to_vec(), 12, 12);\n    let resp = rx_txn11_k2\n        .recv_timeout(Duration::from_millis(500))\n        .unwrap();\n    assert!(resp.region_error.is_none());\n    assert!(resp.errors.is_empty());\n    assert_eq!(resp.results[0].get_type(), LockResultNormal);\n    must_kv_pessimistic_rollback(&client, ctx, key2.to_vec(), 11, 11);\n}"}
{"code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_when_warmup_fail_and_its_timeout_is_too_long() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.max_entry_cache_warmup_duration = ReadableDuration::secs(1000);\n    prevent_from_gc_raft_log(&mut cluster);\n    run_cluster_for_test_warmup_entry_cache(&mut cluster);\n\n    fail::cfg(\"worker_async_fetch_raft_log\", \"pause\").unwrap();\n    cluster.transfer_leader(1, new_peer(2, 2));\n    // Theoretically, the leader transfer can't succeed unless it sleeps\n    // max_entry_cache_warmup_duration.\n    sleep_ms(50);\n    let leader = cluster.leader_of_region(1).unwrap();\n    assert_eq!(leader.get_id(), 1);\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_datagram() {\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n    let tcp_message = message(query.clone(), vec![tcp_record], vec![], vec![]);\n    let udp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        Default::default(),\n    );\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver],\n        vec![tcp_nameserver],\n        None,\n        Default::default(),\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_delete_lock_proposed_before_proposing_locks() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_heartbeat_ticks = 20;\n    cluster.run();\n\n    let region_id = 1;\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let leader = cluster.leader_of_region(region_id).unwrap();\n\n    let snapshot = cluster.must_get_snapshot_of_region(region_id);\n    let txn_ext = snapshot.txn_ext.unwrap();\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(\n            Key::from_raw(b\"key\"),\n            PessimisticLock {\n                primary: b\"key\".to_vec().into_boxed_slice(),\n                start_ts: 10.into(),\n                ttl: 1000,\n                for_update_ts: 10.into(),\n                min_commit_ts: 20.into(),\n                last_change_ts: 5.into(),\n                versions_to_last_change: 3,\n            },\n        )])\n        .unwrap();\n\n    let addr = cluster.sim.rl().get_addr(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env).connect(&addr);\n    let client = TikvClient::new(channel);\n\n    let mut req = CleanupRequest::default();\n    let mut ctx = Context::default();\n    ctx.set_region_id(region_id);\n    ctx.set_region_epoch(cluster.get_region_epoch(region_id));\n    ctx.set_peer(leader);\n    req.set_context(ctx);\n    req.set_key(b\"key\".to_vec());\n    req.set_start_version(10);\n    req.set_current_ts(u64::MAX);\n\n    // Pause the command before it actually removes locks.\n    fail::cfg(\"scheduler_async_write_finish\", \"pause\").unwrap();\n    let (tx, resp_rx) = mpsc::channel();\n    thread::spawn(move || tx.send(client.kv_cleanup(&req).unwrap()).unwrap());\n\n    thread::sleep(Duration::from_millis(200));\n    resp_rx.try_recv().unwrap_err();\n\n    cluster.transfer_leader(1, new_peer(2, 2));\n    thread::sleep(Duration::from_millis(200));\n\n    // Transfer leader will not make the command fail.\n    fail::remove(\"scheduler_async_write_finish\");\n    let resp = resp_rx.recv().unwrap();\n    assert!(!resp.has_region_error());\n\n    for _ in 0..10 {\n        thread::sleep(Duration::from_millis(100));\n        cluster.reset_leader_of_region(region_id);\n        if cluster.leader_of_region(region_id).unwrap().id == 2 {\n            let snapshot = cluster.must_get_snapshot_of_region(1);\n            assert!(\n                snapshot\n                    .get_cf(CF_LOCK, &Key::from_raw(b\"key\"))\n                    .unwrap()\n                    .is_none()\n            );\n            return;\n        }\n    }\n    panic!(\"region should succeed to transfer leader to peer 2\");\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_none() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file1 = \"test_mv_arg_update_none_file1\";\n    let file2 = \"test_mv_arg_update_none_file2\";\n    let file1_content = \"file1 content\\n\";\n    let file2_content = \"file2 content\\n\";\n\n    at.write(file1, file1_content);\n    at.write(file2, file2_content);\n\n    ucmd.arg(file1)\n        .arg(file2)\n        .arg(\"--update=none\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(file2), file2_content);\n}"}
{"code": "pub fn leader_of_region(&mut self, region_id: u64) -> Option<metapb::Peer> {\n        let timer = Instant::now_coarse();\n        let timeout = Duration::from_secs(5);\n        let mut store_ids = None;\n        while timer.saturating_elapsed() < timeout {\n            match self.voter_store_ids_of_region(region_id) {\n                None => thread::sleep(Duration::from_millis(10)),\n                Some(ids) => {\n                    store_ids = Some(ids);\n                    break;\n                }\n            }\n        }\n        let store_ids = store_ids?;\n        if let Some(l) = self.leaders.get(&region_id) {\n            // leader may be stopped in some tests.\n            if self.valid_leader_id(region_id, l.get_store_id()) {\n                return Some(l.clone());\n            }\n        }\n        self.reset_leader_of_region(region_id);\n        let mut leader = None;\n        let mut leaders = HashMap::default();\n\n        let node_ids = self.sim.rl().get_node_ids();\n        // For some tests, we stop the node but pd still has this information,\n        // and we must skip this.\n        let alive_store_ids: Vec<_> = store_ids\n            .iter()\n            .filter(|id| node_ids.contains(id))\n            .cloned()\n            .collect();\n        while timer.saturating_elapsed() < timeout {\n            for store_id in &alive_store_ids {\n                let l = match self.query_leader(*store_id, region_id, Duration::from_secs(1)) {\n                    None => continue,\n                    Some(l) => l,\n                };\n                leaders\n                    .entry(l.get_id())\n                    .or_insert((l, vec![]))\n                    .1\n                    .push(*store_id);\n            }\n            if let Some((_, (l, c))) = leaders.iter().max_by_key(|(_, (_, c))| c.len()) {\n                if c.contains(&l.get_store_id()) {\n                    leader = Some(l.clone());\n                    // Technically, correct calculation should use two quorum when in joint\n                    // state. Here just for simplicity.\n                    if c.len() > store_ids.len() / 2 {\n                        break;\n                    }\n                }\n            }\n            debug!(\"failed to detect leaders\"; \"leaders\" => ?leaders, \"store_ids\" => ?store_ids);\n            sleep_ms(10);\n            leaders.clear();\n        }\n\n        if let Some(l) = leader {\n            self.leaders.insert(region_id, l);\n        }\n\n        self.leaders.get(&region_id).cloned()\n    }", "test": "fn test_leader_drop_with_pessimistic_lock() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    let txn_ext = cluster\n        .must_get_snapshot_of_region(1)\n        .ext()\n        .get_txn_ext()\n        .unwrap()\n        .clone();\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(\n            Key::from_raw(b\"k1\"),\n            PessimisticLock {\n                primary: b\"k1\".to_vec().into_boxed_slice(),\n                start_ts: 10.into(),\n                ttl: 1000,\n                for_update_ts: 10.into(),\n                min_commit_ts: 10.into(),\n                last_change_ts: 5.into(),\n                versions_to_last_change: 3,\n            },\n        )])\n        .unwrap();\n\n    // Isolate node 1, leader should be transferred to another node.\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    assert_ne!(cluster.leader_of_region(1).unwrap().id, 1);\n\n    // When peer 1 becomes leader again, the pessimistic locks should be cleared\n    // before.\n    cluster.clear_send_filters();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    assert!(txn_ext.pessimistic_locks.read().is_empty());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn cf_names() {\n    let db = engine_cfs(ALL_CFS);\n    let names = db.engine.cf_names();\n    assert_eq!(names.len(), ALL_CFS.len());\n    for cf in ALL_CFS {\n        assert!(names.contains(cf));\n    }\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn iter() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            for j in 0..10 {\n                table.insert(&i, &j).unwrap();\n            }\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(U64_TABLE).unwrap();\n    let mut iter = table.iter().unwrap();\n    for i in 0..10 {\n        let (k, mut values) = iter.next().unwrap().unwrap();\n        assert_eq!(k.value(), i);\n        for j in 0..10 {\n            assert_eq!(values.next().unwrap().unwrap().value(), j);\n        }\n    }\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_concurrent_requests_more_than_conns() {\n    let mut options = ResolverOpts::default();\n\n    // there are only two conns, but this requests 3 concurrent requests, only 2 called\n    options.num_concurrent_reqs = 3;\n\n    // we want to make sure that both udp connections are called\n    //   this will count down to 0 only if both are called.\n    let on_send = OnSendBarrier::new(2);\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n\n    let udp1_nameserver = mock_nameserver_on_send(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        options.clone(),\n        on_send.clone(),\n    );\n    let udp2_nameserver = mock_nameserver_on_send(vec![], options.clone(), on_send);\n\n    let pool = mock_nameserver_pool_on_send(\n        vec![udp2_nameserver, udp1_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    // there's no actual network traffic happening, 1 sec should be plenty\n    //   TODO: for some reason this timeout doesn't work, not clear why...\n    // let future = Timeout::new(future, Duration::from_secs(1));\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"code": "pub fn as_str(&self) -> &str {\n        &self.0.regex_strings()[0]\n    }", "test": "fn regex_string() {\n    assert_eq!(r\"[a-zA-Z0-9]+\", regex!(r\"[a-zA-Z0-9]+\").as_str());\n    assert_eq!(r\"[a-zA-Z0-9]+\", &format!(\"{}\", regex!(r\"[a-zA-Z0-9]+\")));\n    assert_eq!(r\"[a-zA-Z0-9]+\", &format!(\"{:?}\", regex!(r\"[a-zA-Z0-9]+\")));\n}"}
{"code": "fn write(&mut self, bytes: &[u8]) -> io::Result<usize> {\n        self.tls_conn.writer().write(bytes)\n    }", "test": "fn client_respects_buffer_limit_post_handshake() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n\n    do_handshake(&mut client, &mut server);\n    client.set_buffer_limit(Some(48));\n\n    assert_eq!(\n        client\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        20\n    );\n    assert_eq!(\n        client\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        6\n    );\n\n    transfer(&mut client, &mut server);\n    server.process_new_packets().unwrap();\n\n    check_read(&mut server.reader(), b\"01234567890123456789012345\");\n}"}
{"code": "pub fn is_nan(&self) -> bool {\n        match self.n {\n            N::PosInt(_) | N::NegInt(_) => false,\n            N::Float(f) => f.is_nan(),\n        }\n    }", "test": "fn test_float() {\n    let thing = 25.6;\n    let yaml = indoc! {\"\n        25.6\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = 25.;\n    let yaml = indoc! {\"\n        25.0\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f64::INFINITY;\n    let yaml = indoc! {\"\n        .inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let thing = f64::NEG_INFINITY;\n    let yaml = indoc! {\"\n        -.inf\n    \"};\n    test_serde(&thing, yaml);\n\n    let float: f64 = serde_yaml::from_str(indoc! {\"\n        .nan\n    \"})\n    .unwrap();\n    assert!(float.is_nan());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn parse_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), PARSE_ERROR.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"parse_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn compute_float64(q: i64, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        is_negative: false,\n        many_digits: false,\n        integer: &[],\n        fraction: None,\n    };\n    let fp = bellerophon::<f64, { STANDARD }>(&num, false);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f64_rounding() {\n    // Also need to check halfway cases **inside** that exponent range.\n\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740993), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));\n    assert_eq!(compute_float64(0, 9007199254740995), (1076, 2));\n    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));\n    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));\n    assert_eq!(compute_float64(0, 18014398509481986), (1077, 0));\n    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));\n    assert_eq!(compute_float64(0, 18014398509481990), (1077, 2));\n    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));\n\n    // Test a much closer set of examples.\n    assert_eq!(compute_float64(0, 9007199254740991), (1075, 4503599627370495));\n    assert_eq!(compute_float64(0, 9223372036854776831), (1086, 0));\n    assert_eq!(compute_float64(0, 9223372036854776832), (1086, 0));\n    assert_eq!(compute_float64(0, 9223372036854776833), (1086, 1));\n    assert_eq!(compute_float64(-42, 9123456727292927), (936, 1854521741541368));\n    assert_eq!(compute_float64(-43, 91234567272929275), (936, 1854521741541369));\n    assert_eq!(compute_float64(-42, 9123456727292928), (936, 1854521741541369));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));\n    assert_eq!(compute_float64(-3, 9007199254740993000), (1076, 0));\n    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));\n    assert_eq!(compute_float64(-3, 9007199254740995000), (1076, 2));\n    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_config_ok_linter_not_formatter() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"format.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"format.json\");\n    fs.insert(format.into(), r#\"{ \"formatter\": { \"enabled\": true } }\"#);\n    let lint = Path::new(\"linter.json\");\n    fs.insert(\n        lint.into(),\n        r#\"{\n  \"linter\": {\n    \"rules\": {\n      \"all\": false,\n      \"suspicious\": {\n        \"noDebugger\": \"warn\"\n      }\n    }\n  }\n}\n        \"#,\n    );\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), test_file.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_config_ok_linter_not_formatter\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn errors_if_recv_frame_exceeds_max_frame_size() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let h2 = async move {\n        let (mut client, h2) = client::handshake(io).await.unwrap();\n        let req = async move {\n            let resp = client.get(\"https://example.com/\").await.expect(\"response\");\n            assert_eq!(resp.status(), StatusCode::OK);\n            let body = resp.into_parts().1;\n            let res = util::concat(body).await;\n            let err = res.unwrap_err();\n            assert_eq!(\n                err.to_string(),\n                \"connection error detected: frame with invalid size\"\n            );\n        };\n\n        // client should see a conn error\n        let conn = async move {\n            let err = h2.await.unwrap_err();\n            assert_eq!(\n                err.to_string(),\n                \"connection error detected: frame with invalid size\"\n            );\n        };\n        join(conn, req).await;\n    };\n\n    // a bad peer\n    srv.codec_mut().set_max_send_frame_size(16_384 * 4);\n\n    let srv = async move {\n        let _ = srv.assert_client_handshake().await;\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://example.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.send_frame(frames::data(1, vec![0; 16_385]).eos()).await;\n        srv.recv_frame(frames::go_away(0).frame_size()).await;\n    };\n\n    join(srv, h2).await;\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn funcs_live_on_to_fight_another_day() -> Result<()> {\n    struct DropMe(Arc<AtomicUsize>);\n\n    impl Drop for DropMe {\n        fn drop(&mut self) {\n            self.0.fetch_add(1, SeqCst);\n        }\n    }\n\n    let flag = Arc::new(AtomicUsize::new(0));\n    let engine = Engine::default();\n    let mut linker = Linker::new(&engine);\n    let drop_me = DropMe(flag.clone());\n    linker.func_wrap(\"\", \"\", move || {\n        let _ = &drop_me;\n    })?;\n    assert_eq!(flag.load(SeqCst), 0);\n\n    let get_and_call = || -> Result<()> {\n        assert_eq!(flag.load(SeqCst), 0);\n        let mut store = Store::new(&engine, ());\n        let func = linker.get(&mut store, \"\", \"\").unwrap();\n        func.into_func().unwrap().call(&mut store, &[], &mut [])?;\n        assert_eq!(flag.load(SeqCst), 0);\n        Ok(())\n    };\n\n    get_and_call()?;\n    get_and_call()?;\n    drop(linker);\n    assert_eq!(flag.load(SeqCst), 1);\n    Ok(())\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn call_signature_mismatch() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let binary = wat::parse_str(\n        r#\"\n            (module $a\n                (func $foo\n                    i32.const 0\n                    call_indirect)\n                (func $bar (param i32))\n                (start $foo)\n\n                (table 1 anyfunc)\n                (elem (i32.const 0) 1)\n            )\n        \"#,\n    )?;\n\n    let module = Module::new(store.engine(), &binary)?;\n    let err = Instance::new(&mut store, &module, &[])\n        .err()\n        .unwrap()\n        .downcast::<Trap>()\n        .unwrap();\n    assert!(err\n        .to_string()\n        .contains(\"wasm trap: indirect call type mismatch\"));\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_off() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=off\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(!at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub(crate) fn lower_n_mask(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n <= bits, \"lower_n_mask() overflow in shl.\");\n\n    if n == bits {\n        u64::max_value()\n    } else {\n        (1 << n) - 1\n    }\n}", "test": "fn lower_n_mask_test() {\n    assert_eq!(lower_n_mask(0u64), 0b0);\n    assert_eq!(lower_n_mask(1u64), 0b1);\n    assert_eq!(lower_n_mask(2u64), 0b11);\n    assert_eq!(lower_n_mask(10u64), 0b1111111111);\n    assert_eq!(lower_n_mask(32u64), 0b11111111111111111111111111111111);\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_standalone() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"obs-lines-standalone\";\n    RandomFile::new(&at, name).add_lines(4);\n    ucmd.args(&[\"-2\", name]).succeeds().no_stderr().no_stdout();\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_chroot_extra_arg() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    let dir = \"CHROOT_DIR\";\n    at.mkdir(dir);\n    let env_cd = std::env::current_dir().unwrap();\n    // Verify that -P is pwd's and not chroot\n    if let Ok(result) = run_ucmd_as_root(&ts, &[dir, \"pwd\", \"-P\"]) {\n        assert_eq!(\n            result.success().no_stderr().stdout_str(),\n            env_cd.to_str().unwrap()\n        );\n    } else {\n        print!(\"Test skipped; requires root user\");\n    }\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn generic_signature_lifetimes() {\n    fn write_key_generic<K: RedbKey>(\n        table: TableDefinition<K, &[u8]>,\n        key: K::SelfType<'_>,\n        db: &Database,\n    ) {\n        let buf = [1, 2, 3];\n        let write_txn = db.begin_write().unwrap();\n        {\n            let mut table = write_txn.open_table(table).unwrap();\n            table.insert(key, buf.as_slice()).unwrap();\n        }\n        write_txn.commit().unwrap();\n    }\n\n    fn read_key_generic<K: RedbKey>(\n        table: TableDefinition<K, &[u8]>,\n        key: K::SelfType<'_>,\n        db: &Database,\n    ) {\n        let buf = [1, 2, 3];\n        let read_txn = db.begin_read().unwrap();\n        let table = read_txn.open_table(table).unwrap();\n        assert_eq!(table.get(key).unwrap().unwrap().value(), buf);\n    }\n\n    let tmpfile = create_tempfile();\n    let db = &Database::create(tmpfile.path()).unwrap();\n    {\n        let (table, key) = (TableDefinition::<&str, _>::new(\"&str\"), \"key\");\n        write_key_generic(table, key, db);\n        read_key_generic(table, key, db);\n    }\n    {\n        let (table, key) = (TableDefinition::<(), _>::new(\"()\"), ());\n        write_key_generic(table, key, db);\n        read_key_generic(table, key, db);\n    }\n}"}
{"code": "fn check(&mut self, ctx: &RpcContext<'_>) -> CheckResult {\n        match check_common_name(&self.allowed_cn, ctx) {\n            Ok(()) => CheckResult::Continue,\n            Err(reason) => CheckResult::Abort(RpcStatus::with_message(\n                RpcStatusCode::UNAUTHENTICATED,\n                format!(\n                    \"Common name check fail, reason: {}, cert_allowed_cn: {:?}\",\n                    reason, self.allowed_cn\n                ),\n            )),\n        }\n    }", "test": "fn test_serving_status() {\n    let mut cluster = new_server_cluster(0, 3);\n    // A round is 30 ticks, set inspect interval to 20ms, so one round is 0.3s.\n    cluster.cfg.raft_store.inspect_interval = ReadableDuration::millis(10);\n    cluster.run();\n\n    let service = cluster.sim.rl().health_services.get(&1).unwrap().clone();\n    let builder =\n        ServerBuilder::new(Arc::new(Environment::new(1))).register_service(create_health(service));\n    let mut server = builder.bind(\"127.0.0.1\", 0).build().unwrap();\n    server.start();\n\n    let (addr, port) = server.bind_addrs().next().unwrap();\n    let ch =\n        ChannelBuilder::new(Arc::new(Environment::new(1))).connect(&format!(\"{}:{}\", addr, port));\n    let client = HealthClient::new(ch);\n\n    let check = || {\n        let req = HealthCheckRequest {\n            service: \"\".to_string(),\n            ..Default::default()\n        };\n        let resp = client.check(&req).unwrap();\n        resp.status\n    };\n\n    thread::sleep(Duration::from_millis(500));\n    assert_eq!(check(), ServingStatus::Serving);\n\n    fail::cfg(\"pause_on_peer_collect_message\", \"pause\").unwrap();\n\n    thread::sleep(Duration::from_secs(1));\n    assert_eq!(check(), ServingStatus::ServiceUnknown);\n\n    fail::remove(\"pause_on_peer_collect_message\");\n\n    // It should recover within one round.\n    thread::sleep(Duration::from_millis(200));\n    assert_eq!(check(), ServingStatus::Serving);\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn delete() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n        table.insert(\"hello2\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    assert_eq!(table.len().unwrap(), 2);\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        assert_eq!(\"world\", table.remove(\"hello\").unwrap().unwrap().value());\n        assert!(table.remove(\"hello\").unwrap().is_none());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert!(table.get(\"hello\").unwrap().is_none());\n    assert_eq!(table.len().unwrap(), 1);\n}"}
{"code": "async fn status(Extension(index): Extension<Arc<Index>>) -> (StatusCode, &'static str) {\n    if index.is_unrecoverably_reorged() {\n      (\n        StatusCode::OK,\n        \"unrecoverable reorg detected, please rebuild the database.\",\n      )\n    } else {\n      (\n        StatusCode::OK,\n        StatusCode::OK.canonical_reason().unwrap_or_default(),\n      )\n    }\n  }", "test": "fn inscription_content() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  let (inscription, _) = inscribe(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  let response =\n    TestServer::spawn_with_args(&rpc_server, &[]).request(format!(\"/content/{inscription}\"));\n\n  assert_eq!(response.status(), StatusCode::OK);\n  assert_eq!(\n    response.headers().get(\"content-type\").unwrap(),\n    \"text/plain;charset=utf-8\"\n  );\n  assert_eq!(\n    response\n      .headers()\n      .get_all(\"content-security-policy\")\n      .into_iter()\n      .collect::<Vec<&http::HeaderValue>>(),\n    &[\n      \"default-src 'self' 'unsafe-eval' 'unsafe-inline' data: blob:\",\n      \"default-src *:*/content/ *:*/blockheight *:*/blockhash *:*/blockhash/ *:*/blocktime *:*/r/ 'unsafe-eval' 'unsafe-inline' data: blob:\",\n    ]\n  );\n  assert_eq!(response.bytes().unwrap(), \"FOO\");\n}"}
