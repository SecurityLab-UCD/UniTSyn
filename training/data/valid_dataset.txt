fn test_read_index_on_replica() {
    let count = 3;
    let mut cluster = new_server_cluster(0, count);
    cluster.run();

    let k1 = b"k1";
    let (k2, v2) = (b"k2", b"v2");

    // make sure leader has been elected.
    assert_eq!(cluster.must_get(k1), None);

    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let mut storage = cluster.sim.rl().storages[&leader.get_id()].clone();

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader.clone());
    let snap_ctx = SnapContext {
        pb_ctx: &ctx,
        ..Default::default()
    };

    // write some data
    let peers = region.get_peers();
    assert_none(snap_ctx, &mut storage, k2);
    must_put(&ctx, &storage, k2, v2);

    // read on follower
    let mut follower_peer = None;
    for p in peers {
        if p.get_id() != leader.get_id() {
            follower_peer = Some(p.clone());
            break;
        }
    }

    assert!(follower_peer.is_some());
    ctx.set_peer(follower_peer.as_ref().unwrap().clone());
    let resp = read_index_on_peer(
        &mut cluster,
        follower_peer.unwrap(),
        region.clone(),
        false,
        std::time::Duration::from_secs(5),
    );
    assert!(!resp.as_ref().unwrap().get_header().has_error());
    assert_ne!(
        resp.unwrap().get_responses()[0]
            .get_read_index()
            .get_read_index(),
        0
    );
}
fn test_sharp() {
    let sql = "SELECT #_of_values";
    let select = redshift().verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("#_of_values"))),
        select.projection[0]
    );
}
fn dont_see_stale_stack_walking_registers() -> Result<()> {
    let engine = Engine::default();

    let module = Module::new(
        &engine,
        r#"
            (module
                (import "" "host_start" (func $host_start))
                (import "" "host_get_trap" (func $host_get_trap))
                (export "get_trap" (func $host_get_trap))

                ;; We enter and exit Wasm, which saves registers in the
                ;; `VMRuntimeLimits`. Later, when we call a re-exported host
                ;; function, we should not accidentally reuse those saved
                ;; registers.
                (start $start)
                (func $start
                    (call $host_start)
                )
            )
        "#,
    )?;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);

    let host_start = Func::new(
        &mut store,
        FuncType::new([], []),
        |_caller, _args, _results| Ok(()),
    );
    linker.define(&store, "", "host_start", host_start)?;

    let host_get_trap = Func::new(
        &mut store,
        FuncType::new([], []),
        |_caller, _args, _results| Err(anyhow::anyhow!("trap!!!")),
    );
    linker.define(&store, "", "host_get_trap", host_get_trap)?;

    let instance = linker.instantiate(&mut store, &module)?;
    let get_trap = instance.get_func(&mut store, "get_trap").unwrap();

    let err = get_trap.call(&mut store, &[], &mut []).unwrap_err();
    assert!(err.to_string().contains("trap!!!"));

    Ok(())
}
fn test_install_creating_leading_dirs_with_multiple_sources_and_target_dir() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let source1 = "source_file_1";
    let source2 = "source_file_2";
    let target_dir = "missing_target_dir";

    at.touch(source1);
    at.touch(source2);

    // installing multiple files into a missing directory will fail, when -D is used w/o -t parameter
    scene
        .ucmd()
        .arg("-D")
        .arg(source1)
        .arg(source2)
        .arg(at.plus(target_dir))
        .fails()
        .stderr_contains("missing_target_dir' is not a directory");

    assert!(!at.dir_exists(target_dir));

    scene
        .ucmd()
        .arg("-D")
        .arg(source1)
        .arg(source2)
        .arg("-t")
        .arg(at.plus(target_dir))
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(target_dir));
}
fn rust_panic_import() -> Result<()> {
    let mut store = Store::<()>::default();
    let binary = wat::parse_str(
        r#"
            (module $a
                (import "" "" (func $foo))
                (import "" "" (func $bar))
                (func (export "foo") call $foo)
                (func (export "bar") call $bar)
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let sig = FuncType::new(None, None);
    let func = Func::new(&mut store, sig, |_, _, _| panic!("this is a panic"));
    let func2 = Func::wrap(&mut store, || panic!("this is another panic"));
    let instance = Instance::new(&mut store, &module, &[func.into(), func2.into()])?;
    let func = instance.get_typed_func::<(), ()>(&mut store, "foo")?;
    let err =
        panic::catch_unwind(AssertUnwindSafe(|| drop(func.call(&mut store, ())))).unwrap_err();
    assert_eq!(err.downcast_ref::<&'static str>(), Some(&"this is a panic"));

    let func = instance.get_typed_func::<(), ()>(&mut store, "bar")?;
    let err = panic::catch_unwind(AssertUnwindSafe(|| {
        drop(func.call(&mut store, ()));
    }))
    .unwrap_err();
    assert_eq!(
        err.downcast_ref::<&'static str>(),
        Some(&"this is another panic")
    );
    Ok(())
}
fn test_struct_fields() {
    assert_eq!(
        ron::from_str::<TestStruct>("TestStruct(a: true, b: 'b', c: -42, d: \"gotcha\")"),
        Err(SpannedError {
            code: Error::NoSuchStructField {
                expected: &["a", "b", "c"],
                found: String::from("d"),
                outer: Some(String::from("TestStruct")),
            },
            position: Position { line: 1, col: 38 },
        })
    );

    assert_eq!(
        ron::from_str::<TestStruct>("TestStruct(a: true, c: -42)"),
        Err(SpannedError {
            code: Error::MissingStructField {
                field: "b",
                outer: Some(String::from("TestStruct")),
            },
            position: Position { line: 1, col: 27 },
        })
    );

    assert_eq!(
        ron::from_str::<TestStruct>("TestStruct(a: true, b: 'b', a: false, c: -42)"),
        Err(SpannedError {
            code: Error::DuplicateStructField {
                field: "a",
                outer: Some(String::from("TestStruct")),
            },
            position: Position { line: 1, col: 30 },
        })
    );
}
fn dynamic_many_types_works() {
    let mut store = test_setup();
    // Function taking no arguments and returning 16 results as tuple (maximum).
    let func = Func::wrap(
        &mut store,
        |v0: i32, v1: u32, v2: i64, v3: u64, v4: F32, v5: F64| (v0, v1, v2, v3, v4, v5),
    );
    let mut results = [0; 6].map(Value::I32);
    let inputs = [
        Value::I32(0),
        Value::I32(1),
        Value::I64(2),
        Value::I64(3),
        Value::F32(4.0.into()),
        Value::F64(5.0.into()),
    ];
    func.call(&mut store, &inputs, &mut results).unwrap();
    assert_eq!(results[0].i32(), Some(0));
    assert_eq!(results[1].i32(), Some(1));
    assert_eq!(results[2].i64(), Some(2));
    assert_eq!(results[3].i64(), Some(3));
    assert_eq!(results[4].f32(), Some(4.0.into()));
    assert_eq!(results[5].f64(), Some(5.0.into()));
}
fn smoke() -> anyhow::Result<()> {
    let mut store = Store::<()>::default();
    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::I32, Mutability::Const),
        0.into(),
    )?;
    assert_eq!(g.get(&mut store).i32(), Some(0));
    assert!(g.set(&mut store, 0.into()).is_err());

    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::I32, Mutability::Const),
        1i32.into(),
    )?;
    assert_eq!(g.get(&mut store).i32(), Some(1));

    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::I64, Mutability::Const),
        2i64.into(),
    )?;
    assert_eq!(g.get(&mut store).i64(), Some(2));

    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::F32, Mutability::Const),
        3.0f32.into(),
    )?;
    assert_eq!(g.get(&mut store).f32(), Some(3.0));

    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::F64, Mutability::Const),
        4.0f64.into(),
    )?;
    assert_eq!(g.get(&mut store).f64(), Some(4.0));
    Ok(())
}
fn scientific_exponent_test() {
    let mut number = Number {
        exponent: -4,
        mantissa: 12345,
        is_negative: false,
        many_digits: false,
        integer: &[],
        fraction: None,
    };
    assert_eq!(slow::scientific_exponent::<{ STANDARD }>(&number), 0);

    number.exponent = -15;
    assert_eq!(slow::scientific_exponent::<{ STANDARD }>(&number), -11);

    number.mantissa = 1234567890123456;
    assert_eq!(slow::scientific_exponent::<{ STANDARD }>(&number), 0);
}
fn save_point_pop_after_write() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();

    wb.write().unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_some());

    db.engine.delete(b"a").unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());

    wb.pop_save_point().unwrap();
    wb.write().unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_some());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();
    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }

    db.engine.delete(b"a").unwrap();
    for i in 0..max_keys {
        db.engine.delete(&i.to_be_bytes()).unwrap();
    }

    assert!(db.engine.get_value(b"a").unwrap().is_none());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }

    wb.pop_save_point().unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }
}
fn test_trailing_comma_some() {
    assert!(from_str::<Option<i32>>("Some(1)").is_ok());
    assert!(from_str::<Option<i32>>("Some(1,)").is_ok());
    assert!(from_str::<Option<i32>>("Some(1,,)").is_err());
}
fn parse_create_table() {
    let sql = "CREATE TABLE uk_cities (\
               name VARCHAR(100) NOT NULL,\
               lat DOUBLE NULL,\
               lng DOUBLE,
               constrained INT NULL CONSTRAINT pkey PRIMARY KEY NOT NULL UNIQUE CHECK (constrained > 0),
               ref INT REFERENCES othertable (a, b),\
               ref2 INT references othertable2 on delete cascade on update no action,\
               constraint fkey foreign key (lat) references othertable3 (lat) on delete restrict,\
               constraint fkey2 foreign key (lat) references othertable4(lat) on delete no action on update restrict, \
               foreign key (lat) references othertable4(lat) on update set default on delete cascade, \
               FOREIGN KEY (lng) REFERENCES othertable4 (longitude) ON UPDATE SET NULL
               )";
    let ast = one_statement_parses_to(
        sql,
        "CREATE TABLE uk_cities (\
         name VARCHAR(100) NOT NULL, \
         lat DOUBLE NULL, \
         lng DOUBLE, \
         constrained INT NULL CONSTRAINT pkey PRIMARY KEY NOT NULL UNIQUE CHECK (constrained > 0), \
         ref INT REFERENCES othertable (a, b), \
         ref2 INT REFERENCES othertable2 ON DELETE CASCADE ON UPDATE NO ACTION, \
         CONSTRAINT fkey FOREIGN KEY (lat) REFERENCES othertable3(lat) ON DELETE RESTRICT, \
         CONSTRAINT fkey2 FOREIGN KEY (lat) REFERENCES othertable4(lat) ON DELETE NO ACTION ON UPDATE RESTRICT, \
         FOREIGN KEY (lat) REFERENCES othertable4(lat) ON DELETE CASCADE ON UPDATE SET DEFAULT, \
         FOREIGN KEY (lng) REFERENCES othertable4(longitude) ON UPDATE SET NULL)",
    );
    match ast {
        Statement::CreateTable {
            name,
            columns,
            constraints,
            with_options,
            if_not_exists: false,
            external: false,
            file_format: None,
            location: None,
            ..
        } => {
            assert_eq!("uk_cities", name.to_string());
            assert_eq!(
                columns,
                vec![
                    ColumnDef {
                        name: "name".into(),
                        data_type: DataType::Varchar(Some(CharacterLength {
                            length: 100,
                            unit: None,
                        })),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull,
                        }],
                    },
                    ColumnDef {
                        name: "lat".into(),
                        data_type: DataType::Double,
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::Null,
                        }],
                    },
                    ColumnDef {
                        name: "lng".into(),
                        data_type: DataType::Double,
                        collation: None,
                        options: vec![],
                    },
                    ColumnDef {
                        name: "constrained".into(),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Null,
                            },
                            ColumnOptionDef {
                                name: Some("pkey".into()),
                                option: ColumnOption::Unique { is_primary: true },
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::NotNull,
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Unique { is_primary: false },
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Check(verified_expr("constrained > 0")),
                            },
                        ],
                    },
                    ColumnDef {
                        name: "ref".into(),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::ForeignKey {
                                foreign_table: ObjectName(vec!["othertable".into()]),
                                referred_columns: vec!["a".into(), "b".into()],
                                on_delete: None,
                                on_update: None,
                            },
                        }],
                    },
                    ColumnDef {
                        name: "ref2".into(),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::ForeignKey {
                                foreign_table: ObjectName(vec!["othertable2".into()]),
                                referred_columns: vec![],
                                on_delete: Some(ReferentialAction::Cascade),
                                on_update: Some(ReferentialAction::NoAction),
                            },
                        },],
                    },
                ]
            );
            assert_eq!(
                constraints,
                vec![
                    TableConstraint::ForeignKey {
                        name: Some("fkey".into()),
                        columns: vec!["lat".into()],
                        foreign_table: ObjectName(vec!["othertable3".into()]),
                        referred_columns: vec!["lat".into()],
                        on_delete: Some(ReferentialAction::Restrict),
                        on_update: None,
                    },
                    TableConstraint::ForeignKey {
                        name: Some("fkey2".into()),
                        columns: vec!["lat".into()],
                        foreign_table: ObjectName(vec!["othertable4".into()]),
                        referred_columns: vec!["lat".into()],
                        on_delete: Some(ReferentialAction::NoAction),
                        on_update: Some(ReferentialAction::Restrict),
                    },
                    TableConstraint::ForeignKey {
                        name: None,
                        columns: vec!["lat".into()],
                        foreign_table: ObjectName(vec!["othertable4".into()]),
                        referred_columns: vec!["lat".into()],
                        on_delete: Some(ReferentialAction::Cascade),
                        on_update: Some(ReferentialAction::SetDefault),
                    },
                    TableConstraint::ForeignKey {
                        name: None,
                        columns: vec!["lng".into()],
                        foreign_table: ObjectName(vec!["othertable4".into()]),
                        referred_columns: vec!["longitude".into()],
                        on_delete: None,
                        on_update: Some(ReferentialAction::SetNull),
                    },
                ]
            );
            assert_eq!(with_options, vec![]);
        }
        _ => unreachable!(),
    }

    let res = parse_sql_statements("CREATE TABLE t (a int NOT NULL GARBAGE)");
    assert!(res
        .unwrap_err()
        .to_string()
        .contains("Expected \',\' or \')\' after column definition, found: GARBAGE"));

    let res = parse_sql_statements("CREATE TABLE t (a int NOT NULL CONSTRAINT foo)");
    assert!(res
        .unwrap_err()
        .to_string()
        .contains("Expected constraint details after CONSTRAINT <name>"));
}
fn fuzz_tests() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let f = 355259285044678240000000000000000000000000000000000000000000f64;
    let actual = unsafe { std::str::from_utf8_unchecked(f.to_lexical(&mut buffer)) };
    let roundtrip = actual.parse::<f64>();
    assert_eq!(Ok(f), roundtrip);
}
fn parse_between() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE age {}BETWEEN 25 AND 32",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::Between {
                expr: Box::new(Expr::Identifier(Ident::new("age"))),
                low: Box::new(Expr::Value(number("25"))),
                high: Box::new(Expr::Value(number("32"))),
                negated,
            },
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn tuple2_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<(&str, u8), (u16, u32)> = TableDefinition::new("table");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(table_def).unwrap();
        table.insert(&("hello", 5), &(0, 123)).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(table_def).unwrap();
    assert_eq!(table.get(&("hello", 5)).unwrap().unwrap().value(), (0, 123));
}
fn parse_scalar_subqueries() {
    let sql = "(SELECT 1) + (SELECT 2)";
    assert_matches!(
        verified_expr(sql),
        Expr::BinaryOp {
            op: BinaryOperator::Plus,
            ..
        }
    );
}
fn specify_env() -> Result<()> {
    // By default no env is inherited
    let output = get_wasmtime_command()?
        .args(&["run", "tests/all/cli_tests/print_env.wat"])
        .env("THIS_WILL_NOT", "show up in the output")
        .output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), "");

    // Specify a single env var
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "--env",
            "FOO=bar",
            "tests/all/cli_tests/print_env.wat",
        ])
        .output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), "FOO=bar\n");

    // Inherit a single env var
    let output = get_wasmtime_command()?
        .args(&["run", "--env", "FOO", "tests/all/cli_tests/print_env.wat"])
        .env("FOO", "bar")
        .output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), "FOO=bar\n");

    // Inherit a nonexistent env var
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "--env",
            "SURELY_THIS_ENV_VAR_DOES_NOT_EXIST_ANYWHERE_RIGHT",
            "tests/all/cli_tests/print_env.wat",
        ])
        .output()?;
    assert!(!output.status.success());

    Ok(())
}
fn special_bytes_test() {
    const FORMAT: u128 = STANDARD;

    // Test serializing and deserializing special strings.
    assert!(f32::from_lexical(b"NaN").unwrap().is_nan());
    assert!(f32::from_lexical(b"nan").unwrap().is_nan());
    assert!(f32::from_lexical(b"NAN").unwrap().is_nan());
    assert!(f32::from_lexical(b"inf").unwrap().is_infinite());
    assert!(f32::from_lexical(b"INF").unwrap().is_infinite());
    assert!(f32::from_lexical(b"Infinity").unwrap().is_infinite());

    let options =
        Options::builder().nan_string(Some(b"nan")).inf_string(Some(b"Infinity")).build().unwrap();

    // The error message depends on whether the radix feature is enabled.
    assert!(f32::from_lexical_with_options::<FORMAT>(b"inf", &options).is_err());
    assert!(f32::from_lexical_with_options::<FORMAT>(b"Infinity", &options).unwrap().is_infinite());
}
fn test_watch_global_config_on_closed_server() {
    let (mut server, client) = new_test_server_and_client(ReadableDuration::millis(100));
    let global_items = vec![("test1", "val1"), ("test2", "val2"), ("test3", "val3")];
    let items_clone = global_items.clone();

    let client = Arc::new(client);
    let cli_clone = client.clone();
    use futures::StreamExt;
    let background_worker = Builder::new("background").thread_count(1).create();
    background_worker.spawn_async_task(async move {
        match cli_clone.watch_global_config("global".into(), 0) {
            Ok(mut stream) => {
                let mut i: usize = 0;
                while let Some(grpc_response) = stream.next().await {
                    match grpc_response {
                        Ok(r) => {
                            for item in r.get_changes() {
                                assert_eq!(item.get_name(), items_clone[i].0);
                                assert_eq!(
                                    from_utf8(item.get_payload()).unwrap(),
                                    items_clone[i].1
                                );
                                i += 1;
                            }
                        }
                        Err(err) => panic!("failed to get stream, err: {:?}", err),
                    }
                }
            }
            Err(err) => {
                if !err.to_string().contains("UNAVAILABLE") {
                    // Not 14-UNAVAILABLE
                    panic!("other error occur {:?}", err)
                }
            }
        }
    });

    if let Err(err) = futures::executor::block_on(
        client.store_global_config(
            "global".into(),
            global_items
                .iter()
                .map(|(name, value)| {
                    let mut item = GlobalConfigItem::default();
                    item.set_name(name.to_string());
                    item.set_payload(value.as_bytes().into());
                    item
                })
                .collect::<Vec<GlobalConfigItem>>(),
        ),
    ) {
        panic!("error occur {:?}", err);
    }

    thread::sleep(Duration::from_millis(100));
    server.stop();
}
fn line_width_parse_errors_overflow() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--line-width"), ("321"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "line_width_parse_errors_overflow",
        fs,
        console,
        result,
    ));
}
fn test_when_warmup_range_start_is_larger_than_last_index() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::secs(1000);
    prevent_from_gc_raft_log(&mut cluster);
    run_cluster_for_test_warmup_entry_cache(&mut cluster);
    cluster.pd_client.disable_default_operator();

    let s4 = cluster.add_new_engine();

    // Prevent peer 4 from appending logs, so it's last index should
    // be really small.
    let recv_filter_s4 = Box::new(
        RegionPacketFilter::new(1, s4)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend),
    );
    cluster.sim.wl().add_recv_filter(s4, recv_filter_s4);

    let (sx, rx) = channel::unbounded();
    let recv_filter_1 = Box::new(
        RegionPacketFilter::new(1, 1)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgTransferLeader)
            .set_msg_callback(Arc::new(move |m| {
                sx.send(m.get_message().get_from()).unwrap();
            })),
    );
    cluster.sim.wl().add_recv_filter(1, recv_filter_1);

    cluster.pd_client.must_add_peer(1, new_peer(s4, s4));
    cluster.transfer_leader(1, new_peer(s4, s4));
    // Store(s4) should ack the transfer leader msg immediately.
    assert_eq!(rx.recv_timeout(Duration::from_millis(500)).unwrap(), s4);
}
fn replace_file() {
    let f = super::fixture().join("browser-module");

    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![
            vec!["browser".into()],
            vec!["innerBrowser1".into(), "field2".into(), "browser".into()], // not presented
            vec!["innerBrowser1".into(), "field".into(), "browser".into()],
            vec!["innerBrowser2".into(), "browser".into()],
        ],
        // Not part of enhanced-resolve. Added to make sure no interaction between these two fields.
        main_fields: vec!["browser".into()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let data = [
        ("should replace a file 1", f.clone(), "./lib/replaced", f.join("lib/browser.js")),
        ("should replace a file 2", f.clone(), "./lib/replaced.js", f.join("lib/browser.js")),
        ("should replace a file 3", f.join("lib"), "./replaced", f.join("lib/browser.js")),
        ("should replace a file 4", f.join("lib"), "./replaced.js", f.join("lib/browser.js")),
        ("should replace a module with a file 1", f.clone(), "module-a", f.join("browser/module-a.js")),
        ("should replace a module with a file 2", f.join("lib"), "module-a", f.join("browser/module-a.js")),
        ("should replace a module with a module 1", f.clone(), "module-b", f.join("node_modules/module-c.js")),
        ("should replace a module with a module 2", f.join("lib"), "module-b", f.join("node_modules/module-c.js")),
        ("should resolve in nested property 1", f.clone(), "./lib/main1.js", f.join("lib/main.js")),
        ("should resolve in nested property 2", f.clone(), "./lib/main2.js", f.join("lib/browser.js")),
        ("should check only alias field properties", f.clone(), "./toString", f.join("lib/toString.js")),
        // not part of enhanced-resolve
        ("recursion", f.clone(), "module-c", f.join("node_modules/module-c.js")),
    ];

    for (comment, path, request, expected) in data {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn test_unlink_symlink() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.touch("foo");
    at.symlink_file("foo", "bar");

    ucmd.arg("bar").succeeds().no_stderr();

    assert!(at.file_exists("foo"));
    assert!(!at.file_exists("bar"));
}
fn test_witness_raftlog_gc_pull_voter_replicated_index() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(50);
    cluster
        .cfg
        .raft_store
        .request_voter_replicated_index_interval = ReadableDuration::millis(100);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(200));
    let mut before_states = HashMap::default();
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        before_states.insert(id, state.take_truncated_state());
    }

    // one follower is down
    cluster.stop_node(nodes[1]);

    // write some data to make log gap exceeds the gc limit
    for i in 1..1000 {
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
    }

    // the witness truncated index is not advanced
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        if id == 2 {
            assert_eq!(
                state.get_truncated_state().get_index() - before_states[&id].get_index(),
                0
            );
        } else {
            assert_ne!(
                900,
                state.get_truncated_state().get_index() - before_states[&id].get_index()
            );
        }
    }

    fail::cfg("on_raft_gc_log_tick", "return").unwrap();

    // the follower is back online
    cluster.run_node(nodes[1]).unwrap();
    cluster.must_put(b"k00", b"v00");
    must_get_equal(&cluster.get_engine(nodes[1]), b"k00", b"v00");
    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(300));

    // the truncated index is advanced now, as all the peers has replicated
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        assert_ne!(
            900,
            state.get_truncated_state().get_index() - before_states[&id].get_index()
        );
    }
    fail::remove("on_raft_gc_log_tick");
}
fn test_writer_indent() -> Result<()> {
    let txt = include_str!("../tests/documents/test_writer_indent.xml");
    let mut reader = Reader::from_str(txt);
    reader.trim_text(true);
    let mut writer = Writer::new_with_indent(Cursor::new(Vec::new()), b' ', 4);
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(result, txt.as_bytes());

    Ok(())
}
fn test_null_delimiter() {
    let out = new_ucmd!()
        .arg("-i")
        .arg("--null")
        .arg("FOO=bar")
        .arg("ABC=xyz")
        .succeeds()
        .stdout_move_str();

    let mut vars: Vec<_> = out.split('\0').collect();
    assert_eq!(vars.len(), 3);
    vars.sort_unstable();
    assert_eq!(vars[0], "");
    assert_eq!(vars[1], "ABC=xyz");
    assert_eq!(vars[2], "FOO=bar");
}
fn parse_partial_number_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::new();
    let string = b"1.2345e10";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_partial_number(byte, false, &options);
    assert!(result.is_ok());
    let (num, count) = result.unwrap();
    assert_eq!(num.mantissa, 12345);
    assert_eq!(num.exponent, 6);
    assert_eq!(num.many_digits, false);
    assert_eq!(count, 9);

    let string = b"1.2345e";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_partial_number(byte, false, &options);
    assert!(result.is_err());

    let string = b"1.2345 ";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_partial_number(byte, false, &options);
    assert!(result.is_ok());
    let (num, count) = result.unwrap();
    assert_eq!(num.mantissa, 12345);
    assert_eq!(num.exponent, -4);
    assert_eq!(num.many_digits, false);
    assert_eq!(count, 6);

    // Leading zeros
    let string = b"00000000000000000000001.2345 ";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_partial_number(byte, false, &options);
    assert!(result.is_ok());
    let (num, count) = result.unwrap();
    assert_eq!(num.mantissa, 12345);
    assert_eq!(num.exponent, -4);
    assert_eq!(num.many_digits, false);
    assert_eq!(count, 28);

    // Leading zeros
    let string = b"0.00000000000000000000012345 ";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_partial_number(byte, false, &options);
    assert!(result.is_ok());
    let (num, count) = result.unwrap();
    assert_eq!(num.mantissa, 12345);
    assert_eq!(num.exponent, -26);
    assert_eq!(num.many_digits, false);
    assert_eq!(count, 28);
}
fn drain() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
        // Test draining uncommitted data
        drop(table.drain(0..10).unwrap());
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        assert_eq!(table.len().unwrap(), 10);
        for (i, item) in table.drain(0..5).unwrap().enumerate() {
            let (k, v) = item.unwrap();
            assert_eq!(i as u64, k.value());
            assert_eq!(i as u64, v.value());
        }
        assert_eq!(table.len().unwrap(), 5);
        let mut i = 5u64;
        for item in table.range(0..10).unwrap() {
            let (k, v) = item.unwrap();
            assert_eq!(i, k.value());
            assert_eq!(i, v.value());
            i += 1;
        }
    }
    write_txn.abort().unwrap();

    // Check that dropping the iter early works too
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        assert_eq!(table.len().unwrap(), 10);
        drop(table.drain(0..5).unwrap());
        assert_eq!(table.len().unwrap(), 5);
    }
    write_txn.abort().unwrap();
}
fn test_rm_interactive() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_rm_interactive_file_a";
    let file_b = "test_rm_interactive_file_b";

    at.touch(file_a);
    at.touch(file_b);
    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    scene
        .ucmd()
        .arg("-i")
        .arg(file_a)
        .arg(file_b)
        .pipe_in("n")
        .succeeds();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    scene
        .ucmd()
        .arg("-i")
        .arg(file_a)
        .arg(file_b)
        .pipe_in("Yesh") // spell-checker:disable-line
        .succeeds();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
}
fn instant_close_1() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    info!("connecting");
    let client_ch = pair.begin_connect(client_config());
    pair.client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .close(pair.time, VarInt(0), Bytes::new());
    pair.drive();
    let server_ch = pair.server.assert_accept();
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::ConnectionClosed(ConnectionClose {
                error_code: TransportErrorCode::APPLICATION_ERROR,
                ..
            }),
        })
    );
}
fn test_something() {
    let data = [];
    if let Ok((leftover, stanza)) = read::age_stanza(data) {
        let mut buf = Vec::with_capacity(data.len());
        gen(
            write::age_stanza(stanza.tag, &stanza.args, &stanza.body()),
            &mut buf,
        )
        .expect("can write to Vec");
        assert_eq!(buf, &data[0..data.len() - leftover.len()]);
    }
}
fn get_and_set_config_fields() -> anyhow::Result<()> {
    let temp = setup_wasmer_dir();

    // ---- config get

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.token")
        .output()?;

    let original_token = String::from_utf8_lossy(&output.stdout);

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("registry.token")
        .arg("abc123")
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.token")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "abc123\n".to_string()
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("registry.token")
        .arg(original_token.to_string().trim())
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.token")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        format!("{}\n", original_token.to_string().trim())
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.url")
        .output()?;

    let original_url = String::from_utf8_lossy(&output.stdout);

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("registry.url")
        .arg("wasmer.wtf")
        .output()?;

    let output_str = String::from_utf8_lossy(&output.stdout);

    assert_eq!(output_str, "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.url")
        .output()?;

    let output_str = String::from_utf8_lossy(&output.stdout);
    assert_eq!(
        output_str,
        "https://registry.wasmer.wtf/graphql\n".to_string()
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("registry.url")
        .arg(original_url.to_string().trim())
        .output()?;

    let output_str = String::from_utf8_lossy(&output.stdout);
    assert_eq!(output_str, "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("registry.url")
        .output()?;

    let output_str = String::from_utf8_lossy(&output.stdout);
    assert_eq!(output_str, original_url.to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("telemetry.enabled")
        .output()?;

    let original_output = String::from_utf8_lossy(&output.stdout);

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("telemetry.enabled")
        .arg("true")
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("telemetry.enabled")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "true\n".to_string()
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("telemetry.enabled")
        .arg(original_output.to_string().trim())
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("telemetry.enabled")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        original_output.to_string()
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("update-notifications.enabled")
        .output()?;

    let original_output = String::from_utf8_lossy(&output.stdout);

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("update-notifications.enabled")
        .arg("true")
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("update-notifications.enabled")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "true\n".to_string()
    );

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("set")
        .arg("update-notifications.enabled")
        .arg(original_output.to_string().trim())
        .output()?;

    assert_eq!(String::from_utf8_lossy(&output.stdout), "".to_string());

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("get")
        .arg("update-notifications.enabled")
        .output()?;

    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        original_output.to_string()
    );

    Ok(())
}
fn test_storage_error() {
    let data = vec![(1, Some("name:0"), 2), (2, Some("name:4"), 3)];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);
    let req = DagSelect::from(&product).build();

    fail::cfg("kv_cursor_seek", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_other_error().contains("kv cursor seek error"));
}
fn filter_filter_works() {
    #[derive(Debug, Serialize)]
    struct Author {
        id: u8,
    }

    let mut context = Context::new();
    context.insert("authors", &vec![Author { id: 1 }, Author { id: 2 }, Author { id: 3 }]);

    let inputs =
        vec![(r#"{{ authors | filter(attribute="id", value=1) | first | get(key="id") }}"#, "1")];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_trap_through_host() -> Result<()> {
    let wat = r#"
        (module $hello_mod
            (import "" "" (func $host_func_a))
            (import "" "" (func $host_func_b))
            (func $a (export "a")
                call $host_func_a
            )
            (func $b (export "b")
                call $host_func_b
            )
            (func $c (export "c")
                unreachable
            )
        )
    "#;

    let engine = Engine::default();
    let module = Module::new(&engine, wat)?;
    let mut store = Store::<()>::new(&engine, ());

    let host_func_a = Func::new(
        &mut store,
        FuncType::new(vec![], vec![]),
        |mut caller, _args, _results| {
            caller
                .get_export("b")
                .unwrap()
                .into_func()
                .unwrap()
                .call(caller, &[], &mut [])?;
            Ok(())
        },
    );
    let host_func_b = Func::new(
        &mut store,
        FuncType::new(vec![], vec![]),
        |mut caller, _args, _results| {
            caller
                .get_export("c")
                .unwrap()
                .into_func()
                .unwrap()
                .call(caller, &[], &mut [])?;
            Ok(())
        },
    );

    let instance = Instance::new(
        &mut store,
        &module,
        &[host_func_a.into(), host_func_b.into()],
    )?;
    let a = instance.get_typed_func::<(), ()>(&mut store, "a")?;
    let err = a.call(&mut store, ()).unwrap_err();
    let trace = err.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 3);
    assert_eq!(trace[0].func_name(), Some("c"));
    assert_eq!(trace[1].func_name(), Some("b"));
    assert_eq!(trace[2].func_name(), Some("a"));
    Ok(())
}
fn test_read_write_roundtrip() -> Result<()> {
    let input = r#"
        <?xml version="1.0" encoding="UTF-8"?>
        <section ns:label="header">
            <section ns:label="empty element section" />
            <section ns:label="start/end section"></section>
            <section ns:label="with text">data &lt;escaped&gt;</section>
            </section>
    "#;

    let mut reader = Reader::from_str(input);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(String::from_utf8(result).unwrap(), input);
    Ok(())
}
fn does_handle_included_file_and_disable_linter() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "include": ["test.js", "special/**"]
  },
  "overrides": [{ "include": ["special/**"], "linter": { "enabled": false } }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), FIX_BEFORE.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FIX_BEFORE);
    assert_file_contents(&fs, test, FIX_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_included_file_and_disable_linter",
        fs,
        console,
        result,
    ));
}
fn test_rm_multiple_files() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_rm_multiple_file_a";
    let file_b = "test_rm_multiple_file_b";

    at.touch(file_a);
    at.touch(file_b);

    ucmd.arg(file_a).arg(file_b).succeeds().no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
}
fn strip_double_space() {
    assert_eq!("test mess", normalize_html("test  mess"));
}
fn test_cp_existing_target() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_EXISTING_FILE)
        .succeeds();

    // Check the content of the destination file
    assert_eq!(at.read(TEST_EXISTING_FILE), "Hello, World!\n");

    // No backup should have been created
    assert!(!at.file_exists(format!("{TEST_EXISTING_FILE}~")));
}
fn math() {
    assert_eq!(size(10) + size(5), size(15));
    assert_eq!(size(10) - size(5), size(5));
}
fn test_install_dir_dot() {
    // To match tests/install/d-slashdot.sh
    let scene = TestScenario::new(util_name!());

    scene.ucmd().arg("-d").arg("dir1/.").succeeds();
    scene.ucmd().arg("-d").arg("dir2/..").succeeds();
    // Tests that we don't have dir3/. in the output
    // but only 'dir3'
    scene
        .ucmd()
        .arg("-d")
        .arg("dir3/.")
        .arg("-v")
        .succeeds()
        .stdout_contains("creating directory 'dir3'");
    scene
        .ucmd()
        .arg("-d")
        .arg("dir4/./cal")
        .arg("-v")
        .succeeds()
        .stdout_contains("creating directory 'dir4/./cal'");
    scene
        .ucmd()
        .arg("-d")
        .arg("dir5/./cali/.")
        .arg("-v")
        .succeeds()
        .stdout_contains("creating directory 'dir5/cali'");

    let at = &scene.fixtures;

    assert!(at.dir_exists("dir1"));
    assert!(at.dir_exists("dir2"));
    assert!(at.dir_exists("dir3"));
    assert!(at.dir_exists("dir4/cal"));
    assert!(at.dir_exists("dir5/cali"));
}
fn test_scan_detail() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = {
        let engine = TestEngineBuilder::new().build().unwrap();
        let mut cfg = Config::default();
        cfg.end_point_batch_row_limit = 50;
        init_data_with_details(Context::default(), engine, &product, &data, true, &cfg)
    };

    let reqs = vec![
        DagSelect::from(&product).build(),
        DagSelect::from_index(&product, &product["name"]).build(),
    ];

    for mut req in reqs {
        req.mut_context().set_record_scan_stat(true);
        req.mut_context().set_record_time_stat(true);

        let resp = handle_request(&endpoint, req);
        assert!(resp.get_exec_details().has_time_detail());
        let scan_detail = resp.get_exec_details().get_scan_detail();
        // Values would occur in data cf are inlined in write cf.
        assert_eq!(scan_detail.get_write().get_total(), 5);
        assert_eq!(scan_detail.get_write().get_processed(), 4);
        assert_eq!(scan_detail.get_lock().get_total(), 1);

        assert!(resp.get_exec_details_v2().has_time_detail());
        assert!(resp.get_exec_details_v2().has_time_detail_v2());
        let scan_detail_v2 = resp.get_exec_details_v2().get_scan_detail_v2();
        assert_eq!(scan_detail_v2.get_total_versions(), 5);
        assert_eq!(scan_detail_v2.get_processed_versions(), 4);
        assert!(scan_detail_v2.get_processed_versions_size() > 0);
    }
}
fn test_split() {
    let mut cluster = Cluster::default();
    let store_id = cluster.node(0).id();
    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();
    let router = &mut cluster.routers[0];

    let region_2 = 2;
    let region = router.region_detail(region_2);
    let peer = region.get_peers()[0].clone();
    router.wait_applied_to_current_term(region_2, Duration::from_secs(3));

    // Region 2 ["", ""]
    //   -> Region 2    ["", "k22"]
    //      Region 1000 ["k22", ""] peer(1, 10)
    let region_state = raft_engine
        .get_region_state(region_2, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
    let (left, mut right) = split_region(
        router,
        region,
        peer.clone(),
        1000,
        new_peer(store_id, 10),
        Some(b"k11"),
        Some(b"k33"),
        b"k22",
        b"k22",
        false,
    );
    let region_state = raft_engine
        .get_region_state(region_2, u64::MAX)
        .unwrap()
        .unwrap();
    assert_ne!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
    assert_eq!(
        region_state.get_region().get_region_epoch().get_version(),
        INIT_EPOCH_VER + 1
    );
    let region_state0 = raft_engine
        .get_region_state(region_2, region_state.get_tablet_index())
        .unwrap()
        .unwrap();
    assert_eq!(region_state, region_state0);
    let flushed_index = raft_engine
        .get_flushed_index(region_2, CF_RAFT)
        .unwrap()
        .unwrap();
    assert!(
        flushed_index >= region_state.get_tablet_index(),
        "{flushed_index} >= {}",
        region_state.get_tablet_index()
    );

    // Region 2 ["", "k22"]
    //   -> Region 2    ["", "k11"]
    //      Region 1001 ["k11", "k22"] peer(1, 11)
    let _ = split_region(
        router,
        left,
        peer,
        1001,
        new_peer(store_id, 11),
        Some(b"k00"),
        Some(b"k11"),
        b"k11",
        b"k11",
        false,
    );
    let region_state = raft_engine
        .get_region_state(region_2, u64::MAX)
        .unwrap()
        .unwrap();
    assert_ne!(
        region_state.get_tablet_index(),
        region_state0.get_tablet_index()
    );
    assert_eq!(
        region_state.get_region().get_region_epoch().get_version(),
        INIT_EPOCH_VER + 2
    );
    let region_state1 = raft_engine
        .get_region_state(region_2, region_state.get_tablet_index())
        .unwrap()
        .unwrap();
    assert_eq!(region_state, region_state1);
    let flushed_index = raft_engine
        .get_flushed_index(region_2, CF_RAFT)
        .unwrap()
        .unwrap();
    assert!(
        flushed_index >= region_state.get_tablet_index(),
        "{flushed_index} >= {}",
        region_state.get_tablet_index()
    );

    // Region 1000 ["k22", ""] peer(1, 10)
    //   -> Region 1000 ["k22", "k33"] peer(1, 10)
    //      Region 1002 ["k33", ""]    peer(1, 12)
    let region_1000 = 1000;
    let region_state = raft_engine
        .get_region_state(region_1000, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
    right = split_region(
        router,
        right,
        new_peer(store_id, 10),
        1002,
        new_peer(store_id, 12),
        Some(b"k22"),
        Some(b"k33"),
        b"k33",
        b"k33",
        false,
    )
    .1;
    let region_state = raft_engine
        .get_region_state(region_1000, u64::MAX)
        .unwrap()
        .unwrap();
    assert_ne!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
    assert_eq!(
        region_state.get_region().get_region_epoch().get_version(),
        INIT_EPOCH_VER + 2
    );
    let region_state2 = raft_engine
        .get_region_state(region_1000, region_state.get_tablet_index())
        .unwrap()
        .unwrap();
    assert_eq!(region_state, region_state2);
    let flushed_index = raft_engine
        .get_flushed_index(region_1000, CF_RAFT)
        .unwrap()
        .unwrap();
    assert!(
        flushed_index >= region_state.get_tablet_index(),
        "{flushed_index} >= {}",
        region_state.get_tablet_index()
    );

    // 1002 -> 1002, 1003
    let split_key = Key::from_raw(b"k44").append_ts(TimeStamp::zero());
    let actual_split_key = split_key.clone().truncate_ts().unwrap();
    split_region(
        router,
        right,
        new_peer(store_id, 12),
        1003,
        new_peer(store_id, 13),
        Some(b"k33"),
        Some(b"k55"),
        split_key.as_encoded(),
        actual_split_key.as_encoded(),
        false,
    );

    // Split should survive restart.
    drop(raft_engine);
    cluster.restart(0);
    let region_and_key = vec![
        (2, b"k00"),
        (1000, b"k22"),
        (1001, b"k11"),
        (1002, b"k33"),
        (1003, b"k55"),
    ];
    for (region_id, key) in region_and_key {
        let snapshot = cluster.routers[0].stale_snapshot(region_id);
        assert!(
            snapshot.get_value(key).unwrap().is_some(),
            "{} {:?}",
            region_id,
            key
        );
    }
}
fn lex_continue_tag() {
    assert!(TeraParser::parse(Rule::continue_tag, "{% continue %}").is_ok());
}
fn fabsd_spec_test() {
    assert!(libm::fabsd(f64::NAN).is_nan());
    for f in [0.0, -0.0].iter().copied() {
        assert_eq!(libm::fabsd(f), 0.0);
    }
    for f in [f64::INFINITY, f64::NEG_INFINITY].iter().copied() {
        assert_eq!(libm::fabsd(f), f64::INFINITY);
    }
}
fn formatter_biome_json() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_FORMAT.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), CUSTOM_CONFIGURATION_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--line-width"),
                ("10"),
                ("--indent-style"),
                ("space"),
                ("--indent-size"),
                ("8"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, CUSTOM_CONFIGURATION_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "formatter_biome_json",
        fs,
        console,
        result,
    ));
}
fn test_trap_return_downcast() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module
        (func $hello (import "" "hello"))
        (func (export "run") (call $hello))
        )
    "#;

    #[derive(Debug)]
    struct MyTrap;
    impl std::fmt::Display for MyTrap {
        fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
            write!(f, "my trap")
        }
    }
    impl std::error::Error for MyTrap {}

    let module = Module::new(store.engine(), wat)?;
    let hello_type = FuncType::new(None, None);
    let hello_func = Func::new(&mut store, hello_type, |_, _, _| {
        Err(anyhow::Error::from(MyTrap))
    });

    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func
        .call(&mut store, ())
        .err()
        .expect("error calling function");
    let dbg = format!("{:?}", e);
    println!("{}", dbg);

    assert!(!e.to_string().contains("my trap"));
    assert!(dbg.contains("Caused by:\n    my trap"));

    e.downcast_ref::<MyTrap>()
        .expect("error downcasts to MyTrap");
    let bt = e
        .downcast_ref::<WasmBacktrace>()
        .expect("error downcasts to WasmBacktrace");
    assert_eq!(bt.frames().len(), 1);
    println!("{:?}", bt);

    Ok(())
}
fn test_issue173() {
    // Denormal boundary
    assert_eq!(
        2.2250738585072012e-308,
        s2d(b"2.2250738585072012e-308").unwrap(),
    );
    assert_eq!(
        2.2250738585072013e-308,
        s2d(b"2.2250738585072013e-308").unwrap(),
    );
    assert_eq!(
        2.2250738585072014e-308,
        s2d(b"2.2250738585072014e-308").unwrap(),
    );
}
fn parse_select_group_by() {
    let sql = "SELECT id, fname, lname FROM customer GROUP BY lname, fname";
    let select = verified_only_select(sql);
    assert_eq!(
        GroupByExpr::Expressions(vec![
            Expr::Identifier(Ident::new("lname")),
            Expr::Identifier(Ident::new("fname")),
        ]),
        select.group_by
    );

    // Tuples can also be in the set
    one_statement_parses_to(
        "SELECT id, fname, lname FROM customer GROUP BY (lname, fname)",
        "SELECT id, fname, lname FROM customer GROUP BY (lname, fname)",
    );
}
fn borrowing_no_duplication() -> Result<()> {
    wasmtime::component::bindgen!({
        inline: "
        package inline:inline;
        world test {
            export lists: interface {
                foo: func(a: list<list<string>>) -> list<list<string>>;
            }

            export thing-in: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                bar: func(a: thing);
            }

            export thing-in-and-out: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                baz: func(a: thing) -> thing;
            }
        }",
        ownership: Borrowing {
            duplicate_if_necessary: false
        }
    });

    impl PartialEq for exports::thing_in::Thing<'_> {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    impl PartialEq for exports::thing_in_and_out::Thing {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    let engine = engine();
    let component = Component::new(&engine, component())?;

    let linker = Linker::new(&engine);
    let mut store = Store::new(&engine, ());
    let (test, _) = Test::instantiate(&mut store, &component, &linker)?;

    let value = &[&["a", "b"] as &[_]] as &[_];
    assert_eq!(value, test.lists().call_foo(&mut store, value)?);

    let value = exports::thing_in::Thing {
        name: "thing 1",
        value: &["some value", "another value"],
    };
    test.thing_in().call_bar(&mut store, value)?;

    let value = exports::thing_in_and_out::Thing {
        name: "thing 1".to_owned(),
        value: vec!["some value".to_owned(), "another value".to_owned()],
    };
    assert_eq!(value, test.thing_in_and_out().call_baz(&mut store, &value)?);

    Ok(())
}
fn test_uname_operating_system() {
    #[cfg(target_os = "android")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("Android\n");
    #[cfg(target_vendor = "apple")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("Darwin\n");
    #[cfg(target_os = "freebsd")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("FreeBSD\n");
    #[cfg(target_os = "fuchsia")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("Fuchsia\n");
    #[cfg(all(target_os = "linux", any(target_env = "gnu", target_env = "")))]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("GNU/Linux\n");
    #[cfg(all(target_os = "linux", not(any(target_env = "gnu", target_env = ""))))]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("Linux\n");
    #[cfg(target_os = "netbsd")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("NetBSD\n");
    #[cfg(target_os = "openbsd")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("OpenBSD\n");
    #[cfg(target_os = "redox")]
    new_ucmd!()
        .arg("--operating-system")
        .succeeds()
        .stdout_is("Redox\n");
    #[cfg(target_os = "windows")]
    {
        let result = new_ucmd!().arg("--operating-system").succeeds();
        println!("{:?}", result.stdout_str());
        assert!(result.stdout_str().starts_with("MS/Windows"));
    }
}
fn reject_missing_client_cert() {
    let _guard = subscribe();

    let key = rustls::PrivateKey(CERTIFICATE.serialize_private_key_der());
    let cert = util::CERTIFICATE.serialize_der().unwrap();

    let config = rustls::ServerConfig::builder()
        .with_safe_default_cipher_suites()
        .with_safe_default_kx_groups()
        .with_protocol_versions(&[&rustls::version::TLS13])
        .unwrap()
        .with_client_cert_verifier(Arc::new(rustls::server::AllowAnyAuthenticatedClient::new(
            rustls::RootCertStore::empty(),
        )))
        .with_single_cert(vec![rustls::Certificate(cert)], key)
        .unwrap();

    let mut pair = Pair::new(
        Default::default(),
        ServerConfig::with_crypto(Arc::new(config)),
    );

    info!("connecting");
    let client_ch = pair.begin_connect(client_config());
    pair.drive();

    // The client completes the connection, but finds it immediately closed
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected)
    );
    assert_matches!(pair.client_conn_mut(client_ch).poll(),
                    Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(ref close)})
                    if close.error_code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));

    // The server never completes the connection
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(pair.server_conn_mut(server_ch).poll(),
                    Some(Event::ConnectionLost { reason: ConnectionError::TransportError(ref error)})
                    if error.code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));
}
fn roundtrip_sep_tuple_members() {
    #[derive(Debug, Deserialize, PartialEq, Eq, Serialize)]
    pub enum FileOrMem {
        File(String),
        Memory,
    }

    #[derive(Debug, Deserialize, PartialEq, Serialize)]
    struct Both {
        a: Struct,
        b: FileOrMem,
    }

    let a = Struct {
        tuple: ((), NewType(0.5), TupleStruct(UnitStruct, -5)),
        vec: vec![None, Some(UnitStruct)],
        map: vec![
            (Key(5), Enum::Unit),
            (Key(6), Enum::Bool(false)),
            (Key(7), Enum::Bool(true)),
            (Key(9), Enum::Chars('x', "".to_string())),
        ]
        .into_iter()
        .collect(),
    };
    let b = FileOrMem::File("foo".to_owned());

    let value = Both { a, b };

    let pretty = ron::ser::PrettyConfig::new().separate_tuple_members(true);
    let serial = ron::ser::to_string_pretty(&value, pretty).unwrap();

    println!("Serialized: {}", serial);

    let deserial = ron::de::from_str(&serial);

    assert_eq!(Ok(value), deserial);
}
fn client_closes_uncleanly() {
    let kt = KeyType::Rsa;
    let server_config = Arc::new(make_server_config(kt));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(kt, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        do_handshake(&mut client, &mut server);

        // check that unclean EOF reporting does not overtake appdata
        assert_eq!(
            12,
            server
                .writer()
                .write(b"from-server!")
                .unwrap()
        );
        assert_eq!(
            12,
            client
                .writer()
                .write(b"from-client!")
                .unwrap()
        );

        transfer(&mut client, &mut server);
        transfer_eof(&mut server);
        let io_state = server.process_new_packets().unwrap();
        assert!(!io_state.peer_has_closed());
        check_read(&mut server.reader(), b"from-client!");

        check_read_err(
            &mut server.reader() as &mut dyn io::Read,
            io::ErrorKind::UnexpectedEof,
        );

        // may still transmit pending frames
        transfer(&mut server, &mut client);
        client.process_new_packets().unwrap();
        check_read(&mut client.reader(), b"from-server!");
    }
}
fn c_flags() {
    let temp = setup_wasmer_dir();
    let wasmer_dir = temp.path();

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--bindir")
        .assert()
        .success()
        .stdout(contains_path(temp.path().join("bin")));

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--cflags")
        .assert()
        .success()
        .stdout(contains(format!(
            "-I{}\n",
            wasmer_dir.join("include").display()
        )));

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--includedir")
        .assert()
        .success()
        .stdout(contains_path(wasmer_dir.join("include")));

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--libdir")
        .assert()
        .success()
        .stdout(contains_path(wasmer_dir.join("lib")));

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--libs")
        .assert()
        .stdout(contains(format!(
            "-L{} -lwasmer\n",
            wasmer_dir.join("lib").display()
        )));

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--prefix")
        .assert()
        .success()
        .stdout(contains_path(wasmer_dir));

    let output = wasmer_cmd(&temp)
        .arg("config")
        .arg("--pkg-config")
        .output()
        .unwrap();

    let pkg_config = vec![
        format!("prefix={}", wasmer_dir.display()),
        format!("exec_prefix={}", wasmer_dir.join("bin").display()),
        format!("includedir={}", wasmer_dir.join("include").display()),
        format!("libdir={}", wasmer_dir.join("lib").display()),
        format!(""),
        format!("Name: wasmer"),
        format!("Description: The Wasmer library for running WebAssembly"),
        format!("Version: {}", env!("CARGO_PKG_VERSION")),
        format!("Cflags: -I{}", wasmer_dir.join("include").display()),
        format!("Libs: -L{} -lwasmer", wasmer_dir.join("lib").display()),
    ]
    .join("\n");

    assert!(output.status.success());
    let stderr = std::str::from_utf8(&output.stdout)
        .unwrap()
        .replace("\r\n", "\n");
    assert_eq!(stderr.trim(), pkg_config.trim());

    wasmer_cmd(&temp)
        .arg("config")
        .arg("--config-path")
        .assert()
        .success()
        .stdout(contains_path(temp.path().join("wasmer.toml")));
}
fn test_something() {
    let data = [];
    assert_ne!(is_nfc_quick(input.chars()), from_bool(!is_nfc(&input)));
    assert_ne!(is_nfd_quick(input.chars()), from_bool(!is_nfd(&input)));
    assert_ne!(is_nfkc_quick(input.chars()), from_bool(!is_nfkc(&input)));
    assert_ne!(is_nfkd_quick(input.chars()), from_bool(!is_nfkd(&input)));
    assert_ne!(
        is_nfc_stream_safe_quick(input.chars()),
        from_bool(!is_nfc_stream_safe(&input))
    );
    assert_ne!(
        is_nfd_stream_safe_quick(input.chars()),
        from_bool(!is_nfd_stream_safe(&input))
    );
    let nfc = input.chars().nfc().collect::<String>();
    assert_eq!(nfc.is_empty(), input.is_empty());
    assert_ne!(is_nfc_quick(nfc.chars()), IsNormalized::No);
    assert!(is_nfc(&nfc));
    let nfd = input.chars().nfd().collect::<String>();
    assert!(nfd.len() >= nfc.len());
    assert_ne!(is_nfd_quick(nfd.chars()), IsNormalized::No);
    assert!(is_nfd(&nfd));
    let nfkc = input.chars().nfkc().collect::<String>();
    assert_eq!(nfkc.is_empty(), input.is_empty());
    assert_ne!(is_nfkc_quick(nfkc.chars()), IsNormalized::No);
    assert!(is_nfkc(&nfkc));
    let nfkd = input.chars().nfkd().collect::<String>();
    assert!(nfkd.len() >= nfkc.len());
    assert_ne!(is_nfkd_quick(nfkd.chars()), IsNormalized::No);
    assert!(is_nfkd(&nfkd));
    let nfc_ss = nfc.chars().stream_safe().collect::<String>();
    assert!(nfc_ss.len() >= nfc.len());
    assert_ne!(is_nfc_stream_safe_quick(nfc_ss.chars()), IsNormalized::No);
    assert!(is_nfc_stream_safe(&nfc_ss));
    let nfd_ss = nfd.chars().stream_safe().collect::<String>();
    assert!(nfd_ss.len() >= nfd.len());
    assert_ne!(is_nfd_stream_safe_quick(nfd_ss.chars()), IsNormalized::No);
    assert!(is_nfd_stream_safe(&nfd_ss));
    let ss_nfc = input.chars().stream_safe().nfc().collect::<String>();
    assert_eq!(ss_nfc.is_empty(), input.is_empty());
    assert_ne!(is_nfc_stream_safe_quick(ss_nfc.chars()), IsNormalized::No);
    assert!(is_nfc_stream_safe(&ss_nfc));
    let ss_nfd = input.chars().stream_safe().nfd().collect::<String>();
    assert_eq!(ss_nfd.is_empty(), input.is_empty());
    assert_ne!(is_nfd_stream_safe_quick(ss_nfd.chars()), IsNormalized::No);
    assert!(is_nfd_stream_safe(&ss_nfd));
}
fn test_dynamic() {
    let mut env = Environment::new();
    let template = String::from("Hello World 2!");
    env.add_template_owned("hello2", template).unwrap();
    env.set_loader(|name| match name {
        "hello" => Ok(Some("Hello World!".into())),
        _ => Ok(None),
    });
    let t = env.get_template("hello").unwrap();
    assert_eq!(t.render(()).unwrap(), "Hello World!");
    let t = env.get_template("hello2").unwrap();
    assert_eq!(t.render(()).unwrap(), "Hello World 2!");
    let err = env.get_template("missing").unwrap_err();
    assert_eq!(
        err.to_string(),
        "template not found: template \"missing\" does not exist"
    );
}
fn parse_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), PARSE_ERROR.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );
    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "parse_error",
        fs,
        console,
        result,
    ));
}
fn decimal_test() {
    const FORMAT: u128 = NumberFormatBuilder::decimal();
    let format = NumberFormat::<FORMAT> {};
    assert!(format.is_valid());
    assert_eq!(format.radix(), 10);
    assert_eq!(format.mantissa_radix(), 10);
    assert_eq!(format.exponent_base(), 10);
    assert_eq!(format.exponent_radix(), 10);
}
fn test_something() {
    let data = [];
    let wasm_bytes = module.0.to_bytes();
    if let Ok(path) = std::env::var("DUMP_TESTCASE") {
        use std::fs::File;
        use std::io::Write;
        let mut file = File::create(path).unwrap();
        file.write_all(&wasm_bytes).unwrap();
        return;
    }
    #[cfg(feature = "singlepass")]
    let singlepass = maybe_instantiate_singlepass(&wasm_bytes)
        .transpose()
        .map(evaluate_instance);
    #[cfg(feature = "cranelift")]
    let cranelift = maybe_instantiate_cranelift(&wasm_bytes)
        .transpose()
        .map(evaluate_instance);
    #[cfg(feature = "llvm")]
    let llvm = maybe_instantiate_llvm(&wasm_bytes)
        .transpose()
        .map(evaluate_instance);
    #[cfg(all(feature = "singlepass", feature = "cranelift"))]
    if singlepass.is_some() && cranelift.is_some() {
        assert_eq!(singlepass.as_ref().unwrap(), cranelift.as_ref().unwrap());
    }
    #[cfg(all(feature = "singlepass", feature = "llvm"))]
    if singlepass.is_some() && llvm.is_some() {
        assert_eq!(singlepass.as_ref().unwrap(), llvm.as_ref().unwrap());
    }
    #[cfg(all(feature = "cranelift", feature = "llvm"))]
    if cranelift.is_some() && llvm.is_some() {
        assert_eq!(cranelift.as_ref().unwrap(), llvm.as_ref().unwrap());
    }
}
fn test_transfer_leader() {
    let mut cluster = Cluster::with_node_count(3, None);
    let region_id = 2;
    let router0 = &cluster.routers[0];

    let mut req = router0.new_request_for(region_id);
    let admin_req = req.mut_admin_request();
    admin_req.set_cmd_type(AdminCmdType::ChangePeer);
    admin_req
        .mut_change_peer()
        .set_change_type(ConfChangeType::AddNode);
    let store_id = cluster.node(1).id();
    let peer1 = new_peer(store_id, 10);
    admin_req.mut_change_peer().set_peer(peer1.clone());
    let req_clone = req.clone();
    let resp = router0.admin_command(region_id, req_clone).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let epoch = req.get_header().get_region_epoch();
    let new_conf_ver = epoch.get_conf_ver() + 1;
    let leader_peer = req.get_header().get_peer().clone();
    let meta = router0
        .must_query_debug_info(region_id, Duration::from_secs(3))
        .unwrap();
    assert_eq!(meta.region_state.epoch.version, epoch.get_version());
    assert_eq!(meta.region_state.epoch.conf_ver, new_conf_ver);
    assert_eq!(meta.region_state.peers, vec![leader_peer, peer1.clone()]);
    let peer0_id = meta.raft_status.id;

    // So heartbeat will create a learner.
    cluster.dispatch(region_id, vec![]);
    let router1 = &cluster.routers[1];
    let meta = router1
        .must_query_debug_info(region_id, Duration::from_secs(3))
        .unwrap();
    assert_eq!(peer0_id, meta.raft_status.soft_state.leader_id);
    assert_eq!(meta.raft_status.id, peer1.id, "{:?}", meta);
    assert_eq!(meta.region_state.epoch.version, epoch.get_version());
    assert_eq!(meta.region_state.epoch.conf_ver, new_conf_ver);
    cluster.dispatch(region_id, vec![]);

    // Ensure follower has latest entries before transfer leader.
    put_data(region_id, &mut cluster, 0, 1, b"key1");

    // Perform transfer leader
    must_transfer_leader(&cluster, region_id, 0, 1, peer1);

    // Before transfer back to peer0, put some data again.
    put_data(region_id, &mut cluster, 1, 0, b"key2");

    // Perform transfer leader
    let store_id = cluster.node(0).id();
    must_transfer_leader(&cluster, region_id, 1, 0, new_peer(store_id, peer0_id));
}
fn test_node_leader_change_with_log_overlap() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 50;
    // disable compact log to make test more stable.
    cluster.cfg.raft_store.raft_log_gc_threshold = 1000;
    // We use three peers([1, 2, 3]) for this test.
    cluster.run();

    sleep_ms(500);

    // guarantee peer 1 is leader
    cluster.must_transfer_leader(1, new_peer(1, 1));

    // So peer 3 won't replicate any message of the region but still can vote.
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 3).msg_type(MessageType::MsgAppend),
    ));
    cluster.must_put(b"k1", b"v1");

    // peer 1 and peer 2 must have k1, but peer 3 must not.
    for i in 1..3 {
        let engine = cluster.get_engine(i);
        must_get_equal(&engine, b"k1", b"v1");
    }

    let engine3 = cluster.get_engine(3);
    must_get_none(&engine3, b"k1");

    // now only peer 1 and peer 2 can step to leader.
    // Make peer 1's msg won't be replicated,
    // so the proposed entries won't be committed.
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 1)
            .msg_type(MessageType::MsgAppend)
            .direction(Direction::Send),
    ));
    let put_msg = vec![new_put_cmd(b"k2", b"v2")];
    let region = cluster.get_region(b"");
    let mut put_req = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        put_msg,
        false,
    );
    put_req.mut_header().set_peer(new_peer(1, 1));
    let called = Arc::new(AtomicBool::new(false));
    let called_ = Arc::clone(&called);
    cluster
        .sim
        .rl()
        .get_node_router(1)
        .send_command(
            put_req,
            Callback::write(Box::new(move |resp: WriteResponse| {
                called_.store(true, Ordering::SeqCst);
                assert!(resp.response.get_header().has_error());
                assert!(resp.response.get_header().get_error().has_stale_command());
            })),
            RaftCmdExtraOpts::default(),
        )
        .unwrap();

    // Now let peer(1, 1) steps down. Can't use transfer leader here, because
    // it still has pending proposed entries.
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 1)
            .msg_type(MessageType::MsgHeartbeat)
            .direction(Direction::Send),
    ));
    // make sure k2 has not been committed.
    must_get_none(&cluster.get_engine(1), b"k2");

    // Here just use `must_transfer_leader` to wait for peer (2, 2) becomes leader.
    cluster.must_transfer_leader(1, new_peer(2, 2));

    must_get_none(&cluster.get_engine(2), b"k2");

    cluster.clear_send_filters();

    for _ in 0..50 {
        sleep_ms(100);
        if called.load(Ordering::SeqCst) {
            return;
        }
    }
    panic!("callback has not been called after 5s.");
}
fn test_normal() {
    let result = new_ucmd!().run();
    println!("env::var(CI).is_ok() = {}", env::var("CI").is_ok());

    for (key, value) in env::vars() {
        println!("{key}: {value}");
    }
    if (is_ci() || uucore::os::is_wsl_1()) && result.stderr_str().contains("no login name") {
        // ToDO: investigate WSL failure
        // In the CI, some server are failing to return logname.
        // As seems to be a configuration issue, ignoring it
        return;
    }

    result.success();
    assert!(!result.stdout_str().trim().is_empty());
}
fn ArrayVec_iteration() {
  let av = array_vec!([i32; 4] => 10, 11, 12, 13);

  let mut i = av.into_iter();
  assert_eq!(i.next(), Some(10));
  assert_eq!(i.next(), Some(11));
  assert_eq!(i.next(), Some(12));
  assert_eq!(i.next(), Some(13));
  assert_eq!(i.next(), None);

  let av = array_vec!([i32; 4] => 10, 11, 12, 13);

  let mut av2: ArrayVec<[i32; 4]> = av.clone().into_iter().collect();
  assert_eq!(av, av2);

  // IntoIterator for &mut ArrayVec
  for x in &mut av2 {
    *x = -*x;
  }

  // IntoIterator for &ArrayVec
  assert!(av.iter().zip(&av2).all(|(&a, &b)| a == -b));
}
fn test_undefined_roundtrip() {
    let v = Value::UNDEFINED;
    let v2 = Value::from_serializable(&v);
    assert!(v.is_undefined());
    assert!(v2.is_undefined());
}
fn builder_test() {
    let mut builder = OptionsBuilder::default();

    builder = builder.lossy(true);
    builder = builder.exponent(b'^');
    builder = builder.decimal_point(b',');
    builder = builder.nan_string(Some(b"nan"));
    builder = builder.inf_string(Some(b"Infinity"));
    builder = builder.infinity_string(Some(b"Infiniiiiiity"));

    assert_eq!(builder.get_lossy(), true);
    assert_eq!(builder.get_exponent(), b'^');
    assert_eq!(builder.get_decimal_point(), b',');
    assert_eq!(builder.get_nan_string(), Some("nan".as_bytes()));
    assert_eq!(builder.get_inf_string(), Some("Infinity".as_bytes()));
    assert_eq!(builder.get_infinity_string(), Some("Infiniiiiiity".as_bytes()));

    assert!(builder.is_valid());
    assert_eq!(builder.build(), Ok(unsafe { builder.build_unchecked() }));
}
fn test_block_size_with_suffix() {
    fn get_header(block_size: &str) -> String {
        let output = new_ucmd!()
            .args(&["-B", block_size, "--output=size"])
            .succeeds()
            .stdout_move_str();
        output.lines().next().unwrap().trim().to_string()
    }

    assert_eq!(get_header("K"), "1K-blocks");
    assert_eq!(get_header("M"), "1M-blocks");
    assert_eq!(get_header("G"), "1G-blocks");
    assert_eq!(get_header("1K"), "1K-blocks");
    assert_eq!(get_header("1M"), "1M-blocks");
    assert_eq!(get_header("1G"), "1G-blocks");
    assert_eq!(get_header("1KiB"), "1K-blocks");
    assert_eq!(get_header("1MiB"), "1M-blocks");
    assert_eq!(get_header("1GiB"), "1G-blocks");
    assert_eq!(get_header("1KB"), "1kB-blocks");
    assert_eq!(get_header("1MB"), "1MB-blocks");
    assert_eq!(get_header("1GB"), "1GB-blocks");
}
fn lower_n_mask_test() {
    assert_eq!(lower_n_mask(0u64), 0b0);
    assert_eq!(lower_n_mask(1u64), 0b1);
    assert_eq!(lower_n_mask(2u64), 0b11);
    assert_eq!(lower_n_mask(10u64), 0b1111111111);
    assert_eq!(lower_n_mask(32u64), 0b11111111111111111111111111111111);
}
fn test_copy_into_with_files_and_pattern_and_verification() {
    let sql = concat!(
        "COPY INTO my_company.emp_basic ",
        "FROM 'gcs://mybucket/./../a.csv' AS some_alias ",
        "FILES = ('file1.json', 'file2.json') ",
        "PATTERN = '.*employees0[1-5].csv.gz' ",
        "VALIDATION_MODE = RETURN_7_ROWS"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake {
            files,
            pattern,
            validation_mode,
            from_stage_alias,
            ..
        } => {
            assert_eq!(files.unwrap(), vec!["file1.json", "file2.json"]);
            assert_eq!(pattern.unwrap(), ".*employees0[1-5].csv.gz");
            assert_eq!(validation_mode.unwrap(), "RETURN_7_ROWS");
            assert_eq!(from_stage_alias.unwrap(), Ident::new("some_alias"));
        }
        _ => unreachable!(),
    }
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn lifecycle() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert!(pair.client_conn_mut(client_ch).using_ecn());
    assert!(pair.server_conn_mut(server_ch).using_ecn());

    const REASON: &[u8] = b"whee";
    info!("closing");
    pair.client.connections.get_mut(&client_ch).unwrap().close(
        pair.time,
        VarInt(42),
        REASON.into(),
    );
    pair.drive();
    assert_matches!(pair.server_conn_mut(server_ch).poll(),
                    Some(Event::ConnectionLost { reason: ConnectionError::ApplicationClosed(
                        ApplicationClose { error_code: VarInt(42), ref reason }
                    )}) if reason == REASON);
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert_eq!(pair.client.known_connections(), 0);
    assert_eq!(pair.client.known_cids(), 0);
    assert_eq!(pair.server.known_connections(), 0);
    assert_eq!(pair.server.known_cids(), 0);
}
fn parse_array() {
    let sql = "SELECT CAST(a AS ARRAY) FROM customer";
    let select = snowflake().verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("a"))),
            data_type: DataType::Array(ArrayElemTypeDef::None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );
}
fn lower_n_mask_test() {
    assert_eq!(mask::lower_n_mask(2), 0b11);
}
fn finish_stream_flow_control_reordered() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();

    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive_client(); // Send stream data
    pair.server.drive(pair.time, pair.client.addr); // Receive

    // Issue flow control credit
    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG
    );
    let _ = chunks.finalize();

    pair.server.drive(pair.time, pair.client.addr);
    pair.server.delay_outbound(); // Delay it

    pair.client_send(client_ch, s).finish().unwrap();
    pair.drive_client(); // Send FIN
    pair.server.drive(pair.time, pair.client.addr); // Acknowledge
    pair.server.finish_delay(); // Add flow control packets after
    pair.drive();

    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Stream(StreamEvent::Finished { id })) if id == s
    );
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);

    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(chunks.next(usize::MAX), Ok(None));
    let _ = chunks.finalize();
}
fn test_vessd_case() {
    let foo_vec = vec![Foo::Bar(0); 5];
    let foo_str = to_string(&foo_vec).unwrap();
    assert_eq!(foo_str.as_str(), "[0,0,0,0,0]");
    assert_eq!(from_str::<Vec<Foo>>(&foo_str).unwrap(), foo_vec);
}
fn test_unsafe_recovery_send_report() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);
    cluster.put(b"random_key1", b"random_val1").unwrap();

    // Blocks the raft apply process on store 1 entirely .
    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);
    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("on_handle_apply_store_1", move || {
        let _ = apply_triggered_tx.send(());
        let _ = apply_released_rx.recv();
    })
    .unwrap();

    // Manually makes an update, and wait for the apply to be triggered, to
    // simulate "some entries are committed but not applied" scenario.
    cluster.put(b"random_key2", b"random_val2").unwrap();
    apply_triggered_rx
        .recv_timeout(Duration::from_secs(1))
        .unwrap();

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);

    // Triggers the unsafe recovery store reporting process.
    let plan = pdpb::RecoveryPlan::default();
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    // No store report is sent, since there are peers have unapplied entries.
    for _ in 0..20 {
        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);
        sleep_ms(100);
    }

    // Unblocks the apply process.
    drop(apply_released_tx);

    // Store reports are sent once the entries are applied.
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    fail::remove("on_handle_apply_store_1");
}
fn not_apply_to_extension_nor_main_files() {
    let f = super::fixture().join("extension-alias");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        main_files: vec!["index.js".into()],
        extension_alias: vec![(".js".into(), vec![])],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("directory", f.clone(), "./dir2", "dir2/index.js"),
        ("file", f.clone(), "./dir2/index", "dir2/index.js"),
    ];

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        let expected = f.join(expected);
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn compute_float_f32_rounding() {
    // These test near-halfway cases for single-precision floats.
    assert_eq!(compute_float32(0, 16777216), (151, 0));
    assert_eq!(compute_float32(0, 16777217), (151, 0));
    assert_eq!(compute_float32(0, 16777218), (151, 1));
    assert_eq!(compute_float32(0, 16777219), (151, 2));
    assert_eq!(compute_float32(0, 16777220), (151, 2));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));
    assert_eq!(compute_float32(-10, 167772170000000000), (151, 0));
    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));
    // Let's check the lines to see if anything is different in table...
    assert_eq!(compute_float32(-10, 167772190000000000), (151, 2));
    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));
}
fn invalid_exponent_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.exponent(b'\x00');
    assert!(!builder.is_valid());
    builder = builder.exponent(b'\x7f');
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.exponent(b'^');
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
}
fn test_source_peer_read_delegate_after_apply() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_split(&cluster.get_region(b""), b"k2");
    let target = cluster.get_region(b"k1");
    let source = cluster.get_region(b"k3");

    cluster.must_transfer_leader(target.get_id(), find_peer(&target, 1).unwrap().to_owned());

    let on_destroy_peer_fp = "destroy_peer";
    fail::cfg(on_destroy_peer_fp, "pause").unwrap();

    // Merge finish means the leader of the target region have call
    // `on_ready_commit_merge`
    pd_client.must_merge(source.get_id(), target.get_id());

    // The source peer's `ReadDelegate` should not be removed yet and mark as
    // `pending_remove`
    assert!(
        cluster.store_metas[&1]
            .lock()
            .unwrap()
            .readers
            .get(&source.get_id())
            .unwrap()
            .pending_remove
    );

    fail::remove(on_destroy_peer_fp);
    // Wait for source peer is destroyed
    sleep_ms(100);

    assert!(
        cluster.store_metas[&1]
            .lock()
            .unwrap()
            .readers
            .get(&source.get_id())
            .is_none()
    );
}
fn parse_select_count_wildcard() {
    let sql = "SELECT COUNT(*) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Function(Function {
            name: ObjectName(vec![Ident::new("COUNT")]),
            args: vec![FunctionArg::Unnamed(FunctionArgExpr::Wildcard)],
            null_treatment: None,
            filter: None,
            over: None,
            distinct: false,
            special: false,
            order_by: vec![],
        }),
        expr_from_projection(only(&select.projection))
    );
}
fn batch_inscribe_can_create_one_inscription() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet inscribe --fee-rate 2.1 --batch batch.yaml")
    .write("inscription.txt", "Hello World")
    .write(
      "batch.yaml",
      "mode: shared-output\ninscriptions:\n- file: inscription.txt\n  metadata: 123\n  metaprotocol: foo",
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  let request = ord_server.request(format!("/content/{}", output.inscriptions[0].id));

  assert_eq!(request.status(), 200);
  assert_eq!(
    request.headers().get("content-type").unwrap(),
    "text/plain;charset=utf-8"
  );
  assert_eq!(request.text().unwrap(), "Hello World");

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    r".*<dt>metadata</dt>\s*<dd>\n    123\n  </dd>.*<dt>metaprotocol</dt>\s*<dd>foo</dd>.*",
  );
}
fn test_short_hex_suffix_no_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-l", "9", "-x", "onehundredlines.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x00"), "00\n01\n02\n03\n04\n05\n06\n07\n08\n");
    assert_eq!(at.read("x01"), "09\n10\n11\n12\n13\n14\n15\n16\n17\n");
    assert_eq!(at.read("x02"), "18\n19\n20\n21\n22\n23\n24\n25\n26\n");
    assert_eq!(at.read("x03"), "27\n28\n29\n30\n31\n32\n33\n34\n35\n");
    assert_eq!(at.read("x04"), "36\n37\n38\n39\n40\n41\n42\n43\n44\n");
    assert_eq!(at.read("x05"), "45\n46\n47\n48\n49\n50\n51\n52\n53\n");
    assert_eq!(at.read("x06"), "54\n55\n56\n57\n58\n59\n60\n61\n62\n");
    assert_eq!(at.read("x07"), "63\n64\n65\n66\n67\n68\n69\n70\n71\n");
    assert_eq!(at.read("x08"), "72\n73\n74\n75\n76\n77\n78\n79\n80\n");
    assert_eq!(at.read("x09"), "81\n82\n83\n84\n85\n86\n87\n88\n89\n");
    assert_eq!(at.read("x0a"), "90\n91\n92\n93\n94\n95\n96\n97\n98\n");
    assert_eq!(at.read("x0b"), "99\n");
}
fn test_notify() {
    let io_loop = Runtime::new().unwrap();
    let authority = create_example();
    let mut catalog = Catalog::new();
    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));

    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));
    let client = AsyncClient::new(stream, sender, None);
    let (mut client, bg) = io_loop.block_on(client).expect("client failed to connect");
    hickory_proto::spawn_bg(&io_loop, bg);

    let name = Name::from_str("ping.example.com").unwrap();

    let message =
        io_loop.block_on(client.notify(name, DNSClass::IN, RecordType::A, None::<RecordSet>));
    assert!(message.is_ok());
    let message = message.unwrap();
    assert_eq!(
        message.response_code(),
        ResponseCode::NotImp,
        "the catalog must support Notify now, update this"
    );
}
pub fn test_receiver_shutdown() {
    let port = alloc_port();
    let mut test_suite = TestSuite::new(resource_metering::Config {
        receiver_address: format!("127.0.0.1:{}", port),
        report_receiver_interval: ReadableDuration::secs(3),
        max_resource_groups: 5000,
        precision: ReadableDuration::secs(1),
    });
    test_suite.start_receiver_at(port);

    // Workload
    // [req-1, req-2]
    test_suite.setup_workload(vec!["req-1", "req-2"]);

    // | Receiver Alive |
    // |       o        |
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));

    // Workload
    // [req-3, req-4]
    test_suite.cancel_workload();
    test_suite.setup_workload(vec!["req-3", "req-4"]);

    // | Receiver Alive |
    // |       x        |
    test_suite.shutdown_receiver();
    test_suite.flush_receiver();
    sleep(Duration::from_millis(3500));
    assert!(test_suite.nonblock_receiver_all().is_empty());

    // | Receiver Alive |
    // |       o        |
    test_suite.start_receiver_at(port);
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-3"));
    assert!(res.contains_key("req-4"));
}
fn as_f32_test() {
    assert_eq!(f16::from_bits(1).as_f32(), 0.000000059604645);
    assert_eq!(f16::ZERO.as_f32(), 0.0f32);
    assert_eq!(f16::ZERO.to_bits(), 0);
    assert_eq!(f16::ONE.as_f32(), 1.0f32);
    assert_eq!(f16::ONE.to_bits(), (15 << 10));
    assert_eq!(f16::TWO.as_f32(), 2.0f32);
    assert_eq!(f16::TWO.to_bits(), (16 << 10));
    assert_eq!(f16::from_bits(14 << 10).as_f32(), 0.5f32);
    assert!(f16::NAN.as_f32().is_nan());
    assert!(f16::INFINITY.as_f32().is_inf());
    assert!(f16::NEG_INFINITY.as_f32().is_inf());
}
fn parse_scalar_function_in_projection() {
    let names = vec!["sqrt", "foo"];

    for function_name in names {
        // like SELECT sqrt(id) FROM foo
        let sql = dbg!(format!("SELECT {function_name}(id) FROM foo"));
        let select = verified_only_select(&sql);
        assert_eq!(
            &Expr::Function(Function {
                name: ObjectName(vec![Ident::new(function_name)]),
                args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(
                    Expr::Identifier(Ident::new("id"))
                ))],
                null_treatment: None,
                filter: None,
                over: None,
                distinct: false,
                special: false,
                order_by: vec![],
            }),
            expr_from_projection(only(&select.projection))
        );
    }
}
fn TinyVec_drain() {
  let mut tv: TinyVec<[i32; 10]> = Default::default();
  tv.push(1);
  tv.push(2);
  tv.push(3);

  assert_eq!(Vec::from_iter(tv.clone().drain(..)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().drain(..2)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(..3)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().drain(..=1)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(..=2)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().drain(0..)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().drain(1..)), vec![2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().drain(0..2)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(0..3)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().drain(1..2)), vec![2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(1..3)), vec![2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().drain(0..=1)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(0..=2)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().drain(1..=1)), vec![2]);
  assert_eq!(Vec::from_iter(tv.clone().drain(1..=2)), vec![2, 3]);
}
fn can_use_concat_to_push_to_array() {
    let mut tera = Tera::default();
    tera.add_raw_template(
        "tpl",
        r#"
{%- set ids = [] -%}
{% for i in range(end=5) -%}
{%- set_global ids = ids | concat(with=i) -%}
{%- endfor -%}
{{ids}}"#,
    )
    .unwrap();
    let context = Context::new();
    let result = tera.render("tpl", &context);

    assert_eq!(result.unwrap(), "[0, 1, 2, 3, 4]");
}
fn test_mv_arg_update_older_dest_not_older() {
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_mv_arg_update_none_file1";
    let new = "test_mv_arg_update_none_file2";
    let old_content = "file1 content\n";
    let new_content = "file2 content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("--update=older")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), new_content);
}
fn try_fast_path_test() {
    let mut number = Number {
        exponent: -4,
        mantissa: 12345,
        many_digits: false,
    };
    assert_eq!(number.try_fast_path::<f32>(), Some(1.2345));
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345));

    number.exponent = -10;
    assert_eq!(number.try_fast_path::<f32>(), Some(1.2345e-6));
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345e-6));

    number.exponent = -20;
    assert_eq!(number.try_fast_path::<f32>(), None);
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345e-16));

    number.exponent = -25;
    assert_eq!(number.try_fast_path::<f32>(), None);
    assert_eq!(number.try_fast_path::<f64>(), None);

    number.exponent = 12;
    assert_eq!(number.try_fast_path::<f32>(), Some(1.2345e16));
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345e16));

    number.exponent = 25;
    assert_eq!(number.try_fast_path::<f32>(), None);
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345e29));

    number.exponent = 32;
    assert_eq!(number.try_fast_path::<f32>(), None);
    assert_eq!(number.try_fast_path::<f64>(), Some(1.2345e36));

    number.exponent = 36;
    assert_eq!(number.try_fast_path::<f32>(), None);
    assert_eq!(number.try_fast_path::<f64>(), None);
}
fn batch_inscribe_with_multiple_inscriptions() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet inscribe --batch batch.yaml --fee-rate 55")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      "mode: shared-output\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n"
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let request = TestServer::spawn_with_args(&rpc_server, &[])
    .request(format!("/content/{}", output.inscriptions[0].id));
  assert_eq!(request.status(), 200);
  assert_eq!(
    request.headers().get("content-type").unwrap(),
    "text/plain;charset=utf-8"
  );
  assert_eq!(request.text().unwrap(), "Hello World");

  let request = TestServer::spawn_with_args(&rpc_server, &[])
    .request(format!("/content/{}", output.inscriptions[1].id));
  assert_eq!(request.status(), 200);
  assert_eq!(request.headers().get("content-type").unwrap(), "image/png");

  let request = TestServer::spawn_with_args(&rpc_server, &[])
    .request(format!("/content/{}", output.inscriptions[2].id));
  assert_eq!(request.status(), 200);
  assert_eq!(request.headers().get("content-type").unwrap(), "audio/wav");
}
fn test_mv_target_dir_single_source() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_mv_target_dir_single_source_dir";
    let file = "test_mv_target_dir_single_source_file";

    at.touch(file);
    at.mkdir(dir);
    ucmd.arg("-t").arg(dir).arg(file).succeeds().no_stderr();

    assert!(!at.file_exists(file));
    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn test_copy_into_with_transformations() {
    let sql = concat!(
        "COPY INTO my_company.emp_basic FROM ",
        "(SELECT t1.$1:st AS st, $1:index, t2.$1 FROM @schema.general_finished AS T) ",
        "FILES = ('file1.json', 'file2.json') ",
        "PATTERN = '.*employees0[1-5].csv.gz' ",
        "VALIDATION_MODE = RETURN_7_ROWS"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake {
            from_stage,
            from_transformations,
            ..
        } => {
            assert_eq!(
                from_stage,
                ObjectName(vec![Ident::new("@schema"), Ident::new("general_finished")])
            );
            assert_eq!(
                from_transformations.as_ref().unwrap()[0],
                StageLoadSelectItem {
                    alias: Some(Ident::new("t1")),
                    file_col_num: 1,
                    element: Some(Ident::new("st")),
                    item_as: Some(Ident::new("st"))
                }
            );
            assert_eq!(
                from_transformations.as_ref().unwrap()[1],
                StageLoadSelectItem {
                    alias: None,
                    file_col_num: 1,
                    element: Some(Ident::new("index")),
                    item_as: None
                }
            );
            assert_eq!(
                from_transformations.as_ref().unwrap()[2],
                StageLoadSelectItem {
                    alias: Some(Ident::new("t2")),
                    file_col_num: 1,
                    element: None,
                    item_as: None
                }
            );
        }
        _ => unreachable!(),
    }
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn test_parenthesized_tuple_member() {
    let source_code = r#"(a, (b))"#;
    let expr = parse_expression(source_code, "<filename>").unwrap();

    let tuple = expr.as_tuple_expr().unwrap();
    let member = tuple.elts.last().unwrap();

    let parenthesized = parenthesized_range(
        member.into(),
        tuple.into(),
        &CommentRanges::default(),
        source_code,
    );
    assert_eq!(parenthesized, Some(TextRange::new(4.into(), 7.into())));
}
fn test_split_separator_nl_lines() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--lines=2", "-t", "\n"])
        .pipe_in("1\n2\n3\n4\n5\n")
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\n2\n");
    assert_eq!(file_read(&at, "xab"), "3\n4\n");
    assert_eq!(file_read(&at, "xac"), "5\n");
    assert!(!at.plus("xad").exists());
}
fn overflow_incomplete_tuple() {
  assert_eq!(
    parser02(&b"3"[..]),
    Err(Err::Incomplete(Needed::new(18446744073709551615)))
  );
}
fn name_same_as_builtin_command() -> Result<()> {
    // a bare subcommand shouldn't run successfully
    let output = get_wasmtime_command()?
        .current_dir("tests/all/cli_tests")
        .arg("run")
        .output()?;
    assert!(!output.status.success());

    // a `--` prefix should let everything else get interpreted as a wasm
    // module and arguments, even if the module has a name like `run`
    let output = get_wasmtime_command()?
        .current_dir("tests/all/cli_tests")
        .arg("--")
        .arg("run")
        .output()?;
    assert!(output.status.success(), "expected success got {output:#?}");

    // Passing options before the subcommand should work and doesn't require
    // `--` to disambiguate
    let output = get_wasmtime_command()?
        .current_dir("tests/all/cli_tests")
        .arg("-Ccache=n")
        .arg("run")
        .output()?;
    assert!(output.status.success(), "expected success got {output:#?}");
    Ok(())
}
fn timeout_in_invoke() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/iloop-invoke.wat")?;
    let output = run_wasmtime_for_output(
        &[
            "run",
            "-Wtimeout=1ms",
            "-Ccache=n",
            wasm.path().to_str().unwrap(),
        ],
        None,
    )?;
    assert!(!output.status.success());
    assert_eq!(output.stdout, b"");
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("wasm trap: interrupt"),
        "bad stderr: {}",
        stderr
    );
    Ok(())
}
fn can_load_macro_in_parent_with_grandparent() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 }}{% endmacro hello %}"),
        ("grandparent", "{% block bob %}{% endblock bob %}"),
        ("parent", "{% extends \"grandparent\" %}{% import \"macros\" as macros %}{% block bob %}{{ macros::hello() }} - Hey{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{ super() }}{% endblock bob %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "1 - Hey".to_string());
}
fn test_pluralize() {
    use minijinja::context;

    let mut env = minijinja::Environment::new();

    env.add_filter("pluralize", pluralize);
    for (num, s) in [
        (0, "You have 0 messages."),
        (1, "You have 1 message."),
        (10, "You have 10 messages."),
    ] {
        assert_eq!(
            env.render_str(
                "You have {{ num_messages }} message{{ num_messages|pluralize }}.",
                context! {
                    num_messages => num,
                }
            )
            .unwrap(),
            s
        );
    }

    for (num, s) in [
        (0, "You have 0 walruses."),
        (1, "You have 1 walrus."),
        (10, "You have 10 walruses."),
    ] {
        assert_eq!(
            env.render_str(
                r#"You have {{ num_walruses }} walrus{{ num_walruses|pluralize(None, "es") }}."#,
                context! {
                    num_walruses => num,
                }
            )
            .unwrap(),
            s
        );
    }

    for (num, s) in [
        (0, "You have 0 cherries."),
        (1, "You have 1 cherry."),
        (10, "You have 10 cherries."),
    ] {
        assert_eq!(
            env.render_str(
                r#"You have {{ num_cherries }} cherr{{ num_cherries|pluralize("y", "ies") }}."#,
                context! {
                    num_cherries => num,
                }
            )
            .unwrap(),
            s
        );
    }

    assert_eq!(
        env.render_str(
            r#"You have {{ num_cherries|length }} cherr{{ num_cherries|pluralize("y", "ies") }}."#,
            context! {
                num_cherries => vec![(); 5],
            }
        )
        .unwrap(),
        "You have 5 cherries."
    );
    assert_eq!(
        env.render_str(
            r#"You have {{ num_cherries }} cherr{{ num_cherries|pluralize("y", "ies") }}."#,
            context! {
                num_cherries => 5,
            }
        )
        .unwrap(),
        "You have 5 cherries."
    );
    assert_eq!(
        env.render_str(
            r#"You have {{ num_cherries }} cherr{{ num_cherries|pluralize("y", "ies") }}."#,
            context! {
                num_cherries => 0.5f32,
            }
        )
        .unwrap_err()
        .to_string(),
        "invalid operation: Pluralize argument is not an integer, or a sequence / object with \
            a length but of type number (in <string>:1)",
    );
}
fn test_timeformat() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("TIME_FORMAT", "[hour]:[minute]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("1687624642.5|timeformat(format=format)")
        .unwrap();

    assert_eq!(
        expr.eval(context!(format => "short")).unwrap().to_string(),
        "18:37"
    );
    assert_eq!(
        expr.eval(context!(format => "medium")).unwrap().to_string(),
        "18:37"
    );
    assert_eq!(
        expr.eval(context!(format => "long")).unwrap().to_string(),
        "18:37:22"
    );
    assert_eq!(
        expr.eval(context!(format => "full")).unwrap().to_string(),
        "18:37:22.5"
    );
    assert_eq!(
        expr.eval(context!(format => "unix")).unwrap().to_string(),
        "1687624642"
    );
    assert_eq!(
        expr.eval(context!(format => "iso")).unwrap().to_string(),
        "2023-06-24T18:37:22+02:00"
    );

    let expr = env
        .compile_expression("1687624642|timeformat(tz='Europe/Moscow')")
        .unwrap();
    assert_eq!(expr.eval(()).unwrap().to_string(), "19:37");
}
fn preview_enabled_prefix() {
    // E741 and E225 (preview) should both be detected
    let args = ["--select", "E", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    -:1:2: E225 [*] Missing whitespace around operator
    Found 2 errors.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn lint_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "lint_help",
        fs,
        console,
        result,
    ));
}
fn server_streamowned_handshake_error() {
    let (client_config, server_config) = make_disjoint_suite_configs();
    let (mut client, server) = make_pair_for_configs(client_config, server_config);

    client
        .writer()
        .write_all(b"world")
        .unwrap();

    let pipe = OtherSession::new_fails(&mut client);
    let mut server_stream = StreamOwned::new(server, pipe);
    let mut bytes = [0u8; 5];
    let rc = server_stream.read(&mut bytes);
    assert!(rc.is_err());
    assert_eq!(
        format!("{:?}", rc),
        "Err(Custom { kind: InvalidData, error: PeerIncompatible(NoCipherSuitesInCommon) })"
    );
}
fn mismatched_arguments() -> Result<()> {
    let mut store = Store::<()>::default();
    let binary = wat::parse_str(
        r#"
            (module $a
                (func (export "foo") (param i32))
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let func = instance.get_func(&mut store, "foo").unwrap();
    assert_eq!(
        func.call(&mut store, &[], &mut []).unwrap_err().to_string(),
        "expected 1 arguments, got 0"
    );
    assert_eq!(
        func.call(&mut store, &[Val::F32(0)], &mut [])
            .unwrap_err()
            .to_string(),
        "argument type mismatch: found f32 but expected i32",
    );
    assert_eq!(
        func.call(&mut store, &[Val::I32(0), Val::I32(1)], &mut [])
            .unwrap_err()
            .to_string(),
        "expected 1 arguments, got 2"
    );
    Ok(())
}
fn files_max_size_parse_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--files-max-size=-1"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "files_max_size_parse_error",
        fs,
        console,
        result,
    ));
}
fn drop_func() -> Result<()> {
    static HITS: AtomicUsize = AtomicUsize::new(0);
    struct A;

    impl Drop for A {
        fn drop(&mut self) {
            HITS.fetch_add(1, SeqCst);
        }
    }

    let engine = Engine::default();
    let mut linker = Linker::<()>::new(&engine);
    linker.allow_shadowing(true);

    let a = A;
    linker.func_wrap("", "", move || {
        let _ = &a;
    })?;

    assert_eq!(HITS.load(SeqCst), 0);

    // Define the function again to ensure redefined functions are dropped

    let a = A;
    linker.func_wrap("", "", move || {
        let _ = &a;
    })?;

    assert_eq!(HITS.load(SeqCst), 1);

    drop(linker);

    assert_eq!(HITS.load(SeqCst), 2);

    Ok(())
}
fn parse_json_using_colon() {
    let sql = "SELECT a:b FROM t";
    let select = snowflake().verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::JsonAccess {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            operator: JsonOperator::Colon,
            right: Box::new(Expr::Value(Value::UnQuotedString("b".to_string()))),
        }),
        select.projection[0]
    );

    let sql = "SELECT a:type FROM t";
    let select = snowflake().verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::JsonAccess {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            operator: JsonOperator::Colon,
            right: Box::new(Expr::Value(Value::UnQuotedString("type".to_string()))),
        }),
        select.projection[0]
    );

    let sql = "SELECT a:location FROM t";
    let select = snowflake().verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::JsonAccess {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            operator: JsonOperator::Colon,
            right: Box::new(Expr::Value(Value::UnQuotedString("location".to_string()))),
        }),
        select.projection[0]
    );

    let sql = "SELECT a:date FROM t";
    let select = snowflake().verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::JsonAccess {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            operator: JsonOperator::Colon,
            right: Box::new(Expr::Value(Value::UnQuotedString("date".to_string()))),
        }),
        select.projection[0]
    );

    snowflake().one_statement_parses_to("SELECT a:b::int FROM t", "SELECT CAST(a:b AS INT) FROM t");
}
fn format_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
indent-width = 8
line-length = 84

[format]
indent-style = "tab"
quote-style = "single"
skip-magic-trailing-comma = true
line-ending = "cr-lf"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["format", "--config"])
        .arg(&ruff_toml)
        .arg("-")
        .pass_stdin(r#"
def foo(arg1, arg2,):
    print("Shouldn't change quotes. It exceeds the line width with the tab size 8")


if condition:

    print("Should change quotes")

"#), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    def foo(arg1, arg2):
        print(
            "Shouldn't change quotes. It exceeds the line width with the tab size 8"
        )


    if condition:
        print('Should change quotes')

    ----- stderr -----
    "###);
    Ok(())
}
fn struct_ignored_fields() {
    #[derive(CacheKey)]
    struct NamedFieldsStruct {
        a: String,
        #[cache_key(ignore)]
        #[allow(unused)]
        b: String,
    }

    impl Hash for NamedFieldsStruct {
        fn hash<H: Hasher>(&self, state: &mut H) {
            self.a.hash(state);
        }
    }

    let mut key = CacheKeyHasher::new();

    let named_fields = NamedFieldsStruct {
        a: "Hello".into(),
        b: "World".into(),
    };

    named_fields.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    named_fields.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn test_install_target_new_file_with_owner() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "file";
    let dir = "target_dir";
    let uid = geteuid();

    at.touch(file);
    at.mkdir(dir);
    let result = ucmd
        .arg(file)
        .arg("--owner")
        .arg(uid.to_string())
        .arg(format!("{dir}/{file}"))
        .run();

    if is_ci() && result.stderr_str().contains("no such user:") {
        // In the CI, some server are failing to return the user id.
        // As seems to be a configuration issue, ignoring it
        return;
    }

    result.success();
    assert!(at.file_exists(file));
    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn max_diagnostics_default() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    for i in 0..60 {
        let file_path = PathBuf::from(format!("src/file_{i}.js"));
        fs.insert(file_path, UNFORMATTED.as_bytes());
    }

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), ("src")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut diagnostic_count = 0;
    let mut filtered_messages = Vec::new();

    for msg in console.out_buffer {
        let MarkupBuf(nodes) = &msg.content;
        let is_diagnostic = nodes.iter().any(|node| {
            node.content
                .contains("File content differs from formatting output")
                || node.content.contains("format")
                || node.content.contains("lint")
                || node.content.contains("ci")
        });

        if is_diagnostic {
            diagnostic_count += 1;
        } else {
            filtered_messages.push(msg);
        }
    }

    console.out_buffer = filtered_messages;

    for i in 0..60 {
        let file_path = format!("src/file_{i}.js");
        fs.remove(Path::new(&file_path));
    }

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "max_diagnostics_default",
        fs,
        console,
        result,
    ));

    assert_eq!(diagnostic_count, 20);
}
fn exclude() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-select = ["B", "Q"]
extend-exclude = ["out"]

[lint]
exclude = ["test.py", "generated.py"]

[lint.flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    fs::write(
        tempdir.path().join("main.py"),
        r#"
from test import say_hy

if __name__ == "__main__":
    say_hy("dear Ruff contributor")
"#,
    )?;

    // Excluded file but passed to the CLI directly, should be linted
    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    fs::write(
        tempdir.path().join("generated.py"),
        r#"NUMBERS = [
     0,  1,  2,  3,  4,  5,  6,  7,  8,  9,
    10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
OTHER = "OTHER"
"#,
    )?;

    let out_dir = tempdir.path().join("out");
    fs::create_dir(&out_dir)?;

    fs::write(out_dir.join("a.py"), r#"a = "a""#)?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .arg("check")
        .args(STDIN_BASE_OPTIONS)
        .args(["--config", &ruff_toml.file_name().unwrap().to_string_lossy()])
        // Explicitly pass test.py, should be linted regardless of it being excluded by lint.exclude
        .arg(test_path.file_name().unwrap())
        // Lint all other files in the directory, should respect the `exclude` and `lint.exclude` options
        .arg("."), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    main.py:4:16: Q000 [*] Double quotes found but single quotes preferred
    main.py:5:12: Q000 [*] Double quotes found but single quotes preferred
    test.py:3:15: Q000 [*] Double quotes found but single quotes preferred
    Found 3 errors.
    [*] 3 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
async fn read_preface_in_multiple_frames() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .read(b"PRI * HTTP/2.0")
        .read(b"\r\n\r\nSM\r\n\r\n")
        .write(SETTINGS)
        .read(SETTINGS)
        .write(SETTINGS_ACK)
        .read(SETTINGS_ACK)
        .build();

    let mut h2 = server::handshake(mock).await.unwrap();

    assert!(h2.next().await.is_none());
}
fn test_min_and_max() {
    assert_eq!(f64::from_bits(0x7fefffffffffffff), 1.7976931348623157e308);
    check!(1.7976931348623157e308);
    assert_eq!(f64::from_bits(1), 5e-324);
    check!(5e-324);
}
fn nursery_all() {
    // `--select ALL` should detect E741, but not E225, which is in the nursery.
    let args = ["--select", "ALL"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    -:1:1: D100 Missing docstring in public module
    Found 2 errors.

    ----- stderr -----
    warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
    warning: `multi-line-summary-first-line` (D212) and `multi-line-summary-second-line` (D213) are incompatible. Ignoring `multi-line-summary-second-line`.
    "###);
}
fn parse_test() {
    let ast = parse("{{ a is divisibleby(2) }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Test(Test {
                ident: "a".to_string(),
                negated: false,
                name: "divisibleby".to_string(),
                args: vec![Expr::new(ExprVal::Int(2))]
            }))
        )
    );
}
fn force_exclude() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-exclude = ["out"]

[format]
exclude = ["test.py", "generated.py"]
"#,
    )?;

    fs::write(
        tempdir.path().join("main.py"),
        r#"
from test import say_hy

if __name__ == "__main__":
    say_hy("dear Ruff contributor")
"#,
    )?;

    // Excluded file but passed to the CLI directly, should be formatted
    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    fs::write(
        tempdir.path().join("generated.py"),
        r#"NUMBERS = [
     0,  1,  2,  3,  4,  5,  6,  7,  8,  9,
    10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
OTHER = "OTHER"
"#,
    )?;

    let out_dir = tempdir.path().join("out");
    fs::create_dir(&out_dir)?;

    fs::write(out_dir.join("a.py"), "a = a")?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .args(["format", "--no-cache", "--force-exclude", "--check", "--config"])
        .arg(ruff_toml.file_name().unwrap())
        // Explicitly pass test.py, should be respect the `format.exclude` when `--force-exclude` is present
        .arg(test_path.file_name().unwrap())
        // Format all other files in the directory, should respect the `exclude` and `format.exclude` options
        .arg("."), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    Would reformat: main.py
    1 file would be reformatted

    ----- stderr -----
    "###);
    Ok(())
}
fn loop_interrupt_from_afar() -> anyhow::Result<()> {
    // Create an instance which calls an imported function on each iteration of
    // the loop so we can count the number of loop iterations we've executed so
    // far.
    static HITS: AtomicUsize = AtomicUsize::new(0);
    static STOP: AtomicBool = AtomicBool::new(false);
    let mut store = interruptable_store();
    let module = Module::new(
        store.engine(),
        r#"
            (import "" "" (func))

            (func (export "loop")
                (loop
                    call 0
                    br 0)
            )
        "#,
    )?;
    let func = Func::wrap(&mut store, || {
        HITS.fetch_add(1, SeqCst);
    });
    let instance = Instance::new(&mut store, &module, &[func.into()])?;

    // Use the engine to wait for it to enter the loop long enough and then we
    // signal an interrupt happens.
    let engine = store.engine().clone();
    let thread = std::thread::spawn(move || {
        while HITS.load(SeqCst) <= NUM_HITS && !STOP.load(SeqCst) {
            // continue ...
        }
        println!("interrupting");
        engine.increment_epoch();
    });

    // Enter the infinitely looping function and assert that our interrupt
    // handle does indeed actually interrupt the function.
    let iloop = instance.get_typed_func::<(), ()>(&mut store, "loop")?;
    let trap = iloop.call(&mut store, ()).unwrap_err().downcast::<Trap>()?;
    STOP.store(true, SeqCst);
    thread.join().unwrap();
    assert!(HITS.load(SeqCst) > NUM_HITS);
    assert_eq!(trap, Trap::Interrupt);
    Ok(())
}
fn test_mv_target_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_mv_target_dir_dir";
    let file_a = "test_mv_target_dir_file_a";
    let file_b = "test_mv_target_dir_file_b";

    at.touch(file_a);
    at.touch(file_b);
    at.mkdir(dir);
    ucmd.arg("-t")
        .arg(dir)
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
    assert!(at.file_exists(format!("{dir}/{file_a}")));
    assert!(at.file_exists(format!("{dir}/{file_b}")));
}
fn funcs_live_on_to_fight_another_day() -> Result<()> {
    struct DropMe(Arc<AtomicUsize>);

    impl Drop for DropMe {
        fn drop(&mut self) {
            self.0.fetch_add(1, SeqCst);
        }
    }

    let flag = Arc::new(AtomicUsize::new(0));
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    let drop_me = DropMe(flag.clone());
    linker.func_wrap("", "", move || {
        let _ = &drop_me;
    })?;
    assert_eq!(flag.load(SeqCst), 0);

    let get_and_call = || -> Result<()> {
        assert_eq!(flag.load(SeqCst), 0);
        let mut store = Store::new(&engine, ());
        let func = linker.get(&mut store, "", "").unwrap();
        func.into_func().unwrap().call(&mut store, &[], &mut [])?;
        assert_eq!(flag.load(SeqCst), 0);
        Ok(())
    };

    get_and_call()?;
    get_and_call()?;
    drop(linker);
    assert_eq!(flag.load(SeqCst), 1);
    Ok(())
}
fn tsconfig() {
    let f = super::fixture_root().join("parcel");

    #[rustfmt::skip]
    let pass = [
        (f.clone(), "ts-path", f.join("foo.js")),
        (f.join("nested"), "ts-path", f.join("nested/test.js")),
        (f.join("tsconfig/index"), "foo", f.join("node_modules/tsconfig-index/foo.js")),
        // This requires reading package.json.tsconfig field
        // (f.join("tsconfig/field"), "foo", f.join("node_modules/tsconfig-field/foo.js"))
        (f.join("tsconfig/exports"), "foo", f.join("node_modules/tsconfig-exports/foo.js")),
        (f.join("tsconfig/extends-extension"), "foo", f.join("tsconfig/extends-extension/foo.js")),
        (f.join("tsconfig/extends-extensionless"), "foo", f.join("node_modules/tsconfig-field/foo.js"))
    ];

    for (path, request, expected) in pass {
        let resolver = Resolver::new(ResolveOptions {
            tsconfig: Some(TsconfigOptions {
                config_file: path.join("tsconfig.json"),
                references: TsconfigReferences::Auto,
            }),
            ..ResolveOptions::default()
        });
        let resolved_path = resolver.resolve(&path, request).map(|f| f.full_path());
        assert_eq!(resolved_path, Ok(expected), "{request} {path:?}");
    }

    #[rustfmt::skip]
    let data = [
        (f.join("node_modules/tsconfig-not-used"), "ts-path", Ok(f.join("foo.js"))),
    ];

    let resolver = Resolver::new(ResolveOptions {
        tsconfig: Some(TsconfigOptions {
            config_file: f.join("tsconfig.json"),
            references: TsconfigReferences::Auto,
        }),
        ..ResolveOptions::default()
    });
    for (path, request, expected) in data {
        let resolution = resolver.resolve(&path, request).map(|f| f.full_path());
        assert_eq!(resolution, expected, "{path:?} {request}");
    }
}
fn from_f32_test() {
    assert_eq!(
        compact::from_float(0.0f32),
        ExtendedFloat80 {
            mant: 0,
            exp: -149
        }
    );
    assert_eq!(
        compact::from_float(-0.0f32),
        ExtendedFloat80 {
            mant: 0,
            exp: -149
        }
    );
    assert_eq!(
        compact::from_float(1e-45f32),
        ExtendedFloat80 {
            mant: 1,
            exp: -149
        }
    );
    assert_eq!(
        compact::from_float(1e-40f32),
        ExtendedFloat80 {
            mant: 71362,
            exp: -149
        }
    );
    assert_eq!(
        compact::from_float(2e-40f32),
        ExtendedFloat80 {
            mant: 142725,
            exp: -149
        }
    );
    assert_eq!(
        compact::from_float(1e-20f32),
        ExtendedFloat80 {
            mant: 12379400,
            exp: -90
        }
    );
    assert_eq!(
        compact::from_float(2e-20f32),
        ExtendedFloat80 {
            mant: 12379400,
            exp: -89
        }
    );
    assert_eq!(
        compact::from_float(1.0f32),
        ExtendedFloat80 {
            mant: 8388608,
            exp: -23
        }
    );
    assert_eq!(
        compact::from_float(2.0f32),
        ExtendedFloat80 {
            mant: 8388608,
            exp: -22
        }
    );
    assert_eq!(
        compact::from_float(1e20f32),
        ExtendedFloat80 {
            mant: 11368684,
            exp: 43
        }
    );
    assert_eq!(
        compact::from_float(2e20f32),
        ExtendedFloat80 {
            mant: 11368684,
            exp: 44
        }
    );
    assert_eq!(
        compact::from_float(3.402823e38f32),
        ExtendedFloat80 {
            mant: 16777213,
            exp: 104
        }
    );
}
fn test_touch_set_both_date_and_reference() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ref_file = "test_touch_reference";
    let file = "test_touch_set_both_date_and_reference";

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501011234");

    at.touch(ref_file);
    set_file_times(&at, ref_file, start_of_year, start_of_year);
    assert!(at.file_exists(ref_file));

    ucmd.args(&["-d", "Thu Jan 01 12:34:00 2015", "-r", ref_file, file])
        .succeeds()
        .no_stderr();
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, start_of_year);
    assert_eq!(mtime, start_of_year);
}
async fn reject_authority_target_on_extended_connect_request() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;

        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));

        client
            .send_frame(
                frames::headers(1)
                    .request("CONNECT", "bread:80")
                    .protocol("the-bread-protocol"),
            )
            .await;

        client.recv_frame(frames::reset(1).protocol_error()).await;
    };

    let srv = async move {
        let mut builder = server::Builder::new();

        builder.enable_connect_protocol();

        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");

        assert!(srv.next().await.is_none());

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn test_ingest_key_manager_delete_file_failed() {
    // test with tde
    let (_tmp_key_dir, cluster, ctx, _tikv, import) = new_cluster_and_tikv_import_client_tde();

    let temp_dir = Builder::new()
        .prefix("test_download_sst_blocking_sst_writer")
        .tempdir()
        .unwrap();
    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());

    upload_sst(&import, &meta, &data).unwrap();

    let deregister_fp = "key_manager_fails_before_delete_file";
    // the first delete is in check before ingest, the second is in ingest cleanup
    // set the ingest clean up failed to trigger remove file but not remove key
    // condition
    fail::cfg(deregister_fp, "1*off->1*return->off").unwrap();

    // Do an ingest and verify the result is correct. Though the ingest succeeded,
    // the clone file is still in the key manager
    // TODO: how to check the key manager contains the clone key
    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.set_sst(meta.clone());
    let resp = import.ingest(&ingest).unwrap();

    assert!(!resp.has_error());

    fail::remove(deregister_fp);

    let node_id = *cluster.sim.rl().get_node_ids().iter().next().unwrap();
    let save_path = cluster
        .sim
        .rl()
        .importers
        .get(&node_id)
        .unwrap()
        .get_path(&meta);
    // wait up to 5 seconds to make sure raw uploaded file is deleted by the async
    // clean up task.
    for _ in 0..50 {
        if !save_path.as_path().exists() {
            break;
        }
        std::thread::sleep(Duration::from_millis(100));
    }
    assert!(!save_path.as_path().exists());

    // Do upload and ingest again, though key manager contains this file, the ingest
    // action should success.
    upload_sst(&import, &meta, &data).unwrap();
    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx);
    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error());
}
fn parse_select_all_distinct() {
    let result = parse_sql_statements("SELECT ALL DISTINCT name FROM customer");
    assert_eq!(
        ParserError::ParserError("Cannot specify both ALL and DISTINCT".to_string()),
        result.unwrap_err(),
    );
}
fn render_filter_section_inheritance() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("top", "{% filter upper %}hello {% block main %}top{% endblock main %}{% endfilter %}"),
        ("bottom", "{% extends 'top' %}{% block main %}bottom{% endblock %}"),
    ])
    .unwrap();
    let result = tera.render("bottom", &Context::new());

    assert_eq!(result.unwrap(), "HELLO BOTTOM".to_string());
}
fn test_get() {
    let tag = "tag_get";

    let (test_suite, mut store, _) = setup_test_suite();
    fail::cfg_callback("point_getter_get", || cpu_load(Duration::from_millis(100))).unwrap();
    defer!(fail::remove("point_getter_get"));

    let jh = test_suite
        .rt
        .spawn(require_cpu_time_not_zero(&test_suite, tag));

    let table = ProductTable::new();
    let insert = prepare_insert(&mut store, &table);
    insert.execute();
    store.commit();

    let storage = store.get_storage();
    for (k, v) in store.export() {
        let mut ctx = Context::default();
        ctx.set_resource_group_tag(tag.as_bytes().to_vec());
        assert_eq!(
            storage
                .get(ctx, &Key::from_raw(&k), TimeStamp::max())
                .unwrap()
                .0
                .unwrap()
                .as_slice(),
            v.as_slice()
        );
    }

    assert!(block_on(jh).unwrap());
}
fn u8_decimal_test() {
    assert_eq!(Ok(0), u8::from_lexical(b"0"));
    assert_eq!(Ok(127), u8::from_lexical(b"127"));
    assert_eq!(Ok(128), u8::from_lexical(b"128"));
    assert_eq!(Ok(255), u8::from_lexical(b"255"));
    assert_eq!(Err(Error::InvalidDigit(0)), u8::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), u8::from_lexical(b"1a"));
}
fn test_async_apply_prewrite_fallback() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();

    let engine = cluster
        .sim
        .read()
        .unwrap()
        .storages
        .get(&1)
        .unwrap()
        .clone();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .async_apply_prewrite(true)
        .build()
        .unwrap();

    let mut ctx = Context::default();
    ctx.set_region_id(1);
    ctx.set_region_epoch(cluster.get_region_epoch(1));
    ctx.set_peer(cluster.leader_of_region(1).unwrap());

    let before_async_apply_prewrite_finish = "before_async_apply_prewrite_finish";
    let on_handle_apply = "on_handle_apply";

    fail::cfg(before_async_apply_prewrite_finish, "return()").unwrap();
    fail::cfg(on_handle_apply, "pause").unwrap();

    let (key, value) = (b"k1", b"v1");
    let (tx, rx) = channel();
    storage
        .sched_txn_command(
            commands::Prewrite::new(
                vec![Mutation::make_put(Key::from_raw(key), value.to_vec())],
                key.to_vec(),
                10.into(),
                0,
                false,
                1,
                0.into(),
                0.into(),
                Some(vec![]),
                false,
                AssertionLevel::Off,
                ctx.clone(),
            ),
            Box::new(move |r| tx.send(r).unwrap()),
        )
        .unwrap();

    assert_eq!(
        rx.recv_timeout(Duration::from_millis(200)).unwrap_err(),
        RecvTimeoutError::Timeout
    );

    fail::remove(on_handle_apply);

    let res = rx.recv().unwrap().unwrap();
    assert!(res.min_commit_ts > 10.into());

    fail::remove(before_async_apply_prewrite_finish);

    let (tx, rx) = channel();
    storage
        .sched_txn_command(
            commands::Commit::new(vec![Key::from_raw(key)], 10.into(), res.min_commit_ts, ctx),
            Box::new(move |r| tx.send(r).unwrap()),
        )
        .unwrap();

    rx.recv_timeout(Duration::from_secs(5)).unwrap().unwrap();
}
fn host_return_error_no_backtrace() -> Result<()> {
    let mut config = Config::new();
    config.wasm_backtrace(false);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, ());
    let module = Module::new(
        &engine,
        r#"
            (module
                (import "" "" (func $host))
                (func $foo (export "f") call $bar)
                (func $bar call $host)
            )
        "#,
    )?;
    let func = Func::wrap(&mut store, |_cx: Caller<'_, ()>| -> Result<()> {
        bail!("test")
    });
    let instance = Instance::new(&mut store, &module, &[func.into()])?;
    let f = instance.get_typed_func::<(), ()>(&mut store, "f")?;
    assert!(f.call(&mut store, ()).is_err());
    Ok(())
}
fn u64_test() {
    let mut buffer = [b'\x00'; 32];
    assert_eq!(b"0", 0u64.to_lexical(&mut buffer));
    assert_eq!(b"1", 1u64.to_lexical(&mut buffer));
    assert_eq!(b"5", 5u64.to_lexical(&mut buffer));
    assert_eq!(b"9223372036854775807", 9223372036854775807u64.to_lexical(&mut buffer));
    assert_eq!(b"9223372036854775808", 9223372036854775808u64.to_lexical(&mut buffer));
    assert_eq!(b"18446744073709551615", 18446744073709551615u64.to_lexical(&mut buffer));
    assert_eq!(b"18446744073709551615", (-1i64 as u64).to_lexical(&mut buffer));
}
fn test_witness_not_reported_while_disabled() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);
    assert_eq!(nodes[2], 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();

    cluster.must_put(b"k0", b"v0");

    // update region but the peer is not destroyed yet
    fail::cfg("change_peer_after_update_region_store_3", "pause").unwrap();

    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store3.clone());

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cmd(b"k0")],
        false,
    );
    request.mut_header().set_peer(peer_on_store3);
    request.mut_header().set_replica_read(true);

    let resp = cluster
        .read(None, request.clone(), Duration::from_millis(100))
        .unwrap();
    assert!(resp.get_header().has_error());
    assert!(!resp.get_header().get_error().has_is_witness());
    fail::remove("change_peer_after_update_region_store_3");
}
fn retry_on_retryable_error() {
    let handle = RetryDnsHandle::new(
        TestClient {
            retries: 1,
            error_response: ResolveError::from(std::io::Error::from(std::io::ErrorKind::TimedOut)),
            attempts: Arc::new(AtomicU16::new(0)),
        },
        2,
    );
    let test1 = Message::new();
    let result = block_on(handle.send(test1).first_answer()).expect("should have succeeded");
    assert_eq!(result.id(), 1); // this is checking the number of iterations the TestClient ran
}
fn parse_variable_tag_macro_call() {
    let ast = parse("{{ macros::get_time(some=1) }}").unwrap();
    let mut args = HashMap::new();
    args.insert("some".to_string(), Expr::new(ExprVal::Int(1)));

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::MacroCall(MacroCall {
                namespace: "macros".to_string(),
                name: "get_time".to_string(),
                args,
            },)),
        )
    );
}
fn test_rmdir_empty_directory_no_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir(DIR);

    ucmd.arg(DIR).succeeds().no_stderr();

    assert!(!at.dir_exists(DIR));
}
fn error_when_missing_macro_templates() {
    let mut tera = Tera::default();
    let result = tera.add_raw_templates(vec![(
        "parent",
        "{% import \"macros\" as macros %}{{ macros::hello() }}{% block bob %}{% endblock bob %}",
    )]);
    assert_eq!(
        result.unwrap_err().to_string(),
        "Template `parent` loads macros from `macros` which isn\'t present in Tera"
    );
}
fn parse_join_syntax_variants() {
    one_statement_parses_to(
        "SELECT c1 FROM t1 INNER JOIN t2 USING(c1)",
        "SELECT c1 FROM t1 JOIN t2 USING(c1)",
    );
    one_statement_parses_to(
        "SELECT c1 FROM t1 LEFT OUTER JOIN t2 USING(c1)",
        "SELECT c1 FROM t1 LEFT JOIN t2 USING(c1)",
    );
    one_statement_parses_to(
        "SELECT c1 FROM t1 RIGHT OUTER JOIN t2 USING(c1)",
        "SELECT c1 FROM t1 RIGHT JOIN t2 USING(c1)",
    );
    one_statement_parses_to(
        "SELECT c1 FROM t1 FULL OUTER JOIN t2 USING(c1)",
        "SELECT c1 FROM t1 FULL JOIN t2 USING(c1)",
    );

    let res = parse_sql_statements("SELECT * FROM a OUTER JOIN b ON 1");
    assert_eq!(
        ParserError::ParserError("Expected APPLY, found: JOIN".to_string()),
        res.unwrap_err()
    );
}
fn test_cp_arg_update_none() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("--update=none")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "How are you?\n");
}
fn format_stdin_with_errors() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--stdin-file-path"), ("mock.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_stdin_with_errors",
        fs,
        console,
        result,
    ));
}
fn compute_error_scaled64_test() {
    // These are the same examples above, just using pre-computed scaled values.

    // These test near-halfway cases for double-precision floats.
    assert_eq!(
        compute_error_scaled64(0, 4611686018427387904, 10),
        (1065 + INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388416, 10),
        (1065 + INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388928, 10),
        (1065 + INVALID_FP, 9223372036854777856)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427389440, 10),
        (1065 + INVALID_FP, 9223372036854778880)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427389952, 10),
        (1065 + INVALID_FP, 9223372036854779904)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427387904, 9),
        (1066 + INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388416, 9),
        (1066 + INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388928, 9),
        (1066 + INVALID_FP, 9223372036854777856)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427389440, 9),
        (1066 + INVALID_FP, 9223372036854778880)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427389952, 9),
        (1066 + INVALID_FP, 9223372036854779904)
    );

    // Test a much closer set of examples.
    assert_eq!(
        compute_error_scaled64(0, 9223372036854774784, 11),
        (1064 + INVALID_FP, 18446744073709549568)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388415, 0),
        (1075 + INVALID_FP, 9223372036854776830)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388416, 0),
        (1075 + INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error_scaled64(0, 4611686018427388416, 0),
        (1075 + INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error_scaled64(-42, 6510716281765748947, 10),
        (925 + INVALID_FP, 13021432563531497894)
    );
    assert_eq!(
        compute_error_scaled64(-43, 6510716281765749303, 7),
        (925 + INVALID_FP, 13021432563531498606)
    );
    assert_eq!(
        compute_error_scaled64(-42, 6510716281765749660, 10),
        (925 + INVALID_FP, 13021432563531499320)
    );

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(
        compute_error_scaled64(-3, 9223372036854775808, 1),
        (1065 + INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled64(-3, 9223372036854776832, 1),
        (1065 + INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error_scaled64(-3, 9223372036854777856, 1),
        (1065 + INVALID_FP, 9223372036854777856)
    );
    assert_eq!(
        compute_error_scaled64(-3, 9223372036854778880, 1),
        (1065 + INVALID_FP, 9223372036854778880)
    );
    assert_eq!(
        compute_error_scaled64(-3, 9223372036854779904, 1),
        (1065 + INVALID_FP, 9223372036854779904)
    );

    // Test from errors in atof.
    assert_eq!(
        compute_error_scaled64(-18, 9223373686122217470, 4),
        (1012 + INVALID_FP, 9223373686122217470)
    );

    // Check edge-cases from previous errors.
    assert_eq!(
        compute_error_scaled64(-342, 9223372036854775804, 2),
        (-64 + INVALID_FP, 18446744073709551608)
    );
}
fn remove_entry_multi_0() {
    let mut headers = HeaderMap::new();
    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 0);
    assert_eq!(headers.len(), 0);
}
fn exponent_limit_test() {
    assert_eq!(f32::exponent_limit(10), (-10, 10));
    assert_eq!(f64::exponent_limit(10), (-22, 22));
}
fn test_reconnect_limit() {
    let pd_client_reconnect_fp = "pd_client_reconnect";
    let (_server, client) = new_test_server_and_client(ReadableDuration::secs(100));

    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.
    thread::sleep(Duration::from_millis(200));

    // The first reconnection will succeed, and the last_update will not be updated.
    fail::cfg(pd_client_reconnect_fp, "return").unwrap();
    client.reconnect().unwrap();
    // The subsequent reconnection will be cancelled.
    for _ in 0..10 {
        let ret = client.reconnect();
        assert!(format!("{:?}", ret.unwrap_err()).contains("cancel reconnection"));
    }

    fail::remove(pd_client_reconnect_fp);
}
fn test_touch_set_date2() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_date";

    ucmd.args(&["-d", "2000-01-23", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "200001230000");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime, start_of_year);
    assert_eq!(mtime, start_of_year);
}
fn test_newtype_struct_name_mismatch() {
    assert_eq!(
        ron::from_str::<MyNewtypeStruct>("((true, 42))"),
        Ok(MyNewtypeStruct(MyTupleStruct(true, 42))),
    );
    assert_eq!(
        ron::from_str::<MyNewtypeStruct>("MyNewtypeStruct((true, 42))"),
        Ok(MyNewtypeStruct(MyTupleStruct(true, 42))),
    );
    assert_eq!(
        ron::from_str::<MyNewtypeStruct>("MyNewtypeStrucl((true, 42))"),
        Err(SpannedError {
            code: Error::ExpectedDifferentStructName {
                expected: "MyNewtypeStruct",
                found: String::from("MyNewtypeStrucl")
            },
            position: Position { line: 1, col: 16 }
        }),
    );
    assert_eq!(
        ron::from_str::<MyNewtypeStruct>("42"),
        Err(SpannedError {
            code: Error::ExpectedNamedStructLike("MyNewtypeStruct"),
            position: Position { line: 1, col: 1 }
        }),
    );
}
fn buffered_both_data_sent() {
    let server_config = Arc::new(make_server_config(KeyType::Rsa));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);

        assert_eq!(
            12,
            server
                .writer()
                .write(b"from-server!")
                .unwrap()
        );
        assert_eq!(
            12,
            client
                .writer()
                .write(b"from-client!")
                .unwrap()
        );

        do_handshake(&mut client, &mut server);

        transfer(&mut server, &mut client);
        client.process_new_packets().unwrap();
        transfer(&mut client, &mut server);
        server.process_new_packets().unwrap();

        check_read(&mut client.reader(), b"from-server!");
        check_read(&mut server.reader(), b"from-client!");
    }
}
fn client_streamowned_handshake_error() {
    let (client_config, server_config) = make_disjoint_suite_configs();
    let (client, mut server) = make_pair_for_configs(client_config, server_config);

    let pipe = OtherSession::new_fails(&mut server);
    let mut client_stream = StreamOwned::new(client, pipe);
    let rc = client_stream.write(b"hello");
    assert!(rc.is_err());
    assert_eq!(
        format!("{:?}", rc),
        "Err(Custom { kind: InvalidData, error: AlertReceived(HandshakeFailure) })"
    );
    let rc = client_stream.write(b"hello");
    assert!(rc.is_err());
    assert_eq!(
        format!("{:?}", rc),
        "Err(Custom { kind: InvalidData, error: AlertReceived(HandshakeFailure) })"
    );
}
fn bindgen_test_layout_lol_html_text_chunk_content_t() {
    const UNINIT: ::std::mem::MaybeUninit<lol_html_text_chunk_content_t> =
        ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<lol_html_text_chunk_content_t>(),
        16usize,
        concat!("Size of: ", stringify!(lol_html_text_chunk_content_t))
    );
    assert_eq!(
        ::std::mem::align_of::<lol_html_text_chunk_content_t>(),
        8usize,
        concat!("Alignment of ", stringify!(lol_html_text_chunk_content_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).data) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_text_chunk_content_t),
            "::",
            stringify!(data)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).len) as usize - ptr as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_text_chunk_content_t),
            "::",
            stringify!(len)
        )
    );
}
fn total_core_instances_limit() -> Result<()> {
    const INSTANCE_LIMIT: u32 = 10;
    let mut pool = crate::small_pool_config();
    pool.total_core_instances(INSTANCE_LIMIT);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    config.dynamic_memory_guard_size(0);
    config.static_memory_guard_size(0);
    config.static_memory_maximum_size(65536);

    let engine = Engine::new(&config)?;
    let module = Module::new(&engine, r#"(module)"#)?;

    // Instantiate to the limit
    {
        let mut store = Store::new(&engine, ());

        for _ in 0..INSTANCE_LIMIT {
            Instance::new(&mut store, &module, &[])?;
        }

        match Instance::new(&mut store, &module, &[]) {
            Ok(_) => panic!("instantiation should fail"),
            Err(e) => assert_eq!(
                e.to_string(),
                format!(
                    "maximum concurrent core instance limit of {} reached",
                    INSTANCE_LIMIT
                )
            ),
        }
    }

    // With the above store dropped, ensure instantiations can be made

    let mut store = Store::new(&engine, ());

    for _ in 0..INSTANCE_LIMIT {
        Instance::new(&mut store, &module, &[])?;
    }

    Ok(())
}
fn read_info() {
    let path = Path::new("tests").join("reftest").join("images").join("mozilla").join("jpg-progressive.jpg");

    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    let ref_data = decoder.decode().unwrap();
    let ref_info = decoder.info().unwrap();

    decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    decoder.read_info().unwrap();
    let info = decoder.info().unwrap();
    let data = decoder.decode().unwrap();

    assert_eq!(info, decoder.info().unwrap());
    assert_eq!(info, ref_info);
    assert_eq!(data, ref_data);
}
fn parse_compound_expr_2() {
    use self::BinaryOperator::*;
    use self::Expr::*;
    let sql = "a * b + c";
    assert_eq!(
        BinaryOp {
            left: Box::new(BinaryOp {
                left: Box::new(Identifier(Ident::new("a"))),
                op: Multiply,
                right: Box::new(Identifier(Ident::new("b"))),
            }),
            op: Plus,
            right: Box::new(Identifier(Ident::new("c"))),
        },
        verified_expr(sql)
    );
}
fn run_is_an_alias_for_update() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  let tempdir = TempDir::new().unwrap();

  let index_path = tempdir.path().join("foo.redb");

  CommandBuilder::new(format!("--index {} index run", index_path.display()))
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Empty>();

  assert!(index_path.is_file())
}
fn test_write_batch_rollback() {
    let mut cluster = Cluster::default();
    let router = &mut cluster.routers[0];
    let header = Box::new(router.new_request_for(2).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");

    router.wait_applied_to_current_term(2, Duration::from_secs(3));
    // Make several entries to batch in apply thread.
    fail::cfg("APPLY_COMMITTED_ENTRIES", "pause").unwrap();

    // Good proposal should be committed.
    let (msg, mut sub0) = PeerMsg::simple_write(header.clone(), put.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub0.wait_proposed()));
    assert!(block_on(sub0.wait_committed()));

    // If the write batch is correctly initialized, next write should not contain
    // last result.
    put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key1", b"value");
    let (msg, mut sub1) = PeerMsg::simple_write(header.clone(), put.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub1.wait_proposed()));
    assert!(block_on(sub1.wait_committed()));

    fail::cfg("APPLY_PUT", "1*return()").unwrap();
    // Wake up and sleep in next committed entry.
    fail::remove("APPLY_COMMITTED_ENTRIES");
    // First apply will fail due to aborted. If write batch is initialized
    // correctly, correct response can be returned.
    let resp = block_on(sub0.result()).unwrap();
    assert!(
        resp.get_header()
            .get_error()
            .get_message()
            .contains("aborted"),
        "{:?}",
        resp
    );
    let resp = block_on(sub1.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    let snap = router.stale_snapshot(2);
    assert_matches!(snap.get_value(b"key"), Ok(None));
    assert_eq!(snap.get_value(b"key1").unwrap().unwrap(), b"value");

    fail::cfg("APPLY_COMMITTED_ENTRIES", "pause").unwrap();

    // Trigger error again, so an initialized write batch should be rolled back.
    put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key2", b"value");
    let (msg, mut sub0) = PeerMsg::simple_write(header.clone(), put.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub0.wait_proposed()));
    assert!(block_on(sub0.wait_committed()));

    // If the write batch is correctly rollbacked, next write should not contain
    // last result.
    put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key3", b"value");
    let (msg, mut sub1) = PeerMsg::simple_write(header, put.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub1.wait_proposed()));
    assert!(block_on(sub1.wait_committed()));

    fail::cfg("APPLY_PUT", "1*return()").unwrap();
    fail::remove("APPLY_COMMITTED_ENTRIES");
    let resp = block_on(sub0.result()).unwrap();
    assert!(
        resp.get_header()
            .get_error()
            .get_message()
            .contains("aborted"),
        "{:?}",
        resp
    );
    let resp = block_on(sub1.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let snap = router.stale_snapshot(2);
    assert_matches!(snap.get_value(b"key2"), Ok(None));
    assert_eq!(snap.get_value(b"key3").unwrap().unwrap(), b"value");
}
fn test_chroot_extra_arg() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    let dir = "CHROOT_DIR";
    at.mkdir(dir);
    let env_cd = std::env::current_dir().unwrap();
    // Verify that -P is pwd's and not chroot
    if let Ok(result) = run_ucmd_as_root(&ts, &[dir, "pwd", "-P"]) {
        assert_eq!(
            result.success().no_stderr().stdout_str(),
            env_cd.to_str().unwrap()
        );
    } else {
        print!("Test skipped; requires root user");
    }
}
fn is_empty() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        assert!(table.is_empty().unwrap());
        table.insert("hello", "world").unwrap();
        assert!(!table.is_empty().unwrap());
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert!(!table.is_empty().unwrap());
}
fn test_map() {
    let v = BTreeMap::<String, i32>::deserialize(Value::from_iter([
        ("foo", Value::from(1)),
        ("bar", Value::from(2)),
    ]))
    .unwrap();
    assert_eq!(
        v,
        BTreeMap::from_iter([("foo".to_string(), 1), ("bar".to_string(), 2)])
    );
}
fn test_get_var() {
    let result = TestScenario::new(util_name!())
        .ucmd()
        .env("KEY", "VALUE")
        .arg("KEY")
        .succeeds();

    assert!(!result.stdout_str().is_empty());
    assert_eq!(result.stdout_str().trim(), "VALUE");
}
fn test_touch_no_create_file_exists() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_no_create_file_exists";

    at.touch(file);
    assert!(at.file_exists(file));

    ucmd.arg("-c").arg(file).succeeds().no_stderr();

    assert!(at.file_exists(file));
}
fn test_placeholder() {
    let sql = "SELECT * FROM student WHERE id = ?";
    let ast = verified_only_select(sql);
    assert_eq!(
        ast.selection,
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Identifier(Ident::new("id"))),
            op: BinaryOperator::Eq,
            right: Box::new(Expr::Value(Value::Placeholder("?".into()))),
        })
    );

    let dialects = TestedDialects {
        dialects: vec![
            Box::new(GenericDialect {}),
            Box::new(DuckDbDialect {}),
            Box::new(PostgreSqlDialect {}),
            Box::new(MsSqlDialect {}),
            Box::new(AnsiDialect {}),
            Box::new(BigQueryDialect {}),
            Box::new(SnowflakeDialect {}),
            // Note: `$` is the starting word for the HiveDialect identifier
            // Box::new(sqlparser::dialect::HiveDialect {}),
        ],
        options: None,
    };
    let sql = "SELECT * FROM student WHERE id = $Id1";
    let ast = dialects.verified_only_select(sql);
    assert_eq!(
        ast.selection,
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Identifier(Ident::new("id"))),
            op: BinaryOperator::Eq,
            right: Box::new(Expr::Value(Value::Placeholder("$Id1".into()))),
        })
    );

    let sql = "SELECT * FROM student LIMIT $1 OFFSET $2";
    let ast = dialects.verified_query(sql);
    assert_eq!(
        ast.limit,
        Some(Expr::Value(Value::Placeholder("$1".into())))
    );
    assert_eq!(
        ast.offset,
        Some(Offset {
            value: Expr::Value(Value::Placeholder("$2".into())),
            rows: OffsetRows::None,
        }),
    );

    let sql = "SELECT $fromage_franais, :x, ?123";
    let ast = dialects.verified_only_select(sql);
    assert_eq!(
        ast.projection,
        vec![
            UnnamedExpr(Expr::Value(Value::Placeholder("$fromage_franais".into()))),
            UnnamedExpr(Expr::Value(Value::Placeholder(":x".into()))),
            UnnamedExpr(Expr::Value(Value::Placeholder("?123".into()))),
        ]
    );
}


fn test_restart_in_joint_state() {
    let mut cluster = new_node_cluster(0, 3);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region_id = cluster.run_conf_change();

    cluster.must_put(b"k1", b"v1");

    pd_client.must_add_peer(region_id, new_peer(2, 2));
    pd_client.must_add_peer(region_id, new_learner_peer(3, 3));
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");

    // Enter joint
    pd_client.must_joint_confchange(
        region_id,
        vec![
            (ConfChangeType::AddLearnerNode, new_learner_peer(2, 2)),
            (ConfChangeType::AddNode, new_peer(3, 3)),
        ],
    );
    assert!(pd_client.is_in_joint(region_id));

    cluster.stop_node(1);
    sleep_ms(50);

    cluster.run_node(1).unwrap();
    cluster.must_transfer_leader(1, new_peer(1, 1));

    // Still in joint state
    assert!(pd_client.is_in_joint(region_id));
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(2), b"k2", b"v2");
    must_get_equal(&cluster.get_engine(3), b"k2", b"v2");

    // Leave joint
    pd_client.must_leave_joint(region_id);

    // Joint confchange finished
    let region = cluster.get_region(b"k2");
    must_has_peer(&region, 1, PeerRole::Voter);
    must_has_peer(&region, 2, PeerRole::Learner);
    must_has_peer(&region, 3, PeerRole::Voter);
}
fn working_directory_is_correct() {
  let tmp = tempdir();

  fs::write(tmp.path().join("justfile"), "").unwrap();
  fs::write(tmp.path().join("bar"), "baz").unwrap();
  fs::create_dir(tmp.path().join("foo")).unwrap();

  let output = Command::new(executable_path("just"))
    .args(["--command", "cat", "bar"])
    .current_dir(tmp.path().join("foo"))
    .output()
    .unwrap();

  assert_eq!(str::from_utf8(&output.stderr).unwrap(), "");

  assert!(output.status.success());

  assert_eq!(str::from_utf8(&output.stdout).unwrap(), "baz");
}
fn test_cp_numbered_if_existing_backup_existing() {
    let (at, mut ucmd) = at_and_ucmd!();
    let existing_backup = &format!("{TEST_HOW_ARE_YOU_SOURCE}.~1~");
    at.touch(existing_backup);

    ucmd.arg("--backup=existing")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(TEST_HOW_ARE_YOU_SOURCE));
    assert!(at.file_exists(existing_backup));
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}.~2~")),
        "How are you?\n"
    );
}
fn test_effective_suffix_numeric_last() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&[
        "-n",
        "4",
        "--numeric-suffixes=7",
        "--hex-suffixes=4",
        "-d",
        "-x",
        "--numeric-suffixes=9",
        "threebytes.txt",
    ])
    .succeeds()
    .no_stdout()
    .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x10"), "b");
    assert_eq!(at.read("x11"), "c");
    assert_eq!(at.read("x12"), "");
}
fn parse_escaped_single_quote_string_predicate_with_no_escape() {
    use self::BinaryOperator::*;
    let sql = "SELECT id, fname, lname FROM customer \
               WHERE salary <> 'Jim''s salary'";

    let ast = TestedDialects {
        dialects: vec![Box::new(MySqlDialect {})],
        options: Some(
            ParserOptions::new()
                .with_trailing_commas(true)
                .with_unescape(false),
        ),
    }
    .verified_only_select(sql);

    assert_eq!(
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Identifier(Ident::new("salary"))),
            op: NotEq,
            right: Box::new(Expr::Value(Value::SingleQuotedString(
                "Jim''s salary".to_string()
            ))),
        }),
        ast.selection,
    );
}
fn test_i128_min() {
    assert_eq!(
        std::i128::MIN,
        from_str(&to_string(&std::i128::MIN).unwrap()).unwrap()
    );
}
fn test_split_separator_nl_line_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--line-bytes=4", "-t", "\n"])
        .pipe_in("1\n2\n3\n4\n5\n")
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\n2\n");
    assert_eq!(file_read(&at, "xab"), "3\n4\n");
    assert_eq!(file_read(&at, "xac"), "5\n");
    assert!(!at.plus("xad").exists());
}
fn memory_growth_failure() -> Result<()> {
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "-Wmemory64",
            "-Wtrap-on-grow-failure",
            "tests/all/cli_tests/memory-grow-failure.wat",
        ])
        .output()?;
    assert!(!output.status.success());
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("forcing a memory growth failure to be a trap"),
        "bad stderr: {stderr}"
    );
    Ok(())
}
fn line_too_long_width_override() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
line-length = 80
select = ["E501"]

[pycodestyle]
max-line-length = 100
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .arg("--config")
        .arg(&ruff_toml)
        .args(["--stdin-filename", "test.py"])
        .arg("-")
        .pass_stdin(r#"
# longer than 80, but less than 100
_ = "---------------------------------------------------------------------------"
# longer than 100
_ = "---------------------------------------------------------------------------"
"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    test.py:5:91: E501 Line too long (109 > 100)
    Found 1 error.

    ----- stderr -----
    "###);
    Ok(())
}

#[test]
fn per_file_ignores_stdin() ->
async fn test_catalog_lookup() {
    let example = create_example();
    let test = create_test();
    let origin = example.origin().clone();
    let test_origin = test.origin().clone();

    let mut catalog: Catalog = Catalog::new();
    catalog.upsert(origin.clone(), Box::new(Arc::new(example)));
    catalog.upsert(test_origin.clone(), Box::new(Arc::new(test)));

    let mut question: Message = Message::new();

    let mut query: Query = Query::new();
    query.set_name(origin.into());

    question.add_query(query);

    // temp request
    let question_bytes = question.to_bytes().unwrap();
    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();
    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);

    let response_handler = TestResponseHandler::new();
    catalog
        .lookup(&question_req, None, response_handler.clone())
        .await;
    let result = response_handler.into_message().await;

    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.message_type(), MessageType::Response);
    assert!(result.header().authoritative());

    let answers: &[Record] = result.answers();

    assert!(!answers.is_empty());
    assert_eq!(answers.first().unwrap().record_type(), RecordType::A);
    assert_eq!(
        answers.first().unwrap().data().unwrap(),
        &RData::A(A::new(93, 184, 216, 34))
    );

    let ns = result.name_servers();
    assert!(ns.is_empty());

    // other zone
    let mut question: Message = Message::new();
    let mut query: Query = Query::new();
    query.set_name(test_origin.into());

    question.add_query(query);

    // temp request
    let question_bytes = question.to_bytes().unwrap();
    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();
    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);

    let response_handler = TestResponseHandler::new();
    catalog
        .lookup(&question_req, None, response_handler.clone())
        .await;
    let result = response_handler.into_message().await;

    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.message_type(), MessageType::Response);
    assert!(result.header().authoritative());

    let answers: &[Record] = result.answers();

    assert!(!answers.is_empty());
    assert_eq!(answers.first().unwrap().record_type(), RecordType::A);
    assert_eq!(
        answers.first().unwrap().data().unwrap(),
        &RData::A(A::new(94, 184, 216, 34))
    );
}
fn test_lock() {
    let sql = "SELECT * FROM student WHERE id = '1' FOR UPDATE";
    let mut ast = verified_query(sql);
    assert_eq!(ast.locks.len(), 1);
    let lock = ast.locks.pop().unwrap();
    assert_eq!(lock.lock_type, LockType::Update);
    assert!(lock.of.is_none());
    assert!(lock.nonblock.is_none());

    let sql = "SELECT * FROM student WHERE id = '1' FOR SHARE";
    let mut ast = verified_query(sql);
    assert_eq!(ast.locks.len(), 1);
    let lock = ast.locks.pop().unwrap();
    assert_eq!(lock.lock_type, LockType::Share);
    assert!(lock.of.is_none());
    assert!(lock.nonblock.is_none());
}
fn trap_start_function_import() -> Result<()> {
    let mut store = Store::<()>::default();
    let binary = wat::parse_str(
        r#"
            (module $a
                (import "" "" (func $foo))
                (start $foo)
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let sig = FuncType::new(None, None);
    let func = Func::new(&mut store, sig, |_, _, _| bail!("user trap"));
    let err = Instance::new(&mut store, &module, &[func.into()]).unwrap_err();
    assert!(format!("{err:?}").contains("user trap"));
    Ok(())
}
fn render_super_in_grandchild_without_redefining_in_parent_works() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("grandparent", "{% block title %}Title{% endblock %}"),
        ("parent", "{% extends \"grandparent\" %}"),
        ("child", "{% extends \"parent\" %}{% block title %}{{ super() }} - More{% endblock %}"),
    ])
    .unwrap();

    let result = tera.render("child", &Context::new());
    assert_eq!(result.unwrap(), "Title - More".to_string());
}
fn test_read_hibernated_region() {
    let mut cluster = new_node_cluster(0, 3);
    // Initialize the cluster.
    configure_for_lease_read(&mut cluster.cfg, Some(100), Some(8));
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration(Duration::from_millis(1));
    cluster.cfg.raft_store.check_leader_lease_interval = ReadableDuration::hours(10);
    cluster.pd_client.disable_default_operator();
    let r1 = cluster.run_conf_change();
    let p2 = new_peer(2, 2);
    cluster.pd_client.must_add_peer(r1, p2.clone());
    let p3 = new_peer(3, 3);
    cluster.pd_client.must_add_peer(r1, p3.clone());
    cluster.must_put(b"k0", b"v0");
    let region = cluster.get_region(b"k0");
    cluster.must_transfer_leader(region.get_id(), p3);
    // Make sure leader writes the data.
    must_get_equal(&cluster.get_engine(3), b"k0", b"v0");
    // Wait for region is hibernated.
    thread::sleep(Duration::from_secs(1));
    cluster.stop_node(2);
    cluster.run_node(2).unwrap();

    let store2_sent_msgs = Arc::new(Mutex::new(Vec::new()));
    let filter = Box::new(
        RegionPacketFilter::new(1, 2)
            .direction(Direction::Send)
            .reserve_dropped(Arc::clone(&store2_sent_msgs)),
    );
    cluster.sim.wl().add_send_filter(2, filter);
    cluster.pd_client.trigger_leader_info_loss();
    // This request will fail because no valid leader.
    let resp1_ch = async_read_on_peer(&mut cluster, p2.clone(), region.clone(), b"k1", true, true);
    let resp1 = block_on_timeout(resp1_ch, Duration::from_secs(5)).unwrap();
    assert!(
        resp1.get_header().get_error().has_not_leader(),
        "{:?}",
        resp1.get_header()
    );
    thread::sleep(Duration::from_millis(300));
    cluster.sim.wl().clear_send_filters(2);
    let mut has_extra_message = false;
    for msg in std::mem::take(&mut *store2_sent_msgs.lock().unwrap()) {
        let to_store = msg.get_to_peer().get_store_id();
        assert_ne!(to_store, 0, "{:?}", msg);
        if to_store == 3 && msg.has_extra_msg() {
            has_extra_message = true;
        }
        let router = cluster.sim.wl().get_router(to_store).unwrap();
        router.send_raft_message(msg).unwrap();
    }
    // Had a wakeup message from 2 to 3.
    assert!(has_extra_message);
    // Wait for the leader is woken up.
    thread::sleep(Duration::from_millis(500));
    let resp2_ch = async_read_on_peer(&mut cluster, p2, region, b"k1", true, true);
    let resp2 = block_on_timeout(resp2_ch, Duration::from_secs(5)).unwrap();
    assert!(!resp2.get_header().has_error(), "{:?}", resp2);
}
fn test_skip_iter_itc() {
    // Test iterators that skip multiple, internal or trailing digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_trailing_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"_455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"__455");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"45.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"_45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"__45.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"_45.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"__45.56");
}
fn test_error_render_non_math() {
    let result = render_tpl("non_math_operation.html");

    assert!(result.is_err());
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Variable `username` was used in a math operation but is not a number"
    );
}
fn scalar_add_test() {
    assert_eq!(bigint::scalar_add(5, 5), (10, false));
    assert_eq!(bigint::scalar_add(Limb::MAX, 1), (0, true));
}
fn render_if_elif_else() {
    let mut context = Context::new();
    context.insert("is_true", &true);
    context.insert("is_false", &false);
    context.insert("age", &18);
    context.insert("name", &"john");
    context.insert("empty_string", &"");
    context.insert("numbers", &vec![1, 2, 3]);

    let inputs = vec![
        ("{% if is_true %}Admin{% endif %}", "Admin"),
        ("{% if is_true or age + 1 > 18 %}Adult{% endif %}", "Adult"),
        ("{% if is_true and age == 18 %}Adult{% endif %}", "Adult"),
        // https://github.com/Keats/tera/issues/187
        ("{% if 1 <= 2 %}a{% endif %}", "a"),
        ("{% if 2 >= 1 %}a{% endif %}", "a"),
        ("{% if 1 < 2 %}a{% endif %}", "a"),
        ("{% if 2 > 1 %}a{% endif %}", "a"),
        ("{% if 1 == 1 %}a{% endif %}", "a"),
        ("{% if 1 != 2 %}a{% endif %}", "a"),
        // testing string conditions
        ("{% if 'true' %}a{% endif %}", "a"),
        ("{% if name %}a{% endif %}", "a"),
        ("{% if '' %}a{% endif %}", ""),
        ("{% if empty_string %}a{% endif %}", ""),
        ("{% if '' ~ name %}a{% endif %}", "a"),
        ("{% if '' ~ empty_string %}a{% endif %}", ""),
        // some not conditions
        ("{% if not is_false %}a{% endif %}", "a"),
        ("{% if not is_true %}a{% endif %}", ""),
        ("{% if undefined %}a{% endif %}", ""),
        ("{% if not undefined %}a{% endif %}", "a"),
        ("{% if not is_false and is_true %}a{% endif %}", "a"),
        ("{% if not is_false or numbers | length > 0 %}a{% endif %}", "a"),
        // doesn't panic with NaN results
        ("{% if 0 / 0 %}a{% endif %}", ""),
        // if and else
        ("{% if is_true %}Admin{% else %}User{% endif %}", "Admin"),
        ("{% if is_false %}Admin{% else %}User{% endif %}", "User"),
        // if and elifs
        ("{% if is_true %}Admin{% elif is_false %}User{% endif %}", "Admin"),
        ("{% if is_true %}Admin{% elif is_true %}User{% endif %}", "Admin"),
        ("{% if is_true %}Admin{% elif numbers | length > 0 %}User{% endif %}", "Admin"),
        // if, elifs and else
        ("{% if is_true %}Admin{% elif is_false %}User{% else %}Hmm{% endif %}", "Admin"),
        ("{% if false %}Admin{% elif is_false %}User{% else %}Hmm{% endif %}", "Hmm"),
        // doesn't fallthrough elifs
        // https://github.com/Keats/tera/issues/188
        ("{% if 1 < 4 %}a{% elif 2 < 4 %}b{% elif 3 < 4 %}c{% else %}d{% endif %}", "a"),
        // with in operator
        (
            "{% if 1 in numbers %}Admin{% elif 100 in numbers %}User{% else %}Hmm{% endif %}",
            "Admin",
        ),
        ("{% if 100 in numbers %}Admin{% elif 1 in numbers %}User{% else %}Hmm{% endif %}", "User"),
        ("{% if 'n' in name %}Admin{% else %}Hmm{% endif %}", "Admin"),
        // function in if
        ("{% if get_true() %}Truth{% endif %}", "Truth"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_install_backup_nil() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=nil")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_unset_variable() {
    let out = TestScenario::new(util_name!())
        .ucmd()
        .env("HOME", "FOO")
        .arg("-u")
        .arg("HOME")
        .succeeds()
        .stdout_move_str();

    assert!(!out.lines().any(|line| line.starts_with("HOME=")));
}
fn inscriptions() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);
  rpc_server.mine_blocks(1);

  let (inscription, reveal) = inscribe(&rpc_server);

  let output = CommandBuilder::new("wallet inscriptions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<inscriptions::Output>>();

  assert_eq!(output.len(), 1);
  assert_eq!(output[0].inscription, inscription);
  assert_eq!(output[0].location, format!("{reveal}:0:0").parse().unwrap());
  assert_eq!(
    output[0].explorer,
    format!("https://ordinals.com/inscription/{inscription}")
  );

  let address = CommandBuilder::new("wallet receive")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<receive::Output>()
    .address;

  let txid = CommandBuilder::new(format!(
    "wallet send --fee-rate 1 {} {inscription}",
    address.assume_checked()
  ))
  .rpc_server(&rpc_server)
  .expected_exit_code(0)
  .stdout_regex(".*")
  .run_and_deserialize_output::<send::Output>()
  .transaction;

  rpc_server.mine_blocks(1);

  let output = CommandBuilder::new("wallet inscriptions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<inscriptions::Output>>();

  assert_eq!(output.len(), 1);
  assert_eq!(output[0].inscription, inscription);
  assert_eq!(output[0].location, format!("{txid}:0:0").parse().unwrap());
}
fn gzip_decoder_empty_read() {
    let original: &[u8] = b"Lorem ipsum dolor sit amet.";
    let mut encoder = flate2::write::GzEncoder::new(Vec::new(), flate2::Compression::default());
    encoder.write_all(original).unwrap();
    let encoded: Vec<u8> = encoder.finish().unwrap();
    let mut decoder = flate2::read::GzDecoder::new(encoded.as_slice());
    assert_eq!(decoder.read(&mut []).unwrap(), 0);
    let mut decoded = Vec::new();
    decoder.read_to_end(&mut decoded).unwrap();
    assert_eq!(decoded.as_slice(), original);
}
fn test_call_kwargs() {
    let mut env = Environment::new();
    env.add_template("foo", "").unwrap();
    let tmpl = env.get_template("foo").unwrap();
    let state = tmpl.new_state();
    let val = Value::from_function(|kwargs: Kwargs| kwargs.get::<i32>("foo"));
    let rv = val
        .call(
            &state,
            &[Kwargs::from_iter([("foo", Value::from(42))]).into()],
        )
        .unwrap();
    assert_eq!(rv, Value::from(42));
}
fn parse_multiple_keys_and_values_test() {
  let ini_file = "parameter=value;abc

key = value2

[category]";

  let ini_without_key_value = "[category]";

  let res = keys_and_values(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, ref o)) => println!("i: {} | o: {:?}", i, o),
    _ => println!("error"),
  }

  let mut expected: HashMap<&str, &str> = HashMap::new();
  expected.insert("parameter", "value");
  expected.insert("key", "value2");
  assert_eq!(res, Ok((ini_without_key_value, expected)));
}
fn exports() -> Result<(), String> {
    let store = Store::default();
    let wat = r#"(module
(func (export "func") nop)
(memory (export "memory") 1)
(table (export "table") 1 funcref)
(global (export "global") i32 (i32.const 0))
)"#;
    let module = Module::new(&store, wat).map_err(|e| format!("{e:?}"))?;
    assert_eq!(
        module.exports().collect::<Vec<_>>(),
        vec![
            ExportType::new(
                "func",
                ExternType::Function(FunctionType::new(vec![], vec![]))
            ),
            ExportType::new(
                "memory",
                ExternType::Memory(MemoryType::new(Pages(1), None, false))
            ),
            ExportType::new(
                "table",
                ExternType::Table(TableType::new(Type::FuncRef, 1, None))
            ),
            ExportType::new(
                "global",
                ExternType::Global(GlobalType::new(Type::I32, Mutability::Const))
            )
        ]
    );

    // Now we test the iterators
    assert_eq!(
        module.exports().functions().collect::<Vec<_>>(),
        vec![ExportType::new("func", FunctionType::new(vec![], vec![])),]
    );
    assert_eq!(
        module.exports().memories().collect::<Vec<_>>(),
        vec![ExportType::new(
            "memory",
            MemoryType::new(Pages(1), None, false)
        ),]
    );
    assert_eq!(
        module.exports().tables().collect::<Vec<_>>(),
        vec![ExportType::new(
            "table",
            TableType::new(Type::FuncRef, 1, None)
        ),]
    );
    assert_eq!(
        module.exports().globals().collect::<Vec<_>>(),
        vec![ExportType::new(
            "global",
            GlobalType::new(Type::I32, Mutability::Const)
        ),]
    );
    Ok(())
}
fn test_region_collection_find_region_by_key() {
    let mut cluster = new_node_cluster(0, 3);

    let (tx, rx) = channel();
    cluster
        .sim
        .wl()
        .post_create_coprocessor_host(Box::new(move |id, host| {
            let p = RegionInfoAccessor::new(host);
            tx.send((id, p)).unwrap()
        }));

    cluster.run();
    let region_info_providers: HashMap<_, _> = rx.try_iter().collect();
    assert_eq!(region_info_providers.len(), 3);
    let regions = prepare_cluster(&mut cluster);

    for node_id in cluster.get_node_ids() {
        let engine = &region_info_providers[&node_id];

        let region = engine.find_region_by_key(b"").unwrap();
        assert_eq!(region, regions[0]);

        let region = engine.find_region_by_key(b"k2").unwrap();
        assert_eq!(region, regions[1]);

        let region = engine.find_region_by_key(b"k99").unwrap();
        assert_eq!(region, *regions.last().unwrap());
    }

    for (_, p) in region_info_providers {
        p.stop();
    }
}
fn parse_mssql_identifiers() {
    let sql = "SELECT @@version, _foo$123 FROM ##temp";
    let select = ms_and_generic().verified_only_select(sql);
    assert_eq!(
        &Expr::Identifier(Ident::new("@@version")),
        expr_from_projection(&select.projection[0]),
    );
    assert_eq!(
        &Expr::Identifier(Ident::new("_foo$123")),
        expr_from_projection(&select.projection[1]),
    );
    assert_eq!(2, select.projection.len());
    match &only(&select.from).relation {
        TableFactor::Table { name, .. } => {
            assert_eq!("##temp".to_string(), name.to_string());
        }
        _ => unreachable!(),
    };
}
fn test_duplicate_and_close() {
    let (_cluster, ctx, _, import) = new_cluster_and_tikv_import_client();
    let mut req = SwitchModeRequest::default();
    req.set_mode(SwitchMode::Import);
    import.switch_mode(&req).unwrap();

    let data_count: u64 = 4096;
    for commit_ts in 0..4 {
        let mut meta = new_sst_meta(0, 0);
        meta.set_region_id(ctx.get_region_id());
        meta.set_region_epoch(ctx.get_region_epoch().clone());

        let mut keys = vec![];
        let mut values = vec![];
        for i in 1000..data_count {
            let key = i.to_string();
            keys.push(key.as_bytes().to_vec());
            values.push(key.as_bytes().to_vec());
        }
        let resp = send_write_sst(&import, &meta, keys, values, commit_ts).unwrap();
        for m in resp.metas.into_iter() {
            let mut ingest = IngestRequest::default();
            ingest.set_context(ctx.clone());
            ingest.set_sst(m.clone());
            let resp = import.ingest(&ingest).unwrap();
            assert!(!resp.has_error());
        }
    }

    let mut duplicate = DuplicateDetectRequest::default();
    duplicate.set_context(ctx);
    duplicate.set_start_key((0_u64).to_string().as_bytes().to_vec());
    let mut stream = import.duplicate_detect(&duplicate).unwrap();
    let ret = block_on(async move {
        let mut ret: Vec<KvPair> = vec![];
        while let Some(resp) = stream.next().await {
            match resp {
                Ok(mut resp) => {
                    if resp.has_key_error() || resp.has_region_error() {
                        break;
                    }
                    let pairs = resp.take_pairs();
                    ret.append(&mut pairs.into());
                }
                Err(e) => {
                    println!("receive error: {:?}", e);
                    break;
                }
            }
        }
        ret
    });
    assert_eq!(ret.len(), (data_count - 1000) as usize * 4);
    req.set_mode(SwitchMode::Normal);
    import.switch_mode(&req).unwrap();
}
fn test_format_created_seconds() {
    let args = ["-c", "%W", "/bin"];
    let ts = TestScenario::new(util_name!());
    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();
    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();
    println!("actual: {actual:?}");
    println!("expect: {expect:?}");
    // note: using a regex instead of `split_whitespace()` in order to detect whitespace differences
    let re = regex::Regex::new(r"\s").unwrap();
    let v_actual: Vec<&str> = re.split(&actual).collect();
    let v_expect: Vec<&str> = re.split(&expect).collect();
    assert!(!v_expect.is_empty());
    // * allow for inequality if `stat` (aka, expect) returns "0" (unknown value)
    assert!(
        expect == "0"
            || expect == "0\n"
            || v_actual
                .iter()
                .zip(v_expect.iter())
                .all(|(a, e)| a == e || *e == "0" || *e == "0\n")
    );
}
fn test_symlink_no_deref_dir() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let dir1 = "foo";
    let dir2 = "bar";
    let link = "baz";

    at.mkdir(dir1);
    at.mkdir(dir2);
    scene
        .ucmd()
        .args(&["-s", dir2, link])
        .succeeds()
        .no_stderr();
    assert!(at.dir_exists(dir1));
    assert!(at.dir_exists(dir2));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), dir2);

    // try the normal behavior
    scene
        .ucmd()
        .args(&["-sf", dir1, link])
        .succeeds()
        .no_stderr();
    assert!(at.dir_exists(dir1));
    assert!(at.dir_exists(dir2));
    assert!(at.is_symlink("baz/foo"));
    assert_eq!(at.resolve_link("baz/foo"), dir1);

    // Doesn't work without the force
    scene.ucmd().args(&["-sn", dir1, link]).fails();

    // Try with the no-deref
    scene.ucmd().args(&["-sfn", dir1, link]).succeeds();
    assert!(at.dir_exists(dir1));
    assert!(at.dir_exists(dir2));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), dir1);
}
fn test_install_missing_arguments() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let no_target_dir = "no-target_dir";

    scene
        .ucmd()
        .fails()
        .code_is(1)
        .usage_error("missing file operand");

    scene
        .ucmd()
        .arg("-D")
        .arg(format!("-t {no_target_dir}"))
        .fails()
        .usage_error("missing file operand");
    assert!(!at.dir_exists(no_target_dir));
}
fn test_chown_fail_id() {
    // test chown 1111. file.txt

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("id").arg("-u").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let user_id = String::from(result.stdout_str().trim());
    assert!(!user_id.is_empty());

    let file1 = "test_chown_file1";
    at.touch(file1);

    scene
        .ucmd()
        .arg(format!("{user_id}:"))
        .arg(file1)
        .fails()
        .stderr_contains("invalid spec");

    scene
        .ucmd()
        .arg(format!("{user_id}."))
        .arg(file1)
        .fails()
        .stderr_contains("invalid spec");
}
fn test_read_index_when_transfer_leader_2() {
    let mut cluster = new_node_cluster(0, 3);

    // Increase the election tick to make this test case running reliably.
    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));
    // Stop log compaction to transfer leader with filter easier.
    configure_for_request_snapshot(&mut cluster);
    let max_lease = Duration::from_secs(2);
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration(max_lease);

    // Add peer 2 and 3 and wait them to apply it.
    cluster.pd_client.disable_default_operator();
    let r1 = cluster.run_conf_change();
    cluster.must_put(b"k0", b"v0");
    cluster.pd_client.must_add_peer(r1, new_peer(2, 2));
    cluster.pd_client.must_add_peer(r1, new_peer(3, 3));
    must_get_equal(&cluster.get_engine(2), b"k0", b"v0");
    must_get_equal(&cluster.get_engine(3), b"k0", b"v0");

    // Put and test again to ensure that peer 3 get the latest writes by message
    // append instead of snapshot, so that transfer leader to peer 3 can 100%
    // success.
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    let r1 = cluster.get_region(b"k1");
    let old_leader = cluster.leader_of_region(r1.get_id()).unwrap();

    // Use a macro instead of a closure to avoid any capture of local variables.
    macro_rules! read_on_old_leader {
        () => {{
            let (tx, rx) = mpsc::sync_channel(1);
            let mut read_request = new_request(
                r1.get_id(),
                r1.get_region_epoch().clone(),
                vec![new_get_cmd(b"k1")],
                true, // read quorum
            );
            read_request.mut_header().set_peer(new_peer(1, 1));
            let sim = cluster.sim.wl();
            sim.async_command_on_node(
                old_leader.get_id(),
                read_request,
                Callback::read(Box::new(move |resp| tx.send(resp.response).unwrap())),
            )
            .unwrap();
            rx
        }};
    }

    // Delay all raft messages to peer 1.
    let dropped_msgs = Arc::new(Mutex::new(Vec::new()));
    let filter = Box::new(
        RegionPacketFilter::new(r1.get_id(), old_leader.get_store_id())
            .direction(Direction::Recv)
            .skip(MessageType::MsgTransferLeader)
            .when(Arc::new(AtomicBool::new(true)))
            .reserve_dropped(Arc::clone(&dropped_msgs)),
    );
    cluster
        .sim
        .wl()
        .add_recv_filter(old_leader.get_id(), filter);

    let resp1 = read_on_old_leader!();

    cluster.must_transfer_leader(r1.get_id(), new_peer(3, 3));

    let resp2 = read_on_old_leader!();

    // Unpark all pending messages and clear all filters.
    let router = cluster.sim.wl().get_router(old_leader.get_id()).unwrap();
    let mut reserved_msgs = Vec::new();
    'LOOP: loop {
        for raft_msg in std::mem::take(&mut *dropped_msgs.lock().unwrap()) {
            let msg_type = raft_msg.get_message().get_msg_type();
            if msg_type == MessageType::MsgHeartbeatResponse || msg_type == MessageType::MsgAppend {
                reserved_msgs.push(raft_msg);
                if msg_type == MessageType::MsgAppend {
                    break 'LOOP;
                }
            }
        }
    }

    // Resume reserved messages in one batch to make sure the old leader can get
    // read and role change in one `Ready`.
    fail::cfg("pause_on_peer_collect_message", "pause").unwrap();
    for raft_msg in reserved_msgs {
        router.send_raft_message(raft_msg).unwrap();
    }
    fail::cfg("pause_on_peer_collect_message", "off").unwrap();
    cluster.sim.wl().clear_recv_filters(old_leader.get_id());

    let resp1 = resp1.recv().unwrap();
    assert!(resp1.get_header().get_error().has_stale_command());

    // Response 2 should contains an error.
    let resp2 = resp2.recv().unwrap();
    assert!(resp2.get_header().get_error().has_stale_command());
    drop(cluster);
    fail::remove("pause_on_peer_collect_message");
}
async fn send_trailers_immediately() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        // Write GET /
        .write(&[
            0, 0, 0x10, 1, 4, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,
            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84, 0, 0, 0x0A, 1, 5, 0, 0, 0, 1, 0x40, 0x83,
            0xF6, 0x7A, 0x66, 0x84, 0x9C, 0xB4, 0x50, 0x7F,
        ])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[
            0, 0, 1, 1, 4, 0, 0, 0, 1, 0x88, 0, 0, 0x0B, 0, 1, 0, 0, 0, 1, 0x68, 0x65, 0x6C, 0x6C,
            0x6F, 0x20, 0x77, 0x6F, 0x72, 0x6C, 0x64,
        ])
        .build();

    let (mut client, mut h2) = client::handshake(mock).await.unwrap();

    // Send the request
    let request = Request::builder()
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, mut stream) = client.send_request(request, false).unwrap();

    let mut trailers = HeaderMap::new();
    trailers.insert("zomg", "hello".parse().unwrap());

    stream.send_trailers(trailers).unwrap();

    let response = h2.run(response).await.unwrap();
    assert_eq!(response.status(), StatusCode::OK);

    let (_, mut body) = response.into_parts();

    // There is a data chunk
    let _ = h2.run(body.next()).await.unwrap().unwrap();

    let chunk = h2.run(body.next()).await;
    assert!(chunk.is_none());

    let trailers = h2.run(poll_fn(|cx| body.poll_trailers(cx))).await.unwrap();
    assert!(trailers.is_none());

    h2.await.unwrap();
}
fn test_write_after_destroy() {
    // 3 nodes cluster.
    let mut cluster = new_server_cluster(0, 3);

    let pd_client = cluster.pd_client.clone();
    // Disable default max peer count check.
    pd_client.disable_default_operator();

    let r1 = cluster.run_conf_change();

    // Now region 1 only has peer (1, 1);
    let (key, value) = (b"k1", b"v1");

    cluster.must_put(key, value);
    assert_eq!(cluster.get(key), Some(value.to_vec()));

    // add peer (2,2) to region 1.
    pd_client.must_add_peer(r1, new_peer(2, 2));

    // add peer (3, 3) to region 1.
    pd_client.must_add_peer(r1, new_peer(3, 3));
    let engine_3 = cluster.get_engine(3);
    must_get_equal(&engine_3, b"k1", b"v1");

    let apply_fp = "apply_on_conf_change_1_3_1";
    fail::cfg(apply_fp, "pause").unwrap();

    cluster.must_transfer_leader(r1, new_peer(1, 1));
    let conf_change = new_change_peer_request(ConfChangeType::RemoveNode, new_peer(3, 3));
    let mut epoch = cluster.pd_client.get_region_epoch(r1);
    let mut admin_req = new_admin_request(r1, &epoch, conf_change);
    admin_req.mut_header().set_peer(new_peer(1, 1));
    let (cb1, mut rx1) = make_cb(&admin_req);
    let engines_3 = cluster.get_all_engines(3);
    let region = block_on(cluster.pd_client.get_region_by_id(r1))
        .unwrap()
        .unwrap();
    let reqs = vec![new_put_cmd(b"k5", b"v5")];
    let new_version = epoch.get_conf_ver() + 1;
    epoch.set_conf_ver(new_version);
    let mut put = new_request(r1, epoch, reqs, false);
    put.mut_header().set_peer(new_peer(1, 1));
    cluster
        .sim
        .rl()
        .async_command_on_node(1, admin_req, cb1)
        .unwrap();
    for _ in 0..100 {
        let (cb2, _rx2) = make_cb(&put);
        cluster
            .sim
            .rl()
            .async_command_on_node(1, put.clone(), cb2)
            .unwrap();
    }
    let engine_2 = cluster.get_engine(2);
    must_get_equal(&engine_2, b"k5", b"v5");
    fail::remove(apply_fp);
    let resp = rx1.recv_timeout(Duration::from_secs(2)).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    std::thread::sleep(Duration::from_secs(3));
    must_get_none(&engine_3, b"k5");
    must_region_cleared(&engines_3, &region);
}
fn test_skip_iter_iltc() {
    // Test iterators that skip multiple digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_leading_digit_separator(true)
        .integer_trailing_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"45.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"45.56");
}
fn test_witness_leader_transfer_out() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);

    // prevent this peer from applying the switch witness command until it's elected
    // as the Raft leader
    fail::cfg("before_exec_batch_switch_witness", "pause").unwrap();
    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();
    // nonwitness -> witness
    cluster
        .pd_client
        .switch_witnesses(region.get_id(), vec![peer_on_store2.get_id()], vec![true]);
    // make sure the left peers have applied switch witness cmd
    std::thread::sleep(Duration::from_millis(500));

    // the other follower is isolated
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    for i in 1..10 {
        cluster.must_put(format!("k{}", i).as_bytes(), format!("v{}", i).as_bytes());
    }
    // the leader is down
    cluster.stop_node(1);

    // new leader would help to replicate the logs
    cluster.clear_send_filters();
    std::thread::sleep(Duration::from_millis(1000));
    // make sure the new leader has became to the witness
    fail::remove("before_exec_batch_switch_witness");
    std::thread::sleep(Duration::from_millis(500));

    // forbid writes
    let put = new_put_cmd(b"k3", b"v3");
    must_get_error_is_witness(&mut cluster, &region, put);
    // forbid reads
    let get = new_get_cmd(b"k1");
    must_get_error_is_witness(&mut cluster, &region, get);
    // forbid read index
    let read_index = new_read_index_cmd();
    must_get_error_is_witness(&mut cluster, &region, read_index);

    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();

    cluster.must_transfer_leader(region.get_id(), peer_on_store3);
    cluster.must_put(b"k1", b"v1");
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap().store_id,
        nodes[2],
    );
    assert_eq!(cluster.must_get(b"k9"), Some(b"v9".to_vec()));
}
fn test_cp_cp() {
    let (at, mut ucmd) = at_and_ucmd!();
    // Invoke our binary to make the copy.
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HELLO_WORLD_DEST)
        .succeeds();

    // Check the content of the destination file that was copied.
    assert_eq!(at.read(TEST_HELLO_WORLD_DEST), "Hello, World!\n");
}
fn u32_decimal_test() {
    assert_eq!(Ok(0), u32::from_lexical(b"0"));
    assert_eq!(Ok(2147483647), u32::from_lexical(b"2147483647"));
    assert_eq!(Ok(2147483648), u32::from_lexical(b"2147483648"));
    assert_eq!(Ok(4294967295), u32::from_lexical(b"4294967295"));
    assert_eq!(Err(Error::InvalidDigit(0)), u32::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), u32::from_lexical(b"1a"));
}
fn preview_group_selector() {
    // `--select PREVIEW` should error (selector was removed)
    let args = ["--select", "PREVIEW", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 2
    ----- stdout -----

    ----- stderr -----
    error: invalid value 'PREVIEW' for '--select <RULE_CODE>'

    For more information, try '--help'.
    "###);
}
fn parse_extract() {
    let sql = "SELECT EXTRACT(YEAR FROM d)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Extract {
            field: DateTimeField::Year,
            expr: Box::new(Expr::Identifier(Ident::new("d"))),
        },
        expr_from_projection(only(&select.projection)),
    );

    one_statement_parses_to("SELECT EXTRACT(year from d)", "SELECT EXTRACT(YEAR FROM d)");

    verified_stmt("SELECT EXTRACT(MONTH FROM d)");
    verified_stmt("SELECT EXTRACT(WEEK FROM d)");
    verified_stmt("SELECT EXTRACT(DAY FROM d)");
    verified_stmt("SELECT EXTRACT(DAYOFWEEK FROM d)");
    verified_stmt("SELECT EXTRACT(DAYOFYEAR FROM d)");
    verified_stmt("SELECT EXTRACT(DATE FROM d)");
    verified_stmt("SELECT EXTRACT(HOUR FROM d)");
    verified_stmt("SELECT EXTRACT(MINUTE FROM d)");
    verified_stmt("SELECT EXTRACT(SECOND FROM d)");
    verified_stmt("SELECT EXTRACT(MILLISECOND FROM d)");
    verified_stmt("SELECT EXTRACT(MICROSECOND FROM d)");
    verified_stmt("SELECT EXTRACT(NANOSECOND FROM d)");
    verified_stmt("SELECT EXTRACT(CENTURY FROM d)");
    verified_stmt("SELECT EXTRACT(DECADE FROM d)");
    verified_stmt("SELECT EXTRACT(DOW FROM d)");
    verified_stmt("SELECT EXTRACT(DOY FROM d)");
    verified_stmt("SELECT EXTRACT(EPOCH FROM d)");
    verified_stmt("SELECT EXTRACT(ISODOW FROM d)");
    verified_stmt("SELECT EXTRACT(ISOWEEK FROM d)");
    verified_stmt("SELECT EXTRACT(ISOYEAR FROM d)");
    verified_stmt("SELECT EXTRACT(JULIAN FROM d)");
    verified_stmt("SELECT EXTRACT(MICROSECOND FROM d)");
    verified_stmt("SELECT EXTRACT(MICROSECONDS FROM d)");
    verified_stmt("SELECT EXTRACT(MILLENIUM FROM d)");
    verified_stmt("SELECT EXTRACT(MILLENNIUM FROM d)");
    verified_stmt("SELECT EXTRACT(MILLISECOND FROM d)");
    verified_stmt("SELECT EXTRACT(MILLISECONDS FROM d)");
    verified_stmt("SELECT EXTRACT(QUARTER FROM d)");
    verified_stmt("SELECT EXTRACT(TIMEZONE FROM d)");
    verified_stmt("SELECT EXTRACT(TIMEZONE_HOUR FROM d)");
    verified_stmt("SELECT EXTRACT(TIMEZONE_MINUTE FROM d)");
    verified_stmt("SELECT EXTRACT(TIME FROM d)");

    let res = parse_sql_statements("SELECT EXTRACT(JIFFY FROM d)");
    assert_eq!(
        ParserError::ParserError("Expected date/time field, found: JIFFY".to_string()),
        res.unwrap_err()
    );
}
fn test_single_table_in_parenthesis_with_alias() {
    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a NATURAL JOIN (b) c )",
        "SELECT * FROM (a NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a NATURAL JOIN ((b)) c )",
        "SELECT * FROM (a NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a NATURAL JOIN ( (b) c ) )",
        "SELECT * FROM (a NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a NATURAL JOIN ( (b) as c ) )",
        "SELECT * FROM (a NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a alias1 NATURAL JOIN ( (b) c ) )",
        "SELECT * FROM (a AS alias1 NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a as alias1 NATURAL JOIN ( (b) as c ) )",
        "SELECT * FROM (a AS alias1 NATURAL JOIN b AS c)",
    );

    snowflake_and_generic().one_statement_parses_to(
        "SELECT * FROM (a NATURAL JOIN b) c",
        "SELECT * FROM (a NATURAL JOIN b) AS c",
    );

    let res = snowflake().parse_sql_statements("SELECT * FROM (a b) c");
    assert_eq!(
        ParserError::ParserError("duplicate alias b".to_string()),
        res.unwrap_err()
    );
}
fn test_bytes_big() {
    const FILE: &str = "test_bytes_big.txt";
    const EXPECTED_FILE: &str = "test_bytes_big_expected.txt";
    const BYTES: usize = 1_000_000;
    const N_ARG: usize = 100_000;

    let (at, mut ucmd) = at_and_ucmd!();

    let mut big_input = at.make_file(FILE);
    for i in 0..BYTES {
        let digit = from_digit((i % 10) as u32, 10).unwrap();
        write!(big_input, "{digit}").expect("Could not write to FILE");
    }
    big_input.flush().expect("Could not flush FILE");

    let mut big_expected = at.make_file(EXPECTED_FILE);
    for i in (BYTES - N_ARG)..BYTES {
        let digit = from_digit((i % 10) as u32, 10).unwrap();
        write!(big_expected, "{digit}").expect("Could not write to EXPECTED_FILE");
    }
    big_expected.flush().expect("Could not flush EXPECTED_FILE");

    let result = ucmd
        .arg(FILE)
        .arg("-c")
        .arg(format!("{N_ARG}"))
        .succeeds()
        .stdout_move_str();
    let expected = at.read(EXPECTED_FILE);

    assert_eq!(result.len(), expected.len());
    for (actual_char, expected_char) in result.chars().zip(expected.chars()) {
        assert_eq!(actual_char, expected_char);
    }
}
fn test_split_for_impl() {
    let input = quote! {
        struct S<'a, 'b: 'a, #[may_dangle] T: 'a = ()> where T: Debug;
    };

    snapshot!(input as DeriveInput, @r###"
    DeriveInput {
        vis: Visibility::Inherited,
        ident: "S",
        generics: Generics {
            lt_token: Some,
            params: [
                GenericParam::Lifetime(LifetimeParam {
                    lifetime: Lifetime {
                        ident: "a",
                    },
                }),
                GenericParam::Lifetime(LifetimeParam {
                    lifetime: Lifetime {
                        ident: "b",
                    },
                    colon_token: Some,
                    bounds: [
                        Lifetime {
                            ident: "a",
                        },
                    ],
                }),
                GenericParam::Type(TypeParam {
                    attrs: [
                        Attribute {
                            style: AttrStyle::Outer,
                            meta: Meta::Path {
                                segments: [
                                    PathSegment {
                                        ident: "may_dangle",
                                    },
                                ],
                            },
                        },
                    ],
                    ident: "T",
                    colon_token: Some,
                    bounds: [
                        TypeParamBound::Lifetime {
                            ident: "a",
                        },
                    ],
                    eq_token: Some,
                    default: Some(Type::Tuple),
                }),
            ],
            gt_token: Some,
            where_clause: Some(WhereClause {
                predicates: [
                    WherePredicate::Type(PredicateType {
                        bounded_ty: Type::Path {
                            path: Path {
                                segments: [
                                    PathSegment {
                                        ident: "T",
                                    },
                                ],
                            },
                        },
                        bounds: [
                            TypeParamBound::Trait(TraitBound {
                                path: Path {
                                    segments: [
                                        PathSegment {
                                            ident: "Debug",
                                        },
                                    ],
                                },
                            }),
                        ],
                    }),
                ],
            }),
        },
        data: Data::Struct {
            fields: Fields::Unit,
            semi_token: Some,
        },
    }
    "###);

    let generics = input.generics;
    let (impl_generics, ty_generics, where_clause) = generics.split_for_impl();

    let generated = quote! {
        impl #impl_generics MyTrait for Test #ty_generics #where_clause {}
    };
    let expected = quote! {
        impl<'a, 'b: 'a, #[may_dangle] T: 'a> MyTrait
        for Test<'a, 'b, T>
        where
            T: Debug
        {}
    };
    assert_eq!(generated.to_string(), expected.to_string());

    let turbofish = ty_generics.as_turbofish();
    let generated = quote! {
        Test #turbofish
    };
    let expected = quote! {
        Test::<'a, 'b, T>
    };
    assert_eq!(generated.to_string(), expected.to_string());
}
fn forward_call_works() -> Result<()> {
    let mut store = store_with_padding(128 * MB)?;
    let module = Module::new(
        store.engine(),
        r#"
            (module
                (func (export "foo") (result i32)
                    call 1)
                (func (result i32)
                    i32.const 4)
            )
        "#,
    )?;

    let i = Instance::new(&mut store, &module, &[])?;
    let foo = i.get_typed_func::<(), i32>(&mut store, "foo")?;
    assert_eq!(foo.call(&mut store, ())?, 4);
    Ok(())
}
fn test_reject_proposal_during_region_split() {
    let mut cluster = new_node_cluster(0, 3);
    let pd_client = cluster.pd_client.clone();
    pd_client.disable_default_operator();
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k", b"v");

    // Pause on applying so that region split is not finished.
    let fp = "apply_before_split";
    fail::cfg(fp, "pause").unwrap();

    // Try to split region.
    let (split_tx, split_rx) = mpsc::channel();
    let cb = Callback::read(Box::new(move |resp: ReadResponse<RocksSnapshot>| {
        split_tx.send(resp.response).unwrap()
    }));
    let r = cluster.get_region(b"");
    cluster.split_region(&r, b"k", cb);
    split_rx
        .recv_timeout(Duration::from_millis(100))
        .unwrap_err();

    // Try to put a key.
    let force_delay_propose_batch_raft_command_fp = "force_delay_propose_batch_raft_command";
    let mut receivers = vec![];
    for i in 0..2 {
        if i == 1 {
            // Test another path of calling proposed callback.
            fail::cfg(force_delay_propose_batch_raft_command_fp, "2*return").unwrap();
        }
        let write_req = make_write_req(&mut cluster, b"k1");
        let (cb, mut cb_receivers) = make_cb(&write_req);
        cluster
            .sim
            .rl()
            .async_command_on_node(1, write_req, cb)
            .unwrap();
        // The write request should be blocked until split is finished.
        cb_receivers.assert_not_ready();
        receivers.push(cb_receivers);
    }

    fail::remove(fp);
    // Split is finished.
    assert!(
        !split_rx
            .recv_timeout(Duration::from_secs(1))
            .unwrap()
            .get_header()
            .has_error()
    );

    // The write request fails due to epoch not match.
    for mut r in receivers {
        r.assert_err();
    }

    // New write request can succeed.
    let write_req = make_write_req(&mut cluster, b"k1");
    let (cb, mut cb_receivers) = make_cb(&write_req);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, write_req, cb)
        .unwrap();
    cb_receivers.assert_ok();
}
fn test_eq() {
    assert_eq!(version("1.2.3"), version("1.2.3"));
    assert_eq!(version("1.2.3-alpha1"), version("1.2.3-alpha1"));
    assert_eq!(version("1.2.3+build.42"), version("1.2.3+build.42"));
    assert_eq!(version("1.2.3-alpha1+42"), version("1.2.3-alpha1+42"));
}
fn test_log_backward_compatible() {
    let content = read_file_in_project_dir("integrations/config/test-log-compatible.toml");
    let mut cfg: TikvConfig = toml::from_str(&content).unwrap();
    assert_eq!(cfg.log.level, slog::Level::Info.into());
    assert_eq!(cfg.log.file.filename, "");
    assert_eq!(cfg.log.format, LogFormat::Text);
    assert_eq!(cfg.log.file.max_size, 300);
    cfg.logger_compatible_adjust();
    assert_eq!(cfg.log.level, slog::Level::Critical.into());
    assert_eq!(cfg.log.file.filename, "foo");
    assert_eq!(cfg.log.format, LogFormat::Json);
    assert_eq!(cfg.log.file.max_size, 1024);
}
fn aes256_encrypted_file() {
    let mut v = Vec::new();
    v.extend_from_slice(include_bytes!("data/aes_archive.zip"));
    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect("couldn't open test zip file");

    let mut file = archive
        .by_name_decrypt("secret_data_256", PASSWORD)
        .expect("couldn't find file in archive")
        .expect("invalid password");
    assert_eq!("secret_data_256", file.name());

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("couldn't read encrypted and compressed file");
    assert_eq!(SECRET_CONTENT, content);
}
fn test_snapshot_failed_2() {
    let product = ProductTable::new();
    let (store, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    store.get_engine().trigger_not_leader();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_region_error().has_not_leader());
}
fn dynamic_add2_works() {
    let (mut store, add2, add2_dyn) = setup_add2();
    for a in 0..10 {
        for b in 0..10 {
            let params = [Value::I32(a), Value::I32(b)];
            let expected = a + b;
            let mut result = Value::I32(0);
            // Call to Func with statically typed closure.
            add2.call(&mut store, &params, slice::from_mut(&mut result))
                .unwrap();
            // Reset result before execution.
            result = Value::I32(0);
            // Call to Func with dynamically typed closure.
            add2_dyn
                .call(&mut store, &params, slice::from_mut(&mut result))
                .unwrap();
            assert_eq!(result.i32(), Some(expected));
        }
    }
}
fn test_deleted_dir() {
    use std::process::Command;

    let ts = TestScenario::new(util_name!());
    let at = ts.fixtures;
    let output = Command::new("sh")
        .arg("-c")
        .arg(format!(
            "cd '{}'; mkdir foo; cd foo; rmdir ../foo; exec '{}' {}",
            at.root_dir_resolved(),
            ts.bin_path.to_str().unwrap(),
            ts.util_name,
        ))
        .output()
        .unwrap();
    assert!(!output.status.success());
    assert!(output.stdout.is_empty());
    assert_eq!(
        output.stderr,
        b"pwd: failed to get current directory: No such file or directory\n"
    );
}
fn test_something() {
    let data = [];
    if let Ok(s) = std::str::from_utf8(data) {
        if STANDARD_RANGE.is_match(s) {
            return;
        }
        if let Ok(parsed) = parse_range_header(s) {
            let v = parsed.validate(u64::MAX);
            assert!(
                parsed.validate(u64::MAX).is_err(),
                "range {:?} accepted as {:?}",
                s,
                v
            );
        }
    }
}
fn test_cp_arg_update_short_no_overwrite() {
    // same as --update=older
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_short_no_overwrite_file1";
    let new = "test_cp_arg_update_short_no_overwrite_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("-u")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), "new content\n");
}
fn ignore_vcs_ignored_file_via_cli() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let git_ignore = r#"
file2.js
"#;

    let code2 = r#"foo.call();


    bar.call();"#;
    let code1 = r#"array.map(sentence =>


    sentence.split(' ')).flat();"#;

    // ignored files
    let file_path1 = Path::new("file1.js");
    fs.insert(file_path1.into(), code1.as_bytes());
    let file_path2 = Path::new("file2.js");
    fs.insert(file_path2.into(), code2.as_bytes());

    // git folder
    let git_folder = Path::new("./.git");
    fs.insert(git_folder.into(), "".as_bytes());

    // git ignore file
    let ignore_file = Path::new("./.gitignore");
    fs.insert(ignore_file.into(), git_ignore.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--vcs-enabled=true"),
                ("--vcs-client-kind=git"),
                ("--vcs-use-ignore-file=true"),
                ("--vcs-root=."),
                ("--write"),
                file_path1.as_os_str().to_str().unwrap(),
                file_path2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ignore_vcs_ignored_file_via_cli",
        fs,
        console,
        result,
    ));
}
fn test_pub_super() {
    assert_vis_parse!("pub(super)", Ok(Visibility::Restricted(_)));
}
fn delete_all_tables() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let x_def: TableDefinition<&str, &str> = TableDefinition::new("x");
    let y_def: TableDefinition<&str, &str> = TableDefinition::new("y");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(x_def).unwrap();
        table.insert("hello", "world").unwrap();
        let mut table = write_txn.open_table(y_def).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    assert_eq!(2, read_txn.list_tables().unwrap().count());

    let write_txn = db.begin_write().unwrap();
    for table in write_txn.list_tables().unwrap() {
        write_txn.delete_table(table).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    assert_eq!(0, read_txn.list_tables().unwrap().count());
}
fn test_split_separator_nul_number_l() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--number=l/3", "--separator=\\0", "separator_nul.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\x002\0");
    assert_eq!(file_read(&at, "xab"), "3\x004\0");
    assert_eq!(file_read(&at, "xac"), "5\0");
    assert!(!at.plus("xad").exists());
}
fn parse_multiple_keys_and_values_test() {
  let ini_file = &b"parameter=value;abc

key = value2

[category]"[..];

  let ini_without_key_value = &b"[category]"[..];

  let res = keys_and_values(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, ref o)) => println!("i: {:?} | o: {:?}", str::from_utf8(i), o),
    _ => println!("error"),
  }

  let mut expected: HashMap<&str, &str> = HashMap::new();
  expected.insert("parameter", "value");
  expected.insert("key", "value2");
  assert_eq!(res, Ok((ini_without_key_value, expected)));
}
fn test_undetermined_write_err() {
    let (cluster, leader, ctx) = must_new_cluster_mul(1);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env)
        .keepalive_time(Duration::from_millis(500))
        .keepalive_timeout(Duration::from_millis(500))
        .connect(&cluster.sim.read().unwrap().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut mutation = Mutation::default();
    mutation.set_op(Op::Put);
    mutation.set_key(b"k".to_vec());
    mutation.set_value(b"v".to_vec());
    fail::cfg("applied_cb_return_undetermined_err", "return()").unwrap();
    let err = try_kv_prewrite_with_impl(
        &client,
        ctx,
        vec![mutation],
        b"k".to_vec(),
        10,
        0,
        false,
        false,
    )
    .unwrap_err();
    assert_eq!(err.to_string(), "RpcFailure: 1-CANCELLED CANCELLED",);
    fail::remove("applied_cb_return_undetermined_err");
    // The previous panic hasn't been captured.
    assert!(std::panic::catch_unwind(std::panic::AssertUnwindSafe(|| drop(cluster))).is_err());
}
fn parse_variable_tag_simple_logic_expression() {
    let ast = parse("{{ 1 > 2 }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Logic(LogicExpr {
                lhs: Box::new(Expr::new(ExprVal::Int(1))),
                operator: LogicOperator::Gt,
                rhs: Box::new(Expr::new(ExprVal::Int(2))),
            },))
        )
    );
}
fn test_tombstone_block_list() {
    let pd_server = test_pd::Server::new(1);
    let eps = pd_server.bind_addrs();
    let pd_client = Arc::new(test_pd::util::new_client(eps, None));
    let bg_worker = WorkerBuilder::new(thd_name!("background"))
        .thread_count(2)
        .create();
    let resolver = resolve::new_resolver(pd_client, &bg_worker, FakeExtension).0;

    let msg_count = Arc::new(AtomicUsize::new(0));
    let batch_msg_count = Arc::new(AtomicUsize::new(0));
    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), true);
    let (_mock_server, port) = create_mock_server(service, 60200, 60300).unwrap();

    let mut raft_client = get_raft_client(FakeExtension, resolver);

    let mut store1 = metapb::Store::default();
    store1.set_id(1);
    store1.set_address(format!("127.0.0.1:{}", port));
    pd_server.default_handler().add_store(store1.clone());

    // `send` should success.
    for _ in 0..10 {
        // 5M per RaftMessage.
        let mut raft_m = RaftMessage::default();
        raft_m.mut_to_peer().set_store_id(1);
        for _ in 0..(5 * 1024) {
            let mut e = Entry::default();
            e.set_data(vec![b'a'; 1024].into());
            raft_m.mut_message().mut_entries().push(e);
        }
        raft_client.send(raft_m).unwrap();
    }
    raft_client.flush();

    check_msg_count(500, &msg_count, 10);

    let mut store2 = metapb::Store::default();
    store2.set_id(2);
    store2.set_address(store1.get_address().to_owned());
    store2.set_state(metapb::StoreState::Tombstone);
    pd_server.default_handler().add_store(store2);
    let mut message = RaftMessage::default();
    message.mut_to_peer().set_store_id(2);
    // First message should be OK.
    raft_client.send(message.clone()).unwrap();
    // Wait some time for the resolve result.
    thread::sleep(time::Duration::from_millis(50));
    // Second message should fail as the store should be added to block list.
    assert_eq!(
        DiscardReason::Disconnected,
        raft_client.send(message).unwrap_err()
    );
}
async fn read_data_empty_payload() {
    let mut codec = raw_codec! {
        read => [
            0, 0, 0, 0, 0, 0, 0, 0, 1,
        ];
    };

    let data = poll_frame!(Data, codec);
    assert_eq!(data.stream_id(), 1);
    assert_eq!(data.payload(), &b""[..]);
    assert!(!data.is_end_stream());

    assert_closed!(codec);
}
fn test_numeric_suffix() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n", "4", "--numeric-suffixes=9", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x10"), "b");
    assert_eq!(at.read("x11"), "c");
    assert_eq!(at.read("x12"), "");
}
fn idle_timeout() {
    let _guard = subscribe();
    const IDLE_TIMEOUT: u64 = 100;
    let server = ServerConfig {
        transport: Arc::new(TransportConfig {
            max_idle_timeout: Some(VarInt(IDLE_TIMEOUT)),
            ..TransportConfig::default()
        }),
        ..server_config()
    };
    let mut pair = Pair::new(Default::default(), server);
    let (client_ch, server_ch) = pair.connect();
    pair.client_conn_mut(client_ch).ping();
    let start = pair.time;

    while !pair.client_conn_mut(client_ch).is_closed()
        || !pair.server_conn_mut(server_ch).is_closed()
    {
        if !pair.step() {
            if let Some(t) = min_opt(pair.client.next_wakeup(), pair.server.next_wakeup()) {
                pair.time = t;
            }
        }
        pair.client.inbound.clear(); // Simulate total S->C packet loss
    }

    assert!(pair.time - start < Duration::from_millis(2 * IDLE_TIMEOUT));
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::TimedOut,
        })
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::TimedOut,
        })
    );
}
fn multithreaded_traps() -> Result<()> {
    // Compile and run unreachable on a thread, then moves over the whole store to another thread,
    // and make sure traps are still correctly caught after notifying the store of the move.
    let mut store = Store::<()>::default();
    let module = Module::new(
        store.engine(),
        r#"(module (func (export "run") unreachable))"#,
    )?;
    let instance = Instance::new(&mut store, &module, &[])?;

    assert!(instance
        .get_typed_func::<(), ()>(&mut store, "run")?
        .call(&mut store, ())
        .is_err());

    let handle = std::thread::spawn(move || {
        assert!(instance
            .get_typed_func::<(), ()>(&mut store, "run")
            .unwrap()
            .call(&mut store, ())
            .is_err());
    });

    handle.join().expect("couldn't join thread");

    Ok(())
}
fn calculate_shift_test() {
    assert_eq!(shared::calculate_shift::<f64>(-63), 64);
    assert_eq!(shared::calculate_shift::<f64>(-15), 16);
    assert_eq!(shared::calculate_shift::<f64>(-8), 11);
    assert_eq!(shared::calculate_shift::<f64>(0), 11);
    assert_eq!(shared::calculate_shift::<f64>(50), 11);
}
fn do_nothing_if_unneeded() {
    let ast = vec![Node::Text("hey ".to_string())];
    assert_eq!(remove_whitespace(ast.clone(), None), ast);
}
fn test_indent_one_line() {
    let teststring = String::from("test\n");
    assert_eq!(indent(teststring, 2, None, None), String::from("test"));
}
fn test_increase_pool() {
    let mut cluster = new_node_cluster(0, 1);
    cluster.cfg.raft_store.store_batch_system.pool_size = 1;
    cluster.cfg.raft_store.apply_batch_system.pool_size = 1;
    cluster.pd_client.disable_default_operator();
    let fp1 = "poll";

    // Pause at the entrance of the apply-0, apply-low-0, rafstore-1-0 threads
    fail::cfg(fp1, "3*pause").unwrap();
    let _ = cluster.run_conf_change();

    // Request cann't be handled as all pollers have been paused
    put_with_timeout(&mut cluster, b"k1", b"k1", Duration::from_secs(1)).unwrap();
    must_get_none(&cluster.get_engine(1), b"k1");

    {
        let sim = cluster.sim.rl();
        let cfg_controller = sim.get_cfg_controller().unwrap();

        let change = {
            let mut change = HashMap::new();
            change.insert("raftstore.store-pool-size".to_owned(), "2".to_owned());
            change.insert("raftstore.apply_pool_size".to_owned(), "2".to_owned());
            change
        };

        // Update config, expand from 1 to 2
        cfg_controller.update(change).unwrap();
        assert_eq!(
            cfg_controller
                .get_current()
                .raft_store
                .apply_batch_system
                .pool_size,
            2
        );
        assert_eq!(
            cfg_controller
                .get_current()
                .raft_store
                .store_batch_system
                .pool_size,
            2
        );
    }

    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");

    fail::remove(fp1);
}
fn test_nonexistent_dir_prefix() {
    #[cfg(not(windows))]
    new_ucmd!().arg("d/XXX").fails().stderr_only(
        "mktemp: failed to create file via template 'd/XXX': No such file or directory\n",
    );
    #[cfg(windows)]
    {
        let result = new_ucmd!().arg(r"d\XXX").fails();
        result.no_stdout();
        let stderr = result.stderr_str();
        assert!(
            stderr.starts_with("mktemp: failed to create file via template"),
            "{}",
            stderr
        );
        assert!(
            stderr.ends_with("d\\XXX': No such file or directory\n"),
            "{}",
            stderr
        );
    }

    #[cfg(not(windows))]
    new_ucmd!().arg("-d").arg("d/XXX").fails().stderr_only(
        "mktemp: failed to create directory via template 'd/XXX': No such file or directory\n",
    );
    #[cfg(windows)]
    {
        let result = new_ucmd!().arg("-d").arg(r"d\XXX").fails();
        result.no_stdout();
        let stderr = result.stderr_str();
        assert!(
            stderr.starts_with("mktemp: failed to create directory via template"),
            "{}",
            stderr
        );
        assert!(
            stderr.ends_with("d\\XXX': No such file or directory\n"),
            "{}",
            stderr
        );
    }
}
fn mixed_line_endings() -> Result<()> {
    let tempdir = TempDir::new()?;

    fs::write(
        tempdir.path().join("main.py"),
        "from test import say_hy\n\nif __name__ == \"__main__\":\n    say_hy(\"dear Ruff contributor\")\n",
    )?;

    fs::write(
        tempdir.path().join("test.py"),
        "def say_hy(name: str):\r\n    print(f\"Hy {name}\")\r\n",
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .args(["format", "--no-cache", "--diff", "--isolated"])
        .arg("."), @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    2 files left unchanged
    "###);
    Ok(())
}
fn set_statement_with_minus() {
    assert_eq!(
        hive().verified_stmt("SET hive.tez.java.opts = -Xmx4g"),
        Statement::SetVariable {
            local: false,
            hivevar: false,
            variable: ObjectName(vec![
                Ident::new("hive"),
                Ident::new("tez"),
                Ident::new("java"),
                Ident::new("opts")
            ]),
            value: vec![Expr::UnaryOp {
                op: UnaryOperator::Minus,
                expr: Box::new(Expr::Identifier(Ident::new("Xmx4g")))
            }],
        }
    );

    assert_eq!(
        hive().parse_sql_statements("SET hive.tez.java.opts = -"),
        Err(ParserError::ParserError(
            "Expected variable value, found: EOF".to_string()
        ))
    )
}
fn restriction1() {
    let fixture = super::fixture();
    let f = fixture.join("restrictions");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        restrictions: vec![Restriction::Path(f.clone())],
        ..ResolveOptions::default()
    });

    let resolution = resolver.resolve(&f, "pck2");
    assert_eq!(resolution, Err(ResolveError::Restriction(fixture.join("c.js"))));
}
fn parse_is_not_distinct_from() {
    use self::Expr::*;
    let sql = "a IS NOT DISTINCT FROM b";
    assert_eq!(
        IsNotDistinctFrom(
            Box::new(Identifier(Ident::new("a"))),
            Box::new(Identifier(Ident::new("b"))),
        ),
        verified_expr(sql)
    );
}
fn test_mv_overwrite_nonempty_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir_a = "test_mv_overwrite_nonempty_dir_a";
    let dir_b = "test_mv_overwrite_nonempty_dir_b";
    let dummy = "test_mv_overwrite_nonempty_dir_b/file";

    at.mkdir(dir_a);
    at.mkdir(dir_b);
    at.touch(dummy);
    // Not same error as GNU; the error message is a rust builtin
    // TODO: test (and implement) correct error message (or at least decide whether to do so)
    // Current: "mv: couldn't rename path (Directory not empty; from=a; to=b)"
    // GNU:     "mv: cannot move 'a' to 'b': Directory not empty"

    // Verbose output for the move should not be shown on failure
    let result = ucmd.arg("-vT").arg(dir_a).arg(dir_b).fails();
    result.no_stdout();
    assert!(!result.stderr_str().is_empty());

    assert!(at.dir_exists(dir_a));
    assert!(at.dir_exists(dir_b));
}
fn test_data_recovery() {
    let mut cluster = Cluster::default();
    let registry = cluster.node(0).tablet_registry();
    let tablet_2_path = registry.tablet_path(2, RAFT_INIT_LOG_INDEX);
    // The rocksdb is a bootstrapped tablet, so it will be opened and closed in
    // bootstrap, and then open again in fsm initialization.
    assert_eq!(count_info_log(&tablet_2_path), 2);
    let router = &mut cluster.routers[0];
    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    // Write 100 keys to default CF and not flush.
    let header = Box::new(router.new_request_for(2).take_header());
    for i in 0..100 {
        let mut put = SimpleWriteEncoder::with_capacity(64);
        put.put(
            CF_DEFAULT,
            format!("key{}", i).as_bytes(),
            format!("value{}", i).as_bytes(),
        );
        router
            .send(2, PeerMsg::simple_write(header.clone(), put.encode()).0)
            .unwrap();
    }

    // Write 100 keys to write CF and flush half.
    let mut sub = None;
    for i in 0..50 {
        let mut put = SimpleWriteEncoder::with_capacity(64);
        put.put(
            CF_WRITE,
            format!("key{}", i).as_bytes(),
            format!("value{}", i).as_bytes(),
        );
        let (msg, s) = PeerMsg::simple_write(header.clone(), put.encode());
        router.send(2, msg).unwrap();
        sub = Some(s);
    }
    let resp = block_on(sub.take().unwrap().result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    let mut cached = cluster.node(0).tablet_registry().get(2).unwrap();
    cached.latest().unwrap().flush_cf(CF_WRITE, true).unwrap();
    let router = &mut cluster.routers[0];
    for i in 50..100 {
        let mut put = SimpleWriteEncoder::with_capacity(64);
        put.put(
            CF_WRITE,
            format!("key{}", i).as_bytes(),
            format!("value{}", i).as_bytes(),
        );
        router
            .send(2, PeerMsg::simple_write(header.clone(), put.encode()).0)
            .unwrap();
    }

    // Write 100 keys to lock CF and flush all.
    for i in 0..100 {
        let mut put = SimpleWriteEncoder::with_capacity(64);
        put.put(
            CF_LOCK,
            format!("key{}", i).as_bytes(),
            format!("value{}", i).as_bytes(),
        );
        let (msg, s) = PeerMsg::simple_write(header.clone(), put.encode());
        router.send(2, msg).unwrap();
        sub = Some(s);
    }
    let resp = block_on(sub.take().unwrap().result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    cached = cluster.node(0).tablet_registry().get(2).unwrap();
    cached.latest().unwrap().flush_cf(CF_LOCK, true).unwrap();

    // Make sure all keys must be written.
    let router = &mut cluster.routers[0];
    let snap = router.stale_snapshot(2);
    for cf in DATA_CFS {
        for i in 0..100 {
            let key = format!("key{}", i);
            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();
            assert_eq!(
                value.as_deref(),
                Some(format!("value{}", i).as_bytes()),
                "{} {}",
                cf,
                key
            );
        }
    }
    let registry = cluster.node(0).tablet_registry();
    cached = registry.get(2).unwrap();
    cached
        .latest()
        .unwrap()
        .set_db_options(&[("avoid_flush_during_shutdown", "true")])
        .unwrap();
    drop((snap, cached));

    cluster.restart(0);

    let registry = cluster.node(0).tablet_registry();
    cached = registry.get(2).unwrap();
    cached
        .latest()
        .unwrap()
        .set_db_options(&[("avoid_flush_during_shutdown", "true")])
        .unwrap();
    let router = &mut cluster.routers[0];

    // Write another key to ensure all data are recovered.
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key101", b"value101");
    let resp = router.simple_write(2, header, put).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    // After being restarted, all unflushed logs should be applied again. So there
    // should be no missing data.
    let snap = router.stale_snapshot(2);
    for cf in DATA_CFS {
        for i in 0..100 {
            let key = format!("key{}", i);
            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();
            assert_eq!(
                value.as_deref(),
                Some(format!("value{}", i).as_bytes()),
                "{} {}",
                cf,
                key
            );
        }
    }

    // There is a restart, so LOG file should be rotate.
    assert_eq!(count_info_log(&tablet_2_path), 3);
    // We only trigger Flush twice, so there should be only 2 files. And because WAL
    // is disabled, so when rocksdb is restarted, there should be no WAL to recover,
    // so no additional flush will be triggered.
    assert_eq!(count_sst(&tablet_2_path), 2);

    cached = cluster.node(0).tablet_registry().get(2).unwrap();
    cached.latest().unwrap().flush_cfs(DATA_CFS, true).unwrap();

    // Although all CFs are triggered again, but recovery should only write:
    // 1. [0, 101) to CF_DEFAULT
    // 2. [50, 100) to CF_WRITE
    //
    // So there will be only 2 memtables to be flushed.
    assert_eq!(count_sst(&tablet_2_path), 4);

    drop((snap, cached));

    cluster.restart(0);

    let router = &mut cluster.routers[0];

    assert_eq!(count_info_log(&tablet_2_path), 4);
    // Because data is flushed before restarted, so all data can be read
    // immediately.
    let snap = router.stale_snapshot(2);
    for cf in DATA_CFS {
        for i in 0..100 {
            let key = format!("key{}", i);
            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();
            assert_eq!(
                value.as_deref(),
                Some(format!("value{}", i).as_bytes()),
                "{} {}",
                cf,
                key
            );
        }
    }
    // Trigger flush again.
    cached = cluster.node(0).tablet_registry().get(2).unwrap();
    cached.latest().unwrap().flush_cfs(DATA_CFS, true).unwrap();

    // There is no recovery, so there should be nothing to flush.
    assert_eq!(count_sst(&tablet_2_path), 4);
}
fn test_trailing_comma_enum_newtype_variant() {
    assert!(from_str::<Enum>("Newtype(1)").is_ok());
    assert!(from_str::<Enum>("Newtype(1,)").is_ok());
    assert!(from_str::<Enum>("Newtype(1,,)").is_err());
}
fn client_can_override_certificate_verification_and_reject_tls13_signatures() {
    for kt in ALL_KEY_TYPES.iter() {
        let mut client_config = make_client_config_with_versions(*kt, &[&rustls::version::TLS13]);
        let verifier = Arc::new(MockServerVerifier::rejects_tls13_signatures(
            Error::InvalidMessage(InvalidMessage::HandshakePayloadTooLarge),
        ));

        client_config
            .dangerous()
            .set_certificate_verifier(verifier);

        let server_config = Arc::new(make_server_config(*kt));

        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        let errs = do_handshake_until_both_error(&mut client, &mut server);
        assert_eq!(
            errs,
            Err(vec![
                ErrorFromPeer::Client(Error::InvalidMessage(
                    InvalidMessage::HandshakePayloadTooLarge,
                )),
                ErrorFromPeer::Server(Error::AlertReceived(AlertDescription::HandshakeFailure)),
            ]),
        );
    }
}
fn fast_log2_test() {
    assert_eq!(binary::fast_log2(2), 1);
    assert_eq!(binary::fast_log2(4), 2);
    assert_eq!(binary::fast_log2(8), 3);
    assert_eq!(binary::fast_log2(16), 4);
    assert_eq!(binary::fast_log2(32), 5);
}
fn parse_searched_case_expr() {
    let sql = "SELECT CASE WHEN bar IS NULL THEN 'null' WHEN bar = 0 THEN '=0' WHEN bar >= 0 THEN '>=0' ELSE '<0' END FROM foo";
    use self::BinaryOperator::*;
    use self::Expr::{BinaryOp, Case, Identifier, IsNull};
    let select = verified_only_select(sql);
    assert_eq!(
        &Case {
            operand: None,
            conditions: vec![
                IsNull(Box::new(Identifier(Ident::new("bar")))),
                BinaryOp {
                    left: Box::new(Identifier(Ident::new("bar"))),
                    op: Eq,
                    right: Box::new(Expr::Value(number("0"))),
                },
                BinaryOp {
                    left: Box::new(Identifier(Ident::new("bar"))),
                    op: GtEq,
                    right: Box::new(Expr::Value(number("0"))),
                },
            ],
            results: vec![
                Expr::Value(Value::SingleQuotedString("null".to_string())),
                Expr::Value(Value::SingleQuotedString("=0".to_string())),
                Expr::Value(Value::SingleQuotedString(">=0".to_string())),
            ],
            else_result: Some(Box::new(Expr::Value(Value::SingleQuotedString(
                "<0".to_string()
            )))),
        },
        expr_from_projection(only(&select.projection)),
    );
}
fn indent_style_parse_errors() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--indent-style"), ("invalid"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "indent_style_parse_errors",
        fs,
        console,
        result,
    ));
}
fn apply_noop() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_AFTER.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_noop",
        fs,
        console,
        result,
    ));
}
fn insert() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        assert!(!table.insert("hello", "world").unwrap());
        assert!(!table.insert("hello", "world2").unwrap());
        assert!(table.insert("hello", "world2").unwrap());
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert_eq!(
        vec!["world".to_string(), "world2".to_string()],
        get_vec(&table, "hello")
    );
    assert_eq!(table.len().unwrap(), 2);
}
fn test_value_as_bytes() {
    assert_eq!(Value::from("foo").as_bytes(), Some(&b"foo"[..]));
    assert_eq!(Value::from(&b"foo"[..]).as_bytes(), Some(&b"foo"[..]));
}
fn transactions_with_limit() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  CommandBuilder::new("wallet transactions")
    .rpc_server(&rpc_server)
    .stdout_regex(".*")
    .run_and_extract_stdout();

  rpc_server.mine_blocks(1);

  let output = CommandBuilder::new("wallet transactions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  assert_regex_match!(output[0].transaction.to_string(), "[[:xdigit:]]{64}");
  assert_eq!(output[0].confirmations, 1);

  rpc_server.mine_blocks(1);

  let output = CommandBuilder::new("wallet transactions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  assert_regex_match!(output[1].transaction.to_string(), "[[:xdigit:]]{64}");
  assert_eq!(output[1].confirmations, 2);

  let output = CommandBuilder::new("wallet transactions --limit 1")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  assert_regex_match!(output[0].transaction.to_string(), "[[:xdigit:]]{64}");
  assert_eq!(output[0].confirmations, 1);
}
fn test_du_no_permission() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    at.mkdir_all(SUB_DIR_LINKS);

    ts.ccmd("chmod").arg("-r").arg(SUB_DIR_LINKS).succeeds();

    let result = ts.ucmd().arg(SUB_DIR_LINKS).fails();
    result.stderr_contains("du: cannot read directory 'subdir/links': Permission denied");

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));
        if result_reference
            .stderr_str()
            .contains("du: cannot read directory 'subdir/links': Permission denied")
        {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }

    _du_no_permission(result.stdout_str());
}
fn test_majority_disk_full() {
    let mut cluster = new_node_cluster(0, 3);
    // To ensure the thread has full store disk usage infomation.
    cluster.cfg.raft_store.store_batch_system.pool_size = 1;
    cluster.pd_client.disable_default_operator();
    cluster.run();

    // To ensure all replicas are not pending.
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");

    cluster.must_transfer_leader(1, new_peer(1, 1));
    let region = cluster.get_region(b"k1");
    let epoch = region.get_region_epoch().clone();

    // To ensure followers have reported disk usages to the leader.
    for i in 1..3 {
        fail::cfg(get_fp(DiskUsage::AlmostFull, i + 1), "return").unwrap();
        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);
    }

    // Normal proposals will be rejected because of majority peers' disk full.
    let mut ch = cluster.async_put(b"k2", b"v2").unwrap();
    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();
    assert_eq!(disk_full_stores(&resp), vec![2, 3]);

    // Proposals with special `DiskFullOpt`s can be accepted even if all peers are
    // disk full.
    fail::cfg(get_fp(DiskUsage::AlmostFull, 1), "return").unwrap();
    let reqs = vec![new_put_cmd(b"k3", b"v3")];
    let put = new_request(1, epoch.clone(), reqs, false);
    let mut opts = RaftCmdExtraOpts::default();
    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;
    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();
    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();
    assert!(!resp.get_header().has_error());

    // Reset disk full status for peer 2 and 3. 2 follower reads must success
    // because the leader will continue to append entries to followers after the
    // new disk usages are reported.
    for i in 1..3 {
        fail::remove(get_fp(DiskUsage::AlmostFull, i + 1));
        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);
        must_get_equal(&cluster.get_engine(i + 1), b"k3", b"v3");
    }

    // To ensure followers have reported disk usages to the leader.
    for i in 1..3 {
        fail::cfg(get_fp(DiskUsage::AlreadyFull, i + 1), "return").unwrap();
        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);
    }

    // Proposals with special `DiskFullOpt`s will still be rejected if majority
    // peers are already disk full.
    let reqs = vec![new_put_cmd(b"k3", b"v3")];
    let put = new_request(1, epoch.clone(), reqs, false);
    let mut opts = RaftCmdExtraOpts::default();
    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;
    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();
    let resp = ch.recv_timeout(Duration::from_secs(10)).unwrap();
    assert_eq!(disk_full_stores(&resp), vec![2, 3]);

    // Peer 2 disk usage changes from already full to almost full.
    fail::remove(get_fp(DiskUsage::AlreadyFull, 2));
    fail::cfg(get_fp(DiskUsage::AlmostFull, 2), "return").unwrap();
    ensure_disk_usage_is_reported(&mut cluster, 2, 2, &region);

    // Configuration change should be alloed.
    cluster.pd_client.must_remove_peer(1, new_peer(2, 2));

    // After the last configuration change is applied, the raft group will be like
    // `[(1, DiskUsage::AlmostFull), (3, DiskUsage::AlreadyFull)]`. So no more
    // proposals should be allowed.
    let reqs = vec![new_put_cmd(b"k4", b"v4")];
    let put = new_request(1, epoch, reqs, false);
    let mut opts = RaftCmdExtraOpts::default();
    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;
    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();
    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();
    assert_eq!(disk_full_stores(&resp), vec![3]);

    for i in 0..3 {
        fail::remove(get_fp(DiskUsage::AlreadyFull, i + 1));
        fail::remove(get_fp(DiskUsage::AlmostFull, i + 1));
    }
}
fn test_gc_bypass_raft() {
    let (cluster, leader, ctx) = must_new_cluster_mul(2);
    cluster.pd_client.disable_default_operator();

    let env = Arc::new(Environment::new(1));
    let leader_store = leader.get_store_id();
    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader_store));
    let client = TikvClient::new(channel);

    let pk = b"k1".to_vec();
    let value = vec![b'x'; 300];
    let engine = cluster.engines.get(&leader_store).unwrap();

    for &start_ts in &[10, 20, 30, 40] {
        let commit_ts = start_ts + 5;
        let muts = vec![new_mutation(Op::Put, b"k1", &value)];

        must_kv_prewrite(&client, ctx.clone(), muts, pk.clone(), start_ts);
        let keys = vec![pk.clone()];
        must_kv_commit(&client, ctx.clone(), keys, start_ts, commit_ts, commit_ts);

        let key = Key::from_raw(b"k1").append_ts(start_ts.into());
        let key = data_key(key.as_encoded());
        assert!(engine.kv.get_value(&key).unwrap().is_some());

        let key = Key::from_raw(b"k1").append_ts(commit_ts.into());
        let key = data_key(key.as_encoded());
        assert!(engine.kv.get_value_cf(CF_WRITE, &key).unwrap().is_some());
    }

    let node_ids = cluster.get_node_ids();
    for store_id in node_ids {
        let gc_sched = cluster.sim.rl().get_gc_worker(store_id).scheduler();

        let mut region = cluster.get_region(b"a");
        region.set_start_key(b"k1".to_vec());
        region.set_end_key(b"k2".to_vec());
        sync_gc(&gc_sched, region, 200.into()).unwrap();

        let engine = cluster.engines.get(&store_id).unwrap();
        for &start_ts in &[10, 20, 30] {
            let commit_ts = start_ts + 5;
            let key = Key::from_raw(b"k1").append_ts(start_ts.into());
            let key = data_key(key.as_encoded());
            assert!(engine.kv.get_value(&key).unwrap().is_none());

            let key = Key::from_raw(b"k1").append_ts(commit_ts.into());
            let key = data_key(key.as_encoded());
            assert!(engine.kv.get_value_cf(CF_WRITE, &key).unwrap().is_none());
        }
    }
}
fn test_deny_non_finite_f32_key() {
    // We store float bits so that we can derive Ord, and other traits. In a
    // real context the code might involve a crate like ordered-float.

    #[derive(Eq, PartialEq, Ord, PartialOrd, Debug, Clone)]
    struct F32Bits(u32);
    impl Serialize for F32Bits {
        fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
        where
            S: Serializer,
        {
            serializer.serialize_f32(f32::from_bits(self.0))
        }
    }

    let map = treemap!(F32Bits(f32::INFINITY.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());

    let map = treemap!(F32Bits(f32::NEG_INFINITY.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());

    let map = treemap!(F32Bits(f32::NAN.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());
}
fn test_check_need_gc() {
    GC_COMPACTION_FILTER_PERFORM.reset();
    GC_COMPACTION_FILTER_SKIP.reset();

    let mut cfg = DbConfig::default();
    cfg.defaultcf.disable_auto_compactions = true;
    cfg.defaultcf.dynamic_level_bytes = false;
    let dir = tempfile::TempDir::new().unwrap();
    let builder = TestEngineBuilder::new().path(dir.path());
    let engine = builder
        .api_version(ApiVersion::V2)
        .build_with_cfg(&cfg)
        .unwrap();
    let raw_engine = engine.get_rocksdb();
    let mut gc_runner = TestGcRunner::new(0);

    do_write(&engine, false, 5);

    // Check init value
    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        0
    );
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        0
    );

    // TEST 1: If ratio_threshold < 1.0 || context.is_bottommost_level() is true,
    // check_need_gc return true, call dofilter
    gc_runner
        .safe_point(TimeStamp::max().into_inner())
        .gc_raw(&raw_engine);

    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        0
    );

    // TEST 2: props.num_versions as f64 > props.num_rows as f64 * ratio_threshold
    // return true.
    do_write(&engine, false, 5);
    engine.get_rocksdb().flush_cfs(&[], true).unwrap();

    do_gc(&raw_engine, 2, &mut gc_runner, &dir);

    do_write(&engine, false, 5);
    engine.get_rocksdb().flush_cfs(&[], true).unwrap();

    // Set ratio_threshold, let (props.num_versions as f64 > props.num_rows as
    // f64 * ratio_threshold) return true
    gc_runner.ratio_threshold = Option::Some(0.0f64);

    // is_bottommost_level = false
    do_gc(&raw_engine, 1, &mut gc_runner, &dir);

    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        3
    );
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        0
    );
}
fn batch_inscribe_with_multiple_inscriptions_with_parent() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let parent_output = CommandBuilder::new("wallet inscribe --fee-rate 5.0 --file parent.png")
    .write("parent.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let parent_id = parent_output.inscriptions[0].id;

  let output = CommandBuilder::new("wallet inscribe --fee-rate 1 --batch batch.yaml")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      format!("parent: {parent_id}\nmode: shared-output\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n")
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    r".*<dt>parent</dt>\s*<dd>.*</dd>.*",
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[1].id),
    r".*<dt>parent</dt>\s*<dd>.*</dd>.*",
  );

  let request = TestServer::spawn_with_args(&rpc_server, &[])
    .request(format!("/content/{}", output.inscriptions[2].id));
  assert_eq!(request.status(), 200);
  assert_eq!(request.headers().get("content-type").unwrap(), "audio/wav");
}
fn smoke() {
    let mut headers = HeaderMap::new();

    assert!(headers.get("hello").is_none());

    let name: HeaderName = "hello".parse().unwrap();

    match headers.entry(&name) {
        Entry::Vacant(e) => {
            e.insert("world".parse().unwrap());
        }
        _ => panic!(),
    }

    assert!(headers.get("hello").is_some());

    match headers.entry(&name) {
        Entry::Occupied(mut e) => {
            assert_eq!(e.get(), &"world");

            // Push another value
            e.append("zomg".parse().unwrap());

            let mut i = e.iter();

            assert_eq!(*i.next().unwrap(), "world");
            assert_eq!(*i.next().unwrap(), "zomg");
            assert!(i.next().is_none());
        }
        _ => panic!(),
    }
}
fn test_mv_arg_update_short_no_overwrite() {
    // same as --update=older
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_mv_arg_update_none_file1";
    let new = "test_mv_arg_update_none_file2";
    let old_content = "file1 content\n";
    let new_content = "file2 content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("-u")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), new_content);
}
fn test_placeholder() {
    // In postgres, this would be the absolute value operator '@' applied to the column 'xxx'
    // But in sqlite, this is a named parameter.
    // see https://www.sqlite.org/lang_expr.html#varparam
    let sql = "SELECT @xxx";
    let ast = sqlite().verified_only_select(sql);
    assert_eq!(
        ast.projection[0],
        UnnamedExpr(Expr::Value(Value::Placeholder("@xxx".into()))),
    );
}
fn test_default_issue_4821_t_tmpdir_p() {
    let scene = TestScenario::new(util_name!());
    let pathname = scene.fixtures.as_string();
    let result = scene
        .ucmd()
        .arg("-t")
        .arg("-p")
        .arg(&pathname)
        .arg("foo.XXXX")
        .succeeds();
    let stdout = result.stdout_str();
    println!("stdout = {stdout}");
    assert!(stdout.contains(&pathname));
}
fn starts_with_test() {
    assert_eq!(shared::starts_with(b"NaN".iter(), b"nAN".iter()), false);
    assert_eq!(shared::starts_with(b"nAN".iter(), b"nAN".iter()), true);
    assert_eq!(shared::starts_with(b"nAN1".iter(), b"nAN".iter()), true);
    assert_eq!(shared::starts_with(b"nAN1".iter(), b"nAN12".iter()), false);
}
fn delete() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
        table.insert("hello", "world2").unwrap();
        table.insert("hello", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert_eq!(
        vec![
            "world".to_string(),
            "world2".to_string(),
            "world3".to_string()
        ],
        get_vec(&table, "hello")
    );
    assert_eq!(table.len().unwrap(), 3);

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        table.remove("hello", "world2").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert_eq!(
        vec!["world".to_string(), "world3".to_string()],
        get_vec(&table, "hello")
    );
    assert_eq!(table.len().unwrap(), 2);

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        let mut iter = table.remove_all("hello").unwrap();
        assert_eq!("world", iter.next().unwrap().unwrap().value());
        assert_eq!("world3", iter.next().unwrap().unwrap().value());
        assert!(iter.next().is_none());
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert!(table.is_empty().unwrap());
    let empty: Vec<String> = vec![];
    assert_eq!(empty, get_vec(&table, "hello"));
}
fn test_mv_custom_backup_suffix() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_custom_backup_suffix_file_a";
    let file_b = "test_mv_custom_backup_suffix_file_b";
    let suffix = "super-suffix-of-the-century";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("-b")
        .arg(format!("--suffix={suffix}"))
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn config_builder_for_client_rejects_empty_kx_groups() {
    assert_eq!(
        ClientConfig::builder()
            .with_safe_default_cipher_suites()
            .with_kx_groups(&[])
            .with_safe_default_protocol_versions()
            .err(),
        Some(Error::General("no kx groups configured".into()))
    );
}
fn test_touch_set_date7() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_date";

    ucmd.args(&["-d", "2004-01-16 12:00 +0000", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let expected = FileTime::from_unix_time(1_074_254_400, 0);

    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime, expected);
    assert_eq!(mtime, expected);
}
async fn send_data_without_requesting_capacity() {
    h2_support::trace_init!();

    let payload = vec![0; 1024];

    let mock = mock_io::Builder::new()
        .handshake()
        .write(&[
            // POST /
            0, 0, 16, 1, 4, 0, 0, 0, 1, 131, 135, 65, 139, 157, 41, 172, 75, 143, 168, 233, 25, 151,
            33, 233, 132,
        ])
        .write(&[
            // DATA
            0, 4, 0, 0, 1, 0, 0, 0, 1,
        ])
        .write(&payload[..])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[0, 0, 1, 1, 5, 0, 0, 0, 1, 0x89])
        .build();

    let (mut client, mut h2) = client::handshake(mock).await.unwrap();

    let request = Request::builder()
        .method(Method::POST)
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    let (response, mut stream) = client.send_request(request, false).unwrap();

    // The capacity should be immediately allocated
    assert_eq!(stream.capacity(), 0);

    // Send the data
    stream.send_data(payload.into(), true).unwrap();

    // Get the response
    let resp = h2.run(response).await.unwrap();
    assert_eq!(resp.status(), StatusCode::NO_CONTENT);

    h2.await.unwrap();
}
fn inscribe_to_specific_destination() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);
  rpc_server.mine_blocks(1);

  let destination = CommandBuilder::new("wallet receive")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<ord::subcommand::wallet::receive::Output>()
    .address;

  let txid = CommandBuilder::new(format!(
    "wallet inscribe --destination {} --file degenerate.png --fee-rate 1",
    destination.clone().assume_checked()
  ))
  .write("degenerate.png", [1; 520])
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Inscribe>()
  .reveal;

  let reveal_tx = &rpc_server.mempool()[1]; // item 0 is the commit, item 1 is the reveal.
  assert_eq!(reveal_tx.txid(), txid);
  assert_eq!(
    reveal_tx.output.first().unwrap().script_pubkey,
    destination.payload.script_pubkey()
  );
}
fn add_set_values_in_context() {
    let mut context = Context::new();
    context.insert("my_var", &"hey");
    context.insert("malicious", &"<html>");
    context.insert("admin", &true);
    context.insert("num", &1);

    let inputs = vec![
        ("{% set i = 1 %}{{ i }}", "1"),
        ("{% set i = 1 + 2 %}{{ i }}", "3"),
        (r#"{% set i = "hey" %}{{ i }}"#, "hey"),
        (r#"{% set i = "<html>" %}{{ i | safe }}"#, "<html>"),
        (r#"{% set i = "<html>" %}{{ i }}"#, "&lt;html&gt;"),
        ("{% set i = my_var %}{{ i }}", "hey"),
        ("{% set i = malicious %}{{ i | safe }}", "<html>"),
        ("{% set i = malicious %}{{ i }}", "&lt;html&gt;"),
        ("{% set i = my_var | upper %}{{ i }}", "HEY"),
        ("{% set i = range(end=3) %}{{ i }}", "[0, 1, 2]"),
        ("{% set i = admin or true %}{{ i }}", "true"),
        ("{% set i = admin and num > 0 %}{{ i }}", "true"),
        ("{% set i = 0 / 0 %}{{ i }}", "NaN"),
        ("{% set i = [1,2] %}{{ i }}", "[1, 2]"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn render_macros_override_default_args() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello(val=1) %}{{val}}{% endmacro hello %}"),
        ("hello.html", "{% import \"macros\" as macros %}{{macros::hello(val=2)}}"),
    ])
    .unwrap();
    let result = tera.render("hello.html", &Context::new());

    assert_eq!(result.unwrap(), "2".to_string());
}
fn can_inherit_macro_import_from_grandparent() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}HELLO{% endmacro hello %}"),
        ("grandparent", "{% import \"macros\" as macros %}{% block bob %}grandparent{% endblock bob %}"),
        ("parent", "{% extends \"grandparent\" %}{% import \"macros\" as macros2 %}{% block bob %}parent{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{macros::hello()}}-{{macros2::hello()}}{% endblock bob %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::default());
    assert_eq!(result.unwrap(), "HELLO-HELLO".to_string());
}
fn test_something() {
    let data = [];
    let stream_safe = input.chars().stream_safe().collect::<String>();
    let mut value = Rc::new(RefCell::new(0));
    let counter = Counter {
        iter: stream_safe.chars(),
        value: Rc::clone(&mut value),
    };
    for _ in counter.nfc() {
        assert!(*value.borrow() <= MAX_NONSTARTERS + 1);
        *value.borrow_mut() = 0;
    }
}
fn test_index_aggr_count() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:3"), 3),
        (4, Some("name:0"), 1),
        (5, Some("name:5"), 4),
        (6, Some("name:5"), 4),
        (7, None, 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);
    // for dag
    let req = DagSelect::from_index(&product, &product["name"])
        .count(&product["id"])
        .output_offsets(Some(vec![0]))
        .build();
    let mut resp = handle_select(&endpoint, req);
    let mut spliter = DagChunkSpliter::new(resp.take_chunks().into(), 1);
    let expected_encoded = datum::encode_value(
        &mut EvalContext::default(),
        &[Datum::U64(data.len() as u64)],
    )
    .unwrap();
    let ret_data = spliter.next();
    assert_eq!(ret_data.is_some(), true);
    let result_encoded =
        datum::encode_value(&mut EvalContext::default(), &ret_data.unwrap()).unwrap();
    assert_eq!(&*result_encoded, &*expected_encoded);
    assert_eq!(spliter.next().is_none(), true);

    let exp = vec![
        (Datum::Null, 1),
        (Datum::Bytes(b"name:0".to_vec()), 2),
        (Datum::Bytes(b"name:3".to_vec()), 1),
        (Datum::Bytes(b"name:5".to_vec()), 2),
    ];
    // for dag
    let req = DagSelect::from_index(&product, &product["name"])
        .count(&product["id"])
        .group_by(&[&product["name"]])
        .output_offsets(Some(vec![0, 1]))
        .build();
    resp = handle_select(&endpoint, req);
    let mut row_count = 0;
    let exp_len = exp.len();
    let spliter = DagChunkSpliter::new(resp.take_chunks().into(), 2);
    let mut results = spliter.collect::<Vec<Vec<Datum>>>();
    sort_by!(results, 1, Bytes);
    for (row, (name, cnt)) in results.iter().zip(exp) {
        let expected_datum = vec![Datum::U64(cnt), name];
        let expected_encoded =
            datum::encode_value(&mut EvalContext::default(), &expected_datum).unwrap();
        let result_encoded = datum::encode_value(&mut EvalContext::default(), row).unwrap();
        assert_eq!(&*result_encoded, &*expected_encoded);
        row_count += 1;
    }
    assert_eq!(row_count, exp_len);

    let exp = vec![
        (vec![Datum::Null, Datum::I64(4)], 1),
        (vec![Datum::Bytes(b"name:0".to_vec()), Datum::I64(1)], 1),
        (vec![Datum::Bytes(b"name:0".to_vec()), Datum::I64(2)], 1),
        (vec![Datum::Bytes(b"name:3".to_vec()), Datum::I64(3)], 1),
        (vec![Datum::Bytes(b"name:5".to_vec()), Datum::I64(4)], 2),
    ];
    let req = DagSelect::from_index(&product, &product["name"])
        .count(&product["id"])
        .group_by(&[&product["name"], &product["count"]])
        .build();
    resp = handle_select(&endpoint, req);
    let mut row_count = 0;
    let exp_len = exp.len();
    let spliter = DagChunkSpliter::new(resp.take_chunks().into(), 3);
    let mut results = spliter.collect::<Vec<Vec<Datum>>>();
    sort_by!(results, 1, Bytes);
    for (row, (gk_data, cnt)) in results.iter().zip(exp) {
        let mut expected_datum = vec![Datum::U64(cnt)];
        expected_datum.extend_from_slice(gk_data.as_slice());
        let expected_encoded =
            datum::encode_value(&mut EvalContext::default(), &expected_datum).unwrap();
        let result_encoded = datum::encode_value(&mut EvalContext::default(), row).unwrap();
        assert_eq!(&*result_encoded, &*expected_encoded);
        row_count += 1;
    }
    assert_eq!(row_count, exp_len);
}
fn error_tests() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let f = 2762159900.0f32;
    let actual = unsafe { std::str::from_utf8_unchecked(f.to_lexical(&mut buffer)) };
    let roundtrip = actual.parse::<f32>();
    assert_eq!(Ok(f), roundtrip);

    let f = 77371252000000000000000000.0f32;
    let actual = unsafe { std::str::from_utf8_unchecked(f.to_lexical(&mut buffer)) };
    let roundtrip = actual.parse::<f32>();
    assert_eq!(Ok(f), roundtrip);
}
fn test_parenthesized_argument() {
    let source_code = r#"f((a))"#;
    let expr = parse_expression(source_code, "<filename>").unwrap();

    let call = expr.as_call_expr().unwrap();
    let arguments = &call.arguments;
    let argument = arguments.args.first().unwrap();

    let parenthesized = parenthesized_range(
        argument.into(),
        arguments.into(),
        &CommentRanges::default(),
        source_code,
    );
    assert_eq!(parenthesized, Some(TextRange::new(2.into(), 5.into())));
}
fn test_indent() {
    let teststring = String::from("test\ntest1\n\ntest2\n");
    assert_eq!(
        indent(teststring, 2, None, None),
        String::from("test\n  test1\n\n  test2")
    );
}
fn cid_rotation() {
    let _guard = subscribe();
    const CID_TIMEOUT: Duration = Duration::from_secs(2);

    let cid_generator_factory: fn() -> Box<dyn ConnectionIdGenerator> =
        || Box::new(*RandomConnectionIdGenerator::new(8).set_lifetime(CID_TIMEOUT));

    // Only test cid rotation on server side to have a clear output trace
    let server = Endpoint::new(
        Arc::new(EndpointConfig {
            connection_id_generator_factory: Arc::new(cid_generator_factory),
            ..EndpointConfig::default()
        }),
        Some(Arc::new(server_config())),
        true,
    );
    let client = Endpoint::new(Arc::new(EndpointConfig::default()), None, true);

    let mut pair = Pair::new_from_endpoint(client, server);
    let (_, server_ch) = pair.connect();

    let mut round: u64 = 1;
    let mut stop = pair.time;
    let end = pair.time + 5 * CID_TIMEOUT;

    use crate::cid_queue::CidQueue;
    use crate::LOC_CID_COUNT;
    let mut active_cid_num = CidQueue::LEN as u64 + 1;
    active_cid_num = active_cid_num.min(LOC_CID_COUNT);
    let mut left_bound = 0;
    let mut right_bound = active_cid_num - 1;

    while pair.time < end {
        stop += CID_TIMEOUT;
        // Run a while until PushNewCID timer fires
        while pair.time < stop {
            if !pair.step() {
                if let Some(time) = min_opt(pair.client.next_wakeup(), pair.server.next_wakeup()) {
                    pair.time = time;
                }
            }
        }
        info!(
            "Checking active cid sequence range before {:?} seconds",
            round * CID_TIMEOUT.as_secs()
        );
        let _bound = (left_bound, right_bound);
        assert_matches!(
            pair.server_conn_mut(server_ch).active_local_cid_seq(),
            _bound
        );
        round += 1;
        left_bound += active_cid_num;
        right_bound += active_cid_num;
        pair.drive_server();
    }
}
fn test() {
    let f = super::fixture().join("exports-field");
    let f2 = super::fixture().join("exports-field2");
    let f4 = super::fixture().join("exports-field-error");
    let f5 = super::fixture().join("imports-exports-wildcard");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        fully_specified: true,
        condition_names: vec!["webpack".into()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("resolve root using exports field, not a main field", f.clone(), "exports-field", f.join("node_modules/exports-field/x.js")),
        ("resolver should respect condition names", f.clone(), "exports-field/dist/main.js", f.join("node_modules/exports-field/lib/lib2/main.js")),
        // enhanced_resolve behaves differently to node.js. enhanced_resolve fallbacks when an
        // array item is unresolved, where as node.js fallbacks when an array has an
        // InvalidPackageTarget error.
        // ("resolver should respect fallback", f2.clone(), "exports-field/dist/browser.js", f2.join("node_modules/exports-field/lib/browser.js")),
        // The following two tests require fallback from array values, the path is changed here to
        // only test query and fragment.
        ("resolver should respect query parameters #1", f2.clone(), "exports-field/dist/main.js?foo", f2.join("node_modules/exports-field/lib/lib2/main.js?foo")),
        ("resolver should respect fragment parameters #1", f2.clone(), "exports-field/dist/main.js#foo", f2.join("node_modules/exports-field/lib/lib2/main.js#foo")),
        ("relative path should work, if relative path as request is used", f.clone(), "./node_modules/exports-field/lib/main.js", f.join("node_modules/exports-field/lib/main.js")),
        ("self-resolving root", f.clone(), "@exports-field/core", f.join("a.js")),
        ("should resolve with wildcard pattern #1", f5.clone(), "m/features/f.js", f5.join("node_modules/m/src/features/f.js")),
        ("should resolve with wildcard pattern #2", f5.clone(), "m/features/y/y.js", f5.join("node_modules/m/src/features/y/y.js")),
        ("should resolve with wildcard pattern #3", f5.clone(), "m/features-no-ext/y/y.js", f5.join("node_modules/m/src/features/y/y.js")),
        ("should resolve with wildcard pattern #4", f5.clone(), "m/middle/nested/f.js", f5.join("node_modules/m/src/middle/nested/f.js")),
        ("should resolve with wildcard pattern #5", f5.clone(), "m/middle-1/nested/f.js", f5.join("node_modules/m/src/middle-1/nested/f.js")),
        ("should resolve with wildcard pattern #6", f5.clone(), "m/middle-2/nested/f.js", f5.join("node_modules/m/src/middle-2/nested/f.js")),
        ("should resolve with wildcard pattern #7", f5.clone(), "m/middle-3/nested/f", f5.join("node_modules/m/src/middle-3/nested/f/nested/f.js")),
        ("should resolve with wildcard pattern #8", f5.clone(), "m/middle-4/f/nested", f5.join("node_modules/m/src/middle-4/f/f.js")),
        ("should resolve with wildcard pattern #9", f5.clone(), "m/middle-5/f$/$", f5.join("node_modules/m/src/middle-5/f$/$.js")),
    ];

    // Not needed or snapshot:
    //   * should log the correct info

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }

    #[rustfmt::skip]
    let fail = [
        // ("throw error if extension not provided", f2.clone(), "exports-field/dist/main", ResolveError::NotFound(f2.join("node_modules/exports-field/lib/lib2/main"))),
        ("resolver should respect query parameters #2. Direct matching", f2.clone(), "exports-field?foo", ResolveError::PackagePathNotExported("./?foo".into())),
        ("resolver should respect fragment parameters #2. Direct matching", f2, "exports-field#foo", ResolveError::PackagePathNotExported("./#foo".into())),
        ("relative path should not work with exports field", f.clone(), "./node_modules/exports-field/dist/main.js", ResolveError::NotFound(f.join("node_modules/exports-field/dist/main.js"))),
        ("backtracking should not work for request", f.clone(), "exports-field/dist/../../../a.js", ResolveError::InvalidPackageTarget("./lib/../../../a.js".to_string())),
        ("backtracking should not work for exports field target", f.clone(), "exports-field/dist/a.js", ResolveError::InvalidPackageTarget("./../../a.js".to_string())),
        ("not exported error", f.clone(), "exports-field/anything/else", ResolveError::PackagePathNotExported("./anything/else".to_string())),
        ("request ending with slash #1", f.clone(), "exports-field/", ResolveError::PackagePathNotExported("./".to_string())),
        ("request ending with slash #2", f.clone(), "exports-field/dist/", ResolveError::PackagePathNotExported("./dist/".to_string())),
        ("request ending with slash #3", f.clone(), "exports-field/lib/", ResolveError::PackagePathNotExported("./lib/".to_string())),
        ("should throw error if target is invalid", f4, "exports-field", ResolveError::InvalidPackageTarget("./a/../b/../../pack1/index.js".to_string())),
        ("throw error if exports field is invalid", f.clone(), "invalid-exports-field", ResolveError::InvalidPackageConfig(f.join("node_modules/invalid-exports-field/package.json"))),
        ("should throw error if target is 'null'", f5, "m/features/internal/file.js", ResolveError::PackagePathNotExported("./features/internal/file.js".to_string())),
    ];

    for (comment, path, request, error) in fail {
        let resolution = resolver.resolve(&path, request);
        assert_eq!(resolution, Err(error), "{comment} {path:?} {request}");
    }
}
fn test_backup_huge_range_and_import() {
    let mut suite = TestSuite::new(3, 100, ApiVersion::V1);
    // 3 version for each key.
    // make sure we will have two batch files
    let key_count = 1024 * 3 / 2;
    suite.must_kv_put(key_count, 3);

    // Push down backup request.
    let tmp = Builder::new().tempdir().unwrap();
    let backup_ts = suite.alloc_ts();
    let storage_path = make_unique_dir(tmp.path());
    let rx = suite.backup(
        vec![],   // start
        vec![],   // end
        0.into(), // begin_ts
        backup_ts,
        &storage_path,
    );
    let mut resps1 = block_on(rx.collect::<Vec<_>>());
    resps1.sort_by(|r1, r2| r1.start_key.cmp(&r2.start_key));

    // Only leader can handle backup.
    // ... But the response may be split into two parts (when meeting huge region).
    assert_eq!(resps1.len(), 2, "{:?}", resps1);
    let mut files1 = resps1
        .iter()
        .flat_map(|x| x.files.iter())
        .cloned()
        .collect::<Vec<_>>();
    // Short value is piggybacked in write cf, so we get 1 sst at least.
    assert!(!resps1[0].get_files().is_empty());

    // Sort the files for avoiding race conditions. (would this happen?)
    files1.sort_by(|f1, f2| f1.start_key.cmp(&f2.start_key));

    assert_eq!(resps1[0].start_key, b"".to_vec());
    assert_eq!(resps1[0].end_key, resps1[1].start_key);
    assert_eq!(resps1[1].end_key, b"".to_vec());

    assert_eq!(files1.len(), 2);
    assert_ne!(files1[0].start_key, files1[0].end_key);
    assert_ne!(files1[1].start_key, files1[1].end_key);
    assert_eq!(files1[0].end_key, files1[1].start_key);

    // Use importer to restore backup files.
    let backend = make_local_backend(&storage_path);
    let storage = create_storage(&backend, Default::default()).unwrap();
    let region = suite.cluster.get_region(b"");
    let mut sst_meta = SstMeta::default();
    sst_meta.region_id = region.get_id();
    sst_meta.set_region_epoch(region.get_region_epoch().clone());
    let mut metas = vec![];
    for f in files1.clone().into_iter() {
        let mut reader = storage.read(&f.name);
        let mut content = vec![];
        block_on(reader.read_to_end(&mut content)).unwrap();
        let mut m = sst_meta.clone();
        m.crc32 = calc_crc32_bytes(&content);
        m.length = content.len() as _;
        // set different uuid for each file
        m.set_uuid(uuid::Uuid::new_v4().as_bytes().to_vec());
        m.cf_name = name_to_cf(&f.name).to_owned();
        metas.push((m, content));
    }

    for (m, c) in &metas {
        for importer in suite.cluster.sim.rl().importers.values() {
            let mut f = importer.create(m).unwrap();
            f.append(c).unwrap();
            f.finish().unwrap();
        }

        // Make ingest command.
        let mut ingest = Request::default();
        ingest.set_cmd_type(CmdType::IngestSst);
        ingest.mut_ingest_sst().set_sst(m.clone());
        let mut header = RaftRequestHeader::default();
        let leader = suite.context.get_peer().clone();
        header.set_peer(leader);
        header.set_region_id(suite.context.get_region_id());
        header.set_region_epoch(suite.context.get_region_epoch().clone());
        let mut cmd = RaftCmdRequest::default();
        cmd.set_header(header);
        cmd.mut_requests().push(ingest);
        let resp = suite
            .cluster
            .call_command_on_leader(cmd, Duration::from_secs(5))
            .unwrap();
        assert!(!resp.get_header().has_error(), "{:?}", resp);
    }

    // Backup file should have same contents.
    let rx = suite.backup(
        vec![],   // start
        vec![],   // end
        0.into(), // begin_ts
        backup_ts,
        &make_unique_dir(tmp.path()),
    );
    let resps3 = block_on(rx.collect::<Vec<_>>());
    assert_same_files(
        files1,
        resps3
            .iter()
            .flat_map(|x| x.files.iter())
            .cloned()
            .collect(),
    );

    suite.stop();
}
fn test_concurrent_requests_0_conn() {
    let mut options = ResolverOpts::default();

    // there are two connections, but no concurrency requested, 0==1
    options.num_concurrent_reqs = 0;

    // we want to make sure that both udp connections are called
    //   this will count down to 0 only if both are called.
    let on_send = OnSendBarrier::new(1);

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));

    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);

    let udp1_nameserver = mock_nameserver_on_send(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        options.clone(),
        on_send,
    );
    let udp2_nameserver = udp1_nameserver.clone();

    let pool = mock_nameserver_pool_on_send(
        vec![udp2_nameserver, udp1_nameserver],
        vec![],
        None,
        options,
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    // there's no actual network traffic happening, 1 sec should be plenty
    //   TODO: for some reason this timeout doesn't work, not clear why...
    // let future = Timeout::new(future, Duration::from_secs(1));

    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], udp_record);
}
fn test_node_merge_write_data_to_source_region_after_merging() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(100);
    // For snapshot after merging
    cluster.cfg.raft_store.merge_max_log_gap = 10;
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(12);
    cluster.cfg.raft_store.apply_batch_system.max_batch_size = Some(1);
    cluster.cfg.raft_store.apply_batch_system.pool_size = 2;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k2", b"v2");

    let mut region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");

    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    let right_peer_2 = find_peer(&right, 2).cloned().unwrap();
    assert_eq!(right_peer_2.get_id(), 2);

    // Make sure peer 2 finish split before pause
    cluster.must_put(b"k2pause", b"vpause");
    must_get_equal(&cluster.get_engine(2), b"k2pause", b"vpause");

    let on_handle_apply_2_fp = "on_handle_apply_2";
    fail::cfg(on_handle_apply_2_fp, "pause").unwrap();

    let right_peer_1 = find_peer(&right, 1).cloned().unwrap();
    cluster.must_transfer_leader(right.get_id(), right_peer_1);

    let left_peer_3 = find_peer(&left, 3).cloned().unwrap();
    cluster.must_transfer_leader(left.get_id(), left_peer_3.clone());

    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    cluster.must_try_merge(left.get_id(), right.get_id());

    cluster.add_send_filter(IsolationFilterFactory::new(3));

    fail::remove(schedule_merge_fp);

    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));

    region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");
    let state1 = cluster.apply_state(region.get_id(), 1);
    for i in 0..15 {
        cluster.must_put(format!("k2{}", i).as_bytes(), b"v2");
    }
    cluster.wait_log_truncated(region.get_id(), 1, state1.get_applied_index());
    // Ignore this msg to make left region exist.
    let on_has_merge_target_fp = "on_has_merge_target";
    fail::cfg(on_has_merge_target_fp, "return").unwrap();

    cluster.clear_send_filters();
    // On store 3, now the right region is updated by snapshot not applying logs
    // so the left region still exist.
    // Wait for left region to rollback merge (in previous wrong implementation)
    sleep_ms(200);
    // Write data to left region
    let mut new_left = left;
    let mut epoch = new_left.take_region_epoch();
    // prepareMerge => conf_ver + 1, version + 1
    // rollbackMerge => version + 1
    epoch.set_conf_ver(epoch.get_conf_ver() + 1);
    epoch.set_version(epoch.get_version() + 2);
    let mut req = new_request(
        new_left.get_id(),
        epoch,
        vec![new_put_cf_cmd("default", b"k11", b"v11")],
        false,
    );
    req.mut_header().set_peer(left_peer_3);
    if let Ok(()) = cluster
        .sim
        .rl()
        .async_command_on_node(3, req, Callback::None)
    {
        sleep_ms(200);
        // The write must not succeed
        must_get_none(&cluster.get_engine(2), b"k11");
        must_get_none(&cluster.get_engine(3), b"k11");
    }

    fail::remove(on_handle_apply_2_fp);
}
fn test_parse_zone_keys() {
    use hickory_proto::rr::dnssec::Algorithm;
    use hickory_proto::rr::Name;

    let config = Config::from_toml(
        "
[[zones]]
zone = \"example.com\"
zone_type = \"Primary\"
file = \"example.com.zone\"

\
         [[zones.keys]]
key_path = \"/path/to/my_ed25519.pem\"
algorithm = \"ED25519\"
\
         signer_name = \"ns.example.com.\"
is_zone_signing_key = false
is_zone_update_auth = true

[[zones.keys]]
key_path = \"/path/to/my_rsa.pem\"
algorithm = \
         \"RSASHA256\"
signer_name = \"ns.example.com.\"
",
    )
    .unwrap();
    assert_eq!(
        config.get_zones()[0].get_keys()[0].key_path(),
        Path::new("/path/to/my_ed25519.pem")
    );
    assert_eq!(
        config.get_zones()[0].get_keys()[0].algorithm().unwrap(),
        Algorithm::ED25519
    );
    assert_eq!(
        config.get_zones()[0].get_keys()[0]
            .signer_name()
            .unwrap()
            .unwrap(),
        Name::parse("ns.example.com.", None).unwrap()
    );
    assert!(!config.get_zones()[0].get_keys()[0].is_zone_signing_key(),);
    assert!(config.get_zones()[0].get_keys()[0].is_zone_update_auth(),);

    assert_eq!(
        config.get_zones()[0].get_keys()[1].key_path(),
        Path::new("/path/to/my_rsa.pem")
    );
    assert_eq!(
        config.get_zones()[0].get_keys()[1].algorithm().unwrap(),
        Algorithm::RSASHA256
    );
    assert_eq!(
        config.get_zones()[0].get_keys()[1]
            .signer_name()
            .unwrap()
            .unwrap(),
        Name::parse("ns.example.com.", None).unwrap()
    );
    assert!(!config.get_zones()[0].get_keys()[1].is_zone_signing_key(),);
    assert!(!config.get_zones()[0].get_keys()[1].is_zone_update_auth(),);
}
fn hash() {
  assert_eq!(
    CommandBuilder::new("parse 0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef")
      .run_and_deserialize_output::<Output>(),
    Output {
      object: "0123456789abcdef0123456789abcdef0123456789abcdef0123456789abcdef"
        .parse::<Object>()
        .unwrap(),
    }
  );
}
fn parse_select_distinct_missing_paren() {
    let result = parse_sql_statements("SELECT DISTINCT (name, id FROM customer");
    assert_eq!(
        ParserError::ParserError("Expected ), found: FROM".to_string()),
        result.unwrap_err(),
    );
}
fn i128_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();

    let definition: TableDefinition<i128, i128> = TableDefinition::new("x");

    {
        let mut table = write_txn.open_table(definition).unwrap();
        for i in -10..=10 {
            table.insert(&i, &(i - 1)).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(-2, table.get(&-1).unwrap().unwrap().value());
    let mut iter: Range<i128, i128> = table.range::<i128>(..).unwrap();
    for i in -11..10 {
        assert_eq!(iter.next().unwrap().unwrap().1.value(), i);
    }
    assert!(iter.next().is_none());
}
async fn async_then_sync_trap() -> Result<()> {
    // Test the trapping and capturing the stack with the following sequence of
    // calls:
    //
    // a[async] ---> b[host] ---> c[sync]

    drop(env_logger::try_init());

    let wat = r#"
        (module
            (import "" "b" (func $b))
            (func $a (export "a")
                call $b
            )
            (func $c (export "c")
                unreachable
            )
        )
    "#;

    let mut sync_store = Store::new(&Engine::default(), ());

    let sync_module = Module::new(sync_store.engine(), wat)?;

    let mut sync_linker = Linker::new(sync_store.engine());
    sync_linker.func_wrap("", "b", |_caller: Caller<_>| unreachable!())?;

    let sync_instance = sync_linker.instantiate(&mut sync_store, &sync_module)?;

    struct AsyncCtx {
        sync_instance: Instance,
        sync_store: Store<()>,
    }

    let mut async_store = Store::new(
        &Engine::new(Config::new().async_support(true)).unwrap(),
        AsyncCtx {
            sync_instance,
            sync_store,
        },
    );

    let async_module = Module::new(async_store.engine(), wat)?;

    let mut async_linker = Linker::new(async_store.engine());
    async_linker.func_wrap("", "b", move |mut caller: Caller<AsyncCtx>| {
        log::info!("Called `b`...");
        let sync_instance = caller.data().sync_instance;
        let sync_store = &mut caller.data_mut().sync_store;

        log::info!("Calling `c`...");
        let c = sync_instance
            .get_typed_func::<(), ()>(&mut *sync_store, "c")
            .unwrap();
        c.call(sync_store, ())?;
        Ok(())
    })?;

    let async_instance = async_linker
        .instantiate_async(&mut async_store, &async_module)
        .await?;

    log::info!("Calling `a`...");
    let a = async_instance
        .get_typed_func::<(), ()>(&mut async_store, "a")
        .unwrap();
    let trap = a.call_async(&mut async_store, ()).await.unwrap_err();

    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();
    // We don't support cross-store or cross-engine symbolication currently, so
    // the other frames are ignored.
    assert_eq!(trace.len(), 1);
    assert_eq!(trace[0].func_name(), Some("c"));

    Ok(())
}
fn test_create_stage_with_file_format() {
    let sql = concat!(
        "CREATE OR REPLACE STAGE my_ext_stage ",
        "URL='s3://load/files/' ",
        "FILE_FORMAT=(COMPRESSION=AUTO BINARY_FORMAT=HEX ESCAPE='\\')"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CreateStage { file_format, .. } => {
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "COMPRESSION".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "AUTO".to_string()
            }));
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "BINARY_FORMAT".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "HEX".to_string()
            }));
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "ESCAPE".to_string(),
                option_type: DataLoadingOptionType::STRING,
                value: "\\".to_string()
            }));
        }
        _ => unreachable!(),
    };
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn does_not_handle_included_files_if_overridden_by_ignore_formatter() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "formatter": { "include": ["test.js", "test2.js"], "ignore": ["test.js"] }
}
"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED);

    drop(file);

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_included_files_if_overridden_by_ignore_formatter",
        fs,
        console,
        result,
    ));
}
fn does_include_file_with_different_overrides() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "overrides": [
    { "include": ["test.js"], "formatter": { "lineWidth": 20 } },
    { "include": ["test2.js"], "formatter": { "lineWidth": 20, "indentStyle": "space" } }
   ]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test, FORMATTED_LINE_WIDTH_OVERRIDDEN);
    assert_file_contents(&fs, test2, FORMATTED_LINE_WITH_SPACES);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_overrides",
        fs,
        console,
        result,
    ));
}
fn type_mismatch() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (type $t' (resource (rep i32)))
                (export $t "t" (type $t'))

                (core func $drop (canon resource.drop $t))

                (func (export "f1") (param "x" (own $t))
                    (canon lift (core func $drop)))
                (func (export "f2") (param "x" (borrow $t))
                    (canon lift (core func $drop)))
                (func (export "f3") (param "x" u32)
                    (canon lift (core func $drop)))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let i = Linker::new(&engine).instantiate(&mut store, &c)?;

    assert!(i
        .get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f1")
        .is_err());
    assert!(i
        .get_typed_func::<(&ResourceAny,), ()>(&mut store, "f1")
        .is_ok());

    assert!(i
        .get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f2")
        .is_err());
    assert!(i
        .get_typed_func::<(&ResourceAny,), ()>(&mut store, "f2")
        .is_ok());

    assert!(i
        .get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f3")
        .is_err());
    assert!(i
        .get_typed_func::<(&ResourceAny,), ()>(&mut store, "f3")
        .is_err());
    assert!(i.get_typed_func::<(u32,), ()>(&mut store, "f3").is_ok());

    Ok(())
}
fn is_success() {
    assert!(status_code(200).is_success());
    assert!(status_code(299).is_success());

    assert!(!status_code(199).is_success());
    assert!(!status_code(300).is_success());
}
fn compute_float_f32_rounding() {
    // These test near-halfway cases for single-precision floats.
    assert_eq!(compute_float32(0, 16777216), (151, 0));
    assert_eq!(compute_float32(0, 16777217), (151, 0));
    assert_eq!(compute_float32(0, 16777218), (151, 1));
    assert_eq!(compute_float32(0, 16777219), (151, 2));
    assert_eq!(compute_float32(0, 16777220), (151, 2));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));
    assert_eq!(compute_float32(-10, 167772170000000000), (151, 0));
    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));
    // Let's check the lines to see if anything is different in table...
    assert_eq!(compute_float32(-10, 167772190000000000), (151, 2));
    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));
}
fn test_force_leader_twice_on_same_peer() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    // restart to clean lease
    cluster.stop_node(1);
    cluster.run_node(1).unwrap();
    cluster.stop_node(2);
    cluster.run_node(2).unwrap();

    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn stdin_override_parser_ipynb() {
    let args = ["--extension", "py:ipynb", "--stdin-filename", "Jupyter.py"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin(r#"{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccc687c-96e2-4604-b957-a8a89b5bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1b029-f516-4662-a9b9-623b93edac1a",
   "metadata": {},
   "source": [
    "Foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdce7b92-b0fb-4c02-86f6-e233b26fa84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40b33d2-7fe4-46c5-bdf0-8802f3052565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1899bc8-d46f-4ec0-b1d1-e1ca0f04bf60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    Jupyter.py:cell 1:1:8: F401 [*] `os` imported but unused
    Jupyter.py:cell 3:1:8: F401 [*] `sys` imported but unused
    Found 2 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn parse_value_forloop_array_with_filter() {
    let ast = parse("{% for item in [1,2,] | reverse %}A{%- endfor %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Forloop(
            start_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::with_filters(
                    ExprVal::Array(vec![Expr::new(ExprVal::Int(1)), Expr::new(ExprVal::Int(2)),]),
                    vec![FunctionCall { name: "reverse".to_string(), args: HashMap::new() },],
                ),
                body: vec![Node::Text("A".to_string())],
                empty_body: None,
            },
            end_ws,
        )
    );
}
fn test_snowflake_create_table() {
    let sql = "CREATE TABLE _my_$table (am00unt number)";
    match snowflake_and_generic().verified_stmt(sql) {
        Statement::CreateTable { name, .. } => {
            assert_eq!("_my_$table", name.to_string());
        }
        _ => unreachable!(),
    }
}
fn parse_bad_constraint() {
    let res = parse_sql_statements("ALTER TABLE tab ADD");
    assert_eq!(
        ParserError::ParserError("Expected identifier, found: EOF".to_string()),
        res.unwrap_err()
    );

    let res = parse_sql_statements("CREATE TABLE tab (foo int,");
    assert_eq!(
        ParserError::ParserError(
            "Expected column name or constraint definition, found: EOF".to_string()
        ),
        res.unwrap_err()
    );
}
fn parse_invalid_brackets() {
    let sql = "SELECT STRUCT<INT64>>(NULL)";
    assert_eq!(
        bigquery().parse_sql_statements(sql).unwrap_err(),
        ParserError::ParserError("unmatched > in STRUCT literal".to_string())
    );

    let sql = "SELECT STRUCT<STRUCT<INT64>>>(NULL)";
    assert_eq!(
        bigquery().parse_sql_statements(sql).unwrap_err(),
        ParserError::ParserError("Expected (, found: >".to_string())
    );

    let sql = "CREATE TABLE table (x STRUCT<STRUCT<INT64>>>)";
    assert_eq!(
        bigquery().parse_sql_statements(sql).unwrap_err(),
        ParserError::ParserError(
            "Expected ',' or ')' after column definition, found: >".to_string()
        )
    );
}
fn ArrayVec_drain() {
  let mut av: ArrayVec<[i32; 10]> = Default::default();
  av.push(1);
  av.push(2);
  av.push(3);

  assert_eq!(Vec::from_iter(av.clone().drain(..)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(av.clone().drain(..2)), vec![1, 2]);
  assert_eq!(Vec::from_iter(av.clone().drain(..3)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(av.clone().drain(..=1)), vec![1, 2]);
  assert_eq!(Vec::from_iter(av.clone().drain(..=2)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(av.clone().drain(0..)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(av.clone().drain(1..)), vec![2, 3]);

  assert_eq!(Vec::from_iter(av.clone().drain(0..2)), vec![1, 2]);
  assert_eq!(Vec::from_iter(av.clone().drain(0..3)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(av.clone().drain(1..2)), vec![2]);
  assert_eq!(Vec::from_iter(av.clone().drain(1..3)), vec![2, 3]);

  assert_eq!(Vec::from_iter(av.clone().drain(0..=1)), vec![1, 2]);
  assert_eq!(Vec::from_iter(av.clone().drain(0..=2)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(av.clone().drain(1..=1)), vec![2]);
  assert_eq!(Vec::from_iter(av.clone().drain(1..=2)), vec![2, 3]);
}
fn checked_math() {
    assert_eq!(size(1).checked_add(size(1)), Some(size(2)));
    assert_eq!(size(1).checked_sub(size(1)), Some(size(0)));
    assert_eq!(size(1).checked_sub(size(2)), None);
    assert_eq!(size(!0).checked_add(size(1)), None);
}
fn test_create() {
    let catalog = Catalog::new();
    let (client, origin) = create_sig0_ready_client(catalog);

    // create a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert_eq!(result.answers()[0], record);

    // trying to create again should error
    // TODO: it would be cool to make this
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);

    // will fail if already set and not the same value.
    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));

    let result = client.create(record, origin).expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);
}
fn test_wasmer_run_works_with_dir() {
    let temp_dir = tempfile::TempDir::new().unwrap();
    let qjs_path = temp_dir.path().join("qjs.wasm");

    std::fs::copy(fixtures::qjs(), &qjs_path).unwrap();
    std::fs::copy(
        fixtures::qjs_wasmer_toml(),
        temp_dir.path().join("wasmer.toml"),
    )
    .unwrap();

    assert!(temp_dir.path().exists());
    assert!(temp_dir.path().join("wasmer.toml").exists());
    assert!(temp_dir.path().join("qjs.wasm").exists());

    // test with "wasmer qjs.wasm"
    Command::new(get_wasmer_path())
        .arg(temp_dir.path())
        .arg("--")
        .arg("--quit")
        .assert()
        .success();

    // test again with "wasmer run qjs.wasm"
    Command::new(get_wasmer_path())
        .arg("run")
        .arg(temp_dir.path())
        .arg("--")
        .arg("--quit")
        .assert()
        .success();
}
fn compute_float_f64_rounding() {
    // Also need to check halfway cases **inside** that exponent range.

    // These test near-halfway cases for double-precision floats.
    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));
    assert_eq!(compute_float64(0, 9007199254740993), (1076, 0));
    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));
    assert_eq!(compute_float64(0, 9007199254740995), (1076, 2));
    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));
    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));
    assert_eq!(compute_float64(0, 18014398509481986), (1077, 0));
    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));
    assert_eq!(compute_float64(0, 18014398509481990), (1077, 2));
    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));

    // Test a much closer set of examples.
    assert_eq!(compute_float64(0, 9007199254740991), (1075, 4503599627370495));
    assert_eq!(compute_float64(0, 9223372036854776831), (1086, 0));
    assert_eq!(compute_float64(0, 9223372036854776832), (1086, 0));
    assert_eq!(compute_float64(0, 9223372036854776833), (1086, 1));
    assert_eq!(compute_float64(-42, 9123456727292927), (936, 1854521741541368));
    assert_eq!(compute_float64(-43, 91234567272929275), (936, 1854521741541369));
    assert_eq!(compute_float64(-42, 9123456727292928), (936, 1854521741541369));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));
    assert_eq!(compute_float64(-3, 9007199254740993000), (1076, 0));
    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));
    assert_eq!(compute_float64(-3, 9007199254740995000), (1076, 2));
    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));
}
fn check_hints_hidden_unsafe_fixes() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args([
            "-",
            "--output-format=text",
            "--isolated",
            "--select",
            "F601,UP034",
            "--no-cache",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
        @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    -:2:7: UP034 [*] Avoid extraneous parentheses
    Found 2 errors.
    [*] 1 fixable with the `--fix` option (1 hidden fix can be enabled with the `--unsafe-fixes` option).

    ----- stderr -----
    "###);
}
fn test_du_one_file_system() {
    let ts = TestScenario::new(util_name!());

    let result = ts.ucmd().arg("-x").arg(SUB_DIR).succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &["-x", SUB_DIR]));
        if result_reference.succeeded() {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }
    _du_basics_subdir(result.stdout_str());
}
fn caches_across_engines() {
    let c = Config::new();

    let bytes = Module::new(&Engine::new(&c).unwrap(), "(module)")
        .unwrap()
        .serialize()
        .unwrap();

    unsafe {
        let res = Module::deserialize(&Engine::default(), &bytes);
        assert!(res.is_ok());

        // differ in runtime settings
        let res = Module::deserialize(
            &Engine::new(Config::new().static_memory_maximum_size(0)).unwrap(),
            &bytes,
        );
        assert!(res.is_err());

        // differ in wasm features enabled (which can affect
        // runtime/compilation settings)
        let res = Module::deserialize(
            &Engine::new(Config::new().wasm_simd(false)).unwrap(),
            &bytes,
        );
        assert!(res.is_err());
    }
}
fn fast_log2_test() {
    // Check the first, even if illogical case works.
    assert_eq!(decimal::fast_log2(0u32), 0);
    assert_eq!(decimal::fast_log2(1u32), 0);
    assert_eq!(decimal::fast_log2(2u32), 1);
    assert_eq!(decimal::fast_log2(3u32), 1);

    assert_eq!(decimal::fast_log2((1u32 << 16) - 1), 15);
    assert_eq!(decimal::fast_log2(1u32 << 16), 16);
    assert_eq!(decimal::fast_log2((1u32 << 16) + 1), 16);

    assert_eq!(decimal::fast_log2(u32::MAX), 31);
}
fn test_witness_leader_ignore_gen_snapshot() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);
    configure_for_snapshot(&mut cluster.cfg);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // the other follower is isolated
    cluster.add_send_filter(IsolationFilterFactory::new(3));

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(200));
    let mut before_states = HashMap::default();
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        before_states.insert(id, state.take_truncated_state());
    }

    // write some data to make log gap exceeds the gc limit
    for i in 1..1000 {
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
    }

    std::thread::sleep(Duration::from_millis(200));

    // the truncated index is advanced
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        let diff = state.get_truncated_state().get_index() - before_states[&id].get_index();
        error!("EEEEE";
            "id" => &id,
            "diff" => diff,
            "state.get_truncated_state().get_index()" => state.get_truncated_state().get_index(),
            "before_states[&id].get_index()" => before_states[&id].get_index()
        );
        assert_ne!(
            900,
            state.get_truncated_state().get_index() - before_states[&id].get_index()
        );
    }

    // ingore raft log gc to avoid canceling snapshots
    fail::cfg("on_raft_gc_log_tick", "return").unwrap();
    // wait for leader applied switch to witness
    fail::cfg("before_region_gen_snap", "pause").unwrap();
    fail::cfg("ignore_snap_try_cnt", "return").unwrap();
    // After the snapshot is generated, it will be checked as invalidated and will
    // not be regenerated (handle_snapshot will not generate a snapshot for
    // witness)
    cluster.clear_send_filters();
    std::thread::sleep(Duration::from_millis(500));

    // non-witness -> witness
    fail::cfg("ignore_forbid_leader_to_be_witness", "return").unwrap();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store1.get_id()],
        vec![true],
    );
    fail::remove("before_region_gen_snap");

    std::thread::sleep(Duration::from_millis(500));

    // forbid writes
    let put = new_put_cmd(b"k3", b"v3");
    must_get_error_is_witness(&mut cluster, &region, put);
    // forbid reads
    let get = new_get_cmd(b"k1");
    must_get_error_is_witness(&mut cluster, &region, get);
    // forbid read index
    let read_index = new_read_index_cmd();
    must_get_error_is_witness(&mut cluster, &region, read_index);

    // reject to transfer, as can't send snapshot to peer_on_store3, there's a log
    // gap
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    let _ = cluster.try_transfer_leader(region.get_id(), peer_on_store3);
    std::thread::sleep(Duration::from_secs(5));
    assert_eq!(cluster.leader_of_region(1).unwrap(), peer_on_store1);

    // should be enable to transfer leader to peer_on_store2
    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();
    cluster.must_transfer_leader(1, peer_on_store2);
    cluster.must_put(b"k1", b"v1");
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap().store_id,
        nodes[1],
    );
    assert_eq!(cluster.must_get(b"k9"), Some(b"v9".to_vec()));

    fail::remove("on_raft_gc_log_tick");
    fail::remove("ignore_snap_try_cnt");
    fail::remove("ignore_forbid_leader_to_be_witness");
}
fn dtor_delayed() -> Result<()> {
    static HITS: AtomicUsize = AtomicUsize::new(0);

    struct A;

    impl Drop for A {
        fn drop(&mut self) {
            HITS.fetch_add(1, SeqCst);
        }
    }

    let mut store = Store::<()>::default();
    let a = A;
    let func = Func::wrap(&mut store, move || {
        let _ = &a;
    });

    assert_eq!(HITS.load(SeqCst), 0);
    let wasm = wat::parse_str(r#"(import "" "" (func))"#)?;
    let module = Module::new(store.engine(), &wasm)?;
    let _instance = Instance::new(&mut store, &module, &[func.into()])?;
    assert_eq!(HITS.load(SeqCst), 0);
    drop(store);
    assert_eq!(HITS.load(SeqCst), 1);
    Ok(())
}
fn explain_status_codes_ruf404() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME)).args(["--explain", "RUF404"]), @r###"
    success: false
    exit_code: 2
    ----- stdout -----

    ----- stderr -----
    error: invalid value 'RUF404' for '[RULE]'

    For more information, try '--help'.
    "###);
}
fn parse_select_wildcard() {
    let sql = "SELECT * FROM foo";
    let select = verified_only_select(sql);
    assert_eq!(
        &SelectItem::Wildcard(WildcardAdditionalOptions::default()),
        only(&select.projection)
    );

    let sql = "SELECT foo.* FROM foo";
    let select = verified_only_select(sql);
    assert_eq!(
        &SelectItem::QualifiedWildcard(
            ObjectName(vec![Ident::new("foo")]),
            WildcardAdditionalOptions::default()
        ),
        only(&select.projection)
    );

    let sql = "SELECT myschema.mytable.* FROM myschema.mytable";
    let select = verified_only_select(sql);
    assert_eq!(
        &SelectItem::QualifiedWildcard(
            ObjectName(vec![Ident::new("myschema"), Ident::new("mytable"),]),
            WildcardAdditionalOptions::default(),
        ),
        only(&select.projection)
    );

    let sql = "SELECT * + * FROM foo;";
    let result = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: +".to_string()),
        result.unwrap_err(),
    );
}
fn indent_size_parse_errors_negative() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--indent-size=-1"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "indent_size_parse_errors_negative",
        fs,
        console,
        result,
    ));
}
fn test_mv_backup_numbered_with_t() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=t")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}.~1~")));
}
fn test_pub_crate() {
    assert_vis_parse!("pub(crate)", Ok(Visibility::Restricted(_)));
}
fn overflow_incomplete_tuple() {
    assert_eq!(
        parser02(Partial::new(&b"3"[..])),
        Err(ErrMode::Incomplete(Needed::new(18446744073709551615)))
    );
}
fn static_add3_works() {
    let (mut store, add3, add3_dyn) = setup_add3();
    let add3 = add3.typed::<(i32, i32, i32), i32>(&mut store).unwrap();
    let add3_dyn = add3_dyn.typed::<(i32, i32, i32), i32>(&mut store).unwrap();
    for a in 0..5 {
        for b in 0..5 {
            for c in 0..5 {
                let expected = a + b + c;
                assert_eq!(add3.call(&mut store, (a, b, c)).unwrap(), expected);
                assert_eq!(add3_dyn.call(&mut store, (a, b, c)).unwrap(), expected);
            }
        }
    }
}
fn test_chroot_skip_chdir() {
    let ts = TestScenario::new(util_name!());
    let at = ts.fixtures.clone();
    let dirs = ["/", "/.", "/..", "isroot"];
    at.symlink_file("/", "isroot");
    for dir in dirs {
        let env_cd = std::env::current_dir().unwrap();
        if let Ok(result) = run_ucmd_as_root(&ts, &[dir, "--skip-chdir"]) {
            // Should return the same path
            assert_eq!(
                result.success().no_stderr().stdout_str(),
                env_cd.to_str().unwrap()
            );
        } else {
            print!("Test skipped; requires root user");
        }
    }
}
fn test_large_number() {
    let test_var = Value::Number(Number::new(10000000000000000000000.0f64));
    let test_ser = ron::ser::to_string(&test_var).unwrap();
    let test_deser = ron::de::from_str::<Value>(&test_ser);

    assert_eq!(
        test_deser.unwrap(),
        Value::Number(Number::new(10000000000000000000000.0))
    );
}
fn parse_array_expr() {
    let sql = "SELECT ['1', '2'] FROM test";
    let select = clickhouse().verified_only_select(sql);
    assert_eq!(
        &Expr::Array(Array {
            elem: vec![
                Expr::Value(Value::SingleQuotedString("1".to_string())),
                Expr::Value(Value::SingleQuotedString("2".to_string())),
            ],
            named: false,
        }),
        expr_from_projection(only(&select.projection))
    )
}
fn preview_disabled_does_not_warn_for_empty_fixable_selections() {
    // Does not warn that the selection is empty since the user is not trying to enable the rule
    let args = ["--fixable", "CPY"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    Found 1 error.

    ----- stderr -----
    "###);
}
fn test_infinite_lease() {
    let mut cluster = new_node_cluster(0, 3);
    // Avoid triggering the log compaction in this test case.
    cluster.cfg.raft_store.raft_log_gc_threshold = 100;
    // Increase the Raft tick interval to make this test case running reliably.
    // Use large election timeout to make leadership stable.
    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));
    // Override max leader lease to 2 seconds.
    let max_lease = Duration::from_secs(2);
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration(max_lease);

    let peer = new_peer(1, 1);
    cluster.pd_client.disable_default_operator();
    let region_id = cluster.run_conf_change();

    let key = b"k";
    cluster.must_put(key, b"v0");
    for id in 2..=cluster.engines.len() as u64 {
        cluster.pd_client.must_add_peer(region_id, new_peer(id, id));
        must_get_equal(&cluster.get_engine(id), key, b"v0");
    }

    // Force `peer` to become leader.
    let region = cluster.get_region(key);
    let region_id = region.get_id();
    cluster.must_transfer_leader(region_id, peer.clone());

    let detector = LeaseReadFilter::default();
    cluster.add_send_filter(CloneFilterFactory(detector.clone()));

    // Issue a read request and check the value on response.
    must_read_on_peer(&mut cluster, peer.clone(), region.clone(), key, b"v0");
    assert_eq!(detector.ctx.rl().len(), 0);

    // Wait for the leader lease to expire.
    thread::sleep(max_lease);

    // Check if renew-lease-tick proposed a read index and renewed the leader lease.
    assert_eq!(cluster.leader_of_region(region_id), Some(peer.clone()));
    assert_eq!(detector.ctx.rl().len(), 1);
    // Issue a read request to verify the lease.
    must_read_on_peer(&mut cluster, peer.clone(), region, key, b"v0");
    assert_eq!(cluster.leader_of_region(region_id), Some(peer));
    assert_eq!(detector.ctx.rl().len(), 1);

    // renew-lease-tick shouldn't propose any request if the leader lease is not
    // expired.
    for _ in 0..4 {
        cluster.must_put(key, b"v0");
        thread::sleep(max_lease / 4);
    }
    assert_eq!(detector.ctx.rl().len(), 1);
}
fn test_block_size_1024() {
    fn get_header(block_size: u64) -> String {
        let output = new_ucmd!()
            .args(&["-B", &format!("{block_size}"), "--output=size"])
            .succeeds()
            .stdout_move_str();
        output.lines().next().unwrap().trim().to_string()
    }

    assert_eq!(get_header(1024), "1K-blocks");
    assert_eq!(get_header(2048), "2K-blocks");
    assert_eq!(get_header(4096), "4K-blocks");
    assert_eq!(get_header(1024 * 1024), "1M-blocks");
    assert_eq!(get_header(2 * 1024 * 1024), "2M-blocks");
    assert_eq!(get_header(1024 * 1024 * 1024), "1G-blocks");
    assert_eq!(get_header(34 * 1024 * 1024 * 1024), "34G-blocks");

    // multiples of both 1024 and 1000
    assert_eq!(get_header(128_000), "128kB-blocks");
    assert_eq!(get_header(1000 * 1024), "1.1MB-blocks");
    assert_eq!(get_header(1_000_000_000_000), "1TB-blocks");
}
fn parse_key_value_forloop() {
    let ast = parse("{% for key, item in get_map() %}A{%- endfor %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Forloop(
            start_ws,
            Forloop {
                key: Some("key".to_string()),
                value: "item".to_string(),
                container: Expr::new(ExprVal::FunctionCall(FunctionCall {
                    name: "get_map".to_string(),
                    args: HashMap::new(),
                },)),
                body: vec![Node::Text("A".to_string())],
                empty_body: None,
            },
            end_ws,
        )
    );
}
async fn reject_non_authority_target_on_connect_request() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;

        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));

        client
            .send_frame(frames::headers(1).request("CONNECT", "https://bread/baguette"))
            .await;

        client.recv_frame(frames::reset(1).protocol_error()).await;
    };

    let srv = async move {
        let mut builder = server::Builder::new();

        builder.enable_connect_protocol();

        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");

        assert!(srv.next().await.is_none());

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn fix_only_flag_applies_unsafe_fixes_with_opt_in() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601,UP034",
                "--fix-only",
                "--unsafe-fixes",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    x = {'a': 1}
    print('foo')

    ----- stderr -----
    Fixed 2 errors.
    "###);
}
fn apply_suggested() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, APPLY_SUGGESTED_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_suggested",
        fs,
        console,
        result,
    ));
}
fn test_timestamp() {
    use std::collections::HashSet;

    let timestamp = ::prost_types::Timestamp {
        seconds: 100,
        nanos: 42,
    };

    let mut non_normalized_timestamp = ::prost_types::Timestamp {
        seconds: 99,
        nanos: 1_000_000_042,
    };

    let mut hashset = HashSet::new();
    assert!(hashset.insert(timestamp.clone()));
    assert!(
        hashset.insert(non_normalized_timestamp.clone()),
        "hash for non-normalized different and should be inserted"
    );

    assert_ne!(
        timestamp, non_normalized_timestamp,
        "non-nomarlized timestamp considered different"
    );
    non_normalized_timestamp.normalize();
    assert_eq!(
        timestamp, non_normalized_timestamp,
        "normalized timestamp matches"
    );

    let mut hashset = HashSet::new();
    assert!(hashset.insert(timestamp));
    assert!(
        !hashset.insert(non_normalized_timestamp),
        "hash for normalized should match and not inserted"
    );
}
fn test_error_render_filter_section_invalid() {
    let result = render_tpl("filter_section_invalid.html");
    assert!(result.is_err());
    let err = result.unwrap_err();
    let source = err.source().unwrap();

    assert_eq!(source.to_string(), "Filter call \'round\' failed");
    let source2 = source.source().unwrap();
    assert_eq!(
        source2.to_string(),
        "Filter `round` was called on an incorrect value: got `\"hello\"` but expected a f64"
    );
}
fn TinyVec_try_reserve_exact() {
  let mut tv: TinyVec<[i32; 4]> = Default::default();
  assert_eq!(tv.capacity(), 4);

  tv.extend_from_slice(&[1, 2]);
  assert_eq!(tv.capacity(), 4);
  assert!(tv.try_reserve_exact(2).is_ok());
  assert_eq!(tv.capacity(), 4);
  assert!(tv.try_reserve_exact(4).is_ok());
  assert!(tv.capacity() >= 6);
  tv.extend_from_slice(&[3, 4, 5, 6]);
  assert!(tv.try_reserve_exact(4).is_ok());
  assert!(tv.capacity() >= 10);
}
fn first_last() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        assert!(table.first().unwrap().is_none());
        assert!(table.last().unwrap().is_none());
        table.insert("a", "world1").unwrap();
        assert_eq!(table.first().unwrap().unwrap().0.value(), "a");
        assert_eq!(table.last().unwrap().unwrap().0.value(), "a");
        table.insert("b", "world2").unwrap();
        table.insert("c", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!(table.first().unwrap().unwrap().0.value(), "a");
    assert_eq!(table.last().unwrap().unwrap().0.value(), "c");
}
fn parse_similar_to() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that SIMILAR TO and NOT SIMILAR TO have the same precedence.
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn parse_where_delete_statement() {
    use self::BinaryOperator::*;

    let sql = "DELETE FROM foo WHERE name = 5";
    match verified_stmt(sql) {
        Statement::Delete {
            tables: _,
            from,
            using,
            selection,
            returning,
            ..
        } => {
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("foo")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                from[0].relation,
            );

            assert_eq!(None, using);
            assert_eq!(
                Expr::BinaryOp {
                    left: Box::new(Expr::Identifier(Ident::new("name"))),
                    op: Eq,
                    right: Box::new(Expr::Value(number("5"))),
                },
                selection.unwrap(),
            );
            assert_eq!(None, returning);
        }
        _ => unreachable!(),
    }
}
fn test_rm_interactive_once_prompt() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file1 = "test_rm_interactive_once_recursive_prompt_file1";
    let file2 = "test_rm_interactive_once_recursive_prompt_file2";
    let file3 = "test_rm_interactive_once_recursive_prompt_file3";
    let file4 = "test_rm_interactive_once_recursive_prompt_file4";

    at.touch(file1);
    at.touch(file2);
    at.touch(file3);
    at.touch(file4);

    ucmd.arg("--interactive=once")
        .arg(file1)
        .arg(file2)
        .arg(file3)
        .arg(file4)
        .pipe_in("y")
        .succeeds()
        .stderr_contains("remove 4 arguments?");

    assert!(!at.file_exists(file1));
    assert!(!at.file_exists(file2));
    assert!(!at.file_exists(file3));
    assert!(!at.file_exists(file4));
}
fn name() {
  assert_eq!(
    CommandBuilder::new("parse a").run_and_deserialize_output::<Output>(),
    Output {
      object: Object::Integer(2099999997689999),
    }
  );
}
fn applies_custom_configuration_over_config_file_issue_3175_v1() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_ISSUE_3175_1.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), "import React from 'react';\n".as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--quote-style"),
                ("single"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, "import React from 'react';\n");

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_configuration_over_config_file_issue_3175_v1",
        fs,
        console,
        result,
    ));
}
fn external_sst_info_key_values_with_delete() -> Result<()> {
    let tempdir = tempdir();
    let sst_path = tempdir
        .path()
        .join("test-data.sst")
        .to_string_lossy()
        .to_string();
    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();
    let mut sst_writer = sst_builder.build(&sst_path)?;

    sst_writer.delete(b"k1")?;

    let info = sst_writer.finish()?;

    assert_eq!(b"k1", info.smallest_key());
    assert_eq!(b"k1", info.largest_key());
    assert_eq!(1, info.num_entries());

    let size = fs::metadata(&sst_path).unwrap().len();

    assert_eq!(size, info.file_size());

    Ok(())
}
fn test_invalid() {
    struct X;

    impl Serialize for X {
        fn serialize<S>(&self, _serializer: S) -> Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            Err(serde::ser::Error::custom("meh"))
        }
    }

    let v = Value::from_serializable(&X);
    assert_eq!(v.to_string(), "<invalid value: meh>");

    let err = bool::deserialize(v).unwrap_err();
    assert_eq!(err.to_string(), "cannot deserialize: meh");
}
fn thread_options_through_inner() -> Result<()> {
    let component = format!(
        r#"
(component
  (import "hostfn" (func $host (param "a" u32) (result string)))

  (component $c
    (import "hostfn" (func $host (param "a" u32) (result string)))

    (core module $libc
        (memory (export "memory") 1)
        {REALLOC_AND_FREE}
    )
    (core instance $libc (instantiate $libc))

    (core func $host_lower
        (canon lower
            (func $host)
            (memory $libc "memory")
            (realloc (func $libc "realloc"))
        )
    )

    (core module $m
        (import "" "host" (func $host (param i32 i32)))
        (import "libc" "memory" (memory 1))
        (func (export "run") (param i32) (result i32)
            i32.const 42
            i32.const 100
            call $host
            i32.const 100
        )
        (export "memory" (memory 0))
    )
    (core instance $m (instantiate $m
        (with "" (instance (export "host" (func $host_lower))))
        (with "libc" (instance $libc))
    ))

    (func (export "run") (param "a" u32) (result string)
        (canon lift
            (core func $m "run")
            (memory $m "memory")
        )
    )
  )
  (instance $c (instantiate $c (with "hostfn" (func $host))))
  (export "run" (func $c "run"))
)
    "#
    );
    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, 0);
    let mut linker = Linker::new(&engine);
    linker
        .root()
        .func_wrap("hostfn", |_, (param,): (u32,)| Ok((param.to_string(),)))?;
    let instance = linker.instantiate(&mut store, &component)?;
    let result = instance
        .get_typed_func::<(u32,), (WasmStr,)>(&mut store, "run")?
        .call(&mut store, (43,))?
        .0;
    assert_eq!(result.to_str(&store)?, "42");
    Ok(())
}
fn client_checks_server_certificate_with_given_name() {
    for kt in ALL_KEY_TYPES.iter() {
        let server_config = Arc::new(make_server_config(*kt));

        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions(*kt, &[version]);
            let mut client = ClientConnection::new(
                Arc::new(client_config),
                dns_name("not-the-right-hostname.com"),
            )
            .unwrap();
            let mut server = ServerConnection::new(Arc::clone(&server_config)).unwrap();

            let err = do_handshake_until_error(&mut client, &mut server);
            assert_eq!(
                err,
                Err(ErrorFromPeer::Client(Error::InvalidCertificate(
                    CertificateError::NotValidForName
                )))
            );
        }
    }
}
fn valid_version_with_trailing_characters_is_other() {
  assert_eq!(
    stdout("refs/tags/0.0.0-rc1"),
    "::set-output name=value::other\n"
  );
}
fn test_number_placeholder() {
    let sql_only_select = "SELECT :1";
    let select = snowflake().verified_only_select(sql_only_select);
    assert_eq!(
        &Expr::Value(Value::Placeholder(":1".into())),
        expr_from_projection(only(&select.projection))
    );

    snowflake()
        .parse_sql_statements("alter role 1 with name = 'foo'")
        .expect_err("should have failed");
}
fn test_underflow() {
    assert_eq!(0.0, s2d(b"2.4e-324").unwrap());
    assert_eq!(0.0, s2d(b"1e-324").unwrap());
    assert_eq!(0.0, s2d(b"9.99999e-325").unwrap());
    // These are just about halfway between 0 and the smallest float.
    // The first is just below the halfway point, the second just above.
    assert_eq!(0.0, s2d(b"2.4703282292062327e-324").unwrap());
    assert_eq!(5e-324, s2d(b"2.4703282292062328e-324").unwrap());
}
fn regression8() {
    let tmpfile = create_tempfile();

    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<u64, &[u8]> = TableDefinition::new("x");

    let mut tx = db.begin_write().unwrap();
    tx.set_durability(Durability::None);
    {
        let mut t = tx.open_table(table_def).unwrap();
        let v = vec![0u8; 1186];
        t.insert(&145227, v.as_slice()).unwrap();
        let v = vec![0u8; 1585];
        t.insert(&565922, v.as_slice()).unwrap();
    }
    tx.commit().unwrap();

    let tx = db.begin_write().unwrap();
    {
        let mut t = tx.open_table(table_def).unwrap();
        let v = vec![0u8; 2040];
        t.insert(&94937, v.as_slice()).unwrap();
        let v = vec![0u8; 2058];
        t.insert(&130571, v.as_slice()).unwrap();
        t.remove(&145227).unwrap();
    }
    tx.commit().unwrap();

    let tx = db.begin_write().unwrap();
    {
        let mut t = tx.open_table(table_def).unwrap();
        let v = vec![0u8; 947];
        t.insert(&118749, v.as_slice()).unwrap();
    }
    tx.commit().unwrap();

    let tx = db.begin_write().unwrap();
    {
        let t = tx.open_table(table_def).unwrap();
        let mut iter = t.range(118749..142650).unwrap();
        assert_eq!(iter.next().unwrap().unwrap().0.value(), 118749);
        assert_eq!(iter.next().unwrap().unwrap().0.value(), 130571);
        assert!(iter.next().is_none());
    }
    tx.commit().unwrap();
}
fn parse_multiple_categories_test() {
  let ini_file = &b"[abcd]

parameter=value;abc

key = value2

[category]
parameter3=value3
key4 = value4
"[..];

  let ini_after_parser = &b""[..];

  let res = categories(ini_file);
  //println!("{:?}", res);
  match res {
    Ok((i, ref o)) => println!("i: {:?} | o: {:?}", str::from_utf8(i), o),
    _ => println!("error"),
  }

  let mut expected_1: HashMap<&str, &str> = HashMap::new();
  expected_1.insert("parameter", "value");
  expected_1.insert("key", "value2");
  let mut expected_2: HashMap<&str, &str> = HashMap::new();
  expected_2.insert("parameter3", "value3");
  expected_2.insert("key4", "value4");
  let mut expected_h: HashMap<&str, HashMap<&str, &str>> = HashMap::new();
  expected_h.insert("abcd", expected_1);
  expected_h.insert("category", expected_2);
  assert_eq!(res, Ok((ini_after_parser, expected_h)));
}
fn test_node_merge_catch_up_logs_no_need() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 25;
    cluster.cfg.raft_store.raft_log_gc_threshold = 12;
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(12);
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(100);
    cluster.run();

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let pd_client = Arc::clone(&cluster.pd_client);
    let region = pd_client.get_region(b"k1").unwrap();
    let peer_on_store1 = find_peer(&region, 1).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    cluster.must_split(&region, b"k2");
    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    // put some keys to trigger compact raft log
    for i in 2..20 {
        cluster.must_put(format!("k1{}", i).as_bytes(), b"v");
    }

    // let the peer of left region on store 3 falls behind.
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(left.get_id(), 3)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend),
    ));

    // make sure the peer is isolated.
    cluster.must_put(b"k11", b"v11");
    must_get_none(&cluster.get_engine(3), b"k11");

    // propose merge but not let apply index make progress.
    fail::cfg("apply_after_prepare_merge", "pause").unwrap();
    pd_client.merge_region(left.get_id(), right.get_id());
    must_get_none(&cluster.get_engine(3), b"k11");

    // wait to trigger compact raft log
    thread::sleep(Duration::from_millis(100));

    // let source region not merged
    fail::cfg("before_handle_catch_up_logs_for_merge", "pause").unwrap();
    fail::cfg("after_handle_catch_up_logs_for_merge", "pause").unwrap();
    // due to `before_handle_catch_up_logs_for_merge` failpoint, we already pass
    // `apply_index < catch_up_logs.merge.get_commit()` so now can let apply
    // index make progress.
    fail::remove("apply_after_prepare_merge");

    // make sure all the logs are committed, including the compact command
    cluster.clear_send_filters();
    thread::sleep(Duration::from_millis(50));

    // let merge process continue
    fail::remove("before_handle_catch_up_logs_for_merge");
    fail::remove("after_handle_catch_up_logs_for_merge");
    thread::sleep(Duration::from_millis(50));

    // the source region should be merged and the peer should be destroyed.
    assert!(pd_client.check_merged(left.get_id()));
    must_get_equal(&cluster.get_engine(3), b"k11", b"v11");
    cluster.must_region_not_exist(left.get_id(), 3);
}
fn user_change() {
    let (dir, mut cmd) = at_and_ucmd!();

    dir.touch("a.tmp");
    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    let new_a_context = if let Some(a_context) = a_context {
        let mut components: Vec<_> = a_context.split(':').collect();
        components[0] = "guest_u";
        components.join(":")
    } else {
        set_file_context(dir.plus("a.tmp"), "unconfined_u:object_r:user_tmp_t:s0").unwrap();
        String::from("guest_u:object_r:user_tmp_t:s0")
    };

    cmd.args(&["--verbose", "--user=guest_u"])
        .arg(dir.plus("a.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("a.tmp")).unwrap(),
        Some(new_a_context)
    );
}
fn read_lines_test() {
    let res = Ok(("", vec!["Duck", "Dog", "Cow"]));

    assert_eq!(read_lines("Duck\nDog\nCow\n"), res);
    assert_eq!(read_lines("Duck\nDog\nCow"), res);
}
fn test_relative_recursive() {
    let (at, mut ucmd) = at_and_ucmd!();
    at.mkdir("dir");
    ucmd.args(&["-sr", "dir", "dir/recursive"]).succeeds();
    assert_eq!(at.resolve_link("dir/recursive"), ".");
}
fn test_dnssec_restart_with_update_journal_dep() {
    // TODO: make journal path configurable, it should be in target/tests/...
    let server_path = env::var("TDNS_WORKSPACE_ROOT").unwrap_or_else(|_| "..".to_owned());
    let server_path = Path::new(&server_path);
    let journal = server_path.join("tests/test-data/test_configs/example.com.jrnl");
    std::fs::remove_file(&journal).ok();

    generic_test(
        "dnssec_with_update_deprecated.toml",
        "tests/test-data/test_configs/dnssec/rsa_2048.pem",
        KeyFormat::Pem,
        Algorithm::RSASHA256,
    );

    // after running the above test, the journal file should exist
    assert!(journal.exists());

    // and all dnssec tests should still pass
    generic_test(
        "dnssec_with_update_deprecated.toml",
        "tests/test-data/test_configs/dnssec/rsa_2048.pem",
        KeyFormat::Pem,
        Algorithm::RSASHA256,
    );

    // and journal should still exist
    assert!(journal.exists());

    // cleanup...
    // TODO: fix journal path so that it doesn't leave the dir dirty... this might make windows an option after that
    std::fs::remove_file(&journal).expect("failed to cleanup after test");
}
fn lex_else_tag() {
    assert!(TeraParser::parse(Rule::else_tag, "{% else %}").is_ok());
}
async fn recv_push_when_push_disabled_is_conn_error() {
    h2_support::trace_init!();

    let (io, mut srv) = mock::new();
    let mock = async move {
        let _ = srv.assert_client_handshake().await;
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://http2.akamai.com/")
                .eos(),
        )
        .await;
        srv.send_frame(
            frames::push_promise(1, 3).request("GET", "https://http2.akamai.com/style.css"),
        )
        .await;
        srv.send_frame(frames::headers(1).response(200).eos()).await;
        srv.recv_frame(frames::go_away(0).protocol_error()).await;
    };

    let h2 = async move {
        let (mut client, h2) = client::Builder::new()
            .enable_push(false)
            .handshake::<_, Bytes>(io)
            .await
            .unwrap();
        let request = Request::builder()
            .method(Method::GET)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let req = async move {
            let res = client.send_request(request, true).unwrap().0.await;
            let err = res.unwrap_err();
            assert_eq!(
                err.to_string(),
                "connection error detected: unspecific protocol error detected"
            );
        };

        // client should see a protocol error
        let conn = async move {
            let res = h2.await;
            let err = res.unwrap_err();
            assert_eq!(
                err.to_string(),
                "connection error detected: unspecific protocol error detected"
            );
        };

        join(conn, req).await;
    };

    join(mock, h2).await;
}
fn test_skip_iter_ltc() {
    // Test iterators that skip multiple, leading or trailing digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_leading_digit_separator(true)
        .integer_trailing_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"45_5");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"45__5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".45_5");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".45__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"4_5.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4__5.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"4_5.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"4__5.56");
}
fn genesis() {
  assert_eq!(
    CommandBuilder::new("supply").run_and_deserialize_output::<Output>(),
    Output {
      supply: 2099999997690000,
      first: 0,
      last: 2099999997689999,
      last_mined_in_block: 6929999
    }
  );
}
async fn invalid_connect_protocol_enabled_setting() {
    h2_support::trace_init!();

    let (io, mut srv) = mock::new();

    let srv = async move {
        // Send a settings frame
        srv.send(frames::settings().enable_connect_protocol(2).into())
            .await
            .unwrap();
        srv.read_preface().await.unwrap();

        let settings = assert_settings!(srv.next().await.expect("unexpected EOF").unwrap());
        assert_default_settings!(settings);

        // Send the ACK
        let ack = frame::Settings::ack();

        // TODO: Don't unwrap?
        srv.send(ack.into()).await.unwrap();

        let frame = srv.next().await.unwrap().unwrap();
        let go_away = assert_go_away!(frame);
        assert_eq!(go_away.reason(), Reason::PROTOCOL_ERROR);
    };

    let h2 = async move {
        let (mut client, mut h2) = client::handshake(io).await.unwrap();

        // we send a simple req here just to drive the connection so we can
        // receive the server settings.
        let request = Request::get("https://example.com/").body(()).unwrap();
        let (response, _) = client.send_request(request, true).unwrap();

        let error = h2.drive(response).await.unwrap_err();
        assert_eq!(error.reason(), Some(Reason::PROTOCOL_ERROR));
    };

    join(srv, h2).await;
}
fn sub_capture_matches() {
    let re = regex!(r"([a-z])(([a-z])|([0-9]))");
    let cap = re.captures(t!("a5")).unwrap();
    let subs: Vec<_> = cap.iter().collect();

    assert_eq!(5, subs.len());
    assert!(subs[0].is_some());
    assert!(subs[1].is_some());
    assert!(subs[2].is_some());
    assert!(subs[3].is_none());
    assert!(subs[4].is_some());

    assert_eq!(t!("a5"), match_text!(subs[0].unwrap()));
    assert_eq!(t!("a"), match_text!(subs[1].unwrap()));
    assert_eq!(t!("5"), match_text!(subs[2].unwrap()));
    assert_eq!(t!("5"), match_text!(subs[4].unwrap()));
}
fn test_version() {
    for version_flg in ["-V", "--version"] {
        assert!(new_ucmd!()
            .arg(version_flg)
            .succeeds()
            .no_stderr()
            .stdout_str()
            .starts_with("basename"));
    }
}
fn test_is_8digits() {
    let value: u64 = 0x31_32_33_34_35_36_37_38;
    #[cfg(feature = "power-of-two")]
    assert!(!algorithm::is_8digits::<{ from_radix(4) }>(value));
    #[cfg(feature = "radix")]
    assert!(!algorithm::is_8digits::<{ from_radix(5) }>(value));
    assert!(algorithm::is_8digits::<{ STANDARD }>(value));

    let value: u64 = 0x29_30_31_32_33_34_35_36;
    assert!(!algorithm::is_8digits::<{ STANDARD }>(value));

    let value: u64 = 0x30_31_32_33_34_35_36_40;
    assert!(!algorithm::is_8digits::<{ STANDARD }>(value));

    let value: u64 = 0x31_32_33_34_35_36_37_39;
    #[cfg(feature = "radix")]
    assert!(!algorithm::is_8digits::<{ from_radix(9) }>(value));
    assert!(algorithm::is_8digits::<{ STANDARD }>(value));
}
fn parse_window_functions() {
    let sql = "SELECT row_number() OVER (ORDER BY dt DESC), \
               sum(foo) OVER (PARTITION BY a, b ORDER BY c, d \
               ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW), \
               avg(bar) OVER (ORDER BY a \
               RANGE BETWEEN 1 PRECEDING AND 1 FOLLOWING), \
               sum(bar) OVER (ORDER BY a \
               RANGE BETWEEN INTERVAL '1' DAY PRECEDING AND INTERVAL '1 MONTH' FOLLOWING), \
               COUNT(*) OVER (ORDER BY a \
               RANGE BETWEEN INTERVAL '1 DAY' PRECEDING AND INTERVAL '1 DAY' FOLLOWING), \
               max(baz) OVER (ORDER BY a \
               ROWS UNBOUNDED PRECEDING), \
               sum(qux) OVER (ORDER BY a \
               GROUPS BETWEEN 1 PRECEDING AND 1 FOLLOWING) \
               FROM foo";
    let select = verified_only_select(sql);
    assert_eq!(7, select.projection.len());
    assert_eq!(
        &Expr::Function(Function {
            name: ObjectName(vec![Ident::new("row_number")]),
            args: vec![],
            null_treatment: None,
            filter: None,
            over: Some(WindowType::WindowSpec(WindowSpec {
                partition_by: vec![],
                order_by: vec![OrderByExpr {
                    expr: Expr::Identifier(Ident::new("dt")),
                    asc: Some(false),
                    nulls_first: None,
                }],
                window_frame: None,
            })),
            distinct: false,
            special: false,
            order_by: vec![],
        }),
        expr_from_projection(&select.projection[0])
    );
}
fn compute_error32_test() {
    // These test near-halfway cases for single-precision floats.
    assert_eq!(compute_error32(0, 16777216), (111 + INVALID_FP, 9223372036854775808));
    assert_eq!(compute_error32(0, 16777217), (111 + INVALID_FP, 9223372586610589696));
    assert_eq!(compute_error32(0, 16777218), (111 + INVALID_FP, 9223373136366403584));
    assert_eq!(compute_error32(0, 16777219), (111 + INVALID_FP, 9223373686122217472));
    assert_eq!(compute_error32(0, 16777220), (111 + INVALID_FP, 9223374235878031360));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_error32(-10, 167772160000000000), (111 + INVALID_FP, 9223372036854775808));
    assert_eq!(compute_error32(-10, 167772170000000000), (111 + INVALID_FP, 9223372586610589696));
    assert_eq!(compute_error32(-10, 167772180000000000), (111 + INVALID_FP, 9223373136366403584));
    // Let's check the lines to see if anything is different in table...
    assert_eq!(compute_error32(-10, 167772190000000000), (111 + INVALID_FP, 9223373686122217472));
    assert_eq!(compute_error32(-10, 167772200000000000), (111 + INVALID_FP, 9223374235878031360));
}
fn fs_error_read_only() {
    let mut fs = MemoryFileSystem::new_read_only();
    let mut console = BufferConsole::default();

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), *b"content");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Do not store the content of the file in the snapshot
    fs.remove(file_path);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_read_only",
        fs,
        console,
        result,
    ));
}
fn preview_disabled_prefix_empty() {
    // Warns that the selection is empty since all of the CPY rules are in preview
    let args = ["--select", "CPY"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    warning: Selection `CPY` has no effect because the `--preview` flag was not included.
    "###);
}
fn invocation_directory_native() {
  let Output { stdout, tempdir } = Test::new()
    .justfile("x := invocation_directory_native()")
    .args(["--evaluate", "x"])
    .stdout_regex(".*")
    .run();

  if cfg!(windows) {
    assert_eq!(Path::new(&stdout), tempdir.path());
  } else {
    assert_eq!(Path::new(&stdout), tempdir.path().canonicalize().unwrap());
  }
}
fn parse_create_sqlite_quote() {
    let sql = "CREATE TABLE `PRIMARY` (\"KEY\" INT, [INDEX] INT)";
    match sqlite().verified_stmt(sql) {
        Statement::CreateTable { name, columns, .. } => {
            assert_eq!(name.to_string(), "`PRIMARY`");
            assert_eq!(
                vec![
                    ColumnDef {
                        name: Ident::with_quote('"', "KEY"),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![],
                    },
                    ColumnDef {
                        name: Ident::with_quote('[', "INDEX"),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![],
                    },
                ],
                columns
            );
        }
        _ => unreachable!(),
    }
}
fn test_guard_input() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    ts.ucmd()
        .args(&["-C", "6"])
        .pipe_in("1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n")
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "1\n2\n3\n");

    ts.ucmd()
        .args(&["-C", "6"])
        .pipe_in("1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n")
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "1\n2\n3\n");

    ts.ucmd()
        .args(&["-C", "6", "xaa"])
        .fails()
        .stderr_only("split: 'xaa' would overwrite input; aborting\n");
    assert_eq!(at.read("xaa"), "1\n2\n3\n");
}
fn test_delete_by_rdata() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // append a record
    let mut record1 = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record1.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = io_loop
        .block_on(client.delete_by_rdata(record1.clone(), origin.clone()))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = io_loop
        .block_on(client.create(record1.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let mut record2 = record1.clone();
    record2.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let result = io_loop
        .block_on(client.append(record2.clone(), origin.clone(), true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = io_loop
        .block_on(client.delete_by_rdata(record2, origin))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record1.name().clone(),
            record1.dns_class(),
            record1.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert!(result.answers().iter().any(|rr| *rr == record1));
}
fn test_node_merge_rollback() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run_conf_change();

    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");
    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    pd_client.must_add_peer(left.get_id(), new_peer(2, 2));
    pd_client.must_add_peer(right.get_id(), new_peer(2, 4));

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let region = pd_client.get_region(b"k1").unwrap();
    let target_region = pd_client.get_region(b"k3").unwrap();

    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    // The call is finished when prepare_merge is applied.
    cluster.must_try_merge(region.get_id(), target_region.get_id());

    // Add a peer to trigger rollback.
    pd_client.must_add_peer(right.get_id(), new_peer(3, 5));
    cluster.must_put(b"k4", b"v4");
    must_get_equal(&cluster.get_engine(3), b"k4", b"v4");

    let mut region = pd_client.get_region(b"k1").unwrap();
    // After split and prepare_merge, version becomes 1 + 2 = 3;
    assert_eq!(region.get_region_epoch().get_version(), 3);
    // After ConfChange and prepare_merge, conf version becomes 1 + 2 = 3;
    assert_eq!(region.get_region_epoch().get_conf_ver(), 3);
    fail::remove(schedule_merge_fp);
    // Wait till rollback.
    cluster.must_put(b"k11", b"v11");

    // After rollback, version becomes 3 + 1 = 4;
    region.mut_region_epoch().set_version(4);
    for i in 1..3 {
        must_get_equal(&cluster.get_engine(i), b"k11", b"v11");
        let state_key = keys::region_state_key(region.get_id());
        let state: RegionLocalState = cluster
            .get_engine(i)
            .get_msg_cf(CF_RAFT, &state_key)
            .unwrap()
            .unwrap();
        assert_eq!(state.get_state(), PeerState::Normal);
        assert_eq!(*state.get_region(), region);
    }

    pd_client.must_remove_peer(right.get_id(), new_peer(3, 5));
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    let target_region = pd_client.get_region(b"k3").unwrap();
    cluster.must_try_merge(region.get_id(), target_region.get_id());
    let mut region = pd_client.get_region(b"k1").unwrap();

    // Split to trigger rollback.
    cluster.must_split(&right, b"k3");
    fail::remove(schedule_merge_fp);
    // Wait till rollback.
    cluster.must_put(b"k12", b"v12");

    // After premerge and rollback, conf_ver becomes 3 + 1 = 4, version becomes 4 +
    // 2 = 6;
    region.mut_region_epoch().set_conf_ver(4);
    region.mut_region_epoch().set_version(6);
    for i in 1..3 {
        must_get_equal(&cluster.get_engine(i), b"k12", b"v12");
        let state_key = keys::region_state_key(region.get_id());
        let state: RegionLocalState = cluster
            .get_engine(i)
            .get_msg_cf(CF_RAFT, &state_key)
            .unwrap()
            .unwrap();
        assert_eq!(state.get_state(), PeerState::Normal);
        assert_eq!(*state.get_region(), region);
    }
}
fn test_lines() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file_read = |f| {
        let mut s = String::new();
        at.open(f).read_to_string(&mut s).unwrap();
        s
    };

    // Split into two files without splitting up lines.
    ucmd.args(&["-n", "l/2", "fivelines.txt"]).succeeds();

    assert_eq!(file_read("xaa"), "1\n2\n3\n");
    assert_eq!(file_read("xab"), "4\n5\n");
}
fn test_lt() {
    assert!(version("0.0.0") < version("1.2.3-alpha2"));
    assert!(version("1.0.0") < version("1.2.3-alpha2"));
    assert!(version("1.2.0") < version("1.2.3-alpha2"));
    assert!(version("1.2.3-alpha1") < version("1.2.3"));
    assert!(version("1.2.3-alpha1") < version("1.2.3-alpha2"));
    assert!(!(version("1.2.3-alpha2") < version("1.2.3-alpha2")));
    assert!(version("1.2.3+23") < version("1.2.3+42"));
}
fn get_from_wrapper() {
    let mut store = Store::<()>::default();
    let f = Func::wrap(&mut store, || {});
    assert!(f.typed::<(), ()>(&store).is_ok());
    assert!(f.typed::<(), i32>(&store).is_err());
    assert!(f.typed::<(), ()>(&store).is_ok());
    assert!(f.typed::<i32, ()>(&store).is_err());
    assert!(f.typed::<i32, i32>(&store).is_err());
    assert!(f.typed::<(i32, i32), ()>(&store).is_err());
    assert!(f.typed::<(i32, i32), i32>(&store).is_err());

    let f = Func::wrap(&mut store, || -> i32 { loop {} });
    assert!(f.typed::<(), i32>(&store).is_ok());
    let f = Func::wrap(&mut store, || -> f32 { loop {} });
    assert!(f.typed::<(), f32>(&store).is_ok());
    let f = Func::wrap(&mut store, || -> f64 { loop {} });
    assert!(f.typed::<(), f64>(&store).is_ok());
    let f = Func::wrap(&mut store, || -> Option<ExternRef> { loop {} });
    assert!(f.typed::<(), Option<ExternRef>>(&store).is_ok());
    let f = Func::wrap(&mut store, || -> Option<Func> { loop {} });
    assert!(f.typed::<(), Option<Func>>(&store).is_ok());

    let f = Func::wrap(&mut store, |_: i32| {});
    assert!(f.typed::<i32, ()>(&store).is_ok());
    assert!(f.typed::<i64, ()>(&store).is_err());
    assert!(f.typed::<f32, ()>(&store).is_err());
    assert!(f.typed::<f64, ()>(&store).is_err());
    let f = Func::wrap(&mut store, |_: i64| {});
    assert!(f.typed::<i64, ()>(&store).is_ok());
    let f = Func::wrap(&mut store, |_: f32| {});
    assert!(f.typed::<f32, ()>(&store).is_ok());
    let f = Func::wrap(&mut store, |_: f64| {});
    assert!(f.typed::<f64, ()>(&store).is_ok());
    let f = Func::wrap(&mut store, |_: Option<ExternRef>| {});
    assert!(f.typed::<Option<ExternRef>, ()>(&store).is_ok());
    let f = Func::wrap(&mut store, |_: Option<Func>| {});
    assert!(f.typed::<Option<Func>, ()>(&store).is_ok());
}
fn ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_rage(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("rage")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_rage_snapshot(SnapshotPayload::new(
        module_path!(),
        "rage_ok",
        fs,
        console,
        result,
    ));
}
fn ignore_test() {
    let fmt = format::NumberFormat::<{ format::IGNORE }> {};
    assert_eq!(fmt.flags(), format::DIGIT_SEPARATOR_FLAG_MASK);
    assert_eq!(fmt.digit_separator(), b'_');
    assert_eq!(fmt.required_integer_digits(), false);
    assert_eq!(fmt.required_fraction_digits(), false);
    assert_eq!(fmt.required_exponent_digits(), false);
    assert_eq!(fmt.required_mantissa_digits(), false);
    assert_eq!(fmt.required_digits(), false);
    assert_eq!(fmt.no_positive_mantissa_sign(), false);
    assert_eq!(fmt.required_mantissa_sign(), false);
    assert_eq!(fmt.no_exponent_notation(), false);
    assert_eq!(fmt.no_positive_exponent_sign(), false);
    assert_eq!(fmt.required_exponent_sign(), false);
    assert_eq!(fmt.no_exponent_without_fraction(), false);
    assert_eq!(fmt.no_special(), false);
    assert_eq!(fmt.case_sensitive_special(), false);
    assert_eq!(fmt.no_integer_leading_zeros(), false);
    assert_eq!(fmt.no_float_leading_zeros(), false);
    assert_eq!(fmt.required_exponent_notation(), false);
    assert_eq!(fmt.case_sensitive_exponent(), false);
    #[cfg(feature = "power-of-two")]
    assert_eq!(fmt.case_sensitive_base_prefix(), false);
    #[cfg(feature = "power-of-two")]
    assert_eq!(fmt.case_sensitive_base_suffix(), false);
    assert_eq!(fmt.integer_internal_digit_separator(), true);
    assert_eq!(fmt.fraction_internal_digit_separator(), true);
    assert_eq!(fmt.exponent_internal_digit_separator(), true);
    assert_eq!(fmt.internal_digit_separator(), true);
    assert_eq!(fmt.integer_leading_digit_separator(), true);
    assert_eq!(fmt.fraction_leading_digit_separator(), true);
    assert_eq!(fmt.exponent_leading_digit_separator(), true);
    assert_eq!(fmt.leading_digit_separator(), true);
    assert_eq!(fmt.integer_trailing_digit_separator(), true);
    assert_eq!(fmt.fraction_trailing_digit_separator(), true);
    assert_eq!(fmt.exponent_trailing_digit_separator(), true);
    assert_eq!(fmt.trailing_digit_separator(), true);
    assert_eq!(fmt.integer_consecutive_digit_separator(), true);
    assert_eq!(fmt.fraction_consecutive_digit_separator(), true);
    assert_eq!(fmt.exponent_consecutive_digit_separator(), true);
    assert_eq!(fmt.consecutive_digit_separator(), true);
    assert_eq!(fmt.special_digit_separator(), true);
}
async fn too_big_headers_sends_431() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;
        assert_frame_eq(settings, frames::settings().max_header_list_size(10));
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .field("some-header", "some-value")
                    .eos(),
            )
            .await;
        client
            .recv_frame(frames::headers(1).response(431).eos())
            .await;
        idle_ms(10).await;
    };

    let srv = async move {
        let mut srv = server::Builder::new()
            .max_header_list_size(10)
            .handshake::<_, Bytes>(io)
            .await
            .expect("handshake");

        let req = srv.next().await;
        assert!(req.is_none(), "req is {:?}", req);
    };

    join(client, srv).await;
}
fn test_new_file_no_create() {
    let (at, mut ucmd) = at_and_ucmd!();
    let filename = "new_file_that_does_not_exist_yet";
    ucmd.args(&["-s", "8", "-c", filename])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert!(!at.file_exists(filename));
}
fn server_error_is_sticky() {
    let (_, mut server) = make_pair(KeyType::Rsa);
    server
        .read_tls(&mut b"\x16\x03\x03\x00\x08\x0f\x00\x00\x04junk".as_ref())
        .unwrap();
    let mut err = server.process_new_packets();
    assert!(err.is_err());
    err = server.process_new_packets();
    assert!(err.is_err());
}
fn test_boxed_raw_value() {
    #[derive(Serialize, Deserialize)]
    struct Wrapper {
        a: i8,
        b: Box<RawValue>,
        c: i8,
    }

    let wrapper_from_str: Wrapper =
        serde_json::from_str(r#"{"a": 1, "b": {"foo": 2}, "c": 3}"#).unwrap();
    assert_eq!(r#"{"foo": 2}"#, wrapper_from_str.b.get());

    let wrapper_from_reader: Wrapper =
        serde_json::from_reader(br#"{"a": 1, "b": {"foo": 2}, "c": 3}"#.as_ref()).unwrap();
    assert_eq!(r#"{"foo": 2}"#, wrapper_from_reader.b.get());

    let wrapper_from_value: Wrapper =
        serde_json::from_value(json!({"a": 1, "b": {"foo": 2}, "c": 3})).unwrap();
    assert_eq!(r#"{"foo":2}"#, wrapper_from_value.b.get());

    let wrapper_to_string = serde_json::to_string(&wrapper_from_str).unwrap();
    assert_eq!(r#"{"a":1,"b":{"foo": 2},"c":3}"#, wrapper_to_string);

    let wrapper_to_value = serde_json::to_value(&wrapper_from_str).unwrap();
    assert_eq!(json!({"a": 1, "b": {"foo": 2}, "c": 3}), wrapper_to_value);

    let array_from_str: Vec<Box<RawValue>> =
        serde_json::from_str(r#"["a", 42, {"foo": "bar"}, null]"#).unwrap();
    assert_eq!(r#""a""#, array_from_str[0].get());
    assert_eq!(r#"42"#, array_from_str[1].get());
    assert_eq!(r#"{"foo": "bar"}"#, array_from_str[2].get());
    assert_eq!(r#"null"#, array_from_str[3].get());

    let array_from_reader: Vec<Box<RawValue>> =
        serde_json::from_reader(br#"["a", 42, {"foo": "bar"}, null]"#.as_ref()).unwrap();
    assert_eq!(r#""a""#, array_from_reader[0].get());
    assert_eq!(r#"42"#, array_from_reader[1].get());
    assert_eq!(r#"{"foo": "bar"}"#, array_from_reader[2].get());
    assert_eq!(r#"null"#, array_from_reader[3].get());

    let array_to_string = serde_json::to_string(&array_from_str).unwrap();
    assert_eq!(r#"["a",42,{"foo": "bar"},null]"#, array_to_string);
}
fn ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), FORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");
}
fn parse_not_precedence() {
    // NOT has higher precedence than OR/AND, so the following must parse as (NOT true) OR true
    let sql = "NOT true OR true";
    assert_matches!(
        verified_expr(sql),
        Expr::BinaryOp {
            op: BinaryOperator::Or,
            ..
        }
    );

    // But NOT has lower precedence than comparison operators, so the following parses as NOT (a IS NULL)
    let sql = "NOT a IS NULL";
    assert_matches!(
        verified_expr(sql),
        Expr::UnaryOp {
            op: UnaryOperator::Not,
            ..
        }
    );

    // NOT has lower precedence than BETWEEN, so the following parses as NOT (1 NOT BETWEEN 1 AND 2)
    let sql = "NOT 1 NOT BETWEEN 1 AND 2";
    assert_eq!(
        verified_expr(sql),
        Expr::UnaryOp {
            op: UnaryOperator::Not,
            expr: Box::new(Expr::Between {
                expr: Box::new(Expr::Value(number("1"))),
                low: Box::new(Expr::Value(number("1"))),
                high: Box::new(Expr::Value(number("2"))),
                negated: true,
            }),
        },
    );

    // NOT has lower precedence than LIKE, so the following parses as NOT ('a' NOT LIKE 'b')
    let sql = "NOT 'a' NOT LIKE 'b'";
    assert_eq!(
        verified_expr(sql),
        Expr::UnaryOp {
            op: UnaryOperator::Not,
            expr: Box::new(Expr::Like {
                expr: Box::new(Expr::Value(Value::SingleQuotedString("a".into()))),
                negated: true,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("b".into()))),
                escape_char: None,
            }),
        },
    );

    // NOT has lower precedence than IN, so the following parses as NOT (a NOT IN 'a')
    let sql = "NOT a NOT IN ('a')";
    assert_eq!(
        verified_expr(sql),
        Expr::UnaryOp {
            op: UnaryOperator::Not,
            expr: Box::new(Expr::InList {
                expr: Box::new(Expr::Identifier("a".into())),
                list: vec![Expr::Value(Value::SingleQuotedString("a".into()))],
                negated: true,
            }),
        },
    );
}
fn parse_in_unnest() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE segment {}IN UNNEST(expr)",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::InUnnest {
                expr: Box::new(Expr::Identifier(Ident::new("segment"))),
                array_expr: Box::new(verified_expr("expr")),
                negated,
            },
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn host_resource_types() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (import "u" (type $u (sub resource)))

                (export "t1" (type $t))
                (export "t2" (type $t))
                (export "u1" (type $u))
                (export "u2" (type $u))

                (component $c
                    (import "r" (type $r (sub resource)))
                    (export "r1" (type $r))
                )
                (instance $i1 (instantiate $c (with "r" (type $t))))
                (instance $i2 (instantiate $c (with "r" (type $t))))
                (export "t3" (type $i1 "r1"))
                (export "t4" (type $i2 "r1"))
            )
        "#,
    )?;

    struct T;
    struct U;
    assert!(ResourceType::host::<T>() != ResourceType::host::<U>());

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<T>("t", |_, _| Ok(()))?;
    linker.root().resource::<U>("u", |_, _| Ok(()))?;
    let i = linker.instantiate(&mut store, &c)?;
    let t1 = i.get_resource(&mut store, "t1").unwrap();
    let t2 = i.get_resource(&mut store, "t2").unwrap();
    let t3 = i.get_resource(&mut store, "t3").unwrap();
    let t4 = i.get_resource(&mut store, "t4").unwrap();
    let u1 = i.get_resource(&mut store, "u1").unwrap();
    let u2 = i.get_resource(&mut store, "u2").unwrap();

    assert_eq!(t1, ResourceType::host::<T>());
    assert_eq!(t2, ResourceType::host::<T>());
    assert_eq!(t3, ResourceType::host::<T>());
    assert_eq!(t4, ResourceType::host::<T>());
    assert_eq!(u1, ResourceType::host::<U>());
    assert_eq!(u2, ResourceType::host::<U>());
    Ok(())
}
fn does_not_handle_included_files_if_overridden_by_ignore_linter() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "linter": { "include": ["test.js", "test2.js"], "ignore": ["test.js"] }
}
"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), FIX_BEFORE.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FIX_AFTER);

    drop(file);

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FIX_BEFORE);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_included_files_if_overridden_by_ignore_linter",
        fs,
        console,
        result,
    ));
}
fn test_non_ascii() {
    assert_eq!(to_string(&"").unwrap(), "\"\"");
    assert_eq!(to_string(&"").unwrap(), "\"\"");
    assert_eq!(to_string(&"").unwrap(), "\"\"");
    assert_eq!(to_string(&"").unwrap(), "\"\"");
    assert_eq!(to_string(&"").unwrap(), "\"\"");
}

#[test]
fn
async fn timeout_async_hook() -> Result<(), Error> {
    struct HandlerR;

    #[async_trait::async_trait]
    impl CallHookHandler<State> for HandlerR {
        async fn handle_call_event(&self, obj: &mut State, ch: CallHook) -> Result<()> {
            if obj.calls_into_host > 200 {
                bail!("timeout");
            }

            match ch {
                CallHook::CallingHost => obj.calls_into_host += 1,
                CallHook::CallingWasm => obj.calls_into_wasm += 1,
                CallHook::ReturningFromHost => obj.returns_from_host += 1,
                CallHook::ReturningFromWasm => obj.returns_from_wasm += 1,
            }

            Ok(())
        }
    }

    let mut config = Config::new();
    config.async_support(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, State::default());
    store.call_hook_async(HandlerR {});

    assert_eq!(store.data().calls_into_host, 0);
    assert_eq!(store.data().returns_from_host, 0);
    assert_eq!(store.data().calls_into_wasm, 0);
    assert_eq!(store.data().returns_from_wasm, 0);

    let mut linker = Linker::new(&engine);

    linker.func_wrap(
        "host",
        "f",
        |_caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {
            assert_eq!(a, 1);
            assert_eq!(b, 2);
            assert_eq!(c, 3.0);
            assert_eq!(d, 4.0);
        },
    )?;

    let wat = r#"
        (module
            (import "host" "f"
                (func $f (param i32) (param i64) (param f32) (param f64)))
            (func (export "export")
                (loop $start
                    (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0))
                    (br $start)))
        )
    "#;
    let module = Module::new(&engine, wat)?;

    let inst = linker.instantiate_async(&mut store, &module).await?;
    let export = inst
        .get_typed_func::<(), ()>(&mut store, "export")
        .expect("export is func");

    store.set_epoch_deadline(1);
    store.epoch_deadline_async_yield_and_update(1);
    assert!(export.call_async(&mut store, ()).await.is_err());

    // One switch from vm to host to call f, another in return from f.
    assert!(store.data().calls_into_host > 1);
    assert!(store.data().returns_from_host > 1);
    assert_eq!(store.data().calls_into_wasm, 1);
    assert_eq!(store.data().returns_from_wasm, 0);

    Ok(())
}
fn second_block() {
  assert_eq!(
    CommandBuilder::new("subsidy 1").run_and_deserialize_output::<Output>(),
    Output {
      first: 5000000000,
      subsidy: 5000000000,
      name: "nvtcsezkbth".into(),
    }
  );
}
fn test_install_creating_leading_dirs() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let source = "create_leading_test_file";
    let target = "dir1/dir2/dir3/test_file";

    at.touch(source);

    scene
        .ucmd()
        .arg("-D")
        .arg(source)
        .arg(at.plus(target))
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(target));
}
fn comments_are_ignored() {
    let inputs = vec![
        ("Hello {# comment #}world", "Hello world"),
        ("Hello {# comment {# nested #}world", "Hello world"),
        ("My name {# was {{ name }} #}is No One.", "My name is No One."),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &Context::new()).unwrap(), expected);
    }
}
fn test_memory_traps_on_limited_growth() -> Result<(), Error> {
    let limits = StoreLimitsBuilder::new()
        .memory_size(0x30_0000)
        .trap_on_grow_failure(true)
        .build();
    let mut test = Test::new(0x20, 100, limits)?;
    // Check memory size is what we expect.
    assert_eq!(test.memory_size.call(&mut test.store, ())?, 0x20);
    // First memory.grow doesn't hit the limit, so succeeds, returns previous size.
    assert_eq!(test.memory_grow.call(&mut test.store, (0x10,))?, 0x20);
    // Check memory size is what we expect.
    assert_eq!(test.memory_size.call(&mut test.store, ())?, 0x30);
    // Second call goes past the limit, so fails to grow the memory, and we've configured it to trap.
    assert!(matches!(
        test.memory_grow
            .call(&mut test.store, (0x10,))
            .unwrap_err()
            .trap_code(),
        Some(TrapCode::GrowthOperationLimited)
    ));
    // Check memory size is what we expect.
    assert_eq!(test.memory_size.call(&mut test.store, ())?, 0x30);
    Ok(())
}
fn second_to_last_block_with_subsidy() {
  assert_eq!(
    CommandBuilder::new("subsidy 6929998").run_and_deserialize_output::<Output>(),
    Output {
      first: 2099999997689998,
      subsidy: 1,
      name: "b".into(),
    }
  );
}
fn test_cp_multiple_files() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), "Hello, World!\n");
    assert_eq!(at.read(TEST_HOW_ARE_YOU_DEST), "How are you?\n");
}
async fn server_builder_set_max_concurrent_streams() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let mut settings = frame::Settings::default();
    settings.set_max_concurrent_streams(Some(1));

    let client = async move {
        let recv_settings = client.assert_server_handshake().await;
        assert_frame_eq(recv_settings, settings);
        client
            .send_frame(frames::headers(1).request("GET", "https://example.com/"))
            .await;
        client
            .send_frame(frames::headers(3).request("GET", "https://example.com/"))
            .await;
        client
            .send_frame(frames::data(1, &b"hello"[..]).eos())
            .await;
        client.recv_frame(frames::reset(3).refused()).await;
        client
            .recv_frame(frames::headers(1).response(200).eos())
            .await;
    };

    let mut builder = server::Builder::new();
    builder.max_concurrent_streams(1);

    let h2 = async move {
        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");
        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(req.method(), &http::Method::GET);

        let rsp = http::Response::builder().status(200).body(()).unwrap();
        stream.send_response(rsp, true).unwrap();

        assert!(srv.next().await.is_none());
    };

    join(client, h2).await;
}
fn valid_context_directory_recursive_follow_args_dir_symlinks() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.mkdir("a");
    dir.symlink_dir("a", "la");

    let b_path = Path::new("a").join("b.txt");
    dir.touch(b_path.to_str().unwrap());

    let la_context = get_file_context(dir.plus("la")).unwrap();
    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    /*
    let lc_path = Path::new("a").join("lc");
    dir.symlink_dir("c", lc_path.to_str().unwrap());
    assert_eq!(
        get_file_context(dir.plus(lc_path.to_str().unwrap())).unwrap(),
        None
    );
    */

    // -H: if a command line argument is a symbolic link to a directory, traverse it.
    cmd.args(&["--verbose", "--recursive", "-H", new_la_context])
        .arg(dir.plus("la"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("a")).unwrap().as_deref(),
        Some(new_la_context)
    );
    assert_eq!(
        get_file_context(dir.plus(b_path.to_str().unwrap()))
            .unwrap()
            .as_deref(),
        Some(new_la_context)
    );
    assert_eq!(get_file_context(dir.plus("la")).unwrap(), la_context);
    /*
    assert_eq!(
        get_file_context(dir.plus(lc_path.to_str().unwrap()))
            .unwrap()
            .as_deref(),
        Some(new_la_context)
    );
    */
}
fn client_can_get_server_cert() {
    for kt in ALL_KEY_TYPES.iter() {
        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions(*kt, &[version]);
            let (mut client, mut server) =
                make_pair_for_configs(client_config, make_server_config(*kt));
            do_handshake(&mut client, &mut server);

            let certs = client.peer_certificates();
            assert_eq!(certs, Some(kt.get_chain().as_slice()));
        }
    }
}
fn test_install_backup_never() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=never")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_default() {
    assert_eq!(Value::default(), Value::Null);
}
fn maximum_diagnostics() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), ERRORS.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    assert_eq!(
        messages
            .iter()
            .filter(|m| m.level == LogLevel::Error)
            .count(),
        20_usize
    );

    assert!(messages
        .iter()
        .filter(|m| m.level == LogLevel::Log)
        .any(|m| {
            let content = format!("{:?}", m.content);
            content.contains("The number of diagnostics exceeds the number allowed by Biome")
                && content.contains("Diagnostics not shown")
                && content.contains("79")
        }));

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "maximum_diagnostics",
        fs,
        console,
        result,
    ));
}
fn test_invalid_range() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);

    let mut select = DagSelect::from(&product);
    select.key_ranges[0].set_start(b"xxx".to_vec());
    select.key_ranges[0].set_end(b"zzz".to_vec());
    let req = select.build();
    let resp = handle_request(&endpoint, req);
    assert!(!resp.get_other_error().is_empty());
}
fn parse_create_schema_if_not_exists() {
    let sql = "CREATE SCHEMA IF NOT EXISTS schema_name";
    let ast = pg_and_generic().verified_stmt(sql);
    match ast {
        Statement::CreateSchema {
            if_not_exists: true,
            schema_name,
        } => assert_eq!("schema_name", schema_name.to_string()),
        _ => unreachable!(),
    }
}
fn test_compute_pow5() {
    for (i, entry) in DOUBLE_POW5_SPLIT.iter().enumerate() {
        assert_eq!(*entry, unsafe { compute_pow5(i as u32) }, "entry {}", i);
    }
}
fn exit2_wasi_snapshot1() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit2_wasi_snapshot1.wat")?;
    let output = run_wasmtime_for_output(&["-Ccache=n", wasm.path().to_str().unwrap()], None)?;
    assert_eq!(output.status.code().unwrap(), 2);
    Ok(())
}
fn test_context() {
    let var1 = 23;
    let ctx = context!(var1, var2 => 42);
    assert_eq!(ctx.get_attr("var1").unwrap(), Value::from(23));
    assert_eq!(ctx.get_attr("var2").unwrap(), Value::from(42));
}
fn applies_extended_values_in_current_config() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let format = Path::new("format.json");
    fs.insert(
        format.into(),
        r#"{ "javascript": { "formatter": { "quoteStyle": "single" } } }"#,
    );

    let rome_json = Path::new("biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["format.json"], "formatter": { "lineWidth": 20 } }"#,
    );

    let test_file = Path::new("test.js");
    fs.insert(
        test_file.into(),
        r#"debugger; const a = ["lorem", "ipsum"]; "#,
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                "--write",
                test_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_extended_values_in_current_config",
        fs,
        console,
        result,
    ));
}
fn test_old_value_cache_without_downstreams() {
    fn check_old_value_cache(scheduler: &Scheduler<Task>, updates: usize) {
        let (tx, rx) = mpsc::sync_channel(1);
        let checker = move |c: &OldValueCache| tx.send(c.update_count()).unwrap();
        scheduler
            .schedule(Task::Validate(Validate::OldValueCache(Box::new(checker))))
            .unwrap();
        assert_eq!(rx.recv().unwrap(), updates);
    }

    let mutation = || {
        let mut mutation = Mutation::default();
        mutation.set_op(Op::Put);
        mutation.key = b"key".to_vec();
        mutation.value = b"value".to_vec();
        mutation
    };

    fail::cfg("cdc_flush_old_value_metrics", "return").unwrap();

    let cluster = new_server_cluster(0, 1);
    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();
    let scheduler = suite.endpoints[&1].scheduler();

    // Add a subscription and then check old value cache.
    let (mut req_tx, event_feed, receive_event) = new_event_feed(suite.get_region_cdc_client(1));
    let req = suite.new_changedata_request(1);
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();
    receive_event(false); // Wait until the initialization finishes.

    // Old value cache will be updated because there is 1 capture.
    suite.must_kv_prewrite(1, vec![mutation()], b"key".to_vec(), 3.into());
    suite.must_kv_commit(1, vec![b"key".to_vec()], 3.into(), 4.into());
    check_old_value_cache(&scheduler, 1);

    drop(req_tx);
    drop(event_feed);
    drop(receive_event);
    sleep_ms(200);

    // Old value cache won't be updated because there is no captures.
    suite.must_kv_prewrite(1, vec![mutation()], b"key".to_vec(), 5.into());
    suite.must_kv_commit(1, vec![b"key".to_vec()], 5.into(), 6.into());
    check_old_value_cache(&scheduler, 1);

    fail::remove("cdc_flush_old_value_metrics");
}
fn fs_error_read_only() {
    let mut fs = MemoryFileSystem::new_read_only();
    let mut console = BufferConsole::default();

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), *b"content");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Do not store the content of the file in the snapshot
    fs.remove(file_path);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_read_only",
        fs,
        console,
        result,
    ));
}
fn test_datagram_stream_upgrade_on_truncation_despite_udp() {
    // Lookup to UDP should return a truncated message, then we expect lookup on TCP.
    // This should occur even though `try_tcp_on_error` is set to false.

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));
    let tcp_record1 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));
    let tcp_record2 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 3));

    let mut udp_message = message(query.clone(), vec![udp_record], vec![], vec![]);
    udp_message.set_truncated(true);

    let tcp_message = message(
        query.clone(),
        vec![tcp_record1.clone(), tcp_record2.clone()],
        vec![],
        vec![],
    );

    let udp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        Default::default(),
    );
    let tcp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],
        Default::default(),
    );

    let pool = mock_nameserver_pool(
        vec![udp_nameserver],
        vec![tcp_nameserver],
        None,
        Default::default(),
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    let response = block_on(future).unwrap();
    assert_eq!(response.answers(), &[tcp_record1, tcp_record2]);
}
fn render_macros() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}Hello{% endmacro hello %}"),
        (
            "tpl",
            "{% import \"macros\" as macros %}{% block hey %}{{macros::hello()}}{% endblock hey %}",
        ),
    ])
    .unwrap();

    let result = tera.render("tpl", &Context::new());

    assert_eq!(result.unwrap(), "Hello".to_string());
}
fn test_normalization_tests_unaffected() {
    for test in NORMALIZATION_TESTS {
        for &s in &[test.source, test.nfc, test.nfd, test.nfkc, test.nfkd] {
            assert_eq!(stream_safe(s), s);
        }
    }
}
fn test_debug_region_size_v2() {
    let (cluster, debug_client, store_id) = test_raftstore_v2::must_new_cluster_and_debug_client();
    let raft_engine = cluster.get_raft_engine(store_id);
    let engine = cluster.get_engine(store_id);

    let mut lb = raft_engine.log_batch(10);
    // Put some data.
    let region_id = 1;
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    region.set_start_key(b"a".to_vec());
    region.set_end_key(b"z".to_vec());
    let mut state = RegionLocalState::default();
    state.set_region(region);
    state.set_tablet_index(5);
    lb.put_region_state(region_id, 5, &state).unwrap();
    raft_engine.consume(&mut lb, false).unwrap();

    let cfs = vec![CF_DEFAULT, CF_LOCK, CF_WRITE];
    // At lease 8 bytes for the WRITE cf.
    let (k, v) = (keys::data_key(b"kkkk_kkkk"), b"v");
    for cf in &cfs {
        engine.put_cf(cf, k.as_slice(), v).unwrap();
    }

    let mut req = debugpb::RegionSizeRequest::default();
    req.set_region_id(region_id);
    req.set_cfs(cfs.iter().map(|s| s.to_string()).collect());
    let entries: Vec<_> = debug_client
        .region_size(&req)
        .unwrap()
        .take_entries()
        .into();
    assert_eq!(entries.len(), 3);
    for e in entries {
        cfs.iter().find(|&&c| c == e.cf).unwrap();
        assert!(e.size > 0);
    }

    req.set_region_id(region_id + 1);
    match debug_client.region_size(&req).unwrap_err() {
        Error::RpcFailure(status) => {
            assert_eq!(status.code(), RpcStatusCode::NOT_FOUND);
        }
        _ => panic!("expect NotFound"),
    }
}
fn artifact_deserialization_roundtrip() {
    // This test is included to make sure we don't break the serialized format
    // by mistake. Otherwise, everything in this test is already tested in
    // `artifact_serialization_roundtrip`.
    let file_names = ["bash.wasmu", "cowsay.wasmu", "python-3.11.3.wasmu"];

    cfg_if!(
        if #[cfg(target_os = "windows")] {
            let base_path = "tests/compilers/wasmu/windows";
        } else {
            let base_path = "tests/compilers/wasmu/linux";
        }
    );

    for file_name in file_names {
        let path = PathBuf::from(base_path).join(file_name);
        let wasm_module_bytes = fs::read(path).unwrap();
        let engine = Engine::default();
        let module = unsafe { Module::deserialize(&engine, wasm_module_bytes.clone()) }.unwrap();
        let reserialized_bytes = module.serialize().unwrap();
        assert_eq!(wasm_module_bytes.to_vec(), reserialized_bytes);
    }
}
fn test_mv_rename_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir1 = "test_mv_rename_dir";
    let dir2 = "test_mv_rename_dir2";

    at.mkdir(dir1);

    ucmd.arg(dir1).arg(dir2).succeeds().no_stderr();

    assert!(at.dir_exists(dir2));
}
fn test_rm_force() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_rm_force_a";
    let file_b = "test_rm_force_b";

    at.touch(file_a);
    at.touch(file_b);
    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    ucmd.arg("-f")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
}
fn test_analyze_sampling_bernoulli() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, None, 4),
        (6, Some("name:1"), 1),
        (7, Some("name:1"), 1),
        (8, Some("name:1"), 1),
        (9, Some("name:2"), 1),
        (10, Some("name:2"), 1),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);

    // Pass the 2nd column as a column group.
    let req = new_analyze_sampling_req(&product, 1, 0, 0.5);
    let resp = handle_request(&endpoint, req);
    assert!(!resp.get_data().is_empty());
    let mut analyze_resp = AnalyzeColumnsResp::default();
    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();
    let collector = analyze_resp.get_row_collector();
    // The column group is at 4th place and the data should be equal to the 2nd.
    assert_eq!(collector.get_null_counts(), vec![0, 1, 0, 1]);
    assert_eq!(collector.get_count(), 9);
    assert_eq!(collector.get_fm_sketch().len(), 4);
    assert_eq!(collector.get_total_size(), vec![72, 56, 9, 56]);
}
fn test_split_separator_semicolon_number_l() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--number=l/3", "--separator=;", "separator_semicolon.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1;2;");
    assert_eq!(file_read(&at, "xab"), "3;4;");
    assert_eq!(file_read(&at, "xac"), "5;");
    assert!(!at.plus("xad").exists());
}
fn test_snapshot_failed() {
    let product = ProductTable::new();
    let (_cluster, raft_engine, ctx) = new_raft_engine(1, "");

    let (_, endpoint, _) = init_data_with_engine_and_commit(ctx, raft_engine, &product, &[], true);

    // Use an invalid context to make errors.
    let req = DagSelect::from(&product).build_with(Context::default(), &[0]);
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_region_error().has_store_not_match());
}
fn issue_31() {
    let mut router = Router::new();
    router.insert("/path/foo/:arg", "foo").unwrap();
    router.insert("/path/*rest", "wildcard").unwrap();

    assert_eq!(
        router.at("/path/foo/myarg/bar/baz").map(|m| *m.value),
        Ok("wildcard")
    );
}
fn test_mv_move_file_between_dirs() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir1 = "test_mv_move_file_between_dirs_dir1";
    let dir2 = "test_mv_move_file_between_dirs_dir2";
    let file = "test_mv_move_file_between_dirs_file";

    at.mkdir(dir1);
    at.mkdir(dir2);
    at.touch(format!("{dir1}/{file}"));

    assert!(at.file_exists(format!("{dir1}/{file}")));

    ucmd.arg(&format!("{dir1}/{file}"))
        .arg(dir2)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(format!("{dir1}/{file}")));
    assert!(at.file_exists(format!("{dir2}/{file}")));
}
fn does_error_with_only_warnings() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"
{
    "formatter": { "enabled": false},
  "linter": {
    "rules": {
        "recommended": true,
        "suspicious": {
            "noClassAssign": "warn"
        }
    }
  }
}
        "#
        .as_bytes(),
    );

    let file_path = Path::new("file.js");
    fs.insert(
        file_path.into(),
        r#"class A {};
A = 0;
"#
        .as_bytes(),
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                "ci",
                "--error-on-warnings",
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_error_with_only_warnings",
        fs,
        console,
        result,
    ));
}
fn i32_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0i32.to_lexical(&mut buffer));
    assert_eq!(b"1", 1i32.to_lexical(&mut buffer));
    assert_eq!(b"5", 5i32.to_lexical(&mut buffer));
    assert_eq!(b"2147483647", 2147483647i32.to_lexical(&mut buffer));
    assert_eq!(b"-2147483648", (2147483648u32 as i32).to_lexical(&mut buffer));
    assert_eq!(b"-1", (4294967295u32 as i32).to_lexical(&mut buffer));
    assert_eq!(b"-1", (-1i32).to_lexical(&mut buffer));
}
fn safe_function_works() {
    struct Safe;
    impl crate::Function for Safe {
        fn call(&self, _args: &HashMap<String, Value>) -> Result<Value> {
            Ok(Value::String("<div>Hello</div>".to_owned()))
        }

        fn is_safe(&self) -> bool {
            true
        }
    }

    let mut tera = Tera::default();
    tera.register_function("safe_function", Safe);
    tera.add_raw_template("test.html", "{{ safe_function() }}").unwrap();

    let res = tera.render("test.html", &Context::new());
    assert_eq!(res.unwrap(), "<div>Hello</div>");
}
fn test_overflow() {
    assert_eq!(f64::INFINITY, s2d(b"2e308").unwrap());
    assert_eq!(f64::INFINITY, s2d(b"1e309").unwrap());
}
fn test_expression_lifetimes() {
    let mut env = Environment::new();
    let s = String::new();
    env.add_template("test", &s).unwrap();
    {
        let x = String::from("1 + 1");
        let expr = env.compile_expression(&x).unwrap();
        assert_eq!(expr.eval(()).unwrap().to_string(), "2");
    }
}
fn test_hex_suffix() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n", "4", "--hex-suffixes=9", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x0a"), "b");
    assert_eq!(at.read("x0b"), "c");
    assert_eq!(at.read("x0c"), "");
}
fn iter() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(U64_TABLE).unwrap();
        for i in 0..10 {
            for j in 0..10 {
                table.insert(&i, &j).unwrap();
            }
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(U64_TABLE).unwrap();
    let mut iter = table.iter().unwrap();
    for i in 0..10 {
        let (k, mut values) = iter.next().unwrap().unwrap();
        assert_eq!(k.value(), i);
        for j in 0..10 {
            assert_eq!(values.next().unwrap().unwrap().value(), j);
        }
    }
}
fn test_lookup() {
    let authority = create_example();
    let mut catalog = Catalog::new();
    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));

    let io_loop = Runtime::new().unwrap();
    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));
    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());
    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);

    let (client, bg) = io_loop.block_on(client).expect("client failed to connect");
    hickory_proto::spawn_bg(&io_loop, bg);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, false),
    );
    let lookup = io_loop.block_on(lookup).unwrap();

    assert_eq!(
        *lookup.iter().next().unwrap(),
        RData::A(A::new(93, 184, 216, 34))
    );
}
fn test_symlink_existing_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_existing_file";
    let link = "test_symlink_existing_file_link";

    at.touch(file);

    ucmd.args(&["-s", file, link]).succeeds().no_stderr();

    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);
}
fn parse_break() {
    let ast = parse("{% for item in items %}{% break -%}{% endfor %}").unwrap();
    let for_ws = WS::default();
    assert_eq!(
        ast[0],
        Node::Forloop(
            for_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::new(ExprVal::Ident("items".to_string())),
                body: vec![Node::Break(WS { left: false, right: true }),],
                empty_body: None,
            },
            for_ws,
        )
    );
}
fn test_error_wrong_args_macros() {
    let result = render_tpl("macro_wrong_args.html");

    assert!(result.is_err());
    assert!(result
        .unwrap_err()
        .source()
        .unwrap()
        .to_string()
        .contains("Macro `input` is missing the argument"));
}
fn cover_offset() {
    assert_eq!(range(1..3).cover_offset(size(0)), range(0..3));
    assert_eq!(range(1..3).cover_offset(size(1)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(2)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(3)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(4)), range(1..4));
}
fn client_with_sni_disabled_does_not_send_sni() {
    for kt in ALL_KEY_TYPES.iter() {
        let mut server_config = make_server_config(*kt);
        server_config.cert_resolver = Arc::new(ServerCheckNoSNI {});
        let server_config = Arc::new(server_config);

        for version in rustls::ALL_VERSIONS {
            let mut client_config = make_client_config_with_versions(*kt, &[version]);
            client_config.enable_sni = false;

            let mut client =
                ClientConnection::new(Arc::new(client_config), dns_name("value-not-sent")).unwrap();
            let mut server = ServerConnection::new(Arc::clone(&server_config)).unwrap();

            let err = do_handshake_until_error(&mut client, &mut server);
            assert!(err.is_err());
        }
    }
}
fn test_hostname_ip() {
    let result = new_ucmd!().arg("-i").succeeds();
    assert!(!result.stdout_str().trim().is_empty());
}
fn test_batch_size_edge_limit() {
    let msg_count = Arc::new(AtomicUsize::new(0));
    let batch_msg_count = Arc::new(AtomicUsize::new(0));
    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), true);
    let (mock_server, port) = create_mock_server(service, 60200, 60300).unwrap();

    let mut raft_client = get_raft_client_by_port(port);

    // Put them in buffer so sibling messages will be likely be batched during
    // sending.
    let mut msgs = Vec::with_capacity(5);
    for _ in 0..5 {
        let mut raft_m = RaftMessage::default();
        // Magic number, this can make estimated size about 4940000, hence two messages
        // will be batched together, but the total size will be way larger than
        // 10MiB as there are many indexes and terms.
        for _ in 0..38000 {
            let mut e = Entry::default();
            e.set_term(1);
            e.set_index(256);
            e.set_data(vec![b'a'; 130].into());
            raft_m.mut_message().mut_entries().push(e);
        }
        msgs.push(raft_m);
    }
    for m in msgs {
        raft_client.send(m).unwrap();
    }
    raft_client.flush();

    check_msg_count(10000, &msg_count, 5);
    // The final received message count should be 5 exactly.
    drop(raft_client);
    drop(mock_server);
    assert_eq!(msg_count.load(Ordering::SeqCst), 5);
}
fn stdin_source_type_py() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(["--stdin-filename", "TCH.py"])
        .pass_stdin("import os\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    TCH.py:1:8: F401 [*] `os` imported but unused
    Found 1 error.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn test_upload_sst() {
    let (_cluster, ctx, _, import) = new_cluster_and_tikv_import_client();

    let data = vec![1; 1024];
    let crc32 = calc_data_crc32(&data);
    let length = data.len() as u64;

    // Mismatch crc32
    let meta = new_sst_meta(0, length);
    assert_to_string_contains!(send_upload_sst(&import, &meta, &data).unwrap_err(), "crc32");

    let mut meta = new_sst_meta(crc32, length);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());
    send_upload_sst(&import, &meta, &data).unwrap();

    // Can't upload the same uuid file again.
    assert_to_string_contains!(
        send_upload_sst(&import, &meta, &data).unwrap_err(),
        "FileExists"
    );
}
