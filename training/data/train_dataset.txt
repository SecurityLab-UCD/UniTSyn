{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_demote_failed_voters() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut demoted = true;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n        demoted = true;\n        for peer in region.get_peers() {\n            if peer.get_id() != nodes[0] && peer.get_role() == metapb::PeerRole::Voter {\n                demoted = false;\n            }\n        }\n        if demoted {\n            break;\n        }\n        sleep_ms(200);\n    }\n    assert!(demoted);\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_bytes_ser() {\n    let buf = vec![];\n    let bytes = Bytes::new(&buf);\n    assert_eq!(to_string(&bytes).unwrap(), \"[]\".to_string());\n\n    let buf = vec![1, 2, 3];\n    let bytes = Bytes::new(&buf);\n    assert_eq!(to_string(&bytes).unwrap(), \"[1,2,3]\".to_string());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_create_region() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let store0_peer = find_peer(&region, nodes[0]).unwrap().to_owned();\n\n    // Removes the boostrap region, since it overlaps with any regions we create.\n    pd_client.must_remove_peer(region.get_id(), store0_peer);\n    cluster.must_remove_region(nodes[0], region.get_id());\n\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());\n\n    let mut create = metapb::Region::default();\n    create.set_id(101);\n    create.set_start_key(b\"anykey\".to_vec());\n    let mut peer = metapb::Peer::default();\n    peer.set_id(102);\n    peer.set_store_id(nodes[0]);\n    create.mut_peers().push(peer);\n    let mut plan = pdpb::RecoveryPlan::default();\n    plan.mut_creates().push(create);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n    let mut created = false;\n    for _ in 1..11 {\n        let region = pd_client.get_region(b\"anykey1\").unwrap();\n        if region.get_id() == 101 {\n            created = true;\n        }\n        sleep_ms(200);\n    }\n    assert_eq!(created, true);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn upgrade_severity() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(\n        file_path.into(),\n        CONFIG_LINTER_UPGRADE_DIAGNOSTIC.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), UPGRADE_SEVERITY_CODE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    let error_count = messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Error)\n        .filter(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"style/noNegationElse\")\n        })\n        .count();\n\n    assert_eq!(\n        error_count, 1,\n        \"expected 1 error-level message in console buffer, found {error_count:?}:\\n{:?}\",\n        console.out_buffer\n    );\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"upgrade_severity\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_multiple_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let target_dir = \"test_mv_multiple_files_dir\";\n    let file_a = \"test_mv_multiple_file_a\";\n    let file_b = \"test_mv_multiple_file_b\";\n\n    at.mkdir(target_dir);\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(file_a)\n        .arg(file_b)\n        .arg(target_dir)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(format!(\"{target_dir}/{file_a}\")));\n    assert!(at.file_exists(format!(\"{target_dir}/{file_b}\")));\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_nan_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.nan_string(Some(b\"naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaan\"));\n    assert!(!builder.is_valid());\n    builder = builder.nan_string(Some(b\"inf\"));\n    assert!(!builder.is_valid());\n    builder = builder.nan_string(Some(b\"na00n\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.nan_string(Some(b\"nan\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.nan_string(None);\n    assert!(builder.is_valid());\n}"}
{"code": "fn is_none(&self) -> bool {\n        self.index == !0\n    }", "test": "fn smoke() {\n    let mut headers = HeaderMap::new();\n\n    assert!(headers.get(\"hello\").is_none());\n\n    let name: HeaderName = \"hello\".parse().unwrap();\n\n    match headers.entry(&name) {\n        Entry::Vacant(e) => {\n            e.insert(\"world\".parse().unwrap());\n        }\n        _ => panic!(),\n    }\n\n    assert!(headers.get(\"hello\").is_some());\n\n    match headers.entry(&name) {\n        Entry::Occupied(mut e) => {\n            assert_eq!(e.get(), &\"world\");\n\n            // Push another value\n            e.append(\"zomg\".parse().unwrap());\n\n            let mut i = e.iter();\n\n            assert_eq!(*i.next().unwrap(), \"world\");\n            assert_eq!(*i.next().unwrap(), \"zomg\");\n            assert!(i.next().is_none());\n        }\n        _ => panic!(),\n    }\n}"}
{"code": "pub fn reason(&self) -> Option<Reason> {\n        match self.kind {\n            Kind::Reset(_, reason, _) | Kind::GoAway(_, reason, _) | Kind::Reason(reason) => {\n                Some(reason)\n            }\n            _ => None,\n        }\n    }", "test": "async fn recv_too_big_headers() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_frame_eq(settings, frames::settings().max_header_list_size(10));\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://http2.akamai.com/\")\n                .eos(),\n        )\n        .await;\n        srv.recv_frame(\n            frames::headers(3)\n                .request(\"GET\", \"https://http2.akamai.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(frames::headers(1).response(200).eos()).await;\n        srv.send_frame(frames::headers(3).response(200)).await;\n        // no reset for 1, since it's closed anyway\n        // but reset for 3, since server hasn't closed stream\n        srv.recv_frame(frames::reset(3).refused()).await;\n        idle_ms(10).await;\n    };\n\n    let client = async move {\n        let (mut client, mut conn) = client::Builder::new()\n            .max_header_list_size(10)\n            .handshake::<_, Bytes>(io)\n            .await\n            .expect(\"handshake\");\n\n        let request = Request::builder()\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let req1 = client.send_request(request, true);\n        let req1 = async move {\n            let err = req1.expect(\"send_request\").0.await.expect_err(\"response1\");\n            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));\n        };\n\n        let request = Request::builder()\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let req2 = client.send_request(request, true);\n        let req2 = async move {\n            let err = req2.expect(\"send_request\").0.await.expect_err(\"response2\");\n            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));\n        };\n\n        conn.drive(join(req1, req2)).await;\n        conn.await.expect(\"client\");\n    };\n    join(srv, client).await;\n}"}
{"code": "pub fn get_size(&self) -> (usize, usize) {\n        (self.height(), self.width())\n    }", "test": "fn issue_195() {\n    setup();\n\n    let path = format!(\n        \"{}/JLCPCB SMT Parts Library(20210204).xls\",\n        env!(\"CARGO_MANIFEST_DIR\")\n    );\n    let mut excel: Xls<_> = open_workbook(&path).expect(\"can't open wb\");\n    let range = excel\n        .worksheet_range(\"JLCPCB SMT Parts Library\")\n        .expect(\"error in wks range\")\n        .expect(\"sheet not found\");\n    assert_eq!(range.get_size(), (52046, 12));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn files_max_size_parse_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--files-max-size=-1\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"files_max_size_parse_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_failing_omitting_directory() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file1 = \"file1\";\n    let dir1 = \"dir1\";\n    let no_dir2 = \"no-dir2\";\n    let dir3 = \"dir3\";\n\n    at.mkdir(dir1);\n    at.mkdir(dir3);\n    at.touch(file1);\n\n    // GNU install checks for existing target dir first before checking on source params\n    scene\n        .ucmd()\n        .arg(file1)\n        .arg(dir1)\n        .arg(no_dir2)\n        .fails()\n        .stderr_contains(\"is not a directory\");\n\n    // file1 will be copied before install fails on dir1\n    scene\n        .ucmd()\n        .arg(file1)\n        .arg(dir1)\n        .arg(dir3)\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"omitting directory\");\n    assert!(at.file_exists(format!(\"{dir3}/{file1}\")));\n\n    // install also fails, when only one source param is given\n    scene\n        .ucmd()\n        .arg(dir1)\n        .arg(dir3)\n        .fails()\n        .code_is(1)\n        .stderr_contains(\"omitting directory\");\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn f32_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u8, f32> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(&0, &0.3).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert_eq!(0.3, table.get(&0).unwrap().unwrap().value());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_demotion_reentrancy() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[2]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    {\n        let put = new_put_cmd(b\"k2\", b\"v2\");\n        let req = new_request(\n            region.get_id(),\n            region.get_region_epoch().clone(),\n            vec![put],\n            true,\n        );\n        // marjority is lost, can't propose command successfully.\n        cluster\n            .call_command_on_leader(req, Duration::from_millis(10))\n            .unwrap_err();\n    }\n\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    // Construct recovery plan.\n    let mut plan = pdpb::RecoveryPlan::default();\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n\n    // Blocks the raft apply process on store 1 entirely .\n    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"on_handle_apply_store_1\", move || {\n        let _ = apply_released_rx.recv();\n    })\n    .unwrap();\n\n    // Triggers the unsafe recovery plan execution.\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // No store report is sent, since there are peers have unapplied entries.\n    for _ in 0..10 {\n        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);\n        sleep_ms(100);\n    }\n\n    // Send the plan again.\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // Unblocks the apply process.\n    drop(apply_released_tx);\n\n    let mut demoted = false;\n    for _ in 0..10 {\n        let region_in_pd = block_on(pd_client.get_region_by_id(region.get_id()))\n            .unwrap()\n            .unwrap();\n        assert_eq!(region_in_pd.get_peers().len(), 3);\n        demoted = region_in_pd\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        sleep_ms(100);\n    }\n    assert_eq!(demoted, true);\n    fail::remove(\"on_handle_apply_store_1\");\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_lookup() {\n    let authority = create_example();\n    let mut catalog = Catalog::new();\n    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));\n\n    let io_loop = Runtime::new().unwrap();\n    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));\n    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());\n    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);\n\n    let (client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, false),\n    );\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        *lookup.iter().next().unwrap(),\n        RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_infinite_symlink_expansion_to_dirs() {\n    let fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"lint_rome_test_infinite_symlink_expansion_to_dirs\");\n    let subdir1_path = root_path.join(\"prefix\");\n    let subdir2_path = root_path.join(\"foo\").join(\"bar\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(&subdir1_path).unwrap();\n    create_dir_all(&subdir2_path).unwrap();\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(&subdir2_path, subdir1_path.join(\"symlink1\")).unwrap();\n        symlink(subdir1_path, subdir2_path.join(\"symlink2\")).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_dir(&subdir2_path, &subdir1_path.join(\"symlink1\")));\n        check_windows_symlink!(symlink_dir(subdir1_path, subdir2_path.join(\"symlink2\")));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"lint\"), (root_path.display().to_string().as_str())].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_infinite_symlink_expansion_to_dirs\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn name(&self) -> Option<&str> {\n        self.compiled_module().module().name.as_deref()\n    }", "test": "fn test_module_no_name() -> anyhow::Result<()> {\n    let engine = Engine::default();\n    let wat = r#\"\n        (module\n        (func (export \"run\") (nop))\n        )\n    \"#;\n\n    let module = Module::new(&engine, wat)?;\n    assert_eq!(module.name(), None);\n\n    Ok(())\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn add_set_values_in_context() {\n    let mut context = Context::new();\n    context.insert(\"my_var\", &\"hey\");\n    context.insert(\"malicious\", &\"<html>\");\n    context.insert(\"admin\", &true);\n    context.insert(\"num\", &1);\n\n    let inputs = vec![\n        (\"{% set i = 1 %}{{ i }}\", \"1\"),\n        (\"{% set i = 1 + 2 %}{{ i }}\", \"3\"),\n        (r#\"{% set i = \"hey\" %}{{ i }}\"#, \"hey\"),\n        (r#\"{% set i = \"<html>\" %}{{ i | safe }}\"#, \"<html>\"),\n        (r#\"{% set i = \"<html>\" %}{{ i }}\"#, \"&lt;html&gt;\"),\n        (\"{% set i = my_var %}{{ i }}\", \"hey\"),\n        (\"{% set i = malicious %}{{ i | safe }}\", \"<html>\"),\n        (\"{% set i = malicious %}{{ i }}\", \"&lt;html&gt;\"),\n        (\"{% set i = my_var | upper %}{{ i }}\", \"HEY\"),\n        (\"{% set i = range(end=3) %}{{ i }}\", \"[0, 1, 2]\"),\n        (\"{% set i = admin or true %}{{ i }}\", \"true\"),\n        (\"{% set i = admin and num > 0 %}{{ i }}\", \"true\"),\n        (\"{% set i = 0 / 0 %}{{ i }}\", \"NaN\"),\n        (\"{% set i = [1,2] %}{{ i }}\", \"[1, 2]\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn get_attr(&self, key: &str) -> Result<Value, Error> {\n        Ok(match self.0 {\n            ValueRepr::Undefined => return Err(Error::from(ErrorKind::UndefinedError)),\n            ValueRepr::Map(ref items, _) => items.get(&KeyRef::Str(key)).cloned(),\n            ValueRepr::Dynamic(ref dy) => match dy.kind() {\n                ObjectKind::Struct(s) => s.get_field(key),\n                ObjectKind::Plain | ObjectKind::Seq(_) => None,\n            },\n            _ => None,\n        }\n        .unwrap_or(Value::UNDEFINED))\n    }", "test": "fn test_context_merge() {\n    let one = context!(a => 1);\n    let two = context!(b => 2, a => 42);\n    let ctx = context![..one, ..two];\n    assert_eq!(ctx.get_attr(\"a\").unwrap(), Value::from(1));\n    assert_eq!(ctx.get_attr(\"b\").unwrap(), Value::from(2));\n\n    let two = context!(b => 2, a => 42);\n    let ctx = context!(a => 1, ..two);\n    assert_eq!(ctx.get_attr(\"a\").unwrap(), Value::from(1));\n    assert_eq!(ctx.get_attr(\"b\").unwrap(), Value::from(2));\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_only_owner() {\n    // test chown username file.txt\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    let file1 = \"test_chown_file1\";\n    at.touch(file1);\n\n    // since only superuser can change owner, we have to change from ourself to ourself\n    let result = scene\n        .ucmd()\n        .arg(user_name)\n        .arg(\"--verbose\")\n        .arg(file1)\n        .run();\n    result.stderr_contains(\"retained as\");\n\n    // try to change to another existing user, e.g. 'root'\n    scene\n        .ucmd()\n        .arg(\"root\")\n        .arg(\"--verbose\")\n        .arg(file1)\n        .fails()\n        .stderr_contains(\"failed to change\");\n}"}
{"code": "fn nothing(i: Partial<&[u8]>) -> IResult<Partial<&[u8]>, &[u8]> {\n        take_till0(|_| true).parse_peek(i)\n    }", "test": "fn take_till0_issue() {\n    use winnow::token::take_till0;\n\n    fn nothing(i: Partial<&[u8]>) -> IResult<Partial<&[u8]>, &[u8]> {\n        take_till0(|_| true).parse_peek(i)\n    }\n\n    assert_eq!(\n        nothing(Partial::new(b\"\")),\n        Err(ErrMode::Incomplete(Needed::new(1)))\n    );\n    assert_eq!(\n        nothing(Partial::new(b\"abc\")),\n        Ok((Partial::new(&b\"abc\"[..]), &b\"\"[..]))\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_creating_leading_dirs() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let source = \"create_leading_test_file\";\n    let target = \"dir1/dir2/dir3/test_file\";\n\n    at.touch(source);\n\n    scene\n        .ucmd()\n        .arg(\"-D\")\n        .arg(source)\n        .arg(at.plus(target))\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(target));\n}"}
{"code": "fn get(&self, _: &[u8]) -> Option<&[u8]> {\n        None\n    }", "test": "fn test_check_need_gc() {\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n\n    let mut cfg = DbConfig::default();\n    cfg.defaultcf.disable_auto_compactions = true;\n    cfg.defaultcf.dynamic_level_bytes = false;\n    let dir = tempfile::TempDir::new().unwrap();\n    let builder = TestEngineBuilder::new().path(dir.path());\n    let engine = builder\n        .api_version(ApiVersion::V2)\n        .build_with_cfg(&cfg)\n        .unwrap();\n    let raw_engine = engine.get_rocksdb();\n    let mut gc_runner = TestGcRunner::new(0);\n\n    do_write(&engine, false, 5);\n\n    // Check init value\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        0\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        0\n    );\n\n    // TEST 1: If ratio_threshold < 1.0 || context.is_bottommost_level() is true,\n    // check_need_gc return true, call dofilter\n    gc_runner\n        .safe_point(TimeStamp::max().into_inner())\n        .gc_raw(&raw_engine);\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        1\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        0\n    );\n\n    // TEST 2: props.num_versions as f64 > props.num_rows as f64 * ratio_threshold\n    // return true.\n    do_write(&engine, false, 5);\n    engine.get_rocksdb().flush_cfs(&[], true).unwrap();\n\n    do_gc(&raw_engine, 2, &mut gc_runner, &dir);\n\n    do_write(&engine, false, 5);\n    engine.get_rocksdb().flush_cfs(&[], true).unwrap();\n\n    // Set ratio_threshold, let (props.num_versions as f64 > props.num_rows as\n    // f64 * ratio_threshold) return true\n    gc_runner.ratio_threshold = Option::Some(0.0f64);\n\n    // is_bottommost_level = false\n    do_gc(&raw_engine, 1, &mut gc_runner, &dir);\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        3\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        0\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_short_overwrite() {\n    // same as --update=older\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_cp_arg_update_short_overwrite_file1\";\n    let new = \"test_cp_arg_update_short_overwrite_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(new)\n        .arg(old)\n        .arg(\"-u\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(old), \"new content\\n\");\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn indent_style_parse_errors() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"--indent-style\"), (\"invalid\"), (\"file.js\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"indent_style_parse_errors\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn len(self) -> bool {\n        self.0 & 0x02 != 0\n    }", "test": "fn packet_splitting_not_necessary_after_higher_mtu_discovered() {\n    let _guard = subscribe();\n    let payload = vec![42; 1300];\n\n    let mut pair = Pair::default();\n    pair.mtu = 1500;\n\n    let (client_ch, _) = pair.connect();\n    pair.drive();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    pair.client_send(client_ch, s).write(&payload).unwrap();\n    pair.client.drive(pair.time, pair.server.addr);\n    assert_eq!(pair.client.outbound.len(), 1);\n\n    pair.drive_client();\n    assert_eq!(pair.server.inbound.len(), 1);\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_lookup_ipv4_like() {\n    let authority = create_ip_like_example();\n    let mut catalog = Catalog::new();\n    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));\n\n    let io_loop = Runtime::new().unwrap();\n    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));\n    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());\n\n    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);\n    let (client, bg) = io_loop.block_on(client).expect(\"client connect failed\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let lookup = LookupIpFuture::lookup(\n        vec![Name::from_str(\"1.2.3.4.example.com.\").unwrap()],\n        LookupIpStrategy::default(),\n        CachingClient::new(0, client, false),\n        Default::default(),\n        Some(Arc::new(Hosts::default())),\n        Some(RData::A(A::new(1, 2, 3, 4))),\n    );\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        lookup.iter().next().unwrap(),\n        Ipv4Addr::new(198, 51, 100, 35)\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_custom_backup_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_custom_backup_suffix_file_a\";\n    let file_b = \"test_mv_custom_backup_suffix_file_b\";\n    let suffix = \"super-suffix-of-the-century\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"-b\")\n        .arg(format!(\"--suffix={suffix}\"))\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}{suffix}\")));\n}"}
{"code": "pub fn name(&self) -> Option<&str> {\n        self.repr.name.as_deref()\n    }", "test": "fn test_error_info() {\n    let mut c = CodeGenerator::new(\"hello.html\", \"\");\n    c.set_line(1);\n    c.add(Instruction::EmitRaw(\"<h1>Hello</h1>\\n\"));\n    c.set_line(2);\n    c.add(Instruction::Lookup(\"a_string\"));\n    c.add(Instruction::Lookup(\"an_int\"));\n    c.add(Instruction::Add);\n\n    let mut ctx = std::collections::BTreeMap::new();\n    ctx.insert(\"a_string\", Value::from(\"foo\"));\n    ctx.insert(\"an_int\", Value::from(42));\n\n    let err = simple_eval(&c.finish().0, ctx).unwrap_err();\n    assert_eq!(err.name(), Some(\"hello.html\"));\n    assert_eq!(err.line(), Some(2));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_silently_accepts_presume_input_tty2() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_2 = \"test_rm_silently_accepts_presume_input_tty2\";\n\n    at.touch(file_2);\n\n    ucmd.arg(\"---presume-input-tty\").arg(file_2).succeeds();\n\n    assert!(!at.file_exists(file_2));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn simple() -> Result<()> {\n    let component = r#\"\n        (component\n            (import \"a\" (func $log (param \"a\" string)))\n\n            (core module $libc\n                (memory (export \"memory\") 1)\n\n                (func (export \"realloc\") (param i32 i32 i32 i32) (result i32)\n                    unreachable)\n            )\n            (core instance $libc (instantiate $libc))\n            (core func $log_lower\n                (canon lower (func $log) (memory $libc \"memory\") (realloc (func $libc \"realloc\")))\n            )\n            (core module $m\n                (import \"libc\" \"memory\" (memory 1))\n                (import \"host\" \"log\" (func $log (param i32 i32)))\n\n                (func (export \"call\")\n                    i32.const 5\n                    i32.const 11\n                    call $log)\n\n                (data (i32.const 5) \"hello world\")\n            )\n            (core instance $i (instantiate $m\n                (with \"libc\" (instance $libc))\n                (with \"host\" (instance (export \"log\" (func $log_lower))))\n            ))\n            (func (export \"call\")\n                (canon lift (core func $i \"call\"))\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, None);\n    assert!(store.data().is_none());\n\n    // First, test the static API\n\n    let mut linker = Linker::new(&engine);\n    linker.root().func_wrap(\n        \"a\",\n        |mut store: StoreContextMut<'_, Option<String>>, (arg,): (WasmStr,)| -> Result<_> {\n            let s = arg.to_str(&store)?.to_string();\n            assert!(store.data().is_none());\n            *store.data_mut() = Some(s);\n            Ok(())\n        },\n    )?;\n    let instance = linker.instantiate(&mut store, &component)?;\n    instance\n        .get_typed_func::<(), ()>(&mut store, \"call\")?\n        .call(&mut store, ())?;\n    assert_eq!(store.data().as_ref().unwrap(), \"hello world\");\n\n    // Next, test the dynamic API\n\n    *store.data_mut() = None;\n    let mut linker = Linker::new(&engine);\n    linker.root().func_new(\n        &component,\n        \"a\",\n        |mut store: StoreContextMut<'_, Option<String>>, args, _results| {\n            if let Val::String(s) = &args[0] {\n                assert!(store.data().is_none());\n                *store.data_mut() = Some(s.to_string());\n                Ok(())\n            } else {\n                panic!()\n            }\n        },\n    )?;\n    let instance = linker.instantiate(&mut store, &component)?;\n    instance\n        .get_func(&mut store, \"call\")\n        .unwrap()\n        .call(&mut store, &[], &mut [])?;\n    assert_eq!(store.data().as_ref().unwrap(), \"hello world\");\n\n    Ok(())\n}"}
{"code": "pub fn last(&self) -> Option<&V> {\n        self.elems.last()\n    }", "test": "fn trapping() -> Result<(), Error> {\n    const TRAP_IN_F: i32 = 0;\n    const TRAP_NEXT_CALL_HOST: i32 = 1;\n    const TRAP_NEXT_RETURN_HOST: i32 = 2;\n    const TRAP_NEXT_CALL_WASM: i32 = 3;\n    const TRAP_NEXT_RETURN_WASM: i32 = 4;\n\n    let engine = Engine::default();\n\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\n        \"host\",\n        \"f\",\n        |mut caller: Caller<State>, action: i32, recur: i32| -> Result<()> {\n            assert_eq!(caller.data().context.last(), Some(&Context::Host));\n            assert_eq!(caller.data().calls_into_host, caller.data().calls_into_wasm);\n\n            match action {\n                TRAP_IN_F => bail!(\"trapping in f\"),\n                TRAP_NEXT_CALL_HOST => caller.data_mut().trap_next_call_host = true,\n                TRAP_NEXT_RETURN_HOST => caller.data_mut().trap_next_return_host = true,\n                TRAP_NEXT_CALL_WASM => caller.data_mut().trap_next_call_wasm = true,\n                TRAP_NEXT_RETURN_WASM => caller.data_mut().trap_next_return_wasm = true,\n                _ => {} // Do nothing\n            }\n\n            // recur so that we can trigger a next call.\n            // propogate its trap, if it traps!\n            if recur > 0 {\n                let _ = caller\n                    .get_export(\"export\")\n                    .expect(\"caller exports \\\"export\\\"\")\n                    .into_func()\n                    .expect(\"export is a func\")\n                    .typed::<(i32, i32), ()>(&caller)\n                    .expect(\"export typing\")\n                    .call(&mut caller, (action, 0))?;\n            }\n\n            Ok(())\n        },\n    )?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32) (param i32)))\n            (func (export \"export\") (param i32) (param i32)\n                (call $f (local.get 0) (local.get 1)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let run = |action: i32, recur: bool| -> (State, Option<Error>) {\n        let mut store = Store::new(&engine, State::default());\n        store.call_hook(State::call_hook);\n        let inst = linker\n            .instantiate(&mut store, &module)\n            .expect(\"instantiate\");\n        let export = inst\n            .get_export(&mut store, \"export\")\n            .expect(\"get export\")\n            .into_func()\n            .expect(\"export is func\");\n\n        let r = export.call(\n            &mut store,\n            &[Val::I32(action), Val::I32(if recur { 1 } else { 0 })],\n            &mut [],\n        );\n        (store.into_data(), r.err())\n    };\n\n    let (s, e) = run(TRAP_IN_F, false);\n    assert!(format!(\"{:?}\", e.unwrap()).contains(\"trapping in f\"));\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 1);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    // trap in next call to host. No calls after the bit is set, so this trap shouldn't happen\n    let (s, e) = run(TRAP_NEXT_CALL_HOST, false);\n    assert!(e.is_none());\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 1);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    // trap in next call to host. recur, so the second call into host traps:\n    let (s, e) = run(TRAP_NEXT_CALL_HOST, true);\n    assert!(format!(\"{:?}\", e.unwrap()).contains(\"call_hook: trapping on CallingHost\"));\n    assert_eq!(s.calls_into_host, 2);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 2);\n    assert_eq!(s.returns_from_wasm, 2);\n\n    // trap in the return from host. should trap right away, without recursion\n    let (s, e) = run(TRAP_NEXT_RETURN_HOST, false);\n    assert!(format!(\"{:?}\", e.unwrap()).contains(\"call_hook: trapping on ReturningFromHost\"));\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 1);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    // trap in next call to wasm. No calls after the bit is set, so this trap shouldnt happen:\n    let (s, e) = run(TRAP_NEXT_CALL_WASM, false);\n    assert!(e.is_none());\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 1);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    // trap in next call to wasm. recur, so the second call into wasm traps:\n    let (s, e) = run(TRAP_NEXT_CALL_WASM, true);\n    assert!(format!(\"{:?}\", e.unwrap()).contains(\"call_hook: trapping on CallingWasm\"));\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 2);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    // trap in the return from wasm. should trap right away, without recursion\n    let (s, e) = run(TRAP_NEXT_RETURN_WASM, false);\n    assert!(format!(\"{:?}\", e.unwrap()).contains(\"call_hook: trapping on ReturningFromWasm\"));\n    assert_eq!(s.calls_into_host, 1);\n    assert_eq!(s.returns_from_host, 1);\n    assert_eq!(s.calls_into_wasm, 1);\n    assert_eq!(s.returns_from_wasm, 1);\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"target_dir\";\n    let file1 = \"source_file1\";\n    let file2 = \"source_file2\";\n\n    at.touch(file1);\n    at.touch(file2);\n    at.mkdir(dir);\n    ucmd.arg(file1)\n        .arg(file2)\n        .arg(&format!(\"--target-directory={dir}\"))\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n    assert!(at.file_exists(format!(\"{dir}/{file1}\")));\n    assert!(at.file_exists(format!(\"{dir}/{file2}\")));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_interactive_never() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_2 = \"test_rm_interactive\";\n\n    at.touch(file_2);\n    #[cfg(feature = \"chmod\")]\n    scene.ccmd(\"chmod\").arg(\"0\").arg(file_2).succeeds();\n\n    scene\n        .ucmd()\n        .arg(\"--interactive=never\")\n        .arg(file_2)\n        .succeeds()\n        .stdout_is(\"\");\n\n    assert!(!at.file_exists(file_2));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_line_bytes_no_final_newline() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-C\", \"2\"])\n        .pipe_in(\"1\\n2222\\n3\\n4\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n\");\n    assert_eq!(at.read(\"xab\"), \"22\");\n    assert_eq!(at.read(\"xac\"), \"22\");\n    assert_eq!(at.read(\"xad\"), \"\\n\");\n    assert_eq!(at.read(\"xae\"), \"3\\n\");\n    assert_eq!(at.read(\"xaf\"), \"4\");\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_line_bytes_concatenated_with_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-C8\", \"letters.txt\"]).succeeds();\n    assert_eq!(at.read(\"xaa\"), \"aaaaaaaa\");\n    assert_eq!(at.read(\"xab\"), \"a\\nbbbb\\n\");\n    assert_eq!(at.read(\"xac\"), \"cccc\\ndd\\n\");\n    assert_eq!(at.read(\"xad\"), \"ee\\n\");\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_allow_empty_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"a\");\n    assert_eq!(at.read(\"xab\"), \"b\");\n    assert_eq!(at.read(\"xac\"), \"c\");\n    assert_eq!(at.read(\"xad\"), \"\");\n}"}
{"code": "fn get_cluster_id(&self) -> Result<u64> {\n        Ok(self.cluster_id)\n    }", "test": "fn test_rpc_client() {\n    let eps_count = 1;\n    let server = MockServer::new(eps_count);\n    let eps = server.bind_addrs();\n\n    let client = new_client(eps.clone(), None);\n    assert_ne!(client.get_cluster_id().unwrap(), 0);\n\n    let store_id = client.alloc_id().unwrap();\n    let mut store = metapb::Store::default();\n    store.set_id(store_id);\n    debug!(\"bootstrap store {:?}\", store);\n\n    let peer_id = client.alloc_id().unwrap();\n    let mut peer = metapb::Peer::default();\n    peer.set_id(peer_id);\n    peer.set_store_id(store_id);\n\n    let region_id = client.alloc_id().unwrap();\n    let mut region = metapb::Region::default();\n    region.set_id(region_id);\n    region.mut_peers().push(peer.clone());\n    debug!(\"bootstrap region {:?}\", region);\n\n    client\n        .bootstrap_cluster(store.clone(), region.clone())\n        .unwrap();\n    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);\n\n    let tmp_stores = client.get_all_stores(false).unwrap();\n    assert_eq!(tmp_stores.len(), 1);\n    assert_eq!(tmp_stores[0], store);\n\n    let tmp_store = client.get_store(store_id).unwrap();\n    assert_eq!(tmp_store.get_id(), store.get_id());\n\n    let region_key = region.get_start_key();\n    let tmp_region = client.get_region(region_key).unwrap();\n    assert_eq!(tmp_region.get_id(), region.get_id());\n\n    let region_info = client.get_region_info(region_key).unwrap();\n    assert_eq!(region_info.region, region);\n    assert_eq!(region_info.leader, None);\n\n    let tmp_region = block_on(client.get_region_by_id(region_id))\n        .unwrap()\n        .unwrap();\n    assert_eq!(tmp_region.get_id(), region.get_id());\n\n    let ts = block_on(client.get_tso()).unwrap();\n    assert_ne!(ts, TimeStamp::zero());\n\n    let ts100 = block_on(client.batch_get_tso(100)).unwrap();\n    assert_eq!(ts.logical() + 100, ts100.logical());\n\n    let mut prev_id = 0;\n    for _ in 0..100 {\n        let client = new_client(eps.clone(), None);\n        let alloc_id = client.alloc_id().unwrap();\n        assert!(alloc_id > prev_id);\n        prev_id = alloc_id;\n    }\n\n    let poller = Builder::new_multi_thread()\n        .thread_name(thd_name!(\"poller\"))\n        .worker_threads(1)\n        .build()\n        .unwrap();\n    let (tx, rx) = mpsc::channel();\n    let f = client.handle_region_heartbeat_response(1, move |resp| {\n        let _ = tx.send(resp);\n    });\n    poller.spawn(f);\n    poller.spawn(client.region_heartbeat(\n        store::RAFT_INIT_LOG_TERM,\n        region.clone(),\n        peer.clone(),\n        RegionStat::default(),\n        None,\n    ));\n    rx.recv_timeout(Duration::from_secs(3)).unwrap();\n\n    let region_info = client.get_region_info(region_key).unwrap();\n    assert_eq!(region_info.region, region);\n    assert_eq!(region_info.leader.unwrap(), peer);\n\n    block_on(client.store_heartbeat(\n        pdpb::StoreStats::default(),\n        None, // store_report\n        None,\n    ))\n    .unwrap();\n    block_on(client.ask_batch_split(metapb::Region::default(), 1)).unwrap();\n    block_on(client.report_batch_split(vec![metapb::Region::default(), metapb::Region::default()]))\n        .unwrap();\n\n    let region_info = client.get_region_info(region_key).unwrap();\n    client.scatter_region(region_info).unwrap();\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_inodes_basic() {\n    let ts = TestScenario::new(util_name!());\n    let result = ts.ucmd().arg(\"--inodes\").succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[\"--inodes\"]));\n        assert_eq!(result.stdout_str(), result_reference.stdout_str());\n    }\n\n    #[cfg(not(any(target_os = \"linux\", target_os = \"android\")))]\n    _du_inodes_basic(result.stdout_str());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.entries.len()\n    }", "test": "fn test_auto_gc() {\n    let count = 3;\n    let (mut cluster, first_leader_storage, ctx) =\n        new_raft_storage_with_store_count::<ApiV1>(count, \"\");\n    let pd_client = Arc::clone(&cluster.pd_client);\n\n    // Used to wait for all storage's GC to finish\n    let (finish_signal_tx, finish_signal_rx) = channel();\n\n    // Create storage object for each store in the cluster\n    let mut storages: HashMap<_, _> = cluster\n        .sim\n        .rl()\n        .storages\n        .iter()\n        .map(|(id, engine)| {\n            let mut config = GcConfig::default();\n            // Do not skip GC\n            config.ratio_threshold = 0.9;\n            let storage = SyncTestStorageBuilderApiV1::from_engine(engine.clone())\n                .gc_config(config)\n                .build(*id)\n                .unwrap();\n\n            (*id, storage)\n        })\n        .collect();\n\n    let mut region_info_accessors = cluster.sim.rl().region_info_accessors.clone();\n\n    for (id, storage) in &mut storages {\n        let tx = finish_signal_tx.clone();\n\n        let mut cfg = AutoGcConfig::new_test_cfg(\n            Arc::clone(&pd_client),\n            region_info_accessors.remove(id).unwrap(),\n            *id,\n        );\n        cfg.post_a_round_of_gc = Some(Box::new(move || tx.send(()).unwrap()));\n\n        storage.start_auto_gc(cfg);\n    }\n\n    assert_eq!(storages.len(), count);\n\n    // test_data will be wrote with ts < 50\n    let test_data: Vec<_> = [\n        (b\"k1\", b\"v1\"),\n        (b\"k2\", b\"v2\"),\n        (b\"k3\", b\"v3\"),\n        (b\"k4\", b\"v4\"),\n        (b\"k5\", b\"v5\"),\n        (b\"k6\", b\"v6\"),\n        (b\"k7\", b\"v7\"),\n        (b\"k8\", b\"v8\"),\n        (b\"k9\", b\"v9\"),\n    ]\n    .iter()\n    .map(|(k, v)| (k.to_vec(), v.to_vec()))\n    .collect();\n\n    let test_data2: Vec<_> = test_data\n        .iter()\n        .map(|(k, v)| {\n            let mut v = v.to_vec();\n            v.push(b'1');\n            (k.to_vec(), v)\n        })\n        .collect();\n\n    let test_data3: Vec<_> = test_data\n        .iter()\n        .map(|(k, v)| {\n            let mut v = v.to_vec();\n            v.push(b'2');\n            (k.to_vec(), v)\n        })\n        .collect();\n\n    write_test_data(&first_leader_storage, &ctx, &test_data, 10);\n    write_test_data(&first_leader_storage, &ctx, &test_data2, 100);\n    write_test_data(&first_leader_storage, &ctx, &test_data3, 200);\n\n    let split_keys: &[&[u8]] = &[b\"k2\", b\"k4\", b\"k6\", b\"k8\"];\n\n    for k in split_keys {\n        let region = cluster.get_region(k);\n        cluster.must_split(&region, k);\n    }\n\n    check_data(&mut cluster, &storages, &test_data, 50, true);\n    check_data(&mut cluster, &storages, &test_data2, 150, true);\n    check_data(&mut cluster, &storages, &test_data3, 250, true);\n\n    pd_client.set_gc_safe_point(150);\n\n    for _ in 0..count {\n        finish_signal_rx.recv().unwrap();\n    }\n\n    check_data(&mut cluster, &storages, &test_data, 50, false);\n    check_data(&mut cluster, &storages, &test_data2, 150, true);\n    check_data(&mut cluster, &storages, &test_data3, 250, true);\n\n    // No more signals.\n    finish_signal_rx\n        .recv_timeout(Duration::from_millis(300))\n        .unwrap_err();\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn send_recv_headers_only() {\n    h2_support::trace_init!();\n\n    let mock = mock_io::Builder::new()\n        .handshake()\n        // Write GET /\n        .write(&[\n            0, 0, 0x10, 1, 5, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,\n            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84,\n        ])\n        .write(frames::SETTINGS_ACK)\n        // Read response\n        .read(&[0, 0, 1, 1, 5, 0, 0, 0, 1, 0x89])\n        .build();\n\n    let (mut client, mut h2) = client::handshake(mock).await.unwrap();\n\n    // Send the request\n    let request = Request::builder()\n        .uri(\"https://http2.akamai.com/\")\n        .body(())\n        .unwrap();\n\n    tracing::info!(\"sending request\");\n    let (response, _) = client.send_request(request, true).unwrap();\n\n    let resp = h2.run(response).await.unwrap();\n    assert_eq!(resp.status(), StatusCode::NO_CONTENT);\n\n    h2.await.unwrap();\n}"}
{"code": "pub(super) fn expect<K>(\n        &mut self,\n        kind: K,\n        context: &'static str,\n        interner: &mut Interner,\n    ) -> ParseResult<Token>\n    where\n        K: Into<TokenKind>,\n    {\n        let next_token = self.next(interner).or_abrupt()?;\n        let kind = kind.into();\n\n        if next_token.kind() == &kind {\n            Ok(next_token)\n        } else {\n            Err(Error::expected(\n                [kind.to_string(interner)],\n                next_token.to_string(interner),\n                next_token.span(),\n                context,\n            ))\n        }\n    }", "test": "fn eph_ephemeron_test() {\n    run_test(|| {\n        let gc_value = Gc::new(3);\n\n        {\n            let cloned_gc = gc_value.clone();\n\n            let ephemeron = Ephemeron::new(&cloned_gc, String::from(\"Hello World!\"));\n\n            assert_eq!(\n                *ephemeron.value().expect(\"Ephemeron is live\"),\n                String::from(\"Hello World!\")\n            );\n            drop(cloned_gc);\n            force_collect();\n            assert_eq!(\n                *ephemeron.value().expect(\"Ephemeron is still live here\"),\n                String::from(\"Hello World!\")\n            );\n\n            drop(gc_value);\n            force_collect();\n\n            assert!(ephemeron.value().is_none());\n        }\n    });\n}"}
{"code": "pub fn has_value(&self) -> bool {\n        // SAFETY: this is safe because `Ephemeron` is tracked to always point to a valid pointer\n        // `inner_ptr`.\n        unsafe { self.inner_ptr.get().as_ref().value().is_some() }\n    }", "test": "fn eph_finalizer() {\n    #[derive(Clone, Trace)]\n    struct S {\n        #[unsafe_ignore_trace]\n        inner: Rc<Cell<bool>>,\n    }\n\n    impl Finalize for S {\n        fn finalize(&self) {\n            self.inner.set(true);\n        }\n    }\n\n    run_test(|| {\n        let val = S {\n            inner: Rc::new(Cell::new(false)),\n        };\n\n        let key = Gc::new(50u32);\n        let eph = Ephemeron::new(&key, Gc::new(val.clone()));\n        assert!(eph.has_value());\n        // finalize hasn't been run\n        assert!(!val.inner.get());\n\n        drop(key);\n        force_collect();\n        assert!(!eph.has_value());\n        // finalize ran when collecting\n        assert!(val.inner.get());\n    });\n}"}
{"code": "pub fn get_state(&self) -> Arc<AtomicCell<DownstreamState>> {\n        self.state.clone()\n    }", "test": "fn test_stale_learner() {\n    let mut cluster = new_server_cluster(0, 4);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::millis(150);\n    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::millis(100);\n    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::millis(100);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n    pd_client.must_add_peer(r1, new_learner_peer(3, 3));\n    cluster.must_put(b\"k1\", b\"v1\");\n    let engine3 = cluster.get_engine(3);\n    must_get_equal(&engine3, b\"k1\", b\"v1\");\n\n    // And then isolate peer on store 3 from leader.\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n\n    // Add a new peer to increase the conf version.\n    pd_client.must_add_peer(r1, new_peer(4, 4));\n\n    // It should not be deleted.\n    thread::sleep(Duration::from_millis(200));\n    must_get_equal(&engine3, b\"k1\", b\"v1\");\n\n    // Promote the learner\n    pd_client.must_add_peer(r1, new_peer(3, 3));\n\n    // It should not be deleted.\n    thread::sleep(Duration::from_millis(200));\n    must_get_equal(&engine3, b\"k1\", b\"v1\");\n\n    // Delete the learner\n    pd_client.must_remove_peer(r1, new_peer(3, 3));\n\n    // Check not leader should fail, all data should be removed.\n    must_get_none(&engine3, b\"k1\");\n    let state_key = keys::region_state_key(r1);\n    let state: RegionLocalState = engine3.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();\n    assert_eq!(state.get_state(), PeerState::Tombstone);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_numbered_with_t() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=t\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}.~1~\")));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn get_set_externref_globals_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    // Initialize with a null externref.\n\n    let global = Global::new(\n        &mut store,\n        GlobalType::new(ValType::ExternRef, Mutability::Var),\n        Val::ExternRef(None),\n    )?;\n    assert!(global.get(&mut store).unwrap_externref().is_none());\n\n    global.set(\n        &mut store,\n        Val::ExternRef(Some(ExternRef::new(\"hello\".to_string()))),\n    )?;\n    let r = global.get(&mut store).unwrap_externref().unwrap();\n    assert!(r.data().is::<String>());\n    assert_eq!(r.data().downcast_ref::<String>().unwrap(), \"hello\");\n\n    // Initialize with a non-null externref.\n\n    let global = Global::new(\n        &mut store,\n        GlobalType::new(ValType::ExternRef, Mutability::Const),\n        Val::ExternRef(Some(ExternRef::new(42_i32))),\n    )?;\n    let r = global.get(&mut store).unwrap_externref().unwrap();\n    assert!(r.data().is::<i32>());\n    assert_eq!(r.data().downcast_ref::<i32>().copied().unwrap(), 42);\n\n    Ok(())\n}"}
{"code": "pub fn do_handshake_until_error(\n    client: &mut ClientConnection,\n    server: &mut ServerConnection,\n) -> Result<(), ErrorFromPeer> {\n    while server.is_handshaking() || client.is_handshaking() {\n        transfer(client, server);\n        server\n            .process_new_packets()\n            .map_err(ErrorFromPeer::Server)?;\n        transfer(server, client);\n        client\n            .process_new_packets()\n            .map_err(ErrorFromPeer::Client)?;\n    }\n\n    Ok(())\n}", "test": "fn client_cert_resolve() {\n    for kt in ALL_KEY_TYPES.iter() {\n        let server_config = Arc::new(make_server_config_with_mandatory_client_auth(*kt));\n\n        let expected_issuers = match *kt {\n            KeyType::Rsa => vec![\n                b\"0,1*0(\\x06\\x03U\\x04\\x03\\x0c!ponytown RSA level 2 intermediate\".to_vec(),\n                b\"0\\x1a1\\x180\\x16\\x06\\x03U\\x04\\x03\\x0c\\x0fponytown RSA CA\".to_vec(),\n            ],\n            KeyType::Ecdsa => vec![\n                b\"0.1,0*\\x06\\x03U\\x04\\x03\\x0c#ponytown ECDSA level 2 intermediate\".to_vec(),\n                b\"0\\x1c1\\x1a0\\x18\\x06\\x03U\\x04\\x03\\x0c\\x11ponytown ECDSA CA\".to_vec(),\n            ],\n            KeyType::Ed25519 => vec![\n                b\"0.1,0*\\x06\\x03U\\x04\\x03\\x0c#ponytown EdDSA level 2 intermediate\".to_vec(),\n                b\"0\\x1c1\\x1a0\\x18\\x06\\x03U\\x04\\x03\\x0c\\x11ponytown EdDSA CA\".to_vec(),\n            ],\n        };\n\n        for version in rustls::ALL_VERSIONS {\n            let expected_sigschemes = match version.version {\n                ProtocolVersion::TLSv1_2 => vec![\n                    SignatureScheme::ECDSA_NISTP384_SHA384,\n                    SignatureScheme::ECDSA_NISTP256_SHA256,\n                    SignatureScheme::ED25519,\n                    SignatureScheme::RSA_PSS_SHA512,\n                    SignatureScheme::RSA_PSS_SHA384,\n                    SignatureScheme::RSA_PSS_SHA256,\n                    SignatureScheme::RSA_PKCS1_SHA512,\n                    SignatureScheme::RSA_PKCS1_SHA384,\n                    SignatureScheme::RSA_PKCS1_SHA256,\n                ],\n                ProtocolVersion::TLSv1_3 => vec![\n                    SignatureScheme::ECDSA_NISTP384_SHA384,\n                    SignatureScheme::ECDSA_NISTP256_SHA256,\n                    SignatureScheme::ED25519,\n                    SignatureScheme::RSA_PSS_SHA512,\n                    SignatureScheme::RSA_PSS_SHA384,\n                    SignatureScheme::RSA_PSS_SHA256,\n                ],\n                _ => unreachable!(),\n            };\n\n            println!(\"{:?} {:?}:\", version.version, *kt);\n\n            let mut client_config = make_client_config_with_versions(*kt, &[version]);\n            client_config.client_auth_cert_resolver = Arc::new(ClientCheckCertResolve::new(\n                1,\n                expected_issuers.clone(),\n                expected_sigschemes,\n            ));\n\n            let (mut client, mut server) =\n                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n\n            assert_eq!(\n                do_handshake_until_error(&mut client, &mut server),\n                Err(ErrorFromPeer::Server(Error::NoCertificatesPresented))\n            );\n        }\n    }\n}"}
{"code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_pessimistic_lock_check_valid() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let txn_ext = cluster\n        .must_get_snapshot_of_region(1)\n        .ext()\n        .get_txn_ext()\n        .unwrap()\n        .clone();\n\n    let region = cluster.get_region(b\"\");\n    let leader = region.get_peers()[0].clone();\n    fail::cfg(\"acquire_pessimistic_lock\", \"pause\").unwrap();\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n\n    let mut mutation = pb::Mutation::default();\n    mutation.set_op(Op::PessimisticLock);\n    mutation.key = b\"key\".to_vec();\n    let mut req = PessimisticLockRequest::default();\n    req.set_context(ctx.clone());\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(10);\n    req.set_for_update_ts(10);\n    req.set_primary_lock(b\"key\".to_vec());\n\n    let lock_resp = thread::spawn(move || client.kv_pessimistic_lock(&req).unwrap());\n    thread::sleep(Duration::from_millis(300));\n    // Set `status` to `TransferringLeader` to make the locks table not writable,\n    // but the region remains available to serve.\n    txn_ext.pessimistic_locks.write().status = LocksStatus::TransferringLeader;\n    fail::remove(\"acquire_pessimistic_lock\");\n\n    let resp = lock_resp.join().unwrap();\n    // There should be no region error.\n    assert!(!resp.has_region_error());\n    // The lock should not be written to the in-memory pessimistic lock table.\n    assert!(txn_ext.pessimistic_locks.read().is_empty());\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn owned_get_signatures() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u32, u32> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &(i + 1)).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n\n    assert_eq!(2, table.get(&1).unwrap().unwrap().value());\n\n    let mut iter: Range<u32, u32> = table.range::<u32>(..).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n    let mut iter: Range<u32, u32> = table.range(0..10).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n    let mut iter = table.range::<&u32>(&0..&10).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);\n    }\n    assert!(iter.next().is_none());\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn deflate_encoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::read::DeflateEncoder::new(original, flate2::Compression::default());\n    assert_eq!(encoder.read(&mut []).unwrap(), 0);\n    let mut encoded = Vec::new();\n    encoder.read_to_end(&mut encoded).unwrap();\n    let mut decoder = flate2::read::DeflateDecoder::new(encoded.as_slice());\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"code": "pub fn stored_bytes(&self) -> u64 {\n        self.stored_leaf_bytes\n    }", "test": "fn efficient_storage() {\n    let tmpfile = create_tempfile();\n    let expected_max_size = 1024 * 1024;\n    // Write enough values that big_key.len() * entries > db_size to check that duplicate key data is not stored\n    // and entries * sizeof(u32) > page_size to validate that large numbers of values can be stored per key\n    let entries = 10000;\n    let db = Database::create(tmpfile.path()).unwrap();\n    let table_def: MultimapTableDefinition<&[u8], u32> = MultimapTableDefinition::new(\"x\");\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(table_def).unwrap();\n        let big_key = [0u8; 1000];\n        for i in 0..entries {\n            table.insert(big_key.as_slice(), &i).unwrap();\n        }\n    }\n    assert!(write_txn.stats().unwrap().stored_bytes() <= expected_max_size);\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(table_def).unwrap();\n    assert_eq!(table.len().unwrap(), entries as u64);\n}"}
{"code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn can_remove_whitespace_inheritance() {\n    let mut context = Context::new();\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n\n    let inputs = vec![\n        (r#\"{%- extends \"base\" -%} {% block content %}{{super()}}{% endblock %}\"#, \" Hey! \"),\n        (r#\"{%- extends \"base\" -%} {% block content -%}{{super()}}{%- endblock %}\"#, \" Hey! \"),\n        (r#\"{%- extends \"base\" %} {%- block content -%}{{super()}}{%- endblock -%} \"#, \" Hey! \"),\n    ];\n\n    for (input, expected) in inputs {\n        let mut tera = Tera::default();\n        tera.add_raw_templates(vec![\n            (\"base\", \"{% block content %} Hey! {% endblock %}\"),\n            (\"tpl\", input),\n        ])\n        .unwrap();\n        assert_eq!(tera.render(\"tpl\", &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn metadata(&self, path: &str) -> fs::Metadata {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn test_cp_parents_with_permissions_copy_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir = \"dir\";\n    let file = \"p1/p2/file\";\n\n    at.mkdir(dir);\n    at.mkdir_all(\"p1/p2\");\n    at.touch(file);\n\n    #[cfg(unix)]\n    {\n        let p1_mode = 0o0777;\n        let p2_mode = 0o0711;\n        let file_mode = 0o0702;\n\n        at.set_mode(\"p1\", p1_mode);\n        at.set_mode(\"p1/p2\", p2_mode);\n        at.set_mode(file, file_mode);\n    }\n\n    ucmd.arg(\"-p\")\n        .arg(\"--parents\")\n        .arg(file)\n        .arg(dir)\n        .succeeds();\n\n    #[cfg(all(unix, not(target_os = \"freebsd\")))]\n    {\n        let p1_metadata = at.metadata(\"p1\");\n        let p2_metadata = at.metadata(\"p1/p2\");\n        let file_metadata = at.metadata(file);\n\n        assert_metadata_eq!(p1_metadata, at.metadata(\"dir/p1\"));\n        assert_metadata_eq!(p2_metadata, at.metadata(\"dir/p1/p2\"));\n        assert_metadata_eq!(file_metadata, at.metadata(\"dir/p1/p2/file\"));\n    }\n}"}
{"code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_reserve() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert_eq!(tv.capacity(), 4);\n  tv.extend_from_slice(&[1, 2]);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve(2);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve(4);\n  assert!(tv.capacity() >= 6);\n  tv.extend_from_slice(&[3, 4, 5, 6]);\n  tv.reserve(4);\n  assert!(tv.capacity() >= 10);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_if_linter_is_disabled() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"fix.js\");\n    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());\n\n    let config_path = Path::new(\"biome.json\");\n    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_if_linter_is_disabled\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn dtor_runs() {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let mut store = Store::<()>::default();\n    let a = A;\n    assert_eq!(HITS.load(SeqCst), 0);\n    Func::wrap(&mut store, move || {\n        let _ = &a;\n    });\n    drop(store);\n    assert_eq!(HITS.load(SeqCst), 1);\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn send_headers_recv_data_single_frame() {\n    h2_support::trace_init!();\n\n    let mock = mock_io::Builder::new()\n        .handshake()\n        // Write GET /\n        .write(&[\n            0, 0, 16, 1, 5, 0, 0, 0, 1, 130, 135, 65, 139, 157, 41, 172, 75, 143, 168, 233, 25,\n            151, 33, 233, 132,\n        ])\n        .write(frames::SETTINGS_ACK)\n        // Read response\n        .read(&[\n            0, 0, 1, 1, 4, 0, 0, 0, 1, 136, 0, 0, 5, 0, 0, 0, 0, 0, 1, 104, 101, 108, 108, 111, 0,\n            0, 5, 0, 1, 0, 0, 0, 1, 119, 111, 114, 108, 100,\n        ])\n        .build();\n\n    let (mut client, mut h2) = client::handshake(mock).await.unwrap();\n\n    // Send the request\n    let request = Request::builder()\n        .uri(\"https://http2.akamai.com/\")\n        .body(())\n        .unwrap();\n\n    tracing::info!(\"sending request\");\n    let (response, _) = client.send_request(request, true).unwrap();\n\n    let resp = h2.run(response).await.unwrap();\n    assert_eq!(resp.status(), StatusCode::OK);\n\n    // Take the body\n    let (_, body) = resp.into_parts();\n\n    // Wait for all the data frames to be received\n    let bytes: Vec<_> = h2.run(body.try_collect()).await.unwrap();\n\n    // Two data frames\n    assert_eq!(2, bytes.len());\n\n    assert_eq!(bytes[0], &b\"hello\"[..]);\n    assert_eq!(bytes[1], &b\"world\"[..]);\n\n    // The H2 connection is closed\n    h2.await.unwrap();\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn filter_args_are_not_escaped() {\n    let mut context = Context::new();\n    context.insert(\"my_var\", &\"hey\");\n    context.insert(\"to\", &\"&\");\n    let input = r#\"{{ my_var | replace(from=\"h\", to=to) }}\"#;\n\n    assert_eq!(render_template(input, &context).unwrap(), \"&amp;ey\");\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_invalid_range() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n    let mut req = new_analyze_index_req(&product, 3, product[\"name\"].index, 4, 32, 0, 1);\n    let mut key_range = KeyRange::default();\n    key_range.set_start(b\"xxx\".to_vec());\n    key_range.set_end(b\"zzz\".to_vec());\n    req.set_ranges(vec![key_range].into());\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_other_error().is_empty());\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_closing_bracket_in_single_quote_mixed() {\n    let mut r = Reader::from_str(r#\"<a attr='\">\"' check='\"2\"'></a>\"#);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Start(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"attr\"),\n                    value: Cow::Borrowed(br#\"\">\"\"#),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"check\"),\n                    value: Cow::Borrowed(br#\"\"2\"\"#),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        x => panic!(\"expected <a attr='>'>, got {:?}\", x),\n    }\n    next_eq!(r, End, b\"a\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_election_priority() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    // make sure logs are replicated to the witness\n    std::thread::sleep(Duration::from_millis(100));\n\n    for i in 1..10 {\n        let node = cluster.leader_of_region(region.get_id()).unwrap().store_id;\n        cluster.stop_node(node);\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n        // the witness can't be elected as the leader when there is no log gap\n        assert_ne!(\n            cluster.leader_of_region(region.get_id()).unwrap().store_id,\n            nodes[2],\n        );\n        cluster.run_node(node).unwrap();\n        // make sure logs are replicated to the restarted node\n        std::thread::sleep(Duration::from_millis(100));\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_3_others_a() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_3=value 3\".parse().unwrap());\n    headers.insert(VARY, \"*\".parse().unwrap());\n\n    assert_eq!(headers.len(), 6);\n\n    let cookie = remove_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookie, Some(\"cookie_1=value 1\".parse().unwrap()));\n    assert_eq!(headers.len(), 3);\n\n    let via = remove_values(&mut headers, VIA);\n    assert_eq!(via, Some(\"1.1 example.com\".parse().unwrap()));\n    assert_eq!(headers.len(), 1);\n\n    let vary = remove_values(&mut headers, VARY);\n    assert_eq!(vary, Some(\"*\".parse().unwrap()));\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn captures_len(&self) -> usize {\n        self.0.capture_names().len()\n    }", "test": "fn capture_names() {\n    let re = regex!(r\"(.)(?P<a>.)\");\n    assert_eq!(3, re.captures_len());\n    assert_eq!((3, Some(3)), re.capture_names().size_hint());\n    assert_eq!(vec![None, None, Some(\"a\")],\n               re.capture_names().collect::<Vec<_>>());\n}"}
{"code": "fn smallest_key(&self) -> &[u8] {\n        panic!()\n    }", "test": "fn other_external_sst_info() -> Result<()> {\n    let tempdir = tempdir();\n    let sst_path = tempdir\n        .path()\n        .join(\"test-data.sst\")\n        .to_string_lossy()\n        .to_string();\n    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();\n    let mut sst_writer = sst_builder.build(&sst_path)?;\n\n    sst_writer.put(b\"k1\", b\"v11\")?;\n    sst_writer.put(b\"k9\", b\"v9\")?;\n\n    let info = sst_writer.finish()?;\n\n    assert_eq!(b\"k1\", info.smallest_key());\n    assert_eq!(b\"k9\", info.largest_key());\n    assert_eq!(2, info.num_entries());\n\n    let size = fs::metadata(&sst_path).unwrap().len();\n\n    assert_eq!(size, info.file_size());\n\n    Ok(())\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn test_debug_region_info_v2() {\n    let (cluster, debug_client, store_id) = test_raftstore_v2::must_new_cluster_and_debug_client();\n\n    let raft_engine = cluster.get_raft_engine(store_id);\n    let region_id = 100;\n    let mut raft_state = raft_serverpb::RaftLocalState::default();\n    raft_state.set_last_index(42);\n    let mut lb = raft_engine.log_batch(10);\n    lb.put_raft_state(region_id, &raft_state).unwrap();\n\n    let mut apply_state = raft_serverpb::RaftApplyState::default();\n    apply_state.set_applied_index(42);\n    lb.put_apply_state(region_id, 42, &apply_state).unwrap();\n\n    let mut region_state = raft_serverpb::RegionLocalState::default();\n    region_state.set_state(raft_serverpb::PeerState::Tombstone);\n    lb.put_region_state(region_id, 42, &region_state).unwrap();\n\n    raft_engine.consume(&mut lb, false).unwrap();\n    assert_eq!(\n        raft_engine.get_raft_state(region_id).unwrap().unwrap(),\n        raft_state\n    );\n\n    assert_eq!(\n        raft_engine\n            .get_apply_state(region_id, u64::MAX)\n            .unwrap()\n            .unwrap(),\n        apply_state\n    );\n\n    assert_eq!(\n        raft_engine\n            .get_region_state(region_id, u64::MAX)\n            .unwrap()\n            .unwrap(),\n        region_state\n    );\n\n    // Debug region_info\n    let mut req = debugpb::RegionInfoRequest::default();\n    req.set_region_id(region_id);\n    let mut resp = debug_client.region_info(&req).unwrap();\n    assert_eq!(resp.take_raft_local_state(), raft_state);\n    assert_eq!(resp.take_raft_apply_state(), apply_state);\n    assert_eq!(resp.take_region_local_state(), region_state);\n\n    req.set_region_id(region_id + 1);\n    match debug_client.region_info(&req).unwrap_err() {\n        Error::RpcFailure(status) => {\n            assert_eq!(status.code(), RpcStatusCode::NOT_FOUND);\n        }\n        _ => panic!(\"expect NotFound\"),\n    }\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.inner.len() == 0\n    }", "test": "fn closed_immediately() {\n    let stream = \"/**/\".parse::<TokenStream>().unwrap();\n    let tokens = stream.into_iter().collect::<Vec<_>>();\n    assert!(tokens.is_empty(), \"not empty -- {:?}\", tokens);\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nl_number_l() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=l/3\", \"--separator=\\n\", \"fivelines.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\n2\\n\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\n4\\n\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\n\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn is_zero(&self) -> bool {\n        let len = word_cnt!(self.int_cnt) + word_cnt!(self.frac_cnt);\n        self.word_buf[0..len as usize].iter().all(|&x| x == 0)\n    }", "test": "fn test_max_commit_ts_error() {\n    let engine = TestEngineBuilder::new().build().unwrap();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .build()\n        .unwrap();\n    let cm = storage.get_concurrency_manager();\n\n    fail::cfg(\"after_prewrite_one_key\", \"sleep(500)\").unwrap();\n    let (prewrite_tx, prewrite_rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                vec![\n                    Mutation::make_put(Key::from_raw(b\"k1\"), b\"v\".to_vec()),\n                    Mutation::make_put(Key::from_raw(b\"k2\"), b\"v\".to_vec()),\n                ],\n                b\"k1\".to_vec(),\n                10.into(),\n                20000,\n                false,\n                2,\n                TimeStamp::default(),\n                100.into(),\n                Some(vec![b\"k2\".to_vec()]),\n                false,\n                AssertionLevel::Off,\n                Context::default(),\n            ),\n            Box::new(move |res| {\n                prewrite_tx.send(res).unwrap();\n            }),\n        )\n        .unwrap();\n    thread::sleep(Duration::from_millis(200));\n    cm.read_key_check(&Key::from_raw(b\"k1\"), |_| Err(()))\n        .unwrap_err();\n    cm.update_max_ts(200.into());\n\n    let res = prewrite_rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts.is_zero());\n    assert!(res.one_pc_commit_ts.is_zero());\n\n    // There should not be any memory lock left.\n    cm.read_range_check(None, None, |_, _| Err(())).unwrap();\n\n    // Two locks should be written, the second one does not async commit.\n    let l1 = must_locked(&mut storage.get_engine(), b\"k1\", 10);\n    let l2 = must_locked(&mut storage.get_engine(), b\"k2\", 10);\n    assert!(l1.use_async_commit);\n    assert!(!l2.use_async_commit);\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_empty_range() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"b\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.delete_range(b\"b\", b\"b\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &1_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_some());\n    for i in 0..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_no_clobber_inferred_arg() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"--no-clob\")\n        .fails();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"How are you?\\n\");\n}"}
{"code": "pub(super) fn len(&self) -> usize {\n            self.buffer.len()\n        }", "test": "fn test_server_no_response_on_response() {\n    let runtime = Runtime::new().expect(\"failed to create Tokio Runtime\");\n    let addr = SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(127, 0, 0, 1), 0));\n    let udp_socket = runtime.block_on(UdpSocket::bind(&addr)).unwrap();\n\n    let ipaddr = udp_socket.local_addr().unwrap();\n    println!(\"udp_socket on port: {}\", ipaddr);\n    let server_continue = Arc::new(AtomicBool::new(true));\n    let server_continue2 = server_continue.clone();\n\n    let server_thread = thread::Builder::new()\n        .name(\"test_server:udp:server\".to_string())\n        .spawn(move || server_thread_udp(runtime, udp_socket, server_continue2))\n        .unwrap();\n\n    let conn = UdpClientConnection::new(ipaddr).unwrap();\n    let client = SyncClient::new(conn);\n\n    // build the message\n    let query_a = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let mut message = Message::new();\n    message\n        .set_message_type(MessageType::Response)\n        .set_op_code(OpCode::Query)\n        .add_query(query_a);\n\n    let client_result = client.send(message);\n    assert_eq!(client_result.len(), 0);\n\n    server_continue.store(false, Ordering::Relaxed);\n    server_thread.join().unwrap();\n}"}
{"code": "fn kind(&self) -> ObjectKind<'_> {\n        Python::with_gil(|py| {\n            let inner = self.inner.as_ref(py);\n            if inner.downcast::<PySequence>().is_ok() || self.sequencified.is_some() {\n                ObjectKind::Seq(self)\n            } else {\n                ObjectKind::Struct(self)\n            }\n        })\n    }", "test": "fn test_strict_undefined() {\n    let mut env = Environment::new();\n    env.set_undefined_behavior(UndefinedBehavior::Strict);\n    env.add_filter(\"test\", |_state: &State, _value: String| -> String {\n        panic!(\"filter must not be called\");\n    });\n\n    assert_eq!(\n        env.render_str(\"{{ true.missing_attribute }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(\n        env.render_str(\"{{ undefined.missing_attribute }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(\n        env.render_str(\"<{% for x in undefined %}...{% endfor %}>\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(\n        env.render_str(\"<{{ undefined }}>\", ()).unwrap_err().kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(render!(in env, \"{{ undefined is undefined }}\"), \"true\");\n    assert_eq!(\n        env.render_str(\"{{ undefined|list }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::InvalidOperation\n    );\n    assert_eq!(\n        env.render_str(\"{{ undefined|test }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(\n        env.render_str(\"{{ 42 in undefined }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_nil() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=nil\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn handle_ws_for_if_nodes_with_else() {\n    let end_ws = WS { left: true, right: true };\n    let ast = vec![\n        Node::Text(\"C \".to_string()),\n        Node::If(\n            If {\n                conditions: vec![\n                    (\n                        WS { left: true, right: true },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                    (\n                        WS { left: true, right: false },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                    (\n                        WS { left: true, right: true },\n                        Expr::new(ExprVal::Int(1)),\n                        vec![Node::Text(\" a \".to_string())],\n                    ),\n                ],\n                otherwise: Some((\n                    WS { left: true, right: true },\n                    vec![Node::Text(\" a \".to_string())],\n                )),\n            },\n            end_ws,\n        ),\n        Node::Text(\"  hey\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::Text(\"C\".to_string()),\n            Node::If(\n                If {\n                    conditions: vec![\n                        (\n                            WS { left: true, right: true },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\"a\".to_string())],\n                        ),\n                        (\n                            WS { left: true, right: false },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\" a\".to_string())],\n                        ),\n                        (\n                            WS { left: true, right: true },\n                            Expr::new(ExprVal::Int(1)),\n                            vec![Node::Text(\"a\".to_string())],\n                        ),\n                    ],\n                    otherwise: Some((\n                        WS { left: true, right: true },\n                        vec![Node::Text(\"a\".to_string())],\n                    )),\n                },\n                end_ws,\n            ),\n            Node::Text(\"hey\".to_string()),\n        ]\n    );\n}"}
{"code": "pub fn i32_exit_status(&self) -> Option<i32> {\n        if let Self::I32Exit(status) = self {\n            return Some(*status);\n        }\n        None\n    }", "test": "fn resumable_call_smoldot_tail_01() {\n    let (mut store, wasm_fn) = resumable_call_smoldot_common(\n        r#\"\n        (module\n            (import \"env\" \"host_fn\" (func $host_fn (result i32)))\n            (func (export \"test\") (result i32)\n                (return_call $host_fn)\n            )\n        )\n        \"#,\n    );\n    assert_eq!(\n        wasm_fn\n            .call_resumable(&mut store, ())\n            .unwrap_err()\n            .i32_exit_status(),\n        Some(100),\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_custom_backup_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_custom_backup_suffix\";\n    let link = \"test_symlink_custom_backup_suffix_link\";\n    let suffix = \"super-suffix-of-the-century\";\n\n    at.touch(file);\n    at.symlink_file(file, link);\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    let arg = &format!(\"--suffix={suffix}\");\n    ucmd.args(&[\"-b\", arg, \"-s\", file, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(file));\n\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    let backup = &format!(\"{link}{suffix}\");\n    assert!(at.is_symlink(backup));\n    assert_eq!(at.resolve_link(backup), file);\n}"}
{"code": "pub fn is_closed(&self) -> bool {\n        self.state.is_closed()\n    }", "test": "fn cid_retirement() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    // Server retires current active remote CIDs\n    pair.server_conn_mut(server_ch)\n        .rotate_local_cid(1, Instant::now());\n    pair.drive();\n    // Any unexpected behavior may trigger TransportError::CONNECTION_ID_LIMIT_ERROR\n    assert!(!pair.client_conn_mut(client_ch).is_closed());\n    assert!(!pair.server_conn_mut(server_ch).is_closed());\n    assert_matches!(pair.client_conn_mut(client_ch).active_rem_cid_seq(), 1);\n\n    use crate::cid_queue::CidQueue;\n    use crate::LOC_CID_COUNT;\n    let mut active_cid_num = CidQueue::LEN as u64;\n    active_cid_num = active_cid_num.min(LOC_CID_COUNT);\n\n    let next_retire_prior_to = active_cid_num + 1;\n    pair.client_conn_mut(client_ch).ping();\n    // Server retires all valid remote CIDs\n    pair.server_conn_mut(server_ch)\n        .rotate_local_cid(next_retire_prior_to, Instant::now());\n    pair.drive();\n    assert!(!pair.client_conn_mut(client_ch).is_closed());\n    assert!(!pair.server_conn_mut(server_ch).is_closed());\n    assert_matches!(\n        pair.client_conn_mut(client_ch).active_rem_cid_seq(),\n        _next_retire_prior_to\n    );\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_simple() {\n    assert_eq!(\n        from_str(\n            \"/*\n * We got a hexadecimal number here!\n *\n */0x507\"\n        ),\n        Ok(0x507)\n    );\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_dec() {\n    assert_eq!(from_str(\"1461\"), Ok(1461));\n    assert_eq!(from_str(\"51\"), Ok(51));\n    assert_eq!(from_str(\"150700\"), Ok(150700));\n\n    assert_eq!(\n        from_str::<i8>(\"-_1\"),\n        Err(SpannedError {\n            code: Error::UnderscoreAtBeginning,\n            position: Position { line: 1, col: 2 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"256\"),\n        Err(SpannedError {\n            code: Error::IntegerOutOfBounds,\n            position: Position { line: 1, col: 4 },\n        })\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_reference() {\n    let scenario = TestScenario::new(\"touch\");\n    let (at, mut _ucmd) = (scenario.fixtures.clone(), scenario.ucmd());\n    let file_a = \"test_touch_reference_a\";\n    let file_b = \"test_touch_reference_b\";\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n\n    at.touch(file_a);\n    set_file_times(&at, file_a, start_of_year, start_of_year);\n    assert!(at.file_exists(file_a));\n    for opt in [\"-r\", \"--ref\", \"--reference\"] {\n        scenario\n            .ccmd(\"touch\")\n            .args(&[opt, file_a, file_b])\n            .succeeds()\n            .no_stderr();\n\n        assert!(at.file_exists(file_b));\n\n        let (atime, mtime) = get_file_times(&at, file_b);\n        assert_eq!(atime, mtime);\n        assert_eq!(atime, start_of_year);\n        assert_eq!(mtime, start_of_year);\n        let _ = remove_file(file_b);\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_config_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(PathBuf::from(\"biome.json\"), CONFIG_FILE_SIZE_LIMIT);\n\n    let file_path = Path::new(\"format.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_config_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn len(self) -> bool {\n        self.0 & 0x02 != 0\n    }", "test": "fn server_can_send_3_inital_packets() {\n    let _guard = subscribe();\n\n    let (cert, key) = big_cert_and_key();\n    let server = server_config_with_cert(cert.clone(), key);\n    let client = client_config_with_certs(vec![cert]);\n    let mut pair = Pair::new(Default::default(), server);\n\n    let client_ch = pair.begin_connect(client);\n    // Client sends initial\n    pair.drive_client();\n    // Server sends first flight, gets blocked on anti-amplification\n    pair.drive_server();\n    // Server should have queued 3 packets at this time\n    assert_eq!(pair.client.inbound.len(), 3);\n\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn recv_data_overflows_stream_window() {\n    // this tests for when streams have smaller windows than their connection\n    h2_support::trace_init!();\n\n    let (io, mut srv) = mock::new();\n\n    let mock = async move {\n        let _ = srv.assert_client_handshake().await;\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://http2.akamai.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        // fill the whole window\n        srv.send_frame(frames::data(1, vec![0u8; 16_384])).await;\n        // this frame overflows the window!\n        srv.send_frame(frames::data(1, &[0; 16][..]).eos()).await;\n        srv.recv_frame(frames::reset(1).flow_control()).await;\n    };\n\n    let h2 = async move {\n        let (mut client, conn) = client::Builder::new()\n            .initial_window_size(16_384)\n            .handshake::<_, Bytes>(io)\n            .await\n            .unwrap();\n        let request = Request::builder()\n            .method(Method::GET)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let req = async move {\n            let resp = client.send_request(request, true).unwrap().0.await.unwrap();\n            assert_eq!(resp.status(), StatusCode::OK);\n            let body = resp.into_parts().1;\n            let res = util::concat(body).await;\n            let err = res.unwrap_err();\n            assert_eq!(\n                err.to_string(),\n                \"stream error detected: flow-control protocol violated\"\n            );\n        };\n\n        join(async move { conn.await.unwrap() }, req).await;\n    };\n    join(mock, h2).await;\n}"}
{"code": "pub(crate) fn internal_n_mask(bit: u64, n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(bit <= bits, \"internal_n_halfway() overflow in shl.\");\n    debug_assert!(n <= bits, \"internal_n_halfway() overflow in shl.\");\n    debug_assert!(bit >= n, \"internal_n_halfway() overflow in sub.\");\n\n    lower_n_mask(bit) ^ lower_n_mask(bit - n)\n}", "test": "fn internal_n_mask_test() {\n    assert_eq!(internal_n_mask(1u64, 0u64), 0b0);\n    assert_eq!(internal_n_mask(1u64, 1u64), 0b1);\n    assert_eq!(internal_n_mask(2u64, 1u64), 0b10);\n    assert_eq!(internal_n_mask(4u64, 2u64), 0b1100);\n    assert_eq!(internal_n_mask(10u64, 2u64), 0b1100000000);\n    assert_eq!(internal_n_mask(10u64, 4u64), 0b1111000000);\n    assert_eq!(\n        internal_n_mask(32u64, 4u64),\n        0b11110000000000000000000000000000\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn missing_configuration_file() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"migrate\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"missing_configuration_file\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_none_then_all() {\n    // take last if multiple update args are supplied,\n    // update=all wins in this case\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_none_then_all_file1\";\n    let new = \"test_mv_arg_update_none_then_all_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=none\")\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), \"old content\\n\");\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_additional_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_additional_suffix\";\n    RandomFile::new(&at, name).add_lines(2000);\n    ucmd.args(&[\"--additional-suffix\", \".txt\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]].txt$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_simple() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=simple\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn render_str(\n        slf: PyRef<'_, Self>,\n        source: &str,\n        name: Option<&str>,\n        ctx: Option<&PyDict>,\n    ) -> PyResult<String> {\n        bind_environment(slf.as_ptr(), || {\n            let ctx = ctx\n                .map(|ctx| Value::from_struct_object(DictLikeObject { inner: ctx.into() }))\n                .unwrap_or_else(|| context!());\n            slf.inner\n                .lock()\n                .unwrap()\n                .env\n                .render_named_str(name.unwrap_or(\"<string>\"), source, ctx)\n                .map_err(to_py_error)\n        })\n    }", "test": "fn test_keep_trailing_newlines() {\n    let mut env = Environment::new();\n    env.add_template(\"foo.txt\", \"blub\\r\\n\").unwrap();\n    assert_eq!(env.render_str(\"blub\\r\\n\", ()).unwrap(), \"blub\");\n\n    env.set_keep_trailing_newline(true);\n    env.add_template(\"foo_keep.txt\", \"blub\\r\\n\").unwrap();\n    assert_eq!(\n        env.get_template(\"foo.txt\").unwrap().render(()).unwrap(),\n        \"blub\"\n    );\n    assert_eq!(\n        env.get_template(\"foo_keep.txt\")\n            .unwrap()\n            .render(())\n            .unwrap(),\n        \"blub\\r\\n\"\n    );\n    assert_eq!(env.render_str(\"blub\\r\\n\", ()).unwrap(), \"blub\\r\\n\");\n}"}
{"code": "pub fn at<'m, 'p>(&'m self, path: &'p str) -> Result<Match<'m, 'p, &'m T>, MatchError> {\n        match self.root.at(path.as_bytes()) {\n            Ok((value, params)) => Ok(Match {\n                // SAFETY: We only expose &mut T through &mut self\n                value: unsafe { &*value.get() },\n                params,\n            }),\n            Err(e) => Err(e),\n        }\n    }", "test": "fn issue_22() {\n    let mut x = Router::new();\n    x.insert(\"/foo_bar\", \"Welcome!\").unwrap();\n    x.insert(\"/foo/bar\", \"Welcome!\").unwrap();\n    assert_eq!(x.at(\"/foo/\").unwrap_err(), MatchError::NotFound);\n\n    let mut x = Router::new();\n    x.insert(\"/foo\", \"Welcome!\").unwrap();\n    x.insert(\"/foo/bar\", \"Welcome!\").unwrap();\n    assert_eq!(x.at(\"/foo/\").unwrap_err(), MatchError::ExtraTrailingSlash);\n}"}
{"code": "fn len(&self) -> usize {\n        self.length\n    }", "test": "fn test_cdc_rawkv_basic() {\n    let mut suite = TestSuite::new(1, ApiVersion::V2);\n\n    // rawkv\n    let mut req = suite.new_changedata_request(1);\n    req.set_kv_api(ChangeDataRequestKvApi::RawKv);\n    let (mut req_tx, _event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(1));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n\n    let event = receive_event(false);\n    event.events.into_iter().for_each(|e| {\n        match e.event.unwrap() {\n            // Even if there is no write,\n            // it should always outputs an Initialized event.\n            Event_oneof_event::Entries(es) => {\n                assert!(es.entries.len() == 1, \"{:?}\", es);\n                let e = &es.entries[0];\n                assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n            }\n            other => panic!(\"unknown event {:?}\", other),\n        }\n    });\n    // Sleep a while to make sure the stream is registered.\n    sleep_ms(1000);\n    // There must be a delegate.\n    let scheduler = suite.endpoints.values().next().unwrap().scheduler();\n    scheduler\n        .schedule(Task::Validate(Validate::Region(\n            1,\n            Box::new(|delegate| {\n                let d = delegate.unwrap();\n                assert_eq!(d.downstreams().len(), 1);\n            }),\n        )))\n        .unwrap();\n\n    // If tikv enable ApiV2, raw key needs to start with 'r';\n    let (k, v) = (b\"rkey1\".to_vec(), b\"value\".to_vec());\n    suite.must_kv_put(1, k, v);\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1, \"{:?}\", events);\n\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Entries(entries) => {\n            assert_eq!(entries.entries.len(), 1);\n            assert_eq!(entries.entries[0].get_type(), EventLogType::Committed);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    // boundary case\n    let (k, v) = (b\"r\\0\".to_vec(), b\"value\".to_vec());\n    suite.must_kv_put(1, k, v);\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1, \"{:?}\", events);\n\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Entries(entries) => {\n            assert_eq!(entries.entries.len(), 1);\n            assert_eq!(entries.entries[0].get_type(), EventLogType::Committed);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n}"}
{"code": "pub(crate) fn len(&self) -> usize {\n        self.records.len()\n    }", "test": "fn test_tsig_zone_transfer() {\n    let (_process, port) = named_process();\n    let socket = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), port);\n    let conn = TcpClientConnection::new(socket).unwrap();\n\n    let client = create_tsig_ready_client(conn);\n\n    let name = Name::from_str(\"example.net.\").unwrap();\n    let result = client.zone_transfer(&name, None).expect(\"query failed\");\n    let result = result.collect::<Result<Vec<_>, _>>().unwrap();\n    assert_ne!(result.len(), 1);\n    assert_eq!(\n        result.iter().map(|r| r.answers().len()).sum::<usize>(),\n        2000 + 3\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_older_dest_not_older() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_none_file1\";\n    let new = \"test_mv_arg_update_none_file2\";\n    let old_content = \"file1 content\\n\";\n    let new_content = \"file2 content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=older\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), new_content);\n}"}
{"code": "pub fn get_id(&self) -> ConnId {\n        self.id\n    }", "test": "fn test_read_after_cleanup_range_for_snap() {\n    let mut cluster = new_server_cluster(1, 3);\n    configure_for_snapshot(&mut cluster.cfg);\n    configure_for_lease_read(&mut cluster.cfg, Some(100), Some(10));\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    // Set region and peers\n    let r1 = cluster.run_conf_change();\n    let p1 = new_peer(1, 1);\n    let p2 = new_peer(2, 2);\n    cluster.pd_client.must_add_peer(r1, p2.clone());\n    let p3 = new_peer(3, 3);\n    cluster.pd_client.must_add_peer(r1, p3.clone());\n    cluster.must_put(b\"k0\", b\"v0\");\n    cluster.pd_client.must_none_pending_peer(p2);\n    cluster.pd_client.must_none_pending_peer(p3.clone());\n    let region = cluster.get_region(b\"k0\");\n    assert_eq!(cluster.leader_of_region(region.get_id()).unwrap(), p1);\n    must_get_equal(&cluster.get_engine(3), b\"k0\", b\"v0\");\n    cluster.stop_node(3);\n    let last_index = cluster.raft_local_state(r1, 1).last_index;\n    (0..10).for_each(|_| cluster.must_put(b\"k1\", b\"v1\"));\n    // Ensure logs are compacted, then node 1 will send a snapshot to node 3 later\n    cluster.wait_log_truncated(r1, 1, last_index + 1);\n\n    fail::cfg(\"send_snapshot\", \"pause\").unwrap();\n    cluster.run_node(3).unwrap();\n    // Sleep for a while to ensure peer 3 receives a HeartBeat\n    thread::sleep(Duration::from_millis(500));\n\n    // Add filter for delaying ReadIndexResp and MsgSnapshot\n    let (read_index_sx, read_index_rx) = channel::unbounded::<RaftMessage>();\n    let (snap_sx, snap_rx) = channel::unbounded::<RaftMessage>();\n    let recv_filter = Box::new(\n        RegionPacketFilter::new(region.get_id(), 3)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgSnapshot)\n            .set_msg_callback(Arc::new(move |msg: &RaftMessage| {\n                snap_sx.send(msg.clone()).unwrap();\n            })),\n    );\n    let send_read_index_filter = RegionPacketFilter::new(region.get_id(), 3)\n        .direction(Direction::Recv)\n        .msg_type(MessageType::MsgReadIndexResp)\n        .set_msg_callback(Arc::new(move |msg: &RaftMessage| {\n            read_index_sx.send(msg.clone()).unwrap();\n        }));\n    cluster.sim.wl().add_recv_filter(3, recv_filter);\n    cluster.add_send_filter(CloneFilterFactory(send_read_index_filter));\n    fail::remove(\"send_snapshot\");\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cf_cmd(\"default\", b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(p3);\n    request.mut_header().set_replica_read(true);\n    // Send follower read request to peer 3\n    let (cb1, mut rx1) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(3, request, cb1)\n        .unwrap();\n    let read_index_msg = read_index_rx.recv_timeout(Duration::from_secs(5)).unwrap();\n    let snap_msg = snap_rx.recv_timeout(Duration::from_secs(5)).unwrap();\n\n    fail::cfg(\"apply_snap_cleanup_range\", \"pause\").unwrap();\n\n    let router = cluster.sim.wl().get_router(3).unwrap();\n    fail::cfg(\"pause_on_peer_collect_message\", \"pause\").unwrap();\n    cluster.sim.wl().clear_recv_filters(3);\n    cluster.clear_send_filters();\n    router.send_raft_message(snap_msg).unwrap();\n    router.send_raft_message(read_index_msg).unwrap();\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    fail::remove(\"pause_on_peer_collect_message\");\n    must_get_none(&cluster.get_engine(3), b\"k0\");\n    // Should not receive resp\n    rx1.recv_timeout(Duration::from_millis(500)).unwrap_err();\n    fail::remove(\"apply_snap_cleanup_range\");\n    rx1.recv_timeout(Duration::from_secs(5)).unwrap();\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_periodical_update() {\n    let eps_count = 3;\n    let server = MockServer::with_case(eps_count, Arc::new(LeaderChange::new()));\n    let eps = server.bind_addrs();\n\n    let counter = Arc::new(AtomicUsize::new(0));\n    let client = new_client_with_update_interval(eps, None, ReadableDuration::secs(3));\n    let counter1 = Arc::clone(&counter);\n    client.handle_reconnect(move || {\n        counter1.fetch_add(1, Ordering::SeqCst);\n    });\n    let leader = client.get_leader();\n\n    for _ in 0..5 {\n        let new = client.get_leader();\n        if new != leader {\n            assert!(counter.load(Ordering::SeqCst) >= 1);\n            return;\n        }\n        thread::sleep(LeaderChange::get_leader_interval());\n    }\n\n    panic!(\"failed, leader should changed\");\n}"}
{"code": "fn clone(&self) -> Self {\n        let refs = self.refs.fetch_add(1, atomic::Ordering::SeqCst);\n\n        trace!(\n            \"Storage referenced\"; \"original_ref\" => refs\n        );\n\n        Self {\n            engine: self.engine.clone(),\n            sched: self.sched.clone(),\n            read_pool: self.read_pool.clone(),\n            refs: self.refs.clone(),\n            max_key_size: self.max_key_size,\n            concurrency_manager: self.concurrency_manager.clone(),\n            api_version: self.api_version,\n            causal_ts_provider: self.causal_ts_provider.clone(),\n            resource_tag_factory: self.resource_tag_factory.clone(),\n            quota_limiter: self.quota_limiter.clone(),\n            _phantom: PhantomData,\n        }\n    }", "test": "fn test_raft_storage() {\n    let (_cluster, storage, mut ctx) = new_raft_storage();\n    let key = Key::from_raw(b\"key\");\n    assert_eq!(storage.get(ctx.clone(), &key, 5).unwrap().0, None);\n    storage\n        .prewrite(\n            ctx.clone(),\n            vec![Mutation::make_put(key.clone(), b\"value\".to_vec())],\n            b\"key\".to_vec(),\n            10,\n        )\n        .unwrap();\n    storage\n        .commit(ctx.clone(), vec![key.clone()], 10, 15)\n        .unwrap();\n    assert_eq!(\n        storage.get(ctx.clone(), &key, 20).unwrap().0.unwrap(),\n        b\"value\".to_vec()\n    );\n\n    // Test wrong region id.\n    let region_id = ctx.get_region_id();\n    ctx.set_region_id(region_id + 1);\n    storage.get(ctx.clone(), &key, 20).unwrap_err();\n    storage\n        .batch_get(ctx.clone(), &[key.clone()], 20)\n        .unwrap_err();\n    storage\n        .scan(ctx.clone(), key, None, 1, false, 20)\n        .unwrap_err();\n    storage.scan_locks(ctx, 20, None, None, 100).unwrap_err();\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.senders.is_empty()\n    }", "test": "fn server_hs_retransmit() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let client_ch = pair.begin_connect(client_config());\n    pair.step();\n    assert!(!pair.client.inbound.is_empty()); // Initial + Handshakes\n    pair.client.inbound.clear();\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_cp() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    // Invoke our binary to make the copy.\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HELLO_WORLD_DEST)\n        .succeeds();\n\n    // Check the content of the destination file that was copied.\n    assert_eq!(at.read(TEST_HELLO_WORLD_DEST), \"Hello, World!\\n\");\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_rm_prompts() {\n    use std::io::Write;\n\n    // Needed for talking with stdin on platforms where CRLF or LF matters\n    const END_OF_LINE: &str = if cfg!(windows) { \"\\r\\n\" } else { \"\\n\" };\n\n    let mut answers = [\n        \"rm: descend into directory 'a'?\",\n        \"rm: remove write-protected regular empty file 'a/empty-no-write'?\",\n        \"rm: remove symbolic link 'a/slink'?\",\n        \"rm: remove symbolic link 'a/slink-dot'?\",\n        \"rm: remove write-protected regular file 'a/f-no-write'?\",\n        \"rm: remove regular empty file 'a/empty'?\",\n        \"rm: remove directory 'a/b'?\",\n        \"rm: remove write-protected directory 'a/b-no-write'?\",\n        \"rm: remove directory 'a'?\",\n    ];\n\n    answers.sort();\n\n    let yes = format!(\"y{END_OF_LINE}\");\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.mkdir(\"a/\");\n\n    let file_1 = \"a/empty\";\n    let file_2 = \"a/empty-no-write\";\n    let file_3 = \"a/f-no-write\";\n\n    at.touch(file_1);\n    at.touch(file_2);\n    at.make_file(file_3)\n        .write_all(b\"not-empty\")\n        .expect(\"Couldn't write to a/f-no-write\");\n\n    at.symlink_dir(\"a/empty-f\", \"a/slink\");\n    at.symlink_dir(\".\", \"a/slink-dot\");\n\n    let dir_1 = \"a/b/\";\n    let dir_2 = \"a/b-no-write/\";\n\n    at.mkdir(dir_1);\n    at.mkdir(dir_2);\n\n    scene\n        .ccmd(\"chmod\")\n        .arg(\"u-w\")\n        .arg(file_3)\n        .arg(dir_2)\n        .arg(file_2)\n        .succeeds();\n\n    let mut child = scene\n        .ucmd()\n        .set_stdin(Stdio::piped())\n        .arg(\"-ri\")\n        .arg(\"a\")\n        .run_no_wait();\n    for _ in 0..9 {\n        child.try_write_in(yes.as_bytes()).unwrap();\n    }\n\n    let result = child.wait().unwrap();\n\n    let mut trimmed_output = Vec::new();\n    for string in result.stderr_str().split(\"rm: \") {\n        if !string.is_empty() {\n            let trimmed_string = format!(\"rm: {string}\").trim().to_string();\n            trimmed_output.push(trimmed_string);\n        }\n    }\n\n    trimmed_output.sort();\n\n    assert_eq!(trimmed_output.len(), answers.len());\n\n    for (i, checking_string) in trimmed_output.iter().enumerate() {\n        assert_eq!(checking_string, answers[i]);\n    }\n\n    assert!(!at.dir_exists(\"a\"));\n}"}
{"code": "pub fn is_writable(&self) -> bool {\n        self.status == LocksStatus::Normal\n    }", "test": "fn test_merge_pessimistic_locks_with_concurrent_prewrite() {\n    let mut cluster = new_server_cluster(0, 2);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k2\");\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k3\");\n\n    cluster.must_transfer_leader(right.id, new_peer(2, 2));\n\n    let addr = cluster.sim.rl().get_addr(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env).connect(&addr);\n    let client = TikvClient::new(channel);\n\n    let snapshot = cluster.must_get_snapshot_of_region(left.id);\n    let txn_ext = snapshot.txn_ext.unwrap();\n    let lock = PessimisticLock {\n        primary: b\"k0\".to_vec().into_boxed_slice(),\n        start_ts: 10.into(),\n        ttl: 3000,\n        for_update_ts: 20.into(),\n        min_commit_ts: 30.into(),\n        last_change_ts: 15.into(),\n        versions_to_last_change: 3,\n    };\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![\n            (Key::from_raw(b\"k0\"), lock.clone()),\n            (Key::from_raw(b\"k1\"), lock),\n        ])\n        .unwrap();\n\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.set_key(b\"k0\".to_vec());\n    mutation.set_value(b\"v\".to_vec());\n    let mut req = PrewriteRequest::default();\n    req.set_context(cluster.get_ctx(b\"k0\"));\n    req.set_mutations(vec![mutation].into());\n    req.set_pessimistic_actions(vec![DoPessimisticCheck]);\n    req.set_start_version(10);\n    req.set_for_update_ts(40);\n    req.set_primary_lock(b\"k0\".to_vec());\n\n    // First, pause apply and prewrite.\n    fail::cfg(\"on_handle_apply\", \"pause\").unwrap();\n    let req2 = req.clone();\n    let client2 = client.clone();\n    let resp = thread::spawn(move || client2.kv_prewrite(&req2).unwrap());\n    thread::sleep(Duration::from_millis(500));\n\n    // Then, start merging. PrepareMerge should wait until prewrite is done.\n    cluster.merge_region(left.id, right.id, Callback::None);\n    thread::sleep(Duration::from_millis(500));\n    assert!(txn_ext.pessimistic_locks.read().is_writable());\n\n    // But a later prewrite request should fail because we have already banned all\n    // later proposals.\n    req.mut_mutations()[0].set_key(b\"k1\".to_vec());\n    let resp2 = thread::spawn(move || client.kv_prewrite(&req).unwrap());\n\n    fail::remove(\"on_handle_apply\");\n    let resp = resp.join().unwrap();\n    assert!(!resp.has_region_error(), \"{:?}\", resp);\n\n    let resp2 = resp2.join().unwrap();\n    assert!(resp2.has_region_error());\n}"}
{"code": "fn to_string(lit: Literal) -> String {\n    let formatted = lit.to_string();\n\n    let mut it = formatted.chars();\n    assert_eq!(it.next(), Some('\"'));\n\n    let mut rv = String::new();\n    loop {\n        match it.next() {\n            Some('\"') => match it.next() {\n                Some(_) => panic!(),\n                None => break,\n            },\n            Some('\\\\') => match it.next() {\n                Some('x') => {\n                    let hi = it.next().unwrap().to_digit(16).unwrap();\n                    let lo = it.next().unwrap().to_digit(16).unwrap();\n                    let v = (hi << 16) | lo;\n                    rv.push(v as u8 as char);\n                }\n                Some('u') => {\n                    assert_eq!(it.next(), Some('{'));\n                    let mut c = it.next().unwrap();\n                    let mut ch = 0;\n                    while let Some(v) = c.to_digit(16) {\n                        ch *= 16;\n                        ch |= v;\n                        c = it.next().unwrap();\n                    }\n                    assert_eq!(c, '}');\n                    rv.push(::std::char::from_u32(ch).unwrap());\n                }\n                Some('0') => rv.push('\\0'),\n                Some('\\\\') => rv.push('\\\\'),\n                Some('\\\"') => rv.push('\\\"'),\n                Some('r') => rv.push('\\r'),\n                Some('n') => rv.push('\\n'),\n                Some('t') => rv.push('\\t'),\n                Some(_) => panic!(),\n                None => panic!(),\n            },\n            Some(c) => rv.push(c),\n            None => panic!(),\n        }\n    }\n\n    rv\n}", "test": "fn drop_guest_twice() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (type $t' (resource (rep i32)))\n\n                (export $t \"t\" (type $t'))\n\n                (core func $ctor (canon resource.new $t))\n                (func (export \"ctor\") (param \"x\" u32) (result (own $t))\n                    (canon lift (core func $ctor)))\n\n                (core func $dtor (canon resource.drop $t))\n                (func (export \"dtor\") (param \"x\" (own $t))\n                    (canon lift (core func $dtor)))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let i = Linker::new(&engine).instantiate(&mut store, &c)?;\n    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, \"ctor\")?;\n    let dtor = i.get_typed_func::<(&ResourceAny,), ()>(&mut store, \"dtor\")?;\n\n    let (t,) = ctor.call(&mut store, (100,))?;\n    ctor.post_return(&mut store)?;\n    dtor.call(&mut store, (&t,))?;\n    dtor.post_return(&mut store)?;\n\n    assert_eq!(\n        dtor.call(&mut store, (&t,)).unwrap_err().to_string(),\n        \"unknown handle index 0\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn write_batch_write_twice_1() {\n    let db = default_engine();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n\n    let db = multi_batch_write_engine();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..123_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    for i in 0..123_usize {\n        let x = i.to_be_bytes();\n        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);\n    }\n}"}
{"code": "pub fn call(\n        &self,\n        mut ctx: impl AsContextMut<UserState = T>,\n        instance: Option<&Instance>,\n        params: FuncParams,\n    ) -> Result<FuncFinished, Trap> {\n        let caller = <Caller<T>>::new(&mut ctx, instance);\n        (self.closure)(caller, params)\n    }", "test": "fn static_add3_works() {\n    let (mut store, add3, add3_dyn) = setup_add3();\n    let add3 = add3.typed::<(i32, i32, i32), i32>(&mut store).unwrap();\n    let add3_dyn = add3_dyn.typed::<(i32, i32, i32), i32>(&mut store).unwrap();\n    for a in 0..5 {\n        for b in 0..5 {\n            for c in 0..5 {\n                let expected = a + b + c;\n                assert_eq!(add3.call(&mut store, (a, b, c)).unwrap(), expected);\n                assert_eq!(add3_dyn.call(&mut store, (a, b, c)).unwrap(), expected);\n            }\n        }\n    }\n}"}
{"code": "pub fn last(&self) -> Option<&V> {\n        self.elems.last()\n    }", "test": "fn recursion() -> Result<(), Error> {\n    // Make sure call hook behaves reasonably when called recursively\n\n    let engine = Engine::default();\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\"host\", \"f\", |mut caller: Caller<State>, n: i32| {\n        assert_eq!(caller.data().context.last(), Some(&Context::Host));\n\n        assert_eq!(caller.data().calls_into_host, caller.data().calls_into_wasm);\n\n        // Recurse\n        if n > 0 {\n            caller\n                .get_export(\"export\")\n                .expect(\"caller exports \\\"export\\\"\")\n                .into_func()\n                .expect(\"export is a func\")\n                .typed::<i32, ()>(&caller)\n                .expect(\"export typing\")\n                .call(&mut caller, n - 1)\n                .unwrap()\n        }\n    })?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32)))\n            (func (export \"export\") (param i32)\n                (call $f (local.get 0)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let inst = linker.instantiate(&mut store, &module)?;\n    let export = inst\n        .get_export(&mut store, \"export\")\n        .expect(\"get export\")\n        .into_func()\n        .expect(\"export is func\");\n\n    // Recursion depth:\n    let n: usize = 10;\n\n    export.call(&mut store, &[Val::I32(n as i32)], &mut [])?;\n\n    // Recurse down to 0: n+1 calls\n    assert_eq!(store.data().calls_into_host, n + 1);\n    assert_eq!(store.data().returns_from_host, n + 1);\n    assert_eq!(store.data().calls_into_wasm, n + 1);\n    assert_eq!(store.data().returns_from_wasm, n + 1);\n\n    export\n        .typed::<i32, ()>(&store)?\n        .call(&mut store, n as i32)?;\n\n    assert_eq!(store.data().calls_into_host, 2 * (n + 1));\n    assert_eq!(store.data().returns_from_host, 2 * (n + 1));\n    assert_eq!(store.data().calls_into_wasm, 2 * (n + 1));\n    assert_eq!(store.data().returns_from_wasm, 2 * (n + 1));\n\n    Ok(())\n}"}
{"code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_raftkv_early_error_report() {\n    let raftkv_fp = \"raftkv_early_error_report\";\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n    cluster.must_split(&cluster.get_region(b\"k0\"), b\"k1\");\n\n    let env = Arc::new(Environment::new(1));\n    let mut clients: HashMap<&[u8], (Context, TikvClient)> = HashMap::default();\n    for &k in &[b\"k0\", b\"k1\"] {\n        let region = cluster.get_region(k);\n        let leader = region.get_peers()[0].clone();\n        let mut ctx = Context::default();\n        let channel = ChannelBuilder::new(env.clone())\n            .connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n        let client = TikvClient::new(channel);\n        ctx.set_region_id(region.get_id());\n        ctx.set_region_epoch(region.get_region_epoch().clone());\n        ctx.set_peer(leader);\n        clients.insert(k, (ctx, client));\n    }\n\n    // Inject error to all regions.\n    fail::cfg(raftkv_fp, \"return\").unwrap();\n    for (k, (ctx, client)) in &clients {\n        let mut put_req = RawPutRequest::default();\n        put_req.set_context(ctx.clone());\n        put_req.key = k.to_vec();\n        put_req.value = b\"v\".to_vec();\n        let put_resp = client.raw_put(&put_req).unwrap();\n        assert!(put_resp.has_region_error(), \"{:?}\", put_resp);\n        assert!(\n            put_resp.get_region_error().has_region_not_found(),\n            \"{:?}\",\n            put_resp\n        );\n        must_get_none(&cluster.get_engine(1), k);\n    }\n    fail::remove(raftkv_fp);\n\n    // Inject only one region\n    let injected_region_id = clients[b\"k0\".as_ref()].0.get_region_id();\n    fail::cfg(raftkv_fp, &format!(\"return({})\", injected_region_id)).unwrap();\n    for (k, (ctx, client)) in &clients {\n        let mut put_req = RawPutRequest::default();\n        put_req.set_context(ctx.clone());\n        put_req.key = k.to_vec();\n        put_req.value = b\"v\".to_vec();\n        let put_resp = client.raw_put(&put_req).unwrap();\n        if ctx.get_region_id() == injected_region_id {\n            assert!(put_resp.has_region_error(), \"{:?}\", put_resp);\n            assert!(\n                put_resp.get_region_error().has_region_not_found(),\n                \"{:?}\",\n                put_resp\n            );\n            must_get_none(&cluster.get_engine(1), k);\n        } else {\n            assert!(!put_resp.has_region_error(), \"{:?}\", put_resp);\n            must_get_equal(&cluster.get_engine(1), k, b\"v\");\n        }\n    }\n    fail::remove(raftkv_fp);\n}"}
{"code": "fn nothing(i: &[u8]) -> IResult<&[u8], &[u8]> {\n    take_till(|_| true)(i)\n  }", "test": "fn take_till_issue() {\n  use nom::bytes::streaming::take_till;\n\n  fn nothing(i: &[u8]) -> IResult<&[u8], &[u8]> {\n    take_till(|_| true)(i)\n  }\n\n  assert_eq!(nothing(b\"\"), Err(Err::Incomplete(Needed::new(1))));\n  assert_eq!(nothing(b\"abc\"), Ok((&b\"abc\"[..], &b\"\"[..])));\n}"}
{"code": "pub fn is_match(&self, text: &[u8]) -> bool {\n        self.is_match_at(text, 0)\n    }", "test": "fn dfa_handles_pathological_case() {\n    fn ones_and_zeroes(count: usize) -> String {\n        use rand::{Rng, thread_rng};\n\n        let mut rng = thread_rng();\n        let mut s = String::new();\n        for _ in 0..count {\n            if rng.gen() {\n                s.push('1');\n            } else {\n                s.push('0');\n            }\n        }\n        s\n    }\n\n    let re = regex!(r\"[01]*1[01]{20}$\");\n    let text = {\n        let mut pieces = ones_and_zeroes(100_000);\n        pieces.push('1');\n        pieces.push_str(&ones_and_zeroes(20));\n        pieces\n    };\n    assert!(re.is_match(text!(&*text)));\n}"}
{"code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn enum_unnamed_fields_variant() {\n    let mut key = CacheKeyHasher::new();\n\n    let variant = Enum::UnnamedFields(\"Hello\".to_string(), \"World\".to_string());\n    variant.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    variant.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"code": "pub fn map<I, O1, O2, E, F, G>(mut parser: F, mut f: G) -> impl FnMut(I) -> IResult<I, O2, E>\nwhere\n  F: Parser<I, O1, E>,\n  G: FnMut(O1) -> O2,\n{\n  move |input: I| {\n    let (input, o1) = parser.parse(input)?;\n    Ok((input, f(o1)))\n  }\n}", "test": "fn factor_test() {\n  assert_eq!(\n    factor(\"  3  \").map(|(i, x)| (i, format!(\"{:?}\", x))),\n    Ok((\"\", String::from(\"3\")))\n  );\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn strip_div_newline() {\n    assert_eq!(\"<div></div>\", normalize_html(\"<div>\\n</div>\"));\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn ok_many_variable_blocks() {\n    let mut context = Context::new();\n    context.insert(\"username\", &\"bob\");\n\n    let mut tpl = String::new();\n    for _ in 0..200 {\n        tpl.push_str(\"{{ username }}\")\n    }\n    let mut expected = String::new();\n    for _ in 0..200 {\n        expected.push_str(\"bob\")\n    }\n    assert_eq!(render_template(&tpl, &context).unwrap(), expected);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_force_replace_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_force_replace_file_a\";\n    let file_b = \"test_mv_force_replace_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"--force\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "pub fn is_writable(&self) -> bool {\n        self.status == LocksStatus::Normal\n    }", "test": "fn test_retry_pending_prepare_merge_fail() {\n    let mut cluster = new_server_cluster(0, 2);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k2\");\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k3\");\n\n    cluster.must_transfer_leader(right.id, new_peer(2, 2));\n\n    // Insert lock l1 into the left region\n    let snapshot = cluster.must_get_snapshot_of_region(left.id);\n    let txn_ext = snapshot.txn_ext.unwrap();\n    let l1 = PessimisticLock {\n        primary: b\"k1\".to_vec().into_boxed_slice(),\n        start_ts: 10.into(),\n        ttl: 3000,\n        for_update_ts: 20.into(),\n        min_commit_ts: 30.into(),\n        last_change_ts: 15.into(),\n        versions_to_last_change: 3,\n    };\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(Key::from_raw(b\"k1\"), l1)])\n        .unwrap();\n\n    // Pause apply and write some data to the left region\n    fail::cfg(\"on_handle_apply\", \"pause\").unwrap();\n    let (propose_tx, propose_rx) = mpsc::sync_channel(10);\n    fail::cfg_callback(\"after_propose\", move || propose_tx.send(()).unwrap()).unwrap();\n\n    let mut rx = cluster.async_put(b\"k1\", b\"v11\").unwrap();\n    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();\n    rx.recv_timeout(Duration::from_millis(200)).unwrap_err();\n\n    // Then, start merging. PrepareMerge should become pending because applied_index\n    // is smaller than proposed_index.\n    cluster.merge_region(left.id, right.id, Callback::None);\n    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();\n    thread::sleep(Duration::from_millis(200));\n    assert!(txn_ext.pessimistic_locks.read().is_writable());\n\n    // Set disk full error to let PrepareMerge fail. (Set both peer to full to avoid\n    // transferring leader)\n    fail::cfg(\"disk_already_full_peer_1\", \"return\").unwrap();\n    fail::cfg(\"disk_already_full_peer_2\", \"return\").unwrap();\n    fail::remove(\"on_handle_apply\");\n    let res = rx.recv_timeout(Duration::from_secs(1)).unwrap();\n    assert!(!res.get_header().has_error(), \"{:?}\", res);\n\n    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();\n    fail::remove(\"disk_already_full_peer_1\");\n    fail::remove(\"disk_already_full_peer_2\");\n\n    // Merge should not succeed because the disk is full.\n    thread::sleep(Duration::from_millis(300));\n    cluster.reset_leader_of_region(left.id);\n    assert_eq!(cluster.get_region(b\"k1\"), left);\n\n    cluster.must_put(b\"k1\", b\"v12\");\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn save_point_pop_after_write() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_some());\n\n    db.engine.delete(b\"a\").unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n\n    wb.pop_save_point().unwrap();\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_some());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n    for i in 0..max_keys {\n        wb.put(&i.to_be_bytes(), b\"\").unwrap();\n    }\n\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n\n    db.engine.delete(b\"a\").unwrap();\n    for i in 0..max_keys {\n        db.engine.delete(&i.to_be_bytes()).unwrap();\n    }\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n\n    wb.pop_save_point().unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn test_custom_table_limiter() -> Result<()> {\n    let engine = Engine::default();\n    let linker = Linker::new(&engine);\n\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 0 anyfunc))\"#)?;\n\n    let context = TableContext {\n        elements_used: 0,\n        element_limit: 10,\n        limit_exceeded: false,\n    };\n\n    let mut store = Store::new(&engine, context);\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n    let instance = linker.instantiate(&mut store, &module)?;\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n\n    // Grow the table by 10 elements\n    table.grow(&mut store, 3, Val::FuncRef(None))?;\n    table.grow(&mut store, 5, Val::FuncRef(None))?;\n    table.grow(&mut store, 2, Val::FuncRef(None))?;\n\n    assert!(!store.data().limit_exceeded);\n\n    // Table is at the maximum, but the limit hasn't been exceeded\n    assert!(!store.data().limit_exceeded);\n\n    // Try to grow the memory again\n    assert_eq!(\n        table\n            .grow(&mut store, 1, Val::FuncRef(None))\n            .map_err(|e| e.to_string())\n            .unwrap_err(),\n        \"failed to grow table by `1`\"\n    );\n\n    assert!(store.data().limit_exceeded);\n\n    Ok(())\n}"}
{"code": "pub fn is_none(v: Value) -> bool {\n    v.is_none()\n}", "test": "fn test_return_none() {\n    let env = Environment::empty();\n    let val = Value::from_function(|| -> Result<(), Error> { Ok(()) });\n    let rv = val.call(&env.empty_state(), &[][..]).unwrap();\n    assert!(rv.is_none());\n    let val = Value::from_function(|| ());\n    let rv = val.call(&env.empty_state(), &[][..]).unwrap();\n    assert!(rv.is_none());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_target_new_file_with_group() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"file\";\n    let dir = \"target_dir\";\n    let gid = getegid();\n\n    at.touch(file);\n    at.mkdir(dir);\n    let result = ucmd\n        .arg(file)\n        .arg(\"--group\")\n        .arg(gid.to_string())\n        .arg(format!(\"{dir}/{file}\"))\n        .run();\n\n    if is_ci() && result.stderr_str().contains(\"no such group:\") {\n        // In the CI, some server are failing to return the group.\n        // As seems to be a configuration issue, ignoring it\n        return;\n    }\n\n    result.success();\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "fn valid(&self) -> Result<bool> {\n        self.0.valid().map_err(r2e)\n    }", "test": "fn delete() -> Result<()> {\n    let tempdir = tempdir();\n    let sst_path = tempdir\n        .path()\n        .join(\"test-data.sst\")\n        .to_string_lossy()\n        .to_string();\n    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();\n    let mut sst_writer = sst_builder.build(&sst_path)?;\n\n    sst_writer.delete(b\"k1\")?;\n    sst_writer.finish()?;\n\n    let sst_reader = <KvTestEngine as SstExt>::SstReader::open(&sst_path)?;\n    let mut iter = sst_reader.iter(IterOptions::default()).unwrap();\n\n    iter.seek_to_first()?;\n\n    assert_eq!(iter.valid()?, false);\n\n    iter.prev().unwrap_err();\n    iter.next().unwrap_err();\n    recover_safe(|| {\n        iter.key();\n    })\n    .unwrap_err();\n    recover_safe(|| {\n        iter.value();\n    })\n    .unwrap_err();\n\n    assert_eq!(iter.seek_to_first()?, false);\n    assert_eq!(iter.seek_to_last()?, false);\n    assert_eq!(iter.seek(b\"foo\")?, false);\n    assert_eq!(iter.seek_for_prev(b\"foo\")?, false);\n\n    Ok(())\n}"}
{"code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn struct_ignored_fields() {\n    #[derive(CacheKey)]\n    struct NamedFieldsStruct {\n        a: String,\n        #[cache_key(ignore)]\n        #[allow(unused)]\n        b: String,\n    }\n\n    impl Hash for NamedFieldsStruct {\n        fn hash<H: Hasher>(&self, state: &mut H) {\n            self.a.hash(state);\n        }\n    }\n\n    let mut key = CacheKeyHasher::new();\n\n    let named_fields = NamedFieldsStruct {\n        a: \"Hello\".into(),\n        b: \"World\".into(),\n    };\n\n    named_fields.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    named_fields.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_verbose_slash() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_verbose_slash_directory\";\n    let file_a = &format!(\"{dir}/test_rm_verbose_slash_file_a\");\n\n    at.mkdir(dir);\n    at.touch(file_a);\n\n    let file_a_normalized = &format!(\n        \"{}{}test_rm_verbose_slash_file_a\",\n        dir,\n        std::path::MAIN_SEPARATOR\n    );\n\n    ucmd.arg(\"-r\")\n        .arg(\"-f\")\n        .arg(\"-v\")\n        .arg(&format!(\"{dir}///\"))\n        .succeeds()\n        .stdout_only(format!(\n            \"removed '{file_a_normalized}'\\nremoved directory '{dir}'\\n\"\n        ));\n\n    assert!(!at.dir_exists(dir));\n    assert!(!at.file_exists(file_a));\n}"}
{"code": "pub fn join(self, rhs: Self) -> Self {\n        let must_return = self.must_return() && rhs.must_return();\n        let explicit = self.may_return_explicit() || rhs.may_return_explicit();\n        let implicit = self.may_return_implicit() || rhs.may_return_implicit();\n\n        Self::create(must_return, explicit, implicit)\n    }", "test": "fn crypto_js() {\n    let f = super::fixture();\n\n    let resolver = Resolver::new(ResolveOptions {\n        alias_fields: vec![vec![\"browser\".into()]],\n        fallback: vec![(\n            \"crypto\".into(),\n            vec![AliasValue::Path(f.join(\"lib.js\").to_string_lossy().to_string())],\n        )],\n        ..ResolveOptions::default()\n    });\n\n    let resolved_path = resolver.resolve(f.join(\"crypto-js\"), \"crypto\").map(|r| r.full_path());\n    assert_eq!(resolved_path, Err(ResolveError::Ignored(f.join(\"crypto-js\"))));\n}"}
{"code": "fn get(&self, mut req: Get) -> PdFuture<GetResponse> {\n        let timer = Instant::now();\n        self.fill_cluster_id_for(req.inner.mut_header());\n        let executor = move |client: &Client, req: GetRequest| {\n            let handler = {\n                let inner = client.inner.rl();\n                let r = inner\n                    .meta_storage\n                    .get_async_opt(&req, call_option_inner(&inner));\n                futures::future::ready(r).err_into().try_flatten()\n            };\n            Box::pin(async move {\n                fail::fail_point!(\"meta_storage_get\", req.key.ends_with(b\"rejectme\"), |_| {\n                    Err(super::Error::Grpc(grpcio::Error::RemoteStopped))\n                });\n                let resp = handler.await?;\n                PD_REQUEST_HISTOGRAM_VEC\n                    .meta_storage_get\n                    .observe(timer.saturating_elapsed_secs());\n                Ok(resp)\n            }) as _\n        };\n\n        self.pd_client\n            .request(req.into(), executor, LEADER_CHANGE_RETRY)\n            .execute()\n    }", "test": "fn test_raw_gc_keys_handled() {\n    let store_id = 1;\n    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();\n    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();\n\n    let engine = TestEngineBuilder::new()\n        .api_version(ApiVersion::V2)\n        .build()\n        .unwrap();\n    let prefixed_engine = PrefixedEngine(engine.clone());\n\n    let (tx, _rx) = mpsc::channel();\n    let feature_gate = FeatureGate::default();\n    let mut gc_worker = GcWorker::new(\n        prefixed_engine,\n        tx,\n        GcConfig::default(),\n        feature_gate,\n        Arc::new(MockRegionInfoProvider::new(vec![])),\n    );\n    gc_worker.start(store_id).unwrap();\n\n    let mut r1 = Region::default();\n    r1.set_id(1);\n    r1.mut_region_epoch().set_version(1);\n    r1.set_start_key(b\"\".to_vec());\n    r1.set_end_key(b\"\".to_vec());\n    r1.mut_peers().push(Peer::default());\n    r1.mut_peers()[0].set_store_id(store_id);\n\n    let sp_provider = MockSafePointProvider(200);\n    let mut host = CoprocessorHost::<RocksEngine>::default();\n    let ri_provider = RegionInfoAccessor::new(&mut host);\n    let auto_gc_cfg = AutoGcConfig::new(sp_provider, ri_provider, store_id);\n    let safe_point = Arc::new(AtomicU64::new(500));\n\n    gc_worker.start_auto_gc(auto_gc_cfg, safe_point).unwrap();\n    host.on_region_changed(&r1, RegionChangeEvent::Create, StateRole::Leader);\n\n    let db = engine.kv_engine().unwrap().as_inner().clone();\n\n    let user_key_del = b\"r\\0aaaaaaaaaaa\";\n\n    // If it's deleted, it will call async scheduler GcTask.\n    let test_raws = vec![\n        (user_key_del, 9, true),\n        (user_key_del, 5, false),\n        (user_key_del, 1, false),\n    ];\n\n    let modifies = test_raws\n        .into_iter()\n        .map(|(key, ts, is_delete)| {\n            (\n                make_key(key, ts),\n                ApiV2::encode_raw_value(RawValue {\n                    user_value: &[0; 10][..],\n                    expire_ts: Some(TimeStamp::max().into_inner()),\n                    is_delete,\n                }),\n            )\n        })\n        .map(|(k, v)| Modify::Put(CF_DEFAULT, Key::from_encoded_slice(k.as_slice()), v))\n        .collect();\n\n    let ctx = Context {\n        api_version: ApiVersion::V2,\n        ..Default::default()\n    };\n\n    let batch = WriteData::from_modifies(modifies);\n\n    engine.write(&ctx, batch).unwrap();\n\n    let cf = get_cf_handle(&db, CF_DEFAULT).unwrap();\n    db.flush_cf(cf, true, false).unwrap();\n\n    db.compact_range_cf(cf, None, None);\n\n    thread::sleep(Duration::from_millis(100));\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_MVCC_DELETION_MET\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        1\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        1\n    );\n\n    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();\n    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();\n}"}
{"code": "pub fn get_speed_limit(&self) -> f64 {\n        self.core.limiter.speed_limit()\n    }", "test": "fn test_update_server_config() {\n    let (mut config, _dir) = TikvConfig::with_tmp().unwrap();\n    config.validate().unwrap();\n    let (cfg_controller, snap_worker, snap_mgr) = start_server(config.clone(), &_dir);\n    let mut svr_cfg = config.server.clone();\n    // dispatch updated config\n    let change = {\n        let mut m = std::collections::HashMap::new();\n        m.insert(\n            \"server.snap-io-max-bytes-per-sec\".to_owned(),\n            \"512MB\".to_owned(),\n        );\n        m.insert(\n            \"server.concurrent-send-snap-limit\".to_owned(),\n            \"100\".to_owned(),\n        );\n        m\n    };\n    cfg_controller.update(change).unwrap();\n\n    svr_cfg.snap_io_max_bytes_per_sec = ReadableSize::mb(512);\n    svr_cfg.concurrent_send_snap_limit = 100;\n    // config should be updated\n    assert_eq!(snap_mgr.get_speed_limit() as u64, 536870912);\n    validate(&snap_worker.scheduler(), move |cfg: &ServerConfig| {\n        assert_eq!(cfg, &svr_cfg);\n    });\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cols.len()\n    }", "test": "fn test_resize_async_ios_failed_2() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_io_pool_size = 0;\n    cluster.pd_client.disable_default_operator();\n    let _ = cluster.run_conf_change();\n\n    // Save current async-io tids before shrinking\n    let org_writers_tids = get_async_writers_tids();\n    assert_eq!(0, org_writers_tids.len());\n    // Request can be handled as usual\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n\n    // Update config, expand from sync-mode(async-ios == 0) to\n    // async-mode(async-ios == 2).\n    {\n        let sim = cluster.sim.rl();\n        let cfg_controller = sim.get_cfg_controller().unwrap();\n\n        let change = {\n            let mut change = HashMap::new();\n            change.insert(\"raftstore.store-io-pool-size\".to_owned(), \"2\".to_owned());\n            change\n        };\n\n        assert!(cfg_controller.update(change).is_err());\n        assert_eq!(\n            cfg_controller.get_current().raft_store.store_io_pool_size,\n            0\n        );\n    }\n    // Save current async-io tids after scaling up, and compared with the\n    // orginial one before scaling up, the thread num should be added up to TWO.\n    let cur_writers_tids = get_async_writers_tids();\n    assert_eq!(cur_writers_tids.len(), org_writers_tids.len());\n\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n}"}
{"code": "pub fn is_data(&self) -> bool {\n        self.classify() == Category::Data\n    }", "test": "fn test_category() {\n    assert!(from_str::<String>(\"123\").unwrap_err().is_data());\n\n    assert!(from_str::<String>(\"]\").unwrap_err().is_syntax());\n\n    assert!(from_str::<String>(\"\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\\\\\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\\\\u\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\\\\u0\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\\\\u00\").unwrap_err().is_eof());\n    assert!(from_str::<String>(\"\\\"\\\\u000\").unwrap_err().is_eof());\n\n    assert!(from_str::<Vec<usize>>(\"[\").unwrap_err().is_eof());\n    assert!(from_str::<Vec<usize>>(\"[0\").unwrap_err().is_eof());\n    assert!(from_str::<Vec<usize>>(\"[0,\").unwrap_err().is_eof());\n\n    assert!(from_str::<BTreeMap<String, usize>>(\"{\")\n        .unwrap_err()\n        .is_eof());\n    assert!(from_str::<BTreeMap<String, usize>>(\"{\\\"k\\\"\")\n        .unwrap_err()\n        .is_eof());\n    assert!(from_str::<BTreeMap<String, usize>>(\"{\\\"k\\\":\")\n        .unwrap_err()\n        .is_eof());\n    assert!(from_str::<BTreeMap<String, usize>>(\"{\\\"k\\\":0\")\n        .unwrap_err()\n        .is_eof());\n    assert!(from_str::<BTreeMap<String, usize>>(\"{\\\"k\\\":0,\")\n        .unwrap_err()\n        .is_eof());\n\n    let fail = FailReader(io::ErrorKind::NotConnected);\n    assert!(from_reader::<_, String>(fail).unwrap_err().is_io());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn parse_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), PARSE_ERROR.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"parse_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_switch_witness() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    std::thread::sleep(Duration::from_millis(100));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    // witness -> non-witness\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![false],\n    );\n\n    std::thread::sleep(Duration::from_millis(100));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n}"}
{"code": "fn len(&self) -> usize {\n        self.length\n    }", "test": "fn test_cdc_filter_key_range() {\n    let mut suite = TestSuite::new(1, ApiVersion::V1);\n\n    let req = suite.new_changedata_request(1);\n\n    // Observe range [key1, key3).\n    let mut req_1_3 = req.clone();\n    req_1_3.request_id = 13;\n    req_1_3.start_key = Key::from_raw(b\"key1\").into_encoded();\n    req_1_3.end_key = Key::from_raw(b\"key3\").into_encoded();\n    let (mut req_tx13, _event_feed_wrap13, receive_event13) =\n        new_event_feed(suite.get_region_cdc_client(1));\n    block_on(req_tx13.send((req_1_3, WriteFlags::default()))).unwrap();\n    let event = receive_event13(false);\n    event\n        .events\n        .into_iter()\n        .for_each(|e| match e.event.unwrap() {\n            Event_oneof_event::Entries(es) => {\n                assert!(es.entries.len() == 1, \"{:?}\", es);\n                let e = &es.entries[0];\n                assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n            }\n            other => panic!(\"unknown event {:?}\", other),\n        });\n\n    let (mut req_tx24, _event_feed_wrap24, receive_event24) =\n        new_event_feed(suite.get_region_cdc_client(1));\n    let mut req_2_4 = req;\n    req_2_4.request_id = 24;\n    req_2_4.start_key = Key::from_raw(b\"key2\").into_encoded();\n    req_2_4.end_key = Key::from_raw(b\"key4\").into_encoded();\n    block_on(req_tx24.send((req_2_4, WriteFlags::default()))).unwrap();\n    let event = receive_event24(false);\n    event\n        .events\n        .into_iter()\n        .for_each(|e| match e.event.unwrap() {\n            Event_oneof_event::Entries(es) => {\n                assert!(es.entries.len() == 1, \"{:?}\", es);\n                let e = &es.entries[0];\n                assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n            }\n            other => panic!(\"unknown event {:?}\", other),\n        });\n\n    // Sleep a while to make sure the stream is registered.\n    sleep_ms(1000);\n\n    let receive_and_check_events = |is13: bool, is24: bool| -> Vec<Event> {\n        if is13 && is24 {\n            let mut events = receive_event13(false).events.to_vec();\n            let mut events24 = receive_event24(false).events.to_vec();\n            events.append(&mut events24);\n            events\n        } else if is13 {\n            let events = receive_event13(false).events.to_vec();\n            let event = receive_event24(true);\n            assert!(event.resolved_ts.is_some(), \"{:?}\", event);\n            events\n        } else if is24 {\n            let events = receive_event24(false).events.to_vec();\n            let event = receive_event13(true);\n            assert!(event.resolved_ts.is_some(), \"{:?}\", event);\n            events\n        } else {\n            let event = receive_event13(true);\n            assert!(event.resolved_ts.is_some(), \"{:?}\", event);\n            let event = receive_event24(true);\n            assert!(event.resolved_ts.is_some(), \"{:?}\", event);\n            vec![]\n        }\n    };\n    for case in &[\n        (\"key1\", true, false, true /* commit */),\n        (\"key1\", true, false, false /* rollback */),\n        (\"key2\", true, true, true),\n        (\"key3\", false, true, true),\n        (\"key4\", false, false, true),\n    ] {\n        let (k, v) = (case.0.to_owned(), \"value\".to_owned());\n        // Prewrite\n        let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n        let mut mutation = Mutation::default();\n        mutation.set_op(Op::Put);\n        mutation.key = k.clone().into_bytes();\n        mutation.value = v.into_bytes();\n        suite.must_kv_prewrite(1, vec![mutation], k.clone().into_bytes(), start_ts);\n        let mut events = receive_and_check_events(case.1, case.2);\n        while let Some(event) = events.pop() {\n            match event.event.unwrap() {\n                Event_oneof_event::Entries(entries) => {\n                    assert_eq!(entries.entries.len(), 1);\n                    assert_eq!(entries.entries[0].get_type(), EventLogType::Prewrite);\n                }\n                other => panic!(\"unknown event {:?}\", other),\n            }\n        }\n\n        if case.3 {\n            // Commit\n            let commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n            suite.must_kv_commit(1, vec![k.into_bytes()], start_ts, commit_ts);\n            let mut events = receive_and_check_events(case.1, case.2);\n            while let Some(event) = events.pop() {\n                match event.event.unwrap() {\n                    Event_oneof_event::Entries(entries) => {\n                        assert_eq!(entries.entries.len(), 1);\n                        assert_eq!(entries.entries[0].get_type(), EventLogType::Commit);\n                    }\n                    other => panic!(\"unknown event {:?}\", other),\n                }\n            }\n        } else {\n            // Rollback\n            suite.must_kv_rollback(1, vec![k.into_bytes()], start_ts);\n            let mut events = receive_and_check_events(case.1, case.2);\n            while let Some(event) = events.pop() {\n                match event.event.unwrap() {\n                    Event_oneof_event::Entries(entries) => {\n                        assert_eq!(entries.entries.len(), 1);\n                        assert_eq!(entries.entries[0].get_type(), EventLogType::Rollback);\n                    }\n                    other => panic!(\"unknown event {:?}\", other),\n                }\n            }\n        }\n    }\n\n    suite.stop();\n}"}
{"code": "fn len(&self) -> usize {\n            self.hash_table.len()\n        }", "test": "fn test_trap_trace_cb() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let wat = r#\"\n        (module $hello_mod\n            (import \"\" \"throw\" (func $throw))\n            (func (export \"run\") (call $hello))\n            (func $hello (call $throw))\n        )\n    \"#;\n\n    let fn_type = FuncType::new(None, None);\n    let fn_func = Func::new(&mut store, fn_type, |_, _, _| bail!(\"cb throw\"));\n\n    let module = Module::new(store.engine(), wat)?;\n    let instance = Instance::new(&mut store, &module, &[fn_func.into()])?;\n    let run_func = instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n\n    let e = run_func.call(&mut store, ()).unwrap_err();\n\n    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    assert_eq!(trace.len(), 2);\n    assert_eq!(trace[0].module().name().unwrap(), \"hello_mod\");\n    assert_eq!(trace[0].func_index(), 2);\n    assert_eq!(trace[1].module().name().unwrap(), \"hello_mod\");\n    assert_eq!(trace[1].func_index(), 1);\n    assert!(format!(\"{e:?}\").contains(\"cb throw\"));\n\n    Ok(())\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_str_prefixed_chunks_by_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_str_prefixed_chunks_by_bytes\";\n    RandomFile::new(&at, name).add_bytes(10000);\n    // Important that this is less than 1024 since that's our internal buffer\n    // size. Good to test that we don't overshoot.\n    ucmd.args(&[\"-b\", \"1000\", name, \"b\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"b[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    for filename in glob.collect() {\n        assert_eq!(glob.directory.metadata(&filename).len(), 1000);\n    }\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn size(&self) -> u32 {\n        match self {\n            Table::Static { size, .. } => *size,\n            Table::Dynamic { elements, .. } => elements.len().try_into().unwrap(),\n        }\n    }", "test": "fn grow_funcref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::FuncRef, 10, None);\n    let table = Table::new(&mut store, table_ty, Val::FuncRef(None))?;\n\n    assert_eq!(table.size(&store), 10);\n    table.grow(&mut store, 3, Val::FuncRef(None))?;\n    assert_eq!(table.size(&store), 13);\n\n    Ok(())\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn new_engine_opt_renamed_dir() {\n    use std::sync::Arc;\n    let dir = tempdir();\n    let root_path = dir.path();\n\n    let encryption_cfg = test_util::new_file_security_config(root_path);\n    let key_manager = Arc::new(\n        data_key_manager_from_config(&encryption_cfg, root_path.to_str().unwrap())\n            .unwrap()\n            .unwrap(),\n    );\n\n    let mut db_opts = DbOptions::default();\n    db_opts.set_key_manager(Some(key_manager.clone()));\n    let cf_opts: Vec<_> = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();\n\n    let path = root_path.join(\"missing\").to_str().unwrap().to_owned();\n    {\n        let db = KvTestEngine::new_kv_engine_opt(&path, db_opts.clone(), cf_opts.clone()).unwrap();\n        db.put(b\"foo\", b\"bar\").unwrap();\n        db.sync().unwrap();\n    }\n    let new_path = root_path.join(\"new\").to_str().unwrap().to_owned();\n    key_manager.link_file(&path, &new_path).unwrap();\n    fs::rename(&path, &new_path).unwrap();\n    key_manager.delete_file(&path).unwrap();\n    {\n        let db =\n            KvTestEngine::new_kv_engine_opt(&new_path, db_opts.clone(), cf_opts.clone()).unwrap();\n        assert_eq!(\n            db.get_value_cf(CF_DEFAULT, b\"foo\").unwrap().unwrap(),\n            b\"bar\"\n        );\n    }\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u128_pow2_test() {\n    let values: &[u128] = &[\n        0,\n        1,\n        2,\n        3,\n        4,\n        5,\n        7,\n        8,\n        9,\n        15,\n        16,\n        17,\n        31,\n        32,\n        33,\n        63,\n        64,\n        65,\n        127,\n        128,\n        129,\n        255,\n        256,\n        257,\n        511,\n        512,\n        513,\n        1023,\n        1024,\n        1025,\n        2047,\n        2048,\n        2049,\n        4095,\n        4096,\n        4097,\n        8191,\n        8192,\n        8193,\n        16383,\n        16384,\n        16385,\n        32767,\n        32768,\n        32769,\n        65535,\n        65536,\n        65537,\n        131071,\n        131072,\n        131073,\n        262143,\n        262144,\n        262145,\n        524287,\n        524288,\n        524289,\n        1048575,\n        1048576,\n        1048577,\n        2097151,\n        2097152,\n        2097153,\n        4194303,\n        4194304,\n        4194305,\n        8388607,\n        8388608,\n        8388609,\n        16777215,\n        16777216,\n        16777217,\n        33554431,\n        33554432,\n        33554433,\n        67108863,\n        67108864,\n        67108865,\n        134217727,\n        134217728,\n        134217729,\n        268435455,\n        268435456,\n        268435457,\n        536870911,\n        536870912,\n        536870913,\n        1073741823,\n        1073741824,\n        1073741825,\n        2147483647,\n        2147483648,\n        2147483649,\n        4294967295,\n        4294967296,\n        4294967297,\n        8589934591,\n        8589934592,\n        8589934593,\n        17179869183,\n        17179869184,\n        17179869185,\n        34359738367,\n        34359738368,\n        34359738369,\n        68719476735,\n        68719476736,\n        68719476737,\n        137438953471,\n        137438953472,\n        137438953473,\n        274877906943,\n        274877906944,\n        274877906945,\n        549755813887,\n        549755813888,\n        549755813889,\n        1099511627775,\n        1099511627776,\n        1099511627777,\n        2199023255551,\n        2199023255552,\n        2199023255553,\n        4398046511103,\n        4398046511104,\n        4398046511105,\n        8796093022207,\n        8796093022208,\n        8796093022209,\n        17592186044415,\n        17592186044416,\n        17592186044417,\n        35184372088831,\n        35184372088832,\n        35184372088833,\n        70368744177663,\n        70368744177664,\n        70368744177665,\n        140737488355327,\n        140737488355328,\n        140737488355329,\n        281474976710655,\n        281474976710656,\n        281474976710657,\n        562949953421311,\n        562949953421312,\n        562949953421313,\n        1125899906842623,\n        1125899906842624,\n        1125899906842625,\n        2251799813685247,\n        2251799813685248,\n        2251799813685249,\n        4503599627370495,\n        4503599627370496,\n        4503599627370497,\n        9007199254740991,\n        9007199254740992,\n        9007199254740993,\n        18014398509481983,\n        18014398509481984,\n        18014398509481985,\n        36028797018963967,\n        36028797018963968,\n        36028797018963969,\n        72057594037927935,\n        72057594037927936,\n        72057594037927937,\n        144115188075855871,\n        144115188075855872,\n        144115188075855873,\n        288230376151711743,\n        288230376151711744,\n        288230376151711745,\n        576460752303423487,\n        576460752303423488,\n        576460752303423489,\n        1152921504606846975,\n        1152921504606846976,\n        1152921504606846977,\n        2305843009213693951,\n        2305843009213693952,\n        2305843009213693953,\n        4611686018427387903,\n        4611686018427387904,\n        4611686018427387905,\n        9223372036854775807,\n        9223372036854775808,\n        9223372036854775809,\n        18446744073709551615,\n        18446744073709551616,\n        18446744073709551617,\n        36893488147419103231,\n        36893488147419103232,\n        36893488147419103233,\n        73786976294838206463,\n        73786976294838206464,\n        73786976294838206465,\n        147573952589676412927,\n        147573952589676412928,\n        147573952589676412929,\n        295147905179352825855,\n        295147905179352825856,\n        295147905179352825857,\n        590295810358705651711,\n        590295810358705651712,\n        590295810358705651713,\n        1180591620717411303423,\n        1180591620717411303424,\n        1180591620717411303425,\n        2361183241434822606847,\n        2361183241434822606848,\n        2361183241434822606849,\n        4722366482869645213695,\n        4722366482869645213696,\n        4722366482869645213697,\n        9444732965739290427391,\n        9444732965739290427392,\n        9444732965739290427393,\n        18889465931478580854783,\n        18889465931478580854784,\n        18889465931478580854785,\n        37778931862957161709567,\n        37778931862957161709568,\n        37778931862957161709569,\n        75557863725914323419135,\n        75557863725914323419136,\n        75557863725914323419137,\n        151115727451828646838271,\n        151115727451828646838272,\n        151115727451828646838273,\n        302231454903657293676543,\n        302231454903657293676544,\n        302231454903657293676545,\n        604462909807314587353087,\n        604462909807314587353088,\n        604462909807314587353089,\n        1208925819614629174706175,\n        1208925819614629174706176,\n        1208925819614629174706177,\n        2417851639229258349412351,\n        2417851639229258349412352,\n        2417851639229258349412353,\n        4835703278458516698824703,\n        4835703278458516698824704,\n        4835703278458516698824705,\n        9671406556917033397649407,\n        9671406556917033397649408,\n        9671406556917033397649409,\n        19342813113834066795298815,\n        19342813113834066795298816,\n        19342813113834066795298817,\n        38685626227668133590597631,\n        38685626227668133590597632,\n        38685626227668133590597633,\n        77371252455336267181195263,\n        77371252455336267181195264,\n        77371252455336267181195265,\n        154742504910672534362390527,\n        154742504910672534362390528,\n        154742504910672534362390529,\n        309485009821345068724781055,\n        309485009821345068724781056,\n        309485009821345068724781057,\n        618970019642690137449562111,\n        618970019642690137449562112,\n        618970019642690137449562113,\n        1237940039285380274899124223,\n        1237940039285380274899124224,\n        1237940039285380274899124225,\n        2475880078570760549798248447,\n        2475880078570760549798248448,\n        2475880078570760549798248449,\n        4951760157141521099596496895,\n        4951760157141521099596496896,\n        4951760157141521099596496897,\n        9903520314283042199192993791,\n        9903520314283042199192993792,\n        9903520314283042199192993793,\n        19807040628566084398385987583,\n        19807040628566084398385987584,\n        19807040628566084398385987585,\n        39614081257132168796771975167,\n        39614081257132168796771975168,\n        39614081257132168796771975169,\n        79228162514264337593543950335,\n        79228162514264337593543950336,\n        79228162514264337593543950337,\n        158456325028528675187087900671,\n        158456325028528675187087900672,\n        158456325028528675187087900673,\n        316912650057057350374175801343,\n        316912650057057350374175801344,\n        316912650057057350374175801345,\n        633825300114114700748351602687,\n        633825300114114700748351602688,\n        633825300114114700748351602689,\n        1267650600228229401496703205375,\n        1267650600228229401496703205376,\n        1267650600228229401496703205377,\n        2535301200456458802993406410751,\n        2535301200456458802993406410752,\n        2535301200456458802993406410753,\n        5070602400912917605986812821503,\n        5070602400912917605986812821504,\n        5070602400912917605986812821505,\n        10141204801825835211973625643007,\n        10141204801825835211973625643008,\n        10141204801825835211973625643009,\n        20282409603651670423947251286015,\n        20282409603651670423947251286016,\n        20282409603651670423947251286017,\n        40564819207303340847894502572031,\n        40564819207303340847894502572032,\n        40564819207303340847894502572033,\n        81129638414606681695789005144063,\n        81129638414606681695789005144064,\n        81129638414606681695789005144065,\n        162259276829213363391578010288127,\n        162259276829213363391578010288128,\n        162259276829213363391578010288129,\n        324518553658426726783156020576255,\n        324518553658426726783156020576256,\n        324518553658426726783156020576257,\n        649037107316853453566312041152511,\n        649037107316853453566312041152512,\n        649037107316853453566312041152513,\n        1298074214633706907132624082305023,\n        1298074214633706907132624082305024,\n        1298074214633706907132624082305025,\n        2596148429267413814265248164610047,\n        2596148429267413814265248164610048,\n        2596148429267413814265248164610049,\n        5192296858534827628530496329220095,\n        5192296858534827628530496329220096,\n        5192296858534827628530496329220097,\n        10384593717069655257060992658440191,\n        10384593717069655257060992658440192,\n        10384593717069655257060992658440193,\n        20769187434139310514121985316880383,\n        20769187434139310514121985316880384,\n        20769187434139310514121985316880385,\n        41538374868278621028243970633760767,\n        41538374868278621028243970633760768,\n        41538374868278621028243970633760769,\n        83076749736557242056487941267521535,\n        83076749736557242056487941267521536,\n        83076749736557242056487941267521537,\n        166153499473114484112975882535043071,\n        166153499473114484112975882535043072,\n        166153499473114484112975882535043073,\n        332306998946228968225951765070086143,\n        332306998946228968225951765070086144,\n        332306998946228968225951765070086145,\n        664613997892457936451903530140172287,\n        664613997892457936451903530140172288,\n        664613997892457936451903530140172289,\n        1329227995784915872903807060280344575,\n        1329227995784915872903807060280344576,\n        1329227995784915872903807060280344577,\n        2658455991569831745807614120560689151,\n        2658455991569831745807614120560689152,\n        2658455991569831745807614120560689153,\n        5316911983139663491615228241121378303,\n        5316911983139663491615228241121378304,\n        5316911983139663491615228241121378305,\n        10633823966279326983230456482242756607,\n        10633823966279326983230456482242756608,\n        10633823966279326983230456482242756609,\n        21267647932558653966460912964485513215,\n        21267647932558653966460912964485513216,\n        21267647932558653966460912964485513217,\n        42535295865117307932921825928971026431,\n        42535295865117307932921825928971026432,\n        42535295865117307932921825928971026433,\n        85070591730234615865843651857942052863,\n        85070591730234615865843651857942052864,\n        85070591730234615865843651857942052865,\n        170141183460469231731687303715884105727,\n        170141183460469231731687303715884105728,\n        170141183460469231731687303715884105729,\n        340282366920938463463374607431768211455,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "fn write_vectored(&mut self, bufs: &[io::IoSlice<'_>]) -> io::Result<usize> {\n        let mut sz = 0;\n        for buf in bufs {\n            sz += self.send_some_plaintext(buf);\n        }\n        Ok(sz)\n    }", "test": "fn client_respects_buffer_limit_pre_handshake_with_vectored_write() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n\n    client.set_buffer_limit(Some(32));\n\n    assert_eq!(\n        client\n            .writer()\n            .write_vectored(&[\n                IoSlice::new(b\"01234567890123456789\"),\n                IoSlice::new(b\"01234567890123456789\")\n            ])\n            .unwrap(),\n        32\n    );\n\n    do_handshake(&mut client, &mut server);\n    transfer(&mut client, &mut server);\n    server.process_new_packets().unwrap();\n\n    check_read(&mut server.reader(), b\"01234567890123456789012345678901\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_interactive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_rm_interactive_file_a\";\n    let file_b = \"test_rm_interactive_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    scene\n        .ucmd()\n        .arg(\"-i\")\n        .arg(file_a)\n        .arg(file_b)\n        .pipe_in(\"n\")\n        .succeeds();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    scene\n        .ucmd()\n        .arg(\"-i\")\n        .arg(file_a)\n        .arg(file_b)\n        .pipe_in(\"Yesh\") // spell-checker:disable-line\n        .succeeds();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_oct() {\n    assert_eq!(from_str(\"0o1461\"), Ok(0o1461));\n    assert_eq!(from_str(\"0o051\"), Ok(0o051));\n    assert_eq!(from_str(\"0o150700\"), Ok(0o150700));\n\n    assert_eq!(\n        from_str::<u8>(\"0o\"),\n        Err(SpannedError {\n            code: Error::ExpectedInteger,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0o_1\"),\n        Err(SpannedError {\n            code: Error::UnderscoreAtBeginning,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0o77777\"),\n        Err(SpannedError {\n            code: Error::IntegerOutOfBounds,\n            position: Position { line: 1, col: 8 },\n        })\n    );\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_empty_directory_no_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir(DIR);\n\n    ucmd.arg(DIR).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(DIR));\n}"}
{"code": "pub fn get_current(&self) -> TikvConfig {\n        self.inner.read().unwrap().current.clone()\n    }", "test": "fn test_increase_pool() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_batch_system.pool_size = 1;\n    cluster.cfg.raft_store.apply_batch_system.pool_size = 1;\n    cluster.pd_client.disable_default_operator();\n    let fp1 = \"poll\";\n\n    // Pause at the entrance of the apply-0, apply-low-0, rafstore-1-0 threads\n    fail::cfg(fp1, \"3*pause\").unwrap();\n    let _ = cluster.run_conf_change();\n\n    // Request cann't be handled as all pollers have been paused\n    put_with_timeout(&mut cluster, b\"k1\", b\"k1\", Duration::from_secs(1)).unwrap();\n    must_get_none(&cluster.get_engine(1), b\"k1\");\n\n    {\n        let sim = cluster.sim.rl();\n        let cfg_controller = sim.get_cfg_controller().unwrap();\n\n        let change = {\n            let mut change = HashMap::new();\n            change.insert(\"raftstore.store-pool-size\".to_owned(), \"2\".to_owned());\n            change.insert(\"raftstore.apply_pool_size\".to_owned(), \"2\".to_owned());\n            change\n        };\n\n        // Update config, expand from 1 to 2\n        cfg_controller.update(change).unwrap();\n        assert_eq!(\n            cfg_controller\n                .get_current()\n                .raft_store\n                .apply_batch_system\n                .pool_size,\n            2\n        );\n        assert_eq!(\n            cfg_controller\n                .get_current()\n                .raft_store\n                .store_batch_system\n                .pool_size,\n            2\n        );\n    }\n\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n\n    fail::remove(fp1);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_simple_backup() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_simple_backup\";\n    let link = \"test_symlink_simple_backup_link\";\n\n    at.touch(file);\n    at.symlink_file(file, link);\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    ucmd.args(&[\"-b\", \"-s\", file, link]).succeeds().no_stderr();\n\n    assert!(at.file_exists(file));\n\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    let backup = &format!(\"{link}~\");\n    assert!(at.is_symlink(backup));\n    assert_eq!(at.resolve_link(backup), file);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_short_no_args_files() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_simple_backup_file_a\";\n    let file_b = \"test_install_simple_backup_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"-b\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_nan_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.nan_string(Some(b\"naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaan\"));\n    assert!(!builder.is_valid());\n    builder = builder.nan_string(Some(b\"inf\"));\n    assert!(!builder.is_valid());\n    builder = builder.nan_string(Some(b\"na00n\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.nan_string(Some(b\"nan\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.nan_string(None);\n    assert!(builder.is_valid());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_request_snapshot_after_term_change() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(20);\n    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    std::thread::sleep(Duration::from_millis(100));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    // witness -> nonwitness\n    let fp1 = \"ignore generate snapshot\";\n    fail::cfg(fp1, \"return\").unwrap();\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);\n    std::thread::sleep(Duration::from_millis(500));\n    // as we ignore generate snapshot, so snapshot should still not applied yet\n    assert_eq!(cluster.pd_client.get_pending_peers().len(), 1);\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    // After leader changes, the `term` and `last term` no longer match, so\n    // continue to receive `MsgAppend` until the two get equal, then retry to\n    // request snapshot and complete the application.\n    std::thread::sleep(Duration::from_millis(500));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    assert_eq!(cluster.pd_client.get_pending_peers().len(), 0);\n    fail::remove(fp1);\n}"}
{"code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_number_old_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-9\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(9));\n}"}
{"code": "fn is_cluster_bootstrapped(&self) -> Result<bool> {\n        let _timer = PD_REQUEST_HISTOGRAM_VEC\n            .is_cluster_bootstrapped\n            .start_coarse_timer();\n\n        let mut req = pdpb::IsBootstrappedRequest::default();\n        req.set_header(self.header());\n\n        let resp = sync_request(&self.pd_client, LEADER_CHANGE_RETRY, |client, option| {\n            client.is_bootstrapped_opt(&req, option)\n        })?;\n        check_resp_header(resp.get_header())?;\n\n        Ok(resp.get_bootstrapped())\n    }", "test": "fn test_get_tombstone_stores() {\n    let eps_count = 1;\n    let server = MockServer::new(eps_count);\n    let eps = server.bind_addrs();\n    let mut client = new_client_v2(eps, None);\n\n    let mut all_stores = vec![];\n    let store_id = client.alloc_id().unwrap();\n    let mut store = metapb::Store::default();\n    store.set_id(store_id);\n    let region_id = client.alloc_id().unwrap();\n    let mut region = metapb::Region::default();\n    region.set_id(region_id);\n    client.bootstrap_cluster(store.clone(), region).unwrap();\n\n    all_stores.push(store);\n    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);\n    let s = client.get_all_stores(false).unwrap();\n    assert_eq!(s, all_stores);\n\n    // Add tombstone store.\n    let mut store99 = metapb::Store::default();\n    store99.set_id(99);\n    store99.set_state(metapb::StoreState::Tombstone);\n    server.default_handler().add_store(store99.clone());\n\n    // do not include tombstone.\n    let s = client.get_all_stores(true).unwrap();\n    assert_eq!(s, all_stores);\n\n    all_stores.push(store99.clone());\n    all_stores.sort_by_key(|a| a.get_id());\n    // include tombstone, there should be 2 stores.\n    let mut s = client.get_all_stores(false).unwrap();\n    s.sort_by_key(|a| a.get_id());\n    assert_eq!(s, all_stores);\n\n    // Add another tombstone store.\n    let mut store199 = store99;\n    store199.set_id(199);\n    server.default_handler().add_store(store199.clone());\n\n    all_stores.push(store199);\n    all_stores.sort_by_key(|a| a.get_id());\n    let mut s = client.get_all_stores(false).unwrap();\n    s.sort_by_key(|a| a.get_id());\n    assert_eq!(s, all_stores);\n\n    client.get_store(store_id).unwrap();\n    client.get_store(99).unwrap_err();\n    client.get_store(199).unwrap_err();\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cols.len()\n    }", "test": "fn test_decrease_async_ios() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_io_pool_size = 4;\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n\n    // Save current async-io tids before shrinking\n    let org_writers_tids = get_async_writers_tids();\n    assert_eq!(4, org_writers_tids.len());\n    // Request can be handled as usual\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n\n    // Update config, shrink from 4 to 1\n    {\n        let sim = cluster.sim.rl();\n        let cfg_controller = sim.get_cfg_controller().unwrap();\n        let change = {\n            let mut change = HashMap::new();\n            change.insert(\"raftstore.store-io-pool-size\".to_owned(), \"1\".to_owned());\n            change\n        };\n\n        cfg_controller.update(change).unwrap();\n        assert_eq!(\n            cfg_controller.get_current().raft_store.store_io_pool_size,\n            1\n        );\n        // Wait for the completion of decreasing async-ios\n        std::thread::sleep(std::time::Duration::from_secs(1));\n    }\n\n    // Save current async-io tids after scaling down, and compared with the\n    // orginial one before shrinking. As the decreasing of async-ios won't\n    // release asynchronous writers, the thread num should not be updated.\n    let cur_writers_tids = get_async_writers_tids();\n    assert_eq!(cur_writers_tids.len(), org_writers_tids.len());\n    // After shrinking, all the left tids must be there before\n    for tid in cur_writers_tids {\n        assert!(org_writers_tids.contains(&tid));\n    }\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_twice() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_target_new_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"file\";\n    let dir = \"target_dir\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(file)\n        .arg(format!(\"{dir}/{file}\"))\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "pub fn eq_case(&self, other: &Self) -> bool {\n        self.cmp_with_f::<CaseSensitive>(other) == Ordering::Equal\n    }", "test": "fn test_query(client: &mut AsyncClient) -> impl Future<Output = ()> {\n    let name = Name::from_ascii(\"WWW.example.com\").unwrap();\n\n    client\n        .query(name.clone(), DNSClass::IN, RecordType::A)\n        .map_ok(move |response| {\n            println!(\"response records: {response:?}\");\n            assert!(response\n                .queries()\n                .first()\n                .expect(\"expected query\")\n                .name()\n                .eq_case(&name));\n\n            let record = &response.answers()[0];\n            assert_eq!(record.name(), &name);\n            assert_eq!(record.record_type(), RecordType::A);\n            assert_eq!(record.dns_class(), DNSClass::IN);\n\n            if let RData::A(ref address) = record.data().unwrap() {\n                assert_eq!(address, &A::new(93, 184, 216, 34))\n            } else {\n                panic!();\n            }\n        })\n        .map(|r: Result<_, _>| r.expect(\"query failed\"))\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_column_with_lock() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    for &iso_level in &[IsolationLevel::Si, IsolationLevel::Rc] {\n        let (_, endpoint, _) = init_data_with_commit(&product, &data, false);\n\n        let mut req = new_analyze_column_req(&product, 3, 3, 3, 3, 4, 32);\n        let mut ctx = Context::default();\n        ctx.set_isolation_level(iso_level);\n        req.set_context(ctx);\n\n        let resp = handle_request(&endpoint, req);\n        match iso_level {\n            IsolationLevel::Si => {\n                assert!(resp.get_data().is_empty(), \"{:?}\", resp);\n                assert!(resp.has_locked(), \"{:?}\", resp);\n            }\n            IsolationLevel::Rc => {\n                let mut analyze_resp = AnalyzeColumnsResp::default();\n                analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n                let hist = analyze_resp.get_pk_hist();\n                assert!(hist.get_buckets().is_empty());\n                assert_eq!(hist.get_ndv(), 0);\n            }\n            IsolationLevel::RcCheckTs => unimplemented!(),\n        }\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_older_dest_older_than_src() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_cp_arg_update_dest_older_file1\";\n    let new = \"test_cp_arg_update_dest_older_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(new)\n        .arg(old)\n        .arg(\"--update=older\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(old), \"new content\\n\");\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_existing_file_truncated() {\n    // Set up test if needed (eg. after failure)\n    let fname = \"this-file-exists-truncated.txt\";\n    let fpath = fixture_path!(fname);\n    match fpath.metadata() {\n        Ok(m) if m.len() == 256 => {}\n        _ => build_test_file!(&fpath, &vec![0; 256]),\n    }\n\n    let (fix, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"status=none\", \"if=null.txt\", of!(fname)])\n        .run()\n        .no_stdout()\n        .no_stderr()\n        .success();\n\n    assert_eq!(0, fix.metadata(fname).len());\n}"}
{"code": "pub fn undefined_behavior(&self) -> UndefinedBehavior {\n        self.env.undefined_behavior()\n    }", "test": "fn test_lenient_undefined() {\n    let mut env = Environment::new();\n    env.add_filter(\"test\", |state: &State, value: String| -> String {\n        assert_eq!(state.undefined_behavior(), UndefinedBehavior::Lenient);\n        assert_eq!(value, \"\");\n        value\n    });\n\n    assert_eq!(env.undefined_behavior(), UndefinedBehavior::Lenient);\n    assert_eq!(render!(in env, \"<{{ true.missing_attribute }}>\"), \"<>\");\n    assert_eq!(\n        env.render_str(\"{{ undefined.missing_attribute }}\", ())\n            .unwrap_err()\n            .kind(),\n        ErrorKind::UndefinedError\n    );\n    assert_eq!(\n        render!(in env, \"<{% for x in undefined %}...{% endfor %}>\"),\n        \"<>\"\n    );\n    assert_eq!(render!(in env, \"<{{ undefined }}>\"), \"<>\");\n    assert_eq!(render!(in env, \"{{ undefined is undefined }}\"), \"true\");\n    assert_eq!(render!(in env, \"{{ undefined|list }}\"), \"[]\");\n    assert_eq!(render!(in env, \"<{{ undefined|test }}>\"), \"<>\");\n    assert_eq!(render!(in env, \"{{ 42 in undefined }}\"), \"false\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_region_split() {\n    let cluster = new_server_cluster(1, 1);\n    cluster.pd_client.disable_default_operator();\n    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();\n\n    let region = suite.cluster.get_region(&[]);\n    let mut req = suite.new_changedata_request(region.get_id());\n    let (mut req_tx, event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(region.get_id()));\n    block_on(req_tx.send((req.clone(), WriteFlags::default()))).unwrap();\n    // Make sure region 1 is registered.\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1);\n    match events.pop().unwrap().event.unwrap() {\n        // Even if there is no write,\n        // it should always outputs an Initialized event.\n        Event_oneof_event::Entries(es) => {\n            assert!(es.entries.len() == 1, \"{:?}\", es);\n            let e = &es.entries[0];\n            assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n    // Split region.\n    suite.cluster.must_split(&region, b\"k0\");\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1);\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Error(err) => {\n            assert!(err.has_epoch_not_match(), \"{:?}\", err);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n    // Try to subscribe region again.\n    let region = suite.cluster.get_region(b\"k0\");\n    // Ensure it is the previous region.\n    assert_eq!(req.get_region_id(), region.get_id());\n    req.set_region_epoch(region.get_region_epoch().clone());\n    block_on(req_tx.send((req.clone(), WriteFlags::default()))).unwrap();\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1);\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Entries(es) => {\n            assert!(es.entries.len() == 1, \"{:?}\", es);\n            let e = &es.entries[0];\n            assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    // Try to subscribe region again.\n    let region1 = suite.cluster.get_region(&[]);\n    req.region_id = region1.get_id();\n    req.set_region_epoch(region1.get_region_epoch().clone());\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1);\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Entries(es) => {\n            assert!(es.entries.len() == 1, \"{:?}\", es);\n            let e = &es.entries[0];\n            assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    // Make sure resolved ts can be advanced normally.\n    let mut counter = 0;\n    let mut previous_ts = 0;\n    loop {\n        // Even if there is no write,\n        // resolved ts should be advanced regularly.\n        let event = receive_event(true);\n        if let Some(resolved_ts) = event.resolved_ts.as_ref() {\n            assert!(resolved_ts.ts >= previous_ts);\n            assert!(\n                resolved_ts.regions == vec![region.id, region1.id]\n                    || resolved_ts.regions == vec![region1.id, region.id]\n            );\n            previous_ts = resolved_ts.ts;\n            counter += 1;\n        }\n        if counter > 5 {\n            break;\n        }\n    }\n\n    event_feed_wrap.replace(None);\n    suite.stop();\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_existing_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_existing_file\";\n    let link = \"test_symlink_existing_file_link\";\n\n    at.touch(file);\n\n    ucmd.args(&[\"-s\", file, link]).succeeds().no_stderr();\n\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n}"}
{"code": "pub fn is_public_assigned(c: char) -> bool {\n    match c {\n        '\\u{0000}'..='\\u{0377}'\n        | '\\u{037A}'..='\\u{037F}'\n        | '\\u{0384}'..='\\u{038A}'\n        | '\\u{038C}'\n        | '\\u{038E}'..='\\u{03A1}'\n        | '\\u{03A3}'..='\\u{052F}'\n        | '\\u{0531}'..='\\u{0556}'\n        | '\\u{0559}'..='\\u{058A}'\n        | '\\u{058D}'..='\\u{058F}'\n        | '\\u{0591}'..='\\u{05C7}'\n        | '\\u{05D0}'..='\\u{05EA}'\n        | '\\u{05EF}'..='\\u{05F4}'\n        | '\\u{0600}'..='\\u{070D}'\n        | '\\u{070F}'..='\\u{074A}'\n        | '\\u{074D}'..='\\u{07B1}'\n        | '\\u{07C0}'..='\\u{07FA}'\n        | '\\u{07FD}'..='\\u{082D}'\n        | '\\u{0830}'..='\\u{083E}'\n        | '\\u{0840}'..='\\u{085B}'\n        | '\\u{085E}'\n        | '\\u{0860}'..='\\u{086A}'\n        | '\\u{0870}'..='\\u{088E}'\n        | '\\u{0890}'..='\\u{0891}'\n        | '\\u{0898}'..='\\u{0983}'\n        | '\\u{0985}'..='\\u{098C}'\n        | '\\u{098F}'..='\\u{0990}'\n        | '\\u{0993}'..='\\u{09A8}'\n        | '\\u{09AA}'..='\\u{09B0}'\n        | '\\u{09B2}'\n        | '\\u{09B6}'..='\\u{09B9}'\n        | '\\u{09BC}'..='\\u{09C4}'\n        | '\\u{09C7}'..='\\u{09C8}'\n        | '\\u{09CB}'..='\\u{09CE}'\n        | '\\u{09D7}'\n        | '\\u{09DC}'..='\\u{09DD}'\n        | '\\u{09DF}'..='\\u{09E3}'\n        | '\\u{09E6}'..='\\u{09FE}'\n        | '\\u{0A01}'..='\\u{0A03}'\n        | '\\u{0A05}'..='\\u{0A0A}'\n        | '\\u{0A0F}'..='\\u{0A10}'\n        | '\\u{0A13}'..='\\u{0A28}'\n        | '\\u{0A2A}'..='\\u{0A30}'\n        | '\\u{0A32}'..='\\u{0A33}'\n        | '\\u{0A35}'..='\\u{0A36}'\n        | '\\u{0A38}'..='\\u{0A39}'\n        | '\\u{0A3C}'\n        | '\\u{0A3E}'..='\\u{0A42}'\n        | '\\u{0A47}'..='\\u{0A48}'\n        | '\\u{0A4B}'..='\\u{0A4D}'\n        | '\\u{0A51}'\n        | '\\u{0A59}'..='\\u{0A5C}'\n        | '\\u{0A5E}'\n        | '\\u{0A66}'..='\\u{0A76}'\n        | '\\u{0A81}'..='\\u{0A83}'\n        | '\\u{0A85}'..='\\u{0A8D}'\n        | '\\u{0A8F}'..='\\u{0A91}'\n        | '\\u{0A93}'..='\\u{0AA8}'\n        | '\\u{0AAA}'..='\\u{0AB0}'\n        | '\\u{0AB2}'..='\\u{0AB3}'\n        | '\\u{0AB5}'..='\\u{0AB9}'\n        | '\\u{0ABC}'..='\\u{0AC5}'\n        | '\\u{0AC7}'..='\\u{0AC9}'\n        | '\\u{0ACB}'..='\\u{0ACD}'\n        | '\\u{0AD0}'\n        | '\\u{0AE0}'..='\\u{0AE3}'\n        | '\\u{0AE6}'..='\\u{0AF1}'\n        | '\\u{0AF9}'..='\\u{0AFF}'\n        | '\\u{0B01}'..='\\u{0B03}'\n        | '\\u{0B05}'..='\\u{0B0C}'\n        | '\\u{0B0F}'..='\\u{0B10}'\n        | '\\u{0B13}'..='\\u{0B28}'\n        | '\\u{0B2A}'..='\\u{0B30}'\n        | '\\u{0B32}'..='\\u{0B33}'\n        | '\\u{0B35}'..='\\u{0B39}'\n        | '\\u{0B3C}'..='\\u{0B44}'\n        | '\\u{0B47}'..='\\u{0B48}'\n        | '\\u{0B4B}'..='\\u{0B4D}'\n        | '\\u{0B55}'..='\\u{0B57}'\n        | '\\u{0B5C}'..='\\u{0B5D}'\n        | '\\u{0B5F}'..='\\u{0B63}'\n        | '\\u{0B66}'..='\\u{0B77}'\n        | '\\u{0B82}'..='\\u{0B83}'\n        | '\\u{0B85}'..='\\u{0B8A}'\n        | '\\u{0B8E}'..='\\u{0B90}'\n        | '\\u{0B92}'..='\\u{0B95}'\n        | '\\u{0B99}'..='\\u{0B9A}'\n        | '\\u{0B9C}'\n        | '\\u{0B9E}'..='\\u{0B9F}'\n        | '\\u{0BA3}'..='\\u{0BA4}'\n        | '\\u{0BA8}'..='\\u{0BAA}'\n        | '\\u{0BAE}'..='\\u{0BB9}'\n        | '\\u{0BBE}'..='\\u{0BC2}'\n        | '\\u{0BC6}'..='\\u{0BC8}'\n        | '\\u{0BCA}'..='\\u{0BCD}'\n        | '\\u{0BD0}'\n        | '\\u{0BD7}'\n        | '\\u{0BE6}'..='\\u{0BFA}'\n        | '\\u{0C00}'..='\\u{0C0C}'\n        | '\\u{0C0E}'..='\\u{0C10}'\n        | '\\u{0C12}'..='\\u{0C28}'\n        | '\\u{0C2A}'..='\\u{0C39}'\n        | '\\u{0C3C}'..='\\u{0C44}'\n        | '\\u{0C46}'..='\\u{0C48}'\n        | '\\u{0C4A}'..='\\u{0C4D}'\n        | '\\u{0C55}'..='\\u{0C56}'\n        | '\\u{0C58}'..='\\u{0C5A}'\n        | '\\u{0C5D}'\n        | '\\u{0C60}'..='\\u{0C63}'\n        | '\\u{0C66}'..='\\u{0C6F}'\n        | '\\u{0C77}'..='\\u{0C8C}'\n        | '\\u{0C8E}'..='\\u{0C90}'\n        | '\\u{0C92}'..='\\u{0CA8}'\n        | '\\u{0CAA}'..='\\u{0CB3}'\n        | '\\u{0CB5}'..='\\u{0CB9}'\n        | '\\u{0CBC}'..='\\u{0CC4}'\n        | '\\u{0CC6}'..='\\u{0CC8}'\n        | '\\u{0CCA}'..='\\u{0CCD}'\n        | '\\u{0CD5}'..='\\u{0CD6}'\n        | '\\u{0CDD}'..='\\u{0CDE}'\n        | '\\u{0CE0}'..='\\u{0CE3}'\n        | '\\u{0CE6}'..='\\u{0CEF}'\n        | '\\u{0CF1}'..='\\u{0CF3}'\n        | '\\u{0D00}'..='\\u{0D0C}'\n        | '\\u{0D0E}'..='\\u{0D10}'\n        | '\\u{0D12}'..='\\u{0D44}'\n        | '\\u{0D46}'..='\\u{0D48}'\n        | '\\u{0D4A}'..='\\u{0D4F}'\n        | '\\u{0D54}'..='\\u{0D63}'\n        | '\\u{0D66}'..='\\u{0D7F}'\n        | '\\u{0D81}'..='\\u{0D83}'\n        | '\\u{0D85}'..='\\u{0D96}'\n        | '\\u{0D9A}'..='\\u{0DB1}'\n        | '\\u{0DB3}'..='\\u{0DBB}'\n        | '\\u{0DBD}'\n        | '\\u{0DC0}'..='\\u{0DC6}'\n        | '\\u{0DCA}'\n        | '\\u{0DCF}'..='\\u{0DD4}'\n        | '\\u{0DD6}'\n        | '\\u{0DD8}'..='\\u{0DDF}'\n        | '\\u{0DE6}'..='\\u{0DEF}'\n        | '\\u{0DF2}'..='\\u{0DF4}'\n        | '\\u{0E01}'..='\\u{0E3A}'\n        | '\\u{0E3F}'..='\\u{0E5B}'\n        | '\\u{0E81}'..='\\u{0E82}'\n        | '\\u{0E84}'\n        | '\\u{0E86}'..='\\u{0E8A}'\n        | '\\u{0E8C}'..='\\u{0EA3}'\n        | '\\u{0EA5}'\n        | '\\u{0EA7}'..='\\u{0EBD}'\n        | '\\u{0EC0}'..='\\u{0EC4}'\n        | '\\u{0EC6}'\n        | '\\u{0EC8}'..='\\u{0ECE}'\n        | '\\u{0ED0}'..='\\u{0ED9}'\n        | '\\u{0EDC}'..='\\u{0EDF}'\n        | '\\u{0F00}'..='\\u{0F47}'\n        | '\\u{0F49}'..='\\u{0F6C}'\n        | '\\u{0F71}'..='\\u{0F97}'\n        | '\\u{0F99}'..='\\u{0FBC}'\n        | '\\u{0FBE}'..='\\u{0FCC}'\n        | '\\u{0FCE}'..='\\u{0FDA}'\n        | '\\u{1000}'..='\\u{10C5}'\n        | '\\u{10C7}'\n        | '\\u{10CD}'\n        | '\\u{10D0}'..='\\u{1248}'\n        | '\\u{124A}'..='\\u{124D}'\n        | '\\u{1250}'..='\\u{1256}'\n        | '\\u{1258}'\n        | '\\u{125A}'..='\\u{125D}'\n        | '\\u{1260}'..='\\u{1288}'\n        | '\\u{128A}'..='\\u{128D}'\n        | '\\u{1290}'..='\\u{12B0}'\n        | '\\u{12B2}'..='\\u{12B5}'\n        | '\\u{12B8}'..='\\u{12BE}'\n        | '\\u{12C0}'\n        | '\\u{12C2}'..='\\u{12C5}'\n        | '\\u{12C8}'..='\\u{12D6}'\n        | '\\u{12D8}'..='\\u{1310}'\n        | '\\u{1312}'..='\\u{1315}'\n        | '\\u{1318}'..='\\u{135A}'\n        | '\\u{135D}'..='\\u{137C}'\n        | '\\u{1380}'..='\\u{1399}'\n        | '\\u{13A0}'..='\\u{13F5}'\n        | '\\u{13F8}'..='\\u{13FD}'\n        | '\\u{1400}'..='\\u{169C}'\n        | '\\u{16A0}'..='\\u{16F8}'\n        | '\\u{1700}'..='\\u{1715}'\n        | '\\u{171F}'..='\\u{1736}'\n        | '\\u{1740}'..='\\u{1753}'\n        | '\\u{1760}'..='\\u{176C}'\n        | '\\u{176E}'..='\\u{1770}'\n        | '\\u{1772}'..='\\u{1773}'\n        | '\\u{1780}'..='\\u{17DD}'\n        | '\\u{17E0}'..='\\u{17E9}'\n        | '\\u{17F0}'..='\\u{17F9}'\n        | '\\u{1800}'..='\\u{1819}'\n        | '\\u{1820}'..='\\u{1878}'\n        | '\\u{1880}'..='\\u{18AA}'\n        | '\\u{18B0}'..='\\u{18F5}'\n        | '\\u{1900}'..='\\u{191E}'\n        | '\\u{1920}'..='\\u{192B}'\n        | '\\u{1930}'..='\\u{193B}'\n        | '\\u{1940}'\n        | '\\u{1944}'..='\\u{196D}'\n        | '\\u{1970}'..='\\u{1974}'\n        | '\\u{1980}'..='\\u{19AB}'\n        | '\\u{19B0}'..='\\u{19C9}'\n        | '\\u{19D0}'..='\\u{19DA}'\n        | '\\u{19DE}'..='\\u{1A1B}'\n        | '\\u{1A1E}'..='\\u{1A5E}'\n        | '\\u{1A60}'..='\\u{1A7C}'\n        | '\\u{1A7F}'..='\\u{1A89}'\n        | '\\u{1A90}'..='\\u{1A99}'\n        | '\\u{1AA0}'..='\\u{1AAD}'\n        | '\\u{1AB0}'..='\\u{1ACE}'\n        | '\\u{1B00}'..='\\u{1B4C}'\n        | '\\u{1B50}'..='\\u{1B7E}'\n        | '\\u{1B80}'..='\\u{1BF3}'\n        | '\\u{1BFC}'..='\\u{1C37}'\n        | '\\u{1C3B}'..='\\u{1C49}'\n        | '\\u{1C4D}'..='\\u{1C88}'\n        | '\\u{1C90}'..='\\u{1CBA}'\n        | '\\u{1CBD}'..='\\u{1CC7}'\n        | '\\u{1CD0}'..='\\u{1CFA}'\n        | '\\u{1D00}'..='\\u{1F15}'\n        | '\\u{1F18}'..='\\u{1F1D}'\n        | '\\u{1F20}'..='\\u{1F45}'\n        | '\\u{1F48}'..='\\u{1F4D}'\n        | '\\u{1F50}'..='\\u{1F57}'\n        | '\\u{1F59}'\n        | '\\u{1F5B}'\n        | '\\u{1F5D}'\n        | '\\u{1F5F}'..='\\u{1F7D}'\n        | '\\u{1F80}'..='\\u{1FB4}'\n        | '\\u{1FB6}'..='\\u{1FC4}'\n        | '\\u{1FC6}'..='\\u{1FD3}'\n        | '\\u{1FD6}'..='\\u{1FDB}'\n        | '\\u{1FDD}'..='\\u{1FEF}'\n        | '\\u{1FF2}'..='\\u{1FF4}'\n        | '\\u{1FF6}'..='\\u{1FFE}'\n        | '\\u{2000}'..='\\u{2064}'\n        | '\\u{2066}'..='\\u{2071}'\n        | '\\u{2074}'..='\\u{208E}'\n        | '\\u{2090}'..='\\u{209C}'\n        | '\\u{20A0}'..='\\u{20C0}'\n        | '\\u{20D0}'..='\\u{20F0}'\n        | '\\u{2100}'..='\\u{218B}'\n        | '\\u{2190}'..='\\u{2426}'\n        | '\\u{2440}'..='\\u{244A}'\n        | '\\u{2460}'..='\\u{2B73}'\n        | '\\u{2B76}'..='\\u{2B95}'\n        | '\\u{2B97}'..='\\u{2CF3}'\n        | '\\u{2CF9}'..='\\u{2D25}'\n        | '\\u{2D27}'\n        | '\\u{2D2D}'\n        | '\\u{2D30}'..='\\u{2D67}'\n        | '\\u{2D6F}'..='\\u{2D70}'\n        | '\\u{2D7F}'..='\\u{2D96}'\n        | '\\u{2DA0}'..='\\u{2DA6}'\n        | '\\u{2DA8}'..='\\u{2DAE}'\n        | '\\u{2DB0}'..='\\u{2DB6}'\n        | '\\u{2DB8}'..='\\u{2DBE}'\n        | '\\u{2DC0}'..='\\u{2DC6}'\n        | '\\u{2DC8}'..='\\u{2DCE}'\n        | '\\u{2DD0}'..='\\u{2DD6}'\n        | '\\u{2DD8}'..='\\u{2DDE}'\n        | '\\u{2DE0}'..='\\u{2E5D}'\n        | '\\u{2E80}'..='\\u{2E99}'\n        | '\\u{2E9B}'..='\\u{2EF3}'\n        | '\\u{2F00}'..='\\u{2FD5}'\n        | '\\u{2FF0}'..='\\u{2FFB}'\n        | '\\u{3000}'..='\\u{303F}'\n        | '\\u{3041}'..='\\u{3096}'\n        | '\\u{3099}'..='\\u{30FF}'\n        | '\\u{3105}'..='\\u{312F}'\n        | '\\u{3131}'..='\\u{318E}'\n        | '\\u{3190}'..='\\u{31E3}'\n        | '\\u{31F0}'..='\\u{321E}'\n        | '\\u{3220}'..='\\u{A48C}'\n        | '\\u{A490}'..='\\u{A4C6}'\n        | '\\u{A4D0}'..='\\u{A62B}'\n        | '\\u{A640}'..='\\u{A6F7}'\n        | '\\u{A700}'..='\\u{A7CA}'\n        | '\\u{A7D0}'..='\\u{A7D1}'\n        | '\\u{A7D3}'\n        | '\\u{A7D5}'..='\\u{A7D9}'\n        | '\\u{A7F2}'..='\\u{A82C}'\n        | '\\u{A830}'..='\\u{A839}'\n        | '\\u{A840}'..='\\u{A877}'\n        | '\\u{A880}'..='\\u{A8C5}'\n        | '\\u{A8CE}'..='\\u{A8D9}'\n        | '\\u{A8E0}'..='\\u{A953}'\n        | '\\u{A95F}'..='\\u{A97C}'\n        | '\\u{A980}'..='\\u{A9CD}'\n        | '\\u{A9CF}'..='\\u{A9D9}'\n        | '\\u{A9DE}'..='\\u{A9FE}'\n        | '\\u{AA00}'..='\\u{AA36}'\n        | '\\u{AA40}'..='\\u{AA4D}'\n        | '\\u{AA50}'..='\\u{AA59}'\n        | '\\u{AA5C}'..='\\u{AAC2}'\n        | '\\u{AADB}'..='\\u{AAF6}'\n        | '\\u{AB01}'..='\\u{AB06}'\n        | '\\u{AB09}'..='\\u{AB0E}'\n        | '\\u{AB11}'..='\\u{AB16}'\n        | '\\u{AB20}'..='\\u{AB26}'\n        | '\\u{AB28}'..='\\u{AB2E}'\n        | '\\u{AB30}'..='\\u{AB6B}'\n        | '\\u{AB70}'..='\\u{ABED}'\n        | '\\u{ABF0}'..='\\u{ABF9}'\n        | '\\u{AC00}'..='\\u{D7A3}'\n        | '\\u{D7B0}'..='\\u{D7C6}'\n        | '\\u{D7CB}'..='\\u{D7FB}'\n        | '\\u{F900}'..='\\u{FA6D}'\n        | '\\u{FA70}'..='\\u{FAD9}'\n        | '\\u{FB00}'..='\\u{FB06}'\n        | '\\u{FB13}'..='\\u{FB17}'\n        | '\\u{FB1D}'..='\\u{FB36}'\n        | '\\u{FB38}'..='\\u{FB3C}'\n        | '\\u{FB3E}'\n        | '\\u{FB40}'..='\\u{FB41}'\n        | '\\u{FB43}'..='\\u{FB44}'\n        | '\\u{FB46}'..='\\u{FBC2}'\n        | '\\u{FBD3}'..='\\u{FD8F}'\n        | '\\u{FD92}'..='\\u{FDC7}'\n        | '\\u{FDCF}'\n        | '\\u{FDF0}'..='\\u{FE19}'\n        | '\\u{FE20}'..='\\u{FE52}'\n        | '\\u{FE54}'..='\\u{FE66}'\n        | '\\u{FE68}'..='\\u{FE6B}'\n        | '\\u{FE70}'..='\\u{FE74}'\n        | '\\u{FE76}'..='\\u{FEFC}'\n        | '\\u{FEFF}'\n        | '\\u{FF01}'..='\\u{FFBE}'\n        | '\\u{FFC2}'..='\\u{FFC7}'\n        | '\\u{FFCA}'..='\\u{FFCF}'\n        | '\\u{FFD2}'..='\\u{FFD7}'\n        | '\\u{FFDA}'..='\\u{FFDC}'\n        | '\\u{FFE0}'..='\\u{FFE6}'\n        | '\\u{FFE8}'..='\\u{FFEE}'\n        | '\\u{FFF9}'..='\\u{FFFD}'\n        | '\\u{10000}'..='\\u{1000B}'\n        | '\\u{1000D}'..='\\u{10026}'\n        | '\\u{10028}'..='\\u{1003A}'\n        | '\\u{1003C}'..='\\u{1003D}'\n        | '\\u{1003F}'..='\\u{1004D}'\n        | '\\u{10050}'..='\\u{1005D}'\n        | '\\u{10080}'..='\\u{100FA}'\n        | '\\u{10100}'..='\\u{10102}'\n        | '\\u{10107}'..='\\u{10133}'\n        | '\\u{10137}'..='\\u{1018E}'\n        | '\\u{10190}'..='\\u{1019C}'\n        | '\\u{101A0}'\n        | '\\u{101D0}'..='\\u{101FD}'\n        | '\\u{10280}'..='\\u{1029C}'\n        | '\\u{102A0}'..='\\u{102D0}'\n        | '\\u{102E0}'..='\\u{102FB}'\n        | '\\u{10300}'..='\\u{10323}'\n        | '\\u{1032D}'..='\\u{1034A}'\n        | '\\u{10350}'..='\\u{1037A}'\n        | '\\u{10380}'..='\\u{1039D}'\n        | '\\u{1039F}'..='\\u{103C3}'\n        | '\\u{103C8}'..='\\u{103D5}'\n        | '\\u{10400}'..='\\u{1049D}'\n        | '\\u{104A0}'..='\\u{104A9}'\n        | '\\u{104B0}'..='\\u{104D3}'\n        | '\\u{104D8}'..='\\u{104FB}'\n        | '\\u{10500}'..='\\u{10527}'\n        | '\\u{10530}'..='\\u{10563}'\n        | '\\u{1056F}'..='\\u{1057A}'\n        | '\\u{1057C}'..='\\u{1058A}'\n        | '\\u{1058C}'..='\\u{10592}'\n        | '\\u{10594}'..='\\u{10595}'\n        | '\\u{10597}'..='\\u{105A1}'\n        | '\\u{105A3}'..='\\u{105B1}'\n        | '\\u{105B3}'..='\\u{105B9}'\n        | '\\u{105BB}'..='\\u{105BC}'\n        | '\\u{10600}'..='\\u{10736}'\n        | '\\u{10740}'..='\\u{10755}'\n        | '\\u{10760}'..='\\u{10767}'\n        | '\\u{10780}'..='\\u{10785}'\n        | '\\u{10787}'..='\\u{107B0}'\n        | '\\u{107B2}'..='\\u{107BA}'\n        | '\\u{10800}'..='\\u{10805}'\n        | '\\u{10808}'\n        | '\\u{1080A}'..='\\u{10835}'\n        | '\\u{10837}'..='\\u{10838}'\n        | '\\u{1083C}'\n        | '\\u{1083F}'..='\\u{10855}'\n        | '\\u{10857}'..='\\u{1089E}'\n        | '\\u{108A7}'..='\\u{108AF}'\n        | '\\u{108E0}'..='\\u{108F2}'\n        | '\\u{108F4}'..='\\u{108F5}'\n        | '\\u{108FB}'..='\\u{1091B}'\n        | '\\u{1091F}'..='\\u{10939}'\n        | '\\u{1093F}'\n        | '\\u{10980}'..='\\u{109B7}'\n        | '\\u{109BC}'..='\\u{109CF}'\n        | '\\u{109D2}'..='\\u{10A03}'\n        | '\\u{10A05}'..='\\u{10A06}'\n        | '\\u{10A0C}'..='\\u{10A13}'\n        | '\\u{10A15}'..='\\u{10A17}'\n        | '\\u{10A19}'..='\\u{10A35}'\n        | '\\u{10A38}'..='\\u{10A3A}'\n        | '\\u{10A3F}'..='\\u{10A48}'\n        | '\\u{10A50}'..='\\u{10A58}'\n        | '\\u{10A60}'..='\\u{10A9F}'\n        | '\\u{10AC0}'..='\\u{10AE6}'\n        | '\\u{10AEB}'..='\\u{10AF6}'\n        | '\\u{10B00}'..='\\u{10B35}'\n        | '\\u{10B39}'..='\\u{10B55}'\n        | '\\u{10B58}'..='\\u{10B72}'\n        | '\\u{10B78}'..='\\u{10B91}'\n        | '\\u{10B99}'..='\\u{10B9C}'\n        | '\\u{10BA9}'..='\\u{10BAF}'\n        | '\\u{10C00}'..='\\u{10C48}'\n        | '\\u{10C80}'..='\\u{10CB2}'\n        | '\\u{10CC0}'..='\\u{10CF2}'\n        | '\\u{10CFA}'..='\\u{10D27}'\n        | '\\u{10D30}'..='\\u{10D39}'\n        | '\\u{10E60}'..='\\u{10E7E}'\n        | '\\u{10E80}'..='\\u{10EA9}'\n        | '\\u{10EAB}'..='\\u{10EAD}'\n        | '\\u{10EB0}'..='\\u{10EB1}'\n        | '\\u{10EFD}'..='\\u{10F27}'\n        | '\\u{10F30}'..='\\u{10F59}'\n        | '\\u{10F70}'..='\\u{10F89}'\n        | '\\u{10FB0}'..='\\u{10FCB}'\n        | '\\u{10FE0}'..='\\u{10FF6}'\n        | '\\u{11000}'..='\\u{1104D}'\n        | '\\u{11052}'..='\\u{11075}'\n        | '\\u{1107F}'..='\\u{110C2}'\n        | '\\u{110CD}'\n        | '\\u{110D0}'..='\\u{110E8}'\n        | '\\u{110F0}'..='\\u{110F9}'\n        | '\\u{11100}'..='\\u{11134}'\n        | '\\u{11136}'..='\\u{11147}'\n        | '\\u{11150}'..='\\u{11176}'\n        | '\\u{11180}'..='\\u{111DF}'\n        | '\\u{111E1}'..='\\u{111F4}'\n        | '\\u{11200}'..='\\u{11211}'\n        | '\\u{11213}'..='\\u{11241}'\n        | '\\u{11280}'..='\\u{11286}'\n        | '\\u{11288}'\n        | '\\u{1128A}'..='\\u{1128D}'\n        | '\\u{1128F}'..='\\u{1129D}'\n        | '\\u{1129F}'..='\\u{112A9}'\n        | '\\u{112B0}'..='\\u{112EA}'\n        | '\\u{112F0}'..='\\u{112F9}'\n        | '\\u{11300}'..='\\u{11303}'\n        | '\\u{11305}'..='\\u{1130C}'\n        | '\\u{1130F}'..='\\u{11310}'\n        | '\\u{11313}'..='\\u{11328}'\n        | '\\u{1132A}'..='\\u{11330}'\n        | '\\u{11332}'..='\\u{11333}'\n        | '\\u{11335}'..='\\u{11339}'\n        | '\\u{1133B}'..='\\u{11344}'\n        | '\\u{11347}'..='\\u{11348}'\n        | '\\u{1134B}'..='\\u{1134D}'\n        | '\\u{11350}'\n        | '\\u{11357}'\n        | '\\u{1135D}'..='\\u{11363}'\n        | '\\u{11366}'..='\\u{1136C}'\n        | '\\u{11370}'..='\\u{11374}'\n        | '\\u{11400}'..='\\u{1145B}'\n        | '\\u{1145D}'..='\\u{11461}'\n        | '\\u{11480}'..='\\u{114C7}'\n        | '\\u{114D0}'..='\\u{114D9}'\n        | '\\u{11580}'..='\\u{115B5}'\n        | '\\u{115B8}'..='\\u{115DD}'\n        | '\\u{11600}'..='\\u{11644}'\n        | '\\u{11650}'..='\\u{11659}'\n        | '\\u{11660}'..='\\u{1166C}'\n        | '\\u{11680}'..='\\u{116B9}'\n        | '\\u{116C0}'..='\\u{116C9}'\n        | '\\u{11700}'..='\\u{1171A}'\n        | '\\u{1171D}'..='\\u{1172B}'\n        | '\\u{11730}'..='\\u{11746}'\n        | '\\u{11800}'..='\\u{1183B}'\n        | '\\u{118A0}'..='\\u{118F2}'\n        | '\\u{118FF}'..='\\u{11906}'\n        | '\\u{11909}'\n        | '\\u{1190C}'..='\\u{11913}'\n        | '\\u{11915}'..='\\u{11916}'\n        | '\\u{11918}'..='\\u{11935}'\n        | '\\u{11937}'..='\\u{11938}'\n        | '\\u{1193B}'..='\\u{11946}'\n        | '\\u{11950}'..='\\u{11959}'\n        | '\\u{119A0}'..='\\u{119A7}'\n        | '\\u{119AA}'..='\\u{119D7}'\n        | '\\u{119DA}'..='\\u{119E4}'\n        | '\\u{11A00}'..='\\u{11A47}'\n        | '\\u{11A50}'..='\\u{11AA2}'\n        | '\\u{11AB0}'..='\\u{11AF8}'\n        | '\\u{11B00}'..='\\u{11B09}'\n        | '\\u{11C00}'..='\\u{11C08}'\n        | '\\u{11C0A}'..='\\u{11C36}'\n        | '\\u{11C38}'..='\\u{11C45}'\n        | '\\u{11C50}'..='\\u{11C6C}'\n        | '\\u{11C70}'..='\\u{11C8F}'\n        | '\\u{11C92}'..='\\u{11CA7}'\n        | '\\u{11CA9}'..='\\u{11CB6}'\n        | '\\u{11D00}'..='\\u{11D06}'\n        | '\\u{11D08}'..='\\u{11D09}'\n        | '\\u{11D0B}'..='\\u{11D36}'\n        | '\\u{11D3A}'\n        | '\\u{11D3C}'..='\\u{11D3D}'\n        | '\\u{11D3F}'..='\\u{11D47}'\n        | '\\u{11D50}'..='\\u{11D59}'\n        | '\\u{11D60}'..='\\u{11D65}'\n        | '\\u{11D67}'..='\\u{11D68}'\n        | '\\u{11D6A}'..='\\u{11D8E}'\n        | '\\u{11D90}'..='\\u{11D91}'\n        | '\\u{11D93}'..='\\u{11D98}'\n        | '\\u{11DA0}'..='\\u{11DA9}'\n        | '\\u{11EE0}'..='\\u{11EF8}'\n        | '\\u{11F00}'..='\\u{11F10}'\n        | '\\u{11F12}'..='\\u{11F3A}'\n        | '\\u{11F3E}'..='\\u{11F59}'\n        | '\\u{11FB0}'\n        | '\\u{11FC0}'..='\\u{11FF1}'\n        | '\\u{11FFF}'..='\\u{12399}'\n        | '\\u{12400}'..='\\u{1246E}'\n        | '\\u{12470}'..='\\u{12474}'\n        | '\\u{12480}'..='\\u{12543}'\n        | '\\u{12F90}'..='\\u{12FF2}'\n        | '\\u{13000}'..='\\u{13455}'\n        | '\\u{14400}'..='\\u{14646}'\n        | '\\u{16800}'..='\\u{16A38}'\n        | '\\u{16A40}'..='\\u{16A5E}'\n        | '\\u{16A60}'..='\\u{16A69}'\n        | '\\u{16A6E}'..='\\u{16ABE}'\n        | '\\u{16AC0}'..='\\u{16AC9}'\n        | '\\u{16AD0}'..='\\u{16AED}'\n        | '\\u{16AF0}'..='\\u{16AF5}'\n        | '\\u{16B00}'..='\\u{16B45}'\n        | '\\u{16B50}'..='\\u{16B59}'\n        | '\\u{16B5B}'..='\\u{16B61}'\n        | '\\u{16B63}'..='\\u{16B77}'\n        | '\\u{16B7D}'..='\\u{16B8F}'\n        | '\\u{16E40}'..='\\u{16E9A}'\n        | '\\u{16F00}'..='\\u{16F4A}'\n        | '\\u{16F4F}'..='\\u{16F87}'\n        | '\\u{16F8F}'..='\\u{16F9F}'\n        | '\\u{16FE0}'..='\\u{16FE4}'\n        | '\\u{16FF0}'..='\\u{16FF1}'\n        | '\\u{17000}'..='\\u{187F7}'\n        | '\\u{18800}'..='\\u{18CD5}'\n        | '\\u{18D00}'..='\\u{18D08}'\n        | '\\u{1AFF0}'..='\\u{1AFF3}'\n        | '\\u{1AFF5}'..='\\u{1AFFB}'\n        | '\\u{1AFFD}'..='\\u{1AFFE}'\n        | '\\u{1B000}'..='\\u{1B122}'\n        | '\\u{1B132}'\n        | '\\u{1B150}'..='\\u{1B152}'\n        | '\\u{1B155}'\n        | '\\u{1B164}'..='\\u{1B167}'\n        | '\\u{1B170}'..='\\u{1B2FB}'\n        | '\\u{1BC00}'..='\\u{1BC6A}'\n        | '\\u{1BC70}'..='\\u{1BC7C}'\n        | '\\u{1BC80}'..='\\u{1BC88}'\n        | '\\u{1BC90}'..='\\u{1BC99}'\n        | '\\u{1BC9C}'..='\\u{1BCA3}'\n        | '\\u{1CF00}'..='\\u{1CF2D}'\n        | '\\u{1CF30}'..='\\u{1CF46}'\n        | '\\u{1CF50}'..='\\u{1CFC3}'\n        | '\\u{1D000}'..='\\u{1D0F5}'\n        | '\\u{1D100}'..='\\u{1D126}'\n        | '\\u{1D129}'..='\\u{1D1EA}'\n        | '\\u{1D200}'..='\\u{1D245}'\n        | '\\u{1D2C0}'..='\\u{1D2D3}'\n        | '\\u{1D2E0}'..='\\u{1D2F3}'\n        | '\\u{1D300}'..='\\u{1D356}'\n        | '\\u{1D360}'..='\\u{1D378}'\n        | '\\u{1D400}'..='\\u{1D454}'\n        | '\\u{1D456}'..='\\u{1D49C}'\n        | '\\u{1D49E}'..='\\u{1D49F}'\n        | '\\u{1D4A2}'\n        | '\\u{1D4A5}'..='\\u{1D4A6}'\n        | '\\u{1D4A9}'..='\\u{1D4AC}'\n        | '\\u{1D4AE}'..='\\u{1D4B9}'\n        | '\\u{1D4BB}'\n        | '\\u{1D4BD}'..='\\u{1D4C3}'\n        | '\\u{1D4C5}'..='\\u{1D505}'\n        | '\\u{1D507}'..='\\u{1D50A}'\n        | '\\u{1D50D}'..='\\u{1D514}'\n        | '\\u{1D516}'..='\\u{1D51C}'\n        | '\\u{1D51E}'..='\\u{1D539}'\n        | '\\u{1D53B}'..='\\u{1D53E}'\n        | '\\u{1D540}'..='\\u{1D544}'\n        | '\\u{1D546}'\n        | '\\u{1D54A}'..='\\u{1D550}'\n        | '\\u{1D552}'..='\\u{1D6A5}'\n        | '\\u{1D6A8}'..='\\u{1D7CB}'\n        | '\\u{1D7CE}'..='\\u{1DA8B}'\n        | '\\u{1DA9B}'..='\\u{1DA9F}'\n        | '\\u{1DAA1}'..='\\u{1DAAF}'\n        | '\\u{1DF00}'..='\\u{1DF1E}'\n        | '\\u{1DF25}'..='\\u{1DF2A}'\n        | '\\u{1E000}'..='\\u{1E006}'\n        | '\\u{1E008}'..='\\u{1E018}'\n        | '\\u{1E01B}'..='\\u{1E021}'\n        | '\\u{1E023}'..='\\u{1E024}'\n        | '\\u{1E026}'..='\\u{1E02A}'\n        | '\\u{1E030}'..='\\u{1E06D}'\n        | '\\u{1E08F}'\n        | '\\u{1E100}'..='\\u{1E12C}'\n        | '\\u{1E130}'..='\\u{1E13D}'\n        | '\\u{1E140}'..='\\u{1E149}'\n        | '\\u{1E14E}'..='\\u{1E14F}'\n        | '\\u{1E290}'..='\\u{1E2AE}'\n        | '\\u{1E2C0}'..='\\u{1E2F9}'\n        | '\\u{1E2FF}'\n        | '\\u{1E4D0}'..='\\u{1E4F9}'\n        | '\\u{1E7E0}'..='\\u{1E7E6}'\n        | '\\u{1E7E8}'..='\\u{1E7EB}'\n        | '\\u{1E7ED}'..='\\u{1E7EE}'\n        | '\\u{1E7F0}'..='\\u{1E7FE}'\n        | '\\u{1E800}'..='\\u{1E8C4}'\n        | '\\u{1E8C7}'..='\\u{1E8D6}'\n        | '\\u{1E900}'..='\\u{1E94B}'\n        | '\\u{1E950}'..='\\u{1E959}'\n        | '\\u{1E95E}'..='\\u{1E95F}'\n        | '\\u{1EC71}'..='\\u{1ECB4}'\n        | '\\u{1ED01}'..='\\u{1ED3D}'\n        | '\\u{1EE00}'..='\\u{1EE03}'\n        | '\\u{1EE05}'..='\\u{1EE1F}'\n        | '\\u{1EE21}'..='\\u{1EE22}'\n        | '\\u{1EE24}'\n        | '\\u{1EE27}'\n        | '\\u{1EE29}'..='\\u{1EE32}'\n        | '\\u{1EE34}'..='\\u{1EE37}'\n        | '\\u{1EE39}'\n        | '\\u{1EE3B}'\n        | '\\u{1EE42}'\n        | '\\u{1EE47}'\n        | '\\u{1EE49}'\n        | '\\u{1EE4B}'\n        | '\\u{1EE4D}'..='\\u{1EE4F}'\n        | '\\u{1EE51}'..='\\u{1EE52}'\n        | '\\u{1EE54}'\n        | '\\u{1EE57}'\n        | '\\u{1EE59}'\n        | '\\u{1EE5B}'\n        | '\\u{1EE5D}'\n        | '\\u{1EE5F}'\n        | '\\u{1EE61}'..='\\u{1EE62}'\n        | '\\u{1EE64}'\n        | '\\u{1EE67}'..='\\u{1EE6A}'\n        | '\\u{1EE6C}'..='\\u{1EE72}'\n        | '\\u{1EE74}'..='\\u{1EE77}'\n        | '\\u{1EE79}'..='\\u{1EE7C}'\n        | '\\u{1EE7E}'\n        | '\\u{1EE80}'..='\\u{1EE89}'\n        | '\\u{1EE8B}'..='\\u{1EE9B}'\n        | '\\u{1EEA1}'..='\\u{1EEA3}'\n        | '\\u{1EEA5}'..='\\u{1EEA9}'\n        | '\\u{1EEAB}'..='\\u{1EEBB}'\n        | '\\u{1EEF0}'..='\\u{1EEF1}'\n        | '\\u{1F000}'..='\\u{1F02B}'\n        | '\\u{1F030}'..='\\u{1F093}'\n        | '\\u{1F0A0}'..='\\u{1F0AE}'\n        | '\\u{1F0B1}'..='\\u{1F0BF}'\n        | '\\u{1F0C1}'..='\\u{1F0CF}'\n        | '\\u{1F0D1}'..='\\u{1F0F5}'\n        | '\\u{1F100}'..='\\u{1F1AD}'\n        | '\\u{1F1E6}'..='\\u{1F202}'\n        | '\\u{1F210}'..='\\u{1F23B}'\n        | '\\u{1F240}'..='\\u{1F248}'\n        | '\\u{1F250}'..='\\u{1F251}'\n        | '\\u{1F260}'..='\\u{1F265}'\n        | '\\u{1F300}'..='\\u{1F6D7}'\n        | '\\u{1F6DC}'..='\\u{1F6EC}'\n        | '\\u{1F6F0}'..='\\u{1F6FC}'\n        | '\\u{1F700}'..='\\u{1F776}'\n        | '\\u{1F77B}'..='\\u{1F7D9}'\n        | '\\u{1F7E0}'..='\\u{1F7EB}'\n        | '\\u{1F7F0}'\n        | '\\u{1F800}'..='\\u{1F80B}'\n        | '\\u{1F810}'..='\\u{1F847}'\n        | '\\u{1F850}'..='\\u{1F859}'\n        | '\\u{1F860}'..='\\u{1F887}'\n        | '\\u{1F890}'..='\\u{1F8AD}'\n        | '\\u{1F8B0}'..='\\u{1F8B1}'\n        | '\\u{1F900}'..='\\u{1FA53}'\n        | '\\u{1FA60}'..='\\u{1FA6D}'\n        | '\\u{1FA70}'..='\\u{1FA7C}'\n        | '\\u{1FA80}'..='\\u{1FA88}'\n        | '\\u{1FA90}'..='\\u{1FABD}'\n        | '\\u{1FABF}'..='\\u{1FAC5}'\n        | '\\u{1FACE}'..='\\u{1FADB}'\n        | '\\u{1FAE0}'..='\\u{1FAE8}'\n        | '\\u{1FAF0}'..='\\u{1FAF8}'\n        | '\\u{1FB00}'..='\\u{1FB92}'\n        | '\\u{1FB94}'..='\\u{1FBCA}'\n        | '\\u{1FBF0}'..='\\u{1FBF9}'\n        | '\\u{20000}'..='\\u{2A6DF}'\n        | '\\u{2A700}'..='\\u{2B739}'\n        | '\\u{2B740}'..='\\u{2B81D}'\n        | '\\u{2B820}'..='\\u{2CEA1}'\n        | '\\u{2CEB0}'..='\\u{2EBE0}'\n        | '\\u{2F800}'..='\\u{2FA1D}'\n        | '\\u{30000}'..='\\u{3134A}'\n        | '\\u{31350}'..='\\u{323AF}'\n        | '\\u{E0001}'\n        | '\\u{E0020}'..='\\u{E007F}'\n        | '\\u{E0100}'..='\\u{E01EF}'\n        => true,\n        _ => false,\n    }\n}", "test": "fn test_public_assigned() {\n    // Misc assigned.\n    assert!(is_public_assigned('\\0'));\n    assert!(is_public_assigned('a'));\n    assert!(is_public_assigned('\\u{7f}'));\n    assert!(is_public_assigned('\\u{80}'));\n    assert!(!is_public_assigned('\\u{9e4}'));\n\n    // Around the first unassigned non-private-use.\n    assert!(is_public_assigned('\\u{377}'));\n    assert!(!is_public_assigned('\\u{378}'));\n    assert!(!is_public_assigned('\\u{379}'));\n    assert!(is_public_assigned('\\u{37a}'));\n    assert!(is_public_assigned('\\u{37f}'));\n\n    // Around the last assigned non-private-use.\n    assert!(!is_public_assigned('\\u{e00ff}'));\n    assert!(is_public_assigned('\\u{e0100}'));\n    assert!(is_public_assigned('\\u{e01ef}'));\n    assert!(!is_public_assigned('\\u{e01f0}'));\n\n    // Private-Use areas\n    assert!(!is_public_assigned('\\u{e000}'));\n    assert!(!is_public_assigned('\\u{f8ff}'));\n    assert!(!is_public_assigned('\\u{f0000}'));\n    assert!(!is_public_assigned('\\u{ffffd}'));\n    assert!(!is_public_assigned('\\u{100000}'));\n    assert!(!is_public_assigned('\\u{10fffd}'));\n\n    // Noncharacters are considered unassigned.\n    assert!(!is_public_assigned('\\u{fdd0}'));\n    assert!(!is_public_assigned('\\u{fdef}'));\n    assert!(!is_public_assigned('\\u{fffe}'));\n    assert!(!is_public_assigned('\\u{ffff}'));\n    assert!(!is_public_assigned('\\u{1fffe}'));\n    assert!(!is_public_assigned('\\u{1ffff}'));\n    assert!(!is_public_assigned('\\u{2fffe}'));\n    assert!(!is_public_assigned('\\u{2ffff}'));\n    assert!(!is_public_assigned('\\u{3fffe}'));\n    assert!(!is_public_assigned('\\u{3ffff}'));\n    assert!(!is_public_assigned('\\u{4fffe}'));\n    assert!(!is_public_assigned('\\u{4ffff}'));\n    assert!(!is_public_assigned('\\u{5fffe}'));\n    assert!(!is_public_assigned('\\u{5ffff}'));\n    assert!(!is_public_assigned('\\u{6fffe}'));\n    assert!(!is_public_assigned('\\u{6ffff}'));\n    assert!(!is_public_assigned('\\u{7fffe}'));\n    assert!(!is_public_assigned('\\u{7ffff}'));\n    assert!(!is_public_assigned('\\u{8fffe}'));\n    assert!(!is_public_assigned('\\u{8ffff}'));\n    assert!(!is_public_assigned('\\u{9fffe}'));\n    assert!(!is_public_assigned('\\u{9ffff}'));\n    assert!(!is_public_assigned('\\u{afffe}'));\n    assert!(!is_public_assigned('\\u{affff}'));\n    assert!(!is_public_assigned('\\u{bfffe}'));\n    assert!(!is_public_assigned('\\u{bffff}'));\n    assert!(!is_public_assigned('\\u{cfffe}'));\n    assert!(!is_public_assigned('\\u{cffff}'));\n    assert!(!is_public_assigned('\\u{dfffe}'));\n    assert!(!is_public_assigned('\\u{dffff}'));\n    assert!(!is_public_assigned('\\u{efffe}'));\n    assert!(!is_public_assigned('\\u{effff}'));\n    assert!(!is_public_assigned('\\u{ffffe}'));\n    assert!(!is_public_assigned('\\u{fffff}'));\n    assert!(!is_public_assigned('\\u{10fffe}'));\n    assert!(!is_public_assigned('\\u{10ffff}'));\n\n    // Several ranges are defined by \"<..., First>\" and \"<..., Last>\" pairs in\n    // UnicodeData.txt:\n\n    // CJK Ideograph Extension A\n    assert!(is_public_assigned('\\u{3400}'));\n    assert!(is_public_assigned('\\u{4dbf}'));\n\n    // CJK Ideograph\n    assert!(is_public_assigned('\\u{4e00}'));\n    assert!(is_public_assigned('\\u{9ffc}'));\n\n    // Hangul Syllable\n    assert!(is_public_assigned('\\u{ac00}'));\n    assert!(is_public_assigned('\\u{d7a3}'));\n\n    // Tangut Ideograph\n    assert!(is_public_assigned('\\u{17000}'));\n    assert!(is_public_assigned('\\u{187f7}'));\n\n    // Tangut Ideograph Supplement\n    assert!(is_public_assigned('\\u{18d00}'));\n    assert!(is_public_assigned('\\u{18d08}'));\n\n    // CJK Ideograph Extension B\n    assert!(is_public_assigned('\\u{20000}'));\n    assert!(is_public_assigned('\\u{2a6dd}'));\n\n    // CJK Ideograph Extension C\n    assert!(is_public_assigned('\\u{2a700}'));\n    assert!(is_public_assigned('\\u{2b734}'));\n\n    // CJK Ideograph Extension D\n    assert!(is_public_assigned('\\u{2b740}'));\n    assert!(is_public_assigned('\\u{2b81d}'));\n\n    // CJK Ideograph Extension E\n    assert!(is_public_assigned('\\u{2b820}'));\n    assert!(is_public_assigned('\\u{2cea1}'));\n\n    // CJK Ideograph Extension F\n    assert!(is_public_assigned('\\u{2ceb0}'));\n    assert!(is_public_assigned('\\u{2ebe0}'));\n\n    // CJK Ideograph Extension G\n    assert!(is_public_assigned('\\u{30000}'));\n    assert!(is_public_assigned('\\u{3134a}'));\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        match self {\n            #[cfg(not(unix))]\n            Self::Stdin(stdin) => stdin.read(buf),\n            Self::File(f) => f.read(buf),\n            #[cfg(unix)]\n            Self::StdinFile(f) => f.read(buf),\n            #[cfg(unix)]\n            Self::Fifo(f) => f.read(buf),\n        }\n    }", "test": "fn test_write_to_self() {\n    let s = TestScenario::new(util_name!());\n    let file_path = s.fixtures.plus(\"first_file\");\n    s.fixtures.write(\"second_file\", \"second_file_content.\");\n\n    let file = OpenOptions::new()\n        .create_new(true)\n        .write(true)\n        .append(true)\n        .open(file_path)\n        .unwrap();\n\n    s.fixtures.append(\"first_file\", \"first_file_content.\");\n\n    s.ucmd()\n        .set_stdout(file)\n        .arg(\"first_file\")\n        .arg(\"first_file\")\n        .arg(\"second_file\")\n        .fails()\n        .code_is(2)\n        .stderr_only(\"cat: first_file: input file is output file\\ncat: first_file: input file is output file\\n\");\n\n    assert_eq!(\n        s.fixtures.read(\"first_file\"),\n        \"first_file_content.second_file_content.\"\n    );\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_integer128_to_value() {\n    let signed = &[i128::from(i64::min_value()), i128::from(u64::max_value())];\n    let unsigned = &[0, u128::from(u64::max_value())];\n\n    for integer128 in signed {\n        let expected = integer128.to_string();\n        assert_eq!(to_value(integer128).unwrap().to_string(), expected);\n    }\n\n    for integer128 in unsigned {\n        let expected = integer128.to_string();\n        assert_eq!(to_value(integer128).unwrap().to_string(), expected);\n    }\n\n    if !cfg!(feature = \"arbitrary_precision\") {\n        let err = to_value(u128::from(u64::max_value()) + 1).unwrap_err();\n        assert_eq!(err.to_string(), \"number out of range\");\n    }\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_integer128_key() {\n    let map = treemap! {\n        100000000000000000000000000000000000000u128 => (),\n    };\n    let j = r#\"{\"100000000000000000000000000000000000000\":null}\"#;\n    assert_eq!(to_string(&map).unwrap(), j);\n    assert_eq!(from_str::<BTreeMap<u128, ()>>(j).unwrap(), map);\n}"}
{"code": "pub fn info(&self) -> Option<ImageInfo> {\n        match self.frame {\n            Some(ref frame) => {\n                let pixel_format = match frame.components.len() {\n                    1 => match frame.precision {\n                        8 => PixelFormat::L8,\n                        16 => PixelFormat::L16,\n                        _ => panic!(),\n                    },\n                    3 => PixelFormat::RGB24,\n                    4 => PixelFormat::CMYK32,\n                    _ => panic!(),\n                };\n\n                Some(ImageInfo {\n                    width: frame.output_size.width,\n                    height: frame.output_size.height,\n                    pixel_format,\n                    coding_process: frame.coding_process,\n                })\n            }\n            None => None,\n        }\n    }", "test": "fn read_info() {\n    let path = Path::new(\"tests\").join(\"reftest\").join(\"images\").join(\"mozilla\").join(\"jpg-progressive.jpg\");\n\n    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());\n    let ref_data = decoder.decode().unwrap();\n    let ref_info = decoder.info().unwrap();\n\n    decoder = jpeg::Decoder::new(File::open(&path).unwrap());\n    decoder.read_info().unwrap();\n    let info = decoder.info().unwrap();\n    let data = decoder.decode().unwrap();\n\n    assert_eq!(info, decoder.info().unwrap());\n    assert_eq!(info, ref_info);\n    assert_eq!(data, ref_data);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_custom_backup_suffix_hyphen_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_custom_backup_suffix_file_a\";\n    let file_b = \"test_mv_custom_backup_suffix_file_b\";\n    let suffix = \"-v\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"-b\")\n        .arg(format!(\"--suffix={suffix}\"))\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}{suffix}\")));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_numbered_with_t() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=t\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~1~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_hostname() {\n    let ls_default_res = new_ucmd!().succeeds();\n    let ls_short_res = new_ucmd!().arg(\"-s\").succeeds();\n    let ls_domain_res = new_ucmd!().arg(\"-d\").succeeds();\n\n    assert!(ls_default_res.stdout().len() >= ls_short_res.stdout().len());\n    assert!(ls_default_res.stdout().len() >= ls_domain_res.stdout().len());\n}"}
{"code": "pub fn owned(&self) -> bool {\n        match self.state.load(Relaxed) {\n            BORROW => false,\n            _ => true,\n        }\n    }", "test": "fn drop_on_owned_resource() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n                (import \"[constructor]t\" (func $ctor (result (own $t))))\n                (import \"[method]t.foo\" (func $foo (param \"self\" (borrow $t)) (result (list u8))))\n\n                (core func $ctor (canon lower (func $ctor)))\n                (core func $drop (canon resource.drop $t))\n\n                (core module $m1\n                    (import \"\" \"drop\" (func $drop (param i32)))\n                    (memory (export \"memory\") 1)\n                    (global $to-drop (export \"to-drop\") (mut i32) (i32.const 0))\n                    (func (export \"realloc\") (param i32 i32 i32 i32) (result i32)\n                        (call $drop (global.get $to-drop))\n                        unreachable)\n                )\n                (core instance $i1 (instantiate $m1\n                    (with \"\" (instance\n                        (export \"drop\" (func $drop))\n                    ))\n                ))\n\n                (core func $foo (canon lower (func $foo)\n                    (memory $i1 \"memory\")\n                    (realloc (func $i1 \"realloc\"))))\n\n                (core module $m2\n                    (import \"\" \"ctor\" (func $ctor (result i32)))\n                    (import \"\" \"foo\" (func $foo (param i32 i32)))\n                    (import \"i1\" \"to-drop\" (global $to-drop (mut i32)))\n\n                    (func (export \"f\")\n                        (local $r i32)\n                        (local.set $r (call $ctor))\n                        (global.set $to-drop (local.get $r))\n                        (call $foo\n                            (local.get $r)\n                            (i32.const 200))\n                    )\n                )\n                (core instance $i2 (instantiate $m2\n                    (with \"\" (instance\n                        (export \"ctor\" (func $ctor))\n                        (export \"foo\" (func $foo))\n                    ))\n                    (with \"i1\" (instance $i1))\n                ))\n                (func (export \"f\") (canon lift (core func $i2 \"f\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n    linker.root().func_wrap(\"[constructor]t\", |_cx, ()| {\n        Ok((Resource::<MyType>::new_own(300),))\n    })?;\n    linker\n        .root()\n        .func_wrap(\"[method]t.foo\", |_cx, (r,): (Resource<MyType>,)| {\n            assert!(!r.owned());\n            Ok((vec![2u8],))\n        })?;\n    let i = linker.instantiate(&mut store, &c)?;\n    let f = i.get_typed_func::<(), ()>(&mut store, \"f\")?;\n\n    let err = f.call(&mut store, ()).unwrap_err();\n    assert!(\n        format!(\"{err:?}\").contains(\"cannot remove owned resource while borrowed\"),\n        \"bad error: {err:?}\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn get_item_by_index(&self, idx: usize) -> Result<Value, Error> {\n        self.get_item(&Value(ValueRepr::U64(idx as _)))\n    }", "test": "fn test_value_by_index() {\n    let val = Value::from(vec![1u32, 2, 3]);\n    assert_eq!(val.get_item_by_index(0).unwrap(), Value::from(1));\n    assert!(val.get_item_by_index(4).unwrap().is_undefined());\n}"}
{"code": "pub fn apply_filter(&self, filter: &str, args: &[Value]) -> Result<Value, Error> {\n        match self.env.get_filter(filter) {\n            Some(filter) => filter.apply_to(self, args),\n            None => Err(Error::from(ErrorKind::UnknownFilter)),\n        }\n    }", "test": "fn test_seq_object_borrow() {\n    fn connect(values: &dyn SeqObject) -> String {\n        let mut rv = String::new();\n        for item in values.iter() {\n            rv.push_str(&item.to_string())\n        }\n        rv\n    }\n\n    let mut env = Environment::new();\n    env.add_filter(\"connect\", connect);\n    let state = env.empty_state();\n    assert_eq!(\n        state\n            .apply_filter(\n                \"connect\",\n                args!(vec![Value::from(\"HELLO\"), Value::from(42)])\n            )\n            .unwrap(),\n        Value::from(\"HELLO42\")\n    );\n}"}
{"code": "fn partial_cmp(&self, other: &Self) -> Option<cmp::Ordering> {\n        Some(bigint::compare(self, other))\n    }", "test": "fn cmp_test() {\n    // Simple\n    let x = VecType::from_u64(1);\n    let y = VecType::from_u64(2);\n    assert_eq!(x.partial_cmp(&x), Some(cmp::Ordering::Equal));\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Less);\n\n    // Check asymmetric\n    let x = VecType::try_from(&[5, 1]).unwrap();\n    let y = VecType::from_u64(2);\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n\n    // Check when we use reverse ordering properly.\n    let x = VecType::try_from(&[5, 1, 9]).unwrap();\n    let y = VecType::try_from(&[6, 2, 8]).unwrap();\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n\n    // Complex scenario, check it properly uses reverse ordering.\n    let x = VecType::try_from(&[0, 1, 9]).unwrap();\n    let y = VecType::try_from(&[4294967295, 0, 9]).unwrap();\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n}"}
{"code": "pub fn apply_filter(&self, filter: &str, args: &[Value]) -> Result<Value, Error> {\n        match self.env.get_filter(filter) {\n            Some(filter) => filter.apply_to(self, args),\n            None => Err(Error::from(ErrorKind::UnknownFilter)),\n        }\n    }", "test": "fn test_rest_args() {\n    fn sum(val: u32, rest: Rest<u32>) -> u32 {\n        rest.iter().fold(val, |a, b| a + b)\n    }\n\n    let mut env = Environment::new();\n    env.add_filter(\"sum\", sum);\n    assert_eq!(\n        env.empty_state()\n            .apply_filter(\"sum\", args!(1, 2, 3, 4))\n            .unwrap(),\n        Value::from(1 + 2 + 3 + 4)\n    );\n}"}
{"code": "fn hi64(&self) -> (u64, bool) {\n        match self.as_ref().len() {\n            0 => (0, false),\n            1 => self.hi64_1(),\n            2 => self.hi64_2(),\n            _ => self.hi64_3(),\n        }\n    }", "test": "fn hi64_test() {\n    assert_eq!(Bigint::from_u64(0xA).hi64(), (0xA000000000000000, false));\n    assert_eq!(Bigint::from_u64(0xAB).hi64(), (0xAB00000000000000, false));\n    assert_eq!(\n        Bigint::from_u64(0xAB00000000).hi64(),\n        (0xAB00000000000000, false)\n    );\n    assert_eq!(\n        Bigint::from_u64(0xA23456789A).hi64(),\n        (0xA23456789A000000, false)\n    );\n}"}
{"code": "pub fn display<'a>(&'a self, params: Option<&'a FunctionParameters>) -> String {\n        match self {\n            FinalizedRelocTarget::ExternalName(name) => format!(\"{}\", name.display(params)),\n            FinalizedRelocTarget::Func(offset) => format!(\"func+{offset}\"),\n        }\n    }", "test": "fn run_coredump_smoketest() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/coredump_smoketest.wat\")?;\n    let coredump_file = NamedTempFile::new()?;\n    let coredump_arg = format!(\"-Dcoredump={}\", coredump_file.path().display());\n    let err = run_wasmtime(&[\n        \"run\",\n        \"--invoke\",\n        \"a\",\n        \"-Ccache=n\",\n        &coredump_arg,\n        wasm.path().to_str().unwrap(),\n    ])\n    .unwrap_err();\n    assert!(err.to_string().contains(&format!(\n        \"core dumped at {}\",\n        coredump_file.path().display()\n    )));\n    Ok(())\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_create_multi() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n    let record = record;\n\n    let mut record2 = record.clone();\n    record2.set_data(Some(RData::A(A::new(100, 10, 100, 11))));\n    let record2 = record2;\n\n    let mut rrset = RecordSet::from(record.clone());\n    rrset.insert(record2.clone(), 0);\n    let rrset = rrset;\n\n    let result = io_loop\n        .block_on(client.create(rrset.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    let result = io_loop\n        .block_on(client.query(\n            record.name().clone(),\n            record.dns_class(),\n            record.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 2);\n\n    assert!(result.answers().iter().any(|rr| *rr == record));\n    assert!(result.answers().iter().any(|rr| *rr == record2));\n\n    // trying to create again should error\n    // TODO: it would be cool to make this\n    let result = io_loop\n        .block_on(client.create(rrset, origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n\n    // will fail if already set and not the same value.\n    let mut record = record;\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 12))));\n\n    let result = io_loop\n        .block_on(client.create(record, origin))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn total_core_instances_limit() -> Result<()> {\n    const INSTANCE_LIMIT: u32 = 10;\n    let mut pool = crate::small_pool_config();\n    pool.total_core_instances(INSTANCE_LIMIT);\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, r#\"(module)\"#)?;\n\n    // Instantiate to the limit\n    {\n        let mut store = Store::new(&engine, ());\n\n        for _ in 0..INSTANCE_LIMIT {\n            Instance::new(&mut store, &module, &[])?;\n        }\n\n        match Instance::new(&mut store, &module, &[]) {\n            Ok(_) => panic!(\"instantiation should fail\"),\n            Err(e) => assert_eq!(\n                e.to_string(),\n                format!(\n                    \"maximum concurrent core instance limit of {} reached\",\n                    INSTANCE_LIMIT\n                )\n            ),\n        }\n    }\n\n    // With the above store dropped, ensure instantiations can be made\n\n    let mut store = Store::new(&engine, ());\n\n    for _ in 0..INSTANCE_LIMIT {\n        Instance::new(&mut store, &module, &[])?;\n    }\n\n    Ok(())\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_combined_file_set_unset() {\n    let out = new_ucmd!()\n        .arg(\"-u\")\n        .arg(\"BAR\")\n        .arg(\"-f\")\n        .arg(\"vars.conf.txt\")\n        .arg(\"FOO=bar.alt\")\n        .succeeds()\n        .stdout_move_str();\n\n    assert_eq!(\n        out.lines()\n            .filter(|&line| line == \"FOO=bar.alt\" || line.starts_with(\"BAR=\"))\n            .count(),\n        1\n    );\n}"}
{"code": "pub const fn decimal() -> u128 {\n        let mut builder = Self::new();\n        builder.mantissa_radix = 10;\n        builder.exponent_base = num::NonZeroU8::new(10);\n        builder.exponent_radix = num::NonZeroU8::new(10);\n        builder.build()\n    }", "test": "fn u32toa_test() {\n    let mut buffer = [b'\\x00'; 16];\n    unsafe {\n        assert_eq!(5u32.decimal(&mut buffer), 1);\n        assert_eq!(&buffer[..1], b\"5\");\n\n        assert_eq!(11u32.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"11\");\n\n        assert_eq!(99u32.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"99\");\n\n        assert_eq!(101u32.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"101\");\n\n        assert_eq!(999u32.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"999\");\n\n        assert_eq!(1001u32.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"1001\");\n\n        assert_eq!(9999u32.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"9999\");\n\n        assert_eq!(10001u32.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"10001\");\n\n        assert_eq!(65535u32.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"65535\");\n\n        assert_eq!(99999u32.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"99999\");\n\n        assert_eq!(100001u32.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"100001\");\n\n        assert_eq!(999999u32.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"999999\");\n\n        assert_eq!(1000001u32.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"1000001\");\n\n        assert_eq!(9999999u32.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"9999999\");\n\n        assert_eq!(10000001u32.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"10000001\");\n\n        assert_eq!(99999999u32.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"99999999\");\n\n        assert_eq!(100000001u32.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"100000001\");\n\n        assert_eq!(999999999u32.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"999999999\");\n\n        assert_eq!(1000000001u32.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"1000000001\");\n\n        assert_eq!(4294967295u32.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"4294967295\");\n    }\n}"}
{"code": "pub fn is_inline(&self) -> bool {\n    !self.is_heap()\n  }", "test": "fn TinyVec_std_io_write() {\n  use std::io::Write;\n  let mut tv: TinyVec<[u8; 3]> = TinyVec::new();\n\n  tv.write_all(b\"foo\").ok();\n  assert!(tv.is_inline());\n  assert_eq!(tv, tiny_vec![b'f', b'o', b'o']);\n\n  tv.write_all(b\"bar\").ok();\n  assert!(tv.is_heap());\n  assert_eq!(tv, tiny_vec![b'f', b'o', b'o', b'b', b'a', b'r']);\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_only_owner_colon() {\n    // test chown username: file.txt\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    let file1 = \"test_chown_file1\";\n    at.touch(file1);\n\n    scene\n        .ucmd()\n        .arg(format!(\"{user_name}:\"))\n        .arg(\"--verbose\")\n        .arg(file1)\n        .succeeds()\n        .stderr_contains(\"retained as\");\n\n    scene\n        .ucmd()\n        .arg(format!(\"{user_name}.\"))\n        .arg(\"--verbose\")\n        .arg(file1)\n        .succeeds()\n        .stderr_contains(\"retained as\");\n\n    scene\n        .ucmd()\n        .arg(\"root:\")\n        .arg(\"--verbose\")\n        .arg(file1)\n        .fails()\n        .stderr_contains(\"failed to change\");\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn attempt_to_leave_during_malloc() -> Result<()> {\n    let component = r#\"\n(component\n  (import \"thunk\" (func $thunk))\n  (import \"ret-string\" (func $ret_string (result string)))\n\n  (core module $host_shim\n    (table (export \"table\") 2 funcref)\n    (func $shim_thunk (export \"thunk\")\n      i32.const 0\n      call_indirect)\n    (func $shim_ret_string (export \"ret-string\") (param i32)\n      local.get 0\n      i32.const 1\n      call_indirect (param i32))\n  )\n  (core instance $host_shim (instantiate $host_shim))\n\n  (core module $m\n    (import \"host\" \"thunk\" (func $thunk))\n    (import \"host\" \"ret-string\" (func $ret_string (param i32)))\n\n    (memory (export \"memory\") 1)\n\n    (func $realloc (export \"realloc\") (param i32 i32 i32 i32) (result i32)\n      call $thunk\n      unreachable)\n\n    (func $run (export \"run\")\n      i32.const 8\n      call $ret_string)\n\n    (func (export \"take-string\") (param i32 i32)\n        unreachable)\n  )\n  (core instance $m (instantiate $m (with \"host\" (instance $host_shim))))\n\n  (core module $host_shim_filler_inner\n    (import \"shim\" \"table\" (table 2 funcref))\n    (import \"host\" \"thunk\" (func $thunk))\n    (import \"host\" \"ret-string\" (func $ret_string (param i32)))\n    (elem (i32.const 0) $thunk $ret_string)\n  )\n\n  (core func $thunk_lower\n    (canon lower (func $thunk) (memory $m \"memory\") (realloc (func $m \"realloc\")))\n  )\n\n  (core func $ret_string_lower\n    (canon lower (func $ret_string) (memory $m \"memory\") (realloc (func $m \"realloc\")))\n  )\n\n  (core instance (instantiate $host_shim_filler_inner\n    (with \"shim\" (instance $host_shim))\n    (with \"host\" (instance\n      (export \"thunk\" (func $thunk_lower))\n      (export \"ret-string\" (func $ret_string_lower))\n    ))\n  ))\n\n  (func (export \"run\")\n    (canon lift (core func $m \"run\"))\n  )\n  (func (export \"take-string\") (param \"a\" string)\n    (canon lift (core func $m \"take-string\") (memory $m \"memory\") (realloc (func $m \"realloc\")))\n  )\n)\n    \"#;\n\n    let engine = super::engine();\n    let mut linker = Linker::new(&engine);\n    linker.root().func_wrap(\"thunk\", |_, _: ()| -> Result<()> {\n        panic!(\"should not get here\")\n    })?;\n    linker\n        .root()\n        .func_wrap(\"ret-string\", |_, _: ()| -> Result<_> {\n            Ok((\"hello\".to_string(),))\n        })?;\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n\n    // Assert that during a host import if we return values to wasm that a trap\n    // happens if we try to leave the instance.\n    let trap = linker\n        .instantiate(&mut store, &component)?\n        .get_typed_func::<(), ()>(&mut store, \"run\")?\n        .call(&mut store, ())\n        .unwrap_err();\n    assert!(\n        format!(\"{trap:?}\").contains(\"cannot leave component instance\"),\n        \"bad trap: {trap:?}\",\n    );\n\n    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    assert_eq!(trace.len(), 4);\n\n    // This was our entry point...\n    assert_eq!(trace[3].module().name(), Some(\"m\"));\n    assert_eq!(trace[3].func_name(), Some(\"run\"));\n\n    // ... which called an imported function which ends up being originally\n    // defined by the shim instance. The shim instance then does an indirect\n    // call through a table which goes to the `canon.lower`'d host function\n    assert_eq!(trace[2].module().name(), Some(\"host_shim\"));\n    assert_eq!(trace[2].func_name(), Some(\"shim_ret_string\"));\n\n    // ... and the lowered host function will call realloc to allocate space for\n    // the result\n    assert_eq!(trace[1].module().name(), Some(\"m\"));\n    assert_eq!(trace[1].func_name(), Some(\"realloc\"));\n\n    // ... but realloc calls the shim instance and tries to exit the\n    // component, triggering a dynamic trap\n    assert_eq!(trace[0].module().name(), Some(\"host_shim\"));\n    assert_eq!(trace[0].func_name(), Some(\"shim_thunk\"));\n\n    // In addition to the above trap also ensure that when we enter a wasm\n    // component if we try to leave while lowering then that's also a dynamic\n    // trap.\n    let trap = linker\n        .instantiate(&mut store, &component)?\n        .get_typed_func::<(&str,), ()>(&mut store, \"take-string\")?\n        .call(&mut store, (\"x\",))\n        .unwrap_err();\n    assert!(\n        format!(\"{trap:?}\").contains(\"cannot leave component instance\"),\n        \"bad trap: {trap:?}\",\n    );\n    Ok(())\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_null_delimiter() {\n    let out = new_ucmd!()\n        .arg(\"-i\")\n        .arg(\"--null\")\n        .arg(\"FOO=bar\")\n        .arg(\"ABC=xyz\")\n        .succeeds()\n        .stdout_move_str();\n\n    let mut vars: Vec<_> = out.split('\\0').collect();\n    assert_eq!(vars.len(), 3);\n    vars.sort_unstable();\n    assert_eq!(vars[0], \"\");\n    assert_eq!(vars[1], \"ABC=xyz\");\n    assert_eq!(vars[2], \"FOO=bar\");\n}"}
{"code": "pub const fn flags(&self) -> u128 {\n        FORMAT & flags::FLAG_MASK\n    }", "test": "fn ignore_test() {\n    let fmt = format::NumberFormat::<{ format::IGNORE }> {};\n    assert_eq!(fmt.flags(), format::DIGIT_SEPARATOR_FLAG_MASK);\n    assert_eq!(fmt.digit_separator(), b'_');\n    assert_eq!(fmt.required_integer_digits(), false);\n    assert_eq!(fmt.required_fraction_digits(), false);\n    assert_eq!(fmt.required_exponent_digits(), false);\n    assert_eq!(fmt.required_mantissa_digits(), false);\n    assert_eq!(fmt.required_digits(), false);\n    assert_eq!(fmt.no_positive_mantissa_sign(), false);\n    assert_eq!(fmt.required_mantissa_sign(), false);\n    assert_eq!(fmt.no_exponent_notation(), false);\n    assert_eq!(fmt.no_positive_exponent_sign(), false);\n    assert_eq!(fmt.required_exponent_sign(), false);\n    assert_eq!(fmt.no_exponent_without_fraction(), false);\n    assert_eq!(fmt.no_special(), false);\n    assert_eq!(fmt.case_sensitive_special(), false);\n    assert_eq!(fmt.no_integer_leading_zeros(), false);\n    assert_eq!(fmt.no_float_leading_zeros(), false);\n    assert_eq!(fmt.required_exponent_notation(), false);\n    assert_eq!(fmt.case_sensitive_exponent(), false);\n    #[cfg(feature = \"power-of-two\")]\n    assert_eq!(fmt.case_sensitive_base_prefix(), false);\n    #[cfg(feature = \"power-of-two\")]\n    assert_eq!(fmt.case_sensitive_base_suffix(), false);\n    assert_eq!(fmt.integer_internal_digit_separator(), true);\n    assert_eq!(fmt.fraction_internal_digit_separator(), true);\n    assert_eq!(fmt.exponent_internal_digit_separator(), true);\n    assert_eq!(fmt.internal_digit_separator(), true);\n    assert_eq!(fmt.integer_leading_digit_separator(), true);\n    assert_eq!(fmt.fraction_leading_digit_separator(), true);\n    assert_eq!(fmt.exponent_leading_digit_separator(), true);\n    assert_eq!(fmt.leading_digit_separator(), true);\n    assert_eq!(fmt.integer_trailing_digit_separator(), true);\n    assert_eq!(fmt.fraction_trailing_digit_separator(), true);\n    assert_eq!(fmt.exponent_trailing_digit_separator(), true);\n    assert_eq!(fmt.trailing_digit_separator(), true);\n    assert_eq!(fmt.integer_consecutive_digit_separator(), true);\n    assert_eq!(fmt.fraction_consecutive_digit_separator(), true);\n    assert_eq!(fmt.exponent_consecutive_digit_separator(), true);\n    assert_eq!(fmt.consecutive_digit_separator(), true);\n    assert_eq!(fmt.special_digit_separator(), true);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_arg_backup_arg_first() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_simple_backup_file_a\";\n    let file_b = \"test_mv_simple_backup_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup\").arg(file_a).arg(file_b).succeeds();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn bad_text_syntax() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .arg(\"-Ccache=n\")\n        .arg(\"tests/all/cli_tests/bad-syntax.wat\")\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"--> tests/all/cli_tests/bad-syntax.wat\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn ref_get_signatures() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(SLICE_TABLE).unwrap();\n        for i in 0..10u8 {\n            table.insert([i].as_slice(), [i + 1].as_slice()).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(SLICE_TABLE).unwrap();\n\n    let zero = vec![0u8];\n    assert_eq!(&[1], table.get([0].as_slice()).unwrap().unwrap().value());\n    assert_eq!(&[1], table.get(b\"\\0\".as_slice()).unwrap().unwrap().value());\n    assert_eq!(&[1], table.get(zero.as_slice()).unwrap().unwrap().value());\n\n    let start = vec![0u8];\n    let end = vec![10u8];\n    let mut iter = table.range::<&[u8]>(..).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), &[i + 1]);\n    }\n    assert!(iter.next().is_none());\n\n    let mut iter = table.range(start.as_slice()..&end).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), &[i + 1]);\n    }\n    assert!(iter.next().is_none());\n    drop(iter);\n\n    let mut iter = table.range(start.as_slice()..end.as_slice()).unwrap();\n    for i in 0..10 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), &[i + 1]);\n    }\n    assert!(iter.next().is_none());\n\n    let mut iter = table.range([0u8].as_slice()..[10u8].as_slice()).unwrap();\n    for i in 0..10u8 {\n        assert_eq!(iter.next().unwrap().unwrap().1.value(), [i + 1].as_slice());\n    }\n    assert!(iter.next().is_none());\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn snapshot_with_writes() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"aa\").unwrap();\n\n    let snapshot = db.engine.snapshot();\n\n    assert_eq!(snapshot.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n\n    db.engine.put(b\"b\", b\"bb\").unwrap();\n\n    assert!(snapshot.get_value(b\"b\").unwrap().is_none());\n    assert_eq!(db.engine.get_value(b\"b\").unwrap().unwrap(), b\"bb\");\n\n    db.engine.delete(b\"a\").unwrap();\n\n    assert_eq!(snapshot.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n}"}
{"code": "pub fn reason(&self) -> Option<Reason> {\n        match self.kind {\n            Kind::Reset(_, reason, _) | Kind::GoAway(_, reason, _) | Kind::Reason(reason) => {\n                Some(reason)\n            }\n            _ => None,\n        }\n    }", "test": "async fn recv_push_promise_over_max_header_list_size() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_frame_eq(settings, frames::settings().max_header_list_size(10));\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://http2.akamai.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(\n            frames::push_promise(1, 2).request(\"GET\", \"https://http2.akamai.com/style.css\"),\n        )\n        .await;\n        srv.recv_frame(frames::reset(2).refused()).await;\n        srv.send_frame(frames::headers(1).response(200).eos()).await;\n        idle_ms(10).await;\n    };\n\n    let client = async move {\n        let (mut client, mut conn) = client::Builder::new()\n            .max_header_list_size(10)\n            .handshake::<_, Bytes>(io)\n            .await\n            .expect(\"handshake\");\n        let request = Request::builder()\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let req = async move {\n            let err = client\n                .send_request(request, true)\n                .expect(\"send_request\")\n                .0\n                .await\n                .expect_err(\"response\");\n            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));\n        };\n\n        conn.drive(req).await;\n        conn.await.expect(\"client\");\n    };\n    join(srv, client).await;\n}"}
{"code": "fn bh<F: Float>(float: F) -> (u64, i32) {\n    let fp = slow::bh(float);\n    (fp.mant, fp.exp)\n}", "test": "fn bh_test() {\n    assert_eq!(bh(1e-45_f32), (3, -150));\n    assert_eq!(bh(5e-324_f64), (3, -1075));\n    assert_eq!(bh(1_f32), (16777217, -24));\n    assert_eq!(bh(1_f64), (9007199254740993, -53));\n    assert_eq!(bh(1e38_f32), (19721523, 102));\n    assert_eq!(bh(1e308_f64), (10020841800044865, 970));\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn passthrough_wrong_type() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n                (import \"f\" (func $f (param \"a\" (borrow $t)) (result (own $t))))\n\n                (core func $f (canon lower (func $f)))\n\n                (core module $m\n                    (import \"\" \"f\" (func $f (param i32) (result i32)))\n                    (func (export \"f2\") (param i32)\n                        (drop (call $f (local.get 0)))\n                    )\n                )\n                (core instance $i (instantiate $m\n                    (with \"\" (instance\n                        (export \"f\" (func $f))\n                    ))\n                ))\n\n                (func (export \"f2\") (param \"x\" (borrow $t))\n                    (canon lift (core func $i \"f2\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n    linker\n        .root()\n        .func_wrap(\"f\", |_cx, (r,): (Resource<MyType>,)| Ok((r,)))?;\n    let i = linker.instantiate(&mut store, &c)?;\n\n    let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f2\")?;\n\n    let resource = Resource::new_own(100);\n    let err = f.call(&mut store, (&resource,)).unwrap_err();\n    assert!(\n        format!(\"{err:?}\").contains(\"cannot lower a `borrow` resource into an `own`\"),\n        \"bad error: {err:?}\"\n    );\n    Ok(())\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn wasm_flags_without_subcommand() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests/\")\n        .arg(\"print-arguments.wat\")\n        .arg(\"-foo\")\n        .arg(\"bar\")\n        .output()?;\n    assert!(output.status.success());\n    assert_eq!(\n        String::from_utf8_lossy(&output.stdout),\n        \"\\\n            print-arguments.wat\\n\\\n            -foo\\n\\\n            bar\\n\\\n        \"\n    );\n    Ok(())\n}"}
{"code": "pub fn fuel(&self) -> Option<u64> {\n        self.fuel\n    }", "test": "fn test_macro_fuel() {\n    let mut env = Environment::new();\n    assert_eq!(env.fuel(), None);\n    env.set_fuel(Some(100));\n    assert_eq!(env.fuel(), Some(100));\n    env.add_template(\n        \"test\",\n        \"\n        {% macro x() %}{% for item in range(5) %}...{% endfor %}{% endmacro %}\n        {% for count in range(macros) %}{{ x() }}{% endfor %}\n    \",\n    )\n    .unwrap();\n    let t = env.get_template(\"test\").unwrap();\n\n    // this should succeed\n    t.render(context!(macros => 3)).unwrap();\n\n    // but running more macros should not\n    let err = t.render(context!(macros => 5)).unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::OutOfFuel);\n}"}
{"code": "pub fn can_enable(&self, feature: Feature) -> bool {\n        self.version.load(Ordering::Relaxed) >= feature.ver\n    }", "test": "fn test_cluster_version() {\n    let server = MockServer::<Service>::new(3);\n    let eps = server.bind_addrs();\n\n    let feature_a = Feature::require(0, 0, 1);\n    let feature_b = Feature::require(5, 0, 0);\n    let feature_c = Feature::require(5, 0, 1);\n\n    let client = new_client(eps, None);\n    let feature_gate = client.feature_gate();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    let emit_heartbeat = || {\n        let req = pdpb::StoreStats::default();\n        block_on(client.store_heartbeat(req, /* store_report= */ None, None)).unwrap();\n    };\n\n    let set_cluster_version = |version: &str| {\n        let h = server.default_handler();\n        h.set_cluster_version(version.to_owned());\n    };\n\n    // Empty version string will be treated as invalid.\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Explicitly invalid version string.\n    set_cluster_version(\"invalid-version\");\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Correct version string.\n    set_cluster_version(\"5.0.0\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_a));\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can't go backwards.\n    set_cluster_version(\"4.99\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // After reconnect the version should be still accessable.\n    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.\n    thread::sleep(Duration::from_millis(200));\n    client.reconnect().unwrap();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can go forwards.\n    set_cluster_version(\"5.0.1\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_c));\n}"}
{"code": "fn len(&self) -> usize {\n            self.hash_table.len()\n        }", "test": "async fn sync_then_async_trap() -> Result<()> {\n    // Test the trapping and capturing the stack with the following sequence of\n    // calls:\n    //\n    // a[sync] ---> b[host] ---> c[async]\n\n    drop(env_logger::try_init());\n\n    let wat = r#\"\n        (module\n            (import \"\" \"b\" (func $b))\n            (func $a (export \"a\")\n                call $b\n            )\n            (func $c (export \"c\")\n                unreachable\n            )\n        )\n    \"#;\n\n    let mut async_store = Store::new(&Engine::new(Config::new().async_support(true)).unwrap(), ());\n\n    let async_module = Module::new(async_store.engine(), wat)?;\n\n    let mut async_linker = Linker::new(async_store.engine());\n    async_linker.func_wrap(\"\", \"b\", |_caller: Caller<_>| unreachable!())?;\n\n    let async_instance = async_linker\n        .instantiate_async(&mut async_store, &async_module)\n        .await?;\n\n    struct SyncCtx {\n        async_instance: Instance,\n        async_store: Store<()>,\n    }\n\n    let mut sync_store = Store::new(\n        &Engine::default(),\n        SyncCtx {\n            async_instance,\n            async_store,\n        },\n    );\n\n    let sync_module = Module::new(sync_store.engine(), wat)?;\n\n    let mut sync_linker = Linker::new(sync_store.engine());\n    sync_linker.func_wrap(\"\", \"b\", move |mut caller: Caller<SyncCtx>| -> Result<()> {\n        log::info!(\"Called `b`...\");\n        let async_instance = caller.data().async_instance;\n        let async_store = &mut caller.data_mut().async_store;\n\n        log::info!(\"Calling `c`...\");\n        let c = async_instance\n            .get_typed_func::<(), ()>(&mut *async_store, \"c\")\n            .unwrap();\n        tokio::task::block_in_place(|| {\n            tokio::runtime::Handle::current()\n                .block_on(async move { c.call_async(async_store, ()).await })\n        })?;\n        Ok(())\n    })?;\n\n    let sync_instance = sync_linker.instantiate(&mut sync_store, &sync_module)?;\n\n    log::info!(\"Calling `a`...\");\n    let a = sync_instance\n        .get_typed_func::<(), ()>(&mut sync_store, \"a\")\n        .unwrap();\n    let trap = a.call(&mut sync_store, ()).unwrap_err();\n\n    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    // We don't support cross-store or cross-engine symbolication currently, so\n    // the other frames are ignored.\n    assert_eq!(trace.len(), 1);\n    assert_eq!(trace[0].func_name(), Some(\"c\"));\n\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_leader_ignore_gen_snapshot() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    configure_for_snapshot(&mut cluster.cfg);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    // the other follower is isolated\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    std::thread::sleep(Duration::from_millis(200));\n\n    // the truncated index is advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        let diff = state.get_truncated_state().get_index() - before_states[&id].get_index();\n        error!(\"EEEEE\";\n            \"id\" => &id,\n            \"diff\" => diff,\n            \"state.get_truncated_state().get_index()\" => state.get_truncated_state().get_index(),\n            \"before_states[&id].get_index()\" => before_states[&id].get_index()\n        );\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n\n    // ingore raft log gc to avoid canceling snapshots\n    fail::cfg(\"on_raft_gc_log_tick\", \"return\").unwrap();\n    // wait for leader applied switch to witness\n    fail::cfg(\"before_region_gen_snap\", \"pause\").unwrap();\n    fail::cfg(\"ignore_snap_try_cnt\", \"return\").unwrap();\n    // After the snapshot is generated, it will be checked as invalidated and will\n    // not be regenerated (handle_snapshot will not generate a snapshot for\n    // witness)\n    cluster.clear_send_filters();\n    std::thread::sleep(Duration::from_millis(500));\n\n    // non-witness -> witness\n    fail::cfg(\"ignore_forbid_leader_to_be_witness\", \"return\").unwrap();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store1.get_id()],\n        vec![true],\n    );\n    fail::remove(\"before_region_gen_snap\");\n\n    std::thread::sleep(Duration::from_millis(500));\n\n    // forbid writes\n    let put = new_put_cmd(b\"k3\", b\"v3\");\n    must_get_error_is_witness(&mut cluster, &region, put);\n    // forbid reads\n    let get = new_get_cmd(b\"k1\");\n    must_get_error_is_witness(&mut cluster, &region, get);\n    // forbid read index\n    let read_index = new_read_index_cmd();\n    must_get_error_is_witness(&mut cluster, &region, read_index);\n\n    // reject to transfer, as can't send snapshot to peer_on_store3, there's a log\n    // gap\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    let _ = cluster.try_transfer_leader(region.get_id(), peer_on_store3);\n    std::thread::sleep(Duration::from_secs(5));\n    assert_eq!(cluster.leader_of_region(1).unwrap(), peer_on_store1);\n\n    // should be enable to transfer leader to peer_on_store2\n    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();\n    cluster.must_transfer_leader(1, peer_on_store2);\n    cluster.must_put(b\"k1\", b\"v1\");\n    assert_eq!(\n        cluster.leader_of_region(region.get_id()).unwrap().store_id,\n        nodes[1],\n    );\n    assert_eq!(cluster.must_get(b\"k9\"), Some(b\"v9\".to_vec()));\n\n    fail::remove(\"on_raft_gc_log_tick\");\n    fail::remove(\"ignore_snap_try_cnt\");\n    fail::remove(\"ignore_forbid_leader_to_be_witness\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_send_report() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n    cluster.put(b\"random_key1\", b\"random_val1\").unwrap();\n\n    // Blocks the raft apply process on store 1 entirely .\n    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);\n    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"on_handle_apply_store_1\", move || {\n        let _ = apply_triggered_tx.send(());\n        let _ = apply_released_rx.recv();\n    })\n    .unwrap();\n\n    // Manually makes an update, and wait for the apply to be triggered, to\n    // simulate \"some entries are committed but not applied\" scenario.\n    cluster.put(b\"random_key2\", b\"random_val2\").unwrap();\n    apply_triggered_rx\n        .recv_timeout(Duration::from_secs(1))\n        .unwrap();\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n\n    // Triggers the unsafe recovery store reporting process.\n    let plan = pdpb::RecoveryPlan::default();\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // No store report is sent, since there are peers have unapplied entries.\n    for _ in 0..20 {\n        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);\n        sleep_ms(100);\n    }\n\n    // Unblocks the apply process.\n    drop(apply_released_tx);\n\n    // Store reports are sent once the entries are applied.\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    fail::remove(\"on_handle_apply_store_1\");\n}"}
{"code": "pub fn get_leader(&mut self) -> pdpb::Member {\n        block_on(self.raw_client.wait_for_ready()).unwrap();\n        self.raw_client.leader()\n    }", "test": "fn test_region_heartbeat() {\n    let region_id = 2;\n    let cluster = Cluster::with_node_count(1, None);\n    let router = &cluster.routers[0];\n\n    // When there is only one peer, it should campaign immediately.\n    let mut req = RaftCmdRequest::default();\n    req.mut_header().set_peer(new_peer(1, 3));\n    req.mut_status_request()\n        .set_cmd_type(StatusCmdType::RegionLeader);\n    let res = router.query(region_id, req.clone()).unwrap();\n    let status_resp = res.response().unwrap().get_status_response();\n    assert_eq!(\n        *status_resp.get_region_leader().get_leader(),\n        new_peer(1, 3)\n    );\n\n    for _ in 0..5 {\n        let resp = block_on(\n            cluster\n                .node(0)\n                .pd_client()\n                .get_region_leader_by_id(region_id),\n        )\n        .unwrap();\n        if let Some((region, peer)) = resp {\n            assert_eq!(region.get_id(), region_id);\n            assert_eq!(peer.get_id(), 3);\n            assert_eq!(peer.get_store_id(), 1);\n            return;\n        }\n        std::thread::sleep(std::time::Duration::from_millis(50));\n    }\n    panic!(\"failed to get region leader\");\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_line_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-C\", \"8\", \"letters.txt\"]).succeeds();\n    assert_eq!(at.read(\"xaa\"), \"aaaaaaaa\");\n    assert_eq!(at.read(\"xab\"), \"a\\nbbbb\\n\");\n    assert_eq!(at.read(\"xac\"), \"cccc\\ndd\\n\");\n    assert_eq!(at.read(\"xad\"), \"ee\\n\");\n}"}
{"code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn special_bytes_test() {\n    const FORMAT: u128 = STANDARD;\n\n    // Test serializing and deserializing special strings.\n    assert!(f32::from_lexical(b\"NaN\").unwrap().is_nan());\n    assert!(f32::from_lexical(b\"nan\").unwrap().is_nan());\n    assert!(f32::from_lexical(b\"NAN\").unwrap().is_nan());\n    assert!(f32::from_lexical(b\"inf\").unwrap().is_infinite());\n    assert!(f32::from_lexical(b\"INF\").unwrap().is_infinite());\n    assert!(f32::from_lexical(b\"Infinity\").unwrap().is_infinite());\n\n    let options =\n        Options::builder().nan_string(Some(b\"nan\")).inf_string(Some(b\"Infinity\")).build().unwrap();\n\n    // The error message depends on whether the radix feature is enabled.\n    assert!(f32::from_lexical_with_options::<FORMAT>(b\"inf\", &options).is_err());\n    assert!(f32::from_lexical_with_options::<FORMAT>(b\"Infinity\", &options).unwrap().is_infinite());\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_twice_1() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_force() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_rm_force_a\";\n    let file_b = \"test_rm_force_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    ucmd.arg(\"-f\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_column() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, None, 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n\n    let req = new_analyze_column_req(&product, 3, 3, 3, 3, 4, 32);\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_data().is_empty());\n    let mut analyze_resp = AnalyzeColumnsResp::default();\n    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n    let hist = analyze_resp.get_pk_hist();\n    assert_eq!(hist.get_buckets().len(), 2);\n    assert_eq!(hist.get_ndv(), 4);\n    let collectors = analyze_resp.get_collectors().to_vec();\n    assert_eq!(collectors.len(), product.columns_info().len() - 1);\n    assert_eq!(collectors[0].get_null_count(), 1);\n    assert_eq!(collectors[0].get_count(), 3);\n    let rows = collectors[0].get_cm_sketch().get_rows();\n    assert_eq!(rows.len(), 4);\n    let sum: u32 = rows.first().unwrap().get_counters().iter().sum();\n    assert_eq!(sum, 3);\n    assert_eq!(collectors[0].get_total_size(), 21);\n    assert_eq!(collectors[1].get_total_size(), 4);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_mdhms_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_mdhms_time\";\n\n    ucmd.args(&[\"-t\", \"01011234.56\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\n        \"%Y%m%d%H%M.%S\",\n        &format!(\"{}01010000.00\", time::OffsetDateTime::now_utc().year()),\n    );\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n}"}
{"code": "pub fn contains_key(&self, key: &JsValue) -> bool {\n        self.map.contains_key(key)\n    }", "test": "fn weak_map_key_live() {\n    run_test(|| {\n        let key = Gc::new(String::from(\"key\"));\n        let key_copy = key.clone();\n\n        let mut map = WeakMap::new();\n\n        map.insert(&key, ());\n\n        assert!(map.contains_key(&key));\n        assert!(map.contains_key(&key_copy));\n\n        assert_eq!(map.remove(&key), Some(()));\n\n        map.insert(&key, ());\n\n        drop(key);\n\n        force_collect();\n\n        assert!(map.contains_key(&key_copy));\n    });\n}"}
{"code": "pub fn get<Q>(&self, key: &Q) -> Option<&Value>\n    where\n        String: Borrow<Q>,\n        Q: ?Sized + Ord + Eq + Hash,\n    {\n        self.map.get(key)\n    }", "test": "fn test_borrowed_raw_value() {\n    #[derive(Serialize, Deserialize)]\n    struct Wrapper<'a> {\n        a: i8,\n        #[serde(borrow)]\n        b: &'a RawValue,\n        c: i8,\n    }\n\n    let wrapper_from_str: Wrapper =\n        serde_json::from_str(r#\"{\"a\": 1, \"b\": {\"foo\": 2}, \"c\": 3}\"#).unwrap();\n    assert_eq!(r#\"{\"foo\": 2}\"#, wrapper_from_str.b.get());\n\n    let wrapper_to_string = serde_json::to_string(&wrapper_from_str).unwrap();\n    assert_eq!(r#\"{\"a\":1,\"b\":{\"foo\": 2},\"c\":3}\"#, wrapper_to_string);\n\n    let wrapper_to_value = serde_json::to_value(&wrapper_from_str).unwrap();\n    assert_eq!(json!({\"a\": 1, \"b\": {\"foo\": 2}, \"c\": 3}), wrapper_to_value);\n\n    let array_from_str: Vec<&RawValue> =\n        serde_json::from_str(r#\"[\"a\", 42, {\"foo\": \"bar\"}, null]\"#).unwrap();\n    assert_eq!(r#\"\"a\"\"#, array_from_str[0].get());\n    assert_eq!(r#\"42\"#, array_from_str[1].get());\n    assert_eq!(r#\"{\"foo\": \"bar\"}\"#, array_from_str[2].get());\n    assert_eq!(r#\"null\"#, array_from_str[3].get());\n\n    let array_to_string = serde_json::to_string(&array_from_str).unwrap();\n    assert_eq!(r#\"[\"a\",42,{\"foo\": \"bar\"},null]\"#, array_to_string);\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_concurrent_requests_0_conn() {\n    let mut options = ResolverOpts::default();\n\n    // there are two connections, but no concurrency requested, 0==1\n    options.num_concurrent_reqs = 0;\n\n    // we want to make sure that both udp connections are called\n    //   this will count down to 0 only if both are called.\n    let on_send = OnSendBarrier::new(1);\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n\n    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);\n\n    let udp1_nameserver = mock_nameserver_on_send(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        options.clone(),\n        on_send,\n    );\n    let udp2_nameserver = udp1_nameserver.clone();\n\n    let pool = mock_nameserver_pool_on_send(\n        vec![udp2_nameserver, udp1_nameserver],\n        vec![],\n        None,\n        options,\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    // there's no actual network traffic happening, 1 sec should be plenty\n    //   TODO: for some reason this timeout doesn't work, not clear why...\n    // let future = Timeout::new(future, Duration::from_secs(1));\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], udp_record);\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_sampling_bernoulli() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, None, 4),\n        (6, Some(\"name:1\"), 1),\n        (7, Some(\"name:1\"), 1),\n        (8, Some(\"name:1\"), 1),\n        (9, Some(\"name:2\"), 1),\n        (10, Some(\"name:2\"), 1),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n\n    // Pass the 2nd column as a column group.\n    let req = new_analyze_sampling_req(&product, 1, 0, 0.5);\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_data().is_empty());\n    let mut analyze_resp = AnalyzeColumnsResp::default();\n    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n    let collector = analyze_resp.get_row_collector();\n    // The column group is at 4th place and the data should be equal to the 2nd.\n    assert_eq!(collector.get_null_counts(), vec![0, 1, 0, 1]);\n    assert_eq!(collector.get_count(), 9);\n    assert_eq!(collector.get_fm_sketch().len(), 4);\n    assert_eq!(collector.get_total_size(), vec![72, 56, 9, 56]);\n}"}
{"code": "fn parse(witnesses: &[Witness]) -> Vec<ParsedEnvelope> {\n    ParsedEnvelope::from_transaction(&Transaction {\n      version: 0,\n      lock_time: LockTime::ZERO,\n      input: witnesses\n        .iter()\n        .map(|witness| TxIn {\n          previous_output: OutPoint::null(),\n          script_sig: ScriptBuf::new(),\n          sequence: Sequence::ENABLE_RBF_NO_LOCKTIME,\n          witness: witness.clone(),\n        })\n        .collect(),\n      output: Vec::new(),\n    })\n  }", "test": "fn send_btc_locks_inscriptions() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n\n  rpc_server.mine_blocks(1);\n\n  let (_, reveal) = inscribe(&rpc_server);\n\n  let output =\n    CommandBuilder::new(\"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 1btc\")\n      .rpc_server(&rpc_server)\n      .run_and_deserialize_output::<Output>();\n\n  assert_eq!(\n    output.transaction,\n    \"0000000000000000000000000000000000000000000000000000000000000000\"\n      .parse()\n      .unwrap()\n  );\n\n  assert_eq!(\n    rpc_server.sent(),\n    &[Sent {\n      amount: 1.0,\n      address: \"bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4\"\n        .parse::<Address<NetworkUnchecked>>()\n        .unwrap()\n        .assume_checked(),\n      locked: vec![OutPoint {\n        txid: reveal,\n        vout: 0,\n      }]\n    }]\n  )\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_inf_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.inf_string(Some(b\"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"nan\"));\n    assert!(!builder.is_valid());\n    builder = builder.inf_string(Some(b\"in00f\"));\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.inf_string(Some(b\"i\"));\n    assert!(builder.is_valid());\n    builder = builder.inf_string(Some(b\"inf\"));\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n    builder = builder.inf_string(None);\n    assert!(builder.is_valid());\n    builder = builder.infinity_string(None);\n    assert!(builder.is_valid());\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn drop_func() -> Result<()> {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let engine = Engine::default();\n    let mut linker = Linker::<()>::new(&engine);\n    linker.allow_shadowing(true);\n\n    let a = A;\n    linker.func_wrap(\"\", \"\", move || {\n        let _ = &a;\n    })?;\n\n    assert_eq!(HITS.load(SeqCst), 0);\n\n    // Define the function again to ensure redefined functions are dropped\n\n    let a = A;\n    linker.func_wrap(\"\", \"\", move || {\n        let _ = &a;\n    })?;\n\n    assert_eq!(HITS.load(SeqCst), 1);\n\n    drop(linker);\n\n    assert_eq!(HITS.load(SeqCst), 2);\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_unimplemented_arg() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"target_dir\";\n    let file = \"source_file\";\n    let context_arg = \"--context\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(context_arg)\n        .arg(file)\n        .arg(dir)\n        .fails()\n        .stderr_contains(\"Unimplemented\");\n\n    assert!(!at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn drain_entry() {\n    let mut headers = HeaderMap::new();\n\n    headers.insert(\n        \"hello\".parse::<HeaderName>().unwrap(),\n        \"world\".parse().unwrap(),\n    );\n    headers.insert(\n        \"zomg\".parse::<HeaderName>().unwrap(),\n        \"foo\".parse().unwrap(),\n    );\n    headers.append(\n        \"hello\".parse::<HeaderName>().unwrap(),\n        \"world2\".parse().unwrap(),\n    );\n    headers.insert(\n        \"more\".parse::<HeaderName>().unwrap(),\n        \"words\".parse().unwrap(),\n    );\n    headers.append(\n        \"more\".parse::<HeaderName>().unwrap(),\n        \"insertions\".parse().unwrap(),\n    );\n    assert_eq!(5, headers.len());\n\n    // Using insert_mult\n    {\n        let mut e = match headers.entry(\"hello\") {\n            Entry::Occupied(e) => e,\n            _ => panic!(),\n        };\n\n        let vals: Vec<_> = e.insert_mult(\"wat\".parse().unwrap()).collect();\n        assert_eq!(2, vals.len());\n        assert_eq!(vals[0], \"world\");\n        assert_eq!(vals[1], \"world2\");\n    }\n\n    assert_eq!(5-2+1, headers.len());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"Thu Jan 01 12:34:00 2015\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501011234\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, start_of_year);\n    assert_eq!(mtime, start_of_year);\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn handle_ws_both_sides_for_raw_tag() {\n    let start_ws = WS { left: true, right: false };\n    let end_ws = WS { left: true, right: true };\n    let ast =\n        vec![Node::Raw(start_ws, \"  hey \".to_string(), end_ws), Node::Text(\"  hey\".to_string())];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            // it removed only the space at the end\n            Node::Raw(start_ws, \"  hey\".to_string(), end_ws),\n            Node::Text(\"hey\".to_string()),\n        ]\n    );\n}"}
{"code": "pub(crate) fn from_u32(x: &[u32]) -> Vec<Limb> {\n    x.iter().cloned().collect()\n}", "test": "fn imul_small_test() {\n    // No overflow check, 1-int.\n    let mut x = Bigint {\n        data: from_u32(&[5]),\n    };\n    x.imul_small(7);\n    assert_eq!(x.data, from_u32(&[35]));\n\n    // No overflow check, 2-ints.\n    let mut x = Bigint::from_u64(0x4000000040000);\n    x.imul_small(5);\n    assert_eq!(x.data, from_u32(&[0x00140000, 0x140000]));\n\n    // Overflow, 1 carry.\n    let mut x = Bigint {\n        data: from_u32(&[0x33333334]),\n    };\n    x.imul_small(5);\n    assert_eq!(x.data, from_u32(&[4, 1]));\n\n    // Overflow, 1 carry, internal.\n    let mut x = Bigint::from_u64(0x133333334);\n    x.imul_small(5);\n    assert_eq!(x.data, from_u32(&[4, 6]));\n\n    // Overflow, 2 carries.\n    let mut x = Bigint::from_u64(0x3333333333333334);\n    x.imul_small(5);\n    assert_eq!(x.data, from_u32(&[4, 0, 1]));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn lint_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"check.js\");\n    fs.insert(file_path.into(), LINT_ERROR.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"lint_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_lines_short_concatenated_with_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_num_prefixed_chunks_by_lines\";\n    RandomFile::new(&at, name).add_lines(10000);\n    ucmd.args(&[\"-l1000\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        !self.is_some()\n    }", "test": "fn test_put_delete() {\n    let mut cluster = Cluster::default();\n    let router = &mut cluster.routers[0];\n    let header = Box::new(router.new_request_for(2).take_header());\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key\", b\"value\");\n\n    router.wait_applied_to_current_term(2, Duration::from_secs(3));\n\n    let snap = router.stale_snapshot(2);\n    assert!(snap.get_value(b\"key\").unwrap().is_none());\n    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub.wait_proposed()));\n    assert!(block_on(sub.wait_committed()));\n    let resp = block_on(sub.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    let snap = router.stale_snapshot(2);\n    assert_eq!(snap.get_value(b\"key\").unwrap().unwrap(), b\"value\");\n\n    let mut delete = SimpleWriteEncoder::with_capacity(64);\n    delete.delete(CF_DEFAULT, b\"key\");\n    let (msg, mut sub) = PeerMsg::simple_write(header, delete.encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub.wait_proposed()));\n    assert!(block_on(sub.wait_committed()));\n    let resp = block_on(sub.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    let snap = router.stale_snapshot(2);\n    assert_matches!(snap.get_value(b\"key\"), Ok(None));\n\n    // Check if WAL is skipped for basic writes.\n    let mut cached = cluster.node(0).tablet_registry().get(2).unwrap();\n    check_skip_wal(cached.latest().unwrap().as_inner().path());\n}"}
{"code": "pub fn send_streams(&self) -> usize {\n        self.state.send_streams\n    }", "test": "fn finish_stream_simple() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 1);\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Finished { id })) if id == s\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 0);\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    // Receive-only streams do not get `StreamFinished` events\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    assert_matches!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n}"}
{"code": "pub fn mode(&self) -> u32 {\n        match self.specified_mode {\n            Some(x) => x,\n            None => DEFAULT_MODE,\n        }\n    }", "test": "fn test_chmod_file_symlink_after_non_existing_file() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let existing = \"file\";\n    let test_existing_symlink = \"file_symlink\";\n\n    let non_existing = \"test_chmod_symlink_non_existing_file\";\n    let test_dangling_symlink = \"test_chmod_symlink_non_existing_file_symlink\";\n    let expected_stdout = &format!(\n        \"failed to change mode of '{test_dangling_symlink}' from 0000 (---------) to 1500 (r-x-----T)\"\n    );\n    let expected_stderr = &format!(\"cannot operate on dangling symlink '{test_dangling_symlink}'\");\n\n    at.touch(existing);\n    set_permissions(at.plus(existing), Permissions::from_mode(0o664)).unwrap();\n    at.symlink_file(non_existing, test_dangling_symlink);\n    at.symlink_file(existing, test_existing_symlink);\n\n    // this cannot succeed since the symbolic link dangles\n    // but the metadata for the existing target should change\n    scene\n        .ucmd()\n        .arg(\"u+x\")\n        .arg(\"-v\")\n        .arg(test_dangling_symlink)\n        .arg(test_existing_symlink)\n        .fails()\n        .code_is(1)\n        .stdout_contains(expected_stdout)\n        .stderr_contains(expected_stderr);\n    assert_eq!(\n        at.metadata(test_existing_symlink).permissions().mode(),\n        0o100_764\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_does_not_run_linter_via_cli() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), UNFORMATTED_AND_INCORRECT.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--linter-enabled=false\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, UNFORMATTED_AND_INCORRECT);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_does_not_run_linter_via_cli\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_within_combined_shorts() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let name = \"obs-lines-within-shorts\";\n    RandomFile::new(at, name).add_lines(400);\n\n    scene\n        .ucmd()\n        .args(&[\"-x200de\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(at, \".\", r\"x\\d\\d$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_infinite_symlink_expansion_to_dirs() {\n    let fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"check_rome_test_infinite_symlink_expansion_to_dirs\");\n    let subdir1_path = root_path.join(\"prefix\");\n    let subdir2_path = root_path.join(\"foo\").join(\"bar\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(&subdir1_path).unwrap();\n    create_dir_all(&subdir2_path).unwrap();\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(&subdir2_path, subdir1_path.join(\"symlink1\")).unwrap();\n        symlink(subdir1_path, subdir2_path.join(\"symlink2\")).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_dir(&subdir2_path, &subdir1_path.join(\"symlink1\")));\n        check_windows_symlink!(symlink_dir(subdir1_path, subdir2_path.join(\"symlink2\")));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"check\"), (root_path.display().to_string().as_str())].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_infinite_symlink_expansion_to_dirs\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn unit_struct_cache_key() {\n    #[derive(CacheKey, Hash)]\n    struct UnitStruct;\n\n    let mut key = CacheKeyHasher::new();\n\n    UnitStruct.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    UnitStruct.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_node_multiple_rollback_merge() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.raft_store.right_derive_when_split = true;\n    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(20);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    for i in 0..10 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), b\"v\");\n    }\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    let left_peer_1 = find_peer(&left, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(left.get_id(), left_peer_1.clone());\n    assert_eq!(left_peer_1.get_id(), 1001);\n\n    let on_schedule_merge_fp = \"on_schedule_merge\";\n    let on_check_merge_not_1001_fp = \"on_check_merge_not_1001\";\n\n    let mut right_peer_1_id = find_peer(&right, 1).unwrap().get_id();\n\n    for i in 0..3 {\n        fail::cfg(on_schedule_merge_fp, \"return()\").unwrap();\n        cluster.must_try_merge(left.get_id(), right.get_id());\n        // Change the epoch of target region and the merge will fail\n        pd_client.must_remove_peer(right.get_id(), new_peer(1, right_peer_1_id));\n        right_peer_1_id += 100;\n        pd_client.must_add_peer(right.get_id(), new_peer(1, right_peer_1_id));\n        // Only the source leader is running `on_check_merge`\n        fail::cfg(on_check_merge_not_1001_fp, \"return()\").unwrap();\n        fail::remove(on_schedule_merge_fp);\n        // In previous implementation, rollback merge proposal can be proposed by leader\n        // itself So wait for the leader propose rollback merge if possible\n        sleep_ms(100);\n        // Check if the source region is still in merging mode.\n        let mut l_r = pd_client.get_region(b\"k1\").unwrap();\n        let req = new_request(\n            l_r.get_id(),\n            l_r.take_region_epoch(),\n            vec![new_put_cf_cmd(\n                \"default\",\n                format!(\"k1{}\", i).as_bytes(),\n                b\"vv\",\n            )],\n            false,\n        );\n        let resp = cluster\n            .call_command_on_leader(req, Duration::from_millis(100))\n            .unwrap();\n        if !resp\n            .get_header()\n            .get_error()\n            .get_message()\n            .contains(\"merging mode\")\n        {\n            panic!(\"resp {:?} does not contain merging mode error\", resp);\n        }\n\n        fail::remove(on_check_merge_not_1001_fp);\n        // Write data for waiting the merge to rollback easily\n        cluster.must_put(format!(\"k1{}\", i).as_bytes(), b\"vv\");\n        // Make sure source region is not merged to target region\n        assert_eq!(pd_client.get_region(b\"k1\").unwrap().get_id(), left.get_id());\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_ymdhms_time() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_ymdhms_time\";\n\n    ucmd.args(&[\"-t\", \"1501011234.56\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M.%S\", \"201501010000.00\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next()\n    }", "test": "fn test_cname_lookup_preserve() {\n    let resp_query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let cname_record = cname_record(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        Name::from_str(\"v4.example.com.\").unwrap(),\n    );\n    let v4_record = v4_record(\n        Name::from_str(\"v4.example.com.\").unwrap(),\n        Ipv4Addr::new(93, 184, 216, 34),\n    );\n    let message = message(\n        resp_query,\n        vec![cname_record.clone(), v4_record],\n        vec![],\n        vec![],\n    );\n    let client: MockClientHandle<_, ResolveError> =\n        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, true),\n    );\n\n    let io_loop = Runtime::new().unwrap();\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    let mut iter = lookup.iter();\n    assert_eq!(iter.next().unwrap(), cname_record.data().unwrap());\n    assert_eq!(*iter.next().unwrap(), RData::A(A::new(93, 184, 216, 34)));\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        !self.0.is_reserved_value()\n    }", "test": "fn create_get_set_funcref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::FuncRef, 10, None);\n    let init = Val::FuncRef(Some(Func::wrap(&mut store, || {})));\n    let table = Table::new(&mut store, table_ty, init)?;\n\n    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_some());\n    table.set(&mut store, 5, Val::FuncRef(None))?;\n    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_none());\n\n    Ok(())\n}"}
{"code": "fn is_empty(&self) -> Result<bool> {\n        self.len().map(|x| x == 0)\n    }", "test": "fn empty_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u8, ()> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(&0, &()).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert!(!table.is_empty().unwrap());\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_bin() {\n    assert_eq!(from_str(\"0b101\"), Ok(0b101));\n    assert_eq!(from_str(\"0b001\"), Ok(0b001));\n    assert_eq!(from_str(\"0b100100\"), Ok(0b100100));\n\n    assert_eq!(\n        from_str::<u8>(\"0b\"),\n        Err(SpannedError {\n            code: Error::ExpectedInteger,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0b_1\"),\n        Err(SpannedError {\n            code: Error::UnderscoreAtBeginning,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0b111111111\"),\n        Err(SpannedError {\n            code: Error::IntegerOutOfBounds,\n            position: Position { line: 1, col: 12 },\n        })\n    );\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn bad_import_alignment() -> Result<()> {\n    let component = format!(\n        r#\"\n(component\n  (import \"unaligned-retptr\" (func $unaligned_retptr (result string)))\n  (type $many_arg (tuple\n    string string string string\n    string string string string\n    string\n  ))\n  (import \"unaligned-argptr\" (func $unaligned_argptr (param \"a\" $many_arg)))\n  (core module $libc_panic\n    (memory (export \"memory\") 1)\n    (func (export \"realloc\") (param i32 i32 i32 i32) (result i32)\n      unreachable)\n  )\n  (core instance $libc_panic (instantiate $libc_panic))\n\n  (core func $unaligned_retptr_lower\n    (canon lower (func $unaligned_retptr) (memory $libc_panic \"memory\") (realloc (func $libc_panic \"realloc\")))\n  )\n  (core func $unaligned_argptr_lower\n    (canon lower (func $unaligned_argptr) (memory $libc_panic \"memory\") (realloc (func $libc_panic \"realloc\")))\n  )\n\n  (core module $m\n    (import \"host\" \"unaligned-retptr\" (func $unaligned_retptr (param i32)))\n    (import \"host\" \"unaligned-argptr\" (func $unaligned_argptr (param i32)))\n\n    (func (export \"unaligned-retptr\")\n     (call $unaligned_retptr (i32.const 1)))\n    (func (export \"unaligned-argptr\")\n     (call $unaligned_argptr (i32.const 1)))\n  )\n  (core instance $m (instantiate $m\n    (with \"host\" (instance\n      (export \"unaligned-retptr\" (func $unaligned_retptr_lower))\n      (export \"unaligned-argptr\" (func $unaligned_argptr_lower))\n    ))\n  ))\n\n  (func (export \"unaligned-retptr2\")\n    (canon lift (core func $m \"unaligned-retptr\"))\n  )\n  (func (export \"unaligned-argptr2\")\n    (canon lift (core func $m \"unaligned-argptr\"))\n  )\n)\n        \"#\n    );\n\n    let engine = super::engine();\n    let mut linker = Linker::new(&engine);\n    linker\n        .root()\n        .func_wrap(\"unaligned-retptr\", |_, _: ()| -> Result<(String,)> {\n            Ok((String::new(),))\n        })?;\n    linker.root().func_wrap(\n        \"unaligned-argptr\",\n        |_,\n         _: ((\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n            WasmStr,\n        ),)|\n         -> Result<()> { unreachable!() },\n    )?;\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n\n    let trap = linker\n        .instantiate(&mut store, &component)?\n        .get_typed_func::<(), ()>(&mut store, \"unaligned-retptr2\")?\n        .call(&mut store, ())\n        .unwrap_err();\n    assert!(\n        format!(\"{:?}\", trap).contains(\"pointer not aligned\"),\n        \"{}\",\n        trap\n    );\n    let trap = linker\n        .instantiate(&mut store, &component)?\n        .get_typed_func::<(), ()>(&mut store, \"unaligned-argptr2\")?\n        .call(&mut store, ())\n        .unwrap_err();\n    assert!(\n        format!(\"{:?}\", trap).contains(\"pointer not aligned\"),\n        \"{}\",\n        trap\n    );\n\n    Ok(())\n}"}
{"code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn server_complete_io_for_handshake_ending_with_alert() {\n    let (client_config, server_config) = make_disjoint_suite_configs();\n    let (mut client, mut server) = make_pair_for_configs(client_config, server_config);\n\n    assert!(server.is_handshaking());\n\n    let mut pipe = OtherSession::new_fails(&mut client);\n    let rc = server.complete_io(&mut pipe);\n    assert!(rc.is_err(), \"server io failed due to handshake failure\");\n    assert!(!server.wants_write(), \"but server did send its alert\");\n    assert_eq!(\n        format!(\"{:?}\", pipe.last_error),\n        \"Some(AlertReceived(HandshakeFailure))\",\n        \"which was received by client\"\n    );\n}"}
{"code": "pub fn has_weak_maps() -> bool {\n    BOA_GC.with(|current| {\n        let gc = current.borrow();\n\n        gc.weak_map_start.get().is_some()\n    })\n}", "test": "fn weak_map_basic() {\n    run_test(|| {\n        let key1 = Gc::new(String::from(\"key1\"));\n        let key2 = Gc::new(String::from(\"key2\"));\n        let key3 = Gc::new(String::from(\"key3\"));\n\n        assert!(!has_weak_maps());\n\n        let mut map = WeakMap::new();\n\n        assert!(has_weak_maps());\n\n        map.insert(&key1, ());\n        map.insert(&key2, ());\n        map.insert(&key3, ());\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key1));\n        assert!(map.contains_key(&key2));\n        assert!(map.contains_key(&key3));\n\n        drop(key1);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key2));\n        assert!(map.contains_key(&key3));\n\n        drop(key2);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map.contains_key(&key3));\n        assert!(has_weak_maps());\n\n        drop(key3);\n\n        assert!(has_weak_maps());\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        drop(map);\n\n        force_collect();\n        assert!(!has_weak_maps());\n    });\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_recursive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    at.mkdir_all(\"a/b/c\");\n    at.mkdir(\"z\");\n    at.touch(at.plus_as_string(\"a/a\"));\n    at.touch(at.plus_as_string(\"a/b/b\"));\n    at.touch(at.plus_as_string(\"a/b/c/c\"));\n    at.touch(at.plus_as_string(\"z/y\"));\n\n    let result = scene\n        .ucmd()\n        .arg(\"-R\")\n        .arg(\"--verbose\")\n        .arg(user_name)\n        .arg(\"a\")\n        .arg(\"z\")\n        .run();\n    result.stderr_contains(\"ownership of 'a/a' retained as\");\n    result.stderr_contains(\"ownership of 'z/y' retained as\");\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "async fn test_catalog_lookup() {\n    let example = create_example();\n    let test = create_test();\n    let origin = example.origin().clone();\n    let test_origin = test.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin.clone(), Box::new(Arc::new(example)));\n    catalog.upsert(test_origin.clone(), Box::new(Arc::new(test)));\n\n    let mut question: Message = Message::new();\n\n    let mut query: Query = Query::new();\n    query.set_name(origin.into());\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert!(result.header().authoritative());\n\n    let answers: &[Record] = result.answers();\n\n    assert!(!answers.is_empty());\n    assert_eq!(answers.first().unwrap().record_type(), RecordType::A);\n    assert_eq!(\n        answers.first().unwrap().data().unwrap(),\n        &RData::A(A::new(93, 184, 216, 34))\n    );\n\n    let ns = result.name_servers();\n    assert!(ns.is_empty());\n\n    // other zone\n    let mut question: Message = Message::new();\n    let mut query: Query = Query::new();\n    query.set_name(test_origin.into());\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert!(result.header().authoritative());\n\n    let answers: &[Record] = result.answers();\n\n    assert!(!answers.is_empty());\n    assert_eq!(answers.first().unwrap().record_type(), RecordType::A);\n    assert_eq!(\n        answers.first().unwrap().data().unwrap(),\n        &RData::A(A::new(94, 184, 216, 34))\n    );\n}"}
{"code": "pub fn read_bytes(&self, name: &str) -> Vec<u8> {\n        let mut f = self.open(name);\n        let mut contents = Vec::new();\n        f.read_to_end(&mut contents)\n            .unwrap_or_else(|e| panic!(\"Couldn't read {name}: {e}\"));\n        contents\n    }", "test": "fn test_cp_sparse_never_empty() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    const BUFFER_SIZE: usize = 4096 * 4;\n    let buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];\n\n    at.make_file(\"src_file1\");\n    at.write_bytes(\"src_file1\", &buf);\n\n    ucmd.args(&[\"--sparse=never\", \"src_file1\", \"dst_file_non_sparse\"])\n        .succeeds();\n    assert_eq!(at.read_bytes(\"dst_file_non_sparse\"), buf);\n    assert_eq!(\n        at.metadata(\"dst_file_non_sparse\").blocks() * 512,\n        buf.len() as u64\n    );\n}"}
{"code": "pub fn send(&mut self, msg: RaftMessage) -> result::Result<(), DiscardReason> {\n        let store_id = msg.get_to_peer().store_id;\n        let grpc_raft_conn_num = self.builder.cfg.value().grpc_raft_conn_num as u64;\n        let conn_id = if grpc_raft_conn_num == 1 {\n            0\n        } else {\n            if self.last_hash.0 == 0 || msg.region_id != self.last_hash.0 {\n                self.last_hash = (\n                    msg.region_id,\n                    seahash::hash(&msg.region_id.to_ne_bytes()) % grpc_raft_conn_num,\n                );\n            };\n            self.last_hash.1 as usize\n        };\n\n        #[allow(unused_mut)]\n        let mut transport_on_send_store_fp = || {\n            fail_point!(\n                \"transport_on_send_snapshot\",\n                msg.get_message().get_msg_type() == raft::eraftpb::MessageType::MsgSnapshot,\n                |sid| if let Some(sid) = sid {\n                    let sid: u64 = sid.parse().unwrap();\n                    if sid == store_id {\n                        // Forbid building new connections.\n                        fail::cfg(_ON_RESOLVE_FP, &format!(\"1*return({})\", sid)).unwrap();\n                        self.cache.remove(&(store_id, conn_id));\n                        self.pool\n                            .lock()\n                            .unwrap()\n                            .connections\n                            .remove(&(store_id, conn_id));\n                    }\n                }\n            )\n        };\n        transport_on_send_store_fp();\n        loop {\n            if let Some(s) = self.cache.get_mut(&(store_id, conn_id)) {\n                match s.queue.push(msg) {\n                    Ok(_) => {\n                        if !s.dirty {\n                            s.dirty = true;\n                            self.need_flush.push((store_id, conn_id));\n                        }\n                        return Ok(());\n                    }\n                    Err(DiscardReason::Full) => {\n                        s.queue.notify();\n                        s.dirty = false;\n                        if !s.full {\n                            s.full = true;\n                            self.full_stores.push((store_id, conn_id));\n                        }\n                        return Err(DiscardReason::Full);\n                    }\n                    Err(DiscardReason::Disconnected) => break,\n                    Err(DiscardReason::Paused) => return Err(DiscardReason::Paused),\n                    Err(DiscardReason::Filtered) => return Err(DiscardReason::Filtered),\n                }\n            }\n            if !self.load_stream(store_id, conn_id) {\n                return Err(DiscardReason::Disconnected);\n            }\n        }\n        self.cache.remove(&(store_id, conn_id));\n        Err(DiscardReason::Disconnected)\n    }", "test": "fn test_tombstone_block_list() {\n    let pd_server = test_pd::Server::new(1);\n    let eps = pd_server.bind_addrs();\n    let pd_client = Arc::new(test_pd::util::new_client(eps, None));\n    let bg_worker = WorkerBuilder::new(thd_name!(\"background\"))\n        .thread_count(2)\n        .create();\n    let resolver = resolve::new_resolver(pd_client, &bg_worker, FakeExtension).0;\n\n    let msg_count = Arc::new(AtomicUsize::new(0));\n    let batch_msg_count = Arc::new(AtomicUsize::new(0));\n    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), true);\n    let (_mock_server, port) = create_mock_server(service, 60200, 60300).unwrap();\n\n    let mut raft_client = get_raft_client(FakeExtension, resolver);\n\n    let mut store1 = metapb::Store::default();\n    store1.set_id(1);\n    store1.set_address(format!(\"127.0.0.1:{}\", port));\n    pd_server.default_handler().add_store(store1.clone());\n\n    // `send` should success.\n    for _ in 0..10 {\n        // 5M per RaftMessage.\n        let mut raft_m = RaftMessage::default();\n        raft_m.mut_to_peer().set_store_id(1);\n        for _ in 0..(5 * 1024) {\n            let mut e = Entry::default();\n            e.set_data(vec![b'a'; 1024].into());\n            raft_m.mut_message().mut_entries().push(e);\n        }\n        raft_client.send(raft_m).unwrap();\n    }\n    raft_client.flush();\n\n    check_msg_count(500, &msg_count, 10);\n\n    let mut store2 = metapb::Store::default();\n    store2.set_id(2);\n    store2.set_address(store1.get_address().to_owned());\n    store2.set_state(metapb::StoreState::Tombstone);\n    pd_server.default_handler().add_store(store2);\n    let mut message = RaftMessage::default();\n    message.mut_to_peer().set_store_id(2);\n    // First message should be OK.\n    raft_client.send(message.clone()).unwrap();\n    // Wait some time for the resolve result.\n    thread::sleep(time::Duration::from_millis(50));\n    // Second message should fail as the store should be added to block list.\n    assert_eq!(\n        DiscardReason::Disconnected,\n        raft_client.send(message).unwrap_err()\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_read_only() {\n    let mut fs = MemoryFileSystem::new_read_only();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"test.js\");\n    fs.insert(file_path.into(), *b\"content\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Do not store the content of the file in the snapshot\n    fs.remove(file_path);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_read_only\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn mismatch_intrinsics() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (type $t' (resource (rep i32)))\n                (type $u' (resource (rep i32)))\n\n                (export $t \"t\" (type $t'))\n                (export $u \"u\" (type $u'))\n\n                ;; note the mismatch where this is an intrinsic for `u` but\n                ;; we're typing it as `t`\n                (core func $t_ctor (canon resource.new $u))\n\n                (func (export \"ctor\") (param \"x\" u32) (result (own $t))\n                    (canon lift (core func $t_ctor)))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let i = Linker::new(&engine).instantiate(&mut store, &c)?;\n    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, \"ctor\")?;\n    assert_eq!(\n        ctor.call(&mut store, (100,)).unwrap_err().to_string(),\n        \"unknown handle index 0\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_multiple_election_rounds() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(30);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store5 = find_peer(&region, 5).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());\n\n    cluster.stop_node(3);\n    cluster.stop_node(4);\n    cluster.stop_node(5);\n\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n\n    // wait election timeout\n    std::thread::sleep(Duration::from_millis(\n        cluster.cfg.raft_store.raft_election_timeout_ticks as u64\n            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n            * 2,\n    ));\n    cluster.enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // wait multiple election rounds\n    std::thread::sleep(Duration::from_millis(\n        cluster.cfg.raft_store.raft_election_timeout_ticks as u64\n            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n            * 6,\n    ));\n\n    cluster.clear_send_filters();\n    // remove the peers on failed nodes\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_prompt_write_protected_no() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file_2 = \"test_rm_prompt_write_protected_2\";\n\n    at.touch(file_2);\n\n    scene.ccmd(\"chmod\").arg(\"0\").arg(file_2).succeeds();\n\n    scene.ucmd().arg(file_2).pipe_in(\"n\").succeeds();\n    assert!(at.file_exists(file_2));\n}"}
{"code": "pub fn server_name(&self) -> Option<&str> {\n        self.server_name\n            .as_ref()\n            .map(<DnsName as AsRef<str>>::as_ref)\n    }", "test": "fn server_exposes_offered_sni_even_if_resolver_fails() {\n    let kt = KeyType::Rsa;\n    let resolver = rustls::server::ResolvesServerCertUsingSni::new();\n\n    let mut server_config = make_server_config(kt);\n    server_config.cert_resolver = Arc::new(resolver);\n    let server_config = Arc::new(server_config);\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(kt, &[version]);\n        let mut server = ServerConnection::new(Arc::clone(&server_config)).unwrap();\n        let mut client =\n            ClientConnection::new(Arc::new(client_config), dns_name(\"thisdoesNOTexist.com\"))\n                .unwrap();\n\n        assert_eq!(None, server.server_name());\n        transfer(&mut client, &mut server);\n        assert_eq!(\n            server.process_new_packets(),\n            Err(Error::General(\n                \"no server certificate chain resolved\".to_string()\n            ))\n        );\n        assert_eq!(Some(\"thisdoesnotexist.com\"), server.server_name());\n    }\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_chroot_skip_chdir() {\n    let ts = TestScenario::new(util_name!());\n    let at = ts.fixtures.clone();\n    let dirs = [\"/\", \"/.\", \"/..\", \"isroot\"];\n    at.symlink_file(\"/\", \"isroot\");\n    for dir in dirs {\n        let env_cd = std::env::current_dir().unwrap();\n        if let Ok(result) = run_ucmd_as_root(&ts, &[dir, \"--skip-chdir\"]) {\n            // Should return the same path\n            assert_eq!(\n                result.success().no_stderr().stdout_str(),\n                env_cd.to_str().unwrap()\n            );\n        } else {\n            print!(\"Test skipped; requires root user\");\n        }\n    }\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_select_failed() {\n    let mut cluster = test_raftstore::new_server_cluster(0, 3);\n    cluster.cfg.raft_store.check_leader_lease_interval = ReadableDuration::hours(10);\n    cluster.run();\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(b\"\"), None);\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let engine = cluster.sim.rl().storages[&leader.get_id()].clone();\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) =\n        init_data_with_engine_and_commit(ctx.clone(), engine, &product, &[], true);\n\n    // Sleep until the leader lease is expired.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_heartbeat_interval()\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32\n            * 2,\n    );\n    for id in 1..=3 {\n        if id != ctx.get_peer().get_store_id() {\n            cluster.stop_node(id);\n        }\n    }\n    let req = DagSelect::from(&product).build_with(ctx.clone(), &[0]);\n    let f = endpoint.parse_and_handle_unary_request(req, None);\n    cluster.stop_node(ctx.get_peer().get_store_id());\n    drop(cluster);\n    let _ = futures::executor::block_on(f);\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.matcher.next_match(&self.haystack[self.position..]) {\n            Some((first, last)) => {\n                let result = (first + self.position, last + self.position);\n                self.position += last;\n                Some(result)\n            }\n            None => None,\n        }\n    }", "test": "fn test_output_selects_columns() {\n    let output = new_ucmd!()\n        .args(&[\"--output=source\"])\n        .succeeds()\n        .stdout_move_str();\n    assert_eq!(output.lines().next().unwrap(), \"Filesystem\");\n\n    let output = new_ucmd!()\n        .args(&[\"--output=source,target\"])\n        .succeeds()\n        .stdout_move_str();\n    assert_eq!(\n        output\n            .lines()\n            .next()\n            .unwrap()\n            .split_whitespace()\n            .collect::<Vec<_>>(),\n        vec![\"Filesystem\", \"Mounted\", \"on\"]\n    );\n\n    let output = new_ucmd!()\n        .args(&[\"--output=source,target,used\"])\n        .succeeds()\n        .stdout_move_str();\n    assert_eq!(\n        output\n            .lines()\n            .next()\n            .unwrap()\n            .split_whitespace()\n            .collect::<Vec<_>>(),\n        vec![\"Filesystem\", \"Mounted\", \"on\", \"Used\"]\n    );\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_turnoff_titan() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.rocksdb.defaultcf.disable_auto_compactions = true;\n    cluster.cfg.rocksdb.defaultcf.num_levels = 1;\n    configure_for_enable_titan(&mut cluster, ReadableSize::kb(0));\n    cluster.run();\n    assert_eq!(cluster.must_get(b\"k1\"), None);\n\n    let size = 5;\n    for i in 0..size {\n        cluster\n            .put(\n                format!(\"k{:02}0\", i).as_bytes(),\n                format!(\"v{}\", i).as_bytes(),\n            )\n            .unwrap();\n    }\n    cluster.must_flush_cf(CF_DEFAULT, true);\n    for i in 0..size {\n        cluster\n            .put(\n                format!(\"k{:02}1\", i).as_bytes(),\n                format!(\"v{}\", i).as_bytes(),\n            )\n            .unwrap();\n    }\n    cluster.must_flush_cf(CF_DEFAULT, true);\n    for i in cluster.get_node_ids().into_iter() {\n        let engine = cluster.get_engine(i);\n        let db = engine.as_inner();\n        assert_eq!(\n            db.get_property_int(\"rocksdb.num-files-at-level0\").unwrap(),\n            2\n        );\n        assert_eq!(\n            db.get_property_int(\"rocksdb.num-files-at-level1\").unwrap(),\n            0\n        );\n        assert_eq!(\n            db.get_property_int(\"rocksdb.titandb.num-live-blob-file\")\n                .unwrap(),\n            2\n        );\n        assert_eq!(\n            db.get_property_int(\"rocksdb.titandb.num-obsolete-blob-file\")\n                .unwrap(),\n            0\n        );\n    }\n    cluster.shutdown();\n\n    // try reopen db when titan isn't properly turned off.\n    configure_for_disable_titan(&mut cluster);\n    cluster.pre_start_check().unwrap_err();\n\n    configure_for_enable_titan(&mut cluster, ReadableSize::kb(0));\n    cluster.pre_start_check().unwrap();\n    cluster.start().unwrap();\n    assert_eq!(cluster.must_get(b\"k1\"), None);\n    for i in cluster.get_node_ids().into_iter() {\n        let db = cluster.get_engine(i);\n        let opt = vec![(\"blob_run_mode\", \"kFallback\")];\n        db.set_options_cf(CF_DEFAULT, &opt).unwrap();\n    }\n    cluster.compact_data();\n    let mut all_check_pass = true;\n    for _ in 0..10 {\n        // wait for gc completes.\n        sleep_ms(10);\n        all_check_pass = true;\n        for i in cluster.get_node_ids().into_iter() {\n            let engine = cluster.get_engine(i);\n            let db = engine.as_inner();\n            if db.get_property_int(\"rocksdb.num-files-at-level0\").unwrap() != 0 {\n                all_check_pass = false;\n                break;\n            }\n            if db.get_property_int(\"rocksdb.num-files-at-level1\").unwrap() != 1 {\n                all_check_pass = false;\n                break;\n            }\n            if db\n                .get_property_int(\"rocksdb.titandb.num-live-blob-file\")\n                .unwrap()\n                != 0\n            {\n                all_check_pass = false;\n                break;\n            }\n        }\n        if all_check_pass {\n            break;\n        }\n    }\n    if !all_check_pass {\n        panic!(\"unexpected titan gc results\");\n    }\n    cluster.shutdown();\n\n    configure_for_disable_titan(&mut cluster);\n    // wait till files are purged, timeout set to purge_obsolete_files_period.\n    for _ in 1..100 {\n        sleep_ms(10);\n        if cluster.pre_start_check().is_ok() {\n            return;\n        }\n    }\n    cluster.pre_start_check().unwrap();\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_suffix_length_short_concatenated_with_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_num_prefixed_chunks_by_lines\";\n    RandomFile::new(&at, name).add_lines(10000);\n    ucmd.args(&[\"-a4\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]][[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit125_wasi_snapshot1() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit125_wasi_snapshot1.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    if cfg!(windows) {\n        assert_eq!(output.status.code().unwrap(), 1);\n    } else {\n        assert_eq!(output.status.code().unwrap(), 125);\n    }\n    Ok(())\n}"}
{"code": "pub async fn wait_committed(&mut self) -> bool {\n        WaitEvent {\n            event: CmdResChannel::COMMITTED_EVENT,\n            core: &self.core,\n        }\n        .await\n    }", "test": "fn test_destroy_by_larger_id_while_applying() {\n    let fp = \"APPLY_COMMITTED_ENTRIES\";\n    let mut cluster = Cluster::default();\n    let router = &cluster.routers[0];\n    router.wait_applied_to_current_term(2, Duration::from_secs(3));\n\n    fail::cfg(fp, \"pause\").unwrap();\n\n    let header = Box::new(router.new_request_for(2).take_header());\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key\", b\"value\");\n    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub.wait_committed()));\n\n    let mut larger_id_msg = Box::<RaftMessage>::default();\n    larger_id_msg.set_region_id(2);\n    let mut target_peer = header.get_peer().clone();\n    target_peer.set_id(target_peer.get_id() + 1);\n    larger_id_msg.set_to_peer(target_peer.clone());\n    larger_id_msg.set_region_epoch(header.get_region_epoch().clone());\n    larger_id_msg\n        .mut_region_epoch()\n        .set_conf_ver(header.get_region_epoch().get_conf_ver() + 1);\n    larger_id_msg.set_from_peer(new_peer(2, 8));\n    let raft_message = larger_id_msg.mut_message();\n    raft_message.set_msg_type(MessageType::MsgHeartbeat);\n    raft_message.set_from(8);\n    raft_message.set_to(target_peer.get_id());\n    raft_message.set_term(10);\n\n    // Larger ID should trigger destroy.\n    router.send_raft_message(larger_id_msg).unwrap();\n    fail::remove(fp);\n    assert_peer_not_exist(2, header.get_peer().get_id(), router);\n    let meta = router\n        .must_query_debug_info(2, Duration::from_secs(3))\n        .unwrap();\n    assert_eq!(meta.raft_status.id, target_peer.get_id());\n    assert_eq!(meta.raft_status.hard_state.term, 10);\n\n    std::thread::sleep(Duration::from_millis(10));\n\n    // New peer should survive restart.\n    cluster.restart(0);\n    let router = &cluster.routers[0];\n    let meta = router\n        .must_query_debug_info(2, Duration::from_secs(3))\n        .unwrap();\n    assert_eq!(meta.raft_status.id, target_peer.get_id());\n    assert_eq!(meta.raft_status.hard_state.term, 10);\n}"}
{"code": "pub(crate) fn finish(\n        self,\n        header_crypto: Option<&dyn crypto::HeaderKey>,\n    ) -> Result<Packet, PacketDecodeError> {\n        use self::PlainHeader::*;\n        let Self {\n            plain_header,\n            mut buf,\n        } = self;\n\n        if let Initial {\n            dst_cid,\n            src_cid,\n            token_pos,\n            version,\n            ..\n        } = plain_header\n        {\n            let number = Self::decrypt_header(&mut buf, header_crypto.unwrap())?;\n            let header_len = buf.position() as usize;\n            let mut bytes = buf.into_inner();\n\n            let header_data = bytes.split_to(header_len).freeze();\n            let token = header_data.slice(token_pos.start..token_pos.end);\n            return Ok(Packet {\n                header: Header::Initial {\n                    dst_cid,\n                    src_cid,\n                    token,\n                    number,\n                    version,\n                },\n                header_data,\n                payload: bytes,\n            });\n        }\n\n        let header = match plain_header {\n            Long {\n                ty,\n                dst_cid,\n                src_cid,\n                version,\n                ..\n            } => Header::Long {\n                ty,\n                dst_cid,\n                src_cid,\n                number: Self::decrypt_header(&mut buf, header_crypto.unwrap())?,\n                version,\n            },\n            Retry {\n                dst_cid,\n                src_cid,\n                version,\n            } => Header::Retry {\n                dst_cid,\n                src_cid,\n                version,\n            },\n            Short { spin, dst_cid, .. } => {\n                let number = Self::decrypt_header(&mut buf, header_crypto.unwrap())?;\n                let key_phase = buf.get_ref()[0] & KEY_PHASE_BIT != 0;\n                Header::Short {\n                    spin,\n                    key_phase,\n                    dst_cid,\n                    number,\n                }\n            }\n            VersionNegotiate {\n                random,\n                dst_cid,\n                src_cid,\n            } => Header::VersionNegotiate {\n                random,\n                dst_cid,\n                src_cid,\n            },\n            Initial { .. } => unreachable!(),\n        };\n\n        let header_len = buf.position() as usize;\n        let mut bytes = buf.into_inner();\n        Ok(Packet {\n            header,\n            header_data: bytes.split_to(header_len).freeze(),\n            payload: bytes,\n        })\n    }", "test": "fn stop_before_finish() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive();\n\n    info!(\"stopping stream\");\n    const ERROR: VarInt = VarInt(42);\n    pair.server_recv(server_ch, s).stop(ERROR).unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.client_send(client_ch, s).finish(),\n        Err(FinishError::Stopped(ERROR))\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_backup_with_other_args() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"-vbL\")\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_target_dir_single_source() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_mv_target_dir_single_source_dir\";\n    let file = \"test_mv_target_dir_single_source_file\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(\"-t\").arg(dir).arg(file).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn client_complete_io_for_handshake() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n\n    assert!(client.is_handshaking());\n    let (rdlen, wrlen) = client\n        .complete_io(&mut OtherSession::new(&mut server))\n        .unwrap();\n    assert!(rdlen > 0 && wrlen > 0);\n    assert!(!client.is_handshaking());\n    assert!(!client.wants_write());\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nul_number_l() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=l/3\", \"--separator=\\\\0\", \"separator_nul.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\x002\\0\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\x004\\0\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\0\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn get<Q>(&self, key: &Q) -> Option<&Value>\n    where\n        String: Borrow<Q>,\n        Q: ?Sized + Ord + Eq + Hash,\n    {\n        self.map.get(key)\n    }", "test": "fn test_serialize_char() {\n    let value = json!(\n        ({\n            let mut map = BTreeMap::new();\n            map.insert('c', ());\n            map\n        })\n    );\n    assert_eq!(&Value::Null, value.get(\"c\").unwrap());\n}"}
{"code": "pub fn accept(&self) -> Accept<'_> {\n        Accept {\n            endpoint: self,\n            notify: self.inner.shared.incoming.notified(),\n        }\n    }", "test": "fn repeated_request_response() {\n    let _guard = subscribe();\n    let server = ServerConfig {\n        transport: Arc::new(TransportConfig {\n            max_concurrent_bidi_streams: 1u32.into(),\n            ..TransportConfig::default()\n        }),\n        ..server_config()\n    };\n    let mut pair = Pair::new(Default::default(), server);\n    let (client_ch, server_ch) = pair.connect();\n    const REQUEST: &[u8] = b\"hello\";\n    const RESPONSE: &[u8] = b\"world\";\n    for _ in 0..3 {\n        let s = pair.client_streams(client_ch).open(Dir::Bi).unwrap();\n\n        pair.client_send(client_ch, s).write(REQUEST).unwrap();\n        pair.client_send(client_ch, s).finish().unwrap();\n\n        pair.drive();\n\n        assert_eq!(pair.server_streams(server_ch).accept(Dir::Bi), Some(s));\n        let mut recv = pair.server_recv(server_ch, s);\n        let mut chunks = recv.read(false).unwrap();\n        assert_matches!(\n            chunks.next(usize::MAX),\n            Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == REQUEST\n        );\n\n        assert_matches!(chunks.next(usize::MAX), Ok(None));\n        let _ = chunks.finalize();\n        pair.server_send(server_ch, s).write(RESPONSE).unwrap();\n        pair.server_send(server_ch, s).finish().unwrap();\n\n        pair.drive();\n\n        let mut recv = pair.client_recv(client_ch, s);\n        let mut chunks = recv.read(false).unwrap();\n        assert_matches!(\n            chunks.next(usize::MAX),\n            Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == RESPONSE\n        );\n        assert_matches!(chunks.next(usize::MAX), Ok(None));\n        let _ = chunks.finalize();\n    }\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_ancestors_directories() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ancestor1 = \"ancestor1\";\n    let ancestor2 = \"ancestor1/ancestor2\";\n    let target_dir = \"ancestor1/ancestor2/target_dir\";\n    let directories_arg = \"-d\";\n\n    ucmd.args(&[directories_arg, target_dir])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(ancestor1));\n    assert!(at.dir_exists(ancestor2));\n    assert!(at.dir_exists(target_dir));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_wait_for_snapshot_apply() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(8);\n    cluster.cfg.raft_store.merge_max_log_gap = 3;\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(10);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n    cluster.stop_node(nodes[1]);\n    let (raft_gc_triggered_tx, raft_gc_triggered_rx) = mpsc::bounded::<()>(1);\n    let (raft_gc_finished_tx, raft_gc_finished_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"worker_gc_raft_log\", move || {\n        let _ = raft_gc_triggered_rx.recv();\n    })\n    .unwrap();\n    fail::cfg_callback(\"worker_gc_raft_log_finished\", move || {\n        let _ = raft_gc_finished_tx.send(());\n    })\n    .unwrap();\n    (0..10).for_each(|_| cluster.must_put(b\"random_k\", b\"random_v\"));\n    // Unblock raft log GC.\n    drop(raft_gc_triggered_tx);\n    // Wait until logs are GCed.\n    raft_gc_finished_rx\n        .recv_timeout(Duration::from_secs(3))\n        .unwrap();\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[2]);\n\n    // Blocks the raft snap apply process.\n    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);\n    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"region_apply_snap\", move || {\n        let _ = apply_triggered_tx.send(());\n        let _ = apply_released_rx.recv();\n    })\n    .unwrap();\n\n    cluster.run_node(nodes[1]).unwrap();\n\n    apply_triggered_rx\n        .recv_timeout(Duration::from_secs(1))\n        .unwrap();\n\n    // Triggers the unsafe recovery store reporting process.\n    let plan = pdpb::RecoveryPlan::default();\n    pd_client.must_set_unsafe_recovery_plan(nodes[1], plan);\n    cluster.must_send_store_heartbeat(nodes[1]);\n\n    // No store report is sent, since there are peers have unapplied entries.\n    for _ in 0..20 {\n        assert_eq!(pd_client.must_get_store_report(nodes[1]), None);\n        sleep_ms(100);\n    }\n\n    // Unblocks the snap apply process.\n    drop(apply_released_tx);\n\n    // Store reports are sent once the entries are applied.\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[1]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n\n    fail::remove(\"worker_gc_raft_log\");\n    fail::remove(\"worker_gc_raft_log_finished\");\n    fail::remove(\"region_apply_snap\");\n}"}
{"code": "fn len(&self) -> Result<u64> {\n        let mut count = 0;\n        for item in self.iter()? {\n            let (_, values) = item?;\n            for v in values {\n                v?;\n                count += 1;\n            }\n        }\n        Ok(count)\n    }", "test": "fn len() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n        table.insert(\"hello2\", \"world2\").unwrap();\n        table.insert(\"hi\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(table.len().unwrap(), 3);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_create_destroy_reentrancy() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n    cluster.put(b\"random_key1\", b\"random_val1\").unwrap();\n\n    // Split the region into 2, and remove one of them, so that we can test both\n    // region peer list update and region creation.\n    pd_client.must_split_region(\n        region,\n        pdpb::CheckPolicy::Usekey,\n        vec![b\"random_key1\".to_vec()],\n    );\n    let region1 = pd_client.get_region(b\"random_key\".as_ref()).unwrap();\n    let region2 = pd_client.get_region(b\"random_key1\".as_ref()).unwrap();\n    let region1_store0_peer = find_peer(&region1, nodes[0]).unwrap().to_owned();\n    pd_client.must_remove_peer(region1.get_id(), region1_store0_peer);\n    cluster.must_remove_region(nodes[0], region1.get_id());\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    {\n        let put = new_put_cmd(b\"k2\", b\"v2\");\n        let req = new_request(\n            region2.get_id(),\n            region2.get_region_epoch().clone(),\n            vec![put],\n            true,\n        );\n        // marjority is lost, can't propose command successfully.\n        cluster\n            .call_command_on_leader(req, Duration::from_millis(10))\n            .unwrap_err();\n    }\n\n    cluster.must_enter_force_leader(region2.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    // Construct recovery plan.\n    let mut plan = pdpb::RecoveryPlan::default();\n\n    let mut create = metapb::Region::default();\n    create.set_id(101);\n    create.set_end_key(b\"random_key1\".to_vec());\n    let mut peer = metapb::Peer::default();\n    peer.set_id(102);\n    peer.set_store_id(nodes[0]);\n    create.mut_peers().push(peer);\n    plan.mut_creates().push(create);\n\n    plan.mut_tombstones().push(region2.get_id());\n\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());\n    cluster.must_send_store_heartbeat(nodes[0]);\n    sleep_ms(100);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // Store reports are sent once the entries are applied.\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    let report = store_report.unwrap();\n    let peer_reports = report.get_peer_reports();\n    assert_eq!(peer_reports.len(), 1);\n    let reported_region = peer_reports[0].get_region_state().get_region();\n    assert_eq!(reported_region.get_id(), 101);\n    assert_eq!(reported_region.get_peers().len(), 1);\n    assert_eq!(reported_region.get_peers()[0].get_id(), 102);\n    fail::remove(\"on_handle_apply_store_1\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_backup_force() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    at.write(\"a\", \"a\\n\");\n    at.write(\"b\", \"b2\\n\");\n\n    scene.ucmd().args(&[\"-s\", \"b\", \"b~\"]).succeeds().no_stderr();\n    assert!(at.file_exists(\"a\"));\n    assert!(at.file_exists(\"b\"));\n    assert!(at.file_exists(\"b~\"));\n    scene\n        .ucmd()\n        .args(&[\"-s\", \"-f\", \"--b=simple\", \"a\", \"b\"])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(\"a\"));\n    assert!(at.file_exists(\"b\"));\n    assert!(at.file_exists(\"b~\"));\n    assert_eq!(at.read(\"a\"), \"a\\n\");\n    assert_eq!(at.read(\"b\"), \"a\\n\");\n    // we should have the same content as b as we had time to do a backup\n    assert_eq!(at.read(\"b~\"), \"b2\\n\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_interactive_no_clobber_force_last_arg_wins() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"a.txt\";\n    let file_b = \"b.txt\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    scene\n        .ucmd()\n        .args(&[file_a, file_b, \"-f\", \"-i\", \"-n\"])\n        .fails()\n        .stderr_is(format!(\"mv: not replacing '{file_b}'\\n\"));\n\n    scene\n        .ucmd()\n        .args(&[file_a, file_b, \"-n\", \"-f\", \"-i\"])\n        .fails()\n        .stderr_is(format!(\"mv: overwrite '{file_b}'? \"));\n\n    at.write(file_a, \"aa\");\n\n    scene\n        .ucmd()\n        .args(&[file_a, file_b, \"-i\", \"-n\", \"-f\"])\n        .succeeds()\n        .no_output();\n\n    assert!(!at.file_exists(file_a));\n    assert_eq!(\"aa\", at.read(file_b));\n}"}
{"code": "fn get(&self, _: &[u8]) -> Option<&[u8]> {\n        None\n    }", "test": "fn test_skip_gc_by_check() {\n    GC_COMPACTION_FILTER_PERFORM.reset();\n    GC_COMPACTION_FILTER_SKIP.reset();\n\n    let mut cfg = DbConfig::default();\n    cfg.defaultcf.disable_auto_compactions = true;\n    cfg.defaultcf.dynamic_level_bytes = false;\n    cfg.defaultcf.num_levels = 7;\n    let dir = tempfile::TempDir::new().unwrap();\n    let builder = TestEngineBuilder::new().path(dir.path());\n    let engine = builder\n        .api_version(ApiVersion::V2)\n        .build_with_cfg(&cfg)\n        .unwrap();\n    let raw_engine = engine.get_rocksdb();\n    let mut gc_runner = TestGcRunner::new(0);\n\n    do_write(&engine, false, 5);\n    engine.get_rocksdb().flush_cfs(&[], true).unwrap();\n\n    // The min_mvcc_ts ts > gc safepoint, check_need_gc return false, don't call\n    // dofilter\n    gc_runner\n        .safe_point(TimeStamp::new(1).into_inner())\n        .gc_raw(&raw_engine);\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        1\n    );\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        1\n    );\n\n    // TEST 2:When is_bottommost_level = false,\n    // write data to level2\n    do_write(&engine, false, 5);\n    engine.get_rocksdb().flush_cfs(&[], true).unwrap();\n\n    do_gc(&raw_engine, 2, &mut gc_runner, &dir);\n\n    do_write(&engine, false, 5);\n    engine.get_rocksdb().flush_cfs(&[], true).unwrap();\n\n    // Set ratio_threshold, let (props.num_versions as f64 > props.num_rows as\n    // f64 * ratio_threshold) return false\n    gc_runner.ratio_threshold = Option::Some(f64::MAX);\n\n    // is_bottommost_level = false\n    do_gc(&raw_engine, 1, &mut gc_runner, &dir);\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_PERFORM\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        3\n    );\n\n    // The check_need_gc return false, GC_COMPACTION_FILTER_SKIP will add 1.\n    assert_eq!(\n        GC_COMPACTION_FILTER_SKIP\n            .with_label_values(&[STAT_RAW_KEYMODE])\n            .get(),\n        2\n    );\n}"}
{"code": "pub fn detail(&self) -> Option<&str> {\n        self.repr.detail.as_deref()\n    }", "test": "fn test_kwargs_error() {\n    let kwargs = Kwargs::from_iter([(\"foo\", Value::from(42))]);\n    let bar = kwargs.get::<Value>(\"bar\").unwrap_err();\n    assert_eq!(bar.detail(), Some(\"missing keyword argument 'bar'\"));\n}"}
{"code": "pub fn get_leader(&mut self) -> pdpb::Member {\n        block_on(self.raw_client.wait_for_ready()).unwrap();\n        self.raw_client.leader()\n    }", "test": "fn test_status() {\n    let cluster = Cluster::default();\n    let router = &cluster.routers[0];\n    // When there is only one peer, it should campaign immediately.\n    let mut req = RaftCmdRequest::default();\n    req.mut_header().set_peer(new_peer(1, 3));\n    req.mut_status_request()\n        .set_cmd_type(StatusCmdType::RegionLeader);\n    let res = router.query(2, req.clone()).unwrap();\n    let status_resp = res.response().unwrap().get_status_response();\n    assert_eq!(\n        *status_resp.get_region_leader().get_leader(),\n        new_peer(1, 3)\n    );\n\n    req.mut_status_request()\n        .set_cmd_type(StatusCmdType::RegionDetail);\n    let res = router.query(2, req.clone()).unwrap();\n    let status_resp = res.response().unwrap().get_status_response();\n    let detail = status_resp.get_region_detail();\n    assert_eq!(*detail.get_leader(), new_peer(1, 3));\n    let region = detail.get_region();\n    assert_eq!(region.get_id(), 2);\n    assert!(region.get_start_key().is_empty());\n    assert!(region.get_end_key().is_empty());\n    assert_eq!(*region.get_peers(), vec![new_peer(1, 3)]);\n    assert_eq!(region.get_region_epoch().get_version(), 1);\n    assert_eq!(region.get_region_epoch().get_conf_ver(), 1);\n\n    // Invalid store id should return error.\n    req.mut_header().mut_peer().set_store_id(4);\n    let res = router.query(2, req).unwrap();\n    let resp = res.response().unwrap();\n    assert!(\n        resp.get_header().get_error().has_store_not_match(),\n        \"{:?}\",\n        resp\n    );\n\n    // TODO: add a peer then check for region change and leadership change.\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_variable_block_logic_expr() {\n    let mut context = Context::new();\n    context.insert(\"name\", &\"john\");\n    context.insert(\"malicious\", &\"<html>\");\n    context.insert(\"a\", &2);\n    context.insert(\"b\", &3);\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n    context.insert(\"tuple_list\", &vec![(1, 2, 3), (1, 2, 3)]);\n    let mut hashmap = HashMap::new();\n    hashmap.insert(\"a\", 1);\n    hashmap.insert(\"b\", 10);\n    hashmap.insert(\"john\", 100);\n    context.insert(\"object\", &hashmap);\n    context.insert(\"urls\", &vec![\"https://test\"]);\n\n    let inputs = vec![\n        (\"{{ (1.9 + a) | round > 10 }}\", \"false\"),\n        (\"{{ (1.9 + a) | round > 10 or b > a }}\", \"true\"),\n        (\"{{ 1.9 + a | round == 4 and numbers | length == 3}}\", \"true\"),\n        (\"{{ numbers | length > 1 }}\", \"true\"),\n        (\"{{ numbers | length == 1 }}\", \"false\"),\n        (\"{{ numbers | length - 2 == 1 }}\", \"true\"),\n        (\"{{ not name }}\", \"false\"),\n        (\"{{ not true }}\", \"false\"),\n        (\"{{ not undefined }}\", \"true\"),\n        (\"{{ name == 'john' }}\", \"true\"),\n        (\"{{ name != 'john' }}\", \"false\"),\n        (\"{{ name == 'john' | capitalize }}\", \"false\"),\n        (\"{{ name != 'john' | capitalize }}\", \"true\"),\n        (\"{{ 1 in numbers }}\", \"true\"),\n        (\"{{ 1 not in numbers }}\", \"false\"),\n        (\"{{ 40 not in numbers }}\", \"true\"),\n        (\"{{ 'e' in 'hello' }}\", \"true\"),\n        (\"{{ 'e' not in 'hello' }}\", \"false\"),\n        (\"{{ 'x' not in 'hello' }}\", \"true\"),\n        (\"{{ name in 'hello john' }}\", \"true\"),\n        (\"{{ name not in 'hello john' }}\", \"false\"),\n        (\"{{ name not in 'hello' }}\", \"true\"),\n        (\"{{ name in ['bob', 2, 'john'] }}\", \"true\"),\n        (\"{{ a in ['bob', 2, 'john'] }}\", \"true\"),\n        (\"{{ \\\"https://test\\\" in [\\\"https://test\\\"] }}\", \"true\"),\n        (\"{{ \\\"https://test\\\" in urls }}\", \"true\"),\n        (\"{{ 'n' in name }}\", \"true\"),\n        (\"{{ '<' in malicious }}\", \"true\"),\n        (\"{{ 'a' in object }}\", \"true\"),\n        (\"{{ name in object }}\", \"true\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_nonempty_directory_with_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir_all(NESTED_DIR);\n    at.touch(NESTED_DIR_FILE);\n\n    ucmd.arg(\"-p\").arg(NESTED_DIR).fails().stderr_is(format!(\n        \"rmdir: failed to remove 'dir/ect/ory': {NOT_EMPTY}\\n\"\n    ));\n\n    assert!(at.dir_exists(NESTED_DIR));\n}"}
{"code": "pub fn precompile_component(&self, bytes: &[u8]) -> Result<Vec<u8>> {\n        #[cfg(feature = \"wat\")]\n        let bytes = wat::parse_bytes(&bytes)?;\n        let (mmap, _) = crate::component::Component::build_artifacts(self, &bytes)?;\n        Ok(mmap.to_vec())\n    }", "test": "fn bare_bones() -> Result<()> {\n    let engine = super::engine();\n    let component = Component::new(&engine, \"(component)\")?.serialize()?;\n    assert_eq!(component, engine.precompile_component(b\"(component)\")?);\n\n    let component = unsafe { Component::deserialize(&engine, &component)? };\n    let mut store = Store::new(&engine, ());\n    Linker::new(&engine).instantiate(&mut store, &component)?;\n\n    Ok(())\n}"}
{"code": "pub fn message_type(&self) -> MessageType {\n        self.message_type\n    }", "test": "async fn test_cname_additionals() {\n    let example = create_example();\n    let origin = example.origin().clone();\n\n    let mut catalog: Catalog = Catalog::new();\n    catalog.upsert(origin, Box::new(Arc::new(example)));\n\n    let mut question: Message = Message::new();\n\n    let mut query: Query = Query::new();\n    query.set_name(Name::from_str(\"alias.example.com.\").unwrap());\n    query.set_query_type(RecordType::A);\n\n    question.add_query(query);\n\n    // temp request\n    let question_bytes = question.to_bytes().unwrap();\n    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();\n    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);\n\n    let response_handler = TestResponseHandler::new();\n    catalog\n        .lookup(&question_req, None, response_handler.clone())\n        .await;\n    let result = response_handler.into_message().await;\n\n    assert_eq!(result.message_type(), MessageType::Response);\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let answers: &[Record] = result.answers();\n    assert_eq!(answers.len(), 1);\n    assert_eq!(answers.first().unwrap().record_type(), RecordType::CNAME);\n    assert_eq!(\n        answers.first().unwrap().data().unwrap(),\n        &RData::CNAME(CNAME(Name::from_str(\"www.example.com.\").unwrap()))\n    );\n\n    let additionals: &[Record] = result.additionals();\n    assert!(!additionals.is_empty());\n    assert_eq!(additionals.first().unwrap().record_type(), RecordType::A);\n    assert_eq!(\n        additionals.first().unwrap().data().unwrap(),\n        &RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_strip_trailing_slashes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    //using --strip-trailing-slashes option\n    ucmd.arg(\"--strip-trailing-slashes\")\n        .arg(format!(\"{TEST_HELLO_WORLD_SOURCE}/\"))\n        .arg(TEST_HELLO_WORLD_DEST)\n        .succeeds();\n\n    // Check the content of the destination file that was copied.\n    assert_eq!(at.read(TEST_HELLO_WORLD_DEST), \"Hello, World!\\n\");\n}"}
{"code": "fn size_hint(&self) -> (usize, Option<usize>) {\n        self.inner.size_hint()\n    }", "test": "fn drain_drop_immediately() {\n    // test mem::forgetting does not double-free\n\n    let mut headers = HeaderMap::new();\n    headers.insert(\"hello\", \"world\".parse().unwrap());\n    headers.insert(\"zomg\", \"bar\".parse().unwrap());\n    headers.append(\"hello\", \"world2\".parse().unwrap());\n\n    let iter = headers.drain();\n    assert_eq!(iter.size_hint(), (2, Some(3)));\n    // not consuming `iter`\n}"}
{"code": "pub fn match_directive<'a>(comment: &'a str, directive: &str) -> Option<&'a str> {\n    assert!(\n        directive.ends_with(':'),\n        \"Directive must include trailing colon\"\n    );\n    let text = comment.trim_start_matches(';').trim_start();\n    if text.starts_with(directive) {\n        Some(text[directive.len()..].trim())\n    } else {\n        None\n    }\n}", "test": "fn test_match_directive() {\n    assert_eq!(match_directive(\"; foo: bar  \", \"foo:\"), Some(\"bar\"));\n    assert_eq!(match_directive(\" foo:bar\", \"foo:\"), Some(\"bar\"));\n    assert_eq!(match_directive(\"foo:bar\", \"foo:\"), Some(\"bar\"));\n    assert_eq!(match_directive(\";x foo: bar\", \"foo:\"), None);\n    assert_eq!(match_directive(\";;; foo: bar\", \"foo:\"), Some(\"bar\"));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_none(),\n            }\n        }\n    }", "test": "fn save_point_pop_rollback() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.pop_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n    let val = db.engine.get_value(b\"b\").unwrap();\n    assert!(val.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.set_save_point();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.pop_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n    let val = db.engine.get_value(b\"b\").unwrap();\n    assert!(val.is_none());\n    for i in 0..512_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_only_user_id() {\n    // test chown 1111 file.txt\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"id\").arg(\"-u\").run();\n    if skipping_test_is_okay(&result, \"id: cannot find name for group ID\") {\n        return;\n    }\n    let user_id = String::from(result.stdout_str().trim());\n    assert!(!user_id.is_empty());\n\n    let file1 = \"test_chown_file1\";\n    at.touch(file1);\n\n    let result = scene.ucmd().arg(user_id).arg(\"--verbose\").arg(file1).run();\n    if skipping_test_is_okay(&result, \"invalid user\") {\n        // From the Logs: \"Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)\"\n        // stderr: \"chown: invalid user: '1001'\n        return;\n    }\n    result.stderr_contains(\"retained as\");\n\n    scene\n        .ucmd()\n        .arg(\"0\")\n        .arg(\"--verbose\")\n        .arg(file1)\n        .fails()\n        .stderr_contains(\"failed to change\");\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_for() {\n    let mut context = Context::new();\n    let mut map = BTreeMap::new();\n    map.insert(\"name\", \"bob\");\n    map.insert(\"age\", \"18\");\n\n    context.insert(\"data\", &vec![1, 2, 3]);\n    context.insert(\"notes\", &vec![1, 2, 3]);\n    context.insert(\"vectors\", &vec![vec![0, 3, 6], vec![1, 4, 7]]);\n    context.insert(\"vectors_some_empty\", &vec![vec![0, 3, 6], vec![], vec![1, 4, 7]]);\n    context.insert(\"map\", &map);\n    context.insert(\"truthy\", &2);\n\n    let inputs = vec![\n        (\"{% for i in data %}{{i}}{% endfor %}\", \"123\"),\n        (\"{% for key, val in map %}{{key}}:{{val}} {% endfor %}\", \"age:18 name:bob \"),\n        (\n            \"{% for i in data %}{{loop.index}}{{loop.index0}}{{loop.first}}{{loop.last}}{% endfor %}\",\n            \"10truefalse21falsefalse32falsetrue\"\n        ),\n        (\n            \"{% for vector in vectors %}{% for j in vector %}{{ j }}{% endfor %}{% endfor %}\",\n            \"036147\"\n        ),\n        (\n            \"{% for vector in vectors_some_empty %}{% for j in vector %}{{ j }}{% endfor %}{% endfor %}\",\n            \"036147\"\n        ),\n        (\n            \"{% for val in data %}{% if val == truthy %}on{% else %}off{% endif %}{% endfor %}\",\n            \"offonoff\"\n        ),\n        (\"{% for i in range(end=5) %}{{i}}{% endfor %}\", \"01234\"),\n        (\"{% for i in range(end=5) | reverse %}{{i}}{% endfor %}\", \"43210\"),\n        (\n            \"{% set looped = 0 %}{% for i in range(end=5) %}{% set looped = i %}{{looped}}{% endfor%}{{looped}}\",\n            \"012340\"\n        ),\n        // https://github.com/Keats/tera/issues/184\n        (\"{% for note in notes %}{{ note }}{% endfor %}\", \"123\"),\n        (\"{% for note in notes | reverse %}{{ note }}{% endfor %}\", \"321\"),\n        (\"{% for v in vectors %}{{ v.0 }}{% endfor %}\", \"01\"),\n        // Loop control (`break` and `continue`)\n        // https://github.com/Keats/tera/issues/267\n        (\n            \"{% for i in data %}{{ i }}{% if i == 2 %}{% break %}{% endif %}{% endfor %}\",\n            \"12\"\n        ),\n        (\n            \"{% for i in data %}{% if i == 2 %}{% continue %}{% endif %}{{ i }}{% endfor %}\",\n            \"13\"\n        ),\n        (\n            \"{% for v in vectors %}{% for i in v %}{% if i == 3 %}{% break %}{% endif %}{{ i }}{% endfor %}{% endfor %}\",\n            \"0147\"\n        ),\n        (\n            \"{% for v in vectors %}{% for i in v %}{% if i == 3 %}{% continue %}{% endif %}{{ i }}{% endfor %}{% endfor %}\",\n            \"06147\"\n        ),\n        (\n            \"{% for a in [1, true, 1.1, 'hello'] %}{{a}}{% endfor %}\",\n            \"1true1.1hello\"\n        ),\n        // https://github.com/Keats/tera/issues/301\n        (\n            \"{% set start = 0 %}{% set end = start + 3 %}{% for i in range(start=start, end=end) %}{{ i }}{% endfor%}\",\n            \"012\"\n        ),\n        // https://github.com/Keats/tera/issues/395\n        (\n            \"{% for a in [] %}{{a}}{% else %}hello{% endfor %}\",\n            \"hello\"\n        ),\n        (\n            \"{% for a in undefined_variable | default(value=[]) %}{{a}}{% else %}hello{% endfor %}\",\n            \"hello\"\n        ),\n        (\n            \"{% for a in [] %}{{a}}{% else %}{% if 1 == 2 %}A{% else %}B{% endif %}{% endfor %}\",\n            \"B\"\n        ),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_i() {\n    // Test iterators that skip single, internal-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"__.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4__.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"_455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"__45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\"_.455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"__.45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4_5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4_5__.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"_45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"__45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"_45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"__45__.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"_45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"__4_5__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"_45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"__4_5__.56\");\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn invoke_post_return() -> Result<()> {\n    let component = r#\"\n        (component\n            (import \"f\" (func $f))\n\n            (core func $f_lower\n                (canon lower (func $f))\n            )\n            (core module $m\n                (import \"\" \"\" (func $f))\n\n                (func (export \"thunk\"))\n\n                (func $post_return\n                    call $f)\n                (export \"post-return\" (func $post_return))\n            )\n            (core instance $i (instantiate $m\n                (with \"\" (instance\n                    (export \"\" (func $f_lower))\n                ))\n            ))\n            (func (export \"thunk\")\n                (canon lift\n                    (core func $i \"thunk\")\n                    (post-return (func $i \"post-return\"))\n                )\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, false);\n    let mut linker = Linker::new(&engine);\n    linker.root().func_wrap(\n        \"f\",\n        |mut store: StoreContextMut<'_, bool>, _: ()| -> Result<()> {\n            assert!(!*store.data());\n            *store.data_mut() = true;\n            Ok(())\n        },\n    )?;\n\n    let instance = linker.instantiate(&mut store, &component)?;\n    let thunk = instance.get_typed_func::<(), ()>(&mut store, \"thunk\")?;\n\n    assert!(!*store.data());\n    thunk.call(&mut store, ())?;\n    assert!(!*store.data());\n    thunk.post_return(&mut store)?;\n    assert!(*store.data());\n\n    Ok(())\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn zero_rtt_rejection() {\n    let _guard = subscribe();\n    let mut server_crypto = server_crypto();\n    server_crypto.alpn_protocols = vec![\"foo\".into(), \"bar\".into()];\n    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);\n    let mut client_crypto = client_crypto();\n    client_crypto.alpn_protocols = vec![\"foo\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto.clone()));\n\n    // Establish normal connection\n    let client_ch = pair.begin_connect(client_config);\n    pair.drive();\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Connected)\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    pair.client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .close(pair.time, VarInt(0), [][..].into());\n    pair.drive();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::ConnectionLost { .. })\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    pair.client.connections.clear();\n    pair.server.connections.clear();\n\n    // Changing protocols invalidates 0-RTT\n    client_crypto.alpn_protocols = vec![\"bar\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto));\n    info!(\"resuming session\");\n    let client_ch = pair.begin_connect(client_config);\n    assert!(pair.client_conn_mut(client_ch).has_0rtt());\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    const MSG: &[u8] = b\"Hello, 0-RTT!\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive();\n    assert!(!pair.client_conn_mut(client_ch).accepted_0rtt());\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Connected)\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n    let s2 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    assert_eq!(s, s2);\n\n    let mut recv = pair.server_recv(server_ch, s2);\n    let mut chunks = recv.read(false).unwrap();\n    assert_eq!(chunks.next(usize::MAX), Err(ReadError::Blocked));\n    let _ = chunks.finalize();\n    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_hard_link() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.hard_link(SUB_FILE, SUB_LINK);\n\n    let result = ts.ucmd().arg(SUB_DIR_LINKS).succeeds();\n\n    #[cfg(target_os = \"linux\")]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n    // We do not double count hard links as the inodes are identical\n    _du_hard_link(result.stdout_str());\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn reject_self_signed_server_cert() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config_with_certs(vec![]));\n    pair.drive();\n    assert_matches!(pair.client_conn_mut(client_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::TransportError(ref error)})\n                    if error.code == TransportErrorCode::crypto(AlertDescription::UnknownCA.get_u8()));\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_arg_symlink() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"--symbolic-link\")\n        .arg(TEST_HELLO_WORLD_DEST)\n        .succeeds();\n\n    assert!(at.is_symlink(TEST_HELLO_WORLD_DEST));\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        self.max_expire_ts.is_some() || self.min_expire_ts.is_some()\n    }", "test": "fn test_gc_bypass_raft() {\n    let (cluster, leader, ctx) = must_new_cluster_mul(2);\n    cluster.pd_client.disable_default_operator();\n\n    let env = Arc::new(Environment::new(1));\n    let leader_store = leader.get_store_id();\n    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader_store));\n    let client = TikvClient::new(channel);\n\n    let pk = b\"k1\".to_vec();\n    let value = vec![b'x'; 300];\n    let engine = cluster.engines.get(&leader_store).unwrap();\n\n    for &start_ts in &[10, 20, 30, 40] {\n        let commit_ts = start_ts + 5;\n        let muts = vec![new_mutation(Op::Put, b\"k1\", &value)];\n\n        must_kv_prewrite(&client, ctx.clone(), muts, pk.clone(), start_ts);\n        let keys = vec![pk.clone()];\n        must_kv_commit(&client, ctx.clone(), keys, start_ts, commit_ts, commit_ts);\n\n        let key = Key::from_raw(b\"k1\").append_ts(start_ts.into());\n        let key = data_key(key.as_encoded());\n        assert!(engine.kv.get_value(&key).unwrap().is_some());\n\n        let key = Key::from_raw(b\"k1\").append_ts(commit_ts.into());\n        let key = data_key(key.as_encoded());\n        assert!(engine.kv.get_value_cf(CF_WRITE, &key).unwrap().is_some());\n    }\n\n    let node_ids = cluster.get_node_ids();\n    for store_id in node_ids {\n        let gc_sched = cluster.sim.rl().get_gc_worker(store_id).scheduler();\n\n        let mut region = cluster.get_region(b\"a\");\n        region.set_start_key(b\"k1\".to_vec());\n        region.set_end_key(b\"k2\".to_vec());\n        sync_gc(&gc_sched, region, 200.into()).unwrap();\n\n        let engine = cluster.engines.get(&store_id).unwrap();\n        for &start_ts in &[10, 20, 30] {\n            let commit_ts = start_ts + 5;\n            let key = Key::from_raw(b\"k1\").append_ts(start_ts.into());\n            let key = data_key(key.as_encoded());\n            assert!(engine.kv.get_value(&key).unwrap().is_none());\n\n            let key = Key::from_raw(b\"k1\").append_ts(commit_ts.into());\n            let key = data_key(key.as_encoded());\n            assert!(engine.kv.get_value_cf(CF_WRITE, &key).unwrap().is_none());\n        }\n    }\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_exponent_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.exponent(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.exponent(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.exponent(b'^');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"code": "pub fn borrow_mut(&self) -> GcRefMut<'_, T> {\n        match self.try_borrow_mut() {\n            Ok(value) => value,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn gc_basic_cell_allocation() {\n    run_test(|| {\n        let gc_cell = Gc::new(GcRefCell::new(16_u16));\n\n        force_collect();\n        Harness::assert_collections(1);\n        Harness::assert_bytes_allocated();\n        assert_eq!(*gc_cell.borrow_mut(), 16);\n    });\n}"}
{"code": "pub fn to_vec(self) -> Vec<u8> {\n        if self.is_empty() {\n            return vec![];\n        }\n        let ctx = self.bits();\n        vec![ctx]\n    }", "test": "fn test_raft_storage_get_after_lease() {\n    let (cluster, storage, ctx) = new_raft_storage();\n    let key = b\"key\";\n    let value = b\"value\";\n    assert_eq!(\n        storage\n            .raw_get(ctx.clone(), \"\".to_string(), key.to_vec())\n            .unwrap(),\n        None\n    );\n    storage\n        .raw_put(ctx.clone(), \"\".to_string(), key.to_vec(), value.to_vec())\n        .unwrap();\n    assert_eq!(\n        storage\n            .raw_get(ctx.clone(), \"\".to_string(), key.to_vec())\n            .unwrap()\n            .unwrap(),\n        value.to_vec()\n    );\n\n    // Sleep until the leader lease is expired.\n    thread::sleep(cluster.cfg.raft_store.raft_store_max_leader_lease.0);\n    assert_eq!(\n        storage\n            .raw_get(ctx, \"\".to_string(), key.to_vec())\n            .unwrap()\n            .unwrap(),\n        value.to_vec()\n    );\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn can_do_string_concat() {\n    let mut context = Context::new();\n    context.insert(\"a_string\", \"hello\");\n    context.insert(\"another_string\", \"xXx\");\n    context.insert(\"an_int\", &1);\n    context.insert(\"a_float\", &3.18);\n\n    let inputs = vec![\n        (r#\"{{ \"hello\" ~ \" world\" }}\"#, \"hello world\"),\n        (r#\"{{ \"hello\" ~ 1 }}\"#, \"hello1\"),\n        (r#\"{{ \"hello\" ~ 3.18 }}\"#, \"hello3.18\"),\n        (r#\"{{ 3.18 ~ \"hello\"}}\"#, \"3.18hello\"),\n        (r#\"{{ \"hello\" ~ get_string() }}\"#, \"helloHello\"),\n        (r#\"{{ get_string() ~ \"hello\" }}\"#, \"Hellohello\"),\n        (r#\"{{ get_string() ~ 3.18 }}\"#, \"Hello3.18\"),\n        (r#\"{{ a_string ~ \" world\" }}\"#, \"hello world\"),\n        (r#\"{{ a_string ~ ' world ' ~ another_string }}\"#, \"hello world xXx\"),\n        (r#\"{{ a_string ~ another_string }}\"#, \"helloxXx\"),\n        (r#\"{{ a_string ~ an_int }}\"#, \"hello1\"),\n        (r#\"{{ a_string ~ a_float }}\"#, \"hello3.18\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_effective_suffix_hex_last() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\n        \"-n\",\n        \"4\",\n        \"--hex-suffixes=7\",\n        \"--numeric-suffixes=4\",\n        \"-x\",\n        \"-d\",\n        \"--hex-suffixes=9\",\n        \"threebytes.txt\",\n    ])\n    .succeeds()\n    .no_stdout()\n    .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x0a\"), \"b\");\n    assert_eq!(at.read(\"x0b\"), \"c\");\n    assert_eq!(at.read(\"x0c\"), \"\");\n}"}
{"code": "pub fn verified_expr(&self, sql: &str) -> Expr {\n        self.expr_parses_to(sql, sql)\n    }", "test": "fn parse_scalar_subqueries() {\n    let sql = \"(SELECT 1) + (SELECT 2)\";\n    assert_matches!(\n        verified_expr(sql),\n        Expr::BinaryOp {\n            op: BinaryOperator::Plus,\n            ..\n        }\n    );\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_hard_logical() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"file1\";\n    let link = \"symlink1\";\n    let target = \"hard-to-a\";\n    let target2 = \"hard-to-a2\";\n    at.touch(file_a);\n    at.symlink_file(file_a, link);\n\n    ucmd.args(&[\"-P\", \"-L\", link, target]);\n    assert!(!at.is_symlink(target));\n\n    ucmd.args(&[\"-P\", \"-L\", \"-s\", link, target2]);\n    assert!(!at.is_symlink(target2));\n}"}
{"code": "pub fn eval<S: Serialize>(&self, ctx: S) -> Result<Value, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _eval.\n        self._eval(Value::from_serializable(&ctx))\n    }", "test": "fn test_expression() {\n    let env = Environment::new();\n    let expr = env.compile_expression(\"foo + bar\").unwrap();\n    let mut ctx = BTreeMap::new();\n    ctx.insert(\"foo\", 42);\n    ctx.insert(\"bar\", 23);\n    assert_eq!(expr.eval(&ctx).unwrap(), Value::from(65));\n}"}
{"code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_capacity() {\n  let mut tv: TinyVec<[i32; 1]> = Default::default();\n  assert_eq!(tv.capacity(), 1);\n  tv.move_to_the_heap();\n  tv.extend_from_slice(&[1, 2, 3, 4]);\n  assert_eq!(tv.capacity(), 4);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_custom_backup_suffix_via_env() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_custom_backup_suffix_file_a\";\n    let file_b = \"test_mv_custom_backup_suffix_file_b\";\n    let suffix = \"super-suffix-of-the-century\";\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"-b\")\n        .env(\"SIMPLE_BACKUP_SUFFIX\", suffix)\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}{suffix}\")));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn vec_var_width_value_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<u8, Vec<&str>> = TableDefinition::new(\"x\");\n\n    let value = vec![\"hello\", \"world\"];\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(0, &value).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n    assert_eq!(value, table.get(0).unwrap().unwrap().value());\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn pass_guest_back_as_borrow() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (type $t' (resource (rep i32)))\n\n                (export $t \"t\" (type $t'))\n\n                (core func $new (canon resource.new $t))\n\n                (core module $m\n                    (import \"\" \"new\" (func $new (param i32) (result i32)))\n\n                    (func (export \"mk\") (result i32)\n                        (call $new (i32.const 100))\n                    )\n\n                    (func (export \"take\") (param i32)\n                        (if (i32.ne (local.get 0) (i32.const 100)) (then (unreachable)))\n                    )\n                )\n                (core instance $i (instantiate $m\n                    (with \"\" (instance\n                        (export \"new\" (func $new))\n                    ))\n                ))\n\n                (func (export \"mk\") (result (own $t))\n                    (canon lift (core func $i \"mk\")))\n                (func (export \"take\") (param \"x\" (borrow $t))\n                    (canon lift (core func $i \"take\")))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let i = Linker::new(&engine).instantiate(&mut store, &c)?;\n    let mk = i.get_typed_func::<(), (ResourceAny,)>(&mut store, \"mk\")?;\n    let take = i.get_typed_func::<(&ResourceAny,), ()>(&mut store, \"take\")?;\n\n    let (resource,) = mk.call(&mut store, ())?;\n    mk.post_return(&mut store)?;\n    take.call(&mut store, (&resource,))?;\n    take.post_return(&mut store)?;\n\n    resource.resource_drop(&mut store)?;\n\n    // Should not be valid to use `resource` again\n    let err = take.call(&mut store, (&resource,)).unwrap_err();\n    assert_eq!(err.to_string(), \"unknown handle index 0\");\n\n    Ok(())\n}"}
{"code": "pub fn get_version(&self) -> u64 {\n        self.memtable_version\n    }", "test": "fn test_node_merge_rollback() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run_conf_change();\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    pd_client.must_add_peer(left.get_id(), new_peer(2, 2));\n    pd_client.must_add_peer(right.get_id(), new_peer(2, 4));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    let target_region = pd_client.get_region(b\"k3\").unwrap();\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    // The call is finished when prepare_merge is applied.\n    cluster.must_try_merge(region.get_id(), target_region.get_id());\n\n    // Add a peer to trigger rollback.\n    pd_client.must_add_peer(right.get_id(), new_peer(3, 5));\n    cluster.must_put(b\"k4\", b\"v4\");\n    must_get_equal(&cluster.get_engine(3), b\"k4\", b\"v4\");\n\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n    // After split and prepare_merge, version becomes 1 + 2 = 3;\n    assert_eq!(region.get_region_epoch().get_version(), 3);\n    // After ConfChange and prepare_merge, conf version becomes 1 + 2 = 3;\n    assert_eq!(region.get_region_epoch().get_conf_ver(), 3);\n    fail::remove(schedule_merge_fp);\n    // Wait till rollback.\n    cluster.must_put(b\"k11\", b\"v11\");\n\n    // After rollback, version becomes 3 + 1 = 4;\n    region.mut_region_epoch().set_version(4);\n    for i in 1..3 {\n        must_get_equal(&cluster.get_engine(i), b\"k11\", b\"v11\");\n        let state_key = keys::region_state_key(region.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Normal);\n        assert_eq!(*state.get_region(), region);\n    }\n\n    pd_client.must_remove_peer(right.get_id(), new_peer(3, 5));\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    let target_region = pd_client.get_region(b\"k3\").unwrap();\n    cluster.must_try_merge(region.get_id(), target_region.get_id());\n    let mut region = pd_client.get_region(b\"k1\").unwrap();\n\n    // Split to trigger rollback.\n    cluster.must_split(&right, b\"k3\");\n    fail::remove(schedule_merge_fp);\n    // Wait till rollback.\n    cluster.must_put(b\"k12\", b\"v12\");\n\n    // After premerge and rollback, conf_ver becomes 3 + 1 = 4, version becomes 4 +\n    // 2 = 6;\n    region.mut_region_epoch().set_conf_ver(4);\n    region.mut_region_epoch().set_version(6);\n    for i in 1..3 {\n        must_get_equal(&cluster.get_engine(i), b\"k12\", b\"v12\");\n        let state_key = keys::region_state_key(region.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Normal);\n        assert_eq!(*state.get_region(), region);\n    }\n}"}
{"code": "pub fn get<Q>(&self, key: &Q) -> Option<&Value>\n    where\n        String: Borrow<Q>,\n        Q: ?Sized + Ord + Eq + Hash,\n    {\n        self.map.get(key)\n    }", "test": "fn test_raw_value_in_map_key() {\n    #[derive(RefCast)]\n    #[repr(transparent)]\n    struct RawMapKey(RawValue);\n\n    impl<'de> Deserialize<'de> for &'de RawMapKey {\n        fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>\n        where\n            D: serde::Deserializer<'de>,\n        {\n            let raw_value = <&RawValue>::deserialize(deserializer)?;\n            Ok(RawMapKey::ref_cast(raw_value))\n        }\n    }\n\n    impl PartialEq for RawMapKey {\n        fn eq(&self, other: &Self) -> bool {\n            self.0.get() == other.0.get()\n        }\n    }\n\n    impl Eq for RawMapKey {}\n\n    impl Hash for RawMapKey {\n        fn hash<H: Hasher>(&self, hasher: &mut H) {\n            self.0.get().hash(hasher);\n        }\n    }\n\n    let map_from_str: HashMap<&RawMapKey, &RawValue> =\n        serde_json::from_str(r#\" {\"\\\\k\":\"\\\\v\"} \"#).unwrap();\n    let (map_k, map_v) = map_from_str.into_iter().next().unwrap();\n    assert_eq!(\"\\\"\\\\\\\\k\\\"\", map_k.0.get());\n    assert_eq!(\"\\\"\\\\\\\\v\\\"\", map_v.get());\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }", "test": "fn write_batch_clear() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.clear();\n    assert!(wb.is_empty());\n    assert_eq!(wb.count(), 0);\n    wb.write().unwrap();\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.clear();\n    assert!(wb.is_empty());\n    assert_eq!(wb.count(), 0);\n    wb.write().unwrap();\n    for i in 0..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn name(&self) -> Option<&str> {\n        self.compiled_module().module().name.as_deref()\n    }", "test": "fn test_module_name() -> anyhow::Result<()> {\n    let engine = Engine::default();\n    let wat = r#\"\n        (module $from_name_section\n        (func (export \"run\") (nop))\n        )\n    \"#;\n\n    let module = Module::new(&engine, wat)?;\n    assert_eq!(module.name(), Some(\"from_name_section\"));\n\n    Ok(())\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn large_initial() {\n    let _guard = subscribe();\n    let mut server_crypto = server_crypto();\n    server_crypto.alpn_protocols = vec![vec![0, 0, 0, 42]];\n    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));\n\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);\n    let mut client_crypto = client_crypto();\n    let protocols = (0..1000u32)\n        .map(|x| x.to_be_bytes().to_vec())\n        .collect::<Vec<_>>();\n    client_crypto.alpn_protocols = protocols;\n    let cfg = ClientConfig::new(Arc::new(client_crypto));\n    let client_ch = pair.begin_connect(cfg);\n    pair.drive();\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"code": "pub fn s2d(buffer: &[u8]) -> Result<f64, Error> {\n    let len = buffer.len();\n    if len == 0 {\n        return Err(Error::InputTooShort);\n    }\n\n    let mut m10digits = 0;\n    let mut e10digits = 0;\n    let mut dot_index = len;\n    let mut e_index = len;\n    let mut m10 = 0u64;\n    let mut e10 = 0i32;\n    let mut signed_m = false;\n    let mut signed_e = false;\n\n    let mut i = 0;\n    if unsafe { *buffer.get_unchecked(0) } == b'-' {\n        signed_m = true;\n        i += 1;\n    }\n\n    while let Some(c) = buffer.get(i).copied() {\n        if c == b'.' {\n            if dot_index != len {\n                return Err(Error::MalformedInput);\n            }\n            dot_index = i;\n            i += 1;\n            continue;\n        }\n        if c < b'0' || c > b'9' {\n            break;\n        }\n        if m10digits >= 17 {\n            return Err(Error::InputTooLong);\n        }\n        m10 = 10 * m10 + (c - b'0') as u64;\n        if m10 != 0 {\n            m10digits += 1;\n        }\n        i += 1;\n    }\n\n    if let Some(b'e') | Some(b'E') = buffer.get(i) {\n        e_index = i;\n        i += 1;\n        match buffer.get(i) {\n            Some(b'-') => {\n                signed_e = true;\n                i += 1;\n            }\n            Some(b'+') => i += 1,\n            _ => {}\n        }\n        while let Some(c) = buffer.get(i).copied() {\n            if c < b'0' || c > b'9' {\n                return Err(Error::MalformedInput);\n            }\n            if e10digits > 3 {\n                // TODO: Be more lenient. Return +/-Infinity or +/-0 instead.\n                return Err(Error::InputTooLong);\n            }\n            e10 = 10 * e10 + (c - b'0') as i32;\n            if e10 != 0 {\n                e10digits += 1;\n            }\n            i += 1;\n        }\n    }\n\n    if i < len {\n        return Err(Error::MalformedInput);\n    }\n    if signed_e {\n        e10 = -e10;\n    }\n    e10 -= if dot_index < e_index {\n        (e_index - dot_index - 1) as i32\n    } else {\n        0\n    };\n    if m10 == 0 {\n        return Ok(if signed_m { -0.0 } else { 0.0 });\n    }\n\n    if m10digits + e10 <= -324 || m10 == 0 {\n        // Number is less than 1e-324, which should be rounded down to 0; return\n        // +/-0.0.\n        let ieee = (signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n    if m10digits + e10 >= 310 {\n        // Number is larger than 1e+309, which should be rounded to +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // Convert to binary float m2 * 2^e2, while retaining information about\n    // whether the conversion was exact (trailing_zeros).\n    let e2: i32;\n    let m2: u64;\n    let mut trailing_zeros: bool;\n    if e10 >= 0 {\n        // The length of m * 10^e in bits is:\n        //   log2(m10 * 10^e10) = log2(m10) + e10 log2(10) = log2(m10) + e10 + e10 * log2(5)\n        //\n        // We want to compute the DOUBLE_MANTISSA_BITS + 1 top-most bits (+1 for\n        // the implicit leading one in IEEE format). We therefore choose a\n        // binary output exponent of\n        //   log2(m10 * 10^e10) - (DOUBLE_MANTISSA_BITS + 1).\n        //\n        // We use floor(log2(5^e10)) so that we get at least this many bits;\n        // better to have an additional bit than to not have enough bits.\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_add(log2_pow5(e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n\n        // We now compute [m10 * 10^e10 / 2^e2] = [m10 * 5^e10 / 2^(e2-e10)].\n        // To that end, we use the DOUBLE_POW5_SPLIT table.\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_sub(ceil_log2_pow5(e10))\n            .wrapping_add(d2s::DOUBLE_POW5_BITCOUNT);\n        debug_assert!(j >= 0);\n        debug_assert!(e10 < d2s::DOUBLE_POW5_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_SPLIT.get_unchecked(e10 as usize) },\n            j as u32,\n        );\n\n        // We also compute if the result is exact, i.e.,\n        //   [m10 * 10^e10 / 2^e2] == m10 * 10^e10 / 2^e2.\n        // This can only be the case if 2^e2 divides m10 * 10^e10, which in turn\n        // requires that the largest power of 2 that divides m10 + e10 is\n        // greater than e2. If e2 is less than e10, then the result must be\n        // exact. Otherwise we use the existing multiple_of_power_of_2 function.\n        trailing_zeros =\n            e2 < e10 || e2 - e10 < 64 && multiple_of_power_of_2(m10, (e2 - e10) as u32);\n    } else {\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_sub(ceil_log2_pow5(-e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_add(ceil_log2_pow5(-e10))\n            .wrapping_sub(1)\n            .wrapping_add(d2s::DOUBLE_POW5_INV_BITCOUNT);\n        debug_assert!(-e10 < d2s::DOUBLE_POW5_INV_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_INV_SPLIT.get_unchecked(-e10 as usize) },\n            j as u32,\n        );\n        trailing_zeros = multiple_of_power_of_5(m10, -e10 as u32);\n    }\n\n    // Compute the final IEEE exponent.\n    let mut ieee_e2 = i32::max(0, e2 + DOUBLE_EXPONENT_BIAS as i32 + floor_log2(m2) as i32) as u32;\n\n    if ieee_e2 > 0x7fe {\n        // Final IEEE exponent is larger than the maximum representable; return +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // We need to figure out how much we need to shift m2. The tricky part is\n    // that we need to take the final IEEE exponent into account, so we need to\n    // reverse the bias and also special-case the value 0.\n    let shift = if ieee_e2 == 0 { 1 } else { ieee_e2 as i32 }\n        .wrapping_sub(e2)\n        .wrapping_sub(DOUBLE_EXPONENT_BIAS as i32)\n        .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS as i32);\n    debug_assert!(shift >= 0);\n\n    // We need to round up if the exact value is more than 0.5 above the value\n    // we computed. That's equivalent to checking if the last removed bit was 1\n    // and either the value was not just trailing zeros or the result would\n    // otherwise be odd.\n    //\n    // We need to update trailing_zeros given that we have the exact output\n    // exponent ieee_e2 now.\n    trailing_zeros &= (m2 & ((1_u64 << (shift - 1)) - 1)) == 0;\n    let last_removed_bit = (m2 >> (shift - 1)) & 1;\n    let round_up = last_removed_bit != 0 && (!trailing_zeros || ((m2 >> shift) & 1) != 0);\n\n    let mut ieee_m2 = (m2 >> shift).wrapping_add(round_up as u64);\n    debug_assert!(ieee_m2 <= 1_u64 << (d2s::DOUBLE_MANTISSA_BITS + 1));\n    ieee_m2 &= (1_u64 << d2s::DOUBLE_MANTISSA_BITS) - 1;\n    if ieee_m2 == 0 && round_up {\n        // Due to how the IEEE represents +/-Infinity, we don't need to check\n        // for overflow here.\n        ieee_e2 += 1;\n    }\n    let ieee = ((((signed_m as u64) << d2s::DOUBLE_EXPONENT_BITS) | ieee_e2 as u64)\n        << d2s::DOUBLE_MANTISSA_BITS)\n        | ieee_m2;\n    Ok(f64::from_bits(ieee))\n}", "test": "fn test_overflow() {\n    assert_eq!(f64::INFINITY, s2d(b\"2e308\").unwrap());\n    assert_eq!(f64::INFINITY, s2d(b\"1e309\").unwrap());\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        // `cmp rdi, -1` -- basically: `repr as i64 == -1`\n        let empty = Self::empty();\n        let is_empty = self.head == empty.head && self.tail == empty.tail;\n        // The empty representation does nothing on Drop. We can't let this one\n        // drop normally because `impl Drop for Identifier` calls is_empty; that\n        // would be an infinite recursion.\n        mem::forget(empty);\n        is_empty\n    }", "test": "fn test_new() {\n    fn test(identifier: Prerelease, expected: &str) {\n        assert_eq!(identifier.is_empty(), expected.is_empty());\n        assert_eq!(identifier.len(), expected.len());\n        assert_eq!(identifier.as_str(), expected);\n        assert_eq!(identifier, identifier);\n        assert_eq!(identifier, identifier.clone());\n    }\n\n    let ref mut string = String::new();\n    let limit = if cfg!(miri) { 40 } else { 280 }; // miri is slow\n    for _ in 0..limit {\n        test(prerelease(string), string);\n        string.push('1');\n    }\n\n    if !cfg!(miri) {\n        let ref string = string.repeat(20000);\n        test(prerelease(string), string);\n    }\n}"}
{"code": "pub fn recv(&mut self, peer_msg_buf: &mut Vec<PeerMsg>, batch_size: usize) -> usize {\n        let l = peer_msg_buf.len();\n        for i in l..batch_size {\n            match self.receiver.try_recv() {\n                Ok(msg) => peer_msg_buf.push(msg),\n                Err(e) => {\n                    if let TryRecvError::Disconnected = e {\n                        self.is_stopped = true;\n                    }\n                    return i - l;\n                }\n            }\n        }\n        batch_size - l\n    }", "test": "fn test_old_value_cache_without_downstreams() {\n    fn check_old_value_cache(scheduler: &Scheduler<Task>, updates: usize) {\n        let (tx, rx) = mpsc::sync_channel(1);\n        let checker = move |c: &OldValueCache| tx.send(c.update_count()).unwrap();\n        scheduler\n            .schedule(Task::Validate(Validate::OldValueCache(Box::new(checker))))\n            .unwrap();\n        assert_eq!(rx.recv().unwrap(), updates);\n    }\n\n    let mutation = || {\n        let mut mutation = Mutation::default();\n        mutation.set_op(Op::Put);\n        mutation.key = b\"key\".to_vec();\n        mutation.value = b\"value\".to_vec();\n        mutation\n    };\n\n    fail::cfg(\"cdc_flush_old_value_metrics\", \"return\").unwrap();\n\n    let cluster = new_server_cluster(0, 1);\n    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();\n    let scheduler = suite.endpoints[&1].scheduler();\n\n    // Add a subscription and then check old value cache.\n    let (mut req_tx, event_feed, receive_event) = new_event_feed(suite.get_region_cdc_client(1));\n    let req = suite.new_changedata_request(1);\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n    receive_event(false); // Wait until the initialization finishes.\n\n    // Old value cache will be updated because there is 1 capture.\n    suite.must_kv_prewrite(1, vec![mutation()], b\"key\".to_vec(), 3.into());\n    suite.must_kv_commit(1, vec![b\"key\".to_vec()], 3.into(), 4.into());\n    check_old_value_cache(&scheduler, 1);\n\n    drop(req_tx);\n    drop(event_feed);\n    drop(receive_event);\n    sleep_ms(200);\n\n    // Old value cache won't be updated because there is no captures.\n    suite.must_kv_prewrite(1, vec![mutation()], b\"key\".to_vec(), 5.into());\n    suite.must_kv_commit(1, vec![b\"key\".to_vec()], 5.into(), 6.into());\n    check_old_value_cache(&scheduler, 1);\n\n    fail::remove(\"cdc_flush_old_value_metrics\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_both_time_and_reference() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ref_file = \"test_touch_reference\";\n    let file = \"test_touch_set_both_time_and_reference\";\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n\n    at.touch(ref_file);\n    set_file_times(&at, ref_file, start_of_year, start_of_year);\n    assert!(at.file_exists(ref_file));\n\n    ucmd.args(&[\"-t\", \"2015010112342\", \"-r\", ref_file, file])\n        .fails();\n}"}
{"code": "pub fn has_region_error(&self) -> bool {\n        matches!(\n            self,\n            Error::Kv(KvError(box EngineErrorInner::Request(_)))\n                | Error::Txn(TxnError(box TxnErrorInner::Engine(KvError(\n                    box EngineErrorInner::Request(_),\n                ))))\n                | Error::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(\n                    box MvccErrorInner::Kv(KvError(box EngineErrorInner::Request(_))),\n                ))))\n                | Error::Request(_)\n        )\n    }", "test": "fn test_merge_with_concurrent_pessimistic_locking() {\n    let mut cluster = new_server_cluster(0, 2);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.pessimistic_txn.pipelined = true;\n    cluster.cfg.pessimistic_txn.in_memory = true;\n    cluster.run();\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k2\");\n    let left = cluster.get_region(b\"k1\");\n    let right = cluster.get_region(b\"k3\");\n\n    // Transfer the leader of the right region to store 2. The leaders of source and\n    // target regions don't need to be on the same store.\n    cluster.must_transfer_leader(right.id, new_peer(2, 2));\n\n    let snapshot = cluster.must_get_snapshot_of_region(left.id);\n    let txn_ext = snapshot.txn_ext.unwrap();\n    txn_ext\n        .pessimistic_locks\n        .write()\n        .insert(vec![(\n            Key::from_raw(b\"k0\"),\n            PessimisticLock {\n                primary: b\"k0\".to_vec().into_boxed_slice(),\n                start_ts: 10.into(),\n                ttl: 3000,\n                for_update_ts: 20.into(),\n                min_commit_ts: 30.into(),\n                last_change_ts: 15.into(),\n                versions_to_last_change: 3,\n            },\n        )])\n        .unwrap();\n\n    let addr = cluster.sim.rl().get_addr(1);\n    let env = Arc::new(Environment::new(1));\n    let channel = ChannelBuilder::new(env).connect(&addr);\n    let client = TikvClient::new(channel);\n\n    fail::cfg(\"before_propose_locks_on_region_merge\", \"pause\").unwrap();\n\n    // 1. Locking before proposing pessimistic locks in the source region can\n    // succeed.\n    let client2 = client.clone();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::PessimisticLock);\n    mutation.key = b\"k1\".to_vec();\n    let mut req = PessimisticLockRequest::default();\n    req.set_context(cluster.get_ctx(b\"k1\"));\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(10);\n    req.set_for_update_ts(10);\n    req.set_primary_lock(b\"k1\".to_vec());\n    fail::cfg(\"txn_before_process_write\", \"pause\").unwrap();\n    let res = thread::spawn(move || client2.kv_pessimistic_lock(&req).unwrap());\n    thread::sleep(Duration::from_millis(150));\n    cluster.merge_region(left.id, right.id, Callback::None);\n    thread::sleep(Duration::from_millis(150));\n    fail::remove(\"txn_before_process_write\");\n    let resp = res.join().unwrap();\n    assert!(!resp.has_region_error());\n    fail::remove(\"before_propose_locks_on_region_merge\");\n\n    // 2. After locks are proposed, later pessimistic lock request should fail.\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::PessimisticLock);\n    mutation.key = b\"k11\".to_vec();\n    let mut req = PessimisticLockRequest::default();\n    req.set_context(cluster.get_ctx(b\"k11\"));\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(10);\n    req.set_for_update_ts(10);\n    req.set_primary_lock(b\"k11\".to_vec());\n    fail::cfg(\"txn_before_process_write\", \"pause\").unwrap();\n    let res = thread::spawn(move || client.kv_pessimistic_lock(&req).unwrap());\n    thread::sleep(Duration::from_millis(200));\n    fail::remove(\"txn_before_process_write\");\n    let resp = res.join().unwrap();\n    assert!(resp.has_region_error());\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn test_async_host_func_pending() {\n    let engine = Engine::default();\n    let mut linker = Linker::new(&engine);\n    atoms::add_to_linker(&mut linker, |cx| cx).unwrap();\n    let mut store = store(&engine);\n\n    let shim_mod = shim_module(&engine);\n    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();\n\n    let result_location: i32 = 0;\n\n    // This input triggers the host func pending forever\n    let input: i32 = TRIGGER_PENDING as i32;\n    let trap = shim_inst\n        .get_func(&mut store, \"double_int_return_float_shim\")\n        .unwrap()\n        .call(\n            &mut store,\n            &[input.into(), result_location.into()],\n            &mut [Val::I32(0)],\n        )\n        .unwrap_err();\n    assert!(\n        format!(\"{:?}\", trap).contains(\"Cannot wait on pending future\"),\n        \"expected get a pending future Trap from dummy executor, got: {}\",\n        trap\n    );\n}"}
{"code": "fn len(&self) -> usize {\n            self.hash_table.len()\n        }", "test": "fn traps_without_address_map() -> Result<()> {\n    let mut config = Config::new();\n    config.generate_address_map(false);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, ());\n    let wat = r#\"\n        (module $hello_mod\n            (func (export \"run\") (call $hello))\n            (func $hello (unreachable))\n        )\n    \"#;\n\n    let module = Module::new(store.engine(), wat)?;\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let run_func = instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n\n    let e = run_func.call(&mut store, ()).unwrap_err();\n\n    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    assert_eq!(trace.len(), 2);\n    assert_eq!(trace[0].func_name(), Some(\"hello\"));\n    assert_eq!(trace[0].func_index(), 1);\n    assert_eq!(trace[0].module_offset(), None);\n    assert_eq!(trace[1].func_name(), None);\n    assert_eq!(trace[1].func_index(), 0);\n    assert_eq!(trace[1].module_offset(), None);\n    Ok(())\n}"}
{"code": "pub fn has_errors(&self) -> bool {\n        self.diagnostics\n            .iter()\n            .any(|diagnostic| diagnostic.is_error())\n    }", "test": "fn quick_test() {\n    let source = r#\"{\n        \"javascript\": {\n            \"formatter\": {\n                \"overrides\": [\n                {}]\n            }\n        }\n    }\"#;\n    let result = deserialize_from_json_str::<Configuration>(source, JsonParserOptions::default());\n\n    dbg!(result.diagnostics());\n    assert!(!result.has_errors());\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_ilt() {\n    // Test iterators that skip single digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_leading_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"_45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"_45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"_45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"_4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"_4_5_.56\");\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_single_primary_column() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, None, 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n\n    let req = new_analyze_column_req(&product, 1, 3, 3, 3, 4, 32);\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_data().is_empty());\n    let mut analyze_resp = AnalyzeColumnsResp::default();\n    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n    let hist = analyze_resp.get_pk_hist();\n    assert_eq!(hist.get_buckets().len(), 2);\n    assert_eq!(hist.get_ndv(), 4);\n    let collectors = analyze_resp.get_collectors().to_vec();\n    assert_eq!(collectors.len(), 0);\n}"}
{"code": "pub fn as_str(&self) -> Option<&str> {\n        match self {\n            KeyRef::Value(v) => v.as_str(),\n            KeyRef::Str(s) => Some(s),\n        }\n    }", "test": "fn test_macro_passing() {\n    let env = Environment::new();\n    let tmpl = env\n        .template_from_str(\"{% macro m(a) %}{{ a }}{% endmacro %}\")\n        .unwrap();\n    let (_, state) = tmpl.render_and_return_state(()).unwrap();\n    let m = state.lookup(\"m\").unwrap();\n    assert_eq!(m.get_attr(\"name\").unwrap().as_str(), Some(\"m\"));\n    let rv = m.call(&state, args!(42)).unwrap();\n    assert_eq!(rv.as_str(), Some(\"42\"));\n\n    // if we call the macro on an empty state it errors\n    let empty_state = env.empty_state();\n    let err = m.call(&empty_state, args!(42)).unwrap_err();\n    assert_eq!(err.kind(), ErrorKind::InvalidOperation);\n    assert_eq!(\n        err.detail(),\n        Some(\"cannot call this macro. template state went away.\")\n    );\n}"}
{"code": "pub fn is_normalized(&self) -> bool {\n        bigint::is_normalized(self)\n    }", "test": "fn math_test() {\n    let mut x = VecType::try_from(&[0, 1, 9]).unwrap();\n    assert_eq!(x.is_normalized(), true);\n    x.try_push(0).unwrap();\n    assert_eq!(&*x, &[0, 1, 9, 0]);\n    assert_eq!(x.is_normalized(), false);\n    x.normalize();\n    assert_eq!(&*x, &[0, 1, 9]);\n    assert_eq!(x.is_normalized(), true);\n\n    x.add_small(1);\n    assert_eq!(&*x, &[1, 1, 9]);\n    x.add_small(LIMB_MAX);\n    assert_eq!(&*x, &[0, 2, 9]);\n\n    x.mul_small(3);\n    assert_eq!(&*x, &[0, 6, 27]);\n    x.mul_small(LIMB_MAX);\n    let expected: VecType = if bigint::LIMB_BITS == 32 {\n        vec_from_u32(&[0, 4294967290, 4294967274, 26])\n    } else {\n        vec_from_u32(&[0, 0, 4294967290, 4294967295, 4294967274, 4294967295, 26])\n    };\n    assert_eq!(&*x, &*expected);\n\n    let mut x = VecType::from_u64(0xFFFFFFFF);\n    let y = VecType::from_u64(5);\n    x *= &y;\n    let expected: VecType = vec_from_u32(&[0xFFFFFFFB, 0x4]);\n    assert_eq!(&*x, &*expected);\n\n    // Test with carry\n    let mut x = VecType::from_u64(1);\n    assert_eq!(&*x, &[1]);\n    x.add_small(LIMB_MAX);\n    assert_eq!(&*x, &[0, 1]);\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        !self.is_some()\n    }", "test": "fn save_point_rollback_two() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    wb.put(b\"b\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_none());\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    wb.set_save_point();\n    for i in 0..max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    for i in max_keys..2 * max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"b\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_none());\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n    for i in 0..2 * max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_replication_mode_allowlist() {\n    let mut cluster = prepare_cluster();\n    run_cluster(&mut cluster);\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::Async, vec![1]);\n    thread::sleep(Duration::from_millis(100));\n\n    // 2,3 are paused, so it should not be able to write.\n    let region = cluster.get_region(b\"k1\");\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k2\", b\"v2\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n\n    // clear allowlist.\n    cluster\n        .pd_client\n        .switch_replication_mode(DrAutoSyncState::Async, vec![]);\n    rx.recv_timeout(Duration::from_millis(100)).unwrap();\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn no_actual_wasm_code() -> Result<()> {\n    let component = r#\"\n        (component\n            (import \"f\" (func $f))\n\n            (core func $f_lower\n                (canon lower (func $f))\n            )\n            (core module $m\n                (import \"\" \"\" (func $f))\n                (export \"f\" (func $f))\n            )\n            (core instance $i (instantiate $m\n                (with \"\" (instance\n                    (export \"\" (func $f_lower))\n                ))\n            ))\n            (func (export \"thunk\")\n                (canon lift\n                    (core func $i \"f\")\n                )\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, 0);\n\n    // First, test the static API\n\n    let mut linker = Linker::new(&engine);\n    linker.root().func_wrap(\n        \"f\",\n        |mut store: StoreContextMut<'_, u32>, _: ()| -> Result<()> {\n            *store.data_mut() += 1;\n            Ok(())\n        },\n    )?;\n\n    let instance = linker.instantiate(&mut store, &component)?;\n    let thunk = instance.get_typed_func::<(), ()>(&mut store, \"thunk\")?;\n\n    assert_eq!(*store.data(), 0);\n    thunk.call(&mut store, ())?;\n    assert_eq!(*store.data(), 1);\n\n    // Next, test the dynamic API\n\n    *store.data_mut() = 0;\n    let mut linker = Linker::new(&engine);\n    linker.root().func_new(\n        &component,\n        \"f\",\n        |mut store: StoreContextMut<'_, u32>, _, _| {\n            *store.data_mut() += 1;\n            Ok(())\n        },\n    )?;\n\n    let instance = linker.instantiate(&mut store, &component)?;\n    let thunk = instance.get_func(&mut store, \"thunk\").unwrap();\n\n    assert_eq!(*store.data(), 0);\n    thunk.call(&mut store, &[], &mut [])?;\n    assert_eq!(*store.data(), 1);\n\n    Ok(())\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_on_healthy_region() {\n    let mut cluster = new_node_cluster(0, 5);\n    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(30);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store5 = find_peer(&region, 5).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());\n\n    // try to enter force leader, it can't succeed due to quorum isn't lost\n    cluster.enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);\n    // make sure it leaves pre force leader state.\n    std::thread::sleep(Duration::from_millis(\n        cluster.cfg.raft_store.raft_election_timeout_ticks as u64\n            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()\n            * 3,\n    ));\n    // put and get can propose successfully.\n    assert_eq!(cluster.must_get(b\"k1\"), Some(b\"v1\".to_vec()));\n    cluster.must_put(b\"k2\", b\"v2\");\n\n    // try to exit force leader, it will be ignored silently as it's not in the\n    // force leader state\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_new_file_no_create() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let filename = \"new_file_that_does_not_exist_yet\";\n    ucmd.args(&[\"-s\", \"8\", \"-c\", filename])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert!(!at.file_exists(filename));\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_file_notexisting() {\n    // test chown username not_existing\n\n    let scene = TestScenario::new(util_name!());\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    scene\n        .ucmd()\n        .arg(&user_name)\n        .arg(\"--verbose\")\n        .arg(\"not_existing\")\n        .fails()\n        .stdout_contains(format!(\n            \"failed to change ownership of 'not_existing' to {user_name}\"\n        ));\n    // TODO: uncomment once message changed from \"cannot dereference\" to \"cannot access\"\n    // result.stderr_contains(\"cannot access 'not_existing': No such file or directory\");\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn server_stateless_reset() {\n    let _guard = subscribe();\n    let mut reset_key = vec![0; 64];\n    let mut rng = rand::thread_rng();\n    rng.fill_bytes(&mut reset_key);\n    let reset_key = hmac::Key::new(hmac::HMAC_SHA256, &reset_key);\n\n    let endpoint_config = Arc::new(EndpointConfig::new(Arc::new(reset_key)));\n\n    let mut pair = Pair::new(endpoint_config.clone(), server_config());\n    let (client_ch, _) = pair.connect();\n    pair.drive(); // Flush any post-handshake frames\n    pair.server.endpoint = Endpoint::new(endpoint_config, Some(Arc::new(server_config())), true);\n    // Force the server to generate the smallest possible stateless reset\n    pair.client.connections.get_mut(&client_ch).unwrap().ping();\n    info!(\"resetting\");\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::Reset\n        })\n    );\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_basics_subdir() {\n    let ts = TestScenario::new(util_name!());\n\n    let result = ts.ucmd().arg(SUB_DIR).succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR]));\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n    _du_basics_subdir(result.stdout_str());\n}"}
{"code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn can_remove_whitespace_include() {\n    let mut context = Context::new();\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n\n    let inputs = vec![\n        (r#\"Hi {%- include \"include\" -%} \"#, \"HiIncluded\"),\n        (r#\"Hi {% include \"include\" -%} \"#, \"Hi Included\"),\n        (r#\"Hi {% include \"include\" %} \"#, \"Hi Included \"),\n    ];\n\n    for (input, expected) in inputs {\n        let mut tera = Tera::default();\n        tera.add_raw_templates(vec![(\"include\", \"Included\"), (\"tpl\", input)]).unwrap();\n        assert_eq!(tera.render(\"tpl\", &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_read_leader_in_lease() {\n    let count = 3;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.run();\n\n    let k1 = b\"k1\";\n    let (k2, v2) = (b\"k2\", b\"v2\");\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(k1), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let mut storage = cluster.sim.rl().storages[&leader.get_id()].clone();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader.clone());\n    let snap_ctx = SnapContext {\n        pb_ctx: &ctx,\n        ..Default::default()\n    };\n\n    // write some data\n    assert_none(snap_ctx.clone(), &mut storage, k2);\n    must_put(&ctx, &storage, k2, v2);\n\n    // isolate leader\n    cluster.add_send_filter(IsolationFilterFactory::new(leader.get_store_id()));\n\n    // leader still in lease, check if can read on leader\n    assert_eq!(can_read(snap_ctx, &mut storage, k2, v2), true);\n}"}
{"code": "fn as_ref(&self) -> &A {\n        self.integrity.check();\n        self.value.as_ref()\n    }", "test": "fn test_something() {\n    let data = [];\n    let wasm_bytes = module.0.to_bytes();\n    if let Ok(path) = std::env::var(\"DUMP_TESTCASE\") {\n        use std::fs::File;\n        use std::io::Write;\n        let mut file = File::create(path).unwrap();\n        file.write_all(&wasm_bytes).unwrap();\n        return;\n    }\n    #[cfg(feature = \"singlepass\")]\n    let singlepass = maybe_instantiate_singlepass(&wasm_bytes)\n        .transpose()\n        .map(evaluate_instance);\n    #[cfg(feature = \"cranelift\")]\n    let cranelift = maybe_instantiate_cranelift(&wasm_bytes)\n        .transpose()\n        .map(evaluate_instance);\n    #[cfg(feature = \"llvm\")]\n    let llvm = maybe_instantiate_llvm(&wasm_bytes)\n        .transpose()\n        .map(evaluate_instance);\n    #[cfg(all(feature = \"singlepass\", feature = \"cranelift\"))]\n    if singlepass.is_some() && cranelift.is_some() {\n        assert_eq!(singlepass.as_ref().unwrap(), cranelift.as_ref().unwrap());\n    }\n    #[cfg(all(feature = \"singlepass\", feature = \"llvm\"))]\n    if singlepass.is_some() && llvm.is_some() {\n        assert_eq!(singlepass.as_ref().unwrap(), llvm.as_ref().unwrap());\n    }\n    #[cfg(all(feature = \"cranelift\", feature = \"llvm\"))]\n    if cranelift.is_some() && llvm.is_some() {\n        assert_eq!(cranelift.as_ref().unwrap(), llvm.as_ref().unwrap());\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_split_number_chunks_short_concatenated_with_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n3\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"a\");\n    assert_eq!(at.read(\"xab\"), \"b\");\n    assert_eq!(at.read(\"xac\"), \"c\");\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_raftlog_gc_lagged_witness() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // the witness is down\n    cluster.stop_node(nodes[2]);\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    // the witness is back online\n    cluster.run_node(nodes[2]).unwrap();\n\n    cluster.must_put(b\"k00\", b\"v00\");\n    std::thread::sleep(Duration::from_millis(200));\n\n    // the truncated index is advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_iltc() {\n    // Test iterators that skip multiple digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_leading_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"45.56\");\n}"}
{"code": "fn get(&self, mut req: Get) -> PdFuture<GetResponse> {\n        let timer = Instant::now();\n        self.fill_cluster_id_for(req.inner.mut_header());\n        let executor = move |client: &Client, req: GetRequest| {\n            let handler = {\n                let inner = client.inner.rl();\n                let r = inner\n                    .meta_storage\n                    .get_async_opt(&req, call_option_inner(&inner));\n                futures::future::ready(r).err_into().try_flatten()\n            };\n            Box::pin(async move {\n                fail::fail_point!(\"meta_storage_get\", req.key.ends_with(b\"rejectme\"), |_| {\n                    Err(super::Error::Grpc(grpcio::Error::RemoteStopped))\n                });\n                let resp = handler.await?;\n                PD_REQUEST_HISTOGRAM_VEC\n                    .meta_storage_get\n                    .observe(timer.saturating_elapsed_secs());\n                Ok(resp)\n            }) as _\n        };\n\n        self.pd_client\n            .request(req.into(), executor, LEADER_CHANGE_RETRY)\n            .execute()\n    }", "test": "fn test_txn_gc_keys_handled() {\n    let store_id = 1;\n    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();\n    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();\n\n    let engine = TestEngineBuilder::new().build().unwrap();\n    let mut prefixed_engine = PrefixedEngine(engine.clone());\n\n    let (tx, _rx) = mpsc::channel();\n    let feature_gate = FeatureGate::default();\n    feature_gate.set_version(\"5.0.0\").unwrap();\n    let mut gc_worker = GcWorker::new(\n        prefixed_engine.clone(),\n        tx,\n        GcConfig::default(),\n        feature_gate,\n        Arc::new(MockRegionInfoProvider::new(vec![])),\n    );\n    gc_worker.start(store_id).unwrap();\n\n    let mut r1 = Region::default();\n    r1.set_id(1);\n    r1.mut_region_epoch().set_version(1);\n    r1.set_start_key(b\"\".to_vec());\n    r1.set_end_key(b\"\".to_vec());\n    r1.mut_peers().push(Peer::default());\n    r1.mut_peers()[0].set_store_id(store_id);\n\n    let sp_provider = MockSafePointProvider(200);\n    let mut host = CoprocessorHost::<RocksEngine>::default();\n    let ri_provider = RegionInfoAccessor::new(&mut host);\n    let auto_gc_cfg = AutoGcConfig::new(sp_provider, ri_provider, 1);\n    let safe_point = Arc::new(AtomicU64::new(500));\n\n    gc_worker.start_auto_gc(auto_gc_cfg, safe_point).unwrap();\n    host.on_region_changed(&r1, RegionChangeEvent::Create, StateRole::Leader);\n\n    let db = engine.kv_engine().unwrap().as_inner().clone();\n    let cf = get_cf_handle(&db, CF_WRITE).unwrap();\n\n    for i in 0..3 {\n        let k = format!(\"k{:02}\", i).into_bytes();\n        must_prewrite_put(&mut prefixed_engine, &k, b\"value\", &k, 101);\n        must_commit(&mut prefixed_engine, &k, 101, 102);\n        must_prewrite_delete(&mut prefixed_engine, &k, &k, 151);\n        must_commit(&mut prefixed_engine, &k, 151, 152);\n    }\n\n    db.flush_cf(cf, true, false).unwrap();\n\n    db.compact_range_cf(cf, None, None);\n\n    // This compaction can schedule gc task\n    db.compact_range_cf(cf, None, None);\n    thread::sleep(Duration::from_millis(100));\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_MVCC_DELETION_MET\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        6\n    );\n\n    assert_eq!(\n        GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED\n            .with_label_values(&[STAT_TXN_KEYMODE])\n            .get(),\n        3\n    );\n\n    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();\n    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn gzip_decoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder = flate2::write::GzEncoder::new(Vec::new(), flate2::Compression::default());\n    encoder.write_all(original).unwrap();\n    let encoded: Vec<u8> = encoder.finish().unwrap();\n    let mut decoder = flate2::read::GzDecoder::new(encoded.as_slice());\n    assert_eq!(decoder.read(&mut []).unwrap(), 0);\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn instant_close_1() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config());\n    pair.client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .close(pair.time, VarInt(0), Bytes::new());\n    pair.drive();\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::ConnectionClosed(ConnectionClose {\n                error_code: TransportErrorCode::APPLICATION_ERROR,\n                ..\n            }),\n        })\n    );\n}"}
{"code": "pub fn must_raw_get(&self, k: Vec<u8>, cf: String) -> Vec<u8> {\n        let mut request = RawGetRequest::default();\n        let mut context = self.context.clone();\n        if context.api_version == ApiVersion::V1ttl {\n            context.api_version = ApiVersion::V1;\n        }\n        request.set_context(context);\n        request.set_key(k);\n        request.set_cf(cf);\n        let mut response = self.tikv_cli.raw_get(&request).unwrap();\n        retry_req!(\n            self.tikv_cli.raw_get(&request).unwrap(),\n            !response.has_region_error() && response.error.is_empty(),\n            response,\n            10,   // retry 10 times\n            1000  // 1s timeout\n        );\n        assert!(response.error.is_empty(), \"{:?}\", response.get_error());\n        response.take_value()\n    }", "test": "fn test_raw_put_key_guard() {\n    let mut suite = TestSuite::new(3, ApiVersion::V2);\n    let pause_write_fp = \"raftkv_async_write\";\n\n    let test_key = b\"rk3\".to_vec();\n    let test_value = b\"v3\".to_vec();\n\n    let region = suite.cluster.get_region(&test_key);\n    let region_id = region.get_id();\n    let client = suite.get_client(region_id);\n    let ctx = suite.get_context(region_id);\n    let node_id = region.get_peers()[0].get_id();\n    let leader_cm = suite.cluster.sim.rl().get_concurrency_manager(node_id);\n    let ts_provider = suite.get_causal_ts_provider(node_id).unwrap();\n    let ts = block_on(ts_provider.async_get_ts()).unwrap();\n\n    let copy_test_key = test_key.clone();\n    let copy_test_value = test_value.clone();\n    fail::cfg(pause_write_fp, \"pause\").unwrap();\n    let handle = thread::spawn(move || {\n        must_raw_put(&client, ctx, copy_test_key, copy_test_value);\n    });\n\n    // Wait for global_min_lock_ts.\n    sleep_ms(500);\n    let start = Instant::now();\n    while leader_cm.global_min_lock_ts().is_none()\n        && start.saturating_elapsed() < Duration::from_secs(5)\n    {\n        sleep_ms(200);\n    }\n\n    // Before raw_put finish, min_ts should be the ts of \"key guard\" of the raw_put\n    // request.\n    assert_eq!(suite.must_raw_get(&test_key), None);\n    let min_ts = leader_cm.global_min_lock_ts();\n    assert_eq!(min_ts.unwrap(), ts.next());\n\n    fail::remove(pause_write_fp);\n    handle.join().unwrap();\n\n    // After raw_put is finished, \"key guard\" is released.\n    assert_eq!(suite.must_raw_get(&test_key), Some(test_value));\n    let min_ts = leader_cm.global_min_lock_ts();\n    assert!(min_ts.is_none());\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn custom_limiter_detect_grow_failure() -> Result<()> {\n    if std::env::var(\"WASMTIME_TEST_NO_HOG_MEMORY\").is_ok() {\n        return Ok(());\n    }\n    let mut pool = crate::small_pool_config();\n    pool.memory_pages(10).table_elements(10);\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    let engine = Engine::new(&config).unwrap();\n    let linker = Linker::new(&engine);\n\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m\") 0) (table (export \"t\") 0 anyfunc))\"#,\n    )?;\n\n    let context = FailureDetector::default();\n\n    let mut store = Store::new(&engine, context);\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n    let instance = linker.instantiate(&mut store, &module)?;\n    let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n    // Grow the memory by 640 KiB (10 pages)\n    memory.grow(&mut store, 10)?;\n\n    assert!(store.data().memory_error.is_none());\n    assert_eq!(store.data().memory_current, 0);\n    assert_eq!(store.data().memory_desired, 10 * 64 * 1024);\n\n    // Grow past the static limit set by ModuleLimits.\n    // The ResourceLimiter will permit this, but the grow will fail.\n    assert_eq!(\n        memory.grow(&mut store, 1).unwrap_err().to_string(),\n        \"failed to grow memory by `1`\"\n    );\n\n    assert_eq!(store.data().memory_current, 10 * 64 * 1024);\n    assert_eq!(store.data().memory_desired, 11 * 64 * 1024);\n    assert_eq!(\n        store.data().memory_error.as_ref().unwrap(),\n        \"Memory maximum size exceeded\"\n    );\n\n    let table = instance.get_table(&mut store, \"t\").unwrap();\n    // Grow the table 10 elements\n    table.grow(&mut store, 10, Val::FuncRef(None))?;\n\n    assert!(store.data().table_error.is_none());\n    assert_eq!(store.data().table_current, 0);\n    assert_eq!(store.data().table_desired, 10);\n\n    // Grow past the static limit set by ModuleLimits.\n    // The ResourceLimiter will permit this, but the grow will fail.\n    assert_eq!(\n        table\n            .grow(&mut store, 1, Val::FuncRef(None))\n            .unwrap_err()\n            .to_string(),\n        \"failed to grow table by `1`\"\n    );\n\n    assert_eq!(store.data().table_current, 10);\n    assert_eq!(store.data().table_desired, 11);\n    assert_eq!(\n        store.data().table_error.as_ref().unwrap(),\n        \"Table maximum size exceeded\"\n    );\n\n    drop(store);\n\n    Ok(())\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_nonempty_directory_no_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir(DIR);\n    at.touch(DIR_FILE);\n\n    ucmd.arg(DIR)\n        .fails()\n        .stderr_is(format!(\"rmdir: failed to remove 'dir': {NOT_EMPTY}\\n\"));\n\n    assert!(at.dir_exists(DIR));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_empty_directory_with_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir_all(NESTED_DIR);\n\n    ucmd.arg(\"-p\").arg(NESTED_DIR).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(NESTED_DIR));\n    assert!(!at.dir_exists(DIR));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_kv_scan_memory_lock() {\n    let (_cluster, client, ctx) = must_new_cluster_and_kv_client();\n\n    let mut req = ScanRequest::default();\n    req.set_context(ctx);\n    req.set_start_key(b\"a\".to_vec());\n    req.version = 50;\n\n    fail::cfg(\"raftkv_async_snapshot_err\", \"return\").unwrap();\n    let resp = client.kv_scan(&req).unwrap();\n    // the injected error should be returned at both places for backward\n    // compatibility.\n    assert!(!resp.pairs[0].get_error().get_abort().is_empty());\n    assert!(!resp.get_error().get_abort().is_empty());\n    fail::remove(\"raftkv_async_snapshot_err\");\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        self.max_expire_ts.is_some() || self.min_expire_ts.is_some()\n    }", "test": "fn test_orphan_versions_from_compaction_filter() {\n    let (cluster, leader, ctx) = must_new_and_configure_cluster(|cluster| {\n        cluster.cfg.gc.enable_compaction_filter = true;\n        cluster.cfg.gc.compaction_filter_skip_version_check = true;\n        cluster.pd_client.disable_default_operator();\n    });\n\n    let env = Arc::new(Environment::new(1));\n    let leader_store = leader.get_store_id();\n    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader_store));\n    let client = TikvClient::new(channel);\n\n    init_compaction_filter(&cluster, leader_store);\n    let engine = cluster.engines.get(&leader_store).unwrap();\n\n    let pk = b\"k1\".to_vec();\n    let large_value = vec![b'x'; 300];\n    for &start_ts in &[10, 20, 30, 40] {\n        let commit_ts = start_ts + 5;\n        let op = if start_ts < 40 { Op::Put } else { Op::Del };\n        let muts = vec![new_mutation(op, b\"k1\", &large_value)];\n        must_kv_prewrite(&client, ctx.clone(), muts, pk.clone(), start_ts);\n        let keys = vec![pk.clone()];\n        must_kv_commit(&client, ctx.clone(), keys, start_ts, commit_ts, commit_ts);\n        if start_ts < 40 {\n            let key = Key::from_raw(b\"k1\").append_ts(start_ts.into());\n            let key = data_key(key.as_encoded());\n            assert!(engine.kv.get_value(&key).unwrap().is_some());\n        }\n    }\n\n    let fp = \"write_compaction_filter_flush_write_batch\";\n    fail::cfg(fp, \"return\").unwrap();\n\n    let mut gc_runner = TestGcRunner::new(100);\n    gc_runner.gc_scheduler = cluster.sim.rl().get_gc_worker(1).scheduler();\n    gc_runner.gc(&engine.kv);\n\n    'IterKeys: for &start_ts in &[10, 20, 30] {\n        let key = Key::from_raw(b\"k1\").append_ts(start_ts.into());\n        let key = data_key(key.as_encoded());\n        for _ in 0..100 {\n            if engine.kv.get_value(&key).unwrap().is_some() {\n                thread::sleep(Duration::from_millis(20));\n                continue;\n            }\n            continue 'IterKeys;\n        }\n        panic!(\"orphan versions should already been cleaned by GC worker\");\n    }\n\n    fail::remove(fp);\n}"}
{"code": "pub(crate) fn to_string(&self) -> String {\n        let mut repr = String::with_capacity(self.digits.len());\n\n        let mut has_nonzero = false;\n        for digit in self.digits.iter().rev() {\n            has_nonzero |= *digit != 0;\n            if has_nonzero {\n                repr.push((*digit + b'0') as char);\n            }\n        }\n\n        if repr.is_empty() {\n            repr.push('0');\n        }\n\n        repr\n    }", "test": "fn test_grouping() {\n    let tokens: TokenStream = TokenStream::from_iter(vec![\n        TokenTree::Literal(Literal::i32_suffixed(1)),\n        TokenTree::Punct(Punct::new('+', Spacing::Alone)),\n        TokenTree::Group(Group::new(\n            Delimiter::None,\n            TokenStream::from_iter(vec![\n                TokenTree::Literal(Literal::i32_suffixed(2)),\n                TokenTree::Punct(Punct::new('+', Spacing::Alone)),\n                TokenTree::Literal(Literal::i32_suffixed(3)),\n            ]),\n        )),\n        TokenTree::Punct(Punct::new('*', Spacing::Alone)),\n        TokenTree::Literal(Literal::i32_suffixed(4)),\n    ]);\n\n    assert_eq!(tokens.to_string(), \"1i32 + 2i32 + 3i32 * 4i32\");\n\n    snapshot!(tokens as Expr, @r###\"\n    Expr::Binary {\n        left: Expr::Lit {\n            lit: 1i32,\n        },\n        op: BinOp::Add,\n        right: Expr::Binary {\n            left: Expr::Group {\n                expr: Expr::Binary {\n                    left: Expr::Lit {\n                        lit: 2i32,\n                    },\n                    op: BinOp::Add,\n                    right: Expr::Lit {\n                        lit: 3i32,\n                    },\n                },\n            },\n            op: BinOp::Mul,\n            right: Expr::Lit {\n                lit: 4i32,\n            },\n        },\n    }\n    \"###);\n}"}
{"code": "pub fn get_state(&self) -> Arc<AtomicCell<DownstreamState>> {\n        self.state.clone()\n    }", "test": "fn test_node_merge_restart() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.run();\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    cluster.must_try_merge(left.get_id(), right.get_id());\n    let leader = cluster.leader_of_region(left.get_id()).unwrap();\n\n    cluster.shutdown();\n    let engine = cluster.get_engine(leader.get_store_id());\n    let state_key = keys::region_state_key(left.get_id());\n    let state: RegionLocalState = engine.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();\n    assert_eq!(state.get_state(), PeerState::Merging, \"{:?}\", state);\n    let state_key = keys::region_state_key(right.get_id());\n    let state: RegionLocalState = engine.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();\n    assert_eq!(state.get_state(), PeerState::Normal, \"{:?}\", state);\n    fail::remove(schedule_merge_fp);\n    cluster.start().unwrap();\n\n    // Wait till merge is finished.\n    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));\n\n    cluster.must_put(b\"k4\", b\"v4\");\n\n    for i in 1..4 {\n        must_get_equal(&cluster.get_engine(i), b\"k4\", b\"v4\");\n        let state_key = keys::region_state_key(left.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Tombstone, \"{:?}\", state);\n        let state_key = keys::region_state_key(right.get_id());\n        let state: RegionLocalState = cluster\n            .get_engine(i)\n            .get_msg_cf(CF_RAFT, &state_key)\n            .unwrap()\n            .unwrap();\n        assert_eq!(state.get_state(), PeerState::Normal, \"{:?}\", state);\n        assert!(state.get_region().get_start_key().is_empty());\n        assert!(state.get_region().get_end_key().is_empty());\n    }\n\n    // Now test if cluster works fine when it crash after merge is applied\n    // but before notifying raftstore thread.\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    let peer_on_store1 = find_peer(&region, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    cluster.must_split(&region, b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n    let peer_on_store1 = find_peer(&left, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(left.get_id(), peer_on_store1);\n    cluster.must_put(b\"k11\", b\"v11\");\n    must_get_equal(&cluster.get_engine(3), b\"k11\", b\"v11\");\n    let skip_destroy_fp = \"raft_store_skip_destroy_peer\";\n    fail::cfg(skip_destroy_fp, \"return()\").unwrap();\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    pd_client.must_merge(left.get_id(), right.get_id());\n    let peer = find_peer(&right, 3).unwrap().to_owned();\n    pd_client.must_remove_peer(right.get_id(), peer);\n    cluster.shutdown();\n    fail::remove(skip_destroy_fp);\n    cluster.clear_send_filters();\n    cluster.start().unwrap();\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    must_get_none(&cluster.get_engine(3), b\"k3\");\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn concurrent_connections_full() {\n    let _guard = subscribe();\n    let mut pair = Pair::new(\n        Default::default(),\n        ServerConfig {\n            concurrent_connections: 0,\n            ..server_config()\n        },\n    );\n    let client_ch = pair.begin_connect(client_config());\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::ConnectionClosed(frame::ConnectionClose {\n                error_code: TransportErrorCode::CONNECTION_REFUSED,\n                ..\n            }),\n        })\n    );\n    assert_eq!(pair.server.connections.len(), 0);\n    assert_eq!(pair.server.known_connections(), 0);\n    assert_eq!(pair.server.known_cids(), 0);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_recursive_multiple() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_recursive_directory\";\n    let file_a = \"test_rm_recursive_directory/test_rm_recursive_file_a\";\n    let file_b = \"test_rm_recursive_directory/test_rm_recursive_file_b\";\n\n    at.mkdir(dir);\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(\"-r\")\n        .arg(\"-r\")\n        .arg(\"-r\")\n        .arg(dir)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.dir_exists(dir));\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_default_with_io_blksize() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_default_with_io_blksize\";\n    RandomFile::new(&at, name).add_lines(2000);\n    ucmd.args(&[name, \"---io-blksize\", \"2M\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn fuel_consumed(&self) -> Option<u64> {\n        self.inner.fuel_consumed()\n    }", "test": "fn manual_fuel() {\n    let mut config = Config::new();\n    config.consume_fuel(true);\n    let engine = Engine::new(&config).unwrap();\n    let mut store = Store::new(&engine, ());\n    store.add_fuel(10_000).unwrap();\n    assert_eq!(store.fuel_consumed(), Some(0));\n    assert_eq!(store.fuel_remaining(), Some(10_000));\n    assert_eq!(store.consume_fuel(1).unwrap(), 9_999);\n    assert_eq!(store.fuel_consumed(), Some(1));\n    assert_eq!(store.fuel_remaining(), Some(9_999));\n    assert!(store.consume_fuel(10_000).is_err());\n    assert_eq!(store.consume_fuel(999).unwrap(), 9_000);\n    assert!(store.consume_fuel(10_000).is_err());\n    assert_eq!(store.consume_fuel(8998).unwrap(), 2);\n    assert!(store.consume_fuel(3).is_err());\n    assert_eq!(store.consume_fuel(1).unwrap(), 1);\n    assert_eq!(store.consume_fuel(1).unwrap(), 0);\n    assert_eq!(store.consume_fuel(0).unwrap(), 0);\n    assert_eq!(store.fuel_remaining(), Some(0));\n}"}
{"code": "pub fn contains<S>(&self, name: S) -> bool\n    where\n        S: Into<String>,\n    {\n        self.map.contains_key(&name.into())\n    }", "test": "fn gen_c_header_works() -> anyhow::Result<()> {\n    let temp_dir = tempfile::tempdir()?;\n    let operating_dir: PathBuf = temp_dir.path().to_owned();\n\n    let wasm_path = operating_dir.join(fixtures::qjs());\n    let out_path = temp_dir.path().join(\"header.h\");\n\n    let _ = Command::new(get_wasmer_path())\n        .arg(\"gen-c-header\")\n        .arg(&wasm_path)\n        .arg(\"-o\")\n        .arg(&out_path)\n        .output()\n        .unwrap();\n\n    let file = std::fs::read_to_string(&out_path).expect(\"no header.h file\");\n    assert!(file.contains(\"wasmer_function_6f62a6bc5c8f8e3e12a54e2ecbc5674ccfe1c75f91d8e4dd6ebb3fec422a4d6c_0\"), \"no wasmer_function_6f62a6bc5c8f8e3e12a54e2ecbc5674ccfe1c75f91d8e4dd6ebb3fec422a4d6c_0 in file\");\n\n    let _ = Command::new(get_wasmer_path())\n        .arg(\"gen-c-header\")\n        .arg(&wasm_path)\n        .arg(\"-o\")\n        .arg(&out_path)\n        .arg(\"--prefix\")\n        .arg(\"abc123\")\n        .output()\n        .unwrap();\n\n    let file = std::fs::read_to_string(&out_path).expect(\"no header.h file\");\n    assert!(\n        file.contains(\"wasmer_function_abc123_0\"),\n        \"no wasmer_function_abc123_0 in file\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn undefined_behavior(&self) -> UndefinedBehavior {\n        self.env.undefined_behavior()\n    }", "test": "fn test_chainable_undefined() {\n    let mut env = Environment::new();\n    env.set_undefined_behavior(UndefinedBehavior::Chainable);\n    env.add_filter(\"test\", |state: &State, value: String| -> String {\n        assert_eq!(state.undefined_behavior(), UndefinedBehavior::Chainable);\n        assert_eq!(value, \"\");\n        value\n    });\n\n    assert_eq!(render!(in env, \"<{{ true.missing_attribute }}>\"), \"<>\");\n    assert_eq!(render!(in env, \"<{{ undefined.missing_attribute }}>\"), \"<>\");\n    assert_eq!(\n        render!(in env, \"<{% for x in undefined %}...{% endfor %}>\"),\n        \"<>\"\n    );\n    assert_eq!(render!(in env, \"<{{ undefined }}>\"), \"<>\");\n    assert_eq!(render!(in env, \"{{ undefined is undefined }}\"), \"true\");\n    assert_eq!(render!(in env, \"{{ undefined|list }}\"), \"[]\");\n    assert_eq!(render!(in env, \"<{{ undefined|test }}>\"), \"<>\");\n    assert_eq!(render!(in env, \"{{ 42 in undefined }}\"), \"false\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_link_no_circular() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let link = \"test_link_no_circular\";\n\n    ucmd.args(&[link, link])\n        .fails()\n        .stderr_is(\"link: cannot create link 'test_link_no_circular' to 'test_link_no_circular': No such file or directory\\n\");\n    assert!(!at.file_exists(link));\n}"}
{"code": "async fn status(Extension(index): Extension<Arc<Index>>) -> (StatusCode, &'static str) {\n    if index.is_unrecoverably_reorged() {\n      (\n        StatusCode::OK,\n        \"unrecoverable reorg detected, please rebuild the database.\",\n      )\n    } else {\n      (\n        StatusCode::OK,\n        StatusCode::OK.canonical_reason().unwrap_or_default(),\n      )\n    }\n  }", "test": "fn get_sat_without_sat_index() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n\n  let response = TestServer::spawn_with_server_args(&rpc_server, &[], &[\"--enable-json-api\"])\n    .json_request(\"/sat/2099999997689999\");\n\n  assert_eq!(response.status(), StatusCode::OK);\n\n  let mut sat_json: SatJson = serde_json::from_str(&response.text().unwrap()).unwrap();\n\n  // this is a hack to ignore the timestamp, since it changes for every request\n  sat_json.timestamp = 0;\n\n  pretty_assert_eq!(\n    sat_json,\n    SatJson {\n      number: 2099999997689999,\n      decimal: \"6929999.0\".into(),\n      degree: \"5\u00b0209999\u20321007\u20330\u2034\".into(),\n      name: \"a\".into(),\n      block: 6929999,\n      cycle: 5,\n      epoch: 32,\n      period: 3437,\n      offset: 0,\n      rarity: Rarity::Uncommon,\n      percentile: \"100%\".into(),\n      satpoint: None,\n      timestamp: 0,\n      inscriptions: vec![],\n    }\n  )\n}\n\n#[tes"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ignore_vcs_ignored_file() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = r#\"{\n        \"vcs\": {\n            \"enabled\": true,\n            \"clientKind\": \"git\",\n            \"useIgnoreFile\": true\n        }\n    }\"#;\n\n    let git_ignore = r#\"\nfile2.js\n\"#;\n\n    let code2 = r#\"foo.call(); bar.call();\"#;\n    let code1 = r#\"array.map(sentence => sentence.split(' ')).flat();\"#;\n\n    // ignored files\n    let file_path1 = Path::new(\"file1.js\");\n    fs.insert(file_path1.into(), code1.as_bytes());\n    let file_path2 = Path::new(\"file2.js\");\n    fs.insert(file_path2.into(), code2.as_bytes());\n\n    // configuration\n    let config_path = Path::new(\"biome.json\");\n    fs.insert(config_path.into(), rome_json.as_bytes());\n\n    // git ignore file\n    let ignore_file = Path::new(\".gitignore\");\n    fs.insert(ignore_file.into(), git_ignore.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                file_path1.as_os_str().to_str().unwrap(),\n                file_path2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ignore_vcs_ignored_file\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.header.response_code()\n    }", "test": "fn test_nodata_where_name_exists() {\n    named_test_harness(\"example.toml\", |_, tcp_port, _, _, _| {\n        let io_loop = Runtime::new().unwrap();\n        let addr: SocketAddr = SocketAddr::new(\n            Ipv4Addr::new(127, 0, 0, 1).into(),\n            tcp_port.expect(\"no tcp_port\"),\n        );\n        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);\n        let client = AsyncClient::new(Box::new(stream), sender, None);\n        let (mut client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n        hickory_proto::spawn_bg(&io_loop, bg);\n\n        let msg = io_loop\n            .block_on(client.query(\n                Name::from_str(\"www.example.com.\").unwrap(),\n                DNSClass::IN,\n                RecordType::SRV,\n            ))\n            .unwrap();\n        assert_eq!(msg.response_code(), ResponseCode::NoError);\n        assert!(msg.answers().is_empty());\n    })\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_hex() {\n    assert_eq!(from_str(\"0x507\"), Ok(0x507));\n    assert_eq!(from_str(\"0x1A5\"), Ok(0x1A5));\n    assert_eq!(from_str(\"0x53C537\"), Ok(0x53C537));\n\n    assert_eq!(\n        from_str::<u8>(\"0x\"),\n        Err(SpannedError {\n            code: Error::ExpectedInteger,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0x_1\"),\n        Err(SpannedError {\n            code: Error::UnderscoreAtBeginning,\n            position: Position { line: 1, col: 3 },\n        })\n    );\n    assert_eq!(\n        from_str::<u8>(\"0xFFF\"),\n        Err(SpannedError {\n            code: Error::IntegerOutOfBounds,\n            position: Position { line: 1, col: 6 },\n        })\n    );\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_request_snapshot_after_reboot() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(20);\n    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    std::thread::sleep(Duration::from_millis(100));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    // witness -> nonwitness\n    let fp = \"ignore request snapshot\";\n    fail::cfg(fp, \"return\").unwrap();\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);\n    std::thread::sleep(Duration::from_millis(500));\n    // as we ignore request snapshot, so snapshot should still not applied yet\n    assert_eq!(cluster.pd_client.get_pending_peers().len(), 1);\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n\n    cluster.stop_node(nodes[2]);\n    fail::remove(fp);\n    std::thread::sleep(Duration::from_millis(100));\n    // the PeerState is Unavailable, so it will request snapshot immediately after\n    // start.\n    cluster.run_node(nodes[2]).unwrap();\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    std::thread::sleep(Duration::from_millis(500));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    assert_eq!(cluster.pd_client.get_pending_peers().len(), 0);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_infinite_symlink_expansion_to_files() {\n    let mut console = BufferConsole::default();\n\n    let root_path = temp_dir().join(\"check_rome_test_infinite_symlink_expansion_to_files\");\n    let subdir1_path = root_path.join(\"prefix\");\n    let subdir2_path = root_path.join(\"foo\").join(\"bar\");\n\n    let _ = remove_dir_all(&root_path);\n    create_dir_all(&subdir1_path).unwrap();\n    create_dir_all(&subdir2_path).unwrap();\n\n    let symlink1_path = subdir1_path.join(\"symlink1\");\n    let symlink2_path = subdir2_path.join(\"symlink2\");\n\n    #[cfg(target_family = \"unix\")]\n    {\n        symlink(&symlink2_path, &symlink1_path).unwrap();\n        symlink(&symlink1_path, &symlink2_path).unwrap();\n    }\n\n    #[cfg(target_os = \"windows\")]\n    {\n        check_windows_symlink!(symlink_dir(&symlink2_path, &symlink1_path));\n        check_windows_symlink!(symlink_dir(&symlink1_path, &symlink2_path));\n    }\n\n    let result = run_cli(\n        DynRef::Owned(Box::new(OsFileSystem)),\n        &mut console,\n        Args::from([(\"check\"), (root_path.display().to_string().as_str())].as_slice()),\n    );\n\n    remove_dir_all(root_path).unwrap();\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Don't use a snapshot here, since the diagnostics can be reported in\n    // arbitrary order:\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(\"Deeply nested symlink expansion\")));\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(&symlink1_path.display().to_string())));\n    assert!(console\n        .out_buffer\n        .iter()\n        .flat_map(|msg| msg.content.0.iter())\n        .any(|node| node.content.contains(&symlink2_path.display().to_string())));\n}"}
{"code": "pub fn is_zero(&self) -> bool {\n        let len = word_cnt!(self.int_cnt) + word_cnt!(self.frac_cnt);\n        self.word_buf[0..len as usize].iter().all(|&x| x == 0)\n    }", "test": "fn test_exceed_max_commit_ts_in_the_middle_of_prewrite() {\n    let engine = TestEngineBuilder::new().build().unwrap();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .build()\n        .unwrap();\n    let cm = storage.get_concurrency_manager();\n\n    let (prewrite_tx, prewrite_rx) = channel();\n    // Pause between getting max ts and store the lock in memory\n    fail::cfg(\"before-set-lock-in-memory\", \"pause\").unwrap();\n\n    cm.update_max_ts(40.into());\n    let mutations = vec![\n        Mutation::make_put(Key::from_raw(b\"k1\"), b\"v\".to_vec()),\n        Mutation::make_put(Key::from_raw(b\"k2\"), b\"v\".to_vec()),\n    ];\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                mutations.clone(),\n                b\"k1\".to_vec(),\n                10.into(),\n                20000,\n                false,\n                2,\n                11.into(),\n                50.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                Context::default(),\n            ),\n            Box::new(move |res| {\n                prewrite_tx.send(res).unwrap();\n            }),\n        )\n        .unwrap();\n    // sleep a while so the first key gets max ts.\n    thread::sleep(Duration::from_millis(200));\n\n    cm.update_max_ts(51.into());\n    fail::remove(\"before-set-lock-in-memory\");\n    let res = prewrite_rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts.is_zero());\n    assert!(res.one_pc_commit_ts.is_zero());\n\n    let locks = block_on(storage.scan_lock(\n        Context::default(),\n        20.into(),\n        Some(Key::from_raw(b\"k1\")),\n        None,\n        2,\n    ))\n    .unwrap();\n    assert_eq!(locks.len(), 2);\n    assert_eq!(locks[0].get_key(), b\"k1\");\n    assert!(locks[0].get_use_async_commit());\n    assert_eq!(locks[0].get_min_commit_ts(), 41);\n    assert_eq!(locks[1].get_key(), b\"k2\");\n    assert!(!locks[1].get_use_async_commit());\n\n    // Send a duplicated request to test the idempotency of prewrite when falling\n    // back to 2PC.\n    let (prewrite_tx, prewrite_rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                mutations,\n                b\"k1\".to_vec(),\n                10.into(),\n                20000,\n                false,\n                2,\n                11.into(),\n                50.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                Context::default(),\n            ),\n            Box::new(move |res| {\n                prewrite_tx.send(res).unwrap();\n            }),\n        )\n        .unwrap();\n    let res = prewrite_rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts.is_zero());\n    assert!(res.one_pc_commit_ts.is_zero());\n}"}
{"code": "fn get(&self, _: &[u8]) -> Option<&[u8]> {\n        None\n    }", "test": "fn test_file_dict_file_record_corrupted() {\n    let tempdir = tempfile::tempdir().unwrap();\n    let mut file_dict_file = FileDictionaryFile::new(\n        tempdir.path(),\n        \"test_file_dict_file_record_corrupted_1\",\n        true,\n        10, // file_rewrite_threshold\n    )\n    .unwrap();\n    let info1 = create_file_info(1, EncryptionMethod::Aes256Ctr);\n    let info2 = create_file_info(2, EncryptionMethod::Unknown);\n    // 9 represents that the first 9 bytes will be discarded.\n    // Crc32 (4 bytes) + File name length (2 bytes) + FileInfo length (2 bytes) +\n    // Log type (1 bytes)\n    fail::cfg(\"file_dict_log_append_incomplete\", \"return(9)\").unwrap();\n    file_dict_file.insert(\"info1\", &info1, true).unwrap();\n    fail::remove(\"file_dict_log_append_incomplete\");\n    file_dict_file.insert(\"info2\", &info2, true).unwrap();\n    // Intermediate record damage is not allowed.\n    file_dict_file.recovery().unwrap_err();\n\n    let mut file_dict_file = FileDictionaryFile::new(\n        tempdir.path(),\n        \"test_file_dict_file_record_corrupted_2\",\n        true,\n        10, // file_rewrite_threshold\n    )\n    .unwrap();\n    let info1 = create_file_info(1, EncryptionMethod::Aes256Ctr);\n    let info2 = create_file_info(2, EncryptionMethod::Unknown);\n    file_dict_file.insert(\"info1\", &info1, true).unwrap();\n    fail::cfg(\"file_dict_log_append_incomplete\", \"return(9)\").unwrap();\n    file_dict_file.insert(\"info2\", &info2, true).unwrap();\n    fail::remove(\"file_dict_log_append_incomplete\");\n    // The ending record can be discarded.\n    let file_dict = file_dict_file.recovery().unwrap();\n    assert_eq!(*file_dict.files.get(\"info1\").unwrap(), info1);\n    assert_eq!(file_dict.files.len(), 1);\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        self.max_expire_ts.is_some() || self.min_expire_ts.is_some()\n    }", "test": "fn save_point_rollback_partial() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    wb.put(b\"b\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_some());\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    for i in 0..max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.set_save_point();\n    wb.put(b\"b\", b\"\").unwrap();\n    for i in max_keys..2 * max_keys {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n\n    wb.rollback_to_save_point().unwrap();\n    wb.write().unwrap();\n    let a = db.engine.get_value(b\"a\").unwrap();\n    assert!(a.is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n    let b = db.engine.get_value(b\"b\").unwrap();\n    assert!(b.is_none());\n    for i in max_keys..2 * max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn mode(&self) -> u32 {\n        match self.specified_mode {\n            Some(x) => x,\n            None => DEFAULT_MODE,\n        }\n    }", "test": "fn test_chmod_file_after_non_existing_file() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    at.touch(TEST_FILE);\n    at.touch(\"file2\");\n    set_permissions(at.plus(TEST_FILE), Permissions::from_mode(0o664)).unwrap();\n    set_permissions(at.plus(\"file2\"), Permissions::from_mode(0o664)).unwrap();\n    scene\n        .ucmd()\n        .arg(\"u+x\")\n        .arg(\"does-not-exist\")\n        .arg(TEST_FILE)\n        .fails()\n        .stderr_contains(\"chmod: cannot access 'does-not-exist': No such file or directory\")\n        .code_is(1);\n\n    assert_eq!(at.metadata(TEST_FILE).permissions().mode(), 0o100_764);\n\n    scene\n        .ucmd()\n        .arg(\"u+x\")\n        .arg(\"--q\")\n        .arg(\"does-not-exist\")\n        .arg(\"file2\")\n        .fails()\n        .no_stderr()\n        .code_is(1);\n    assert_eq!(at.metadata(\"file2\").permissions().mode(), 0o100_764);\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_when_warmup_succeed_and_not_become_leader() {\n    let mut cluster = run_cluster_and_warm_up_cache_for_store2();\n\n    let (sx, rx) = channel::unbounded();\n    fail::cfg_callback(\"worker_async_fetch_raft_log\", move || {\n        sx.send(true).unwrap()\n    })\n    .unwrap();\n    fail::cfg(\"entry_cache_warmed_up_state_is_stale\", \"return\").unwrap();\n\n    // Since the warmup state is stale, the peer should exit warmup state,\n    // and the entry cache should be compacted during post_apply.\n    let applied_index = cluster.apply_state(1, 2).applied_index;\n    cluster.must_put(b\"kk1\", b\"vv1\");\n    cluster.wait_applied_index(1, 2, applied_index + 1);\n    // The peer should warm up cache again when it receives a new TransferLeaderMsg.\n    cluster.transfer_leader(1, new_peer(2, 2));\n    assert!(rx.recv_timeout(Duration::from_millis(500)).unwrap());\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_interactive_dir_to_file_not_affirmative() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir = \"test_mv_interactive_dir_to_file_not_affirmative_dir\";\n    let file = \"test_mv_interactive_dir_to_file_not_affirmative_file\";\n\n    at.mkdir(dir);\n    at.touch(file);\n\n    ucmd.arg(dir)\n        .arg(file)\n        .arg(\"-i\")\n        .pipe_in(\"n\")\n        .fails()\n        .no_stdout();\n\n    assert!(at.dir_exists(dir));\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn test_initial_table_limits_exceeded() -> Result<()> {\n    let engine = Engine::default();\n    let module = Module::new(&engine, r#\"(module (table (export \"t\") 23 anyfunc))\"#)?;\n\n    let mut store = Store::new(&engine, StoreLimitsBuilder::new().table_elements(4).build());\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n\n    match Instance::new(&mut store, &module, &[]) {\n        Ok(_) => unreachable!(),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"table minimum size of 23 elements exceeds table limits\"\n        ),\n    }\n\n    match Table::new(\n        &mut store,\n        TableType::new(ValType::FuncRef, 99, None),\n        Val::FuncRef(None),\n    ) {\n        Ok(_) => unreachable!(),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"table minimum size of 99 elements exceeds table limits\"\n        ),\n    }\n\n    Ok(())\n}"}
{"code": "pub fn get_state(&self) -> Arc<AtomicCell<DownstreamState>> {\n        self.state.clone()\n    }", "test": "fn test_destroy_source_peer_while_merging() {\n    let mut cluster = new_node_cluster(0, 5);\n    configure_for_merge(&mut cluster.cfg);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n    for i in 1..=5 {\n        must_get_equal(&cluster.get_engine(i), b\"k1\", b\"v1\");\n        must_get_equal(&cluster.get_engine(i), b\"k3\", b\"v3\");\n    }\n\n    cluster.must_split(&pd_client.get_region(b\"k1\").unwrap(), b\"k2\");\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k3\").unwrap();\n    cluster.must_transfer_leader(right.get_id(), new_peer(1, 1));\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    // Start merge and wait until peer 5 apply prepare merge\n    cluster.must_try_merge(right.get_id(), left.get_id());\n    cluster.must_peer_state(right.get_id(), 5, PeerState::Merging);\n\n    // filter heartbeat and append message for peer 5\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(right.get_id(), 5)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgHeartbeat)\n            .msg_type(MessageType::MsgAppend),\n    ));\n\n    // remove peer from target region to trigger merge rollback.\n    pd_client.must_remove_peer(left.get_id(), find_peer(&left, 2).unwrap().clone());\n    must_get_none(&cluster.get_engine(2), b\"k1\");\n\n    // Merge must rollbacked if we can put more data to the source region\n    fail::remove(schedule_merge_fp);\n    cluster.must_put(b\"k4\", b\"v4\");\n    for i in 1..=4 {\n        must_get_equal(&cluster.get_engine(i), b\"k4\", b\"v4\");\n    }\n\n    // remove peer 5 from peer list so it will destroy itself by tombstone message\n    // and should not persist the `merge_state`\n    pd_client.must_remove_peer(right.get_id(), new_peer(5, 5));\n    must_get_none(&cluster.get_engine(5), b\"k3\");\n\n    // so that other peers will send message to store 5\n    pd_client.must_add_peer(right.get_id(), new_peer(5, 6));\n    // but it is still in tombstone state due to the message filter\n    let state = cluster.region_local_state(right.get_id(), 5);\n    assert_eq!(state.get_state(), PeerState::Tombstone);\n\n    // let the peer on store 4 have a larger peer id\n    pd_client.must_remove_peer(right.get_id(), new_peer(4, 4));\n    pd_client.must_add_peer(right.get_id(), new_peer(4, 7));\n    must_get_equal(&cluster.get_engine(4), b\"k4\", b\"v4\");\n\n    // if store 5 have persist the merge state, peer 2 and peer 3 will be destroyed\n    // because store 5 will response their request vote message with a gc\n    // message, and peer 7 will cause store 5 panic because peer 7 have larger\n    // peer id than the peer in the merge state\n    cluster.clear_send_filters();\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n\n    cluster.must_put(b\"k5\", b\"v5\");\n    assert!(!state.has_merge_state(), \"{:?}\", state);\n    for i in 2..=5 {\n        must_get_equal(&cluster.get_engine(i), b\"k5\", b\"v5\");\n    }\n}"}
{"code": "pub fn call(\n        &self,\n        mut ctx: impl AsContextMut<UserState = T>,\n        instance: Option<&Instance>,\n        params: FuncParams,\n    ) -> Result<FuncFinished, Trap> {\n        let caller = <Caller<T>>::new(&mut ctx, instance);\n        (self.closure)(caller, params)\n    }", "test": "fn static_add2_works() {\n    let (mut store, add2, add2_dyn) = setup_add2();\n    let add2 = add2.typed::<(i32, i32), i32>(&mut store).unwrap();\n    let add2_dyn = add2_dyn.typed::<(i32, i32), i32>(&mut store).unwrap();\n    for a in 0..10 {\n        for b in 0..10 {\n            let expected = a + b;\n            assert_eq!(add2.call(&mut store, (a, b)).unwrap(), expected);\n            assert_eq!(add2_dyn.call(&mut store, (a, b)).unwrap(), expected);\n        }\n    }\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_lookup_hosts() {\n    let authority = create_example();\n    let mut catalog = Catalog::new();\n    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));\n\n    let io_loop = Runtime::new().unwrap();\n    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));\n    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());\n\n    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);\n    let (client, bg) = io_loop.block_on(client).expect(\"client connect failed\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let mut hosts = Hosts::default();\n    let record = Record::from_rdata(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        86400,\n        RData::A(A::new(10, 0, 1, 104)),\n    );\n    hosts.insert(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        RecordType::A,\n        Lookup::new_with_max_ttl(\n            Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A),\n            Arc::from([record]),\n        ),\n    );\n\n    let lookup = LookupIpFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        LookupIpStrategy::default(),\n        CachingClient::new(0, client, false),\n        Default::default(),\n        Some(Arc::new(hosts)),\n        None,\n    );\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(lookup.iter().next().unwrap(), Ipv4Addr::new(10, 0, 1, 104));\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn write_batch_put() {\n    let db = default_engine();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n\n    let db = multi_batch_write_engine();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..128_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"aa\").unwrap();\n    for i in 128..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);\n    }\n}"}
{"code": "pub fn encoded_len(&self, ident: TokenStream) -> TokenStream {\n        let tag = self.tag;\n        match self.label {\n            Label::Optional => quote! {\n                #ident.as_ref().map_or(0, |msg| ::prost::encoding::group::encoded_len(#tag, msg))\n            },\n            Label::Required => quote! {\n                ::prost::encoding::group::encoded_len(#tag, &#ident)\n            },\n            Label::Repeated => quote! {\n                ::prost::encoding::group::encoded_len_repeated(#tag, &#ident)\n            },\n        }\n    }", "test": "fn test() {\n    use prost::Message;\n\n    let mut widget_factory = widget::factory::WidgetFactory::default();\n    assert_eq!(0, widget_factory.encoded_len());\n\n    widget_factory.inner = Some(widget::factory::widget_factory::Inner {});\n    assert_eq!(2, widget_factory.encoded_len());\n\n    widget_factory.root = Some(Root {});\n    assert_eq!(4, widget_factory.encoded_len());\n\n    widget_factory.root_inner = Some(root::Inner {});\n    assert_eq!(6, widget_factory.encoded_len());\n\n    widget_factory.widget = Some(widget::Widget {});\n    assert_eq!(8, widget_factory.encoded_len());\n\n    widget_factory.widget_inner = Some(widget::widget::Inner {});\n    assert_eq!(10, widget_factory.encoded_len());\n\n    widget_factory.gizmo = Some(gizmo::Gizmo {});\n    assert_eq!(12, widget_factory.encoded_len());\n\n    widget_factory.gizmo_inner = Some(gizmo::gizmo::Inner {});\n    assert_eq!(14, widget_factory.encoded_len());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_multi_1_other() {\n    let mut headers = HeaderMap::new();\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 1);\n    assert_eq!(headers.len(), 1);\n\n    let vias = remove_all_values(&mut headers, VIA);\n    assert_eq!(vias.len(), 1);\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_numbered_with_t() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=t\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}.~1~\")));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_existing_backup() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_existing_backup\";\n    let link = \"test_symlink_existing_backup_link\";\n    let link_backup = \"test_symlink_existing_backup_link.~1~\";\n    let resulting_backup = \"test_symlink_existing_backup_link.~2~\";\n\n    // Create symlink and verify\n    at.touch(file);\n    at.symlink_file(file, link);\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    // Create backup symlink and verify\n    at.symlink_file(file, link_backup);\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link_backup));\n    assert_eq!(at.resolve_link(link_backup), file);\n\n    ucmd.args(&[\"-s\", \"--backup=nil\", file, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(file));\n\n    assert!(at.is_symlink(link_backup));\n    assert_eq!(at.resolve_link(link_backup), file);\n\n    assert!(at.is_symlink(resulting_backup));\n    assert_eq!(at.resolve_link(resulting_backup), file);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_no_create_file_absent() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_no_create_file_absent\";\n\n    ucmd.arg(\"-c\").arg(file).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.slice.is_empty()\n    }", "test": "fn test_parse_self_debug_line() {\n    let debug_info = read_section(\"debug_info\");\n    let debug_info = DebugInfo::new(&debug_info, LittleEndian);\n\n    let debug_abbrev = read_section(\"debug_abbrev\");\n    let debug_abbrev = DebugAbbrev::new(&debug_abbrev, LittleEndian);\n\n    let debug_line = read_section(\"debug_line\");\n    let debug_line = DebugLine::new(&debug_line, LittleEndian);\n\n    let debug_str = read_section(\"debug_str\");\n    let debug_str = DebugStr::new(&debug_str, LittleEndian);\n\n    let mut iter = debug_info.units();\n    while let Some(unit) = iter.next().expect(\"Should parse compilation unit\") {\n        let abbrevs = unit\n            .abbreviations(&debug_abbrev)\n            .expect(\"Should parse abbreviations\");\n\n        let mut cursor = unit.entries(&abbrevs);\n        cursor.next_dfs().expect(\"Should parse next dfs\");\n\n        let unit_entry = cursor.current().expect(\"Should have a root entry\");\n\n        let comp_dir = unit_entry\n            .attr_value(gimli::DW_AT_comp_dir)\n            .expect(\"Should parse comp_dir attribute\")\n            .and_then(|val| val.string_value(&debug_str));\n        let comp_name = unit_entry\n            .attr_value(gimli::DW_AT_name)\n            .expect(\"Should parse name attribute\")\n            .and_then(|val| val.string_value(&debug_str));\n\n        if let Some(AttributeValue::DebugLineRef(offset)) = unit_entry\n            .attr_value(gimli::DW_AT_stmt_list)\n            .expect(\"Should parse stmt_list\")\n        {\n            let program = debug_line\n                .program(offset, unit.address_size(), comp_dir, comp_name)\n                .expect(\"should parse line number program header\");\n\n            let mut results = Vec::new();\n            let mut rows = program.rows();\n            while let Some((_, row)) = rows\n                .next_row()\n                .expect(\"Should parse and execute all rows in the line number program\")\n            {\n                results.push(*row);\n            }\n            results.reverse();\n\n            let program = debug_line\n                .program(offset, unit.address_size(), comp_dir, comp_name)\n                .expect(\"should parse line number program header\");\n            let (program, sequences) = program\n                .sequences()\n                .expect(\"should parse and execute the entire line number program\");\n            assert!(!sequences.is_empty()); // Should be at least one sequence.\n            for sequence in sequences {\n                let mut rows = program.resume_from(&sequence);\n                while let Some((_, row)) = rows\n                    .next_row()\n                    .expect(\"Should parse and execute all rows after resuming\")\n                {\n                    let other_row = results.pop().unwrap();\n                    assert!(row.address() >= sequence.start);\n                    assert!(row.address() <= sequence.end);\n                    assert_eq!(row.address(), other_row.address());\n                    assert_eq!(row.line(), other_row.line());\n                }\n            }\n            assert!(results.is_empty());\n        }\n    }\n}"}
{"code": "pub fn name(&self) -> &str {\n        &self.data.file_name\n    }", "test": "fn aes192_encrypted_file() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"data/aes_archive.zip\"));\n    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    let mut file = archive\n        .by_name_decrypt(\"secret_data_192\", PASSWORD)\n        .expect(\"couldn't find file in archive\")\n        .expect(\"invalid password\");\n    assert_eq!(\"secret_data_192\", file.name());\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"couldn't read encrypted file\");\n    assert_eq!(SECRET_CONTENT, content);\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit2_wasi_snapshot1() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit2_wasi_snapshot1.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 2);\n    Ok(())\n}"}
{"code": "pub fn size(&self, store: impl AsContext) -> u64 {\n        self.internal_size(store.as_context().0)\n    }", "test": "fn memory_zeroed() -> Result<()> {\n    if skip_pooling_allocator_tests() {\n        return Ok(());\n    }\n\n    let mut pool = crate::small_pool_config();\n    pool.memory_pages(1).table_elements(0);\n    let mut config = Config::new();\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n    config.dynamic_memory_guard_size(0);\n    config.static_memory_guard_size(0);\n    config.static_memory_maximum_size(65536);\n\n    let engine = Engine::new(&config)?;\n\n    let module = Module::new(&engine, r#\"(module (memory (export \"m\") 1))\"#)?;\n\n    // Instantiate the module repeatedly after writing data to the entire memory\n    for _ in 0..10 {\n        let mut store = Store::new(&engine, ());\n        let instance = Instance::new(&mut store, &module, &[])?;\n        let memory = instance.get_memory(&mut store, \"m\").unwrap();\n\n        assert_eq!(memory.size(&store,), 1);\n        assert_eq!(memory.data_size(&store), 65536);\n\n        let ptr = memory.data_mut(&mut store).as_mut_ptr();\n\n        unsafe {\n            for i in 0..8192 {\n                assert_eq!(*ptr.cast::<u64>().offset(i), 0);\n            }\n            std::ptr::write_bytes(ptr, 0xFE, memory.data_size(&store));\n        }\n    }\n\n    Ok(())\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_closing_bracket_in_double_quote_mixed() {\n    let mut r = Reader::from_str(r#\"<a attr=\"'>'\" check=\"'2'\"></a>\"#);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Start(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"attr\"),\n                    value: Cow::Borrowed(b\"'>'\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"check\"),\n                    value: Cow::Borrowed(b\"'2'\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        x => panic!(\"expected <a attr='>'>, got {:?}\", x),\n    }\n    next_eq!(r, End, b\"a\");\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn catch_trap_calling_across_stores() -> Result<()> {\n    let _ = env_logger::try_init();\n\n    let engine = Engine::default();\n\n    let mut child_store = Store::new(&engine, ());\n    let child_module = Module::new(\n        child_store.engine(),\n        r#\"\n            (module $child\n              (func $trap (export \"trap\")\n                unreachable\n              )\n            )\n        \"#,\n    )?;\n    let child_instance = Instance::new(&mut child_store, &child_module, &[])?;\n\n    struct ParentCtx {\n        child_store: Store<()>,\n        child_instance: Instance,\n    }\n\n    let mut linker = Linker::new(&engine);\n    linker.func_wrap(\n        \"host\",\n        \"catch_child_trap\",\n        move |mut caller: Caller<'_, ParentCtx>| {\n            let mut ctx = caller.as_context_mut();\n            let data = ctx.data_mut();\n            let func = data\n                .child_instance\n                .get_typed_func::<(), ()>(&mut data.child_store, \"trap\")\n                .expect(\"trap function should be exported\");\n\n            let trap = func.call(&mut data.child_store, ()).unwrap_err();\n            assert!(\n                format!(\"{trap:?}\").contains(\"unreachable\"),\n                \"trap should contain 'unreachable', got: {trap:?}\"\n            );\n\n            let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n\n            assert_eq!(trace.len(), 1);\n            assert_eq!(trace[0].func_name(), Some(\"trap\"));\n            // For now, we only get stack frames for Wasm in this store, not\n            // across all stores.\n            //\n            // assert_eq!(trace[1].func_name(), Some(\"run\"));\n\n            Ok(())\n        },\n    )?;\n\n    let mut store = Store::new(\n        &engine,\n        ParentCtx {\n            child_store,\n            child_instance,\n        },\n    );\n\n    let parent_module = Module::new(\n        store.engine(),\n        r#\"\n            (module $parent\n              (func $host.catch_child_trap (import \"host\" \"catch_child_trap\"))\n              (func $run (export \"run\")\n                call $host.catch_child_trap\n              )\n            )\n        \"#,\n    )?;\n\n    let parent_instance = linker.instantiate(&mut store, &parent_module)?;\n\n    let func = parent_instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n    func.call(store, ())?;\n\n    Ok(())\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn cannot_use_borrow_for_own() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n\n                (core module $m\n                    (func (export \"f\") (param i32) (result i32)\n                        local.get 0\n                    )\n                )\n                (core instance $i (instantiate $m))\n\n                (func (export \"f\") (param \"x\" (borrow $t)) (result (own $t))\n                    (canon lift (core func $i \"f\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n    let i = linker.instantiate(&mut store, &c)?;\n\n    let f = i.get_typed_func::<(&Resource<MyType>,), (Resource<MyType>,)>(&mut store, \"f\")?;\n\n    let resource = Resource::new_own(100);\n    let err = f.call(&mut store, (&resource,)).unwrap_err();\n    assert_eq!(err.to_string(), \"cannot lift own resource from a borrow\");\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> Option<usize> {\n        match self.0 {\n            ValueRepr::String(ref s, _) => Some(s.chars().count()),\n            ValueRepr::Map(ref items, _) => Some(items.len()),\n            ValueRepr::Seq(ref items) => Some(items.len()),\n            ValueRepr::Dynamic(ref dy) => match dy.kind() {\n                ObjectKind::Plain => None,\n                ObjectKind::Seq(s) => Some(s.item_count()),\n                ObjectKind::Struct(s) => Some(s.field_count()),\n            },\n            _ => None,\n        }\n    }", "test": "fn test_args() {\n    fn type_name_of_val<T: ?Sized>(_val: &T) -> &str {\n        std::any::type_name::<T>()\n    }\n\n    let args = args!();\n    assert_eq!(args.len(), 0);\n    assert_eq!(type_name_of_val(args), \"[minijinja::value::Value]\");\n\n    let args = args!(1, 2);\n    assert_eq!(args[0], Value::from(1));\n    assert_eq!(args[1], Value::from(2));\n    assert_eq!(type_name_of_val(args), \"[minijinja::value::Value]\");\n\n    let args = args!(1, 2,);\n    assert_eq!(args[0], Value::from(1));\n    assert_eq!(args[1], Value::from(2));\n\n    let args = args!(1, 2, foo => 42, bar => 23);\n    assert_eq!(args[0], Value::from(1));\n    assert_eq!(args[1], Value::from(2));\n    let kwargs = Kwargs::try_from(args[2].clone()).unwrap();\n    assert_eq!(kwargs.get::<i32>(\"foo\").unwrap(), 42);\n    assert_eq!(kwargs.get::<i32>(\"bar\").unwrap(), 23);\n\n    let args = args!(1, 2, foo => 42, bar => 23,);\n    assert_eq!(args[0], Value::from(1));\n    assert_eq!(args[1], Value::from(2));\n    let kwargs = Kwargs::try_from(args[2].clone()).unwrap();\n    assert_eq!(kwargs.get::<i32>(\"foo\").unwrap(), 42);\n    assert_eq!(kwargs.get::<i32>(\"bar\").unwrap(), 23);\n    assert_eq!(type_name_of_val(args), \"[minijinja::value::Value]\");\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "async fn timeout_async_hook() -> Result<(), Error> {\n    struct HandlerR;\n\n    #[async_trait::async_trait]\n    impl CallHookHandler<State> for HandlerR {\n        async fn handle_call_event(&self, obj: &mut State, ch: CallHook) -> Result<()> {\n            if obj.calls_into_host > 200 {\n                bail!(\"timeout\");\n            }\n\n            match ch {\n                CallHook::CallingHost => obj.calls_into_host += 1,\n                CallHook::CallingWasm => obj.calls_into_wasm += 1,\n                CallHook::ReturningFromHost => obj.returns_from_host += 1,\n                CallHook::ReturningFromWasm => obj.returns_from_wasm += 1,\n            }\n\n            Ok(())\n        }\n    }\n\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook_async(HandlerR {});\n\n    assert_eq!(store.data().calls_into_host, 0);\n    assert_eq!(store.data().returns_from_host, 0);\n    assert_eq!(store.data().calls_into_wasm, 0);\n    assert_eq!(store.data().returns_from_wasm, 0);\n\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\n        \"host\",\n        \"f\",\n        |_caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            assert_eq!(a, 1);\n            assert_eq!(b, 2);\n            assert_eq!(c, 3.0);\n            assert_eq!(d, 4.0);\n        },\n    )?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32) (param i64) (param f32) (param f64)))\n            (func (export \"export\")\n                (loop $start\n                    (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0))\n                    (br $start)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let inst = linker.instantiate_async(&mut store, &module).await?;\n    let export = inst\n        .get_typed_func::<(), ()>(&mut store, \"export\")\n        .expect(\"export is func\");\n\n    store.set_epoch_deadline(1);\n    store.epoch_deadline_async_yield_and_update(1);\n    assert!(export.call_async(&mut store, ()).await.is_err());\n\n    // One switch from vm to host to call f, another in return from f.\n    assert!(store.data().calls_into_host > 1);\n    assert!(store.data().returns_from_host > 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 0);\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_custom_backup_suffix_hyphen_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_custom_backup_suffix\";\n    let link = \"test_symlink_custom_backup_suffix_link\";\n    let suffix = \"-v\";\n\n    at.touch(file);\n    at.symlink_file(file, link);\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    let arg = &format!(\"--suffix={suffix}\");\n    ucmd.args(&[\"-b\", arg, \"-s\", file, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(file));\n\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n\n    let backup = &format!(\"{link}{suffix}\");\n    assert!(at.is_symlink(backup));\n    assert_eq!(at.resolve_link(backup), file);\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_read_on_replica() {\n    let count = 3;\n    let mut cluster = new_server_cluster(0, count);\n    cluster.cfg.raft_store.hibernate_regions = false;\n    cluster.run();\n\n    let k1 = b\"k1\";\n    let (k2, v2) = (b\"k2\", b\"v2\");\n    let (k3, v3) = (b\"k3\", b\"v3\");\n    let (k4, v4) = (b\"k4\", b\"v4\");\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(k1), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let mut leader_storage = cluster.sim.rl().storages[&leader.get_id()].clone();\n\n    let mut leader_ctx = Context::default();\n    leader_ctx.set_region_id(region.get_id());\n    leader_ctx.set_region_epoch(region.get_region_epoch().clone());\n    leader_ctx.set_peer(leader.clone());\n    let leader_snap_ctx = SnapContext {\n        pb_ctx: &leader_ctx,\n        ..Default::default()\n    };\n\n    // write some data\n    let peers = region.get_peers();\n    assert_none(leader_snap_ctx, &mut leader_storage, k2);\n    must_put(&leader_ctx, &leader_storage, k2, v2);\n\n    // read on follower\n    let mut follower_peer = None;\n    let mut follower_id = 0;\n    for p in peers {\n        if p.get_id() != leader.get_id() {\n            follower_id = p.get_id();\n            follower_peer = Some(p.clone());\n            break;\n        }\n    }\n\n    assert!(follower_peer.is_some());\n    let mut follower_ctx = Context::default();\n    follower_ctx.set_region_id(region.get_id());\n    follower_ctx.set_region_epoch(region.get_region_epoch().clone());\n    follower_ctx.set_peer(follower_peer.as_ref().unwrap().clone());\n    follower_ctx.set_replica_read(true);\n    let follower_snap_ctx = SnapContext {\n        pb_ctx: &follower_ctx,\n        ..Default::default()\n    };\n    let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();\n    assert_has(follower_snap_ctx.clone(), &mut follower_storage, k2, v2);\n\n    must_put(&leader_ctx, &leader_storage, k3, v3);\n    assert_has(follower_snap_ctx.clone(), &mut follower_storage, k3, v3);\n\n    cluster.stop_node(follower_id);\n    must_put(&leader_ctx, &leader_storage, k4, v4);\n    cluster.run_node(follower_id).unwrap();\n    let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();\n    // sleep to ensure the follower has received a heartbeat from the leader\n    thread::sleep(time::Duration::from_millis(300));\n    assert_has(follower_snap_ctx, &mut follower_storage, k4, v4);\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn reject_missing_client_cert() {\n    let _guard = subscribe();\n\n    let key = rustls::PrivateKey(CERTIFICATE.serialize_private_key_der());\n    let cert = util::CERTIFICATE.serialize_der().unwrap();\n\n    let config = rustls::ServerConfig::builder()\n        .with_safe_default_cipher_suites()\n        .with_safe_default_kx_groups()\n        .with_protocol_versions(&[&rustls::version::TLS13])\n        .unwrap()\n        .with_client_cert_verifier(Arc::new(rustls::server::AllowAnyAuthenticatedClient::new(\n            rustls::RootCertStore::empty(),\n        )))\n        .with_single_cert(vec![rustls::Certificate(cert)], key)\n        .unwrap();\n\n    let mut pair = Pair::new(\n        Default::default(),\n        ServerConfig::with_crypto(Arc::new(config)),\n    );\n\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config());\n    pair.drive();\n\n    // The client completes the connection, but finds it immediately closed\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected)\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(ref close)})\n                    if close.error_code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));\n\n    // The server never completes the connection\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::TransportError(ref error)})\n                    if error.code == TransportErrorCode::crypto(AlertDescription::CertificateRequired.get_u8()));\n}"}
{"code": "pub fn ceil_log2_pow5(e: i32) -> i32 /* or u32 -> u32 */ {\n    log2_pow5(e) + 1\n}", "test": "fn test_ceil_log2_pow5() {\n    assert_eq!(1, ceil_log2_pow5(0));\n    assert_eq!(3, ceil_log2_pow5(1));\n    assert_eq!(5, ceil_log2_pow5(2));\n    assert_eq!(7, ceil_log2_pow5(3));\n    assert_eq!(10, ceil_log2_pow5(4));\n    assert_eq!(8192, ceil_log2_pow5(3528));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_none() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=none\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(!at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn sqrtf_spec_test() {\n    // Not Asserted: FE_INVALID exception is raised if argument is negative.\n    assert!(libm::sqrtf(-1.0).is_nan());\n    assert!(libm::sqrtf(f32::NAN).is_nan());\n    for f in [0.0, -0.0, f32::INFINITY].iter().copied() {\n        assert_eq!(libm::sqrtf(f), f);\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_unknown() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert_error(PathBuf::from(\"prefix/ci.js\"), ErrorEntry::UnknownFileType);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), (\"prefix\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_unknown\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_config_ok_formatter_no_linter() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"format.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"format.json\");\n    fs.insert(\n        format.into(),\n        r#\"{ \"javascript\": { \"formatter\": { \"quoteStyle\": \"single\" } } }\"#,\n    );\n    let lint = Path::new(\"linter.json\");\n    fs.insert(lint.into(), r#\"{ \"linter\": { \"enabled\": false } }\"#);\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), test_file.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_config_ok_formatter_no_linter\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_get_var() {\n    let result = TestScenario::new(util_name!())\n        .ucmd()\n        .env(\"KEY\", \"VALUE\")\n        .arg(\"KEY\")\n        .succeeds();\n\n    assert!(!result.stdout_str().is_empty());\n    assert_eq!(result.stdout_str().trim(), \"VALUE\");\n}"}
{"code": "pub(crate) fn scientific_exponent(\n    exponent: i32,\n    integer_digits: usize,\n    fraction_start: usize,\n) -> i32 {\n    if integer_digits == 0 {\n        let fraction_start = into_i32(fraction_start);\n        exponent.saturating_sub(fraction_start).saturating_sub(1)\n    } else {\n        let integer_shift = into_i32(integer_digits - 1);\n        exponent.saturating_add(integer_shift)\n    }\n}", "test": "fn scientific_exponent_test() {\n    // 0 digits in the integer\n    assert_eq!(scientific_exponent(0, 0, 5), -6);\n    assert_eq!(scientific_exponent(10, 0, 5), 4);\n    assert_eq!(scientific_exponent(-10, 0, 5), -16);\n\n    // >0 digits in the integer\n    assert_eq!(scientific_exponent(0, 1, 5), 0);\n    assert_eq!(scientific_exponent(0, 2, 5), 1);\n    assert_eq!(scientific_exponent(0, 2, 20), 1);\n    assert_eq!(scientific_exponent(10, 2, 20), 11);\n    assert_eq!(scientific_exponent(-10, 2, 20), -9);\n\n    // Underflow\n    assert_eq!(\n        scientific_exponent(i32::min_value(), 0, 0),\n        i32::min_value()\n    );\n    assert_eq!(\n        scientific_exponent(i32::min_value(), 0, 5),\n        i32::min_value()\n    );\n\n    // Overflow\n    assert_eq!(\n        scientific_exponent(i32::max_value(), 0, 0),\n        i32::max_value() - 1\n    );\n    assert_eq!(\n        scientific_exponent(i32::max_value(), 5, 0),\n        i32::max_value()\n    );\n}"}
{"code": "pub fn send_upload_sst(\n    client: &ImportSstClient,\n    meta: &SstMeta,\n    data: &[u8],\n) -> Result<UploadResponse> {\n    let mut r1 = UploadRequest::default();\n    r1.set_meta(meta.clone());\n    let mut r2 = UploadRequest::default();\n    r2.set_data(data.to_vec());\n    let reqs: Vec<_> = vec![r1, r2]\n        .into_iter()\n        .map(|r| Result::Ok((r, WriteFlags::default())))\n        .collect();\n    let (mut tx, rx) = client.upload().unwrap();\n    let mut stream = stream::iter(reqs);\n    block_on(async move {\n        tx.send_all(&mut stream).await?;\n        tx.close().await?;\n        rx.await\n    })\n}", "test": "fn test_cleanup_sst() {\n    let (mut cluster, ctx, _, import) = new_cluster_and_tikv_import_client();\n\n    let temp_dir = Builder::new().prefix(\"test_cleanup_sst\").tempdir().unwrap();\n\n    let sst_path = temp_dir.path().join(\"test_split.sst\");\n    let sst_range = (0, 100);\n    let (mut meta, data) = gen_sst_file(sst_path, sst_range);\n    meta.set_region_id(ctx.get_region_id());\n    meta.set_region_epoch(ctx.get_region_epoch().clone());\n\n    send_upload_sst(&import, &meta, &data).unwrap();\n\n    // Can not upload the same file when it exists.\n    assert_to_string_contains!(\n        send_upload_sst(&import, &meta, &data).unwrap_err(),\n        \"FileExists\"\n    );\n\n    // The uploaded SST should be deleted if the region split.\n    let region = cluster.get_region(&[]);\n    cluster.must_split(&region, &[100]);\n\n    check_sst_deleted(&import, &meta, &data);\n\n    let left = cluster.get_region(&[]);\n    let right = cluster.get_region(&[100]);\n\n    let sst_path = temp_dir.path().join(\"test_merge.sst\");\n    let sst_range = (0, 100);\n    let (mut meta, data) = gen_sst_file(sst_path, sst_range);\n    meta.set_region_id(left.get_id());\n    meta.set_region_epoch(left.get_region_epoch().clone());\n\n    send_upload_sst(&import, &meta, &data).unwrap();\n\n    // The uploaded SST should be deleted if the region merged.\n    cluster.pd_client.must_merge(left.get_id(), right.get_id());\n    let res = block_on(cluster.pd_client.get_region_by_id(left.get_id()));\n    assert_eq!(res.unwrap(), None);\n\n    check_sst_deleted(&import, &meta, &data);\n}"}
{"code": "pub fn is_undefined(&self) -> bool {\n        matches!(&self.0, ValueRepr::Undefined)\n    }", "test": "fn test_undefined_roundtrip() {\n    let v = Value::UNDEFINED;\n    let v2 = Value::from_serializable(&v);\n    assert!(v.is_undefined());\n    assert!(v2.is_undefined());\n}"}
{"code": "pub fn i32(i: i32) -> ValRaw {\n        // Note that this is intentionally not setting the `i32` field, instead\n        // setting the `i64` field with a zero-extended version of `i`. For more\n        // information on this see the comments on `Lower for Result` in the\n        // `wasmtime` crate. Otherwise though all `ValRaw` constructors are\n        // otherwise constrained to guarantee that the initial 64-bits are\n        // always initialized.\n        ValRaw::u64((i as u32).into())\n    }", "test": "fn call_array_to_native() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let func = Func::wrap(&mut store, |a: i32, b: i32, c: i32| -> (i32, i32, i32) {\n        (a * 10, b * 10, c * 10)\n    });\n    let mut results = [Val::I32(0), Val::I32(0), Val::I32(0)];\n    func.call(\n        &mut store,\n        &[Val::I32(10), Val::I32(20), Val::I32(30)],\n        &mut results,\n    )?;\n    assert_eq!(results[0].i32(), Some(100));\n    assert_eq!(results[1].i32(), Some(200));\n    assert_eq!(results[2].i32(), Some(300));\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_raftlog_gc_pull_voter_replicated_index() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(50);\n    cluster\n        .cfg\n        .raft_store\n        .request_voter_replicated_index_interval = ReadableDuration::millis(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // one follower is down\n    cluster.stop_node(nodes[1]);\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    // the witness truncated index is not advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        if id == 2 {\n            assert_eq!(\n                state.get_truncated_state().get_index() - before_states[&id].get_index(),\n                0\n            );\n        } else {\n            assert_ne!(\n                900,\n                state.get_truncated_state().get_index() - before_states[&id].get_index()\n            );\n        }\n    }\n\n    fail::cfg(\"on_raft_gc_log_tick\", \"return\").unwrap();\n\n    // the follower is back online\n    cluster.run_node(nodes[1]).unwrap();\n    cluster.must_put(b\"k00\", b\"v00\");\n    must_get_equal(&cluster.get_engine(nodes[1]), b\"k00\", b\"v00\");\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(300));\n\n    // the truncated index is advanced now, as all the peers has replicated\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n    fail::remove(\"on_raft_gc_log_tick\");\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_integer_key() {\n    // map with integer keys\n    let map = treemap!(\n        1 => 2,\n        -1 => 6,\n    );\n    let j = r#\"{\"-1\":6,\"1\":2}\"#;\n    test_encode_ok(&[(&map, j)]);\n    test_parse_ok(vec![(j, map)]);\n\n    test_parse_err::<BTreeMap<i32, ()>>(&[\n        (\n            r#\"{\"x\":null}\"#,\n            \"invalid value: expected key to be a number in quotes at line 1 column 2\",\n        ),\n        (\n            r#\"{\" 123\":null}\"#,\n            \"invalid value: expected key to be a number in quotes at line 1 column 2\",\n        ),\n        (r#\"{\"123 \":null}\"#, \"expected `\\\"` at line 1 column 6\"),\n    ]);\n\n    let err = from_value::<BTreeMap<i32, ()>>(json!({\" 123\":null})).unwrap_err();\n    assert_eq!(\n        err.to_string(),\n        \"invalid value: expected key to be a number in quotes\",\n    );\n\n    let err = from_value::<BTreeMap<i32, ()>>(json!({\"123 \":null})).unwrap_err();\n    assert_eq!(\n        err.to_string(),\n        \"invalid value: expected key to be a number in quotes\",\n    );\n}"}
{"code": "fn len(&self) -> usize {\n        self.length() - self.cursor()\n    }", "test": "fn simple_test() {\n    // Test the simple properties of the stack vector.\n    let mut x = VecType::from_u32(1);\n    assert_eq!(x.len(), 1);\n    assert_eq!(x.is_empty(), false);\n    assert_eq!(x.capacity(), SIZE);\n    x.try_push(5).unwrap();\n    assert_eq!(x.len(), 2);\n    assert_eq!(x.pop(), Some(5));\n    assert_eq!(x.len(), 1);\n    assert_eq!(&*x, &[1]);\n    x.try_extend(&[2, 3, 4]).unwrap();\n    assert_eq!(x.len(), 4);\n    assert_eq!(&*x, &[1, 2, 3, 4]);\n    x.try_resize(6, 0).unwrap();\n    assert_eq!(x.len(), 6);\n    assert_eq!(&*x, &[1, 2, 3, 4, 0, 0]);\n    x.try_resize(0, 0).unwrap();\n    assert_eq!(x.len(), 0);\n    assert_eq!(x.is_empty(), true);\n\n    let x = VecType::try_from(&[5, 1]).unwrap();\n    assert_eq!(x.len(), 2);\n    assert_eq!(x.is_empty(), false);\n    assert_eq!(x.hi16(), (0x8000, true));\n    if LIMB_BITS == 32 {\n        assert_eq!(x.hi32(), (0x80000002, true));\n        assert_eq!(x.hi64(), (0x8000000280000000, false));\n    } else {\n        assert_eq!(x.hi32(), (0x80000000, true));\n        assert_eq!(x.hi64(), (0x8000000000000002, true));\n    }\n    let rview = x.rview();\n    assert_eq!(x[0], 5);\n    assert_eq!(x[1], 1);\n    assert_eq!(rview[0], 1);\n    assert_eq!(rview[1], 5);\n    assert_eq!(rview.get(1), Some(&5));\n    assert_eq!(rview.get(2), None);\n\n    assert_eq!(VecType::from_u16(u16::MAX).hi16(), (u16::MAX, false));\n    assert_eq!(VecType::from_u32(u32::MAX).hi32(), (u32::MAX, false));\n    assert_eq!(VecType::from_u64(u64::MAX).hi64(), (u64::MAX, false));\n}"}
{"code": "fn method(s: &str) -> Header<Option<HeaderName>> {\n        Header::Method(Method::from_bytes(s.as_bytes()).unwrap())\n    }", "test": "async fn push_request() {\n    h2_support::trace_init!();\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        client\n            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))\n            .await;\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"GET\", \"https://example.com/\")\n                    .eos(),\n            )\n            .await;\n        client\n            .recv_frame(\n                frames::push_promise(1, 2).request(\"GET\", \"https://http2.akamai.com/style.css\"),\n            )\n            .await;\n        client\n            .recv_frame(frames::headers(2).response(200).eos())\n            .await;\n        client\n            .recv_frame(\n                frames::push_promise(1, 4).request(\"GET\", \"https://http2.akamai.com/style2.css\"),\n            )\n            .await;\n        client\n            .recv_frame(frames::headers(4).response(200).eos())\n            .await;\n        client\n            .recv_frame(frames::headers(1).response(200).eos())\n            .await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n        let (req, mut stream) = srv.next().await.unwrap().unwrap();\n\n        assert_eq!(req.method(), &http::Method::GET);\n\n        // Promise stream 2\n        let mut pushed_s2 = {\n            let req = http::Request::builder()\n                .method(\"GET\")\n                .uri(\"https://http2.akamai.com/style.css\")\n                .body(())\n                .unwrap();\n            stream.push_request(req).unwrap()\n        };\n\n        // Promise stream 4 and push response headers\n        {\n            let req = http::Request::builder()\n                .method(\"GET\")\n                .uri(\"https://http2.akamai.com/style2.css\")\n                .body(())\n                .unwrap();\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            stream\n                .push_request(req)\n                .unwrap()\n                .send_response(rsp, true)\n                .unwrap();\n        }\n\n        // Push response to stream 2\n        {\n            let rsp = http::Response::builder().status(200).body(()).unwrap();\n            pushed_s2.send_response(rsp, true).unwrap();\n        }\n\n        // Send response for stream 1\n        let rsp = http::Response::builder().status(200).body(()).unwrap();\n        stream.send_response(rsp, true).unwrap();\n\n        assert!(srv.next().await.is_none());\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn get_id(&self) -> DownstreamId {\n        self.id\n    }", "test": "fn test_node_merge_transfer_leader() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n    cluster.cfg.raft_store.store_batch_system.max_batch_size = Some(1);\n    cluster.cfg.raft_store.store_batch_system.pool_size = 2;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    // To ensure the region has applied to its current term so that later `split`\n    // can success without any retries. Then, `left_peer_3` will must be `1003`.\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    let peer_1 = find_peer(&region, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), peer_1);\n    let k = b\"k1_for_apply_to_current_term\";\n    cluster.must_put(k, b\"value\");\n    must_get_equal(&cluster.get_engine(1), k, b\"value\");\n\n    cluster.must_split(&region, b\"k2\");\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    let left_peer_1 = find_peer(&left, 1).unwrap().to_owned();\n    cluster.must_transfer_leader(left.get_id(), left_peer_1.clone());\n\n    let left_peer_3 = find_peer(&left, 3).unwrap().to_owned();\n    assert_eq!(left_peer_3.get_id(), 1003);\n\n    let schedule_merge_fp = \"on_schedule_merge\";\n    fail::cfg(schedule_merge_fp, \"return()\").unwrap();\n\n    cluster.must_try_merge(left.get_id(), right.get_id());\n\n    // Prevent peer 1003 to handle ready when it's leader\n    let before_handle_raft_ready_1003 = \"before_handle_raft_ready_1003\";\n    fail::cfg(before_handle_raft_ready_1003, \"pause\").unwrap();\n\n    let epoch = cluster.get_region_epoch(left.get_id());\n    let mut transfer_leader_req =\n        new_admin_request(left.get_id(), &epoch, new_transfer_leader_cmd(left_peer_3));\n    transfer_leader_req.mut_header().set_peer(left_peer_1);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, transfer_leader_req, Callback::None)\n        .unwrap();\n    fail::remove(schedule_merge_fp);\n\n    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));\n\n    fail::remove(before_handle_raft_ready_1003);\n    sleep_ms(100);\n    cluster.must_put(b\"k4\", b\"v4\");\n    must_get_equal(&cluster.get_engine(3), b\"k4\", b\"v4\");\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_attribute_equal() {\n    let src = \"<a att1=\\\"a=b\\\"/>\";\n    let mut r = Reader::from_str(src);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Empty(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"att1\"),\n                    value: Cow::Borrowed(b\"a=b\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        e => panic!(\"Expecting Empty event, got {:?}\", e),\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_nil() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=nil\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn non_durable_read_isolation() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let mut write_txn = db.begin_write().unwrap();\n    write_txn.set_durability(Durability::None);\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let read_table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", read_table.get(\"hello\").unwrap().unwrap().value());\n\n    let mut write_txn = db.begin_write().unwrap();\n    write_txn.set_durability(Durability::None);\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.remove(\"hello\").unwrap();\n        table.insert(\"hello2\", \"world2\").unwrap();\n        table.insert(\"hello3\", \"world3\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn2 = db.begin_read().unwrap();\n    let read_table2 = read_txn2.open_table(STR_TABLE).unwrap();\n    assert!(read_table2.get(\"hello\").unwrap().is_none());\n    assert_eq!(\n        \"world2\",\n        read_table2.get(\"hello2\").unwrap().unwrap().value()\n    );\n    assert_eq!(\n        \"world3\",\n        read_table2.get(\"hello3\").unwrap().unwrap().value()\n    );\n    assert_eq!(read_table2.len().unwrap(), 2);\n\n    assert_eq!(\"world\", read_table.get(\"hello\").unwrap().unwrap().value());\n    assert!(read_table.get(\"hello2\").unwrap().is_none());\n    assert!(read_table.get(\"hello3\").unwrap().is_none());\n    assert_eq!(read_table.len().unwrap(), 1);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_ignore_consistency_check() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_election_timeout_ticks = 50;\n    // disable compact log to make test more stable.\n    cluster.cfg.raft_store.raft_log_gc_threshold = 1000;\n    cluster.cfg.raft_store.consistency_check_interval = ReadableDuration::secs(1);\n    cluster.run();\n\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure the peer_on_store3 has completed applied to witness\n    std::thread::sleep(Duration::from_millis(200));\n\n    for i in 0..300 {\n        cluster.must_put(\n            format!(\"k{:06}\", i).as_bytes(),\n            format!(\"k{:06}\", i).as_bytes(),\n        );\n        std::thread::sleep(Duration::from_millis(10));\n    }\n}"}
{"code": "pub fn stdout(&self) -> &[u8] {\n        &self.stdout\n    }", "test": "fn custom_context() {\n    let t_ud = \"unconfined_t\";\n    let u_ud = \"unconfined_u\";\n    let r_ud = \"unconfined_r\";\n\n    new_ucmd!().args(&[\"--compute\", \"/bin/true\"]).succeeds();\n\n    let args = &[\"--compute\", \"/bin/false\"];\n    new_ucmd!().args(args).fails().code_is(1);\n\n    let args = &[\"--type\", t_ud, \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    let args = &[\"--compute\", \"--type\", t_ud, \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    let args = &[\"--user=system_u\", \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    let args = &[\"--compute\", \"--user=system_u\", \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    let args = &[\"--role=system_r\", \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    let args = &[\"--compute\", \"--role=system_r\", \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    new_ucmd!().args(&[\"--range=s0\", \"/bin/true\"]).succeeds();\n\n    let args = &[\"--compute\", \"--range=s0\", \"/bin/true\"];\n    new_ucmd!().args(args).succeeds();\n\n    for (ctx, u, r) in [\n        (\"unconfined_u:unconfined_r:unconfined_t:s0\", u_ud, r_ud),\n        (\"system_u:unconfined_r:unconfined_t:s0\", \"system_u\", r_ud),\n        (\"unconfined_u:system_r:unconfined_t:s0\", u_ud, \"system_r\"),\n        (\"system_u:system_r:unconfined_t:s0\", \"system_u\", \"system_r\"),\n    ] {\n        let args = &[\"-t\", t_ud, \"-u\", u, \"-r\", r, \"-l\", \"s0\", \"sestatus\", \"-v\"];\n\n        let output = new_ucmd!().args(args).succeeds();\n        assert_eq!(get_sestatus_context(output.stdout()), ctx);\n    }\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn instantiate() -> Result<(), Error> {\n    let mut store = Store::<State>::default();\n    store.call_hook(State::call_hook);\n\n    let m = Module::new(store.engine(), \"(module)\")?;\n    Instance::new(&mut store, &m, &[])?;\n    assert_eq!(store.data().calls_into_wasm, 0);\n    assert_eq!(store.data().calls_into_host, 0);\n\n    let m = Module::new(store.engine(), \"(module (func) (start 0))\")?;\n    Instance::new(&mut store, &m, &[])?;\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().calls_into_host, 0);\n\n    Ok(())\n}"}
{"code": "pub fn stream_id(&self) -> StreamId {\n        self.stream_id\n    }", "test": "async fn read_data_no_padding() {\n    let mut codec = raw_codec! {\n        read => [\n            0, 0, 5, 0, 0, 0, 0, 0, 1,\n            \"hello\",\n        ];\n    };\n\n    let data = poll_frame!(Data, codec);\n    assert_eq!(data.stream_id(), 1);\n    assert_eq!(data.payload(), &b\"hello\"[..]);\n    assert!(!data.is_end_stream());\n\n    assert_closed!(codec);\n}"}
{"code": "pub fn fuel(&self) -> Option<u64> {\n        self.fuel\n    }", "test": "fn test_basic() {\n    let mut env = Environment::new();\n    assert_eq!(env.fuel(), None);\n    env.set_fuel(Some(100));\n    assert_eq!(env.fuel(), Some(100));\n    env.add_template(\"test\", \"{% for x in seq %}{{ x }}\\n{% endfor %}\")\n        .unwrap();\n    let t = env.get_template(\"test\").unwrap();\n\n    // this will still manage to run with 100 fuel\n    let rv = t\n        .render(context!(seq => (0..15).collect::<Vec<_>>()))\n        .unwrap();\n    assert_eq!(rv.lines().count(), 15);\n\n    // this is above the limit\n    let rv = t\n        .render(context!(seq => (0..20).collect::<Vec<_>>()))\n        .unwrap_err();\n    assert_eq!(rv.kind(), ErrorKind::OutOfFuel);\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_overwrite_force() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_symlink_overwrite_force_a\";\n    let file_b = \"test_symlink_overwrite_force_b\";\n    let link = \"test_symlink_overwrite_force_link\";\n\n    // Create symlink\n    at.symlink_file(file_a, link);\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_a);\n\n    // Force overwrite of existing symlink\n    ucmd.args(&[\"--force\", \"-s\", file_b, link]).succeeds();\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_b);\n}"}
{"code": "pub fn can_enable(&self, feature: Feature) -> bool {\n        self.version.load(Ordering::Relaxed) >= feature.ver\n    }", "test": "fn test_cluster_version() {\n    let server = MockServer::<Service>::new(3);\n    let eps = server.bind_addrs();\n\n    let feature_a = Feature::require(0, 0, 1);\n    let feature_b = Feature::require(5, 0, 0);\n    let feature_c = Feature::require(5, 0, 1);\n\n    let mut client = new_client_v2(eps, None);\n    let feature_gate = client.feature_gate().clone();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    let mut client_clone = client.clone();\n    let mut emit_heartbeat = || {\n        let req = pdpb::StoreStats::default();\n        block_on(client_clone.store_heartbeat(req, /* store_report= */ None, None)).unwrap();\n    };\n\n    let set_cluster_version = |version: &str| {\n        let h = server.default_handler();\n        h.set_cluster_version(version.to_owned());\n    };\n\n    // Empty version string will be treated as invalid.\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Explicitly invalid version string.\n    set_cluster_version(\"invalid-version\");\n    emit_heartbeat();\n    assert!(!feature_gate.can_enable(feature_a));\n\n    // Correct version string.\n    set_cluster_version(\"5.0.0\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_a));\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can't go backwards.\n    set_cluster_version(\"4.99\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // After reconnect the version should be still accessable.\n    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.\n    thread::sleep(Duration::from_millis(200));\n    client.reconnect().unwrap();\n    assert!(feature_gate.can_enable(feature_b));\n    assert!(!feature_gate.can_enable(feature_c));\n\n    // Version can go forwards.\n    set_cluster_version(\"5.0.1\");\n    emit_heartbeat();\n    assert!(feature_gate.can_enable(feature_c));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_mode_failing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"target_dir\";\n    let file = \"source_file\";\n    let mode_arg = \"--mode=999\";\n\n    at.touch(file);\n    at.mkdir(dir);\n    ucmd.arg(file)\n        .arg(dir)\n        .arg(mode_arg)\n        .fails()\n        .stderr_contains(\"Invalid mode string: invalid digit found in string\");\n\n    let dest_file = &format!(\"{dir}/{file}\");\n    assert!(at.file_exists(file));\n    assert!(!at.file_exists(dest_file));\n}"}
{"code": "fn len(&mut self) -> io::Result<u64> {\n        match self.plaintext_len {\n            None => {\n                // Cache the current position and nonce, and then grab the start and end\n                // ciphertext positions.\n                let cur_pos = self.inner.seek(SeekFrom::Current(0))?;\n                let cur_nonce = self.stream.nonce.0;\n                let ct_start = self.start()?;\n                let ct_end = self.inner.seek(SeekFrom::End(0))?;\n                let ct_len = ct_end - ct_start;\n\n                // Use ceiling division to determine the number of chunks.\n                let num_chunks =\n                    (ct_len + (ENCRYPTED_CHUNK_SIZE as u64 - 1)) / ENCRYPTED_CHUNK_SIZE as u64;\n\n                // Authenticate the ciphertext length by checking that we can successfully\n                // decrypt the last chunk _as_ a last chunk.\n                let last_chunk_start = ct_start + ((num_chunks - 1) * ENCRYPTED_CHUNK_SIZE as u64);\n                let mut last_chunk = Vec::with_capacity((ct_end - last_chunk_start) as usize);\n                self.inner.seek(SeekFrom::Start(last_chunk_start))?;\n                self.inner.read_to_end(&mut last_chunk)?;\n                self.stream.nonce.set_counter(num_chunks - 1);\n                self.stream.decrypt_chunk(&last_chunk, true).map_err(|_| {\n                    io::Error::new(\n                        io::ErrorKind::InvalidData,\n                        \"Last chunk is invalid, stream might be truncated\",\n                    )\n                })?;\n\n                // Now that we have authenticated the ciphertext length, we can use it to\n                // calculate the plaintext length.\n                let total_tag_size = num_chunks * TAG_SIZE as u64;\n                let pt_len = ct_len - total_tag_size;\n\n                // Return to the original position and restore the nonce.\n                self.inner.seek(SeekFrom::Start(cur_pos))?;\n                self.stream.nonce = Nonce(cur_nonce);\n\n                // Cache the length for future calls.\n                self.plaintext_len = Some(pt_len);\n\n                Ok(pt_len)\n            }\n            Some(pt_len) => Ok(pt_len),\n        }\n    }", "test": "fn test_something() {\n    let data = [];\n    if let Ok((leftover, stanza)) = read::age_stanza(data) {\n        let mut buf = Vec::with_capacity(data.len());\n        gen(\n            write::age_stanza(stanza.tag, &stanza.args, &stanza.body()),\n            &mut buf,\n        )\n        .expect(\"can write to Vec\");\n        assert_eq!(buf, &data[0..data.len() - leftover.len()]);\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_existing_target() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_EXISTING_FILE)\n        .succeeds();\n\n    // Check the content of the destination file\n    assert_eq!(at.read(TEST_EXISTING_FILE), \"Hello, World!\\n\");\n\n    // No backup should have been created\n    assert!(!at.file_exists(format!(\"{TEST_EXISTING_FILE}~\")));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_numeric_suffix_alias() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"--numeric=9\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x10\"), \"b\");\n    assert_eq!(at.read(\"x11\"), \"c\");\n    assert_eq!(at.read(\"x12\"), \"\");\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_change_leader_async() {\n    let eps_count = 3;\n    let server = MockServer::with_case(eps_count, Arc::new(LeaderChange::new()));\n    let eps = server.bind_addrs();\n\n    let counter = Arc::new(AtomicUsize::new(0));\n    let client = new_client(eps, None);\n    let counter1 = Arc::clone(&counter);\n    client.handle_reconnect(move || {\n        counter1.fetch_add(1, Ordering::SeqCst);\n    });\n    let leader = client.get_leader();\n\n    for _ in 0..5 {\n        let region = block_on(client.get_region_by_id(1));\n        region.ok();\n\n        let new = client.get_leader();\n        if new != leader {\n            assert!(counter.load(Ordering::SeqCst) >= 1);\n            return;\n        }\n        thread::sleep(LeaderChange::get_leader_interval());\n    }\n\n    panic!(\"failed, leader should changed\");\n}"}
{"code": "pub fn metadata(&self, path: &str) -> fs::Metadata {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m,\n            Err(e) => panic!(\"{}\", e),\n        }\n    }", "test": "fn test_cp_parents_with_permissions_copy_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir1 = \"dir\";\n    let dir2 = \"p1/p2\";\n    let file = \"p1/p2/file\";\n\n    at.mkdir(dir1);\n    at.mkdir_all(dir2);\n    at.touch(file);\n\n    #[cfg(unix)]\n    {\n        let p1_mode = 0o0777;\n        let p2_mode = 0o0711;\n        let file_mode = 0o0702;\n\n        at.set_mode(\"p1\", p1_mode);\n        at.set_mode(\"p1/p2\", p2_mode);\n        at.set_mode(file, file_mode);\n    }\n\n    ucmd.arg(\"-p\")\n        .arg(\"--parents\")\n        .arg(\"-r\")\n        .arg(dir2)\n        .arg(dir1)\n        .succeeds();\n\n    #[cfg(all(unix, not(target_os = \"freebsd\")))]\n    {\n        let p1_metadata = at.metadata(\"p1\");\n        let p2_metadata = at.metadata(\"p1/p2\");\n        let file_metadata = at.metadata(file);\n\n        assert_metadata_eq!(p1_metadata, at.metadata(\"dir/p1\"));\n        assert_metadata_eq!(p2_metadata, at.metadata(\"dir/p1/p2\"));\n        assert_metadata_eq!(file_metadata, at.metadata(\"dir/p1/p2/file\"));\n    }\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_lookup_ipv4_like_fall_through() {\n    let authority = create_ip_like_example();\n    let mut catalog = Catalog::new();\n    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));\n\n    let io_loop = Runtime::new().unwrap();\n    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));\n    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());\n\n    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);\n    let (client, bg) = io_loop.block_on(client).expect(\"client connect failed\");\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    let lookup = LookupIpFuture::lookup(\n        vec![Name::from_str(\"198.51.100.35.example.com.\").unwrap()],\n        LookupIpStrategy::default(),\n        CachingClient::new(0, client, false),\n        Default::default(),\n        Some(Arc::new(Hosts::default())),\n        Some(RData::A(A::new(198, 51, 100, 35))),\n    );\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        lookup.iter().next().unwrap(),\n        Ipv4Addr::new(198, 51, 100, 35)\n    );\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_raftkv_precheck_write_with_ctx() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n\n    // make sure leader has been elected.\n    assert_eq!(cluster.must_get(b\"k1\"), None);\n\n    let region = cluster.get_region(b\"\");\n    let leader = cluster.leader_of_region(region.get_id()).unwrap();\n    let follower = region\n        .get_peers()\n        .iter()\n        .find(|p| p.get_id() != leader.get_id())\n        .unwrap();\n\n    let leader_storage = cluster.sim.rl().storages[&leader.get_id()].clone();\n    let follower_storage = cluster.sim.rl().storages[&follower.get_id()].clone();\n\n    // Assume this is a write request.\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(region.get_peers()[0].clone());\n\n    // The (write) request can be sent to the leader.\n    leader_storage.precheck_write_with_ctx(&ctx).unwrap();\n    // The (write) request should not be send to a follower.\n    follower_storage.precheck_write_with_ctx(&ctx).unwrap_err();\n\n    // Leader has network partition and it must be not leader any more.\n    let filter = Box::new(RegionPacketFilter::new(\n        region.get_id(),\n        leader.get_store_id(),\n    ));\n    cluster\n        .sim\n        .wl()\n        .add_recv_filter(leader.get_store_id(), filter.clone());\n    cluster\n        .sim\n        .wl()\n        .add_send_filter(leader.get_store_id(), filter);\n    sleep_until_election_triggered(&cluster.cfg);\n    leader_storage.precheck_write_with_ctx(&ctx).unwrap_err();\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_additional_suffix_hyphen_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_additional_suffix\";\n    RandomFile::new(&at, name).add_lines(2000);\n    ucmd.args(&[\"--additional-suffix\", \"-300\", name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]-300$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn encoded_len(&self, ident: TokenStream) -> TokenStream {\n        let tag = self.tag;\n        match self.label {\n            Label::Optional => quote! {\n                #ident.as_ref().map_or(0, |msg| ::prost::encoding::group::encoded_len(#tag, msg))\n            },\n            Label::Required => quote! {\n                ::prost::encoding::group::encoded_len(#tag, &#ident)\n            },\n            Label::Repeated => quote! {\n                ::prost::encoding::group::encoded_len_repeated(#tag, &#ident)\n            },\n        }\n    }", "test": "fn test() {\n    use crate::packages::gizmo;\n    use crate::packages::DoIt;\n    use prost::Message;\n\n    let mut widget_factory = widget::factory::WidgetFactory::default();\n    assert_eq!(0, widget_factory.encoded_len());\n\n    widget_factory.inner = Some(widget::factory::widget_factory::Inner {});\n    assert_eq!(2, widget_factory.encoded_len());\n\n    widget_factory.root = Some(Root {});\n    assert_eq!(4, widget_factory.encoded_len());\n\n    widget_factory.root_inner = Some(root::Inner {});\n    assert_eq!(6, widget_factory.encoded_len());\n\n    widget_factory.widget = Some(widget::Widget {});\n    assert_eq!(8, widget_factory.encoded_len());\n\n    widget_factory.widget_inner = Some(widget::widget::Inner {});\n    assert_eq!(10, widget_factory.encoded_len());\n\n    widget_factory.gizmo = Some(gizmo::Gizmo {});\n    assert_eq!(12, widget_factory.encoded_len());\n    widget_factory.gizmo.as_ref().map(DoIt::do_it);\n\n    widget_factory.gizmo_inner = Some(gizmo::gizmo::Inner {});\n    assert_eq!(14, widget_factory.encoded_len());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn formatting_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), UNFORMATTED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"formatting_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_mv_interactive_error() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let dir = \"test_mv_errors_dir\";\n    let file_a = \"test_mv_errors_file_a\";\n    at.mkdir(dir);\n    at.touch(file_a);\n\n    // $ at.mkdir dir && at.touch file\n    // $ mv -i dir file\n    // err == mv: cannot overwrite non-directory 'file' with directory 'dir'\n    assert!(!scene\n        .ucmd()\n        .arg(\"-i\")\n        .arg(dir)\n        .arg(file_a)\n        .pipe_in(\"y\")\n        .fails()\n        .stderr_str()\n        .is_empty());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.pkeys.len()\n    }", "test": "fn test_cname_loop() {\n    let runtime = Runtime::new().expect(\"failed to create Tokio Runtime\");\n    let mut auth = InMemoryAuthority::empty(\n        Name::from_str(\"example.com.\").unwrap(),\n        ZoneType::Primary,\n        false,\n    );\n\n    auth.upsert_mut(\n        Record::from_rdata(\n            Name::from_str(\"foo.example.com.\").unwrap(),\n            300,\n            RData::CNAME(CNAME(Name::from_str(\"foo.example.com.\").unwrap())),\n        ),\n        0,\n    );\n\n    auth.upsert_mut(\n        Record::from_rdata(\n            Name::from_str(\"bar.example.com.\").unwrap(),\n            300,\n            RData::CNAME(CNAME(Name::from_str(\"foo.example.com.\").unwrap())),\n        ),\n        0,\n    );\n\n    auth.upsert_mut(\n        Record::from_rdata(\n            Name::from_str(\"baz.example.com.\").unwrap(),\n            300,\n            RData::CNAME(CNAME(Name::from_str(\"boz.example.com.\").unwrap())),\n        ),\n        0,\n    );\n\n    auth.upsert_mut(\n        Record::from_rdata(\n            Name::from_str(\"boz.example.com.\").unwrap(),\n            300,\n            RData::CNAME(CNAME(Name::from_str(\"biz.example.com.\").unwrap())),\n        ),\n        0,\n    );\n\n    auth.upsert_mut(\n        Record::from_rdata(\n            Name::from_str(\"biz.example.com.\").unwrap(),\n            300,\n            RData::CNAME(CNAME(Name::from_str(\"baz.example.com.\").unwrap())),\n        ),\n        0,\n    );\n\n    let mut lookup = runtime\n        .block_on(auth.lookup(\n            &Name::from_str(\"foo.example.com.\").unwrap().into(),\n            RecordType::A,\n            Default::default(),\n        ))\n        .unwrap();\n\n    let records: Vec<&Record> = lookup.iter().collect();\n    assert_eq!(records.len(), 1);\n    let record = records[0];\n    assert_eq!(record.name(), &Name::from_str(\"foo.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"foo.example.com.\").unwrap()\n        )))\n    );\n\n    assert!(\n        lookup.take_additionals().is_none(),\n        \"Should be no additional records.\"\n    );\n\n    let mut lookup = runtime\n        .block_on(auth.lookup(\n            &Name::from_str(\"bar.example.com.\").unwrap().into(),\n            RecordType::A,\n            Default::default(),\n        ))\n        .unwrap();\n\n    let records: Vec<&Record> = lookup.iter().collect();\n    assert_eq!(records.len(), 1);\n    let record = records[0];\n    assert_eq!(record.name(), &Name::from_str(\"bar.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"foo.example.com.\").unwrap()\n        )))\n    );\n\n    let additionals = lookup\n        .take_additionals()\n        .expect(\"Should be additional records\");\n    let additionals: Vec<&Record> = additionals.iter().collect();\n    assert_eq!(additionals.len(), 1);\n    let record = additionals[0];\n    assert_eq!(record.name(), &Name::from_str(\"foo.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"foo.example.com.\").unwrap()\n        )))\n    );\n\n    let mut lookup = runtime\n        .block_on(auth.lookup(\n            &Name::from_str(\"baz.example.com.\").unwrap().into(),\n            RecordType::A,\n            Default::default(),\n        ))\n        .unwrap();\n\n    let records: Vec<&Record> = lookup.iter().collect();\n    assert_eq!(records.len(), 1);\n    let record = records[0];\n    assert_eq!(record.name(), &Name::from_str(\"baz.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"boz.example.com.\").unwrap()\n        )))\n    );\n\n    let additionals = lookup\n        .take_additionals()\n        .expect(\"Should be additional records\");\n    let additionals: Vec<&Record> = additionals.iter().collect();\n    assert_eq!(additionals.len(), 2);\n    let record = additionals[0];\n    assert_eq!(record.name(), &Name::from_str(\"boz.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"biz.example.com.\").unwrap()\n        )))\n    );\n    let record = additionals[1];\n    assert_eq!(record.name(), &Name::from_str(\"biz.example.com.\").unwrap());\n    assert_eq!(\n        record.data(),\n        Some(&RData::CNAME(CNAME(\n            Name::from_str(\"baz.example.com.\").unwrap()\n        )))\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_all() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file1 = \"test_mv_arg_update_none_file1\";\n    let file2 = \"test_mv_arg_update_none_file2\";\n    let file1_content = \"file1 content\\n\";\n    let file2_content = \"file2 content\\n\";\n\n    at.write(file1, file1_content);\n    at.write(file2, file2_content);\n\n    ucmd.arg(file1)\n        .arg(file2)\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(file2), file1_content);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_interactive_missing_value() {\n    // `--interactive` is equivalent to `--interactive=always` or `-i`\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file1 = \"test_rm_interactive_missing_value_file1\";\n    let file2 = \"test_rm_interactive_missing_value_file2\";\n\n    at.touch(file1);\n    at.touch(file2);\n\n    ucmd.arg(\"--interactive\")\n        .arg(file1)\n        .arg(file2)\n        .pipe_in(\"y\\ny\")\n        .succeeds();\n\n    assert!(!at.file_exists(file1));\n    assert!(!at.file_exists(file2));\n}"}
{"code": "fn to_string(lit: Literal) -> String {\n    let formatted = lit.to_string();\n\n    let mut it = formatted.chars();\n    assert_eq!(it.next(), Some('\"'));\n\n    let mut rv = String::new();\n    loop {\n        match it.next() {\n            Some('\"') => match it.next() {\n                Some(_) => panic!(),\n                None => break,\n            },\n            Some('\\\\') => match it.next() {\n                Some('x') => {\n                    let hi = it.next().unwrap().to_digit(16).unwrap();\n                    let lo = it.next().unwrap().to_digit(16).unwrap();\n                    let v = (hi << 16) | lo;\n                    rv.push(v as u8 as char);\n                }\n                Some('u') => {\n                    assert_eq!(it.next(), Some('{'));\n                    let mut c = it.next().unwrap();\n                    let mut ch = 0;\n                    while let Some(v) = c.to_digit(16) {\n                        ch *= 16;\n                        ch |= v;\n                        c = it.next().unwrap();\n                    }\n                    assert_eq!(c, '}');\n                    rv.push(::std::char::from_u32(ch).unwrap());\n                }\n                Some('0') => rv.push('\\0'),\n                Some('\\\\') => rv.push('\\\\'),\n                Some('\\\"') => rv.push('\\\"'),\n                Some('r') => rv.push('\\r'),\n                Some('n') => rv.push('\\n'),\n                Some('t') => rv.push('\\t'),\n                Some(_) => panic!(),\n                None => panic!(),\n            },\n            Some(c) => rv.push(c),\n            None => panic!(),\n        }\n    }\n\n    rv\n}", "test": "fn mismatch_resource_types() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (type $t' (resource (rep i32)))\n                (type $u' (resource (rep i32)))\n\n                (export $t \"t\" (type $t'))\n                (export $u \"u\" (type $u'))\n\n                (core func $t_ctor (canon resource.new $t))\n                (func (export \"ctor\") (param \"x\" u32) (result (own $t))\n                    (canon lift (core func $t_ctor)))\n\n                (core func $u_dtor (canon resource.drop $u))\n                (func (export \"dtor\") (param \"x\" (own $u))\n                    (canon lift (core func $u_dtor)))\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let i = Linker::new(&engine).instantiate(&mut store, &c)?;\n    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, \"ctor\")?;\n    let dtor = i.get_typed_func::<(ResourceAny,), ()>(&mut store, \"dtor\")?;\n\n    let (t,) = ctor.call(&mut store, (100,))?;\n    ctor.post_return(&mut store)?;\n    assert_eq!(\n        dtor.call(&mut store, (t,)).unwrap_err().to_string(),\n        \"mismatched resource types\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.root.is_none()\n    }", "test": "fn standalone_backtrace() -> Result<()> {\n    let engine = Engine::default();\n    let mut store = Store::new(&engine, ());\n    let trace = WasmBacktrace::capture(&store);\n    assert!(trace.frames().is_empty());\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (import \"\" \"\" (func $host))\n                (func $foo (export \"f\") call $bar)\n                (func $bar call $host)\n            )\n        \"#,\n    )?;\n    let func = Func::wrap(&mut store, |cx: Caller<'_, ()>| {\n        let trace = WasmBacktrace::capture(&cx);\n        assert_eq!(trace.frames().len(), 2);\n        let frame1 = &trace.frames()[0];\n        let frame2 = &trace.frames()[1];\n        assert_eq!(frame1.func_index(), 2);\n        assert_eq!(frame1.func_name(), Some(\"bar\"));\n        assert_eq!(frame2.func_index(), 1);\n        assert_eq!(frame2.func_name(), Some(\"foo\"));\n    });\n    let instance = Instance::new(&mut store, &module, &[func.into()])?;\n    let f = instance.get_typed_func::<(), ()>(&mut store, \"f\")?;\n    f.call(&mut store, ())?;\n    Ok(())\n}"}
{"code": "fn size(x: u32) -> TextSize {\n    TextSize::from(x)\n}", "test": "fn math() {\n    assert_eq!(size(10) + size(5), size(15));\n    assert_eq!(size(10) - size(5), size(5));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_multiple_name_value_pairs() {\n    let out = new_ucmd!().arg(\"FOO=bar\").arg(\"ABC=xyz\").run();\n\n    assert_eq!(\n        out.stdout_str()\n            .lines()\n            .filter(|&line| line == \"FOO=bar\" || line == \"ABC=xyz\")\n            .count(),\n        2\n    );\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_by_rdata() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = client\n        .delete_by_rdata(record.clone(), origin.clone())\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let result = client\n        .append(record.clone(), origin.clone(), true)\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = client\n        .delete_by_rdata(record.clone(), origin)\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {\n            *ip == A::new(100, 10, 100, 10)\n        } else {\n            false\n        }));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_does_not_run_linter() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(\n        PathBuf::from(\"biome.json\"),\n        CONFIG_LINTER_DISABLED.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, CUSTOM_FORMAT_BEFORE);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_does_not_run_linter\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn must_raw_get(&self, k: Vec<u8>, cf: String) -> Vec<u8> {\n        let mut request = RawGetRequest::default();\n        let mut context = self.context.clone();\n        if context.api_version == ApiVersion::V1ttl {\n            context.api_version = ApiVersion::V1;\n        }\n        request.set_context(context);\n        request.set_key(k);\n        request.set_cf(cf);\n        let mut response = self.tikv_cli.raw_get(&request).unwrap();\n        retry_req!(\n            self.tikv_cli.raw_get(&request).unwrap(),\n            !response.has_region_error() && response.error.is_empty(),\n            response,\n            10,   // retry 10 times\n            1000  // 1s timeout\n        );\n        assert!(response.error.is_empty(), \"{:?}\", response.get_error());\n        response.take_value()\n    }", "test": "fn test_leader_transfer() {\n    let mut suite = TestSuite::new(3, ApiVersion::V2);\n    let key1 = b\"rk1\";\n    let region = suite.cluster.get_region(key1);\n\n    // Transfer leader and write to store 1.\n    {\n        suite.must_transfer_leader(&region, 1);\n        let leader1 = suite.must_leader_on_store(key1, 1);\n\n        suite.must_raw_put(key1, b\"v1\");\n        suite.must_raw_put(key1, b\"v2\");\n        suite.must_raw_put(key1, b\"v3\");\n        suite.flush_timestamp(leader1.get_store_id()); // Flush to make ts bigger than other stores.\n        suite.must_raw_put(key1, b\"v4\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n    }\n\n    // Make causal_ts_provider.async_flush() & handle_update_max_timestamp fail.\n    fail::cfg(FP_GET_TSO, \"return(50)\").unwrap();\n\n    // Transfer leader and write to store 2.\n    {\n        suite.must_transfer_leader(&region, 2);\n        suite.must_leader_on_store(key1, 2);\n\n        // Store 2 has a TSO batch smaller than store 1.\n        suite.raw_put_err_by_timestamp_not_synced(key1, b\"v5\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n        suite.raw_put_err_by_timestamp_not_synced(key1, b\"v6\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v4\".to_vec()));\n    }\n\n    // Transfer leader back.\n    suite.must_transfer_leader(&region, 1);\n    suite.must_leader_on_store(key1, 1);\n    // Make handle_update_max_timestamp succeed.\n    fail::cfg(FP_GET_TSO, \"off\").unwrap();\n    // Transfer leader and write to store 2 again.\n    {\n        suite.must_transfer_leader(&region, 2);\n        suite.must_leader_on_store(key1, 2);\n\n        suite.must_raw_put(key1, b\"v7\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v7\".to_vec()));\n        suite.must_raw_put(key1, b\"v8\");\n        assert_eq!(suite.must_raw_get(key1), Some(b\"v8\".to_vec()));\n    }\n\n    fail::remove(FP_GET_TSO);\n    suite.stop();\n}"}
{"code": "pub fn i32(val: i32) -> Self {\n        Self::I32(val as u32)\n    }", "test": "fn smoke() -> anyhow::Result<()> {\n    let mut store = Store::<()>::default();\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::I32, Mutability::Const),\n        0.into(),\n    )?;\n    assert_eq!(g.get(&mut store).i32(), Some(0));\n    assert!(g.set(&mut store, 0.into()).is_err());\n\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::I32, Mutability::Const),\n        1i32.into(),\n    )?;\n    assert_eq!(g.get(&mut store).i32(), Some(1));\n\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::I64, Mutability::Const),\n        2i64.into(),\n    )?;\n    assert_eq!(g.get(&mut store).i64(), Some(2));\n\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::F32, Mutability::Const),\n        3.0f32.into(),\n    )?;\n    assert_eq!(g.get(&mut store).f32(), Some(3.0));\n\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::F64, Mutability::Const),\n        4.0f64.into(),\n    )?;\n    assert_eq!(g.get(&mut store).f64(), Some(4.0));\n    Ok(())\n}"}
{"code": "pub fn compare(x: &[Limb], y: &[Limb]) -> cmp::Ordering {\n        if x.len() > y.len() {\n            cmp::Ordering::Greater\n        } else if x.len() < y.len() {\n            cmp::Ordering::Less\n        } else {\n            let iter = x.iter().rev().zip(y.iter().rev());\n            for (&xi, &yi) in iter {\n                if xi > yi {\n                    return cmp::Ordering::Greater;\n                } else if xi < yi {\n                    return cmp::Ordering::Less;\n                }\n            }\n            // Equal case.\n            cmp::Ordering::Equal\n        }\n    }", "test": "fn compare_test() {\n    // Simple\n    let x = Bigint {\n        data: from_u32(&[1]),\n    };\n    let y = Bigint {\n        data: from_u32(&[2]),\n    };\n    assert_eq!(x.compare(&y), cmp::Ordering::Less);\n    assert_eq!(x.compare(&x), cmp::Ordering::Equal);\n    assert_eq!(y.compare(&x), cmp::Ordering::Greater);\n\n    // Check asymmetric\n    let x = Bigint {\n        data: from_u32(&[5, 1]),\n    };\n    let y = Bigint {\n        data: from_u32(&[2]),\n    };\n    assert_eq!(x.compare(&y), cmp::Ordering::Greater);\n    assert_eq!(x.compare(&x), cmp::Ordering::Equal);\n    assert_eq!(y.compare(&x), cmp::Ordering::Less);\n\n    // Check when we use reverse ordering properly.\n    let x = Bigint {\n        data: from_u32(&[5, 1, 9]),\n    };\n    let y = Bigint {\n        data: from_u32(&[6, 2, 8]),\n    };\n    assert_eq!(x.compare(&y), cmp::Ordering::Greater);\n    assert_eq!(x.compare(&x), cmp::Ordering::Equal);\n    assert_eq!(y.compare(&x), cmp::Ordering::Less);\n\n    // Complex scenario, check it properly uses reverse ordering.\n    let x = Bigint {\n        data: from_u32(&[0, 1, 9]),\n    };\n    let y = Bigint {\n        data: from_u32(&[4294967295, 0, 9]),\n    };\n    assert_eq!(x.compare(&y), cmp::Ordering::Greater);\n    assert_eq!(x.compare(&x), cmp::Ordering::Equal);\n    assert_eq!(y.compare(&x), cmp::Ordering::Less);\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn leaves_necessary_whitespace_alone_weird() {\n    assert_eq!(\n        \"<u>a </u>b <u>c</u>\",\n        normalize_html(\" <u>a </u>b <u>c</u>\")\n    )\n}"}
{"code": "pub fn b<F: RawFloat>(float: F) -> ExtendedFloat80 {\n    ExtendedFloat80 {\n        mant: float.mantissa().as_u64(),\n        exp: float.exponent(),\n    }\n}", "test": "fn b_test() {\n    assert_eq!(b(1e-45_f32), (1, -149));\n    assert_eq!(b(5e-324_f64), (1, -1074));\n    assert_eq!(b(1e-323_f64), (2, -1074));\n    assert_eq!(b(2e-323_f64), (4, -1074));\n    assert_eq!(b(3e-323_f64), (6, -1074));\n    assert_eq!(b(4e-323_f64), (8, -1074));\n    assert_eq!(b(5e-323_f64), (10, -1074));\n    assert_eq!(b(6e-323_f64), (12, -1074));\n    assert_eq!(b(7e-323_f64), (14, -1074));\n    assert_eq!(b(8e-323_f64), (16, -1074));\n    assert_eq!(b(9e-323_f64), (18, -1074));\n    assert_eq!(b(1_f32), (8388608, -23));\n    assert_eq!(b(1_f64), (4503599627370496, -52));\n    assert_eq!(b(1e38_f32), (9860761, 103));\n    assert_eq!(b(1e308_f64), (5010420900022432, 971));\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_create() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n    let record = record;\n\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    let result = io_loop\n        .block_on(client.query(\n            record.name().clone(),\n            record.dns_class(),\n            record.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert_eq!(result.answers()[0], record);\n\n    // trying to create again should error\n    // TODO: it would be cool to make this\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n\n    // will fail if already set and not the same value.\n    let mut record = record;\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n\n    let result = io_loop\n        .block_on(client.create(record, origin))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn quote_properties_parse_errors_letter_case() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                (\"--quote-properties\"),\n                (\"As-needed\"),\n                (\"file.js\"),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"quote_properties_parse_errors_letter_case\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn client_close_notify() {\n    let kt = KeyType::Rsa;\n    let server_config = Arc::new(make_server_config_with_mandatory_client_auth(kt));\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions_with_auth(kt, &[version]);\n        let (mut client, mut server) =\n            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n        do_handshake(&mut client, &mut server);\n\n        // check that alerts don't overtake appdata\n        assert_eq!(\n            12,\n            server\n                .writer()\n                .write(b\"from-server!\")\n                .unwrap()\n        );\n        assert_eq!(\n            12,\n            client\n                .writer()\n                .write(b\"from-client!\")\n                .unwrap()\n        );\n        client.send_close_notify();\n\n        transfer(&mut client, &mut server);\n        let io_state = server.process_new_packets().unwrap();\n        assert!(io_state.peer_has_closed());\n        check_read_and_close(&mut server.reader(), b\"from-client!\");\n\n        transfer(&mut server, &mut client);\n        client.process_new_packets().unwrap();\n        check_read(&mut client.reader(), b\"from-server!\");\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn downgrade_severity() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(\n        file_path.into(),\n        CONFIG_LINTER_DOWNGRADE_DIAGNOSTIC.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), NO_DEBUGGER.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    assert_eq!(\n        messages\n            .iter()\n            .filter(|m| m.level == LogLevel::Error)\n            .filter(|m| {\n                let content = format!(\"{:#?}\", m.content);\n                content.contains(\"suspicious/noDebugger\")\n            })\n            .count(),\n        1\n    );\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"downgrade_severity\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_itc() {\n    // Test iterators that skip multiple, internal or trailing digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"_455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"__455\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"__45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"__45.56\");\n}"}
{"code": "pub fn compute_float64(q: i64, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        is_negative: false,\n        many_digits: false,\n        integer: &[],\n        fraction: None,\n    };\n    let fp = bellerophon::<f64, { STANDARD }>(&num, false);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f64_test() {\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740993), (1065 + INVALID_FP, 9223372036854776832));\n    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));\n    assert_eq!(compute_float64(0, 9007199254740995), (1065 + INVALID_FP, 9223372036854778880));\n    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));\n    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));\n    assert_eq!(compute_float64(0, 18014398509481986), (1066 + INVALID_FP, 9223372036854776832));\n    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));\n    assert_eq!(compute_float64(0, 18014398509481990), (1066 + INVALID_FP, 9223372036854778880));\n    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));\n    assert_eq!(compute_float64(-3, 9007199254740993000), (1065 + INVALID_FP, 9223372036854776832));\n    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));\n    assert_eq!(compute_float64(-3, 9007199254740995000), (1065 + INVALID_FP, 9223372036854778879));\n    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_it() {\n    // Test iterators that skip single, internal or trailing-only digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_trailing_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\"_.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"_455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"__45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\"_.45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4_5_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"__45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"__45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"__4_5_\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"__4_5_.56\");\n}"}
{"code": "pub fn is_safe(&self) -> bool {\n        matches!(&self.0, ValueRepr::String(_, StringType::Safe))\n    }", "test": "fn test_safe_string_roundtrip() {\n    let v = Value::from_safe_string(\"<b>HTML</b>\".into());\n    let v2 = Value::from_serializable(&v);\n    assert!(v.is_safe());\n    assert!(v2.is_safe());\n    assert_eq!(v.to_string(), v2.to_string());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_line_bytes_no_eof() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-C\", \"3\"])\n        .pipe_in(\"1\\n2222\\n3\\n4\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n\");\n    assert_eq!(at.read(\"xab\"), \"222\");\n    assert_eq!(at.read(\"xac\"), \"2\\n\");\n    assert_eq!(at.read(\"xad\"), \"3\\n\");\n    assert_eq!(at.read(\"xae\"), \"4\");\n    assert!(!at.plus(\"xaf\").exists());\n}"}
{"code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_number_new_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-s\")\n        .arg(\"9\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(9));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn client_stateless_reset() {\n    let _guard = subscribe();\n    let mut reset_key = vec![0; 64];\n    let mut rng = rand::thread_rng();\n    rng.fill_bytes(&mut reset_key);\n    let reset_key = hmac::Key::new(hmac::HMAC_SHA256, &reset_key);\n\n    let endpoint_config = Arc::new(EndpointConfig::new(Arc::new(reset_key)));\n\n    let mut pair = Pair::new(endpoint_config.clone(), server_config());\n    let (_, server_ch) = pair.connect();\n    pair.client.endpoint = Endpoint::new(endpoint_config, Some(Arc::new(server_config())), true);\n    // Send something big enough to allow room for a smaller stateless reset.\n    pair.server.connections.get_mut(&server_ch).unwrap().close(\n        pair.time,\n        VarInt(42),\n        (&[0xab; 128][..]).into(),\n    );\n    info!(\"resetting\");\n    pair.drive();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::Reset\n        })\n    );\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn default_filter_works() {\n    let mut context = Context::new();\n    let i: Option<usize> = None;\n    context.insert(\"existing\", \"hello\");\n    context.insert(\"null\", &i);\n\n    let inputs = vec![\n        (r#\"{{ existing | default(value=\"hey\") }}\"#, \"hello\"),\n        (r#\"{{ val | default(value=1) }}\"#, \"1\"),\n        (r#\"{{ val | default(value=\"hey\") | capitalize }}\"#, \"Hey\"),\n        (r#\"{{ obj.val | default(value=\"hey\") | capitalize }}\"#, \"Hey\"),\n        (r#\"{{ obj.val | default(value=\"hey\") | capitalize }}\"#, \"Hey\"),\n        (r#\"{{ not admin | default(value=false) }}\"#, \"true\"),\n        (r#\"{{ not admin | default(value=true) }}\"#, \"false\"),\n        (r#\"{{ null | default(value=true) }}\"#, \"true\"),\n        (r#\"{{ null | default(value=\"hey\") | capitalize }}\"#, \"Hey\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn is_extended_connect_protocol_enabled(&self) -> Option<bool> {\n        self.enable_connect_protocol.map(|val| val != 0)\n    }", "test": "async fn extended_connect_protocol_disabled_by_default() {\n    h2_support::trace_init!();\n\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        let settings = client.assert_server_handshake().await;\n\n        assert_eq!(settings.is_extended_connect_protocol_enabled(), None);\n\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"CONNECT\", \"http://bread/baguette\")\n                    .protocol(\"the-bread-protocol\"),\n            )\n            .await;\n\n        client.recv_frame(frames::reset(1).protocol_error()).await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n\n        poll_fn(move |cx| srv.poll_closed(cx))\n            .await\n            .expect(\"server\");\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_inexact() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n    db.engine.put(b\"g\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"f\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"f\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"g\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n    db.engine.put(b\"g\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    for i in (0..256_usize).step_by(2) {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n\n    wb.delete_range(b\"b\", b\"f\").unwrap();\n    wb.delete_range(&0_usize.to_be_bytes(), &252_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"f\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"g\").unwrap().is_some());\n    for i in 0..252_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n    assert!(\n        db.engine\n            .get_value(&252_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(\n        db.engine\n            .get_value(&253_usize.to_be_bytes())\n            .unwrap()\n            .is_none()\n    );\n    assert!(\n        db.engine\n            .get_value(&254_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_tc() {\n    // Test iterators that skip multiple, trailing digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_trailing_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"_45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"__45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".45_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".45__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"4_5.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"4__5.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"_45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"__45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"_45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"__45.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"_4_5\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"__4__5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"_4_5.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"__4__5.56\");\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_semicolon_number_l() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--number=l/3\", \"--separator=;\", \"separator_semicolon.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1;2;\");\n    assert_eq!(file_read(&at, \"xab\"), \"3;4;\");\n    assert_eq!(file_read(&at, \"xac\"), \"5;\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn mismatched_arguments() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let binary = wat::parse_str(\n        r#\"\n            (module $a\n                (func (export \"foo\") (param i32))\n            )\n        \"#,\n    )?;\n\n    let module = Module::new(store.engine(), &binary)?;\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let func = instance.get_func(&mut store, \"foo\").unwrap();\n    assert_eq!(\n        func.call(&mut store, &[], &mut []).unwrap_err().to_string(),\n        \"expected 1 arguments, got 0\"\n    );\n    assert_eq!(\n        func.call(&mut store, &[Val::F32(0)], &mut [])\n            .unwrap_err()\n            .to_string(),\n        \"argument type mismatch: found f32 but expected i32\",\n    );\n    assert_eq!(\n        func.call(&mut store, &[Val::I32(0), Val::I32(1)], &mut [])\n            .unwrap_err()\n            .to_string(),\n        \"expected 1 arguments, got 2\"\n    );\n    Ok(())\n}"}
{"code": "pub fn capacity(&self) -> usize {\n        self.inner.capacity() as usize\n    }", "test": "async fn stream_close_by_data_frame_releases_capacity() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let window_size = frame::DEFAULT_INITIAL_WINDOW_SIZE as usize;\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Send request\n        let (resp1, mut s1) = client.send_request(request, false).unwrap();\n\n        // This effectively reserves the entire connection window\n        s1.reserve_capacity(window_size);\n\n        // The capacity should be immediately available as nothing else is\n        // happening on the stream.\n        assert_eq!(s1.capacity(), window_size);\n\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        // Create a second stream\n        let (resp2, mut s2) = client.send_request(request, false).unwrap();\n\n        // Request capacity\n        s2.reserve_capacity(5);\n\n        // There should be no available capacity (as it is being held up by\n        // the previous stream\n        assert_eq!(s2.capacity(), 0);\n\n        // Closing the previous stream by sending an empty data frame will\n        // release the capacity to s2\n        s1.send_data(\"\".into(), true).unwrap();\n\n        // The capacity should be available\n        assert_eq!(s2.capacity(), 5);\n\n        // Send the frame\n        s2.send_data(\"hello\".into(), true).unwrap();\n\n        // Drive both streams to prevent the handles from being dropped\n        // (which will send a RST_STREAM) before the connection is closed.\n        h2.drive(resp1).await.unwrap();\n        h2.drive(resp2).await.unwrap();\n    };\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_default_settings!(settings);\n        srv.recv_frame(frames::headers(1).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.recv_frame(frames::headers(3).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(3).response(200)).await;\n        srv.recv_frame(frames::data(1, &b\"\"[..]).eos()).await;\n        srv.recv_frame(frames::data(3, &b\"hello\"[..]).eos()).await;\n    };\n    join(srv, h2).await;\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_bytes_big() {\n    const FILE: &str = \"test_bytes_big.txt\";\n    const EXPECTED_FILE: &str = \"test_bytes_big_expected.txt\";\n    const BYTES: usize = 1_000_000;\n    const N_ARG: usize = 100_000;\n\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let mut big_input = at.make_file(FILE);\n    for i in 0..BYTES {\n        let digit = from_digit((i % 10) as u32, 10).unwrap();\n        write!(big_input, \"{digit}\").expect(\"Could not write to FILE\");\n    }\n    big_input.flush().expect(\"Could not flush FILE\");\n\n    let mut big_expected = at.make_file(EXPECTED_FILE);\n    for i in (BYTES - N_ARG)..BYTES {\n        let digit = from_digit((i % 10) as u32, 10).unwrap();\n        write!(big_expected, \"{digit}\").expect(\"Could not write to EXPECTED_FILE\");\n    }\n    big_expected.flush().expect(\"Could not flush EXPECTED_FILE\");\n\n    let result = ucmd\n        .arg(FILE)\n        .arg(\"-c\")\n        .arg(format!(\"{N_ARG}\"))\n        .succeeds()\n        .stdout_move_str();\n    let expected = at.read(EXPECTED_FILE);\n\n    assert_eq!(result.len(), expected.len());\n    for (actual_char, expected_char) in result.chars().zip(expected.chars()) {\n        assert_eq!(actual_char, expected_char);\n    }\n}"}
{"code": "pub fn alive_cnt(&self) -> usize {\n        self.normals.len()\n    }", "test": "fn test_router_trace() {\n    let (control_tx, control_fsm) = Runner::new(10);\n    let (router, mut system) =\n        batch_system::create_system(&Config::default(), control_tx, control_fsm, None);\n    let builder = Builder::new();\n    system.spawn(\"test\".to_owned(), builder);\n\n    let register_runner = |addr| {\n        let (sender, runner) = Runner::new(10);\n        let mailbox = BasicMailbox::new(sender, runner, router.state_cnt().clone());\n        router.register(addr, mailbox);\n    };\n    let close_runner = |addr| {\n        router.close(addr);\n    };\n\n    let mut mailboxes = vec![];\n    for i in 0..10 {\n        register_runner(i);\n        mailboxes.push(router.mailbox(i).unwrap());\n    }\n    assert_eq!(router.alive_cnt(), 10);\n    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 11);\n    for i in 0..10 {\n        close_runner(i);\n    }\n    assert_eq!(router.alive_cnt(), 0);\n    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 11);\n    drop(mailboxes);\n    assert_eq!(router.alive_cnt(), 0);\n    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 1);\n}"}
{"code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn test_struct_names() {\n    let value = Point { x: 1.0, y: 2.0 };\n    let struct_name = to_string_pretty(&value, PrettyConfig::default().struct_names(true));\n    assert_eq!(\n        struct_name,\n        Ok(\"Point(\\n    x: 1.0,\\n    y: 2.0,\\n)\".to_string())\n    );\n    let no_struct_name = to_string(&value);\n    assert_eq!(no_struct_name, Ok(\"(x:1.0,y:2.0)\".to_string()));\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_ascii_5_gibi_to_file() {\n    let tname = \"ascii-5G\";\n    let tmp_fn = format!(\"TESTFILE-{}.tmp\", &tname);\n\n    let (fix, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\n        \"status=none\",\n        \"count=5G\",\n        \"iflag=count_bytes\",\n        \"if=/dev/zero\",\n        of!(tmp_fn),\n    ])\n    .run()\n    .no_stderr()\n    .no_stdout()\n    .success();\n\n    assert_eq!(5 * 1024 * 1024 * 1024, fix.metadata(&tmp_fn).len());\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_format_created_seconds() {\n    let args = [\"-c\", \"%W\", \"/bin\"];\n    let ts = TestScenario::new(util_name!());\n    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();\n    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    // note: using a regex instead of `split_whitespace()` in order to detect whitespace differences\n    let re = regex::Regex::new(r\"\\s\").unwrap();\n    let v_actual: Vec<&str> = re.split(&actual).collect();\n    let v_expect: Vec<&str> = re.split(&expect).collect();\n    assert!(!v_expect.is_empty());\n    // * allow for inequality if `stat` (aka, expect) returns \"0\" (unknown value)\n    assert!(\n        expect == \"0\"\n            || expect == \"0\\n\"\n            || v_actual\n                .iter()\n                .zip(v_expect.iter())\n                .all(|(a, e)| a == e || *e == \"0\" || *e == \"0\\n\")\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn trailing_comma_parse_errors() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"--trailing-comma\"), (\"NONE\"), (\"file.js\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"trailing_comma_parse_errors\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn draft_version_compat() {\n    let _guard = subscribe();\n\n    let mut client_config = client_config();\n    client_config.version(0xff00_0020);\n\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect_with(client_config);\n\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert!(pair.client_conn_mut(client_ch).using_ecn());\n    assert!(pair.server_conn_mut(server_ch).using_ecn());\n\n    const REASON: &[u8] = b\"whee\";\n    info!(\"closing\");\n    pair.client.connections.get_mut(&client_ch).unwrap().close(\n        pair.time,\n        VarInt(42),\n        REASON.into(),\n    );\n    pair.drive();\n    assert_matches!(pair.server_conn_mut(server_ch).poll(),\n                    Some(Event::ConnectionLost { reason: ConnectionError::ApplicationClosed(\n                        ApplicationClose { error_code: VarInt(42), ref reason }\n                    )}) if reason == REASON);\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_eq!(pair.client.known_connections(), 0);\n    assert_eq!(pair.client.known_cids(), 0);\n    assert_eq!(pair.server.known_connections(), 0);\n    assert_eq!(pair.server.known_cids(), 0);\n}"}
{"code": "fn into_owned(self) -> PayloadEvent<'static> {\n        match self {\n            PayloadEvent::Start(e) => PayloadEvent::Start(e.into_owned()),\n            PayloadEvent::End(e) => PayloadEvent::End(e.into_owned()),\n            PayloadEvent::Text(e) => PayloadEvent::Text(e.into_owned()),\n            PayloadEvent::CData(e) => PayloadEvent::CData(e.into_owned()),\n            PayloadEvent::DocType(e) => PayloadEvent::DocType(e.into_owned()),\n            PayloadEvent::Eof => PayloadEvent::Eof,\n        }\n    }", "test": "fn issue115() {\n    let mut r = Reader::from_str(\"<tag1 attr1='line 1\\nline 2'></tag1>\");\n    match r.read_event() {\n        Ok(Event::Start(e)) if e.name() == QName(b\"tag1\") => {\n            let v = e.attributes().map(|a| a.unwrap().value).collect::<Vec<_>>();\n            assert_eq!(v[0].clone().into_owned(), b\"line 1\\nline 2\");\n        }\n        _ => (),\n    }\n}"}
{"code": "fn partial_cmp(&self, other: &Self) -> Option<Ordering> {\n        self.as_f32().partial_cmp(&other.as_f32())\n    }", "test": "fn cmp_test() {\n    // Simple\n    let x = VecType::from_u32(1);\n    let y = VecType::from_u32(2);\n    assert_eq!(x.partial_cmp(&x), Some(cmp::Ordering::Equal));\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Less);\n\n    // Check asymmetric\n    let x = VecType::try_from(&[5, 1]).unwrap();\n    let y = VecType::from_u32(2);\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n\n    // Check when we use reverse ordering properly.\n    let x = VecType::try_from(&[5, 1, 9]).unwrap();\n    let y = VecType::try_from(&[6, 2, 8]).unwrap();\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n\n    // Complex scenario, check it properly uses reverse ordering.\n    let x = VecType::try_from(&[0, 1, 9]).unwrap();\n    let y = VecType::try_from(&[4294967295, 0, 9]).unwrap();\n    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);\n    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.entries.len()\n    }", "test": "fn test_transfer_leader_delay() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    let messages = Arc::new(Mutex::new(vec![]));\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 3)\n            .direction(Direction::Send)\n            .msg_type(MessageType::MsgTransferLeader)\n            .reserve_dropped(messages.clone()),\n    ));\n\n    cluster.transfer_leader(1, new_peer(3, 3));\n    let timer = Instant::now();\n    while timer.saturating_elapsed() < Duration::from_secs(3) && messages.lock().unwrap().is_empty()\n    {\n        thread::sleep(Duration::from_millis(10));\n    }\n    assert_eq!(messages.lock().unwrap().len(), 1);\n\n    // Wait till leader peer goes to sleep again.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 2\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n\n    cluster.clear_send_filters();\n    cluster.add_send_filter(CloneFilterFactory(DropMessageFilter::new(Arc::new(|m| {\n        m.get_message().get_msg_type() != MessageType::MsgTimeoutNow\n    }))));\n    let router = cluster.sim.wl().get_router(1).unwrap();\n    router\n        .send_raft_message(messages.lock().unwrap().pop().unwrap())\n        .unwrap();\n\n    let timer = Instant::now();\n    while timer.saturating_elapsed() < Duration::from_secs(3) {\n        let resp = cluster.request(\n            b\"k2\",\n            vec![new_put_cmd(b\"k2\", b\"v2\")],\n            false,\n            Duration::from_secs(5),\n        );\n        let header = resp.get_header();\n        if !header.has_error() {\n            return;\n        }\n        if !header\n            .get_error()\n            .get_message()\n            .contains(\"proposal dropped\")\n        {\n            panic!(\"response {:?} has error\", resp);\n        }\n        thread::sleep(Duration::from_millis(10));\n    }\n    panic!(\"failed to request after 3 seconds\");\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_all() {\n    use hickory_proto::rr::rdata::AAAA;\n\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = client\n        .delete_all(record.name().clone(), origin.clone(), DNSClass::IN)\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_rr_type(RecordType::AAAA);\n    record.set_data(Some(RData::AAAA(AAAA::new(1, 2, 3, 4, 5, 6, 7, 8))));\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = client\n        .delete_all(record.name().clone(), origin, DNSClass::IN)\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), RecordType::A)\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n\n    let result = client\n        .query(record.name(), record.dns_class(), RecordType::AAAA)\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_custom_suffix_via_env() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_custom_suffix_file_a\";\n    let file_b = \"test_install_backup_custom_suffix_file_b\";\n    let suffix = \"super-suffix-of-the-century\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"-b\")\n        .env(\"SIMPLE_BACKUP_SUFFIX\", suffix)\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}{suffix}\")));\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_guard_input() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n\")\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n\n    ts.ucmd()\n        .args(&[\"-C\", \"6\", \"xaa\"])\n        .fails()\n        .stderr_only(\"split: 'xaa' would overwrite input; aborting\\n\");\n    assert_eq!(at.read(\"xaa\"), \"1\\n2\\n3\\n\");\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_rrset() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = client\n        .delete_rrset(record.clone(), origin.clone())\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let result = client\n        .append(record.clone(), origin.clone(), true)\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = client\n        .delete_rrset(record.clone(), origin)\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n}"}
{"code": "pub fn log10_pow2(e: i32) -> u32 /* or u32 -> u32 */ {\n    // The first value this approximation fails for is 2^1651 which is just greater than 10^297.\n    debug_assert!(e >= 0);\n    debug_assert!(e <= 1650);\n    (e as u32 * 78913) >> 18\n}", "test": "fn test_log10_pow2() {\n    assert_eq!(0, log10_pow2(0));\n    assert_eq!(0, log10_pow2(1));\n    assert_eq!(0, log10_pow2(2));\n    assert_eq!(0, log10_pow2(3));\n    assert_eq!(1, log10_pow2(4));\n    assert_eq!(496, log10_pow2(1650));\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_storage_error() {\n    let data = vec![(1, Some(\"name:0\"), 2), (2, Some(\"name:4\"), 3)];\n\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &data);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"kv_cursor_seek\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"kv cursor seek error\"));\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit_with_saved_fprs() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit_with_saved_fprs.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    assert_eq!(output.status.code().unwrap(), 0);\n    assert!(output.stdout.is_empty());\n    Ok(())\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_relative_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let dir = \"test_symlink_existing_dir\";\n    let link = \"test_symlink_existing_dir_link\";\n\n    at.mkdir(dir);\n\n    ucmd.args(&[\"-s\", \"-r\", dir, link]).succeeds().no_stderr();\n    assert!(at.dir_exists(dir));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), dir);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_stream_batch_row_limit() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n        (8, Some(\"name:2\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let stream_row_limit = 2;\n    let (_, endpoint, _) = {\n        let engine = TestEngineBuilder::new().build().unwrap();\n        let mut cfg = Config::default();\n        cfg.end_point_stream_batch_row_limit = stream_row_limit;\n        init_data_with_details(Context::default(), engine, &product, &data, true, &cfg)\n    };\n\n    let req = DagSelect::from(&product).build();\n    assert_eq!(req.get_ranges().len(), 1);\n\n    // only ignore first 7 bytes of the row id\n    let ignored_suffix_len = tidb_query_datatype::codec::table::RECORD_ROW_KEY_LEN - 1;\n\n    // `expected_ranges_last_bytes` checks those assertions:\n    // 1. We always fetch no more than stream_row_limit rows.\n    // 2. The responses' key ranges are disjoint.\n    // 3. Each returned key range should cover the returned rows.\n    let mut expected_ranges_last_bytes: Vec<(&[u8], &[u8])> = vec![\n        (b\"\\x00\", b\"\\x02\\x00\"),\n        (b\"\\x02\\x00\", b\"\\x05\\x00\"),\n        (b\"\\x05\\x00\", b\"\\xFF\"),\n    ];\n    let check_range = move |resp: &Response| {\n        let (start_last_bytes, end_last_bytes) = expected_ranges_last_bytes.remove(0);\n        let start = resp.get_range().get_start();\n        let end = resp.get_range().get_end();\n        assert_eq!(&start[ignored_suffix_len..], start_last_bytes);\n\n        assert_eq!(&end[ignored_suffix_len..], end_last_bytes);\n    };\n\n    let resps = handle_streaming_select(&endpoint, req, check_range);\n    assert_eq!(resps.len(), 3);\n    let expected_output_counts = vec![vec![2_i64], vec![2_i64], vec![1_i64]];\n    for (i, resp) in resps.into_iter().enumerate() {\n        let mut chunk = Chunk::default();\n        chunk.merge_from_bytes(resp.get_data()).unwrap();\n        assert_eq!(\n            resp.get_output_counts(),\n            expected_output_counts[i].as_slice(),\n        );\n\n        let chunks = vec![chunk];\n        let chunk_data_limit = stream_row_limit * 3; // we have 3 fields.\n        check_chunk_datum_count(&chunks, chunk_data_limit);\n\n        let spliter = DagChunkSpliter::new(chunks, 3);\n        let j = cmp::min((i + 1) * stream_row_limit, data.len());\n        let cur_data = &data[i * stream_row_limit..j];\n        for (row, &(id, name, cnt)) in spliter.zip(cur_data) {\n            let name_datum = name.map(|s| s.as_bytes()).into();\n            let expected_encoded = datum::encode_value(\n                &mut EvalContext::default(),\n                &[Datum::I64(id), name_datum, cnt.into()],\n            )\n            .unwrap();\n            let result_encoded = datum::encode_value(&mut EvalContext::default(), &row).unwrap();\n            assert_eq!(result_encoded, &*expected_encoded);\n        }\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_leader() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());\n\n    // can't make leader to witness\n    cluster\n        .pd_client\n        .switch_witnesses(region.get_id(), vec![peer_on_store1.get_id()], vec![true]);\n\n    std::thread::sleep(Duration::from_millis(100));\n    assert_eq!(\n        cluster.leader_of_region(region.get_id()).unwrap().store_id,\n        1\n    );\n    // leader changes to witness failed, so still can get the value\n    must_get_equal(&cluster.get_engine(nodes[0]), b\"k1\", b\"v1\");\n\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    // can't transfer leader to witness\n    cluster.transfer_leader(region.get_id(), peer_on_store3);\n    assert_eq!(\n        cluster.leader_of_region(region.get_id()).unwrap().store_id,\n        nodes[0],\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_hex_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"--hex-suffixes=9\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x0a\"), \"b\");\n    assert_eq!(at.read(\"x0b\"), \"c\");\n    assert_eq!(at.read(\"x0c\"), \"\");\n}"}
{"code": "pub(crate) fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.page.memory()[self.value_range.clone()])\n    }", "test": "fn drain_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let txn = db.begin_write().unwrap();\n    let mut table = txn.open_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.drain::<&str>(start.as_str()..).unwrap()\n    };\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), \"world\");\n    assert!(iter.next().is_none());\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn initial_retransmit() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let client_ch = pair.begin_connect(client_config());\n    pair.client.drive(pair.time, pair.server.addr);\n    pair.client.outbound.clear(); // Drop initial\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Connected { .. })\n    );\n}"}
{"code": "fn len(&self) -> Result<u64> {\n        let mut count = 0;\n        for item in self.iter()? {\n            let (_, values) = item?;\n            for v in values {\n                v?;\n                count += 1;\n            }\n        }\n        Ok(count)\n    }", "test": "fn drain_filter() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n        // Test draining uncommitted data\n        drop(table.drain_filter(0..10, |k, _| k < 5).unwrap());\n        for i in 0..5 {\n            table.insert(&i, &i).unwrap();\n        }\n        assert_eq!(table.len().unwrap(), 10);\n\n        // Test matching on the value\n        drop(table.drain_filter(0..10, |_, v| v < 5).unwrap());\n        for i in 0..5 {\n            table.insert(&i, &i).unwrap();\n        }\n        assert_eq!(table.len().unwrap(), 10);\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        for (i, item) in table.drain_filter(0.., |x, _| x < 5).unwrap().enumerate() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i as u64, k.value());\n            assert_eq!(i as u64, v.value());\n        }\n        assert_eq!(table.len().unwrap(), 5);\n        let mut i = 5u64;\n        for item in table.range(0..10).unwrap() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i, k.value());\n            assert_eq!(i, v.value());\n            i += 1;\n        }\n    }\n    write_txn.abort().unwrap();\n\n    // Check that dropping the iter early works too\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        drop(table.drain_filter(0.., |x, _| x < 5).unwrap());\n        assert_eq!(table.len().unwrap(), 5);\n    }\n    write_txn.abort().unwrap();\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_cli_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"format.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                (\"--files-max-size=16\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_cli_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_off() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=off\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(!at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn format_is_disabled() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"file.js\"), (\"--write\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, CUSTOM_FORMAT_BEFORE);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"format_is_disabled\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn plus<P: AsRef<Path>>(&self, name: P) -> PathBuf {\n        let mut pathbuf = self.subdir.clone();\n        pathbuf.push(name);\n        pathbuf\n    }", "test": "fn valid_context_directory_recursive_follow_all_symlinks() {\n    let (dir, mut cmd) = at_and_ucmd!();\n    dir.mkdir(\"a\");\n    dir.symlink_dir(\"a\", \"la\");\n\n    let b_path = Path::new(\"a\").join(\"b.txt\");\n    dir.touch(b_path.to_str().unwrap());\n\n    let c_path = Path::new(\"a\").join(\"c\");\n    dir.touch(c_path.to_str().unwrap());\n\n    let lc_path = Path::new(\"a\").join(\"lc\");\n    dir.symlink_dir(c_path.to_str().unwrap(), lc_path.to_str().unwrap());\n\n    let la_context = get_file_context(dir.plus(\"la\")).unwrap();\n    let lc_context = get_file_context(dir.plus(lc_path.to_str().unwrap())).unwrap();\n\n    let new_la_context = \"guest_u:object_r:etc_t:s0:c42\";\n\n    // -L: traverse every symbolic link to a directory encountered.\n    cmd.args(&[\"--verbose\", \"--recursive\", \"-L\", new_la_context])\n        .arg(dir.plus(\"la\"))\n        .succeeds();\n    assert_eq!(get_file_context(dir.plus(\"la\")).unwrap(), la_context);\n    assert_eq!(\n        get_file_context(dir.plus(\"a\")).unwrap().as_deref(),\n        Some(new_la_context)\n    );\n    assert_eq!(\n        get_file_context(dir.plus(b_path.to_str().unwrap()))\n            .unwrap()\n            .as_deref(),\n        Some(new_la_context)\n    );\n    assert_eq!(\n        get_file_context(dir.plus(lc_path.to_str().unwrap())).unwrap(),\n        lc_context\n    );\n    assert_eq!(\n        get_file_context(dir.plus(c_path.to_str().unwrap()))\n            .unwrap()\n            .as_deref(),\n        Some(new_la_context)\n    );\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn implicit_open() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n    let s1 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    let s2 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n    pair.client_send(client_ch, s2).write(b\"hello\").unwrap();\n    pair.drive();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), Some(s1));\n    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), Some(s2));\n    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), None);\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_closing_bracket_in_single_quote_attr() {\n    let mut r = Reader::from_str(\"<a attr='>' check='2'></a>\");\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Start(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"attr\"),\n                    value: Cow::Borrowed(b\">\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"check\"),\n                    value: Cow::Borrowed(b\"2\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        x => panic!(\"expected <a attr='>'>, got {:?}\", x),\n    }\n    next_eq!(r, End, b\"a\");\n}"}
{"code": "pub fn load(&self, ctx: TabletContext, create: bool) -> Result<CachedTablet<EK>>\n    where\n        EK: Clone,\n    {\n        assert!(ctx.suffix.is_some());\n        let id = ctx.id;\n        let path = self.tablet_path(id, ctx.suffix.unwrap());\n        if !create && !self.tablets.factory.exists(&path) {\n            return Err(Error::Other(box_err!(\n                \"tablet ({}, {:?}) doesn't exist\",\n                id,\n                ctx.suffix\n            )));\n        }\n        // TODO: use compaction filter to trim range.\n        let tablet = self.tablets.factory.open_tablet(ctx, &path)?;\n        let mut cached = self.get_or_default(id);\n        cached.set(tablet);\n        Ok(cached)\n    }", "test": "fn test_batch_size_edge_limit() {\n    let msg_count = Arc::new(AtomicUsize::new(0));\n    let batch_msg_count = Arc::new(AtomicUsize::new(0));\n    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), true);\n    let (mock_server, port) = create_mock_server(service, 60200, 60300).unwrap();\n\n    let mut raft_client = get_raft_client_by_port(port);\n\n    // Put them in buffer so sibling messages will be likely be batched during\n    // sending.\n    let mut msgs = Vec::with_capacity(5);\n    for _ in 0..5 {\n        let mut raft_m = RaftMessage::default();\n        // Magic number, this can make estimated size about 4940000, hence two messages\n        // will be batched together, but the total size will be way larger than\n        // 10MiB as there are many indexes and terms.\n        for _ in 0..38000 {\n            let mut e = Entry::default();\n            e.set_term(1);\n            e.set_index(256);\n            e.set_data(vec![b'a'; 130].into());\n            raft_m.mut_message().mut_entries().push(e);\n        }\n        msgs.push(raft_m);\n    }\n    for m in msgs {\n        raft_client.send(m).unwrap();\n    }\n    raft_client.flush();\n\n    check_msg_count(10000, &msg_count, 5);\n    // The final received message count should be 5 exactly.\n    drop(raft_client);\n    drop(mock_server);\n    assert_eq!(msg_count.load(Ordering::SeqCst), 5);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_implicit_target_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_implicit_target_dir\";\n    // On windows, slashes aren't allowed in symlink targets, so use\n    // PathBuf to construct `file` instead of simple \"dir/file\".\n    let filename = \"test_symlink_implicit_target_file\";\n    let path = PathBuf::from(dir).join(filename);\n    let file = &path.to_string_lossy();\n\n    at.mkdir(dir);\n    at.touch(&path);\n\n    ucmd.args(&[\"-s\", file]).succeeds().no_stderr();\n\n    assert!(at.file_exists(filename));\n    assert!(at.is_symlink(filename));\n    assert_eq!(at.resolve_link(filename), *file);\n}"}
{"code": "pub fn get_id(&self) -> ConnId {\n        self.id\n    }", "test": "fn test_witness_leader_down() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n\n    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();\n    // nonwitness -> witness\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store2.get_id()],\n        vec![true],\n    );\n\n    // the other follower is isolated\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    for i in 1..10 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), format!(\"v{}\", i).as_bytes());\n    }\n    // the leader is down\n    cluster.stop_node(1);\n\n    // witness would help to replicate the logs\n    cluster.clear_send_filters();\n\n    // forbid writes\n    let put = new_put_cmd(b\"k3\", b\"v3\");\n    must_get_error_is_witness(&mut cluster, &region, put);\n    // forbid reads\n    let get = new_get_cmd(b\"k1\");\n    must_get_error_is_witness(&mut cluster, &region, get);\n    // forbid read index\n    let read_index = new_read_index_cmd();\n    must_get_error_is_witness(&mut cluster, &region, read_index);\n\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store3);\n    cluster.must_put(b\"k1\", b\"v1\");\n    assert_eq!(\n        cluster.leader_of_region(region.get_id()).unwrap().store_id,\n        nodes[2],\n    );\n    assert_eq!(cluster.must_get(b\"k9\"), Some(b\"v9\".to_vec()));\n}"}
{"code": "pub fn roundtrip<F>(float: F, buffer: &mut [u8]) -> Result<(), String>\nwhere\n    F: RawFloat + ToLexical + std::str::FromStr + std::string::ToString,\n{\n    let bytes = float.to_lexical(buffer);\n    let string = unsafe { std::str::from_utf8_unchecked(bytes) };\n    let roundtrip = string.parse::<F>().map_err(|_| float.to_string())?;\n    let is_equal = if float.is_nan() {\n        roundtrip.is_nan()\n    } else {\n        float == roundtrip\n    };\n    if !is_equal {\n        return Err(float.to_string());\n    }\n    Ok(())\n}", "test": "fn u32_pow10_test() {\n    let values: &[u32] = &[\n        0, 1, 5, 9, 10, 11, 15, 99, 100, 101, 105, 999, 1000, 1001, 1005, 9999, 10000, 10001,\n        10005, 99999, 100000, 100001, 100005, 999999, 1000000, 1000001, 1000005, 9999999, 10000000,\n        10000001, 10000005, 99999999, 100000000, 100000001, 100000005, 999999999, 1000000000,\n        1000000001, 1000000005,\n    ];\n    for &i in values.iter() {\n        assert_eq!(i, roundtrip(i));\n    }\n}"}
{"code": "pub fn verified_expr(&self, sql: &str) -> Expr {\n        self.expr_parses_to(sql, sql)\n    }", "test": "fn parse_not_precedence() {\n    // NOT has higher precedence than OR/AND, so the following must parse as (NOT true) OR true\n    let sql = \"NOT true OR true\";\n    assert_matches!(\n        verified_expr(sql),\n        Expr::BinaryOp {\n            op: BinaryOperator::Or,\n            ..\n        }\n    );\n\n    // But NOT has lower precedence than comparison operators, so the following parses as NOT (a IS NULL)\n    let sql = \"NOT a IS NULL\";\n    assert_matches!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            ..\n        }\n    );\n\n    // NOT has lower precedence than BETWEEN, so the following parses as NOT (1 NOT BETWEEN 1 AND 2)\n    let sql = \"NOT 1 NOT BETWEEN 1 AND 2\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::Between {\n                expr: Box::new(Expr::Value(number(\"1\"))),\n                low: Box::new(Expr::Value(number(\"1\"))),\n                high: Box::new(Expr::Value(number(\"2\"))),\n                negated: true,\n            }),\n        },\n    );\n\n    // NOT has lower precedence than LIKE, so the following parses as NOT ('a' NOT LIKE 'b')\n    let sql = \"NOT 'a' NOT LIKE 'b'\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::Like {\n                expr: Box::new(Expr::Value(Value::SingleQuotedString(\"a\".into()))),\n                negated: true,\n                pattern: Box::new(Expr::Value(Value::SingleQuotedString(\"b\".into()))),\n                escape_char: None,\n            }),\n        },\n    );\n\n    // NOT has lower precedence than IN, so the following parses as NOT (a NOT IN 'a')\n    let sql = \"NOT a NOT IN ('a')\";\n    assert_eq!(\n        verified_expr(sql),\n        Expr::UnaryOp {\n            op: UnaryOperator::Not,\n            expr: Box::new(Expr::InList {\n                expr: Box::new(Expr::Identifier(\"a\".into())),\n                list: vec![Expr::Value(Value::SingleQuotedString(\"a\".into()))],\n                negated: true,\n            }),\n        },\n    );\n}"}
{"code": "pub fn leader_of_region(&mut self, region_id: u64) -> Option<metapb::Peer> {\n        let timer = Instant::now_coarse();\n        let timeout = Duration::from_secs(5);\n        let mut store_ids = None;\n        while timer.saturating_elapsed() < timeout {\n            match self.voter_store_ids_of_region(region_id) {\n                None => thread::sleep(Duration::from_millis(10)),\n                Some(ids) => {\n                    store_ids = Some(ids);\n                    break;\n                }\n            }\n        }\n        let store_ids = store_ids?;\n        if let Some(l) = self.leaders.get(&region_id) {\n            // leader may be stopped in some tests.\n            if self.valid_leader_id(region_id, l.get_store_id()) {\n                return Some(l.clone());\n            }\n        }\n        self.reset_leader_of_region(region_id);\n        let mut leader = None;\n        let mut leaders = HashMap::default();\n\n        let node_ids = self.sim.rl().get_node_ids();\n        // For some tests, we stop the node but pd still has this information,\n        // and we must skip this.\n        let alive_store_ids: Vec<_> = store_ids\n            .iter()\n            .filter(|id| node_ids.contains(id))\n            .cloned()\n            .collect();\n        while timer.saturating_elapsed() < timeout {\n            for store_id in &alive_store_ids {\n                let l = match self.query_leader(*store_id, region_id, Duration::from_secs(1)) {\n                    None => continue,\n                    Some(l) => l,\n                };\n                leaders\n                    .entry(l.get_id())\n                    .or_insert((l, vec![]))\n                    .1\n                    .push(*store_id);\n            }\n            if let Some((_, (l, c))) = leaders.iter().max_by_key(|(_, (_, c))| c.len()) {\n                if c.contains(&l.get_store_id()) {\n                    leader = Some(l.clone());\n                    // Technically, correct calculation should use two quorum when in joint\n                    // state. Here just for simplicity.\n                    if c.len() > store_ids.len() / 2 {\n                        break;\n                    }\n                }\n            }\n            debug!(\"failed to detect leaders\"; \"leaders\" => ?leaders, \"store_ids\" => ?store_ids);\n            sleep_ms(10);\n            leaders.clear();\n        }\n\n        if let Some(l) = leader {\n            self.leaders.insert(region_id, l);\n        }\n\n        self.leaders.get(&region_id).cloned()\n    }", "test": "fn test_transfer_leader_slow_apply() {\n    // 3 nodes cluster.\n    let mut cluster = new_node_cluster(0, 3);\n\n    let pd_client = cluster.pd_client.clone();\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n    pd_client.must_add_peer(r1, new_peer(2, 1002));\n    pd_client.must_add_peer(r1, new_peer(3, 1003));\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    let fp = \"on_handle_apply_1003\";\n    fail::cfg(fp, \"pause\").unwrap();\n    for i in 0..=cluster.cfg.raft_store.leader_transfer_max_log_lag {\n        let bytes = format!(\"k{:03}\", i).into_bytes();\n        cluster.must_put(&bytes, &bytes);\n    }\n    cluster.transfer_leader(r1, new_peer(3, 1003));\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n    assert_ne!(cluster.leader_of_region(r1).unwrap(), new_peer(3, 1003));\n    fail::remove(fp);\n    cluster.must_transfer_leader(r1, new_peer(3, 1003));\n    cluster.must_put(b\"k3\", b\"v3\");\n    must_get_equal(&cluster.get_engine(3), b\"k3\", b\"v3\");\n}"}
{"code": "pub fn size(&self) -> u32 {\n        match self {\n            Table::Static { size, .. } => *size,\n            Table::Dynamic { elements, .. } => elements.len().try_into().unwrap(),\n        }\n    }", "test": "fn grow_externref_tables_via_api() -> anyhow::Result<()> {\n    let mut cfg = Config::new();\n    cfg.wasm_reference_types(true);\n    let engine = Engine::new(&cfg)?;\n    let mut store = Store::new(&engine, ());\n\n    let table_ty = TableType::new(ValType::ExternRef, 10, None);\n    let table = Table::new(&mut store, table_ty, Val::ExternRef(None))?;\n\n    assert_eq!(table.size(&store), 10);\n    table.grow(&mut store, 3, Val::ExternRef(None))?;\n    assert_eq!(table.size(&store), 13);\n\n    Ok(())\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_parent_directories() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ancestor1 = \"ancestor1\";\n    let ancestor2 = \"ancestor1/ancestor2\";\n    let target_dir = \"ancestor1/ancestor2/target_dir\";\n    let directories_arg = \"-d\";\n\n    // Here one of the ancestors already exist and only the target_dir and\n    // its parent must be created.\n    at.mkdir(ancestor1);\n\n    ucmd.args(&[directories_arg, target_dir])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(ancestor2));\n    assert!(at.dir_exists(target_dir));\n}"}
{"code": "pub fn owned(&self) -> bool {\n        match self.state.load(Relaxed) {\n            BORROW => false,\n            _ => true,\n        }\n    }", "test": "fn guest_different_host_same() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t1\" (type $t1 (sub resource)))\n                (import \"t2\" (type $t2 (sub resource)))\n\n                (import \"f\" (func $f (param \"a\" (borrow $t1)) (param \"b\" (borrow $t2))))\n\n                (export $g1 \"g1\" (type $t1))\n                (export $g2 \"g2\" (type $t2))\n\n                (core func $f (canon lower (func $f)))\n                (core func $drop1 (canon resource.drop $t1))\n                (core func $drop2 (canon resource.drop $t2))\n\n                (core module $m\n                    (import \"\" \"f\" (func $f (param i32 i32)))\n                    (import \"\" \"drop1\" (func $drop1 (param i32)))\n                    (import \"\" \"drop2\" (func $drop2 (param i32)))\n\n                    (func (export \"f\") (param i32 i32)\n                        ;; separate tables both have initial index of 0\n                        (if (i32.ne (local.get 0) (i32.const 0)) (then (unreachable)))\n                        (if (i32.ne (local.get 1) (i32.const 0)) (then (unreachable)))\n\n                        ;; host should end up getting the same resource\n                        (call $f (local.get 0) (local.get 1))\n\n                        ;; drop our borrows\n                        (call $drop1 (local.get 0))\n                        (call $drop2 (local.get 0))\n                    )\n                )\n                (core instance $i (instantiate $m\n                    (with \"\" (instance\n                        (export \"f\" (func $f))\n                        (export \"drop1\" (func $drop1))\n                        (export \"drop2\" (func $drop2))\n                    ))\n                ))\n\n                (func (export \"f2\") (param \"a\" (borrow $g1)) (param \"b\" (borrow $g2))\n                    (canon lift (core func $i \"f\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t1\", |_, _| Ok(()))?;\n    linker.root().resource::<MyType>(\"t2\", |_, _| Ok(()))?;\n    linker.root().func_wrap(\n        \"f\",\n        |_cx, (r1, r2): (Resource<MyType>, Resource<MyType>)| {\n            assert!(!r1.owned());\n            assert!(!r2.owned());\n            assert_eq!(r1.rep(), 100);\n            assert_eq!(r2.rep(), 100);\n            Ok(())\n        },\n    )?;\n    let i = linker.instantiate(&mut store, &c)?;\n    let f = i.get_typed_func::<(&Resource<MyType>, &Resource<MyType>), ()>(&mut store, \"f2\")?;\n\n    let t1 = i.get_resource(&mut store, \"g1\").unwrap();\n    let t2 = i.get_resource(&mut store, \"g2\").unwrap();\n    assert_eq!(t1, t2);\n    assert_eq!(t1, ResourceType::host::<MyType>());\n\n    let resource = Resource::new_own(100);\n    f.call(&mut store, (&resource, &resource))?;\n    f.post_return(&mut store)?;\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date3() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"@1623786360\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let expected = FileTime::from_unix_time(1_623_786_360, 0);\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, expected);\n    assert_eq!(mtime, expected);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_cdc_rawkv_scan() {\n    let mut suite = TestSuite::new(3, ApiVersion::V2);\n\n    let (k1, v1) = (b\"rkey1\".to_vec(), b\"value1\".to_vec());\n    suite.must_kv_put(1, k1, v1);\n\n    let (k2, v2) = (b\"rkey2\".to_vec(), b\"value2\".to_vec());\n    suite.must_kv_put(1, k2, v2);\n\n    let ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    suite.flush_causal_timestamp_for_region(1);\n\n    let (k3, v3) = (b\"rkey3\".to_vec(), b\"value3\".to_vec());\n    suite.must_kv_put(1, k3.clone(), v3.clone());\n\n    let (k4, v4) = (b\"rkey4\".to_vec(), b\"value4\".to_vec());\n    suite.must_kv_put(1, k4.clone(), v4.clone());\n\n    let mut req = suite.new_changedata_request(1);\n    req.set_kv_api(ChangeDataRequestKvApi::RawKv);\n    req.set_checkpoint_ts(ts.into_inner());\n    let (mut req_tx, event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(1));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n    let mut events = receive_event(false).events.to_vec();\n    if events.len() == 1 {\n        events.extend(receive_event(false).events.into_iter());\n    }\n    assert_eq!(events.len(), 2, \"{:?}\", events);\n\n    match events.remove(0).event.unwrap() {\n        // Batch size is set to 3.\n        Event_oneof_event::Entries(es) => {\n            assert!(es.entries.len() == 2, \"{:?}\", es);\n            let e = &es.entries[0];\n            assert_eq!(e.get_type(), EventLogType::Committed, \"{:?}\", es);\n            assert_eq!(e.key, k3, \"{:?}\", es);\n            assert_eq!(e.value, v3, \"{:?}\", es);\n\n            let e = &es.entries[1];\n            assert_eq!(e.get_type(), EventLogType::Committed, \"{:?}\", es);\n            assert_eq!(e.key, k4, \"{:?}\", es);\n            assert_eq!(e.value, v4, \"{:?}\", es);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    match events.pop().unwrap().event.unwrap() {\n        // Then it outputs Initialized event.\n        Event_oneof_event::Entries(es) => {\n            assert!(es.entries.len() == 1, \"{:?}\", es);\n            let e = &es.entries[0];\n            assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    event_feed_wrap.replace(None);\n    suite.stop();\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn host_borrow_as_resource_any() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n                (import \"f\" (func $f (param \"f\" (borrow $t))))\n\n                (core func $f (canon lower (func $f)))\n\n                (core module $m\n                    (import \"\" \"f\" (func $f (param i32)))\n                    (func (export \"f2\") (param i32)\n                        (call $f (local.get 0))\n                    )\n                )\n                (core instance $i (instantiate $m\n                    (with \"\" (instance\n                        (export \"f\" (func $f))\n                    ))\n                ))\n\n                (func (export \"f2\") (param \"x\" (borrow $t))\n                    (canon lift (core func $i \"f2\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n\n    // First test the above component where the host properly drops the argument\n    {\n        let mut linker = Linker::new(&engine);\n        linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n        linker\n            .root()\n            .func_wrap(\"f\", |mut cx, (r,): (ResourceAny,)| {\n                r.resource_drop(&mut cx)?;\n                Ok(())\n            })?;\n        let i = linker.instantiate(&mut store, &c)?;\n\n        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f2\")?;\n\n        let resource = Resource::new_own(100);\n        f.call(&mut store, (&resource,))?;\n    }\n\n    // Then also test the case where the host forgets a drop\n    {\n        let mut linker = Linker::new(&engine);\n        linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n        linker.root().func_wrap(\"f\", |_cx, (_r,): (ResourceAny,)| {\n            // ... no drop here\n            Ok(())\n        })?;\n        let i = linker.instantiate(&mut store, &c)?;\n\n        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f2\")?;\n\n        let resource = Resource::new_own(100);\n        let err = f.call(&mut store, (&resource,)).unwrap_err();\n        assert!(\n            format!(\"{err:?}\").contains(\"borrow handles still remain at the end of the call\"),\n            \"bad error: {err:?}\"\n        );\n    }\n    Ok(())\n}"}
{"code": "fn term(input: &[u8]) -> IResult<&[u8], i64> {\n  let (input, init) = factor(input)?;\n  fold_many0(\n    pair(one_of(\"*/\"), factor),\n    move || init,\n    |acc, (op, val)| {\n      if op == '*' {\n        acc * val\n      } else {\n        acc / val\n      }\n    },\n  )(input)\n}", "test": "fn term_test() {\n  assert_eq!(term(\" 12 *2 /  3\"), Ok((\"\", 8)));\n  assert_eq!(term(\" 2* 3  *2 *2 /  3\"), Ok((\"\", 8)));\n  assert_eq!(term(\" 48 /  3/2\"), Ok((\"\", 8)));\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_cname_lookup() {\n    let resp_query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let cname_record = cname_record(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        Name::from_str(\"v4.example.com.\").unwrap(),\n    );\n    let v4_record = v4_record(\n        Name::from_str(\"v4.example.com.\").unwrap(),\n        Ipv4Addr::new(93, 184, 216, 34),\n    );\n    let message = message(resp_query, vec![cname_record, v4_record], vec![], vec![]);\n    let client: MockClientHandle<_, ResolveError> =\n        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, false),\n    );\n\n    let io_loop = Runtime::new().unwrap();\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        *lookup.iter().next().unwrap(),\n        RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "pub fn to_str<'a, T: 'a>(&self, store: impl Into<StoreContext<'a, T>>) -> Result<Cow<'a, str>> {\n        let store = store.into().0;\n        let memory = self.options.memory(store);\n        self.to_str_from_memory(memory)\n    }", "test": "fn post_return_string() -> Result<()> {\n    let component = r#\"\n        (component\n            (core module $m\n                (memory (export \"memory\") 1)\n                (func (export \"get\") (result i32)\n                    (i32.store offset=0 (i32.const 8) (i32.const 100))\n                    (i32.store offset=4 (i32.const 8) (i32.const 11))\n                    i32.const 8\n                )\n\n                (func (export \"post\") (param i32)\n                    local.get 0\n                    i32.const 8\n                    i32.ne\n                    if unreachable end)\n\n                (data (i32.const 100) \"hello world\")\n            )\n            (core instance $i (instantiate $m))\n            (func (export \"get\") (result string)\n                (canon lift\n                    (core func $i \"get\")\n                    (post-return (func $i \"post\"))\n                    (memory $i \"memory\")\n                )\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, false);\n    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;\n    let get = instance.get_typed_func::<(), (WasmStr,)>(&mut store, \"get\")?;\n    let s = get.call(&mut store, ())?.0;\n    assert_eq!(s.to_str(&store)?, \"hello world\");\n    get.post_return(&mut store)?;\n\n    Ok(())\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_deadline() {\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"deadline_check_fail\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"exceeding the deadline\"));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_replace_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_replace_file_a\";\n    let file_b = \"test_mv_replace_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(file_a).arg(file_b).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "fn write(&mut self, bytes: &[u8]) -> io::Result<usize> {\n        self.tls_conn.writer().write(bytes)\n    }", "test": "fn exercise_key_log_file_for_server() {\n    serialized(|| {\n        let mut server_config = make_server_config(KeyType::Rsa);\n\n        env::set_var(\"SSLKEYLOGFILE\", \"./sslkeylogfile.txt\");\n        server_config.key_log = Arc::new(rustls::KeyLogFile::new());\n\n        let server_config = Arc::new(server_config);\n\n        for version in rustls::ALL_VERSIONS {\n            let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);\n            let (mut client, mut server) =\n                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n\n            assert_eq!(5, client.writer().write(b\"hello\").unwrap());\n\n            do_handshake(&mut client, &mut server);\n            transfer(&mut client, &mut server);\n            server.process_new_packets().unwrap();\n        }\n    })\n}"}
{"code": "pub fn cover_offset(self, offset: TextSize) -> TextRange {\n        self.cover(TextRange::empty(offset))\n    }", "test": "fn cover_offset() {\n    assert_eq!(range(1..3).cover_offset(size(0)), range(0..3));\n    assert_eq!(range(1..3).cover_offset(size(1)), range(1..3));\n    assert_eq!(range(1..3).cover_offset(size(2)), range(1..3));\n    assert_eq!(range(1..3).cover_offset(size(3)), range(1..3));\n    assert_eq!(range(1..3).cover_offset(size(4)), range(1..4));\n}"}
{"code": "fn twolines(i: Partial<&str>) -> IResult<Partial<&str>, (&str, &str)> {\n        let (i, l1) = not_line_ending.parse_peek(i)?;\n        let (i, _) = line_ending.parse_peek(i)?;\n        let (i, l2) = not_line_ending.parse_peek(i)?;\n        let (i, _) = line_ending.parse_peek(i)?;\n\n        Ok((i, (l1, l2)))\n    }", "test": "fn issue_655() {\n    use winnow::ascii::{line_ending, not_line_ending};\n    fn twolines(i: Partial<&str>) -> IResult<Partial<&str>, (&str, &str)> {\n        let (i, l1) = not_line_ending.parse_peek(i)?;\n        let (i, _) = line_ending.parse_peek(i)?;\n        let (i, l2) = not_line_ending.parse_peek(i)?;\n        let (i, _) = line_ending.parse_peek(i)?;\n\n        Ok((i, (l1, l2)))\n    }\n\n    assert_eq!(\n        twolines(Partial::new(\"foo\\nbar\\n\")),\n        Ok((Partial::new(\"\"), (\"foo\", \"bar\")))\n    );\n    assert_eq!(\n        twolines(Partial::new(\"f\u00e9o\\nbar\\n\")),\n        Ok((Partial::new(\"\"), (\"f\u00e9o\", \"bar\")))\n    );\n    assert_eq!(\n        twolines(Partial::new(\"fo\u00e9\\nbar\\n\")),\n        Ok((Partial::new(\"\"), (\"fo\u00e9\", \"bar\")))\n    );\n    assert_eq!(\n        twolines(Partial::new(\"fo\u00e9\\r\\nbar\\n\")),\n        Ok((Partial::new(\"\"), (\"fo\u00e9\", \"bar\")))\n    );\n}\n\n#[cf"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_datagram_fails_to_stream() {\n    // Lookup to UDP should fail, and then the query should be retried on TCP because\n    // `try_tcp_on_error` is set to true.\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n    let udp_message: Result<DnsResponse, _> = Err(ResolveError::from(\"Forced Testing Error\"));\n\n    let tcp_message = message(query.clone(), vec![tcp_record.clone()], vec![], vec![]);\n\n    let udp_nameserver = mock_nameserver(vec![udp_message], Default::default());\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let mut options = ResolverOpts::default();\n    options.try_tcp_on_error = true;\n    let pool = mock_nameserver_pool(vec![udp_nameserver], vec![tcp_nameserver], None, options);\n\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers()[0], tcp_record);\n}"}
{"code": "pub fn is_handshaking(&self) -> bool {\n        !(self.may_send_application_data && self.may_receive_application_data)\n    }", "test": "fn server_complete_io_for_handshake() {\n    for kt in ALL_KEY_TYPES.iter() {\n        let (mut client, mut server) = make_pair(*kt);\n\n        assert!(server.is_handshaking());\n        let (rdlen, wrlen) = server\n            .complete_io(&mut OtherSession::new(&mut client))\n            .unwrap();\n        assert!(rdlen > 0 && wrlen > 0);\n        assert!(!server.is_handshaking());\n        assert!(!server.wants_write());\n    }\n}"}
{"code": "pub fn encode<T: AsRef<[u8]>>(input: T) -> String {\n    STANDARD.encode(input)\n}", "test": "fn display_wrapper_matches_normal_encode() {\n    let mut bytes = Vec::<u8>::with_capacity(256);\n\n    for i in 0..255 {\n        bytes.push(i);\n    }\n    bytes.push(255);\n\n    assert_eq!(\n        STANDARD.encode(&bytes),\n        format!(\"{}\", display::Base64Display::new(&bytes, &STANDARD))\n    );\n}"}
{"code": "pub fn get<K2: PartialEq<K> + ?Sized>(&self, key: &K2) -> Option<&V> {\n        self.find(key).map(move |pos| &self.vec[pos].1)\n    }", "test": "fn as_header_name() {\n    let mut m = HeaderMap::new();\n    let v: HeaderValue = \"localhost\".parse().unwrap();\n    m.insert(HOST, v.clone());\n\n    let expected = Some(&v);\n\n    assert_eq!(m.get(\"host\"), expected);\n    assert_eq!(m.get(&HOST), expected);\n\n    let s = String::from(\"host\");\n    assert_eq!(m.get(&s), expected);\n    assert_eq!(m.get(s.as_str()), expected);\n}"}
{"code": "pub fn hi64(&self) -> (u64, bool) {\n        bigint::hi64(&self.data)\n    }", "test": "fn hi64_test() {\n    assert_eq!(VecType::from_u64(0xA).hi64(), (0xA000000000000000, false));\n    assert_eq!(VecType::from_u64(0xAB).hi64(), (0xAB00000000000000, false));\n    assert_eq!(VecType::from_u64(0xAB00000000).hi64(), (0xAB00000000000000, false));\n    assert_eq!(VecType::from_u64(0xA23456789A).hi64(), (0xA23456789A000000, false));\n}"}
{"code": "fn open<'a>(\n        &self,\n        data: &'a mut [u8],\n        additional_data: &[u8],\n    ) -> Result<&'a mut [u8], CryptoError> {\n        let aad = ring::aead::Aad::from(additional_data);\n        let zero_nonce = ring::aead::Nonce::assume_unique_for_key([0u8; 12]);\n        Ok(self.open_in_place(zero_nonce, aad, data)?)\n    }", "test": "fn stream_id_limit() {\n    let _guard = subscribe();\n    let server = ServerConfig {\n        transport: Arc::new(TransportConfig {\n            max_concurrent_uni_streams: 1u32.into(),\n            ..TransportConfig::default()\n        }),\n        ..server_config()\n    };\n    let mut pair = Pair::new(Default::default(), server);\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Uni)\n        .expect(\"couldn't open first stream\");\n    assert_eq!(\n        pair.client_streams(client_ch).open(Dir::Uni),\n        None,\n        \"only one stream is permitted at a time\"\n    );\n    // Generate some activity to allow the server to see the stream\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Finished { id })) if id == s\n    );\n    assert_eq!(\n        pair.client_streams(client_ch).open(Dir::Uni),\n        None,\n        \"server does not immediately grant additional credit\"\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    assert_eq!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n\n    // Server will only send MAX_STREAM_ID now that the application's been notified\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Available { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n\n    // Try opening the second stream again, now that we've made room\n    let s = pair\n        .client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .streams()\n        .open(Dir::Uni)\n        .expect(\"didn't get stream id budget\");\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive();\n    // Make sure the server actually processes data on the newly-available stream\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n}"}
{"code": "pub fn remove(&mut self, index: usize) -> A::Item {\n    let targets: &mut [A::Item] = &mut self.deref_mut()[index..];\n    let item = take(&mut targets[0]);\n\n    // A previous implementation used rotate_left\n    // rotate_right and rotate_left generate a huge amount of code and fail to\n    // inline; calling them here incurs the cost of all the cases they\n    // handle even though we're rotating a usually-small array by a constant\n    // 1 offset. This swap-based implementation benchmarks much better for\n    // small array lengths in particular.\n\n    for i in 0..targets.len() - 1 {\n      targets.swap(i, i + 1);\n    }\n    self.len -= 1;\n    item\n  }", "test": "fn ArrayVec_remove() {\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n  assert_eq!(av.remove(1), 2);\n  assert_eq!(&av[..], &[1, 3][..]);\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_chown_owner_group_id() {\n    // test chown 1111:1111 file.txt\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let result = scene.cmd(\"id\").arg(\"-u\").run();\n    if skipping_test_is_okay(&result, \"id: cannot find name for group ID\") {\n        return;\n    }\n    let user_id = String::from(result.stdout_str().trim());\n    assert!(!user_id.is_empty());\n\n    let result = scene.cmd(\"id\").arg(\"-g\").run();\n    if skipping_test_is_okay(&result, \"id: cannot find name for group ID\") {\n        return;\n    }\n    let group_id = String::from(result.stdout_str().trim());\n    assert!(!group_id.is_empty());\n\n    let file1 = \"test_chown_file1\";\n    at.touch(file1);\n\n    let result = scene\n        .ucmd()\n        .arg(format!(\"{user_id}:{group_id}\"))\n        .arg(\"--verbose\")\n        .arg(file1)\n        .run();\n    if skipping_test_is_okay(&result, \"invalid user\") {\n        // From the Logs: \"Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)\"\n        // stderr: \"chown: invalid user: '1001:116'\n        return;\n    }\n    result.stderr_contains(\"retained as\");\n\n    let result = scene\n        .ucmd()\n        .arg(format!(\"{user_id}.{group_id}\"))\n        .arg(\"--verbose\")\n        .arg(file1)\n        .run();\n    if skipping_test_is_okay(&result, \"invalid user\") {\n        // From the Logs: \"Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)\"\n        // stderr: \"chown: invalid user: '1001.116'\n        return;\n    }\n    result.stderr_contains(\"retained as\");\n\n    scene\n        .ucmd()\n        .arg(\"0:0\")\n        .arg(\"--verbose\")\n        .arg(file1)\n        .fails()\n        .stderr_contains(\"failed to change\");\n}"}
{"code": "pub fn success(&self) -> &Self {\n        assert!(\n            self.succeeded(),\n            \"Command was expected to succeed.\\nstdout = {}\\n stderr = {}\",\n            self.stdout_str(),\n            self.stderr_str()\n        );\n        self\n    }", "test": "fn test_deleted_dir() {\n    use std::process::Command;\n\n    let ts = TestScenario::new(util_name!());\n    let at = ts.fixtures;\n    let output = Command::new(\"sh\")\n        .arg(\"-c\")\n        .arg(format!(\n            \"cd '{}'; mkdir foo; cd foo; rmdir ../foo; exec '{}' {}\",\n            at.root_dir_resolved(),\n            ts.bin_path.to_str().unwrap(),\n            ts.util_name,\n        ))\n        .output()\n        .unwrap();\n    assert!(!output.status.success());\n    assert!(output.stdout.is_empty());\n    assert_eq!(\n        output.stderr,\n        b\"pwd: failed to get current directory: No such file or directory\\n\"\n    );\n}"}
{"code": "pub fn compute_float32(q: i32, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        many_digits: false,\n    };\n    let fp = bellerophon::<f32>(&num);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f32_test() {\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(compute_float32(0, 16777216), (151, 0));\n    assert_eq!(compute_float32(0, 16777217), (111 + f32::INVALID_FP, 9223372586610589696));\n    assert_eq!(compute_float32(0, 16777218), (151, 1));\n    assert_eq!(compute_float32(0, 16777219), (111 + f32::INVALID_FP, 9223373686122217472));\n    assert_eq!(compute_float32(0, 16777220), (151, 2));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));\n    assert_eq!(\n        compute_float32(-10, 167772170000000000),\n        (111 + f32::INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));\n    // Let's check the lines to see if anything is different in table...\n    assert_eq!(\n        compute_float32(-10, 167772190000000000),\n        (111 + f32::INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_none() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_errors_for_all_disabled_checks() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CI_CONFIGURATION.as_bytes());\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), UNFORMATTED_AND_INCORRECT.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--linter-enabled=false\"),\n                (\"--formatter-enabled=false\"),\n                (\"--organize-imports-enabled=false\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, UNFORMATTED_AND_INCORRECT);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_errors_for_all_disabled_checks\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn string(input: &str) -> IResult<&str, String> {\n  delimited(\n    char('\"'),\n    fold_many0(character, String::new, |mut string, c| {\n      string.push(c);\n      string\n    }),\n    char('\"'),\n  )(input)\n}", "test": "fn json_string() {\n  assert_eq!(string(\"\\\"\\\"\"), Ok((\"\", \"\".to_string())));\n  assert_eq!(string(\"\\\"abc\\\"\"), Ok((\"\", \"abc\".to_string())));\n  assert_eq!(\n    string(\"\\\"abc\\\\\\\"\\\\\\\\\\\\/\\\\b\\\\f\\\\n\\\\r\\\\t\\\\u0001\\\\u2014\\u{2014}def\\\"\"),\n    Ok((\"\", \"abc\\\"\\\\/\\x08\\x0C\\n\\r\\t\\x01\u2014\u2014def\".to_string())),\n  );\n  assert_eq!(string(\"\\\"\\\\uD83D\\\\uDE10\\\"\"), Ok((\"\", \"\ud83d\ude10\".to_string())));\n\n  assert!(string(\"\\\"\").is_err());\n  assert!(string(\"\\\"abc\").is_err());\n  assert!(string(\"\\\"\\\\\\\"\").is_err());\n  assert!(string(\"\\\"\\\\u123\\\"\").is_err());\n  assert!(string(\"\\\"\\\\uD800\\\"\").is_err());\n  assert!(string(\"\\\"\\\\uD800\\\\uD800\\\"\").is_err());\n  assert!(string(\"\\\"\\\\uDC00\\\"\").is_err());\n}\n\n#[tes"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn does_render_owned_for_loop_with_objects_string_keys() {\n    let mut context = Context::new();\n    let data = json!([\n        {\"id\": 1, \"group\": \"a\"},\n        {\"id\": 2, \"group\": \"b\"},\n        {\"id\": 3, \"group\": \"c\"},\n        {\"id\": 4, \"group\": \"a\"},\n        {\"id\": 5, \"group\": \"b\"},\n        {\"id\": 6, \"group\": \"c\"},\n        {\"id\": 7, \"group\": \"a\"},\n        {\"id\": 8},\n        {\"id\": 9, \"year\": null},\n    ]);\n    context.insert(\"something\", &data);\n\n    let tpl = r#\"{% for group, things in something | group_by(attribute=\"group\") %}{{group}},{% endfor %}\"#;\n    let expected = \"a,b,c,\";\n    assert_eq!(render_template(tpl, &context).unwrap(), expected);\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_twice_2() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    db.engine.put(b\"d\", b\"\").unwrap();\n    db.engine.put(b\"e\", b\"\").unwrap();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n    for i in 64..128_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n    wb.delete_range(b\"b\", b\"e\").unwrap();\n    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())\n        .unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"d\").unwrap().is_none());\n    assert!(db.engine.get_value(b\"e\").unwrap().is_some());\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    for i in 1..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "pub(crate) fn to_string(&self) -> String {\n        let mut repr = String::with_capacity(self.digits.len());\n\n        let mut has_nonzero = false;\n        for digit in self.digits.iter().rev() {\n            has_nonzero |= *digit != 0;\n            if has_nonzero {\n                repr.push((*digit + b'0') as char);\n            }\n        }\n\n        if repr.is_empty() {\n            repr.push('0');\n        }\n\n        repr\n    }", "test": "fn test_literal_mangling() {\n    let code = \"0_4\";\n    let parsed: Lit = syn::parse_str(code).unwrap();\n    assert_eq!(code, quote!(#parsed).to_string());\n}"}
{"code": "pub fn len(&self) -> usize {\n    self.len as usize\n  }", "test": "fn iter_last_nth() {\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n  av.push(4);\n  assert_eq!(av.len(), 4);\n  let mut iter = av.into_iter();\n  assert_eq!(iter.next(), Some(1));\n  assert_eq!(iter.next(), Some(2));\n  assert_eq!(iter.next(), Some(3));\n  assert_eq!(iter.next(), Some(4));\n  assert_eq!(iter.next(), None);\n  assert_eq!(iter.last(), None);\n\n  let mut av: ArrayVec<[i32; 10]> = Default::default();\n  av.push(1);\n  av.push(2);\n  av.push(3);\n\n  assert_eq!(av.into_iter().nth(0), Some(1));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cmds.len()\n    }", "test": "fn test_region_collection_seek_region() {\n    let mut cluster = new_node_cluster(0, 3);\n\n    let (tx, rx) = channel();\n    cluster\n        .sim\n        .wl()\n        .post_create_coprocessor_host(Box::new(move |id, host| {\n            let p = RegionInfoAccessor::new(host);\n            tx.send((id, p)).unwrap()\n        }));\n\n    cluster.run();\n    let region_info_providers: HashMap<_, _> = rx.try_iter().collect();\n    assert_eq!(region_info_providers.len(), 3);\n    let regions = prepare_cluster(&mut cluster);\n\n    for node_id in cluster.get_node_ids() {\n        let engine = &region_info_providers[&node_id];\n\n        // Test traverse all regions\n        let key = b\"\".to_vec();\n        let (tx, rx) = channel();\n        let tx_ = tx.clone();\n        engine\n            .seek_region(\n                &key,\n                Box::new(move |infos| {\n                    tx_.send(infos.map(|i| i.region.clone()).collect()).unwrap();\n                }),\n            )\n            .unwrap();\n        let sought_regions: Vec<_> = rx.recv_timeout(Duration::from_secs(3)).unwrap();\n        assert_eq!(sought_regions, regions);\n\n        // Test end_key is exclusive\n        let (tx, rx) = channel();\n        let tx_ = tx.clone();\n        engine\n            .seek_region(\n                b\"k1\",\n                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),\n            )\n            .unwrap();\n        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();\n        assert_eq!(region, regions[1]);\n\n        // Test seek from non-starting key\n        let tx_ = tx.clone();\n        engine\n            .seek_region(\n                b\"k6\\xff\\xff\\xff\\xff\\xff\",\n                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),\n            )\n            .unwrap();\n        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();\n        assert_eq!(region, regions[3]);\n        let tx_ = tx.clone();\n        engine\n            .seek_region(\n                b\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\",\n                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),\n            )\n            .unwrap();\n        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();\n        assert_eq!(region, regions[5]);\n    }\n\n    for (_, p) in region_info_providers {\n        p.stop();\n    }\n}"}
{"code": "fn is_cluster_bootstrapped(&self) -> Result<bool> {\n        let _timer = PD_REQUEST_HISTOGRAM_VEC\n            .is_cluster_bootstrapped\n            .start_coarse_timer();\n\n        let mut req = pdpb::IsBootstrappedRequest::default();\n        req.set_header(self.header());\n\n        let resp = sync_request(&self.pd_client, LEADER_CHANGE_RETRY, |client, option| {\n            client.is_bootstrapped_opt(&req, option)\n        })?;\n        check_resp_header(resp.get_header())?;\n\n        Ok(resp.get_bootstrapped())\n    }", "test": "fn test_get_tombstone_store() {\n    let eps_count = 1;\n    let server = MockServer::new(eps_count);\n    let eps = server.bind_addrs();\n    let mut client = new_client_v2(eps, None);\n\n    let mut all_stores = vec![];\n    let store_id = client.alloc_id().unwrap();\n    let mut store = metapb::Store::default();\n    store.set_id(store_id);\n    let region_id = client.alloc_id().unwrap();\n    let mut region = metapb::Region::default();\n    region.set_id(region_id);\n    client.bootstrap_cluster(store.clone(), region).unwrap();\n\n    all_stores.push(store);\n    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);\n    let s = client.get_all_stores(false).unwrap();\n    assert_eq!(s, all_stores);\n\n    // Add tombstone store.\n    let mut store99 = metapb::Store::default();\n    store99.set_id(99);\n    store99.set_state(metapb::StoreState::Tombstone);\n    server.default_handler().add_store(store99.clone());\n\n    let r = client.get_store(99);\n    assert_eq!(r.unwrap_err().error_code(), error_code::pd::STORE_TOMBSTONE);\n}"}
{"code": "pub(crate) fn is_some(&self) -> bool {\n            match self {\n                Visibility::Inherited => false,\n                _ => true,\n            }\n        }", "test": "fn print_incomplete_qpath() {\n    // qpath with `as` token\n    let mut ty: TypePath = parse_quote!(<Self as A>::Q);\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self as A > :: Q`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self as A > ::`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self >`)\n    \"###);\n    assert!(ty.path.segments.pop().is_none());\n\n    // qpath without `as` token\n    let mut ty: TypePath = parse_quote!(<Self>::A::B);\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self > :: A :: B`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self > :: A ::`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`< Self > ::`)\n    \"###);\n    assert!(ty.path.segments.pop().is_none());\n\n    // normal path\n    let mut ty: TypePath = parse_quote!(Self::A::B);\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`Self :: A :: B`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`Self :: A ::`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(`Self ::`)\n    \"###);\n    assert!(ty.path.segments.pop().is_some());\n    snapshot!(ty.to_token_stream(), @r###\"\n    TokenStream(``)\n    \"###);\n    assert!(ty.path.segments.pop().is_none());\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn test_pooling_allocator_initial_limits_exceeded() -> Result<()> {\n    let mut pool = crate::small_pool_config();\n    pool.total_memories(2)\n        .max_memories_per_module(2)\n        .memory_pages(5);\n    let mut config = Config::new();\n    config.wasm_multi_memory(true);\n    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));\n\n    let engine = Engine::new(&config)?;\n    let module = Module::new(\n        &engine,\n        r#\"(module (memory (export \"m1\") 2) (memory (export \"m2\") 5))\"#,\n    )?;\n\n    let mut store = Store::new(\n        &engine,\n        StoreLimitsBuilder::new()\n            .memory_size(3 * WASM_PAGE_SIZE)\n            .build(),\n    );\n    store.limiter(|s| s as &mut dyn ResourceLimiter);\n\n    match Instance::new(&mut store, &module, &[]) {\n        Ok(_) => unreachable!(),\n        Err(e) => assert_eq!(\n            e.to_string(),\n            \"memory minimum size of 5 pages exceeds memory limits\"\n        ),\n    }\n\n    // An instance should still be able to be created after the failure above\n    let module = Module::new(&engine, r#\"(module (memory (export \"m\") 2))\"#)?;\n\n    Instance::new(&mut store, &module, &[])?;\n\n    Ok(())\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_if_elif_else() {\n    let mut context = Context::new();\n    context.insert(\"is_true\", &true);\n    context.insert(\"is_false\", &false);\n    context.insert(\"age\", &18);\n    context.insert(\"name\", &\"john\");\n    context.insert(\"empty_string\", &\"\");\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n\n    let inputs = vec![\n        (\"{% if is_true %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if is_true or age + 1 > 18 %}Adult{% endif %}\", \"Adult\"),\n        (\"{% if is_true and age == 18 %}Adult{% endif %}\", \"Adult\"),\n        // https://github.com/Keats/tera/issues/187\n        (\"{% if 1 <= 2 %}a{% endif %}\", \"a\"),\n        (\"{% if 2 >= 1 %}a{% endif %}\", \"a\"),\n        (\"{% if 1 < 2 %}a{% endif %}\", \"a\"),\n        (\"{% if 2 > 1 %}a{% endif %}\", \"a\"),\n        (\"{% if 1 == 1 %}a{% endif %}\", \"a\"),\n        (\"{% if 1 != 2 %}a{% endif %}\", \"a\"),\n        // testing string conditions\n        (\"{% if 'true' %}a{% endif %}\", \"a\"),\n        (\"{% if name %}a{% endif %}\", \"a\"),\n        (\"{% if '' %}a{% endif %}\", \"\"),\n        (\"{% if empty_string %}a{% endif %}\", \"\"),\n        (\"{% if '' ~ name %}a{% endif %}\", \"a\"),\n        (\"{% if '' ~ empty_string %}a{% endif %}\", \"\"),\n        // some not conditions\n        (\"{% if not is_false %}a{% endif %}\", \"a\"),\n        (\"{% if not is_true %}a{% endif %}\", \"\"),\n        (\"{% if undefined %}a{% endif %}\", \"\"),\n        (\"{% if not undefined %}a{% endif %}\", \"a\"),\n        (\"{% if not is_false and is_true %}a{% endif %}\", \"a\"),\n        (\"{% if not is_false or numbers | length > 0 %}a{% endif %}\", \"a\"),\n        // doesn't panic with NaN results\n        (\"{% if 0 / 0 %}a{% endif %}\", \"\"),\n        // if and else\n        (\"{% if is_true %}Admin{% else %}User{% endif %}\", \"Admin\"),\n        (\"{% if is_false %}Admin{% else %}User{% endif %}\", \"User\"),\n        // if and elifs\n        (\"{% if is_true %}Admin{% elif is_false %}User{% endif %}\", \"Admin\"),\n        (\"{% if is_true %}Admin{% elif is_true %}User{% endif %}\", \"Admin\"),\n        (\"{% if is_true %}Admin{% elif numbers | length > 0 %}User{% endif %}\", \"Admin\"),\n        // if, elifs and else\n        (\"{% if is_true %}Admin{% elif is_false %}User{% else %}Hmm{% endif %}\", \"Admin\"),\n        (\"{% if false %}Admin{% elif is_false %}User{% else %}Hmm{% endif %}\", \"Hmm\"),\n        // doesn't fallthrough elifs\n        // https://github.com/Keats/tera/issues/188\n        (\"{% if 1 < 4 %}a{% elif 2 < 4 %}b{% elif 3 < 4 %}c{% else %}d{% endif %}\", \"a\"),\n        // with in operator\n        (\n            \"{% if 1 in numbers %}Admin{% elif 100 in numbers %}User{% else %}Hmm{% endif %}\",\n            \"Admin\",\n        ),\n        (\"{% if 100 in numbers %}Admin{% elif 1 in numbers %}User{% else %}Hmm{% endif %}\", \"User\"),\n        (\"{% if 'n' in name %}Admin{% else %}Hmm{% endif %}\", \"Admin\"),\n        // function in if\n        (\"{% if get_true() %}Truth{% endif %}\", \"Truth\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn strip_inline_block_internal_text() {\n    assert_eq!(\n        \"<u>a </u>b <u>c</u>\",\n        normalize_html(\" <u> a </u> b <u> c </u> \")\n    )\n}"}
{"code": "pub fn i32_exit_status(&self) -> Option<i32> {\n        if let Self::I32Exit(status) = self {\n            return Some(*status);\n        }\n        None\n    }", "test": "fn resumable_call_host() {\n    let (mut store, _linker) = test_setup();\n    let host_fn = Func::wrap(&mut store, || -> Result<(), Trap> {\n        Err(Trap::i32_exit(100))\n    });\n    // Even though the called host function traps we expect a normal error\n    // since the host function is the root function of the call and therefore\n    // it would not make sense to resume it.\n    let error = host_fn\n        .call_resumable(&mut store, &[], &mut [])\n        .unwrap_err();\n    match error {\n        Error::Trap(trap) => {\n            assert_eq!(trap.i32_exit_status(), Some(100));\n        }\n        _ => panic!(\"expected Wasm trap\"),\n    }\n    // The same test for `TypedFunc`:\n    let trap = host_fn\n        .typed::<(), ()>(&store)\n        .unwrap()\n        .call_resumable(&mut store, ())\n        .unwrap_err();\n    assert_eq!(trap.i32_exit_status(), Some(100));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_move_multiple_files_into_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file1 = \"test_mv_move_multiple_files_into_file1\";\n    let file2 = \"test_mv_move_multiple_files_into_file2\";\n    let file3 = \"test_mv_move_multiple_files_into_file3\";\n\n    at.touch(file1);\n    at.touch(file2);\n    at.touch(file3);\n\n    ucmd.arg(file1)\n        .arg(file2)\n        .arg(file3)\n        .fails()\n        .stderr_is(format!(\"mv: target '{file3}': Not a directory\\n\"));\n\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn instance_exports() -> Result<()> {\n    let engine = super::engine();\n    let component = r#\"\n        (component\n            (import \"a\" (instance $i))\n            (import \"b\" (instance $i2 (export \"m\" (core module))))\n\n            (alias export $i2 \"m\" (core module $m))\n\n            (component $c\n                (component $c\n                    (export \"m\" (core module $m))\n                )\n                (instance $c (instantiate $c))\n                (export \"i\" (instance $c))\n            )\n            (instance $c (instantiate $c))\n            (export \"i\" (instance $c))\n            (export \"r\" (instance $i))\n            (export \"r2\" (instance $i2))\n        )\n    \"#;\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.instance(\"a\")?;\n    linker\n        .instance(\"b\")?\n        .module(\"m\", &Module::new(&engine, \"(module)\")?)?;\n    let instance = linker.instantiate(&mut store, &component)?;\n\n    let mut exports = instance.exports(&mut store);\n    assert!(exports.instance(\"not an instance\").is_none());\n    let mut i = exports.instance(\"r\").unwrap();\n    assert!(i.func(\"x\").is_none());\n    drop(i);\n    exports.root().instance(\"i\").unwrap();\n    let mut i2 = exports.instance(\"r2\").unwrap();\n    assert!(i2.func(\"m\").is_none());\n    assert!(i2.module(\"m\").is_some());\n    drop(i2);\n\n    exports\n        .instance(\"i\")\n        .unwrap()\n        .instance(\"i\")\n        .unwrap()\n        .module(\"m\")\n        .unwrap();\n\n    Ok(())\n}"}
{"code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "async fn call_wrapped_async_func() -> Result<(), Error> {\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n    let f = Func::wrap4_async(\n        &mut store,\n        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            Box::new(async move {\n                // Calling this func will switch context into wasm, then back to host:\n                assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);\n\n                assert_eq!(\n                    caller.data().calls_into_host,\n                    caller.data().returns_from_host + 1\n                );\n                assert_eq!(\n                    caller.data().calls_into_wasm,\n                    caller.data().returns_from_wasm + 1\n                );\n\n                assert_eq!(a, 1);\n                assert_eq!(b, 2);\n                assert_eq!(c, 3.0);\n                assert_eq!(d, 4.0);\n            })\n        },\n    );\n\n    f.call_async(\n        &mut store,\n        &[Val::I32(1), Val::I64(2), 3.0f32.into(), 4.0f64.into()],\n        &mut [],\n    )\n    .await?;\n\n    // One switch from vm to host to call f, another in return from f.\n    assert_eq!(store.data().calls_into_host, 1);\n    assert_eq!(store.data().returns_from_host, 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 1);\n\n    f.typed::<(i32, i64, f32, f64), ()>(&store)?\n        .call_async(&mut store, (1, 2, 3.0, 4.0))\n        .await?;\n\n    assert_eq!(store.data().calls_into_host, 2);\n    assert_eq!(store.data().returns_from_host, 2);\n    assert_eq!(store.data().calls_into_wasm, 2);\n    assert_eq!(store.data().returns_from_wasm, 2);\n\n    Ok(())\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn apply_suggested_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"fix.js\");\n    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply-unsafe\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"apply_suggested_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub(crate) fn value(&self) -> Option<&V> {\n        // SAFETY: the garbage collector ensures `ptr` is valid as long as `data` is `Some`.\n        unsafe { self.data.get().map(|ptr| &ptr.as_ref().value) }\n    }", "test": "fn eph_basic_alloc_dump_test() {\n    run_test(|| {\n        let gc_value = Gc::new(String::from(\"gc here\"));\n        let _gc_two = Gc::new(\"hmmm\");\n\n        let eph = Ephemeron::new(&gc_value, 4);\n        let _fourth = Gc::new(\"tail\");\n\n        assert_eq!(eph.value(), Some(4));\n    });\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn active_borrows_at_end_of_call() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t\" (type $t (sub resource)))\n\n                (core module $m\n                    (func (export \"f\") (param i32))\n                )\n                (core instance $i (instantiate $m))\n\n                (func (export \"f\") (param \"x\" (borrow $t))\n                    (canon lift (core func $i \"f\")))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t\", |_, _| Ok(()))?;\n    let i = linker.instantiate(&mut store, &c)?;\n\n    let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, \"f\")?;\n\n    let resource = Resource::new_own(1);\n    f.call(&mut store, (&resource,))?;\n    let err = f.post_return(&mut store).unwrap_err();\n    assert_eq!(\n        err.to_string(),\n        \"borrow handles still remain at the end of the call\",\n    );\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_simple_backup() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_simple_backup_file_a\";\n    let file_b = \"test_mv_simple_backup_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"-b\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn send_upload_sst(\n    client: &ImportSstClient,\n    meta: &SstMeta,\n    data: &[u8],\n) -> Result<UploadResponse> {\n    let mut r1 = UploadRequest::default();\n    r1.set_meta(meta.clone());\n    let mut r2 = UploadRequest::default();\n    r2.set_data(data.to_vec());\n    let reqs: Vec<_> = vec![r1, r2]\n        .into_iter()\n        .map(|r| Result::Ok((r, WriteFlags::default())))\n        .collect();\n    let (mut tx, rx) = client.upload().unwrap();\n    let mut stream = stream::iter(reqs);\n    block_on(async move {\n        tx.send_all(&mut stream).await?;\n        tx.close().await?;\n        rx.await\n    })\n}", "test": "fn test_upload_sst() {\n    let (_cluster, ctx, _, import) = new_cluster_and_tikv_import_client();\n\n    let data = vec![1; 1024];\n    let crc32 = calc_data_crc32(&data);\n    let length = data.len() as u64;\n\n    // Mismatch crc32\n    let meta = new_sst_meta(0, length);\n    assert_to_string_contains!(send_upload_sst(&import, &meta, &data).unwrap_err(), \"crc32\");\n\n    let mut meta = new_sst_meta(crc32, length);\n    meta.set_region_id(ctx.get_region_id());\n    meta.set_region_epoch(ctx.get_region_epoch().clone());\n    send_upload_sst(&import, &meta, &data).unwrap();\n\n    // Can't upload the same uuid file again.\n    assert_to_string_contains!(\n        send_upload_sst(&import, &meta, &data).unwrap_err(),\n        \"FileExists\"\n    );\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_dereference() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_dir(SUB_DEEPER_DIR, SUB_DIR_LINKS_DEEPER_SYM_DIR);\n\n    let result = ts.ucmd().arg(\"-L\").arg(SUB_DIR_LINKS).succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[\"-L\", SUB_DIR_LINKS]));\n\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n\n    _du_dereference(result.stdout_str());\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_output_is_random_permutation() {\n    let input_seq = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];\n    let input = input_seq\n        .iter()\n        .map(ToString::to_string)\n        .collect::<Vec<String>>()\n        .join(\"\\n\");\n\n    let result = new_ucmd!().pipe_in(input.as_bytes()).succeeds();\n    result.no_stderr();\n\n    let mut result_seq: Vec<i32> = result\n        .stdout_str()\n        .split('\\n')\n        .filter(|x| !x.is_empty())\n        .map(|x| x.parse().unwrap())\n        .collect();\n    result_seq.sort_unstable();\n    assert_ne!(result.stdout_str(), input, \"Output is not randomized\");\n    assert_eq!(result_seq, input_seq, \"Output is not a permutation\");\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_byte_buf_ser() {\n    let bytes = ByteBuf::new();\n    assert_eq!(to_string(&bytes).unwrap(), \"[]\".to_string());\n\n    let bytes = ByteBuf::from(vec![1, 2, 3]);\n    assert_eq!(to_string(&bytes).unwrap(), \"[1,2,3]\".to_string());\n}"}
{"code": "pub fn ty(&self) -> Type {\n        match self {\n            DataValue::I8(_) => types::I8,\n            DataValue::I16(_) => types::I16,\n            DataValue::I32(_) => types::I32,\n            DataValue::I64(_) => types::I64,\n            DataValue::I128(_) => types::I128,\n            DataValue::F32(_) => types::F32,\n            DataValue::F64(_) => types::F64,\n            DataValue::V128(_) => types::I8X16, // A default type.\n            DataValue::V64(_) => types::I8X8,   // A default type.\n        }\n    }", "test": "fn dynamic_val() -> Result<()> {\n    let engine = super::engine();\n    let c = Component::new(\n        &engine,\n        r#\"\n            (component\n                (import \"t1\" (type $t1 (sub resource)))\n                (type $t2' (resource (rep i32)))\n                (export $t2 \"t2\" (type $t2'))\n                (core func $f (canon resource.new $t2))\n\n                (core module $m\n                    (func (export \"pass\") (param i32) (result i32)\n                        (local.get 0)))\n                (core instance $i (instantiate $m))\n\n                (func (export \"a\") (param \"x\" (own $t1)) (result (own $t1))\n                    (canon lift (core func $i \"pass\")))\n                (func (export \"b\") (param \"x\" u32) (result (own $t2))\n                    (canon lift (core func $f)))\n            )\n        \"#,\n    )?;\n\n    struct MyType;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n    linker.root().resource::<MyType>(\"t1\", |_, _| Ok(()))?;\n    let i = linker.instantiate(&mut store, &c)?;\n\n    let a = i.get_func(&mut store, \"a\").unwrap();\n    let a_typed = i.get_typed_func::<(Resource<MyType>,), (ResourceAny,)>(&mut store, \"a\")?;\n    let b = i.get_func(&mut store, \"b\").unwrap();\n    let t2 = i.get_resource(&mut store, \"t2\").unwrap();\n\n    let t1 = Resource::new_own(100);\n    let (t1,) = a_typed.call(&mut store, (t1,))?;\n    a_typed.post_return(&mut store)?;\n    assert_eq!(t1.ty(), ResourceType::host::<MyType>());\n\n    let mut results = [Val::Bool(false)];\n    a.call(&mut store, &[Val::Resource(t1)], &mut results)?;\n    a.post_return(&mut store)?;\n    match &results[0] {\n        Val::Resource(resource) => {\n            assert_eq!(resource.ty(), ResourceType::host::<MyType>());\n        }\n        _ => unreachable!(),\n    }\n\n    b.call(&mut store, &[Val::U32(200)], &mut results)?;\n    match &results[0] {\n        Val::Resource(resource) => {\n            assert_eq!(resource.ty(), t2);\n        }\n        _ => unreachable!(),\n    }\n\n    Ok(())\n}"}
{"code": "fn hex_color(input: &str) -> IResult<&str, Color> {\n  let (input, _) = tag(\"#\")(input)?;\n  let (input, (red, green, blue)) = tuple((hex_primary, hex_primary, hex_primary))(input)?;\n\n  Ok((input, Color { red, green, blue }))\n}", "test": "fn parse_color() {\n  assert_eq!(\n    hex_color(\"#2F14DF\"),\n    Ok((\n      \"\",\n      Color {\n        red: 47,\n        green: 20,\n        blue: 223,\n      }\n    ))\n  );\n}"}
{"code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn depth_limit() {\n    let data = Config {\n        float: (2.18, -1.1),\n        tuple: TupleStruct((), false),\n        map: vec![(8, '1')].into_iter().collect(),\n        nested: Nested {\n            a: \"a\".to_owned(),\n            b: 'b',\n        },\n        var: Variant::A(!0, \"\"),\n        array: vec![(); 3],\n    };\n\n    let pretty = ron::ser::PrettyConfig::new()\n        .depth_limit(1)\n        .separate_tuple_members(true)\n        .enumerate_arrays(true)\n        .new_line(\"\\n\".to_string());\n    let s = ron::ser::to_string_pretty(&data, pretty);\n\n    assert_eq!(s, Ok(EXPECTED.to_string()));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_multiple_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_rm_multiple_file_a\";\n    let file_b = \"test_rm_multiple_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    ucmd.arg(file_a).arg(file_b).succeeds().no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.cols.len()\n    }", "test": "fn test_increase_async_ios() {\n    let mut cluster = new_node_cluster(0, 1);\n    cluster.cfg.raft_store.store_io_pool_size = 1;\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n\n    // Save current async-io tids before shrinking\n    let org_writers_tids = get_async_writers_tids();\n    assert_eq!(1, org_writers_tids.len());\n    // Request can be handled as usual\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n\n    // Update config, expand from 1 to 2\n    {\n        let sim = cluster.sim.rl();\n        let cfg_controller = sim.get_cfg_controller().unwrap();\n\n        let change = {\n            let mut change = HashMap::new();\n            change.insert(\"raftstore.store-io-pool-size\".to_owned(), \"2\".to_owned());\n            change\n        };\n\n        cfg_controller.update(change).unwrap();\n        assert_eq!(\n            cfg_controller.get_current().raft_store.store_io_pool_size,\n            2\n        );\n        // Wait for the completion of increasing async-ios\n        std::thread::sleep(std::time::Duration::from_secs(1));\n    }\n    // Save current async-io tids after scaling up, and compared with the\n    // orginial one before scaling up, the thread num should be added up to TWO.\n    let cur_writers_tids = get_async_writers_tids();\n    assert_eq!(cur_writers_tids.len() - 1, org_writers_tids.len());\n\n    // Request can be handled as usual\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n}"}
{"code": "fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }", "test": "fn test_block_size_from_env_precedences() {\n    fn get_header(one: (&str, &str), two: (&str, &str)) -> String {\n        let (k1, v1) = one;\n        let (k2, v2) = two;\n        let output = new_ucmd!()\n            .arg(\"--output=size\")\n            .env(k1, v1)\n            .env(k2, v2)\n            .succeeds()\n            .stdout_move_str();\n        output.lines().next().unwrap().trim().to_string()\n    }\n\n    let df_block_size = (\"DF_BLOCK_SIZE\", \"111\");\n    let block_size = (\"BLOCK_SIZE\", \"222\");\n    let blocksize = (\"BLOCKSIZE\", \"333\");\n\n    assert_eq!(get_header(df_block_size, block_size), \"111B-blocks\");\n    assert_eq!(get_header(df_block_size, blocksize), \"111B-blocks\");\n    assert_eq!(get_header(block_size, blocksize), \"222B-blocks\");\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.entries.len() == 0\n    }", "test": "fn test_destroy_clean_up_logs_with_log_gc() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(50);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 50;\n    let pd_client = cluster.pd_client.clone();\n\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k2\", b\"v2\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    let raft_engine = cluster.engines[&3].raft.clone();\n    let mut dest = vec![];\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(!dest.is_empty());\n\n    pd_client.must_remove_peer(1, new_peer(3, 3));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    dest.clear();\n    // Normally destroy peer should cleanup all logs.\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(dest.is_empty(), \"{:?}\", dest);\n\n    pd_client.must_add_peer(1, new_peer(3, 4));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n    must_get_equal(&cluster.get_engine(3), b\"k3\", b\"v3\");\n    dest.clear();\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(!dest.is_empty());\n\n    pd_client.must_remove_peer(1, new_peer(3, 4));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    dest.clear();\n    // Peer created by snapshot should also cleanup all logs.\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(dest.is_empty(), \"{:?}\", dest);\n\n    pd_client.must_add_peer(1, new_peer(3, 5));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    cluster.must_put(b\"k4\", b\"v4\");\n    must_get_equal(&cluster.get_engine(3), b\"k4\", b\"v4\");\n    dest.clear();\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(!dest.is_empty());\n\n    let state = cluster.truncated_state(1, 3);\n    for _ in 0..50 {\n        cluster.must_put(b\"k5\", b\"v5\");\n    }\n    cluster.wait_log_truncated(1, 3, state.get_index() + 1);\n\n    pd_client.must_remove_peer(1, new_peer(3, 5));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    dest.clear();\n    // Peer destroy after log gc should also cleanup all logs.\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    assert!(dest.is_empty(), \"{:?}\", dest);\n}"}
{"code": "fn count_info_log(path: &Path) -> usize {\n    count_file(path, |path| {\n        path.file_name()\n            .unwrap()\n            .to_string_lossy()\n            .starts_with(\"LOG\")\n    })\n}", "test": "fn test_data_recovery() {\n    let mut cluster = Cluster::default();\n    let registry = cluster.node(0).tablet_registry();\n    let tablet_2_path = registry.tablet_path(2, RAFT_INIT_LOG_INDEX);\n    // The rocksdb is a bootstrapped tablet, so it will be opened and closed in\n    // bootstrap, and then open again in fsm initialization.\n    assert_eq!(count_info_log(&tablet_2_path), 2);\n    let router = &mut cluster.routers[0];\n    router.wait_applied_to_current_term(2, Duration::from_secs(3));\n\n    // Write 100 keys to default CF and not flush.\n    let header = Box::new(router.new_request_for(2).take_header());\n    for i in 0..100 {\n        let mut put = SimpleWriteEncoder::with_capacity(64);\n        put.put(\n            CF_DEFAULT,\n            format!(\"key{}\", i).as_bytes(),\n            format!(\"value{}\", i).as_bytes(),\n        );\n        router\n            .send(2, PeerMsg::simple_write(header.clone(), put.encode()).0)\n            .unwrap();\n    }\n\n    // Write 100 keys to write CF and flush half.\n    let mut sub = None;\n    for i in 0..50 {\n        let mut put = SimpleWriteEncoder::with_capacity(64);\n        put.put(\n            CF_WRITE,\n            format!(\"key{}\", i).as_bytes(),\n            format!(\"value{}\", i).as_bytes(),\n        );\n        let (msg, s) = PeerMsg::simple_write(header.clone(), put.encode());\n        router.send(2, msg).unwrap();\n        sub = Some(s);\n    }\n    let resp = block_on(sub.take().unwrap().result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    let mut cached = cluster.node(0).tablet_registry().get(2).unwrap();\n    cached.latest().unwrap().flush_cf(CF_WRITE, true).unwrap();\n    let router = &mut cluster.routers[0];\n    for i in 50..100 {\n        let mut put = SimpleWriteEncoder::with_capacity(64);\n        put.put(\n            CF_WRITE,\n            format!(\"key{}\", i).as_bytes(),\n            format!(\"value{}\", i).as_bytes(),\n        );\n        router\n            .send(2, PeerMsg::simple_write(header.clone(), put.encode()).0)\n            .unwrap();\n    }\n\n    // Write 100 keys to lock CF and flush all.\n    for i in 0..100 {\n        let mut put = SimpleWriteEncoder::with_capacity(64);\n        put.put(\n            CF_LOCK,\n            format!(\"key{}\", i).as_bytes(),\n            format!(\"value{}\", i).as_bytes(),\n        );\n        let (msg, s) = PeerMsg::simple_write(header.clone(), put.encode());\n        router.send(2, msg).unwrap();\n        sub = Some(s);\n    }\n    let resp = block_on(sub.take().unwrap().result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    cached = cluster.node(0).tablet_registry().get(2).unwrap();\n    cached.latest().unwrap().flush_cf(CF_LOCK, true).unwrap();\n\n    // Make sure all keys must be written.\n    let router = &mut cluster.routers[0];\n    let snap = router.stale_snapshot(2);\n    for cf in DATA_CFS {\n        for i in 0..100 {\n            let key = format!(\"key{}\", i);\n            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();\n            assert_eq!(\n                value.as_deref(),\n                Some(format!(\"value{}\", i).as_bytes()),\n                \"{} {}\",\n                cf,\n                key\n            );\n        }\n    }\n    let registry = cluster.node(0).tablet_registry();\n    cached = registry.get(2).unwrap();\n    cached\n        .latest()\n        .unwrap()\n        .set_db_options(&[(\"avoid_flush_during_shutdown\", \"true\")])\n        .unwrap();\n    drop((snap, cached));\n\n    cluster.restart(0);\n\n    let registry = cluster.node(0).tablet_registry();\n    cached = registry.get(2).unwrap();\n    cached\n        .latest()\n        .unwrap()\n        .set_db_options(&[(\"avoid_flush_during_shutdown\", \"true\")])\n        .unwrap();\n    let router = &mut cluster.routers[0];\n\n    // Write another key to ensure all data are recovered.\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key101\", b\"value101\");\n    let resp = router.simple_write(2, header, put).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    // After being restarted, all unflushed logs should be applied again. So there\n    // should be no missing data.\n    let snap = router.stale_snapshot(2);\n    for cf in DATA_CFS {\n        for i in 0..100 {\n            let key = format!(\"key{}\", i);\n            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();\n            assert_eq!(\n                value.as_deref(),\n                Some(format!(\"value{}\", i).as_bytes()),\n                \"{} {}\",\n                cf,\n                key\n            );\n        }\n    }\n\n    // There is a restart, so LOG file should be rotate.\n    assert_eq!(count_info_log(&tablet_2_path), 3);\n    // We only trigger Flush twice, so there should be only 2 files. And because WAL\n    // is disabled, so when rocksdb is restarted, there should be no WAL to recover,\n    // so no additional flush will be triggered.\n    assert_eq!(count_sst(&tablet_2_path), 2);\n\n    cached = cluster.node(0).tablet_registry().get(2).unwrap();\n    cached.latest().unwrap().flush_cfs(DATA_CFS, true).unwrap();\n\n    // Although all CFs are triggered again, but recovery should only write:\n    // 1. [0, 101) to CF_DEFAULT\n    // 2. [50, 100) to CF_WRITE\n    //\n    // So there will be only 2 memtables to be flushed.\n    assert_eq!(count_sst(&tablet_2_path), 4);\n\n    drop((snap, cached));\n\n    cluster.restart(0);\n\n    let router = &mut cluster.routers[0];\n\n    assert_eq!(count_info_log(&tablet_2_path), 4);\n    // Because data is flushed before restarted, so all data can be read\n    // immediately.\n    let snap = router.stale_snapshot(2);\n    for cf in DATA_CFS {\n        for i in 0..100 {\n            let key = format!(\"key{}\", i);\n            let value = snap.get_value_cf(cf, key.as_bytes()).unwrap();\n            assert_eq!(\n                value.as_deref(),\n                Some(format!(\"value{}\", i).as_bytes()),\n                \"{} {}\",\n                cf,\n                key\n            );\n        }\n    }\n    // Trigger flush again.\n    cached = cluster.node(0).tablet_registry().get(2).unwrap();\n    cached.latest().unwrap().flush_cfs(DATA_CFS, true).unwrap();\n\n    // There is no recovery, so there should be nothing to flush.\n    assert_eq!(count_sst(&tablet_2_path), 4);\n}"}
{"code": "fn is_informational() {\n    assert!(status_code(100).is_informational());\n    assert!(status_code(199).is_informational());\n\n    assert!(!status_code(200).is_informational());\n}", "test": "fn is_informational() {\n    assert!(status_code(100).is_informational());\n    assert!(status_code(199).is_informational());\n\n    assert!(!status_code(200).is_informational());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.s.len()\n    }", "test": "fn capture_misc() {\n    let re = regex!(r\"(.)(?P<a>a)?(.)(?P<b>.)\");\n    let cap = re.captures(t!(\"abc\")).unwrap();\n\n    assert_eq!(5, cap.len());\n\n    assert_eq!((0, 3), { let m = cap.get(0).unwrap(); (m.start(), m.end()) });\n    assert_eq!(None, cap.get(2));\n    assert_eq!((2, 3), { let m = cap.get(4).unwrap(); (m.start(), m.end()) });\n\n    assert_eq!(t!(\"abc\"), match_text!(cap.get(0).unwrap()));\n    assert_eq!(None, cap.get(2));\n    assert_eq!(t!(\"c\"), match_text!(cap.get(4).unwrap()));\n\n    assert_eq!(None, cap.name(\"a\"));\n    assert_eq!(t!(\"c\"), match_text!(cap.name(\"b\").unwrap()));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir_a = \"test_mv_backup_dir_dir_a\";\n    let dir_b = \"test_mv_backup_dir_dir_b\";\n\n    at.mkdir(dir_a);\n    at.mkdir(dir_b);\n    ucmd.arg(\"-vbT\")\n        .arg(dir_a)\n        .arg(dir_b)\n        .succeeds()\n        .stdout_only(format!(\n            \"renamed '{dir_a}' -> '{dir_b}' (backup: '{dir_b}~')\\n\"\n        ));\n\n    assert!(!at.dir_exists(dir_a));\n    assert!(at.dir_exists(dir_b));\n    assert!(at.dir_exists(&format!(\"{dir_b}~\")));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn apply_unsafe_with_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    // last line doesn't have code fix\n    let source = \"let a = 4;\ndebugger;\nconsole.log(a);\nfunction f() { arguments; }\n\";\n\n    let expected = \"const a = 4;\nconsole.log(a);\nfunction f() {\\n\\targuments;\\n}\n\";\n\n    let test1 = Path::new(\"test1.js\");\n    fs.insert(test1.into(), source.as_bytes());\n\n    let test2 = Path::new(\"test2.js\");\n    fs.insert(test2.into(), source.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"check\"),\n                (\"--apply-unsafe\"),\n                test1.as_os_str().to_str().unwrap(),\n                test2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(test1)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, expected);\n    drop(file);\n\n    content.clear();\n\n    let mut file = fs\n        .open(test2)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    drop(file);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"apply_unsafe_with_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn can_remove_whitespace_macros() {\n    let mut context = Context::new();\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n\n    let inputs = vec![\n        (r#\" {%- import \"macros\" as macros -%} {{macros::hey()}}\"#, \"Hey!\"),\n        (r#\" {% import \"macros\" as macros %} {{macros::hey()}}\"#, \"Hey!\"),\n        (r#\" {%- import \"macros\" as macros %} {%- set hey = macros::hey() -%} {{hey}}\"#, \"Hey!\"),\n    ];\n\n    for (input, expected) in inputs {\n        let mut tera = Tera::default();\n        tera.add_raw_templates(vec![\n            (\"macros\", \"{% macro hey() -%} Hey! {%- endmacro %}\"),\n            (\"tpl\", input),\n        ])\n        .unwrap();\n        assert_eq!(tera.render(\"tpl\", &context).unwrap(), expected);\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_all_then_none() {\n    // take last if multiple update args are supplied,\n    // update=none wins in this case\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_cp_arg_update_all_then_none_file1\";\n    let new = \"test_cp_arg_update_all_then_none_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=all\")\n        .arg(\"--update=none\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), \"new content\\n\");\n}"}
{"code": "pub fn comment(&self) -> &[u8] {\n        &self.shared.comment\n    }", "test": "fn correctly_handle_zip_with_garbage_after_comment() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"../tests/data/comment_garbage.zip\"));\n    let archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    assert_eq!(archive.comment(), \"short.\".as_bytes());\n}"}
{"code": "fn len(&self) -> usize {\n            self.hash_table.len()\n        }", "test": "fn present_after_module_drop() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let module = Module::new(store.engine(), r#\"(func (export \"foo\") unreachable)\"#)?;\n    let instance = Instance::new(&mut store, &module, &[])?;\n    let func = instance.get_typed_func::<(), ()>(&mut store, \"foo\")?;\n\n    println!(\"asserting before we drop modules\");\n    assert_trap(func.call(&mut store, ()).unwrap_err());\n    drop((instance, module));\n\n    println!(\"asserting after drop\");\n    assert_trap(func.call(&mut store, ()).unwrap_err());\n    return Ok(());\n\n    fn assert_trap(t: Error) {\n        println!(\"{:?}\", t);\n        let trace = t.downcast_ref::<WasmBacktrace>().unwrap().frames();\n        assert_eq!(trace.len(), 1);\n        assert_eq!(trace[0].func_index(), 0);\n    }\n}"}
{"code": "fn next_back(&mut self) -> Option<Self::Item> {\n        self.last\n            .next()\n            .map(Pair::End)\n            .or_else(|| self.inner.next_back().map(|(t, p)| Pair::Punctuated(t, p)))\n    }", "test": "fn iter() {\n    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);\n\n    check_exact_size_iterator!(p.iter());\n    check_exact_size_iterator!(p.iter_mut());\n    check_exact_size_iterator!(p.into_iter());\n\n    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);\n\n    assert_eq!(p.iter().next_back(), Some(&4));\n    assert_eq!(p.iter_mut().next_back(), Some(&mut 4));\n    assert_eq!(p.into_iter().next_back(), Some(4));\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn options_tests() {\n    let builder = OptionsBuilder::new();\n    assert!(builder.is_valid());\n    assert!(unsafe { builder.build_unchecked() }.is_valid());\n    assert!(OptionsBuilder::default().is_valid());\n\n    let options: Options = Options::new();\n    assert!(options.is_valid());\n    assert_eq!(options, Options::default());\n    assert!(OptionsBuilder::new().build().is_ok());\n    assert!(OptionsBuilder::default().build().is_ok());\n    assert!(OptionsBuilder::default().is_valid());\n    assert_eq!(options.rebuild(), Options::builder());\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn alpn_mismatch() {\n    let _guard = subscribe();\n    let mut server_crypto = server_crypto();\n    server_crypto.alpn_protocols = vec![\"foo\".into(), \"bar\".into(), \"baz\".into()];\n    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);\n\n    let mut client_crypto = client_crypto();\n    client_crypto.alpn_protocols = vec![\"quux\".into(), \"corge\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto));\n\n    let client_ch = pair.begin_connect(client_config);\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(err) }) if err.error_code == TransportErrorCode::crypto(0x78)\n    );\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_force_leader_three_nodes() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n\n    cluster.run();\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    let region = cluster.get_region(b\"k1\");\n    cluster.must_split(&region, b\"k9\");\n    let region = cluster.get_region(b\"k2\");\n    let peer_on_store3 = find_peer(&region, 3).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store3.clone());\n\n    cluster.stop_node(2);\n    cluster.stop_node(3);\n\n    // quorum is lost, can't propose command successfully.\n    confirm_quorum_is_lost(&mut cluster, &region);\n\n    cluster.must_enter_force_leader(region.get_id(), 1, vec![2, 3]);\n    // remove the peers on failed nodes\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 2).unwrap().clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());\n    // forbid writes in force leader state\n    let put = new_put_cmd(b\"k3\", b\"v3\");\n    must_get_error_recovery_in_progress(&mut cluster, &region, put);\n    // forbid reads in force leader state\n    let get = new_get_cmd(b\"k1\");\n    must_get_error_recovery_in_progress(&mut cluster, &region, get);\n    // forbid read index in force leader state\n    let read_index = new_read_index_cmd();\n    must_get_error_recovery_in_progress(&mut cluster, &region, read_index);\n    cluster.exit_force_leader(region.get_id(), 1);\n\n    // quorum is formed, can propose command successfully now\n    cluster.must_put(b\"k4\", b\"v4\");\n    assert_eq!(cluster.must_get(b\"k2\"), None);\n    assert_eq!(cluster.must_get(b\"k3\"), None);\n    assert_eq!(cluster.must_get(b\"k4\"), Some(b\"v4\".to_vec()));\n}"}
{"code": "fn as_ref(&self) -> &[u8] {\n        self.0\n    }", "test": "fn test_comment_starting_with_gt() {\n    let src = \"<a /><!-->-->\";\n    let mut r = Reader::from_str(src);\n    r.trim_text(true);\n    loop {\n        match r.read_event() {\n            Ok(Comment(e)) => {\n                assert_eq!(e.as_ref(), b\">\");\n                break;\n            }\n            Ok(Eof) => panic!(\"Expecting Comment\"),\n            _ => (),\n        }\n    }\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_all() {\n    use hickory_proto::rr::rdata::AAAA;\n\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = io_loop\n        .block_on(client.delete_all(record.name().clone(), origin.clone(), DNSClass::IN))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_rr_type(RecordType::AAAA);\n    record.set_data(Some(RData::AAAA(AAAA::new(1, 2, 3, 4, 5, 6, 7, 8))));\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = io_loop\n        .block_on(client.delete_all(record.name().clone(), origin, DNSClass::IN))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(record.name().clone(), record.dns_class(), RecordType::A))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n\n    let result = io_loop\n        .block_on(client.query(record.name().clone(), record.dns_class(), RecordType::AAAA))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n}"}
{"code": "fn stream_safe(s: &str) -> String {\n        StreamSafe::new(s.chars()).collect()\n    }", "test": "fn test_normalization_tests_unaffected() {\n    for test in NORMALIZATION_TESTS {\n        for &s in &[test.source, test.nfc, test.nfd, test.nfkc, test.nfkd] {\n            assert_eq!(stream_safe(s), s);\n        }\n    }\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn table_growth_failure() -> Result<()> {\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"-Wtrap-on-grow-failure\",\n            \"tests/all/cli_tests/table-grow-failure.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n    let stderr = String::from_utf8_lossy(&output.stderr);\n    assert!(\n        stderr.contains(\"forcing trap when growing table\"),\n        \"bad stderr: {stderr}\"\n    );\n    Ok(())\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn filter_on_array_literal_works() {\n    let mut context = Context::new();\n    let i: Option<usize> = None;\n    context.insert(\"existing\", \"hello\");\n    context.insert(\"null\", &i);\n\n    let inputs = vec![\n        (r#\"{{ [1, 2, 3] | length }}\"#, \"3\"),\n        (r#\"{% set a = [1, 2, 3] | length %}{{ a }}\"#, \"3\"),\n        (r#\"{% for a in [1, 2, 3] | slice(start=1) %}{{ a }}{% endfor %}\"#, \"23\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_empty_directory_verbose() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_empty_directory_verbose\";\n\n    at.mkdir(dir);\n\n    ucmd.arg(\"-d\")\n        .arg(\"-v\")\n        .arg(dir)\n        .succeeds()\n        .stdout_only(format!(\"removed directory '{dir}'\\n\"));\n\n    assert!(!at.dir_exists(dir));\n}"}
{"code": "fn ceil_divmod(self, y: Self) -> (Self, i32) {\n        let q = self / y;\n        let r = self % y;\n        match r == Self::ZERO {\n            true  => (q, i32::as_cast(r)),\n            false => (q + Self::ONE, i32::as_cast(r) - i32::as_cast(y))\n        }\n    }", "test": "fn ceil_divmod_test() {\n    use lexical_util::num::Integer;\n\n    assert_eq!(5usize.ceil_divmod(7), (1, -2));\n    assert_eq!(0usize.ceil_divmod(7), (0, 0));\n    assert_eq!(35usize.ceil_divmod(7), (5, 0));\n    assert_eq!(36usize.ceil_divmod(7), (6, -6));\n}"}
{"code": "pub fn i32(val: i32) -> Self {\n        Self::I32(val as u32)\n    }", "test": "fn mutability() -> anyhow::Result<()> {\n    let mut store = Store::<()>::default();\n    let g = Global::new(\n        &mut store,\n        GlobalType::new(ValType::I32, Mutability::Var),\n        0.into(),\n    )?;\n    assert_eq!(g.get(&mut store).i32(), Some(0));\n    g.set(&mut store, 1.into())?;\n    assert_eq!(g.get(&mut store).i32(), Some(1));\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.buf.get_ref().len()\n    }", "test": "fn test_something() {\n    let data = [];\n    let len = data.buf.len();\n    let supported_versions = DEFAULT_SUPPORTED_VERSIONS.to_vec();\n    if let Ok(decoded) = PartialDecode::new(\n        data.buf,\n        data.local_cid_len,\n        &supported_versions,\n        data.grease_quic_bit,\n    ) {\n        match decoded.1 {\n            Some(x) => assert_eq!(len, decoded.0.len() + x.len()),\n            None => assert_eq!(len, decoded.0.len()),\n        }\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn line_width_parse_errors_negative() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([\"format\", \"--line-width=-1\", \"file.js\"].as_slice()),\n    );\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"line_width_parse_errors_negative\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn range_query() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(SLICE_U64_TABLE).unwrap();\n        for i in 0..5 {\n            table.insert(b\"0\".as_slice(), &i).unwrap();\n        }\n        for i in 5..10 {\n            table.insert(b\"1\".as_slice(), &i).unwrap();\n        }\n        for i in 10..15 {\n            table.insert(b\"2\".as_slice(), &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(SLICE_U64_TABLE).unwrap();\n    let start = b\"0\".as_ref();\n    let end = b\"1\".as_ref();\n    let mut iter = table.range(start..=end).unwrap();\n\n    {\n        let (key, mut values) = iter.next().unwrap().unwrap();\n        for i in 0..5 {\n            assert_eq!(b\"0\", key.value());\n            let value = values.next().unwrap().unwrap();\n            assert_eq!(i, value.value());\n        }\n    }\n    {\n        let (key, mut values) = iter.next().unwrap().unwrap();\n        for i in 5..10 {\n            assert_eq!(b\"1\", key.value());\n            let value = values.next().unwrap().unwrap();\n            assert_eq!(i, value.value());\n        }\n    }\n    assert!(iter.next().is_none());\n\n    let mut total: u64 = 0;\n    for item in table.range(start..=end).unwrap() {\n        let (_, values) = item.unwrap();\n        total += values.map(|x| x.unwrap().value()).sum::<u64>();\n    }\n    assert_eq!(total, 45);\n}"}
{"code": "pub fn as_bytes(&self) -> Option<BytesRef<'_>> {\n        EvaluableRef::borrow_scalar_value(self)\n    }", "test": "fn test_write_update_to_file() {\n    let (mut cfg, tmp_dir) = TikvConfig::with_tmp().unwrap();\n    cfg.cfg_path = tmp_dir.path().join(\"cfg_file\").to_str().unwrap().to_owned();\n    {\n        let c = r#\"\n## comment should be reserve\n[raftstore]\n\n# config that comment out by one `#` should be update in place\n## pd-heartbeat-tick-interval = \"30s\"\n# pd-heartbeat-tick-interval = \"30s\"\n\n[rocksdb.defaultcf]\n## config should be update in place\nblock-cache-size = \"10GB\"\n\n[rocksdb.lockcf]\n## this config will not update even it has the same last \n## name as `rocksdb.defaultcf.block-cache-size`\nblock-cache-size = \"512MB\"\n\n[coprocessor]\n## the update to `coprocessor.region-split-keys`, which do not show up \n## as key-value pair after [coprocessor], will be written at the end of [coprocessor]\n\n[gc]\n## config should be update in place\nmax-write-bytes-per-sec = \"1KB\"\n\n[rocksdb.defaultcf.titan]\nblob-run-mode = \"normal\"\n\"#;\n        let mut f = File::create(&cfg.cfg_path).unwrap();\n        f.write_all(c.as_bytes()).unwrap();\n        f.sync_all().unwrap();\n    }\n    let cfg_controller = ConfigController::new(cfg);\n    let change = {\n        let mut change = HashMap::new();\n        change.insert(\n            \"raftstore.pd-heartbeat-tick-interval\".to_owned(),\n            \"1h\".to_owned(),\n        );\n        change.insert(\n            \"coprocessor.region-split-keys\".to_owned(),\n            \"10000\".to_owned(),\n        );\n        change.insert(\"gc.max-write-bytes-per-sec\".to_owned(), \"100MB\".to_owned());\n        change.insert(\n            \"rocksdb.defaultcf.block-cache-size\".to_owned(),\n            \"1GB\".to_owned(),\n        );\n        change.insert(\n            \"rocksdb.defaultcf.titan.blob-run-mode\".to_owned(),\n            \"read-only\".to_owned(),\n        );\n        change\n    };\n    cfg_controller.update(change).unwrap();\n    let res = {\n        let mut buf = Vec::new();\n        let mut f = File::open(cfg_controller.get_current().cfg_path).unwrap();\n        f.read_to_end(&mut buf).unwrap();\n        buf\n    };\n\n    let expect = r#\"\n## comment should be reserve\n[raftstore]\n\n# config that comment out by one `#` should be update in place\n## pd-heartbeat-tick-interval = \"30s\"\npd-heartbeat-tick-interval = \"1h\"\n\n[rocksdb.defaultcf]\n## config should be update in place\nblock-cache-size = \"1GB\"\n\n[rocksdb.lockcf]\n## this config will not update even it has the same last \n## name as `rocksdb.defaultcf.block-cache-size`\nblock-cache-size = \"512MB\"\n\n[coprocessor]\n## the update to `coprocessor.region-split-keys`, which do not show up \n## as key-value pair after [coprocessor], will be written at the end of [coprocessor]\n\nregion-split-keys = 10000\n[gc]\n## config should be update in place\nmax-write-bytes-per-sec = \"100MB\"\n\n[rocksdb.defaultcf.titan]\nblob-run-mode = \"read-only\"\n\"#;\n    assert_eq!(expect.as_bytes(), res.as_slice());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_existing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=existing\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn fs_error_unknown() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert_error(PathBuf::from(\"prefix/ci.js\"), ErrorEntry::UnknownFileType);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), (\"prefix\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"fs_error_unknown\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn to_vec(self) -> Vec<u8> {\n        self.0.to_vec()\n    }", "test": "fn artifact_deserialization_roundtrip() {\n    // This test is included to make sure we don't break the serialized format\n    // by mistake. Otherwise, everything in this test is already tested in\n    // `artifact_serialization_roundtrip`.\n    let file_names = [\"bash.wasmu\", \"cowsay.wasmu\", \"python-3.11.3.wasmu\"];\n\n    cfg_if!(\n        if #[cfg(target_os = \"windows\")] {\n            let base_path = \"tests/compilers/wasmu/windows\";\n        } else {\n            let base_path = \"tests/compilers/wasmu/linux\";\n        }\n    );\n\n    for file_name in file_names {\n        let path = PathBuf::from(base_path).join(file_name);\n        let wasm_module_bytes = fs::read(path).unwrap();\n        let engine = Engine::default();\n        let module = unsafe { Module::deserialize(&engine, wasm_module_bytes.clone()) }.unwrap();\n        let reserialized_bytes = module.serialize().unwrap();\n        assert_eq!(wasm_module_bytes.to_vec(), reserialized_bytes);\n    }\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_deadline_2() {\n    // It should not even take any snapshots when request is outdated from the\n    // beginning.\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"rockskv_async_snapshot\", \"panic\").unwrap();\n    fail::cfg(\"deadline_check_fail\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"exceeding the deadline\"));\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn test_anyhow_error_return() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let wat = r#\"\n        (module\n        (func $hello (import \"\" \"hello\"))\n        (func (export \"run\") (call $hello))\n        )\n    \"#;\n\n    let module = Module::new(store.engine(), wat)?;\n    let hello_type = FuncType::new(None, None);\n    let hello_func = Func::new(&mut store, hello_type, |_, _, _| {\n        Err(anyhow::Error::msg(\"test 1234\"))\n    });\n\n    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;\n    let run_func = instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n\n    let e = run_func.call(&mut store, ()).unwrap_err();\n    assert!(!e.to_string().contains(\"test 1234\"));\n    assert!(format!(\"{:?}\", e).contains(\"Caused by:\\n    test 1234\"));\n\n    assert!(e.downcast_ref::<Trap>().is_none());\n    assert!(e.downcast_ref::<WasmBacktrace>().is_some());\n\n    Ok(())\n}"}
{"code": "fn pretty(f: f64) -> String {\n    ryu::Buffer::new().format(f).to_owned()\n}", "test": "fn test_basic() {\n    check!(0.0);\n    check!(-0.0);\n    check!(1.0);\n    check!(-1.0);\n    assert_eq!(pretty(f64::NAN), \"NaN\");\n    assert_eq!(pretty(f64::INFINITY), \"inf\");\n    assert_eq!(pretty(f64::NEG_INFINITY), \"-inf\");\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn closed_streams_are_released() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::get(\"https://example.com/\").body(()).unwrap();\n\n        // Send request\n        let (response, _) = client.send_request(request, true).unwrap();\n        let response = h2.drive(response).await.unwrap();\n        assert_eq!(response.status(), StatusCode::NO_CONTENT);\n\n        // There are no active streams\n        assert_eq!(0, client.num_active_streams());\n\n        // The response contains a handle for the body. This keeps the\n        // stream wired.\n        assert_eq!(1, client.num_wired_streams());\n\n        let (_, body) = response.into_parts();\n        assert!(body.is_end_stream());\n        drop(body);\n\n        // The stream state is now free\n        assert_eq!(0, client.num_wired_streams());\n    };\n\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_default_settings!(settings);\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://example.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(frames::headers(1).response(204).eos()).await;\n    };\n    join(srv, h2).await;\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_create() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert_eq!(result.answers()[0], record);\n\n    // trying to create again should error\n    // TODO: it would be cool to make this\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n\n    // will fail if already set and not the same value.\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n\n    let result = client.create(record, origin).expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::YXRRSet);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_multi_2() {\n    let mut headers = HeaderMap::new();\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 2);\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_semicolon_line_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--line-bytes=4\", \"-t\", \";\", \"separator_semicolon.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1;2;\");\n    assert_eq!(file_read(&at, \"xab\"), \"3;4;\");\n    assert_eq!(file_read(&at, \"xac\"), \"5;\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn test_attributes_empty() {\n    let src = \"<a att1='a' att2='b'/>\";\n    let mut r = Reader::from_str(src);\n    r.trim_text(true);\n    match r.read_event() {\n        Ok(Empty(e)) => {\n            let mut attrs = e.attributes();\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"att1\"),\n                    value: Cow::Borrowed(b\"a\"),\n                }))\n            );\n            assert_eq!(\n                attrs.next(),\n                Some(Ok(Attribute {\n                    key: QName(b\"att2\"),\n                    value: Cow::Borrowed(b\"b\"),\n                }))\n            );\n            assert_eq!(attrs.next(), None);\n        }\n        e => panic!(\"Expecting Empty event, got {:?}\", e),\n    }\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn cap_two() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch_with_cap(2);\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.put(b\"f\", b\"\").unwrap();\n    wb.write().unwrap();\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"f\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(2);\n\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n    wb.put(b\"b\", b\"\").unwrap();\n    wb.put(b\"c\", b\"\").unwrap();\n    wb.put(b\"d\", b\"\").unwrap();\n    wb.put(b\"e\", b\"\").unwrap();\n    wb.put(b\"f\", b\"\").unwrap();\n    wb.write().unwrap();\n    assert!(\n        db.engine\n            .get_value(&0_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(\n        db.engine\n            .get_value(&123_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(\n        db.engine\n            .get_value(&255_usize.to_be_bytes())\n            .unwrap()\n            .is_some()\n    );\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"f\").unwrap().is_some());\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn loop_interrupt_from_afar() -> anyhow::Result<()> {\n    // Create an instance which calls an imported function on each iteration of\n    // the loop so we can count the number of loop iterations we've executed so\n    // far.\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n    static STOP: AtomicBool = AtomicBool::new(false);\n    let mut store = interruptable_store();\n    let module = Module::new(\n        store.engine(),\n        r#\"\n            (import \"\" \"\" (func))\n\n            (func (export \"loop\")\n                (loop\n                    call 0\n                    br 0)\n            )\n        \"#,\n    )?;\n    let func = Func::wrap(&mut store, || {\n        HITS.fetch_add(1, SeqCst);\n    });\n    let instance = Instance::new(&mut store, &module, &[func.into()])?;\n\n    // Use the engine to wait for it to enter the loop long enough and then we\n    // signal an interrupt happens.\n    let engine = store.engine().clone();\n    let thread = std::thread::spawn(move || {\n        while HITS.load(SeqCst) <= NUM_HITS && !STOP.load(SeqCst) {\n            // continue ...\n        }\n        println!(\"interrupting\");\n        engine.increment_epoch();\n    });\n\n    // Enter the infinitely looping function and assert that our interrupt\n    // handle does indeed actually interrupt the function.\n    let iloop = instance.get_typed_func::<(), ()>(&mut store, \"loop\")?;\n    let trap = iloop.call(&mut store, ()).unwrap_err().downcast::<Trap>()?;\n    STOP.store(true, SeqCst);\n    thread.join().unwrap();\n    assert!(HITS.load(SeqCst) > NUM_HITS);\n    assert_eq!(trap, Trap::Interrupt);\n    Ok(())\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn dont_see_stale_stack_walking_registers() -> Result<()> {\n    let engine = Engine::default();\n\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (import \"\" \"host_start\" (func $host_start))\n                (import \"\" \"host_get_trap\" (func $host_get_trap))\n                (export \"get_trap\" (func $host_get_trap))\n\n                ;; We enter and exit Wasm, which saves registers in the\n                ;; `VMRuntimeLimits`. Later, when we call a re-exported host\n                ;; function, we should not accidentally reuse those saved\n                ;; registers.\n                (start $start)\n                (func $start\n                    (call $host_start)\n                )\n            )\n        \"#,\n    )?;\n\n    let mut store = Store::new(&engine, ());\n    let mut linker = Linker::new(&engine);\n\n    let host_start = Func::new(\n        &mut store,\n        FuncType::new([], []),\n        |_caller, _args, _results| Ok(()),\n    );\n    linker.define(&store, \"\", \"host_start\", host_start)?;\n\n    let host_get_trap = Func::new(\n        &mut store,\n        FuncType::new([], []),\n        |_caller, _args, _results| Err(anyhow::anyhow!(\"trap!!!\")),\n    );\n    linker.define(&store, \"\", \"host_get_trap\", host_get_trap)?;\n\n    let instance = linker.instantiate(&mut store, &module)?;\n    let get_trap = instance.get_func(&mut store, \"get_trap\").unwrap();\n\n    let err = get_trap.call(&mut store, &[], &mut []).unwrap_err();\n    assert!(err.to_string().contains(\"trap!!!\"));\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_unlink_symlink() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.touch(\"foo\");\n    at.symlink_file(\"foo\", \"bar\");\n\n    ucmd.arg(\"bar\").succeeds().no_stderr();\n\n    assert!(at.file_exists(\"foo\"));\n    assert!(!at.file_exists(\"bar\"));\n}"}
{"code": "fn get_term(&self) -> Option<NonZeroU64> {\n        self.snapshot.term\n    }", "test": "fn test_pending_snapshot() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_snapshot(&mut cluster.cfg);\n    let election_timeout = configure_for_lease_read(&mut cluster.cfg, None, Some(15));\n    let gc_limit = cluster.cfg.raft_store.raft_log_gc_count_limit();\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);\n\n    let handle_snapshot_fp = \"apply_on_handle_snapshot_1_1\";\n    let handle_snapshot_finish_fp = \"apply_on_handle_snapshot_finish_1_1\";\n    fail::cfg(\"apply_on_handle_snapshot_sync\", \"return\").unwrap();\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer count check.\n    pd_client.disable_default_operator();\n\n    let region_id = cluster.run_conf_change();\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n    cluster.must_transfer_leader(region_id, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    fail::cfg(handle_snapshot_fp, \"pause\").unwrap();\n    pd_client.must_add_peer(region_id, new_peer(3, 3));\n    // Give some time for peer 3 to request snapshot.\n    sleep_ms(100);\n\n    // Isolate peer 1 from rest of the cluster.\n    cluster.add_send_filter(IsolationFilterFactory::new(1));\n\n    sleep_ms((election_timeout.as_millis() * 2) as _);\n    cluster.reset_leader_of_region(region_id);\n    // Compact logs to force requesting snapshot after clearing send filters.\n    let state2 = cluster.truncated_state(1, 2);\n    for i in 1..gc_limit * 10 {\n        let k = i.to_string().into_bytes();\n        cluster.must_put(&k, &k.clone());\n    }\n    cluster.wait_log_truncated(1, 2, state2.get_index() + 5 * gc_limit);\n\n    // Make sure peer 1 has applied snapshot.\n    cluster.clear_send_filters();\n    let start = Instant::now();\n    loop {\n        if cluster.pd_client.get_pending_peers().get(&1).is_none()\n            || start.saturating_elapsed() > election_timeout * 10\n        {\n            break;\n        }\n        sleep_ms(50);\n    }\n    let state1 = cluster.truncated_state(1, 1);\n\n    // Peer 2 continues to handle snapshot.\n    fail::cfg(handle_snapshot_finish_fp, \"pause\").unwrap();\n    fail::remove(handle_snapshot_fp);\n    sleep_ms(200);\n    let state2 = cluster.truncated_state(1, 1);\n    fail::remove(handle_snapshot_finish_fp);\n    assert!(\n        state1.get_term() <= state2.get_term(),\n        \"{:?} {:?}\",\n        state1,\n        state2\n    );\n    assert!(\n        state1.get_index() <= state2.get_index(),\n        \"{:?} {:?}\",\n        state1,\n        state2\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_parents_multiple_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--parents\")\n        .arg(TEST_COPY_FROM_FOLDER_FILE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds();\n\n    assert_eq!(\n        at.read(&format!(\n            \"{TEST_COPY_TO_FOLDER}/{TEST_COPY_FROM_FOLDER_FILE}\"\n        )),\n        \"Hello, World!\\n\"\n    );\n    assert_eq!(\n        at.read(&format!(\"{TEST_COPY_TO_FOLDER}/{TEST_HOW_ARE_YOU_SOURCE}\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "fn nested_many_instantiations() -> Result<()> {\n    let component = r#\"\n(component\n  (import \"count\" (func $count))\n  (component $c1\n    (import \"count\" (func $count))\n    (core func $count_lower (canon lower (func $count)))\n    (core module $m\n        (import \"\" \"\" (func $count))\n        (start $count)\n    )\n    (core instance (instantiate $m (with \"\" (instance (export \"\" (func $count_lower))))))\n    (core instance (instantiate $m (with \"\" (instance (export \"\" (func $count_lower))))))\n  )\n  (component $c2\n    (import \"count\" (func $count))\n    (instance (instantiate $c1 (with \"count\" (func $count))))\n    (instance (instantiate $c1 (with \"count\" (func $count))))\n  )\n  (component $c3\n    (import \"count\" (func $count))\n    (instance (instantiate $c2 (with \"count\" (func $count))))\n    (instance (instantiate $c2 (with \"count\" (func $count))))\n  )\n  (component $c4\n    (import \"count\" (func $count))\n    (instance (instantiate $c3 (with \"count\" (func $count))))\n    (instance (instantiate $c3 (with \"count\" (func $count))))\n  )\n\n  (instance (instantiate $c4 (with \"count\" (func $count))))\n)\n    \"#;\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, 0);\n    let mut linker = Linker::new(&engine);\n    linker\n        .root()\n        .func_wrap(\"count\", |mut store: StoreContextMut<'_, u32>, _: ()| {\n            *store.data_mut() += 1;\n            Ok(())\n        })?;\n    linker.instantiate(&mut store, &component)?;\n    assert_eq!(*store.data(), 16);\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_new_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let filename = \"new_file_that_does_not_exist_yet\";\n    ucmd.args(&[\"-s\", \"8\", filename])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert!(at.file_exists(filename));\n    assert_eq!(at.read_bytes(filename), vec![b'\\0'; 8]);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_link_existing_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_link_existing_file\";\n    let link = \"test_link_existing_file_link\";\n\n    at.touch(file);\n    at.write(file, \"foobar\");\n    assert!(at.file_exists(file));\n\n    ucmd.args(&[file, link]).succeeds().no_stderr();\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(link));\n    assert_eq!(at.read(file), at.read(link));\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn recv_window_update_on_stream_closed_by_data_frame() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let h2 = async move {\n        let (mut client, mut h2) = client::handshake(io).await.unwrap();\n        let request = Request::builder()\n            .method(Method::POST)\n            .uri(\"https://http2.akamai.com/\")\n            .body(())\n            .unwrap();\n\n        let (response, mut stream) = client.send_request(request, false).unwrap();\n\n        // Wait for the response\n        let response = h2.drive(response).await.unwrap();\n        assert_eq!(response.status(), StatusCode::OK);\n\n        // Send a data frame, this will also close the connection\n        stream.send_data(\"hello\".into(), true).unwrap();\n\n        // keep `stream` from being dropped in order to prevent\n        // it from sending an RST_STREAM frame.\n        //\n        // i know this is kind of evil, but it's necessary to\n        // ensure that the stream is closed by the EOS frame,\n        // and not by the RST_STREAM.\n        std::mem::forget(stream);\n\n        // Wait for the connection to close\n        h2.await.unwrap();\n    };\n    let srv = async move {\n        let settings = srv.assert_client_handshake().await;\n        assert_default_settings!(settings);\n        srv.recv_frame(frames::headers(1).request(\"POST\", \"https://http2.akamai.com/\"))\n            .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.recv_frame(frames::data(1, \"hello\").eos()).await;\n        srv.send_frame(frames::window_update(1, 5)).await;\n    };\n    join(srv, h2).await;\n}"}
{"code": "pub fn get_id(&self) -> ConnId {\n        self.id\n    }", "test": "fn test_source_peer_read_delegate_after_apply() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.run();\n\n    cluster.must_split(&cluster.get_region(b\"\"), b\"k2\");\n    let target = cluster.get_region(b\"k1\");\n    let source = cluster.get_region(b\"k3\");\n\n    cluster.must_transfer_leader(target.get_id(), find_peer(&target, 1).unwrap().to_owned());\n\n    let on_destroy_peer_fp = \"destroy_peer\";\n    fail::cfg(on_destroy_peer_fp, \"pause\").unwrap();\n\n    // Merge finish means the leader of the target region have call\n    // `on_ready_commit_merge`\n    pd_client.must_merge(source.get_id(), target.get_id());\n\n    // The source peer's `ReadDelegate` should not be removed yet and mark as\n    // `pending_remove`\n    assert!(\n        cluster.store_metas[&1]\n            .lock()\n            .unwrap()\n            .readers\n            .get(&source.get_id())\n            .unwrap()\n            .pending_remove\n    );\n\n    fail::remove(on_destroy_peer_fp);\n    // Wait for source peer is destroyed\n    sleep_ms(100);\n\n    assert!(\n        cluster.store_metas[&1]\n            .lock()\n            .unwrap()\n            .readers\n            .get(&source.get_id())\n            .is_none()\n    );\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_migrate_replication_mode() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.pd_client.disable_default_operator();\n    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(50);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 10;\n    cluster.add_label(1, \"zone\", \"ES\");\n    cluster.add_label(2, \"zone\", \"ES\");\n    cluster.add_label(3, \"zone\", \"WS\");\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.add_send_filter(IsolationFilterFactory::new(2));\n    cluster.must_put(b\"k1\", b\"v0\");\n    // Non exists label key can't tolerate any node unavailable.\n    cluster.pd_client.configure_dr_auto_sync(\"host\");\n    thread::sleep(Duration::from_millis(100));\n    let region = cluster.get_region(b\"k1\");\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_put_cf_cmd(\"default\", b\"k2\", b\"v2\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(100)),\n        Err(future::RecvTimeoutError::Timeout)\n    );\n    must_get_none(&cluster.get_engine(1), b\"k2\");\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 1);\n    assert_eq!(state.state, RegionReplicationState::SimpleMajority);\n\n    // Correct label key should resume committing log\n    cluster.pd_client.configure_dr_auto_sync(\"zone\");\n    rx.recv_timeout(Duration::from_millis(100)).unwrap();\n    must_get_equal(&cluster.get_engine(1), b\"k2\", b\"v2\");\n    thread::sleep(Duration::from_millis(100));\n    let state = cluster.pd_client.region_replication_status(region.get_id());\n    assert_eq!(state.state_id, 2);\n    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);\n}"}
{"code": "pub(crate) fn poll(&mut self) -> Option<StreamEvent> {\n        if let Some(dir) = Dir::iter().find(|&i| mem::replace(&mut self.opened[i as usize], false))\n        {\n            return Some(StreamEvent::Opened { dir });\n        }\n\n        if self.write_limit() > 0 {\n            while let Some(id) = self.connection_blocked.pop() {\n                let stream = match self.send.get_mut(&id) {\n                    None => continue,\n                    Some(s) => s,\n                };\n\n                debug_assert!(stream.connection_blocked);\n                stream.connection_blocked = false;\n\n                // If it's no longer sensible to write to a stream (even to detect an error) then don't\n                // report it.\n                if stream.is_writable() && stream.max_data > stream.offset() {\n                    return Some(StreamEvent::Writable { id });\n                }\n            }\n        }\n\n        self.events.pop_front()\n    }", "test": "fn version_negotiate_client() {\n    let _guard = subscribe();\n    let server_addr = \"[::2]:7890\".parse().unwrap();\n    let cid_generator_factory: fn() -> Box<dyn ConnectionIdGenerator> =\n        || Box::new(RandomConnectionIdGenerator::new(0));\n    let mut client = Endpoint::new(\n        Arc::new(EndpointConfig {\n            connection_id_generator_factory: Arc::new(cid_generator_factory),\n            ..Default::default()\n        }),\n        None,\n        true,\n    );\n    let (_, mut client_ch) = client\n        .connect(client_config(), server_addr, \"localhost\")\n        .unwrap();\n    let now = Instant::now();\n    let opt_event = client.handle(\n        now,\n        server_addr,\n        None,\n        None,\n        // Version negotiation packet for reserved version\n        hex!(\n            \"80 00000000 04 00000000 04 00000000\n             0a1a2a3a\"\n        )[..]\n            .into(),\n    );\n    if let Some((_, DatagramEvent::ConnectionEvent(event))) = opt_event {\n        client_ch.handle_event(event);\n    }\n    assert_matches!(\n        client_ch.poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::VersionMismatch,\n        })\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_move_file_between_dirs() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir1 = \"test_mv_move_file_between_dirs_dir1\";\n    let dir2 = \"test_mv_move_file_between_dirs_dir2\";\n    let file = \"test_mv_move_file_between_dirs_file\";\n\n    at.mkdir(dir1);\n    at.mkdir(dir2);\n    at.touch(format!(\"{dir1}/{file}\"));\n\n    assert!(at.file_exists(format!(\"{dir1}/{file}\")));\n\n    ucmd.arg(&format!(\"{dir1}/{file}\"))\n        .arg(dir2)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(format!(\"{dir1}/{file}\")));\n    assert!(at.file_exists(format!(\"{dir2}/{file}\")));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_dangling_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_symlink_dangling_file\";\n    let link = \"test_symlink_dangling_file_link\";\n\n    ucmd.args(&[\"-s\", file, link]).succeeds().no_stderr();\n    assert!(!at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_simple() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup=simple\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn instant_close_2() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    info!(\"connecting\");\n    let client_ch = pair.begin_connect(client_config());\n    // Unlike `instant_close`, the server sees a valid Initial packet first.\n    pair.drive_client();\n    pair.client\n        .connections\n        .get_mut(&client_ch)\n        .unwrap()\n        .close(pair.time, VarInt(42), Bytes::new());\n    pair.drive();\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::ConnectionLost {\n            reason: ConnectionError::ConnectionClosed(ConnectionClose {\n                error_code: TransportErrorCode::APPLICATION_ERROR,\n                ..\n            }),\n        })\n    );\n}"}
{"code": "fn factor(i: &str) -> IResult<&str, Expr> {\n  alt((\n    map(\n      map_res(delimited(multispace, digit, multispace), FromStr::from_str),\n      Expr::Value,\n    ),\n    parens,\n  ))(i)\n}", "test": "fn factor_test() {\n  assert_eq!(factor(\"3\"), Ok((\"\", 3)));\n  assert_eq!(factor(\" 12\"), Ok((\"\", 12)));\n  assert_eq!(factor(\"537  \"), Ok((\"\", 537)));\n  assert_eq!(factor(\"  24   \"), Ok((\"\", 24)));\n}"}
{"code": "pub fn verified_stmt(&self, sql: &str) -> Statement {\n        self.one_statement_parses_to(sql, sql)\n    }", "test": "fn parse_create_procedure() {\n    let sql = \"CREATE OR ALTER PROCEDURE test (@foo INT, @bar VARCHAR(256)) AS BEGIN SELECT 1 END\";\n\n    assert_eq!(\n        ms().verified_stmt(sql),\n        Statement::CreateProcedure {\n            or_alter: true,\n            body: vec![Statement::Query(Box::new(Query {\n                with: None,\n                limit: None,\n                limit_by: vec![],\n                offset: None,\n                fetch: None,\n                locks: vec![],\n                order_by: vec![],\n                body: Box::new(SetExpr::Select(Box::new(Select {\n                    distinct: None,\n                    top: None,\n                    projection: vec![SelectItem::UnnamedExpr(Expr::Value(number(\"1\")))],\n                    into: None,\n                    from: vec![],\n                    lateral_views: vec![],\n                    selection: None,\n                    group_by: GroupByExpr::Expressions(vec![]),\n                    cluster_by: vec![],\n                    distribute_by: vec![],\n                    sort_by: vec![],\n                    having: None,\n                    named_window: vec![],\n                    qualify: None\n                })))\n            }))],\n            params: Some(vec![\n                ProcedureParam {\n                    name: Ident {\n                        value: \"@foo\".into(),\n                        quote_style: None\n                    },\n                    data_type: DataType::Int(None)\n                },\n                ProcedureParam {\n                    name: Ident {\n                        value: \"@bar\".into(),\n                        quote_style: None\n                    },\n                    data_type: DataType::Varchar(Some(CharacterLength {\n                        length: 256,\n                        unit: None\n                    }))\n                }\n            ]),\n            name: ObjectName(vec![Ident {\n                value: \"test\".into(),\n                quote_style: None\n            }])\n        }\n    )\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_parse_request_failed_2() {\n    // It should not even take any snapshots when parse failed.\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &[]);\n    let req = DagSelect::from(&product).build();\n\n    fail::cfg(\"rockskv_async_snapshot\", \"panic\").unwrap();\n    fail::cfg(\"coprocessor_parse_request\", \"return()\").unwrap();\n    let resp = handle_request(&endpoint, req);\n\n    assert!(resp.get_other_error().contains(\"unsupported tp\"));\n}"}
{"code": "pub fn to_string_with_root<T>(root_tag: &str, value: &T) -> Result<String, DeError>\nwhere\n    T: ?Sized + Serialize,\n{\n    let mut buffer = String::new();\n    to_writer_with_root(&mut buffer, root_tag, value)?;\n    Ok(buffer)\n}", "test": "fn issue540() {\n    #[derive(Serialize)]\n    pub enum Enum {\n        Variant {},\n    }\n\n    #[derive(Serialize)]\n    pub struct Struct {\n        #[serde(flatten)]\n        flatten: Enum,\n    }\n\n    assert_eq!(\n        to_string_with_root(\n            \"root\",\n            &Struct {\n                flatten: Enum::Variant {},\n            }\n        )\n        .unwrap(),\n        \"<root><Variant/></root>\"\n    );\n}"}
{"code": "fn expr(input: &[u8]) -> IResult<&[u8], i64> {\n  let (input, init) = term(input)?;\n  fold_many0(\n    pair(one_of(\"+-\"), term),\n    move || init,\n    |acc, (op, val)| {\n      if op == '+' {\n        acc + val\n      } else {\n        acc - val\n      }\n    },\n  )(input)\n}", "test": "fn parens_test() {\n  assert_eq!(expr(\" (  2 )\"), Ok((\"\", 2)));\n  assert_eq!(expr(\" 2* (  3 + 4 ) \"), Ok((\"\", 14)));\n  assert_eq!(expr(\"  2*2 / ( 5 - 1) + 3\"), Ok((\"\", 4)));\n}"}
{"code": "pub const fn start(self) -> TextSize {\n        self.start\n    }", "test": "fn extract_elif_else_range() -> Result<(), ParseError> {\n    let contents = \"if a:\n    ...\nelif b:\n    ...\n\";\n    let mut stmts = parse_suite(contents, \"<filename>\")?;\n    let stmt = stmts\n        .pop()\n        .and_then(ruff_python_ast::Stmt::if_stmt)\n        .unwrap();\n    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();\n    assert_eq!(range.start(), TextSize::from(14));\n    assert_eq!(range.end(), TextSize::from(18));\n\n    let contents = \"if a:\n    ...\nelse:\n    ...\n\";\n    let mut stmts = parse_suite(contents, \"<filename>\")?;\n    let stmt = stmts\n        .pop()\n        .and_then(ruff_python_ast::Stmt::if_stmt)\n        .unwrap();\n    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();\n    assert_eq!(range.start(), TextSize::from(14));\n    assert_eq!(range.end(), TextSize::from(18));\n\n    Ok(())\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.header.response_code()\n    }", "test": "fn test_nxdomain_where_no_name_exists() {\n    named_test_harness(\"example.toml\", |_, tcp_port, _, _, _| {\n        let io_loop = Runtime::new().unwrap();\n        let addr: SocketAddr = SocketAddr::new(\n            Ipv4Addr::new(127, 0, 0, 1).into(),\n            tcp_port.expect(\"no tcp_port\"),\n        );\n        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);\n        let client = AsyncClient::new(Box::new(stream), sender, None);\n        let (mut client, bg) = io_loop.block_on(client).expect(\"client failed to connect\");\n        hickory_proto::spawn_bg(&io_loop, bg);\n\n        let msg = io_loop\n            .block_on(client.query(\n                Name::from_str(\"nxdomain.example.com.\").unwrap(),\n                DNSClass::IN,\n                RecordType::SRV,\n            ))\n            .unwrap();\n        assert_eq!(msg.response_code(), ResponseCode::NXDomain);\n        assert!(msg.answers().is_empty());\n    })\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_long_no_args_files() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_simple_backup_file_a\";\n    let file_b = \"test_install_simple_backup_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    scene\n        .ucmd()\n        .arg(\"--backup\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn tuple_type_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: TableDefinition<(&str, u8), (u16, u32)> = TableDefinition::new(\"table\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(table_def).unwrap();\n        table\n            .insert(&(String::from(\"hello\").as_str(), 5), &(0, 123))\n            .unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(table_def).unwrap();\n    assert_eq!(table.get(&(\"hello\", 5)).unwrap().unwrap().value(), (0, 123));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_existing_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_existing_dir\";\n    let link = \"test_symlink_existing_dir_link\";\n\n    at.mkdir(dir);\n\n    ucmd.args(&[\"-s\", dir, link]).succeeds().no_stderr();\n    assert!(at.dir_exists(dir));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), dir);\n}"}
{"code": "pub fn size(&self, store: impl AsContext) -> u64 {\n        self.internal_size(store.as_context().0)\n    }", "test": "fn test_multi_memory() -> Result<()> {\n    let wat = r#\"(module\n        (import \"env\" \"imported\" (memory $imported 5 10 shared))\n        (memory (export \"owned\") 10 20)\n        (memory (export \"shared\") 1 2 shared)\n        (export \"imported\" (memory $imported))\n    )\"#;\n    let mut config = Config::new();\n    config.wasm_threads(true);\n    config.wasm_multi_memory(true);\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, wat)?;\n    let mut store = Store::new(&engine, ());\n    let incoming_shared_memory = SharedMemory::new(&engine, MemoryType::shared(5, 10))?;\n    let instance = Instance::new(&mut store, &module, &[incoming_shared_memory.into()])?;\n    let owned_memory = instance.get_memory(&mut store, \"owned\").unwrap();\n    let shared_memory = instance.get_shared_memory(&mut store, \"shared\").unwrap();\n    let imported_memory = instance.get_shared_memory(&mut store, \"imported\").unwrap();\n\n    assert_eq!(owned_memory.size(&store), 10);\n    assert_eq!(owned_memory.ty(&store).minimum(), 10);\n    assert_eq!(owned_memory.ty(&store).maximum(), Some(20));\n    assert_eq!(owned_memory.ty(&store).is_shared(), false);\n    assert_eq!(shared_memory.size(), 1);\n    assert_eq!(shared_memory.ty().minimum(), 1);\n    assert_eq!(shared_memory.ty().maximum(), Some(2));\n    assert_eq!(shared_memory.ty().is_shared(), true);\n    assert_eq!(imported_memory.size(), 5);\n    assert_eq!(imported_memory.ty().minimum(), 5);\n    assert_eq!(imported_memory.ty().maximum(), Some(10));\n    assert_eq!(imported_memory.ty().is_shared(), true);\n\n    Ok(())\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_short_numeric_suffix_no_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-l\", \"9\", \"-d\", \"onehundredlines.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x00\"), \"00\\n01\\n02\\n03\\n04\\n05\\n06\\n07\\n08\\n\");\n    assert_eq!(at.read(\"x01\"), \"09\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n\");\n    assert_eq!(at.read(\"x02\"), \"18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n\");\n    assert_eq!(at.read(\"x03\"), \"27\\n28\\n29\\n30\\n31\\n32\\n33\\n34\\n35\\n\");\n    assert_eq!(at.read(\"x04\"), \"36\\n37\\n38\\n39\\n40\\n41\\n42\\n43\\n44\\n\");\n    assert_eq!(at.read(\"x05\"), \"45\\n46\\n47\\n48\\n49\\n50\\n51\\n52\\n53\\n\");\n    assert_eq!(at.read(\"x06\"), \"54\\n55\\n56\\n57\\n58\\n59\\n60\\n61\\n62\\n\");\n    assert_eq!(at.read(\"x07\"), \"63\\n64\\n65\\n66\\n67\\n68\\n69\\n70\\n71\\n\");\n    assert_eq!(at.read(\"x08\"), \"72\\n73\\n74\\n75\\n76\\n77\\n78\\n79\\n80\\n\");\n    assert_eq!(at.read(\"x09\"), \"81\\n82\\n83\\n84\\n85\\n86\\n87\\n88\\n89\\n\");\n    assert_eq!(at.read(\"x10\"), \"90\\n91\\n92\\n93\\n94\\n95\\n96\\n97\\n98\\n\");\n    assert_eq!(at.read(\"x11\"), \"99\\n\");\n}"}
{"code": "pub fn leader_of_region(&mut self, region_id: u64) -> Option<metapb::Peer> {\n        let timer = Instant::now_coarse();\n        let timeout = Duration::from_secs(5);\n        let mut store_ids = None;\n        while timer.saturating_elapsed() < timeout {\n            match self.voter_store_ids_of_region(region_id) {\n                None => thread::sleep(Duration::from_millis(10)),\n                Some(ids) => {\n                    store_ids = Some(ids);\n                    break;\n                }\n            }\n        }\n        let store_ids = store_ids?;\n        if let Some(l) = self.leaders.get(&region_id) {\n            // leader may be stopped in some tests.\n            if self.valid_leader_id(region_id, l.get_store_id()) {\n                return Some(l.clone());\n            }\n        }\n        self.reset_leader_of_region(region_id);\n        let mut leader = None;\n        let mut leaders = HashMap::default();\n\n        let node_ids = self.sim.rl().get_node_ids();\n        // For some tests, we stop the node but pd still has this information,\n        // and we must skip this.\n        let alive_store_ids: Vec<_> = store_ids\n            .iter()\n            .filter(|id| node_ids.contains(id))\n            .cloned()\n            .collect();\n        while timer.saturating_elapsed() < timeout {\n            for store_id in &alive_store_ids {\n                let l = match self.query_leader(*store_id, region_id, Duration::from_secs(1)) {\n                    None => continue,\n                    Some(l) => l,\n                };\n                leaders\n                    .entry(l.get_id())\n                    .or_insert((l, vec![]))\n                    .1\n                    .push(*store_id);\n            }\n            if let Some((_, (l, c))) = leaders.iter().max_by_key(|(_, (_, c))| c.len()) {\n                if c.contains(&l.get_store_id()) {\n                    leader = Some(l.clone());\n                    // Technically, correct calculation should use two quorum when in joint\n                    // state. Here just for simplicity.\n                    if c.len() > store_ids.len() / 2 {\n                        break;\n                    }\n                }\n            }\n            debug!(\"failed to detect leaders\"; \"leaders\" => ?leaders, \"store_ids\" => ?store_ids);\n            sleep_ms(10);\n            leaders.clear();\n        }\n\n        if let Some(l) = leader {\n            self.leaders.insert(region_id, l);\n        }\n\n        self.leaders.get(&region_id).cloned()\n    }", "test": "fn test_proposal_prevent_sleep() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_hibernate(&mut cluster.cfg);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 2\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1).direction(Direction::Send),\n    ));\n    let region = block_on(cluster.pd_client.get_region_by_id(1))\n        .unwrap()\n        .unwrap();\n\n    let put = new_put_cmd(b\"k2\", b\"v2\");\n    let mut req = new_request(1, region.get_region_epoch().clone(), vec![put], true);\n    req.mut_header().set_peer(new_peer(1, 1));\n    // ignore error, we just want to send this command to peer (1, 1),\n    // and the command can't be executed because we have only one peer,\n    // so here will return timeout error, we should ignore it.\n    let _ = cluster.call_command(req, Duration::from_millis(10));\n    cluster.clear_send_filters();\n    must_get_equal(&cluster.get_engine(3), b\"k2\", b\"v2\");\n    assert_eq!(cluster.leader_of_region(1), Some(new_peer(1, 1)));\n\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 2\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1).direction(Direction::Send),\n    ));\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_read_index_cmd()],\n        true,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    // send to peer 2\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    thread::sleep(Duration::from_millis(10));\n    cluster.clear_send_filters();\n    let resp = rx.recv_timeout(Duration::from_secs(5)).unwrap();\n    assert!(\n        !resp.get_header().has_error(),\n        \"{:?}\",\n        resp.get_header().get_error()\n    );\n\n    // Wait till leader peer goes to sleep.\n    thread::sleep(\n        cluster.cfg.raft_store.raft_base_tick_interval.0\n            * 2\n            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,\n    );\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(1, 1).direction(Direction::Send),\n    ));\n    let conf_change = new_change_peer_request(ConfChangeType::RemoveNode, new_peer(3, 3));\n    let mut admin_req = new_admin_request(1, region.get_region_epoch(), conf_change);\n    admin_req.mut_header().set_peer(new_peer(1, 1));\n    let (cb, _rx) = make_cb(&admin_req);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, admin_req, cb)\n        .unwrap();\n    thread::sleep(Duration::from_millis(10));\n    cluster.clear_send_filters();\n    cluster.pd_client.must_none_peer(1, new_peer(3, 3));\n}"}
{"code": "pub fn compute_float64(q: i32, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        many_digits: false,\n    };\n    let fp = bellerophon::<f64>(&num);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f64_rounding() {\n    // Also need to check halfway cases **inside** that exponent range.\n\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740993), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));\n    assert_eq!(compute_float64(0, 9007199254740995), (1076, 2));\n    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));\n    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));\n    assert_eq!(compute_float64(0, 18014398509481986), (1077, 0));\n    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));\n    assert_eq!(compute_float64(0, 18014398509481990), (1077, 2));\n    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));\n\n    // Test a much closer set of examples.\n    assert_eq!(compute_float64(0, 9007199254740991), (1075, 4503599627370495));\n    assert_eq!(compute_float64(0, 9223372036854776831), (1086, 0));\n    assert_eq!(compute_float64(0, 9223372036854776832), (1086, 0));\n    assert_eq!(compute_float64(0, 9223372036854776833), (1086, 1));\n    assert_eq!(compute_float64(-42, 9123456727292927), (936, 1854521741541368));\n    assert_eq!(compute_float64(-43, 91234567272929275), (936, 1854521741541369));\n    assert_eq!(compute_float64(-42, 9123456727292928), (936, 1854521741541369));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));\n    assert_eq!(compute_float64(-3, 9007199254740993000), (1076, 0));\n    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));\n    assert_eq!(compute_float64(-3, 9007199254740995000), (1076, 2));\n    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_execution_result_report() {\n    let mut cluster = new_server_cluster(0, 3);\n    // Prolong force leader time.\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    // Makes the leadership definite.\n    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();\n    cluster.must_transfer_leader(region.get_id(), store2_peer);\n    cluster.put(b\"random_key1\", b\"random_val1\").unwrap();\n\n    // Split the region into 2, and remove one of them, so that we can test both\n    // region peer list update and region creation.\n    pd_client.must_split_region(\n        region,\n        pdpb::CheckPolicy::Usekey,\n        vec![b\"random_key1\".to_vec()],\n    );\n    let region1 = pd_client.get_region(b\"random_key\".as_ref()).unwrap();\n    let region2 = pd_client.get_region(b\"random_key1\".as_ref()).unwrap();\n    let region1_store0_peer = find_peer(&region1, nodes[0]).unwrap().to_owned();\n    pd_client.must_remove_peer(region1.get_id(), region1_store0_peer);\n    cluster.must_remove_region(nodes[0], region1.get_id());\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    {\n        let put = new_put_cmd(b\"k2\", b\"v2\");\n        let req = new_request(\n            region2.get_id(),\n            region2.get_region_epoch().clone(),\n            vec![put],\n            true,\n        );\n        // marjority is lost, can't propose command successfully.\n        cluster\n            .call_command_on_leader(req, Duration::from_millis(10))\n            .unwrap_err();\n    }\n\n    cluster.must_enter_force_leader(region2.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    // Construct recovery plan.\n    let mut plan = pdpb::RecoveryPlan::default();\n\n    let to_be_removed: Vec<metapb::Peer> = region2\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region2.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n\n    let mut create = metapb::Region::default();\n    create.set_id(101);\n    create.set_end_key(b\"random_key1\".to_vec());\n    let mut peer = metapb::Peer::default();\n    peer.set_id(102);\n    peer.set_store_id(nodes[0]);\n    create.mut_peers().push(peer);\n    plan.mut_creates().push(create);\n\n    // Blocks the raft apply process on store 1 entirely .\n    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);\n    fail::cfg_callback(\"on_handle_apply_store_1\", move || {\n        let _ = apply_released_rx.recv();\n    })\n    .unwrap();\n\n    // Triggers the unsafe recovery plan execution.\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // No store report is sent, since there are peers have unapplied entries.\n    for _ in 0..20 {\n        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);\n        sleep_ms(100);\n    }\n\n    // Unblocks the apply process.\n    drop(apply_released_tx);\n\n    // Store reports are sent once the entries are applied.\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    for peer_report in store_report.unwrap().get_peer_reports() {\n        let region = peer_report.get_region_state().get_region();\n        if region.get_id() == 101 {\n            assert_eq!(region.get_end_key(), b\"random_key1\".to_vec());\n        } else {\n            assert_eq!(region.get_id(), region2.get_id());\n            for peer in region.get_peers() {\n                if peer.get_store_id() != nodes[0] {\n                    assert_eq!(peer.get_role(), metapb::PeerRole::Learner);\n                }\n            }\n        }\n    }\n    fail::remove(\"on_handle_apply_store_1\");\n}"}
{"code": "fn read(&mut self, buf: &mut [u8]) -> io::Result<usize> {\n        // If we don't have any buffered data and we're doing a massive read\n        // (larger than our internal buffer), bypass our internal buffer\n        // entirely.\n        if self.pos == self.cap && buf.len() >= self.buf.len() {\n            return self.inner.read(buf);\n        }\n        let nread = {\n            let mut rem = self.fill_buf()?;\n            rem.read(buf)?\n        };\n        self.consume(nread);\n        Ok(nread)\n    }", "test": "fn deflate_decoder_empty_read() {\n    let original: &[u8] = b\"Lorem ipsum dolor sit amet.\";\n    let mut encoder =\n        flate2::write::DeflateEncoder::new(Vec::new(), flate2::Compression::default());\n    encoder.write_all(original).unwrap();\n    let encoded: Vec<u8> = encoder.finish().unwrap();\n    let mut decoder = flate2::read::DeflateDecoder::new(encoded.as_slice());\n    assert_eq!(decoder.read(&mut []).unwrap(), 0);\n    let mut decoded = Vec::new();\n    decoder.read_to_end(&mut decoded).unwrap();\n    assert_eq!(decoded.as_slice(), original);\n}"}
{"code": "pub const fn decimal() -> u128 {\n        let mut builder = Self::new();\n        builder.mantissa_radix = 10;\n        builder.exponent_base = num::NonZeroU8::new(10);\n        builder.exponent_radix = num::NonZeroU8::new(10);\n        builder.build()\n    }", "test": "fn u64toa_test() {\n    let mut buffer = [b'\\x00'; 32];\n    unsafe {\n        assert_eq!(5u64.decimal(&mut buffer), 1);\n        assert_eq!(&buffer[..1], b\"5\");\n\n        assert_eq!(11u64.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"11\");\n\n        assert_eq!(99u64.decimal(&mut buffer), 2);\n        assert_eq!(&buffer[..2], b\"99\");\n\n        assert_eq!(101u64.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"101\");\n\n        assert_eq!(999u64.decimal(&mut buffer), 3);\n        assert_eq!(&buffer[..3], b\"999\");\n\n        assert_eq!(1001u64.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"1001\");\n\n        assert_eq!(9999u64.decimal(&mut buffer), 4);\n        assert_eq!(&buffer[..4], b\"9999\");\n\n        assert_eq!(10001u64.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"10001\");\n\n        assert_eq!(65535u64.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"65535\");\n\n        assert_eq!(99999u64.decimal(&mut buffer), 5);\n        assert_eq!(&buffer[..5], b\"99999\");\n\n        assert_eq!(100001u64.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"100001\");\n\n        assert_eq!(999999u64.decimal(&mut buffer), 6);\n        assert_eq!(&buffer[..6], b\"999999\");\n\n        assert_eq!(1000001u64.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"1000001\");\n\n        assert_eq!(9999999u64.decimal(&mut buffer), 7);\n        assert_eq!(&buffer[..7], b\"9999999\");\n\n        assert_eq!(10000001u64.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"10000001\");\n\n        assert_eq!(99999999u64.decimal(&mut buffer), 8);\n        assert_eq!(&buffer[..8], b\"99999999\");\n\n        assert_eq!(100000001u64.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"100000001\");\n\n        assert_eq!(999999999u64.decimal(&mut buffer), 9);\n        assert_eq!(&buffer[..9], b\"999999999\");\n\n        assert_eq!(1000000001u64.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"1000000001\");\n\n        assert_eq!(9999999999u64.decimal(&mut buffer), 10);\n        assert_eq!(&buffer[..10], b\"9999999999\");\n\n        assert_eq!(10000000001u64.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"10000000001\");\n\n        assert_eq!(99999999999u64.decimal(&mut buffer), 11);\n        assert_eq!(&buffer[..11], b\"99999999999\");\n\n        assert_eq!(100000000001u64.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"100000000001\");\n\n        assert_eq!(999999999999u64.decimal(&mut buffer), 12);\n        assert_eq!(&buffer[..12], b\"999999999999\");\n\n        assert_eq!(1000000000001u64.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"1000000000001\");\n\n        assert_eq!(9999999999999u64.decimal(&mut buffer), 13);\n        assert_eq!(&buffer[..13], b\"9999999999999\");\n\n        assert_eq!(10000000000001u64.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"10000000000001\");\n\n        assert_eq!(99999999999999u64.decimal(&mut buffer), 14);\n        assert_eq!(&buffer[..14], b\"99999999999999\");\n\n        assert_eq!(100000000000001u64.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"100000000000001\");\n\n        assert_eq!(999999999999999u64.decimal(&mut buffer), 15);\n        assert_eq!(&buffer[..15], b\"999999999999999\");\n\n        assert_eq!(1000000000000001u64.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"1000000000000001\");\n\n        assert_eq!(9999999999999999u64.decimal(&mut buffer), 16);\n        assert_eq!(&buffer[..16], b\"9999999999999999\");\n\n        assert_eq!(10000000000000001u64.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"10000000000000001\");\n\n        assert_eq!(99999999999999999u64.decimal(&mut buffer), 17);\n        assert_eq!(&buffer[..17], b\"99999999999999999\");\n\n        assert_eq!(100000000000000001u64.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"100000000000000001\");\n\n        assert_eq!(999999999999999999u64.decimal(&mut buffer), 18);\n        assert_eq!(&buffer[..18], b\"999999999999999999\");\n\n        assert_eq!(1000000000000000001u64.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"1000000000000000001\");\n\n        assert_eq!(9999999999999999999u64.decimal(&mut buffer), 19);\n        assert_eq!(&buffer[..19], b\"9999999999999999999\");\n\n        assert_eq!(10000000000000000001u64.decimal(&mut buffer), 20);\n        assert_eq!(&buffer[..20], b\"10000000000000000001\");\n\n        assert_eq!(18446744073709551615u64.decimal(&mut buffer), 20);\n        assert_eq!(&buffer[..20], b\"18446744073709551615\");\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date2() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"2000-01-23\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"200001230000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, start_of_year);\n    assert_eq!(mtime, start_of_year);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_rollback_merge() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);\n    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(20);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    for i in 0..10 {\n        cluster.must_put(format!(\"k{}\", i).as_bytes(), b\"v\");\n    }\n\n    // Block merge commit, let go of the merge prepare.\n    fail::cfg(\"on_schedule_merge\", \"return()\").unwrap();\n\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k2\").unwrap();\n\n    // Makes the leadership definite.\n    let left_peer_2 = find_peer(&left, nodes[2]).unwrap().to_owned();\n    let right_peer_2 = find_peer(&right, nodes[2]).unwrap().to_owned();\n    cluster.must_transfer_leader(left.get_id(), left_peer_2);\n    cluster.must_transfer_leader(right.get_id(), right_peer_2);\n    cluster.must_try_merge(left.get_id(), right.get_id());\n\n    // Makes the group lose its quorum.\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    {\n        let put = new_put_cmd(b\"k2\", b\"v2\");\n        let req = new_request(\n            region.get_id(),\n            region.get_region_epoch().clone(),\n            vec![put],\n            true,\n        );\n        // marjority is lost, can't propose command successfully.\n        cluster\n            .call_command_on_leader(req, Duration::from_millis(10))\n            .unwrap_err();\n    }\n\n    cluster.must_enter_force_leader(left.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n    cluster.must_enter_force_leader(right.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    // Construct recovery plan.\n    let mut plan = pdpb::RecoveryPlan::default();\n\n    let left_demote_peers: Vec<metapb::Peer> = left\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut left_demote = pdpb::DemoteFailedVoters::default();\n    left_demote.set_region_id(left.get_id());\n    left_demote.set_failed_voters(left_demote_peers.into());\n    let right_demote_peers: Vec<metapb::Peer> = right\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut right_demote = pdpb::DemoteFailedVoters::default();\n    right_demote.set_region_id(right.get_id());\n    right_demote.set_failed_voters(right_demote_peers.into());\n    plan.mut_demotes().push(left_demote);\n    plan.mut_demotes().push(right_demote);\n\n    // Triggers the unsafe recovery plan execution.\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    // Can't propose demotion as it's in merging mode\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    let has_force_leader = store_report\n        .unwrap()\n        .get_peer_reports()\n        .iter()\n        .any(|p| p.get_is_force_leader());\n    // Force leader is not exited due to demotion failure\n    assert!(has_force_leader);\n\n    fail::remove(\"on_schedule_merge\");\n    fail::cfg(\"on_schedule_merge_ret_err\", \"return()\").unwrap();\n\n    // Make sure merge check is scheduled, and rollback merge is triggered\n    sleep_ms(50);\n\n    // Re-triggers the unsafe recovery plan execution.\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    // No force leader\n    for peer_report in store_report.unwrap().get_peer_reports() {\n        assert!(!peer_report.get_is_force_leader());\n    }\n\n    // Demotion is done\n    let mut demoted = false;\n    for _ in 0..10 {\n        let new_left = block_on(pd_client.get_region_by_id(left.get_id()))\n            .unwrap()\n            .unwrap();\n        let new_right = block_on(pd_client.get_region_by_id(right.get_id()))\n            .unwrap()\n            .unwrap();\n        assert_eq!(new_left.get_peers().len(), 3);\n        assert_eq!(new_right.get_peers().len(), 3);\n        demoted = new_left\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner)\n            && new_right\n                .get_peers()\n                .iter()\n                .filter(|peer| peer.get_store_id() != nodes[0])\n                .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        if demoted {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_eq!(demoted, true);\n\n    fail::remove(\"on_schedule_merge_ret_err\");\n}"}
{"code": "pub fn encoded_len(&self, ident: TokenStream) -> TokenStream {\n        let tag = self.tag;\n        match self.label {\n            Label::Optional => quote! {\n                #ident.as_ref().map_or(0, |msg| ::prost::encoding::group::encoded_len(#tag, msg))\n            },\n            Label::Required => quote! {\n                ::prost::encoding::group::encoded_len(#tag, &#ident)\n            },\n            Label::Repeated => quote! {\n                ::prost::encoding::group::encoded_len_repeated(#tag, &#ident)\n            },\n        }\n    }", "test": "fn test() {\n    use prost::Message;\n\n    let mut widget_factory = widget::factory::WidgetFactory::default();\n    assert_eq!(0, widget_factory.encoded_len());\n\n    widget_factory.inner = Some(widget::factory::widget_factory::Inner {});\n    assert_eq!(2, widget_factory.encoded_len());\n\n    widget_factory.root = Some(Root {});\n    assert_eq!(4, widget_factory.encoded_len());\n\n    widget_factory.root_inner = Some(root::Inner {});\n    assert_eq!(6, widget_factory.encoded_len());\n\n    widget_factory.widget = Some(widget::Widget {});\n    assert_eq!(8, widget_factory.encoded_len());\n\n    widget_factory.widget_inner = Some(widget::widget::Inner {});\n    assert_eq!(10, widget_factory.encoded_len());\n\n    widget_factory.gizmo = Some(gizmo::Gizmo {});\n    assert_eq!(12, widget_factory.encoded_len());\n\n    widget_factory.gizmo_inner = Some(gizmo::gizmo::Inner {});\n    assert_eq!(14, widget_factory.encoded_len());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ci_formatter_linter_organize_imports() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = r#\"{\n    \"linter\": {\n        \"enabled\": true,\n        \"rules\": {\n            \"recommended\": true\n        }\n    },\n    \"organizeImports\": {\n        \"enabled\": true\n    }\n}\"#;\n\n    let input = r#\"\nimport { B, C } from \"b.js\"\nimport A from \"a.js\"\n\n\nsomething( )\n    \"#;\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), rome_json.as_bytes());\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), input.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"ci target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ci_formatter_linter_organize_imports\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn drain_filter_all_elements_next_back() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    let mut table = write_txn.open_table(U64_TABLE).unwrap();\n    let mut iter = table.drain_filter(0..10, |_, _| true).unwrap();\n    for i in (0..10).rev() {\n        let (k, v) = iter.next_back().unwrap().unwrap();\n        assert_eq!(i, k.value());\n        assert_eq!(i, v.value());\n    }\n}"}
{"code": "pub fn name(&self) -> &str {\n        &self.data.file_name\n    }", "test": "fn aes128_encrypted_file() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"data/aes_archive.zip\"));\n    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    let mut file = archive\n        .by_name_decrypt(\"secret_data_128\", PASSWORD)\n        .expect(\"couldn't find file in archive\")\n        .expect(\"invalid password\");\n    assert_eq!(\"secret_data_128\", file.name());\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"couldn't read encrypted file\");\n    assert_eq!(SECRET_CONTENT, content);\n}"}
{"code": "pub fn resolve_link(&self, path: &str) -> String {\n        log_info(\"resolve_link\", self.plus_as_string(path));\n        match fs::read_link(self.plus(path)) {\n            Ok(p) => self.minus_as_string(p.to_str().unwrap()),\n            Err(_) => String::new(),\n        }\n    }", "test": "fn test_relative_recursive() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    at.mkdir(\"dir\");\n    ucmd.args(&[\"-sr\", \"dir\", \"dir/recursive\"]).succeeds();\n    assert_eq!(at.resolve_link(\"dir/recursive\"), \".\");\n}"}
{"code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn buffered_both_data_sent() {\n    let server_config = Arc::new(make_server_config(KeyType::Rsa));\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);\n        let (mut client, mut server) =\n            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n\n        assert_eq!(\n            12,\n            server\n                .writer()\n                .write(b\"from-server!\")\n                .unwrap()\n        );\n        assert_eq!(\n            12,\n            client\n                .writer()\n                .write(b\"from-client!\")\n                .unwrap()\n        );\n\n        do_handshake(&mut client, &mut server);\n\n        transfer(&mut server, &mut client);\n        client.process_new_packets().unwrap();\n        transfer(&mut client, &mut server);\n        server.process_new_packets().unwrap();\n\n        check_read(&mut client.reader(), b\"from-server!\");\n        check_read(&mut server.reader(), b\"from-client!\");\n    }\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_compare_and_swap() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // create a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    let result = client\n        .create(record.clone(), origin.clone())\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let current = record;\n    let mut new = current.clone();\n    new.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n\n    let result = client\n        .compare_and_swap(current.clone(), new.clone(), origin.clone())\n        .expect(\"compare_and_swap failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(new.name(), new.dns_class(), new.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {\n            *ip == A::new(101, 11, 101, 11)\n        } else {\n            false\n        }));\n\n    // check the it fails if tried again.\n    new.set_data(Some(RData::A(A::new(102, 12, 102, 12))));\n\n    let result = client\n        .compare_and_swap(current, new.clone(), origin)\n        .expect(\"compare_and_swap failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXRRSet);\n\n    let result = client\n        .query(new.name(), new.dns_class(), new.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {\n            *ip == A::new(101, 11, 101, 11)\n        } else {\n            false\n        }));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_str_prefixed_chunks_by_lines() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_str_prefixed_chunks_by_lines\";\n    RandomFile::new(&at, name).add_lines(10000);\n    ucmd.args(&[\"-l\", \"1000\", name, \"d\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"d[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 10);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_try_reserve() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert_eq!(tv.capacity(), 4);\n  tv.extend_from_slice(&[1, 2]);\n  assert_eq!(tv.capacity(), 4);\n  assert!(tv.try_reserve(2).is_ok());\n  assert_eq!(tv.capacity(), 4);\n  assert!(tv.try_reserve(4).is_ok());\n  assert!(tv.capacity() >= 6);\n  tv.extend_from_slice(&[3, 4, 5, 6]);\n  assert!(tv.try_reserve(4).is_ok());\n  assert!(tv.capacity() >= 10);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_multiple_folders() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let target_dir = \"test_mv_multiple_dirs_dir\";\n    let dir_a = \"test_mv_multiple_dir_a\";\n    let dir_b = \"test_mv_multiple_dir_b\";\n\n    at.mkdir(target_dir);\n    at.mkdir(dir_a);\n    at.mkdir(dir_b);\n\n    ucmd.arg(dir_a)\n        .arg(dir_b)\n        .arg(target_dir)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(&format!(\"{target_dir}/{dir_a}\")));\n    assert!(at.dir_exists(&format!(\"{target_dir}/{dir_b}\")));\n}"}
{"code": "fn next(&mut self) -> Option<std::io::Result<Vec<u8>>> {\n        let mut buf = Vec::new();\n        match self.buf.read_until(self.sep, &mut buf) {\n            Ok(0) => None,\n            Ok(_n) => Some(Ok(buf)),\n            Err(e) => Some(Err(e)),\n        }\n    }", "test": "fn test_output_file_all_filesystems() {\n    // When run with no positional arguments, `df` lets \"-\" represent\n    // the \"File\" entry for each row.\n    let output = new_ucmd!()\n        .arg(\"--output=file\")\n        .succeeds()\n        .stdout_move_str();\n    let mut lines = output.lines();\n    assert_eq!(lines.next().unwrap(), \"File\");\n    for line in lines {\n        assert_eq!(line, \"-\");\n    }\n}"}
{"code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_signal_prefixed_name_new_form() {\n    let mut target = Target::new();\n    new_ucmd!()\n        .arg(\"-s\")\n        .arg(\"SIGKILL\")\n        .arg(format!(\"{}\", target.pid()))\n        .succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_ignore_nonempty_directory_no_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir(DIR);\n    at.touch(DIR_FILE);\n\n    ucmd.arg(\"--ignore-fail-on-non-empty\")\n        .arg(DIR)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(DIR));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.data.len()\n    }", "test": "fn simple_test() {\n    // Test the simple properties of the stack vector.\n    let mut x = VecType::from_u64(1);\n    assert_eq!(x.len(), 1);\n    assert_eq!(x.is_empty(), false);\n    assert_eq!(x.capacity(), bigint::BIGINT_LIMBS);\n    x.try_push(5).unwrap();\n    assert_eq!(x.len(), 2);\n    assert_eq!(x.pop(), Some(5));\n    assert_eq!(x.len(), 1);\n    assert_eq!(&*x, &[1]);\n    x.try_extend(&[2, 3, 4]).unwrap();\n    assert_eq!(x.len(), 4);\n    assert_eq!(&*x, &[1, 2, 3, 4]);\n    x.try_resize(6, 0).unwrap();\n    assert_eq!(x.len(), 6);\n    assert_eq!(&*x, &[1, 2, 3, 4, 0, 0]);\n    x.try_resize(0, 0).unwrap();\n    assert_eq!(x.len(), 0);\n    assert_eq!(x.is_empty(), true);\n\n    let x = VecType::try_from(&[5, 1]).unwrap();\n    assert_eq!(x.len(), 2);\n    assert_eq!(x.is_empty(), false);\n    if bigint::LIMB_BITS == 32 {\n        assert_eq!(x.hi64(), (0x8000000280000000, false));\n    } else {\n        assert_eq!(x.hi64(), (0x8000000000000002, true));\n    }\n    let rview = bigint::rview(&x);\n    assert_eq!(x[0], 5);\n    assert_eq!(x[1], 1);\n    assert_eq!(rview[0], 1);\n    assert_eq!(rview[1], 5);\n    assert_eq!(x.len(), 2);\n\n    assert_eq!(VecType::from_u64(U64_MAX).hi64(), (U64_MAX, false));\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "fn test_region_error_in_scan() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_cluster, raft_engine, mut ctx) = new_raft_engine(1, \"\");\n    ctx.set_isolation_level(IsolationLevel::Si);\n\n    let (_, endpoint, _) =\n        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &data, true);\n\n    fail::cfg(\"region_snapshot_seek\", \"return()\").unwrap();\n    let req = DagSelect::from(&product).build_with(ctx, &[0]);\n    let resp = handle_request(&endpoint, req);\n\n    assert!(\n        resp.get_region_error()\n            .get_message()\n            .contains(\"region seek error\")\n    );\n}"}
{"code": "pub fn to_string(&self) -> String {\n        format!(\"label{}\", self.0)\n    }", "test": "fn fill_wrong() {\n    let mut store = Store::<()>::default();\n    let ty = TableType::new(ValType::FuncRef, 1, None);\n    let table = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();\n    assert_eq!(\n        table\n            .fill(&mut store, 0, Val::ExternRef(None), 1)\n            .map_err(|e| e.to_string())\n            .unwrap_err(),\n        \"value does not match table element type\"\n    );\n\n    let ty = TableType::new(ValType::ExternRef, 1, None);\n    let table = Table::new(&mut store, ty, Val::ExternRef(None)).unwrap();\n    assert_eq!(\n        table\n            .fill(&mut store, 0, Val::FuncRef(None), 1)\n            .map_err(|e| e.to_string())\n            .unwrap_err(),\n        \"value does not match table element type\"\n    );\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_several_directories() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir1 = \"dir1\";\n    let dir2 = \"dir2\";\n    let dir3 = \"dir3\";\n    let directories_arg = \"-d\";\n\n    ucmd.args(&[directories_arg, dir1, dir2, dir3])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(dir1));\n    assert!(at.dir_exists(dir2));\n    assert!(at.dir_exists(dir3));\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn render_tests() {\n    let mut context = Context::new();\n    context.insert(\"is_true\", &true);\n    context.insert(\"is_false\", &false);\n    context.insert(\"age\", &18);\n    context.insert(\"name\", &\"john\");\n    let mut map = HashMap::new();\n    map.insert(0, 1);\n    context.insert(\"map\", &map);\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n    context.insert::<Option<usize>, _>(\"maybe\", &None);\n\n    let inputs = vec![\n        (\"{% if is_true is defined %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if hello is undefined %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if name is string %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if age is number %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if age is even %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if age is odd %}Admin{%else%}even{% endif %}\", \"even\"),\n        (\"{% if age is divisibleby(2) %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if numbers is iterable %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if map is iterable %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if map is object %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if name is starting_with('j') %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if name is ending_with('n') %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if numbers is containing(2) %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if name is matching('^j.*') %}Admin{% endif %}\", \"Admin\"),\n        (\"{% if maybe is defined %}Admin{% endif %}\", \"Admin\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &context).unwrap(), expected);\n    }\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_symlink_target_only() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_target_only\";\n\n    at.mkdir(dir);\n\n    assert!(!ucmd\n        .args(&[\"-s\", \"-t\", dir])\n        .fails()\n        .stderr_str()\n        .is_empty());\n}"}
{"code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "fn call_linked_func() -> Result<(), Error> {\n    let engine = Engine::default();\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\n        \"host\",\n        \"f\",\n        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            // Calling this func will switch context into wasm, then back to host:\n            assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);\n\n            assert_eq!(\n                caller.data().calls_into_host,\n                caller.data().returns_from_host + 1\n            );\n            assert_eq!(\n                caller.data().calls_into_wasm,\n                caller.data().returns_from_wasm + 1\n            );\n\n            assert_eq!(a, 1);\n            assert_eq!(b, 2);\n            assert_eq!(c, 3.0);\n            assert_eq!(d, 4.0);\n        },\n    )?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32) (param i64) (param f32) (param f64)))\n            (func (export \"export\")\n                (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let inst = linker.instantiate(&mut store, &module)?;\n    let export = inst\n        .get_export(&mut store, \"export\")\n        .expect(\"get export\")\n        .into_func()\n        .expect(\"export is func\");\n\n    export.call(&mut store, &[], &mut [])?;\n\n    // One switch from vm to host to call f, another in return from f.\n    assert_eq!(store.data().calls_into_host, 1);\n    assert_eq!(store.data().returns_from_host, 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 1);\n\n    export.typed::<(), ()>(&store)?.call(&mut store, ())?;\n\n    assert_eq!(store.data().calls_into_host, 2);\n    assert_eq!(store.data().returns_from_host, 2);\n    assert_eq!(store.data().calls_into_wasm, 2);\n    assert_eq!(store.data().returns_from_wasm, 2);\n\n    Ok(())\n}"}
{"code": "pub fn fuel_consumed(&self) -> Option<u64> {\n        self.inner.fuel_consumed()\n    }", "test": "fn manual_edge_cases() {\n    let mut config = Config::new();\n    config.consume_fuel(true);\n    let engine = Engine::new(&config).unwrap();\n    let mut store = Store::new(&engine, ());\n    store.add_fuel(u64::MAX).unwrap();\n    assert_eq!(store.fuel_consumed(), Some(0));\n    assert!(store.consume_fuel(u64::MAX).is_err());\n    assert!(store.consume_fuel(i64::MAX as u64 + 1).is_err());\n    assert_eq!(store.consume_fuel(i64::MAX as u64).unwrap(), 0);\n}"}
{"code": "pub fn get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, false)\n    }", "test": "fn test_write_after_destroy() {\n    // 3 nodes cluster.\n    let mut cluster = new_server_cluster(0, 3);\n\n    let pd_client = cluster.pd_client.clone();\n    // Disable default max peer count check.\n    pd_client.disable_default_operator();\n\n    let r1 = cluster.run_conf_change();\n\n    // Now region 1 only has peer (1, 1);\n    let (key, value) = (b\"k1\", b\"v1\");\n\n    cluster.must_put(key, value);\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    // add peer (2,2) to region 1.\n    pd_client.must_add_peer(r1, new_peer(2, 2));\n\n    // add peer (3, 3) to region 1.\n    pd_client.must_add_peer(r1, new_peer(3, 3));\n    let engine_3 = cluster.get_engine(3);\n    must_get_equal(&engine_3, b\"k1\", b\"v1\");\n\n    let apply_fp = \"apply_on_conf_change_1_3_1\";\n    fail::cfg(apply_fp, \"pause\").unwrap();\n\n    cluster.must_transfer_leader(r1, new_peer(1, 1));\n    let conf_change = new_change_peer_request(ConfChangeType::RemoveNode, new_peer(3, 3));\n    let mut epoch = cluster.pd_client.get_region_epoch(r1);\n    let mut admin_req = new_admin_request(r1, &epoch, conf_change);\n    admin_req.mut_header().set_peer(new_peer(1, 1));\n    let (cb1, mut rx1) = make_cb(&admin_req);\n    let engines_3 = cluster.get_all_engines(3);\n    let region = block_on(cluster.pd_client.get_region_by_id(r1))\n        .unwrap()\n        .unwrap();\n    let reqs = vec![new_put_cmd(b\"k5\", b\"v5\")];\n    let new_version = epoch.get_conf_ver() + 1;\n    epoch.set_conf_ver(new_version);\n    let mut put = new_request(r1, epoch, reqs, false);\n    put.mut_header().set_peer(new_peer(1, 1));\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, admin_req, cb1)\n        .unwrap();\n    for _ in 0..100 {\n        let (cb2, _rx2) = make_cb(&put);\n        cluster\n            .sim\n            .rl()\n            .async_command_on_node(1, put.clone(), cb2)\n            .unwrap();\n    }\n    let engine_2 = cluster.get_engine(2);\n    must_get_equal(&engine_2, b\"k5\", b\"v5\");\n    fail::remove(apply_fp);\n    let resp = rx1.recv_timeout(Duration::from_secs(2)).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n    std::thread::sleep(Duration::from_secs(3));\n    must_get_none(&engine_3, b\"k5\");\n    must_region_cleared(&engines_3, &region);\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_numeric_prefixed_chunks_by_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_num_prefixed_chunks_by_bytes\";\n    RandomFile::new(&at, name).add_bytes(10000);\n    ucmd.args(&[\n        \"-d\", // --numeric-suffixes\n        \"-b\", // --bytes\n        \"1000\", name, \"a\",\n    ])\n    .succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"a\\d\\d$\");\n    assert_eq!(glob.count(), 10);\n    for filename in glob.collect() {\n        assert_eq!(glob.directory.metadata(&filename).len(), 1000);\n    }\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn server_alpn_unset() {\n    let _guard = subscribe();\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config());\n\n    let mut client_crypto = client_crypto();\n    client_crypto.alpn_protocols = vec![\"foo\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto));\n\n    let client_ch = pair.begin_connect(client_config);\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(err) }) if err.error_code == TransportErrorCode::crypto(0x78)\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_off() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=off\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert!(!at.file_exists(format!(\"{TEST_HOW_ARE_YOU_SOURCE}~\")));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_dangling_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_dangling_dir\";\n    let link = \"test_symlink_dangling_dir_link\";\n\n    ucmd.args(&[\"-s\", dir, link]).succeeds().no_stderr();\n    assert!(!at.dir_exists(dir));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), dir);\n}"}
{"code": "pub fn path(mut self, path: impl AsRef<Path>) -> Self {\n        self.path = Some(path.as_ref().to_path_buf());\n        self\n    }", "test": "fn path() {\n    let db = default_engine();\n    let path = db.tempdir.path().to_str().unwrap();\n    assert_eq!(db.engine.path(), path);\n}"}
{"code": "pub fn is_f64(&self) -> bool {\n        match self.n {\n            N::Float(_) => true,\n            N::PosInt(_) | N::NegInt(_) => false,\n        }\n    }", "test": "fn test_nan() {\n    let pos_nan = serde_yaml::from_str::<Value>(\".nan\").unwrap();\n    assert!(pos_nan.is_f64());\n    assert_eq!(pos_nan, pos_nan);\n\n    let neg_fake_nan = serde_yaml::from_str::<Value>(\"-.nan\").unwrap();\n    assert!(neg_fake_nan.is_string());\n\n    let significand_mask = 0xF_FFFF_FFFF_FFFF;\n    let bits = (f64::NAN.copysign(1.0).to_bits() ^ significand_mask) | 1;\n    let different_pos_nan = Value::Number(Number::from(f64::from_bits(bits)));\n    assert_eq!(pos_nan, different_pos_nan);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_overwrite_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir_a = \"test_mv_overwrite_dir_a\";\n    let dir_b = \"test_mv_overwrite_dir_b\";\n\n    at.mkdir(dir_a);\n    at.mkdir(dir_b);\n    ucmd.arg(\"-T\").arg(dir_a).arg(dir_b).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(dir_a));\n    assert!(at.dir_exists(dir_b));\n}"}
{"code": "pub fn read_bytes(&self, name: &str) -> Vec<u8> {\n        let mut f = self.open(name);\n        let mut contents = Vec::new();\n        f.read_to_end(&mut contents)\n            .unwrap_or_else(|e| panic!(\"Couldn't read {name}: {e}\"));\n        contents\n    }", "test": "fn test_cp_sparse_always_empty() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    const BUFFER_SIZE: usize = 4096 * 4;\n    let buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];\n\n    at.make_file(\"src_file1\");\n    at.write_bytes(\"src_file1\", &buf);\n\n    ucmd.args(&[\"--sparse=always\", \"src_file1\", \"dst_file_sparse\"])\n        .succeeds();\n\n    assert_eq!(at.read_bytes(\"dst_file_sparse\"), buf);\n    assert_eq!(at.metadata(\"dst_file_sparse\").blocks(), 0);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        match self.kind {\n            ErrorKind::None => false,\n            ErrorKind::Str(_) | ErrorKind::Regex(_) => true,\n        }\n    }", "test": "fn invalid_regexes_no_crash() {\n    assert!(regex_new!(\"(*)\").is_err());\n    assert!(regex_new!(\"(?:?)\").is_err());\n    assert!(regex_new!(\"(?)\").is_err());\n    assert!(regex_new!(\"*\").is_err());\n}"}
{"code": "pub fn leader_of_region(&mut self, region_id: u64) -> Option<metapb::Peer> {\n        let timer = Instant::now_coarse();\n        let timeout = Duration::from_secs(5);\n        let mut store_ids = None;\n        while timer.saturating_elapsed() < timeout {\n            match self.voter_store_ids_of_region(region_id) {\n                None => thread::sleep(Duration::from_millis(10)),\n                Some(ids) => {\n                    store_ids = Some(ids);\n                    break;\n                }\n            }\n        }\n        let store_ids = store_ids?;\n        if let Some(l) = self.leaders.get(&region_id) {\n            // leader may be stopped in some tests.\n            if self.valid_leader_id(region_id, l.get_store_id()) {\n                return Some(l.clone());\n            }\n        }\n        self.reset_leader_of_region(region_id);\n        let mut leader = None;\n        let mut leaders = HashMap::default();\n\n        let node_ids = self.sim.rl().get_node_ids();\n        // For some tests, we stop the node but pd still has this information,\n        // and we must skip this.\n        let alive_store_ids: Vec<_> = store_ids\n            .iter()\n            .filter(|id| node_ids.contains(id))\n            .cloned()\n            .collect();\n        while timer.saturating_elapsed() < timeout {\n            for store_id in &alive_store_ids {\n                let l = match self.query_leader(*store_id, region_id, Duration::from_secs(1)) {\n                    None => continue,\n                    Some(l) => l,\n                };\n                leaders\n                    .entry(l.get_id())\n                    .or_insert((l, vec![]))\n                    .1\n                    .push(*store_id);\n            }\n            if let Some((_, (l, c))) = leaders.iter().max_by_key(|(_, (_, c))| c.len()) {\n                if c.contains(&l.get_store_id()) {\n                    leader = Some(l.clone());\n                    // Technically, correct calculation should use two quorum when in joint\n                    // state. Here just for simplicity.\n                    if c.len() > store_ids.len() / 2 {\n                        break;\n                    }\n                }\n            }\n            debug!(\"failed to detect leaders\"; \"leaders\" => ?leaders, \"store_ids\" => ?store_ids);\n            sleep_ms(10);\n            leaders.clear();\n        }\n\n        if let Some(l) = leader {\n            self.leaders.insert(region_id, l);\n        }\n\n        self.leaders.get(&region_id).cloned()\n    }", "test": "fn test_reject_proposal_during_leader_transfer() {\n    let mut cluster = new_node_cluster(0, 2);\n    let pd_client = cluster.pd_client.clone();\n    pd_client.disable_default_operator();\n    let r = cluster.run_conf_change();\n    pd_client.must_add_peer(r, new_peer(2, 2));\n\n    // Don't allow leader transfer succeed if it is actually triggered.\n    cluster.add_send_filter(CloneFilterFactory(\n        RegionPacketFilter::new(r, 2)\n            .msg_type(MessageType::MsgTimeoutNow)\n            .direction(Direction::Recv),\n    ));\n\n    cluster.must_put(b\"k\", b\"v\");\n    cluster.transfer_leader(r, new_peer(2, 2));\n    // The leader can't change to transferring state immediately due to\n    // pre-transfer-leader feature, so wait for a while.\n    sleep_ms(100);\n    assert_ne!(cluster.leader_of_region(r).unwrap(), new_peer(2, 2));\n\n    let force_delay_propose_batch_raft_command_fp = \"force_delay_propose_batch_raft_command\";\n    for i in 0..2 {\n        if i == 1 {\n            // Test another path of calling proposed callback.\n            fail::cfg(force_delay_propose_batch_raft_command_fp, \"2*return\").unwrap();\n        }\n        let write_req = make_write_req(&mut cluster, b\"k\");\n        let (cb, mut cb_receivers) = make_cb(&write_req);\n        cluster\n            .sim\n            .rl()\n            .async_command_on_node(1, write_req, cb)\n            .unwrap();\n        cb_receivers.assert_err();\n    }\n\n    cluster.clear_send_filters();\n}"}
{"code": "pub const fn to_bits(self) -> u16 {\n        self.bits\n    }", "test": "fn from_f32_test() {\n    assert_eq!(f16::from_f32(2.980232e-08).to_bits(), 0);\n    assert_eq!(f16::from_f32(2.9802322e-08).to_bits(), 0);\n    assert_eq!(f16::from_f32(2.9802326e-08).to_bits(), 1);\n    assert_eq!(f16::from_f32(5.960464e-08).to_bits(), 1);\n    assert_eq!(f16::from_f32(5.9604645e-08).to_bits(), 1);\n    assert_eq!(f16::from_f32(5.960465e-08).to_bits(), 1);\n    assert!(f16::from_f32(f32::NAN).is_nan());\n    assert!(f16::from_f32(f32::INFINITY).is_inf());\n    assert!(f16::from_f32(f32::NEG_INFINITY).is_inf());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_both() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_both\";\n\n    ucmd.args(&[\"-t\", \"201501011234\", \"-a\", \"-m\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_async_apply_prewrite_fallback() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .async_apply_prewrite(true)\n        .build()\n        .unwrap();\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(1);\n    ctx.set_region_epoch(cluster.get_region_epoch(1));\n    ctx.set_peer(cluster.leader_of_region(1).unwrap());\n\n    let before_async_apply_prewrite_finish = \"before_async_apply_prewrite_finish\";\n    let on_handle_apply = \"on_handle_apply\";\n\n    fail::cfg(before_async_apply_prewrite_finish, \"return()\").unwrap();\n    fail::cfg(on_handle_apply, \"pause\").unwrap();\n\n    let (key, value) = (b\"k1\", b\"v1\");\n    let (tx, rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Prewrite::new(\n                vec![Mutation::make_put(Key::from_raw(key), value.to_vec())],\n                key.to_vec(),\n                10.into(),\n                0,\n                false,\n                1,\n                0.into(),\n                0.into(),\n                Some(vec![]),\n                false,\n                AssertionLevel::Off,\n                ctx.clone(),\n            ),\n            Box::new(move |r| tx.send(r).unwrap()),\n        )\n        .unwrap();\n\n    assert_eq!(\n        rx.recv_timeout(Duration::from_millis(200)).unwrap_err(),\n        RecvTimeoutError::Timeout\n    );\n\n    fail::remove(on_handle_apply);\n\n    let res = rx.recv().unwrap().unwrap();\n    assert!(res.min_commit_ts > 10.into());\n\n    fail::remove(before_async_apply_prewrite_finish);\n\n    let (tx, rx) = channel();\n    storage\n        .sched_txn_command(\n            commands::Commit::new(vec![Key::from_raw(key)], 10.into(), res.min_commit_ts, ctx),\n            Box::new(move |r| tx.send(r).unwrap()),\n        )\n        .unwrap();\n\n    rx.recv_timeout(Duration::from_secs(5)).unwrap().unwrap();\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nl_lines() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--lines=2\", \"-t\", \"\\n\"])\n        .pipe_in(\"1\\n2\\n3\\n4\\n5\\n\")\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\n2\\n\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\n4\\n\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\n\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"-b\")\n        .arg(\"--suffix\")\n        .arg(\".bak\")\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.bak\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn has_weak_maps() -> bool {\n    BOA_GC.with(|current| {\n        let gc = current.borrow();\n\n        gc.weak_map_start.get().is_some()\n    })\n}", "test": "fn weak_map_multiple() {\n    run_test(|| {\n        let key1 = Gc::new(String::from(\"key1\"));\n        let key2 = Gc::new(String::from(\"key2\"));\n        let key3 = Gc::new(String::from(\"key3\"));\n\n        assert!(!has_weak_maps());\n\n        let mut map_1 = WeakMap::new();\n        let mut map_2 = WeakMap::new();\n\n        assert!(has_weak_maps());\n\n        map_1.insert(&key1, ());\n        map_1.insert(&key2, ());\n        map_2.insert(&key3, ());\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(map_1.contains_key(&key1));\n        assert!(map_1.contains_key(&key2));\n        assert!(!map_1.contains_key(&key3));\n        assert!(!map_2.contains_key(&key1));\n        assert!(!map_2.contains_key(&key2));\n        assert!(map_2.contains_key(&key3));\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        drop(key1);\n        drop(key2);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        assert!(!map_1.contains_key(&key3));\n        assert!(map_2.contains_key(&key3));\n\n        drop(key3);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        drop(map_1);\n\n        force_collect();\n        assert!(has_weak_maps());\n\n        drop(map_2);\n\n        force_collect();\n        assert!(!has_weak_maps());\n    });\n}"}
{"code": "fn len(&self) -> Result<u64> {\n        let mut count = 0;\n        for item in self.iter()? {\n            let (_, values) = item?;\n            for v in values {\n                v?;\n                count += 1;\n            }\n        }\n        Ok(count)\n    }", "test": "fn drain() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n        // Test draining uncommitted data\n        drop(table.drain(0..10).unwrap());\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        for (i, item) in table.drain(0..5).unwrap().enumerate() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i as u64, k.value());\n            assert_eq!(i as u64, v.value());\n        }\n        assert_eq!(table.len().unwrap(), 5);\n        let mut i = 5u64;\n        for item in table.range(0..10).unwrap() {\n            let (k, v) = item.unwrap();\n            assert_eq!(i, k.value());\n            assert_eq!(i, v.value());\n            i += 1;\n        }\n    }\n    write_txn.abort().unwrap();\n\n    // Check that dropping the iter early works too\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        assert_eq!(table.len().unwrap(), 10);\n        drop(table.drain(0..5).unwrap());\n        assert_eq!(table.len().unwrap(), 5);\n    }\n    write_txn.abort().unwrap();\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_empty_directory() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_rm_empty_directory\";\n\n    at.mkdir(dir);\n\n    ucmd.arg(\"-d\").arg(dir).succeeds().no_stderr();\n\n    assert!(!at.dir_exists(dir));\n}"}
{"code": "fn is_empty(&self) -> Result<bool> {\n        self.len().map(|x| x == 0)\n    }", "test": "fn is_empty() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert!(!table.is_empty().unwrap());\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_raw_invalid_utf8() {\n    let j = &[b'\"', b'\\xCE', b'\\xF8', b'\"'];\n    let value_err = serde_json::from_slice::<Value>(j).unwrap_err();\n    let raw_value_err = serde_json::from_slice::<Box<RawValue>>(j).unwrap_err();\n\n    assert_eq!(\n        value_err.to_string(),\n        \"invalid unicode code point at line 1 column 4\",\n    );\n    assert_eq!(\n        raw_value_err.to_string(),\n        \"invalid unicode code point at line 1 column 4\",\n    );\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_index() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, None, 4),\n        (6, Some(\"name:1\"), 1),\n        (7, Some(\"name:1\"), 1),\n        (8, Some(\"name:1\"), 1),\n        (9, Some(\"name:2\"), 1),\n        (10, Some(\"name:2\"), 1),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);\n\n    let req = new_analyze_index_req(&product, 3, product[\"name\"].index, 4, 32, 2, 2);\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_data().is_empty());\n    let mut analyze_resp = AnalyzeIndexResp::default();\n    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n    let hist = analyze_resp.get_hist();\n    assert_eq!(hist.get_ndv(), 6);\n    assert_eq!(hist.get_buckets().len(), 2);\n    assert_eq!(hist.get_buckets()[0].get_count(), 5);\n    assert_eq!(hist.get_buckets()[0].get_ndv(), 3);\n    assert_eq!(hist.get_buckets()[1].get_count(), 9);\n    assert_eq!(hist.get_buckets()[1].get_ndv(), 3);\n    let rows = analyze_resp.get_cms().get_rows();\n    assert_eq!(rows.len(), 4);\n    let sum: u32 = rows.first().unwrap().get_counters().iter().sum();\n    assert_eq!(sum, 13);\n    let top_n = analyze_resp.get_cms().get_top_n();\n    let mut top_n_count = top_n\n        .iter()\n        .map(|data| data.get_count())\n        .collect::<Vec<_>>();\n    top_n_count.sort_unstable();\n    assert_eq!(top_n_count, vec![2, 3]);\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn specify_env() -> Result<()> {\n    // By default no env is inherited\n    let output = get_wasmtime_command()?\n        .args(&[\"run\", \"tests/all/cli_tests/print_env.wat\"])\n        .env(\"THIS_WILL_NOT\", \"show up in the output\")\n        .output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"\");\n\n    // Specify a single env var\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"--env\",\n            \"FOO=bar\",\n            \"tests/all/cli_tests/print_env.wat\",\n        ])\n        .output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"FOO=bar\\n\");\n\n    // Inherit a single env var\n    let output = get_wasmtime_command()?\n        .args(&[\"run\", \"--env\", \"FOO\", \"tests/all/cli_tests/print_env.wat\"])\n        .env(\"FOO\", \"bar\")\n        .output()?;\n    assert!(output.status.success());\n    assert_eq!(String::from_utf8_lossy(&output.stdout), \"FOO=bar\\n\");\n\n    // Inherit a nonexistent env var\n    let output = get_wasmtime_command()?\n        .args(&[\n            \"run\",\n            \"--env\",\n            \"SURELY_THIS_ENV_VAR_DOES_NOT_EXIST_ANYWHERE_RIGHT\",\n            \"tests/all/cli_tests/print_env.wat\",\n        ])\n        .output()?;\n    assert!(!output.status.success());\n\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_numbered() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=numbered\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}.~1~\")));\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "async fn instantiate_async() -> Result<(), Error> {\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n\n    let m = Module::new(store.engine(), \"(module)\")?;\n    Instance::new_async(&mut store, &m, &[]).await?;\n    assert_eq!(store.data().calls_into_wasm, 0);\n    assert_eq!(store.data().calls_into_host, 0);\n\n    let m = Module::new(store.engine(), \"(module (func) (start 0))\")?;\n    Instance::new_async(&mut store, &m, &[]).await?;\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().calls_into_host, 0);\n\n    Ok(())\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_short_combination() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-dxen\", \"4\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x00\"), \"a\");\n    assert_eq!(at.read(\"x01\"), \"b\");\n    assert_eq!(at.read(\"x02\"), \"c\");\n    assert!(!at.file_exists(\"x03\"));\n}"}
{"code": "pub fn capacity(&self, stream: &mut store::Ptr) -> WindowSize {\n        stream.capacity(self.prioritize.max_buffer_size())\n    }", "test": "async fn send_recv_data() {\n    h2_support::trace_init!();\n\n    let mock = mock_io::Builder::new()\n        .handshake()\n        .write(&[\n            // POST /\n            0, 0, 16, 1, 4, 0, 0, 0, 1, 131, 135, 65, 139, 157, 41, 172, 75, 143, 168, 233, 25, 151,\n            33, 233, 132,\n        ])\n        .write(&[\n            // DATA\n            0, 0, 5, 0, 1, 0, 0, 0, 1, 104, 101, 108, 108, 111,\n        ])\n        .write(frames::SETTINGS_ACK)\n        // Read response\n        .read(&[\n            // HEADERS\n            0, 0, 1, 1, 4, 0, 0, 0, 1, 136, // DATA\n            0, 0, 5, 0, 1, 0, 0, 0, 1, 119, 111, 114, 108, 100,\n        ])\n        .build();\n\n    let (mut client, mut h2) = client::Builder::new().handshake(mock).await.unwrap();\n\n    let request = Request::builder()\n        .method(Method::POST)\n        .uri(\"https://http2.akamai.com/\")\n        .body(())\n        .unwrap();\n\n    tracing::info!(\"sending request\");\n    let (response, mut stream) = client.send_request(request, false).unwrap();\n\n    // Reserve send capacity\n    stream.reserve_capacity(5);\n\n    assert_eq!(stream.capacity(), 5);\n\n    // Send the data\n    stream.send_data(\"hello\".as_bytes(), true).unwrap();\n\n    // Get the response\n    let resp = h2.run(response).await.unwrap();\n    assert_eq!(resp.status(), StatusCode::OK);\n\n    // Take the body\n    let (_, body) = resp.into_parts();\n\n    // Wait for all the data frames to be received\n    let bytes: Vec<_> = h2.run(body.try_collect()).await.unwrap();\n\n    // One byte chunk\n    assert_eq!(1, bytes.len());\n\n    assert_eq!(bytes[0], &b\"world\"[..]);\n\n    // The H2 connection is closed\n    h2.await.unwrap();\n}"}
{"code": "pub fn contains(&self, op: IoOp) -> bool {\n        match *self {\n            IoRateLimitMode::WriteOnly => op == IoOp::Write,\n            IoRateLimitMode::ReadOnly => op == IoOp::Read,\n            _ => true,\n        }\n    }", "test": "pub fn test_basic() {\n    let mut test_suite = TestSuite::new(resource_metering::Config {\n        report_receiver_interval: ReadableDuration::secs(3),\n        precision: ReadableDuration::secs(1),\n        ..Default::default()\n    });\n\n    // Workload\n    // [req-1, req-2]\n    test_suite.setup_workload(vec![\"req-1\", \"req-2\"]);\n\n    let (_client, stream) = test_suite.subscribe();\n    let tags = stream.take(4).map(|record| {\n        String::from_utf8_lossy(record.unwrap().get_record().get_resource_group_tag()).into_owned()\n    });\n    let res = block_on(tags.collect::<HashSet<_>>());\n\n    assert!(res.contains(\"req-1\"));\n    assert!(res.contains(\"req-2\"));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_force_multiple() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_rm_force_a\";\n    let file_b = \"test_rm_force_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    ucmd.arg(\"-f\")\n        .arg(\"-f\")\n        .arg(\"-f\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_invalid_range() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    let (_, endpoint) = init_with_data(&product, &data);\n\n    let mut select = DagSelect::from(&product);\n    select.key_ranges[0].set_start(b\"xxx\".to_vec());\n    select.key_ranges[0].set_end(b\"zzz\".to_vec());\n    let req = select.build();\n    let resp = handle_request(&endpoint, req);\n    assert!(!resp.get_other_error().is_empty());\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_none(),\n            }\n        }\n    }", "test": "fn test_summary() {\n    let cfg = Config {\n        report_receiver_interval: ReadableDuration::millis(REPORT_INTERVAL_MS),\n        precision: ReadableDuration::millis(PRECISION_MS),\n        ..Default::default()\n    };\n\n    let (_, collector_reg_handle, resource_tag_factory, mut recorder_worker) =\n        init_recorder(cfg.precision.as_millis());\n    let (_, data_sink_reg_handle, mut reporter_worker) = init_reporter(cfg, collector_reg_handle);\n\n    let data_sink = MockDataSink::default();\n\n    // At this point we are ready for everything except turning on the switch.\n\n    // expect no data\n    {\n        let tf = resource_tag_factory.clone();\n        let data_sink = data_sink.clone();\n        thread::spawn(move || {\n            {\n                let mut ctx = Context::default();\n                ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n                let tag = tf.new_tag(&ctx);\n                let _g = tag.attach();\n                resource_metering::record_read_keys(123);\n                resource_metering::record_write_keys(456);\n            }\n            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n            assert!(data_sink.get(b\"TAG-1\").is_none());\n            data_sink.clear();\n        })\n        .join()\n        .unwrap();\n    }\n\n    // turn on\n    let reg_guard = data_sink_reg_handle.register(Box::new(data_sink.clone()));\n\n    // expect can get data\n    {\n        let tf = resource_tag_factory.clone();\n        let data_sink = data_sink.clone();\n        thread::spawn(move || {\n            {\n                let mut ctx = Context::default();\n                ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n                let tag = tf.new_tag(&ctx);\n                let _g = tag.attach();\n                thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply\n                resource_metering::record_read_keys(123);\n                resource_metering::record_write_keys(456);\n            }\n            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n\n            let r = data_sink.get(b\"TAG-1\").unwrap();\n            assert_eq!(\n                r.get_record()\n                    .get_items()\n                    .iter()\n                    .map(|item| item.read_keys)\n                    .sum::<u32>(),\n                123\n            );\n            assert_eq!(\n                r.get_record()\n                    .get_items()\n                    .iter()\n                    .map(|item| item.write_keys)\n                    .sum::<u32>(),\n                456\n            );\n            data_sink.clear();\n        })\n        .join()\n        .unwrap();\n    }\n\n    // turn off\n    drop(reg_guard);\n\n    // expect no data\n    thread::spawn(move || {\n        {\n            let mut ctx = Context::default();\n            ctx.set_resource_group_tag(b\"TAG-1\".to_vec());\n            let tag = resource_tag_factory.new_tag(&ctx);\n            let _g = tag.attach();\n            thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply\n            resource_metering::record_read_keys(123);\n            resource_metering::record_write_keys(456);\n        }\n        thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report\n        assert!(data_sink.get(b\"TAG-1\").is_none());\n        data_sink.clear();\n    })\n    .join()\n    .unwrap();\n\n    // stop worker\n    recorder_worker.stop();\n    reporter_worker.stop();\n}"}
{"code": "pub fn parse_sql_statements(&self, sql: &str) -> Result<Vec<Statement>, ParserError> {\n        self.one_of_identical_results(|dialect| {\n            let mut tokenizer = Tokenizer::new(dialect, sql);\n            if let Some(options) = &self.options {\n                tokenizer = tokenizer.with_unescape(options.unescape);\n            }\n            let tokens = tokenizer.tokenize()?;\n            self.new_parser(dialect)\n                .with_tokens(tokens)\n                .parse_statements()\n        })\n        // To fail the `ensure_multiple_dialects_are_tested` test:\n        // Parser::parse_sql(&**self.dialects.first().unwrap(), sql)\n    }", "test": "fn parse_invalid_brackets() {\n    let sql = \"SELECT STRUCT<INT64>>(NULL)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\"unmatched > in STRUCT literal\".to_string())\n    );\n\n    let sql = \"SELECT STRUCT<STRUCT<INT64>>>(NULL)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\"Expected (, found: >\".to_string())\n    );\n\n    let sql = \"CREATE TABLE table (x STRUCT<STRUCT<INT64>>>)\";\n    assert_eq!(\n        bigquery().parse_sql_statements(sql).unwrap_err(),\n        ParserError::ParserError(\n            \"Expected ',' or ')' after column definition, found: >\".to_string()\n        )\n    );\n}"}
{"code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_reserve_exact() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert_eq!(tv.capacity(), 4);\n\n  tv.extend_from_slice(&[1, 2]);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve_exact(2);\n  assert_eq!(tv.capacity(), 4);\n  tv.reserve_exact(4);\n  assert!(tv.capacity() >= 6);\n  tv.extend_from_slice(&[3, 4, 5, 6]);\n  tv.reserve_exact(4);\n  assert!(tv.capacity() >= 10);\n}"}
{"code": "pub fn plaintext_bytes_to_read(&self) -> usize {\n        self.plaintext_bytes_to_read\n    }", "test": "fn new_server_returns_initial_io_state() {\n    let (_, mut server) = make_pair(KeyType::Rsa);\n    let io_state = server.process_new_packets().unwrap();\n    println!(\"IoState is Debug {:?}\", io_state);\n    assert_eq!(io_state.plaintext_bytes_to_read(), 0);\n    assert!(!io_state.peer_has_closed());\n    assert_eq!(io_state.tls_bytes_to_write(), 0);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_tee_treat_minus_as_filename() {\n    // Ensure tee treats '-' as the name of a file, as mandated by POSIX.\n\n    let (at, mut ucmd) = at_and_ucmd!();\n    let content = \"tee_sample_content\";\n    let file = \"-\";\n\n    ucmd.arg(\"-\").pipe_in(content).succeeds().stdout_is(content);\n\n    assert!(at.file_exists(file));\n    assert_eq!(at.read(file), content);\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.size\n    }", "test": "fn test_something() {\n    let data = [];\n    let mut set = HashSet::new();\n    let mut nat = NatSet::new();\n    for action in actions {\n        match action {\n            Action::Insert(value) => {\n                let len = nat.len() + if nat.contains(&value) { 0 } else { 1 };\n                nat.insert(value);\n                set.insert(value);\n                assert_eq!(len, set.len());\n            }\n            Action::Remove(value) => {\n                let len = nat.len() - if nat.contains(&value) { 1 } else { 0 };\n                nat.remove(&value);\n                set.remove(&value);\n                assert_eq!(len, set.len());\n            }\n        }\n        assert_eq!(nat.len(), set.len());\n        assert_eq!(HashSet::from(nat.clone()), set);\n    }\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn function_interrupt_from_afar() -> anyhow::Result<()> {\n    // Create an instance which calls an imported function on each iteration of\n    // the loop so we can count the number of loop iterations we've executed so\n    // far.\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n    static STOP: AtomicBool = AtomicBool::new(false);\n\n    let mut store = interruptable_store();\n    let module = hugely_recursive_module(store.engine())?;\n    let func = Func::wrap(&mut store, || {\n        HITS.fetch_add(1, SeqCst);\n    });\n    let instance = Instance::new(&mut store, &module, &[func.into()])?;\n\n    // Use the instance's interrupt handle to wait for it to enter the loop long\n    // enough and then we signal an interrupt happens.\n    let engine = store.engine().clone();\n    let thread = std::thread::spawn(move || {\n        while HITS.load(SeqCst) <= NUM_HITS && !STOP.load(SeqCst) {\n            // continue ...\n        }\n        engine.increment_epoch();\n    });\n\n    // Enter the infinitely looping function and assert that our interrupt\n    // handle does indeed actually interrupt the function.\n    let iloop = instance.get_typed_func::<(), ()>(&mut store, \"loop\")?;\n    let trap = iloop.call(&mut store, ()).unwrap_err().downcast::<Trap>()?;\n    STOP.store(true, SeqCst);\n    thread.join().unwrap();\n    assert!(HITS.load(SeqCst) > NUM_HITS);\n    assert_eq!(trap, Trap::Interrupt);\n    Ok(())\n}"}
{"code": "fn encode_slice<T: AsRef<[u8]>>(\n        &self,\n        input: T,\n        output_buf: &mut [u8],\n    ) -> Result<usize, EncodeSliceError> {\n        fn inner<E>(\n            engine: &E,\n            input_bytes: &[u8],\n            output_buf: &mut [u8],\n        ) -> Result<usize, EncodeSliceError>\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"usize overflow when calculating buffer size\");\n\n            if output_buf.len() < encoded_size {\n                return Err(EncodeSliceError::OutputSliceTooSmall);\n            }\n\n            let b64_output = &mut output_buf[0..encoded_size];\n\n            encode_with_padding(input_bytes, b64_output, engine, encoded_size);\n\n            Ok(encoded_size)\n        }\n\n        inner(self, input.as_ref(), output_buf)\n    }", "test": "fn encode_engine_slice_error_when_buffer_too_small() {\n    for num_triples in 1..100 {\n        let input = \"AAA\".repeat(num_triples);\n        let mut vec = vec![0; (num_triples - 1) * 4];\n        assert_eq!(\n            EncodeSliceError::OutputSliceTooSmall,\n            STANDARD.encode_slice(&input, &mut vec).unwrap_err()\n        );\n        vec.push(0);\n        assert_eq!(\n            EncodeSliceError::OutputSliceTooSmall,\n            STANDARD.encode_slice(&input, &mut vec).unwrap_err()\n        );\n        vec.push(0);\n        assert_eq!(\n            EncodeSliceError::OutputSliceTooSmall,\n            STANDARD.encode_slice(&input, &mut vec).unwrap_err()\n        );\n        vec.push(0);\n        assert_eq!(\n            EncodeSliceError::OutputSliceTooSmall,\n            STANDARD.encode_slice(&input, &mut vec).unwrap_err()\n        );\n        vec.push(0);\n        assert_eq!(\n            num_triples * 4,\n            STANDARD.encode_slice(&input, &mut vec).unwrap()\n        );\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_force_prompts_order() {\n    // Needed for talking with stdin on platforms where CRLF or LF matters\n    const END_OF_LINE: &str = if cfg!(windows) { \"\\r\\n\" } else { \"\\n\" };\n\n    let yes = format!(\"y{END_OF_LINE}\");\n\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let empty_file = \"empty\";\n\n    at.touch(empty_file);\n\n    // This should cause rm to prompt to remove regular empty file\n    let mut child = scene\n        .ucmd()\n        .set_stdin(Stdio::piped())\n        .arg(\"-fi\")\n        .arg(empty_file)\n        .run_no_wait();\n    child.try_write_in(yes.as_bytes()).unwrap();\n\n    let result = child.wait().unwrap();\n    result.stderr_only(\"rm: remove regular empty file 'empty'? \");\n\n    assert!(!at.file_exists(empty_file));\n\n    at.touch(empty_file);\n\n    // This should not cause rm to prompt to remove regular empty file\n    scene\n        .ucmd()\n        .arg(\"-if\")\n        .arg(empty_file)\n        .succeeds()\n        .no_stderr();\n    assert!(!at.file_exists(empty_file));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_file_option() {\n    let out = new_ucmd!()\n        .arg(\"-f\")\n        .arg(\"vars.conf.txt\")\n        .run()\n        .stdout_move_str();\n\n    assert_eq!(\n        out.lines()\n            .filter(|&line| line == \"FOO=bar\" || line == \"BAR=bamf this\")\n            .count(),\n        2\n    );\n}"}
{"code": "pub fn get_leader(&mut self) -> pdpb::Member {\n        block_on(self.raw_client.wait_for_ready()).unwrap();\n        self.raw_client.leader()\n    }", "test": "fn test_report_buckets() {\n    let region_id = 2;\n    let mut cop_cfg = CopConfig::default();\n    cop_cfg.enable_region_bucket = Some(true);\n    cop_cfg.region_bucket_size = ReadableSize::kb(1);\n    let mut config = v2_default_config();\n    config.region_split_check_diff = Some(ReadableSize::kb(1));\n    let cluster = Cluster::with_cop_cfg(Some(config), cop_cfg);\n    let store_id = cluster.node(0).id();\n    let router = &cluster.routers[0];\n\n    // When there is only one peer, it should campaign immediately.\n    let mut req = RaftCmdRequest::default();\n    req.mut_header().set_peer(new_peer(store_id, 3));\n    req.mut_status_request()\n        .set_cmd_type(StatusCmdType::RegionLeader);\n    let res = router.query(region_id, req.clone()).unwrap();\n    let status_resp = res.response().unwrap().get_status_response();\n    assert_eq!(\n        *status_resp.get_region_leader().get_leader(),\n        new_peer(store_id, 3)\n    );\n    router.wait_applied_to_current_term(region_id, Duration::from_secs(3));\n\n    // load data to split bucket.\n    let mut suffix = String::from(\"\");\n    for _ in 0..200 {\n        suffix.push_str(\"fake \");\n    }\n\n    let repeat: u64 = 10;\n    let bytes = write_keys(&cluster, region_id, &suffix, repeat.try_into().unwrap());\n    // To find the split keys, it should flush memtable manually.\n    let mut cached = cluster.node(0).tablet_registry().get(region_id).unwrap();\n    cached.latest().unwrap().flush_cf(CF_DEFAULT, true).unwrap();\n    // send split region check to split bucket.\n    router\n        .send(region_id, PeerMsg::Tick(PeerTick::SplitRegionCheck))\n        .unwrap();\n    std::thread::sleep(std::time::Duration::from_millis(50));\n    // report buckets to pd.\n    router\n        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))\n        .unwrap();\n    std::thread::sleep(std::time::Duration::from_millis(50));\n\n    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();\n    let mut buckets_tmp = vec![];\n    let mut bucket_ranges = vec![];\n    if let Some(buckets) = resp {\n        assert!(buckets.get_keys().len() > 2);\n        assert_eq!(buckets.get_region_id(), region_id);\n        let write_bytes = buckets.get_stats().get_write_bytes();\n        let write_keys = buckets.get_stats().get_write_keys();\n        for i in 0..buckets.keys.len() - 1 {\n            assert!(write_bytes[i] >= bytes);\n            assert!(write_keys[i] >= repeat);\n        }\n        for i in 0..buckets.keys.len() - 1 {\n            buckets_tmp.push(raftstore::store::Bucket::default());\n            let bucket_range =\n                raftstore::store::BucketRange(buckets.keys[i].clone(), buckets.keys[i + 1].clone());\n            bucket_ranges.push(bucket_range);\n        }\n    }\n\n    // report buckets to pd again, the write bytes and keys should be zero.\n    router\n        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))\n        .unwrap();\n    std::thread::sleep(std::time::Duration::from_millis(50));\n\n    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();\n    if let Some(buckets) = resp {\n        assert_eq!(buckets.get_region_id(), region_id);\n        let write_bytes = buckets.get_stats().get_write_bytes();\n        let write_keys = buckets.get_stats().get_write_keys();\n        for i in 0..buckets.keys.len() - 1 {\n            assert!(write_bytes[i] == 0);\n            assert!(write_keys[i] == 0);\n        }\n    }\n\n    // send the same region buckets to refresh which needs to merge the last.\n    let resp = block_on(cluster.node(0).pd_client().get_region_by_id(region_id)).unwrap();\n    if let Some(region) = resp {\n        let region_epoch = region.get_region_epoch().clone();\n        for _ in 0..2 {\n            let msg = PeerMsg::RefreshRegionBuckets {\n                region_epoch: region_epoch.clone(),\n                buckets: buckets_tmp.clone(),\n                bucket_ranges: Some(bucket_ranges.clone()),\n            };\n            router.send(region_id, msg).unwrap();\n            std::thread::sleep(std::time::Duration::from_millis(50));\n        }\n    }\n    // report buckets to pd again, the write bytes and keys should be zero.\n    router\n        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))\n        .unwrap();\n    std::thread::sleep(std::time::Duration::from_millis(50));\n\n    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();\n    if let Some(buckets) = resp {\n        assert_eq!(buckets.get_region_id(), region_id);\n        let write_bytes = buckets.get_stats().get_write_bytes();\n        let write_keys = buckets.get_stats().get_write_keys();\n        assert_eq!(write_bytes.len(), 1);\n        assert_eq!(write_keys.len(), 1);\n    }\n\n    fn write_keys(cluster: &Cluster, region_id: u64, suffix: &str, repeat: usize) -> u64 {\n        let router = &cluster.routers[0];\n        let header = Box::new(router.new_request_for(region_id).take_header());\n        for i in 0..repeat {\n            let mut put = SimpleWriteEncoder::with_capacity(64);\n            let mut key = format!(\"key-{}\", i);\n            key.push_str(suffix);\n            put.put(CF_DEFAULT, key.as_bytes(), b\"value\");\n            let (msg, sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());\n            router.send(region_id, msg).unwrap();\n            let _resp = block_on(sub.result()).unwrap();\n        }\n        ((suffix.as_bytes().len() + 10) * repeat)\n            .try_into()\n            .unwrap()\n    }\n}"}
{"code": "pub fn as_f32(self) -> f32 {\n        f16_to_f32(self)\n    }", "test": "fn as_f32_test() {\n    assert_eq!(f16::from_bits(1).as_f32(), 0.000000059604645);\n    assert_eq!(f16::ZERO.as_f32(), 0.0f32);\n    assert_eq!(f16::ZERO.to_bits(), 0);\n    assert_eq!(f16::ONE.as_f32(), 1.0f32);\n    assert_eq!(f16::ONE.to_bits(), (15 << 10));\n    assert_eq!(f16::TWO.as_f32(), 2.0f32);\n    assert_eq!(f16::TWO.to_bits(), (16 << 10));\n    assert_eq!(f16::from_bits(14 << 10).as_f32(), 0.5f32);\n    assert!(f16::NAN.as_f32().is_nan());\n    assert!(f16::INFINITY.as_f32().is_inf());\n    assert!(f16::NEG_INFINITY.as_f32().is_inf());\n}"}
{"code": "pub unsafe fn load(ptr: *mut Self) -> Self {\n        let other = &*ptr;\n        VMMemoryDefinition {\n            base: other.base,\n            current_length: other.current_length().into(),\n        }\n    }", "test": "fn into_inner() {\n    static HITS: AtomicUsize = AtomicUsize::new(0);\n\n    struct A;\n\n    impl Drop for A {\n        fn drop(&mut self) {\n            HITS.fetch_add(1, SeqCst);\n        }\n    }\n\n    let engine = Engine::default();\n    assert_eq!(HITS.load(SeqCst), 0);\n    drop(Store::new(&engine, A));\n    assert_eq!(HITS.load(SeqCst), 1);\n    Store::new(&engine, A).into_data();\n    assert_eq!(HITS.load(SeqCst), 2);\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_numeric_suffix() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"--numeric-suffixes=9\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x10\"), \"b\");\n    assert_eq!(at.read(\"x11\"), \"c\");\n    assert_eq!(at.read(\"x12\"), \"\");\n}"}
{"code": "pub fn get_listen_port(&self) -> u16 {\n        self.listen_port.unwrap_or(DEFAULT_PORT)\n    }", "test": "fn test_read_config() {\n    let server_path = env::var(\"TDNS_WORKSPACE_ROOT\").unwrap_or_else(|_| \"../..\".to_owned());\n    let path: PathBuf =\n        PathBuf::from(server_path).join(\"tests/test-data/test_configs/example.toml\");\n\n    if !path.exists() {\n        panic!(\"can't locate example.toml and other configs: {:?}\", path)\n    }\n\n    println!(\"reading config\");\n    let config: Config = Config::read_config(&path).unwrap();\n\n    assert_eq!(config.get_listen_port(), 53);\n    assert_eq!(config.get_listen_addrs_ipv4(), Ok(Vec::<Ipv4Addr>::new()));\n    assert_eq!(config.get_listen_addrs_ipv6(), Ok(Vec::<Ipv6Addr>::new()));\n    assert_eq!(config.get_tcp_request_timeout(), Duration::from_secs(5));\n    assert_eq!(config.get_log_level(), tracing::Level::INFO);\n    assert_eq!(config.get_directory(), Path::new(\"/var/named\"));\n    assert_eq!(\n        config.get_zones(),\n        [\n            ZoneConfig::new(\n                \"localhost\".into(),\n                ZoneType::Primary,\n                \"default/localhost.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            ),\n            ZoneConfig::new(\n                \"0.0.127.in-addr.arpa\".into(),\n                ZoneType::Primary,\n                \"default/127.0.0.1.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            ),\n            ZoneConfig::new(\n                \"0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.\\\n                 ip6.arpa\"\n                    .into(),\n                ZoneType::Primary,\n                \"default/ipv6_1.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            ),\n            ZoneConfig::new(\n                \"255.in-addr.arpa\".into(),\n                ZoneType::Primary,\n                \"default/255.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            ),\n            ZoneConfig::new(\n                \"0.in-addr.arpa\".into(),\n                ZoneType::Primary,\n                \"default/0.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            ),\n            ZoneConfig::new(\n                \"example.com\".into(),\n                ZoneType::Primary,\n                \"example.com.zone\".into(),\n                None,\n                None,\n                None,\n                vec![],\n            )\n        ]\n    );\n}"}
{"code": "pub(crate) fn lower_n_halfway(n: u64) -> u64 {\n    let bits: u64 = mem::size_of::<u64>() as u64 * 8;\n    debug_assert!(n <= bits, \"lower_n_halfway() overflow in shl.\");\n\n    if n == 0 {\n        0\n    } else {\n        nth_bit(n - 1)\n    }\n}", "test": "fn lower_n_halfway_test() {\n    assert_eq!(lower_n_halfway(0u64), 0b0);\n    assert_eq!(lower_n_halfway(1u64), 0b1);\n    assert_eq!(lower_n_halfway(2u64), 0b10);\n    assert_eq!(lower_n_halfway(10u64), 0b1000000000);\n    assert_eq!(lower_n_halfway(32u64), 0b10000000000000000000000000000000);\n}"}
{"code": "pub fn as_bytes(&self) -> Option<BytesRef<'_>> {\n        EvaluableRef::borrow_scalar_value(self)\n    }", "test": "fn test_load_global_config() {\n    let (mut _server, client) = new_test_server_and_client(ReadableDuration::millis(100));\n    let global_items = vec![(\"test1\", \"val1\"), (\"test2\", \"val2\"), (\"test3\", \"val3\")];\n    let check_items = global_items.clone();\n    if let Err(err) = futures::executor::block_on(\n        client.store_global_config(\n            String::from(\"global\"),\n            global_items\n                .iter()\n                .map(|(name, value)| {\n                    let mut item = GlobalConfigItem::default();\n                    item.set_name(name.to_string());\n                    item.set_payload(value.as_bytes().into());\n                    item\n                })\n                .collect::<Vec<GlobalConfigItem>>(),\n        ),\n    ) {\n        panic!(\"error occur {:?}\", err);\n    }\n\n    let (res, revision) =\n        futures::executor::block_on(client.load_global_config(String::from(\"global\"))).unwrap();\n    assert!(\n        res.iter()\n            .zip(check_items)\n            .all(|(item1, item2)| item1.name == item2.0 && item1.payload == item2.1.as_bytes())\n    );\n    assert_eq!(revision, 3);\n}"}
{"code": "fn len(&self) -> std::io::Result<i64> {\n        match self {\n            Self::File(f) => Ok(f.metadata()?.len().try_into().unwrap_or(i64::MAX)),\n            _ => Ok(0),\n        }\n    }", "test": "fn test_ascii_521k_to_file() {\n    let tname = \"ascii-521k\";\n    let input = build_ascii_block(512 * 1024);\n    let tmp_fn = format!(\"TESTFILE-{}.tmp\", &tname);\n\n    let (fix, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"status=none\", of!(tmp_fn)])\n        .pipe_in(input.clone())\n        .run()\n        .no_stderr()\n        .no_stdout()\n        .success();\n\n    assert_eq!(512 * 1024, fix.metadata(&tmp_fn).len());\n\n    cmp_file!(\n        {\n            let mut input_f = tempfile().unwrap();\n            input_f.write_all(&input).unwrap();\n            input_f\n        },\n        fix.open(&tmp_fn)\n    );\n}"}
{"code": "fn wait_for_signal(&mut self) -> Option<i32> {\n        let sig = self.child.wait().expect(\"cannot wait on target\").signal();\n        self.killed = true;\n        sig\n    }", "test": "fn test_kill_with_default_signal() {\n    let mut target = Target::new();\n    new_ucmd!().arg(format!(\"{}\", target.pid())).succeeds();\n    assert_eq!(target.wait_for_signal(), Some(libc::SIGTERM));\n}"}
{"code": "pub(crate) fn load(head: Head, mut payload: Bytes) -> Result<Self, Error> {\n        let flags = DataFlags::load(head.flag());\n\n        // The stream identifier must not be zero\n        if head.stream_id().is_zero() {\n            return Err(Error::InvalidStreamId);\n        }\n\n        let pad_len = if flags.is_padded() {\n            let len = util::strip_padding(&mut payload)?;\n            Some(len)\n        } else {\n            None\n        };\n\n        Ok(Data {\n            stream_id: head.stream_id(),\n            data: payload,\n            flags,\n            pad_len,\n        })\n    }", "test": "fn hammer_client_concurrency() {\n    // This reproduces issue #326.\n    const N: usize = 5000;\n\n    let server = Server::serve(|| Bytes::from_static(b\"hello world!\"));\n\n    let addr = server.addr();\n    let rsps = Arc::new(AtomicUsize::new(0));\n\n    for i in 0..N {\n        print!(\"sending {}\", i);\n        let rsps = rsps.clone();\n        let tcp = TcpStream::connect(&addr);\n        let tcp = tcp\n            .then(|res| {\n                let tcp = res.unwrap();\n                client::handshake(tcp)\n            })\n            .then(move |res| {\n                let rsps = rsps;\n                let (mut client, h2) = res.unwrap();\n                let request = Request::builder()\n                    .uri(\"https://http2.akamai.com/\")\n                    .body(())\n                    .unwrap();\n\n                let (response, mut stream) = client.send_request(request, false).unwrap();\n                stream.send_trailers(HeaderMap::new()).unwrap();\n\n                tokio::spawn(async move {\n                    h2.await.unwrap();\n                });\n\n                response\n                    .and_then(|response| {\n                        let mut body = response.into_body();\n\n                        async move {\n                            while let Some(res) = body.data().await {\n                                res?;\n                            }\n                            body.trailers().await?;\n                            Ok(())\n                        }\n                    })\n                    .map_err(|e| {\n                        panic!(\"client error: {:?}\", e);\n                    })\n                    .map(move |_| {\n                        rsps.fetch_add(1, Ordering::Release);\n                    })\n            });\n\n        let rt = tokio::runtime::Runtime::new().unwrap();\n        rt.block_on(tcp);\n        println!(\"...done\");\n    }\n\n    println!(\"all done\");\n\n    assert_eq!(N, rsps.load(Ordering::Acquire));\n    assert_eq!(N, server.request_count());\n}"}
{"code": "pub async fn wait_proposed(&mut self) -> bool {\n        WaitEvent {\n            event: CmdResChannel::PROPOSED_EVENT,\n            core: &self.core,\n        }\n        .await\n    }", "test": "fn test_basic_write() {\n    let cluster = Cluster::default();\n    let router = &cluster.routers[0];\n    let header = Box::new(router.new_request_for(2).take_header());\n    let mut put = SimpleWriteEncoder::with_capacity(64);\n    put.put(CF_DEFAULT, b\"key\", b\"value\");\n\n    router.wait_applied_to_current_term(2, Duration::from_secs(3));\n\n    // Good proposal should be committed.\n    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());\n    router.send(2, msg).unwrap();\n    assert!(block_on(sub.wait_proposed()));\n    assert!(block_on(sub.wait_committed()));\n    let resp = block_on(sub.result()).unwrap();\n    assert!(!resp.get_header().has_error(), \"{:?}\", resp);\n\n    // Store id should be checked.\n    let mut invalid_header = header.clone();\n    invalid_header.set_peer(new_peer(3, 3));\n    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();\n    assert!(\n        resp.get_header().get_error().has_store_not_match(),\n        \"{:?}\",\n        resp\n    );\n\n    // Peer id should be checked.\n    invalid_header = header.clone();\n    invalid_header.set_peer(new_peer(1, 1));\n    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();\n    assert!(resp.get_header().has_error(), \"{:?}\", resp);\n\n    // Epoch should be checked.\n    invalid_header = header.clone();\n    invalid_header\n        .mut_region_epoch()\n        .set_version(INIT_EPOCH_VER - 1);\n    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();\n    assert!(\n        resp.get_header().get_error().has_epoch_not_match(),\n        \"{:?}\",\n        resp\n    );\n\n    // Term should be checked if set.\n    invalid_header = header.clone();\n    invalid_header.set_term(1);\n    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();\n    assert!(\n        resp.get_header().get_error().has_stale_command(),\n        \"{:?}\",\n        resp\n    );\n\n    // Too large message can cause regression and should be rejected.\n    let mut invalid_put = SimpleWriteEncoder::with_capacity(9 * 1024 * 1024);\n    invalid_put.put(CF_DEFAULT, b\"key\", &vec![0; 8 * 1024 * 1024]);\n    let resp = router.simple_write(2, header.clone(), invalid_put).unwrap();\n    assert!(\n        resp.get_header().get_error().has_raft_entry_too_large(),\n        \"{:?}\",\n        resp\n    );\n\n    // Make it step down and follower should reject write.\n    let mut msg = Box::<RaftMessage>::default();\n    msg.set_region_id(2);\n    msg.set_to_peer(new_peer(1, 3));\n    msg.mut_region_epoch().set_conf_ver(INIT_EPOCH_CONF_VER);\n    msg.set_from_peer(new_peer(2, 4));\n    let raft_message = msg.mut_message();\n    raft_message.set_msg_type(raft::prelude::MessageType::MsgHeartbeat);\n    raft_message.set_from(4);\n    raft_message.set_term(8);\n    router.send_raft_message(msg).unwrap();\n    let resp = router.simple_write(2, header, put).unwrap();\n    assert!(resp.get_header().get_error().has_not_leader(), \"{:?}\", resp);\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn ignore_vcs_ignored_file_via_cli() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let git_ignore = r#\"\nfile2.js\n\"#;\n\n    let code2 = r#\"foo.call();\n\n\n    bar.call();\"#;\n    let code1 = r#\"array.map(sentence => sentence.split(' ')).flat();\"#;\n\n    // ignored files\n    let file_path1 = Path::new(\"file1.js\");\n    fs.insert(file_path1.into(), code1.as_bytes());\n    let file_path2 = Path::new(\"file2.js\");\n    fs.insert(file_path2.into(), code2.as_bytes());\n\n    // git folder\n    let git_folder = Path::new(\"./.git\");\n    fs.insert(git_folder.into(), \"\".as_bytes());\n\n    // git ignore file\n    let ignore_file = Path::new(\"./.gitignore\");\n    fs.insert(ignore_file.into(), git_ignore.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--vcs-enabled=true\"),\n                (\"--vcs-client-kind=git\"),\n                (\"--vcs-use-ignore-file=true\"),\n                (\"--vcs-root=.\"),\n                file_path1.as_os_str().to_str().unwrap(),\n                file_path2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"ignore_vcs_ignored_file_via_cli\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.inner.len()\n    }", "test": "fn same_module_multiple_stores() -> Result<()> {\n    let _ = env_logger::try_init();\n\n    let engine = Engine::default();\n\n    let module = Module::new(\n        &engine,\n        r#\"\n            (module\n                (import \"\" \"f\" (func $f))\n                (import \"\" \"call_ref\" (func $call_ref (param funcref)))\n                (global $g (mut i32) (i32.const 0))\n                (func $a (export \"a\")\n                    call $b\n                )\n                (func $b\n                    call $c\n                )\n                (func $c\n                    global.get $g\n                    if\n                        call $f\n                    else\n                        i32.const 1\n                        global.set $g\n                        ref.func $a\n                        call $call_ref\n                    end\n                )\n            )\n        \"#,\n    )?;\n\n    let stacks = Arc::new(Mutex::new(vec![]));\n\n    let mut store3 = Store::new(&engine, ());\n    let f3 = Func::new(&mut store3, FuncType::new([], []), {\n        let stacks = stacks.clone();\n        move |caller, _params, _results| {\n            stacks\n                .lock()\n                .unwrap()\n                .push(WasmBacktrace::force_capture(caller));\n            Ok(())\n        }\n    });\n    let call_ref3 = Func::wrap(&mut store3, |caller: Caller<'_, _>, f: Option<Func>| {\n        f.unwrap().call(caller, &[], &mut [])\n    });\n    let instance3 = Instance::new(&mut store3, &module, &[f3.into(), call_ref3.into()])?;\n\n    let mut store2 = Store::new(&engine, store3);\n    let f2 = Func::new(&mut store2, FuncType::new([], []), {\n        let stacks = stacks.clone();\n        move |mut caller, _params, _results| {\n            stacks\n                .lock()\n                .unwrap()\n                .push(WasmBacktrace::force_capture(&mut caller));\n            instance3\n                .get_typed_func::<(), ()>(caller.data_mut(), \"a\")\n                .unwrap()\n                .call(caller.data_mut(), ())\n                .unwrap();\n            Ok(())\n        }\n    });\n    let call_ref2 = Func::wrap(&mut store2, |caller: Caller<'_, _>, f: Option<Func>| {\n        f.unwrap().call(caller, &[], &mut [])\n    });\n    let instance2 = Instance::new(&mut store2, &module, &[f2.into(), call_ref2.into()])?;\n\n    let mut store1 = Store::new(&engine, store2);\n    let f1 = Func::new(&mut store1, FuncType::new([], []), {\n        let stacks = stacks.clone();\n        move |mut caller, _params, _results| {\n            stacks\n                .lock()\n                .unwrap()\n                .push(WasmBacktrace::force_capture(&mut caller));\n            instance2\n                .get_typed_func::<(), ()>(caller.data_mut(), \"a\")\n                .unwrap()\n                .call(caller.data_mut(), ())\n                .unwrap();\n            Ok(())\n        }\n    });\n    let call_ref1 = Func::wrap(&mut store1, |caller: Caller<'_, _>, f: Option<Func>| {\n        f.unwrap().call(caller, &[], &mut [])\n    });\n    let instance1 = Instance::new(&mut store1, &module, &[f1.into(), call_ref1.into()])?;\n\n    instance1\n        .get_typed_func(&mut store1, \"a\")?\n        .call(&mut store1, ())?;\n\n    let expected_stacks = vec![\n        // [f1, c1, b1, a1, call_ref1, c1, b1, a1]\n        vec![\"c\", \"b\", \"a\", \"c\", \"b\", \"a\"],\n        // [f2, c2, b2, a2, call_ref2, c2, b2, a2, f1, c1, b1, a1, call_ref1, c1, b1, a1]\n        vec![\"c\", \"b\", \"a\", \"c\", \"b\", \"a\"],\n        // [f3, c3, b3, a3, call_ref3, c3, b3, a3, f2, c2, b2, a2, call_ref2, c2, b2, a2, f1, c1, b1, a1, call_ref1, c1, b1, a1]\n        vec![\"c\", \"b\", \"a\", \"c\", \"b\", \"a\"],\n    ];\n    eprintln!(\"expected = {expected_stacks:#?}\");\n    let actual_stacks = stacks.lock().unwrap();\n    eprintln!(\"actaul = {actual_stacks:#?}\");\n\n    assert_eq!(actual_stacks.len(), expected_stacks.len());\n    for (expected_stack, actual_stack) in expected_stacks.into_iter().zip(actual_stacks.iter()) {\n        assert_eq!(expected_stack.len(), actual_stack.frames().len());\n        for (expected_frame, actual_frame) in expected_stack.into_iter().zip(actual_stack.frames())\n        {\n            assert_eq!(actual_frame.func_name(), Some(expected_frame));\n        }\n    }\n\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.map.len()\n    }", "test": "fn test_sst_recovery_basic() {\n    let (mut cluster, pd_client, engine1) = create_tikv_cluster_with_one_node_damaged();\n\n    // Test that only sst recovery can delete the sst file, remove peer don't delete\n    // it.\n    fail::cfg(\"sst_recovery_before_delete_files\", \"pause\").unwrap();\n\n    let store_meta = cluster.store_metas.get(&1).unwrap().clone();\n    std::thread::sleep(CHECK_DURATION);\n    assert_eq!(\n        store_meta\n            .lock()\n            .unwrap()\n            .get_all_damaged_region_ids()\n            .len(),\n        2\n    );\n\n    // Remove peers for safe deletion of files in sst recovery.\n    let region = cluster.get_region(b\"2\");\n    let peer = find_peer(&region, 1).unwrap();\n    pd_client.must_remove_peer(region.id, peer.clone());\n    let region = cluster.get_region(b\"4\");\n    let peer = find_peer(&region, 1).unwrap();\n    pd_client.must_remove_peer(region.id, peer.clone());\n\n    // Read from other store must success.\n    assert_eq!(cluster.must_get(b\"4\").unwrap(), b\"val\");\n\n    std::thread::sleep(CHECK_DURATION);\n\n    must_get_equal(&engine1, b\"1\", b\"val\");\n    must_get_equal(&engine1, b\"7\", b\"val\");\n    assert_corruption(engine1.get_value(b\"z4\"));\n\n    fail::remove(\"sst_recovery_before_delete_files\");\n    std::thread::sleep(CHECK_DURATION);\n\n    must_get_equal(&engine1, b\"1\", b\"val\");\n    must_get_equal(&engine1, b\"7\", b\"val\");\n    assert!(engine1.get_value(b\"z4\").unwrap().is_none());\n\n    // Damaged file has been deleted.\n    let files = engine1.as_inner().get_live_files();\n    assert_eq!(files.get_files_count(), 2);\n    assert_eq!(store_meta.lock().unwrap().damaged_ranges.len(), 0);\n\n    // only store 1 remove peer so key \"4\" should be accessed by cluster.\n    assert_eq!(cluster.must_get(b\"4\").unwrap(), b\"val\");\n}"}
{"code": "pub fn data(&self) -> &T {\n        self.inner.data()\n    }", "test": "async fn basic_async_hook() -> Result<(), Error> {\n    struct HandlerR;\n\n    #[async_trait::async_trait]\n    impl CallHookHandler<State> for HandlerR {\n        async fn handle_call_event(&self, obj: &mut State, ch: CallHook) -> Result<()> {\n            State::call_hook(obj, ch)\n        }\n    }\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook_async(HandlerR {});\n\n    assert_eq!(store.data().calls_into_host, 0);\n    assert_eq!(store.data().returns_from_host, 0);\n    assert_eq!(store.data().calls_into_wasm, 0);\n    assert_eq!(store.data().returns_from_wasm, 0);\n\n    let mut linker = Linker::new(&engine);\n\n    linker.func_wrap(\n        \"host\",\n        \"f\",\n        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            // Calling this func will switch context into wasm, then back to host:\n            assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);\n\n            assert_eq!(\n                caller.data().calls_into_host,\n                caller.data().returns_from_host + 1\n            );\n            assert_eq!(\n                caller.data().calls_into_wasm,\n                caller.data().returns_from_wasm + 1\n            );\n\n            assert_eq!(a, 1);\n            assert_eq!(b, 2);\n            assert_eq!(c, 3.0);\n            assert_eq!(d, 4.0);\n        },\n    )?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32) (param i64) (param f32) (param f64)))\n            (func (export \"export\")\n                (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let inst = linker.instantiate_async(&mut store, &module).await?;\n    let export = inst\n        .get_export(&mut store, \"export\")\n        .expect(\"get export\")\n        .into_func()\n        .expect(\"export is func\");\n\n    export.call_async(&mut store, &[], &mut []).await?;\n\n    // One switch from vm to host to call f, another in return from f.\n    assert_eq!(store.data().calls_into_host, 1);\n    assert_eq!(store.data().returns_from_host, 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 1);\n\n    Ok(())\n}"}
{"code": "fn is_ok(&self) -> bool {\n        let count = self.count.fetch_add(1, Ordering::SeqCst);\n        if count != 0 && count % self.retry == 0 {\n            // it's ok.\n            return true;\n        }\n        // let's sleep awhile, so that client will update its connection.\n        thread::sleep(REQUEST_RECONNECT_INTERVAL);\n        false\n    }", "test": "fn test_pd_client_heartbeat_send_failed() {\n    let pd_client_send_fail_fp = \"region_heartbeat_send_failed\";\n    fail::cfg(pd_client_send_fail_fp, \"return()\").unwrap();\n    let server = MockServer::with_case(1, Arc::new(AlreadyBootstrapped));\n    let eps = server.bind_addrs();\n\n    let client = new_client(eps, None);\n    let poller = Builder::new_multi_thread()\n        .thread_name(thd_name!(\"poller\"))\n        .worker_threads(1)\n        .build()\n        .unwrap();\n    let (tx, rx) = mpsc::channel();\n    let f =\n        client.handle_region_heartbeat_response(1, move |resp| tx.send(resp).unwrap_or_default());\n    poller.spawn(f);\n\n    let heartbeat_send_fail = |ok| {\n        let mut region = metapb::Region::default();\n        region.set_id(1);\n        poller.spawn(client.region_heartbeat(\n            store::RAFT_INIT_LOG_TERM,\n            region,\n            metapb::Peer::default(),\n            RegionStat::default(),\n            None,\n        ));\n        let rsp = rx.recv_timeout(Duration::from_millis(100));\n        if ok {\n            assert!(rsp.is_ok());\n            assert_eq!(rsp.unwrap().get_region_id(), 1);\n        } else {\n            rsp.unwrap_err();\n        }\n\n        let region = block_on(client.get_region_by_id(1));\n        if ok {\n            assert!(region.is_ok());\n            let r = region.unwrap();\n            assert!(r.is_some());\n            assert_eq!(1, r.unwrap().get_id());\n        } else {\n            region.unwrap_err();\n        }\n    };\n    // send fail if network is block.\n    heartbeat_send_fail(false);\n    fail::remove(pd_client_send_fail_fp);\n    // send success after network recovered.\n    heartbeat_send_fail(true);\n}"}
{"code": "pub fn must_get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, true)\n    }", "test": "fn test_lease_read_callback_destroy() {\n    // Only server cluster can fake sending message successfully in raftstore layer.\n    let mut cluster = new_server_cluster(0, 3);\n    // Increase the Raft tick interval to make this test case running reliably.\n    let election_timeout = configure_for_lease_read(&mut cluster.cfg, Some(50), None);\n    cluster.run();\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    // Isolate the target peer to make transfer leader fail.\n    cluster.add_send_filter(IsolationFilterFactory::new(3));\n    cluster.transfer_leader(1, new_peer(3, 3));\n    thread::sleep(election_timeout * 2);\n    // Trigger ReadIndex on the leader.\n    assert_eq!(cluster.must_get(b\"k1\"), Some(b\"v1\".to_vec()));\n    cluster.must_put(b\"k2\", b\"v2\");\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rmdir_ignore_nonempty_directory_with_parents() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir_all(NESTED_DIR);\n    at.touch(NESTED_DIR_FILE);\n\n    ucmd.arg(\"--ignore-fail-on-non-empty\")\n        .arg(\"-p\")\n        .arg(NESTED_DIR)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(NESTED_DIR));\n}"}
{"code": "pub fn as_f32(self) -> f32 {\n        // This is super easy, since we have the same exponent bits:\n        // just need to shift left 16.\n        f32::from_bits((self.bits as u32) << 16)\n    }", "test": "fn as_f32_test() {\n    assert_eq!(bf16::from_bits(1).as_f32(), 9.18355e-41f32);\n    assert_eq!(bf16::ZERO.as_f32(), 0.0f32);\n    assert_eq!(bf16::ZERO.to_bits(), 0);\n    assert_eq!(bf16::ONE.as_f32(), 1.0f32);\n    assert_eq!(bf16::ONE.to_bits(), (127 << 7));\n    assert_eq!(bf16::TWO.as_f32(), 2.0f32);\n    assert_eq!(bf16::TWO.to_bits(), (128 << 7));\n    assert_eq!(bf16::from_bits(126 << 7).as_f32(), 0.5f32);\n    assert!(bf16::NAN.as_f32().is_nan());\n    assert!(bf16::INFINITY.as_f32().is_inf());\n    assert!(bf16::NEG_INFINITY.as_f32().is_inf());\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.len() == 0\n    }", "test": "fn write_batch_is_empty() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    assert!(wb.is_empty());\n    wb.put(b\"a\", b\"\").unwrap();\n    assert!(!wb.is_empty());\n    wb.write().unwrap();\n    assert!(!wb.is_empty());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    assert!(wb.is_empty());\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    assert!(!wb.is_empty());\n    wb.write().unwrap();\n    assert!(!wb.is_empty());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_long_no_args_file_to_dir() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file = \"test_install_simple_backup_file_a\";\n    let dest_dir = \"test_install_dest/\";\n    let expect = format!(\"{dest_dir}{file}\");\n\n    at.touch(file);\n    at.mkdir(dest_dir);\n    at.touch(&expect);\n    scene\n        .ucmd()\n        .arg(\"--backup\")\n        .arg(file)\n        .arg(dest_dir)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(&expect));\n    assert!(at.file_exists(format!(\"{expect}~\")));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_bucket_stats() {\n    let (mut cluster, client, ctx) = must_new_and_configure_cluster_and_kv_client(|cluster| {\n        cluster.cfg.coprocessor.enable_region_bucket = Some(true);\n        cluster.cfg.raft_store.split_region_check_tick_interval = ReadableDuration::days(1);\n        cluster.cfg.raft_store.report_region_buckets_tick_interval = ReadableDuration::millis(100);\n    });\n\n    let fp = \"mock_tick_interval\";\n    fail::cfg(fp, \"return(0)\").unwrap();\n\n    sleep_ms(200);\n    let mut keys = Vec::with_capacity(50);\n    for i in 0..50u8 {\n        let key = vec![b'k', i];\n        cluster.must_put(&key, &[b' '; 4]);\n        cluster.must_get(&[b'k', i]);\n        keys.push(key);\n    }\n    let mut req = RawBatchGetRequest::default();\n    req.set_context(ctx);\n    req.set_keys(protobuf::RepeatedField::from(keys));\n    client.raw_batch_get(&req).unwrap();\n    sleep_ms(600);\n    let buckets = cluster.must_get_buckets(1);\n    assert_eq!(buckets.meta.keys.len(), 2);\n    assert_eq!(buckets.stats.get_write_keys(), [50]);\n    assert_eq!(buckets.stats.get_write_bytes(), [50 * (4 + 2)]);\n    assert_eq!(buckets.stats.get_read_keys(), [50]);\n    assert_eq!(buckets.stats.get_read_bytes(), [50 * (4 + 2)]);\n    fail::remove(fp);\n}"}
{"code": "pub fn to_string<T>(&self, value: &T) -> Result<String>\n    where\n        T: ?Sized + ser::Serialize,\n    {\n        let mut output = Vec::new();\n        let mut s = Serializer::with_options(&mut output, None, self.clone())?;\n        value.serialize(&mut s)?;\n        Ok(String::from_utf8(output).expect(\"Ron should be utf-8\"))\n    }", "test": "fn small_array() {\n    let arr = &[(), (), ()][..];\n    assert_eq!(\n        to_string_pretty(&arr, PrettyConfig::new().new_line(\"\\n\".to_string())).unwrap(),\n        \"[\n    (),\n    (),\n    (),\n]\"\n    );\n    assert_eq!(\n        to_string_pretty(\n            &arr,\n            PrettyConfig::new()\n                .new_line(\"\\n\".to_string())\n                .compact_arrays(true)\n        )\n        .unwrap(),\n        \"[(), (), ()]\"\n    );\n    assert_eq!(\n        to_string_pretty(\n            &arr,\n            PrettyConfig::new()\n                .new_line(\"\\n\".to_string())\n                .compact_arrays(true)\n                .separator(\"\".to_string())\n        )\n        .unwrap(),\n        \"[(),(),()]\"\n    );\n    assert_eq!(\n        to_string_pretty(\n            &vec![(1, 2), (3, 4)],\n            PrettyConfig::new()\n                .new_line(\"\\n\".to_string())\n                .separate_tuple_members(true)\n                .compact_arrays(true)\n        )\n        .unwrap(),\n        \"[(\n    1,\n    2,\n), (\n    3,\n    4,\n)]\"\n    );\n}"}
{"code": "pub fn get_current(&self) -> TikvConfig {\n        self.inner.read().unwrap().current.clone()\n    }", "test": "fn test_update_from_toml_file() {\n    use std::{error::Error, result::Result};\n\n    use online_config::ConfigManager;\n\n    #[derive(Clone)]\n    struct CfgManager(Arc<Mutex<RaftstoreConfig>>);\n\n    impl ConfigManager for CfgManager {\n        fn dispatch(&mut self, c: ConfigChange) -> Result<(), Box<dyn Error>> {\n            self.0.lock().unwrap().update(c)\n        }\n    }\n\n    let (cfg, _dir) = TikvConfig::with_tmp().unwrap();\n    let cfg_controller = ConfigController::new(cfg);\n    let cfg = cfg_controller.get_current();\n    let mgr = CfgManager(Arc::new(Mutex::new(cfg.raft_store.clone())));\n    cfg_controller.register(Module::Raftstore, Box::new(mgr));\n\n    // update config file\n    let c = r#\"\n[raftstore]\nraft-log-gc-threshold = 2000\n\"#;\n    let mut f = File::create(&cfg.cfg_path).unwrap();\n    f.write_all(c.as_bytes()).unwrap();\n    // before update this configuration item should be the default value\n    assert_eq!(\n        cfg_controller\n            .get_current()\n            .raft_store\n            .raft_log_gc_threshold,\n        50\n    );\n    // config update from config file\n    cfg_controller.update_from_toml_file().unwrap();\n    // after update this configration item should be constant with the modified\n    // configuration file\n    assert_eq!(\n        cfg_controller\n            .get_current()\n            .raft_store\n            .raft_log_gc_threshold,\n        2000\n    );\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_split_separator_nul_line_bytes() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"--line-bytes=4\", \"-t\", \"\\\\0\", \"separator_nul.txt\"])\n        .succeeds();\n\n    assert_eq!(file_read(&at, \"xaa\"), \"1\\x002\\0\");\n    assert_eq!(file_read(&at, \"xab\"), \"3\\x004\\0\");\n    assert_eq!(file_read(&at, \"xac\"), \"5\\0\");\n    assert!(!at.plus(\"xad\").exists());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_hex_suffix_alias() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-n\", \"4\", \"--hex=9\", \"threebytes.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x09\"), \"a\");\n    assert_eq!(at.read(\"x0a\"), \"b\");\n    assert_eq!(at.read(\"x0b\"), \"c\");\n    assert_eq!(at.read(\"x0c\"), \"\");\n}"}
{"code": "fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }", "test": "fn test_block_size_with_suffix() {\n    fn get_header(block_size: &str) -> String {\n        let output = new_ucmd!()\n            .args(&[\"-B\", block_size, \"--output=size\"])\n            .succeeds()\n            .stdout_move_str();\n        output.lines().next().unwrap().trim().to_string()\n    }\n\n    assert_eq!(get_header(\"K\"), \"1K-blocks\");\n    assert_eq!(get_header(\"M\"), \"1M-blocks\");\n    assert_eq!(get_header(\"G\"), \"1G-blocks\");\n    assert_eq!(get_header(\"1K\"), \"1K-blocks\");\n    assert_eq!(get_header(\"1M\"), \"1M-blocks\");\n    assert_eq!(get_header(\"1G\"), \"1G-blocks\");\n    assert_eq!(get_header(\"1KiB\"), \"1K-blocks\");\n    assert_eq!(get_header(\"1MiB\"), \"1M-blocks\");\n    assert_eq!(get_header(\"1GiB\"), \"1G-blocks\");\n    assert_eq!(get_header(\"1KB\"), \"1kB-blocks\");\n    assert_eq!(get_header(\"1MB\"), \"1MB-blocks\");\n    assert_eq!(get_header(\"1GB\"), \"1GB-blocks\");\n}"}
{"code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn fabsd_spec_test() {\n    assert!(libm::fabsd(f64::NAN).is_nan());\n    for f in [0.0, -0.0].iter().copied() {\n        assert_eq!(libm::fabsd(f), 0.0);\n    }\n    for f in [f64::INFINITY, f64::NEG_INFINITY].iter().copied() {\n        assert_eq!(libm::fabsd(f), f64::INFINITY);\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_mv_arg_update_all_then_none() {\n    // take last if multiple update args are supplied,\n    // update=none wins in this case\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let old = \"test_mv_arg_update_all_then_none_file1\";\n    let new = \"test_mv_arg_update_all_then_none_file2\";\n    let old_content = \"old content\\n\";\n    let new_content = \"new content\\n\";\n\n    at.write(old, old_content);\n\n    sleep(Duration::from_secs(1));\n\n    at.write(new, new_content);\n\n    ucmd.arg(old)\n        .arg(new)\n        .arg(\"--update=all\")\n        .arg(\"--update=none\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(at.read(new), \"new content\\n\");\n}"}
{"code": "fn pretty(f: f64) -> String {\n    ryu::Buffer::new().format(f).to_owned()\n}", "test": "fn test_basic() {\n    check!(0.0);\n    check!(-0.0);\n    check!(1.0);\n    check!(-1.0);\n    assert_eq!(pretty(f32::NAN), \"NaN\");\n    assert_eq!(pretty(f32::INFINITY), \"inf\");\n    assert_eq!(pretty(f32::NEG_INFINITY), \"-inf\");\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_transfer_leader_msg_index() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::secs(1000);\n    prevent_from_gc_raft_log(&mut cluster);\n    run_cluster_for_test_warmup_entry_cache(&mut cluster);\n\n    let (sx, rx) = channel::unbounded();\n    let recv_filter = Box::new(\n        RegionPacketFilter::new(1, 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgTransferLeader)\n            .set_msg_callback(Arc::new(move |m| {\n                sx.send(m.get_message().get_index()).unwrap();\n            })),\n    );\n    cluster.sim.wl().add_recv_filter(2, recv_filter);\n\n    // TransferLeaderMsg.index should be equal to the store3's replicated_index.\n    cluster.transfer_leader(1, new_peer(2, 2));\n    let replicated_index = cluster.raft_local_state(1, 3).last_index;\n    assert_eq!(\n        rx.recv_timeout(Duration::from_secs(2)).unwrap(),\n        replicated_index,\n    );\n}"}
{"code": "pub fn capacity(&self) -> usize {\n    // Note: This shouldn't use A::CAPACITY, because unsafe code can't rely on\n    // any Array invariants. This ensures that at the very least, the returned\n    // value is a valid length for a subslice of the backing array.\n    self.data.as_slice().len()\n  }", "test": "fn TinyVec_try_reserve_exact() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert_eq!(tv.capacity(), 4);\n\n  tv.extend_from_slice(&[1, 2]);\n  assert_eq!(tv.capacity(), 4);\n  assert!(tv.try_reserve_exact(2).is_ok());\n  assert_eq!(tv.capacity(), 4);\n  assert!(tv.try_reserve_exact(4).is_ok());\n  assert!(tv.capacity() >= 6);\n  tv.extend_from_slice(&[3, 4, 5, 6]);\n  assert!(tv.try_reserve_exact(4).is_ok());\n  assert!(tv.capacity() >= 10);\n}"}
{"code": "pub(super) fn expect<K>(\n        &mut self,\n        kind: K,\n        context: &'static str,\n        interner: &mut Interner,\n    ) -> ParseResult<Token>\n    where\n        K: Into<TokenKind>,\n    {\n        let next_token = self.next(interner).or_abrupt()?;\n        let kind = kind.into();\n\n        if next_token.kind() == &kind {\n            Ok(next_token)\n        } else {\n            Err(Error::expected(\n                [kind.to_string(interner)],\n                next_token.to_string(interner),\n                next_token.span(),\n                context,\n            ))\n        }\n    }", "test": "fn eph_weak_gc_test() {\n    run_test(|| {\n        let gc_value = Gc::new(3);\n\n        {\n            let cloned_gc = gc_value.clone();\n\n            let weak = WeakGc::new(&cloned_gc);\n\n            assert_eq!(*weak.upgrade().expect(\"Is live currently\"), 3);\n            drop(cloned_gc);\n            force_collect();\n            assert_eq!(*weak.upgrade().expect(\"WeakGc is still live here\"), 3);\n\n            drop(gc_value);\n            force_collect();\n\n            assert!(weak.upgrade().is_none());\n        }\n    });\n}"}
{"code": "pub fn unwrap(self) -> T {\n        match self {\n            Res::Ok(t) | Res::Truncated(t) | Res::Overflow(t) => t,\n        }\n    }", "test": "fn write_batch_write_twice_3() {\n    let db = default_engine();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    db.engine.put(b\"a\", b\"b\").unwrap();\n    wb.put(b\"b\", b\"bb\").unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    assert_eq!(db.engine.get_value(b\"b\").unwrap().unwrap(), b\"bb\");\n\n    let db = multi_batch_write_engine();\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    for i in 0..128_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"aa\").unwrap();\n\n    wb.write().unwrap();\n    for i in 0..128_usize {\n        let k = i.to_be_bytes();\n        let v = (2 * i + 1).to_be_bytes();\n        db.engine.put(&k, &v).unwrap();\n    }\n    db.engine.put(b\"a\", b\"b\").unwrap();\n    for i in 128..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"b\", b\"bb\").unwrap();\n    wb.write().unwrap();\n\n    assert_eq!(db.engine.get_value(b\"a\").unwrap().unwrap(), b\"aa\");\n    assert_eq!(db.engine.get_value(b\"b\").unwrap().unwrap(), b\"bb\");\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);\n    }\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next().and_then(Record::data)\n    }", "test": "fn test_chained_cname_lookup() {\n    let resp_query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let cname_record = cname_record(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        Name::from_str(\"v4.example.com.\").unwrap(),\n    );\n    let v4_record = v4_record(\n        Name::from_str(\"v4.example.com.\").unwrap(),\n        Ipv4Addr::new(93, 184, 216, 34),\n    );\n\n    // The first response should be a cname, the second will be the actual record\n    let message1 = message(resp_query.clone(), vec![cname_record], vec![], vec![]);\n    let message2 = message(resp_query, vec![v4_record], vec![], vec![]);\n\n    // the mock pops messages...\n    let client: MockClientHandle<_, ResolveError> = MockClientHandle::mock(vec![\n        Ok(DnsResponse::from_message(message2).unwrap()),\n        Ok(DnsResponse::from_message(message1).unwrap()),\n    ]);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, false),\n    );\n\n    let io_loop = Runtime::new().unwrap();\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    assert_eq!(\n        *lookup.iter().next().unwrap(),\n        RData::A(A::new(93, 184, 216, 34))\n    );\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_terse_normal_format() {\n    // note: contains birth/creation date which increases test fragility\n    // * results may vary due to built-in `stat` limitations as well as linux kernel and rust version capability variations\n    let args = [\"-t\", \"/\"];\n    let ts = TestScenario::new(util_name!());\n    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();\n    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();\n    println!(\"actual: {actual:?}\");\n    println!(\"expect: {expect:?}\");\n    let v_actual: Vec<&str> = actual.trim().split(' ').collect();\n    let mut v_expect: Vec<&str> = expect.trim().split(' ').collect();\n    assert!(!v_expect.is_empty());\n\n    // uu_stat does not support selinux\n    if v_actual.len() == v_expect.len() - 1 && v_expect[v_expect.len() - 1].contains(':') {\n        // assume last element contains: `SELinux security context string`\n        v_expect.pop();\n    }\n\n    // * allow for inequality if `stat` (aka, expect) returns \"0\" (unknown value)\n    assert!(\n        expect == \"0\"\n            || expect == \"0\\n\"\n            || v_actual\n                .iter()\n                .zip(v_expect.iter())\n                .all(|(a, e)| a == e || *e == \"0\" || *e == \"0\\n\")\n    );\n}"}
{"code": "fn call(&mut self, req: Request) -> Self::Future {\n        use http_body_util::BodyExt;\n\n        let handler = self.clone();\n\n        let (sender, receiver) = tokio::sync::oneshot::channel();\n\n        // TODO: need to track the join handle, but don't want to block the response on it\n        tokio::task::spawn(async move {\n            let mut store = handler.0.cmd.new_store(&handler.0.engine)?;\n\n            let req = store.data_mut().new_incoming_request(\n                req.map(|body| body.map_err(|e| anyhow::anyhow!(e)).boxed()),\n            )?;\n\n            let out = store.data_mut().new_response_outparam(sender)?;\n\n            let (proxy, _inst) = wasmtime_wasi_http::proxy::Proxy::instantiate_pre(\n                &mut store,\n                &handler.0.instance_pre,\n            )\n            .await?;\n\n            proxy\n                .wasi_http_incoming_handler()\n                .call_handle(store, req, out)\n                .await?;\n\n            Ok::<_, anyhow::Error>(())\n        });\n\n        Box::pin(async move {\n            let resp = receiver.await.unwrap()?;\n            Ok(resp)\n        })\n    }", "test": "fn forward_call_works() -> Result<()> {\n    let mut store = store_with_padding(128 * MB)?;\n    let module = Module::new(\n        store.engine(),\n        r#\"\n            (module\n                (func (export \"foo\") (result i32)\n                    call 1)\n                (func (result i32)\n                    i32.const 4)\n            )\n        \"#,\n    )?;\n\n    let i = Instance::new(&mut store, &module, &[])?;\n    let foo = i.get_typed_func::<(), i32>(&mut store, \"foo\")?;\n    assert_eq!(foo.call(&mut store, ())?, 4);\n    Ok(())\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_only_atime() {\n    let atime_args = [\"-a\", \"--time=access\", \"--time=atime\", \"--time=use\"];\n    let file = \"test_touch_set_only_atime\";\n\n    for atime_arg in atime_args {\n        let (at, mut ucmd) = at_and_ucmd!();\n\n        ucmd.args(&[\"-t\", \"201501011234\", atime_arg, file])\n            .succeeds()\n            .no_stderr();\n\n        assert!(at.file_exists(file));\n\n        let start_of_year = str_to_filetime(\"%Y%m%d%H%M\", \"201501010000\");\n        let (atime, mtime) = get_file_times(&at, file);\n        assert!(atime != mtime);\n        assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_numbered_if_existing_backup_existing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n    let file_b_backup = \"test_mv_backup_numbering_file_b.~1~\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    at.touch(file_b_backup);\n    ucmd.arg(\"--backup=existing\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(file_b_backup));\n    assert!(at.file_exists(format!(\"{file_b}.~2~\")));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_interactive_once_recursive_prompt() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file1 = \"test_rm_interactive_once_recursive_prompt_file1\";\n\n    at.touch(file1);\n\n    ucmd.arg(\"--interactive=once\")\n        .arg(\"-r\")\n        .arg(file1)\n        .pipe_in(\"y\")\n        .succeeds()\n        .stderr_contains(\"remove 1 argument recursively?\");\n\n    assert!(!at.file_exists(file1));\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String>\nwhere\n    T: ?Sized + Serialize,\n{\n    let vec = tri!(to_vec(value));\n    let string = unsafe {\n        // We do not emit invalid UTF-8.\n        String::from_utf8_unchecked(vec)\n    };\n    Ok(string)\n}", "test": "fn test_serialize_rejects_adt_keys() {\n    let map = treemap!(\n        Some(\"a\") => 2,\n        Some(\"b\") => 4,\n        None => 6,\n    );\n\n    let err = to_vec(&map).unwrap_err();\n    assert_eq!(err.to_string(), \"key must be a string\");\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_no_deref_link_onto_link() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.copy(TEST_HELLO_WORLD_SOURCE, TEST_HELLO_WORLD_DEST);\n\n    #[cfg(not(windows))]\n    let _r = fs::symlink(\n        TEST_HELLO_WORLD_SOURCE,\n        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),\n    );\n    #[cfg(windows)]\n    let _r = symlink_file(\n        TEST_HELLO_WORLD_SOURCE,\n        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),\n    );\n\n    #[cfg(not(windows))]\n    let _r = fs::symlink(\n        TEST_HELLO_WORLD_DEST,\n        at.subdir.join(TEST_HELLO_WORLD_DEST_SYMLINK),\n    );\n    #[cfg(windows)]\n    let _r = symlink_file(\n        TEST_HELLO_WORLD_DEST,\n        at.subdir.join(TEST_HELLO_WORLD_DEST_SYMLINK),\n    );\n\n    ucmd.arg(\"-P\")\n        .arg(TEST_HELLO_WORLD_SOURCE_SYMLINK)\n        .arg(TEST_HELLO_WORLD_DEST_SYMLINK)\n        .succeeds();\n\n    // Ensure that the target of the destination was not modified.\n    assert!(!at\n        .symlink_metadata(TEST_HELLO_WORLD_DEST)\n        .file_type()\n        .is_symlink());\n    assert!(at\n        .symlink_metadata(TEST_HELLO_WORLD_DEST_SYMLINK)\n        .file_type()\n        .is_symlink());\n    assert_eq!(at.read(TEST_HELLO_WORLD_DEST_SYMLINK), \"Hello, World!\\n\");\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_no_deref_dir() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let dir1 = \"foo\";\n    let dir2 = \"bar\";\n    let link = \"baz\";\n\n    at.mkdir(dir1);\n    at.mkdir(dir2);\n    scene\n        .ucmd()\n        .args(&[\"-s\", dir2, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.dir_exists(dir1));\n    assert!(at.dir_exists(dir2));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), dir2);\n\n    // try the normal behavior\n    scene\n        .ucmd()\n        .args(&[\"-sf\", dir1, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.dir_exists(dir1));\n    assert!(at.dir_exists(dir2));\n    assert!(at.is_symlink(\"baz/foo\"));\n    assert_eq!(at.resolve_link(\"baz/foo\"), dir1);\n\n    // Doesn't work without the force\n    scene.ucmd().args(&[\"-sn\", dir1, link]).fails();\n\n    // Try with the no-deref\n    scene.ucmd().args(&[\"-sfn\", dir1, link]).succeeds();\n    assert!(at.dir_exists(dir1));\n    assert!(at.dir_exists(dir2));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), dir1);\n}"}
{"code": "pub fn schema_version(&self) -> i64 {\n        self.version\n    }", "test": "fn test_new_journal() {\n    let conn = Connection::open_in_memory().expect(\"could not create in memory DB\");\n    assert_eq!(\n        Journal::new(conn).expect(\"new Journal\").schema_version(),\n        -1\n    );\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_default() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"split_default\";\n    RandomFile::new(&at, name).add_lines(2000);\n    ucmd.args(&[name]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_no_deref_file() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file1 = \"foo\";\n    let file2 = \"bar\";\n    let link = \"baz\";\n\n    at.touch(file1);\n    at.touch(file2);\n    scene\n        .ucmd()\n        .args(&[\"-s\", file2, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file2);\n\n    // try the normal behavior\n    scene\n        .ucmd()\n        .args(&[\"-sf\", file1, link])\n        .succeeds()\n        .no_stderr();\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n    assert!(at.is_symlink(\"baz\"));\n    assert_eq!(at.resolve_link(\"baz\"), file1);\n\n    // Doesn't work without the force\n    scene.ucmd().args(&[\"-sn\", file1, link]).fails();\n\n    // Try with the no-deref\n    scene.ucmd().args(&[\"-sfn\", file1, link]).succeeds();\n    assert!(at.file_exists(file1));\n    assert!(at.file_exists(file2));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file1);\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_mv_errors() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let dir = \"test_mv_errors_dir\";\n    let file_a = \"test_mv_errors_file_a\";\n    let file_b = \"test_mv_errors_file_b\";\n    at.mkdir(dir);\n    at.touch(file_a);\n    at.touch(file_b);\n\n    // $ mv -T -t a b\n    // mv: cannot combine --target-directory (-t) and --no-target-directory (-T)\n    scene\n        .ucmd()\n        .arg(\"-T\")\n        .arg(\"-t\")\n        .arg(dir)\n        .arg(file_a)\n        .arg(file_b)\n        .fails()\n        .stderr_contains(\"cannot be used with\");\n\n    // $ at.touch file && at.mkdir dir\n    // $ mv -T file dir\n    // err == mv: cannot overwrite directory 'dir' with non-directory\n    scene\n        .ucmd()\n        .arg(\"-T\")\n        .arg(file_a)\n        .arg(dir)\n        .fails()\n        .stderr_is(format!(\n            \"mv: cannot overwrite directory '{dir}' with non-directory\\n\"\n        ));\n\n    // $ at.mkdir dir && at.touch file\n    // $ mv dir file\n    // err == mv: cannot overwrite non-directory 'file' with directory 'dir'\n    assert!(!scene\n        .ucmd()\n        .arg(dir)\n        .arg(file_a)\n        .fails()\n        .stderr_str()\n        .is_empty());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_already_in_joint_state() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store2.clone());\n    cluster.pd_client.must_add_peer(\n        region.get_id(),\n        new_learner_peer(nodes[2], peer_on_store2.get_id()),\n    );\n    // Wait the new learner to be initialized.\n    sleep_ms(100);\n    pd_client.must_joint_confchange(\n        region.get_id(),\n        vec![\n            (\n                ConfChangeType::AddLearnerNode,\n                new_learner_peer(nodes[0], peer_on_store0.get_id()),\n            ),\n            (\n                ConfChangeType::AddNode,\n                new_peer(nodes[2], peer_on_store2.get_id()),\n            ),\n        ],\n    );\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let to_be_removed: Vec<metapb::Peer> = region\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != nodes[0])\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut demoted = true;\n    let mut promoted = false;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n        promoted = region\n            .get_peers()\n            .iter()\n            .find(|peer| peer.get_store_id() == nodes[0])\n            .unwrap()\n            .get_role()\n            == metapb::PeerRole::Voter;\n\n        demoted = region\n            .get_peers()\n            .iter()\n            .filter(|peer| peer.get_store_id() != nodes[0])\n            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);\n        if demoted && promoted {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert!(demoted);\n    assert!(promoted);\n}"}
{"code": "pub fn get_ref(&self) -> &Stream {\n        &self.stream\n    }", "test": "fn write_flush_behaviour() {\n    const SEND_ME_LEN: usize = 10;\n    const BATCH_ME_LEN: usize = 11;\n    const WRITE_BUFFER_SIZE: usize = 600;\n\n    let mut ws = WebSocket::from_raw_socket(\n        MockWrite::default(),\n        tungstenite::protocol::Role::Server,\n        Some(WebSocketConfig { write_buffer_size: WRITE_BUFFER_SIZE, ..<_>::default() }),\n    );\n\n    assert_eq!(ws.get_ref().written_bytes, 0);\n    assert_eq!(ws.get_ref().write_count, 0);\n    assert_eq!(ws.get_ref().flush_count, 0);\n\n    // `send` writes & flushes immediately\n    ws.send(Message::Text(\"Send me!\".into())).unwrap();\n    assert_eq!(ws.get_ref().written_bytes, SEND_ME_LEN);\n    assert_eq!(ws.get_ref().write_count, 1);\n    assert_eq!(ws.get_ref().flush_count, 1);\n\n    // send a batch of messages\n    for msg in (0..100).map(|_| Message::Text(\"Batch me!\".into())) {\n        ws.write(msg).unwrap();\n    }\n    // after 55 writes the out_buffer will exceed write_buffer_size=600\n    // and so do a single underlying write (not flushing).\n    assert_eq!(ws.get_ref().written_bytes, 55 * BATCH_ME_LEN + SEND_ME_LEN);\n    assert_eq!(ws.get_ref().write_count, 2);\n    assert_eq!(ws.get_ref().flush_count, 1);\n\n    // flushing will perform a single write for the remaining out_buffer & flush.\n    ws.flush().unwrap();\n    assert_eq!(ws.get_ref().written_bytes, 100 * BATCH_ME_LEN + SEND_ME_LEN);\n    assert_eq!(ws.get_ref().write_count, 3);\n    assert_eq!(ws.get_ref().flush_count, 2);\n}"}
{"code": "pub fn id(&self) -> u16 {\n        self.id\n    }", "test": "fn retry_on_retryable_error() {\n    let handle = RetryDnsHandle::new(\n        TestClient {\n            retries: 1,\n            error_response: ResolveError::from(std::io::Error::from(std::io::ErrorKind::TimedOut)),\n            attempts: Arc::new(AtomicU16::new(0)),\n        },\n        2,\n    );\n    let test1 = Message::new();\n    let result = block_on(handle.send(test1).first_answer()).expect(\"should have succeeded\");\n    assert_eq!(result.id(), 1); // this is checking the number of iterations the TestClient ran\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_simple_backup_with_file_extension() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_simple_backup_file_a.txt\";\n    let file_b = \"test_mv_simple_backup_file_b.txt\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"-b\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn parse_dwarf_info() -> Result<()> {\n    let wasm = rustc(\n        \"\n            fn main() {\n                panic!();\n            }\n        \",\n    );\n    let mut config = Config::new();\n    config.wasm_backtrace_details(WasmBacktraceDetails::Enable);\n    let engine = Engine::new(&config)?;\n    let module = Module::new(&engine, &wasm)?;\n    let mut linker = Linker::new(&engine);\n    wasmtime_wasi::add_to_linker(&mut linker, |s| s)?;\n    let mut store = Store::new(\n        &engine,\n        wasmtime_wasi::sync::WasiCtxBuilder::new()\n            .inherit_stdio()\n            .build(),\n    );\n    linker.module(&mut store, \"\", &module)?;\n    let run = linker.get_default(&mut store, \"\")?;\n    let trap = run.call(&mut store, &[], &mut []).unwrap_err();\n\n    let mut found = false;\n    let frames = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    for frame in frames {\n        for symbol in frame.symbols() {\n            if let Some(file) = symbol.file() {\n                if file.ends_with(\"input.rs\") {\n                    found = true;\n                    assert!(symbol.name().unwrap().contains(\"main\"));\n                    assert_eq!(symbol.line(), Some(3));\n                }\n            }\n        }\n    }\n    assert!(found);\n    Ok(())\n}"}
{"code": "pub fn status(self, value: StatusCode) -> Self {\n        let (id, mut pseudo, fields) = self.into_parts();\n\n        pseudo.set_status(value);\n\n        Mock(frame::Headers::new(id, pseudo, fields))\n    }", "test": "async fn configure_max_frame_size() {\n    h2_support::trace_init!();\n    let (io, mut srv) = mock::new();\n\n    let h2 = async move {\n        let (mut client, h2) = client::Builder::new()\n            .max_frame_size(16_384 * 2)\n            .handshake::<_, Bytes>(io)\n            .await\n            .expect(\"handshake\");\n\n        let req = async move {\n            let resp = client.get(\"https://example.com/\").await.expect(\"response\");\n            assert_eq!(resp.status(), StatusCode::OK);\n            let body = resp.into_parts().1;\n            let buf = util::concat(body).await.expect(\"body\");\n            assert_eq!(buf.len(), 16_385);\n        };\n\n        join(async move { h2.await.expect(\"client\") }, req).await;\n    };\n    // a good peer\n    srv.codec_mut().set_max_send_frame_size(16_384 * 2);\n\n    let srv = async move {\n        let _ = srv.assert_client_handshake().await;\n        srv.recv_frame(\n            frames::headers(1)\n                .request(\"GET\", \"https://example.com/\")\n                .eos(),\n        )\n        .await;\n        srv.send_frame(frames::headers(1).response(200)).await;\n        srv.send_frame(frames::data(1, vec![0; 16_385]).eos()).await;\n    };\n    join(srv, h2).await;\n}"}
{"code": "pub fn as_slice(&self) -> &[A::Item] {\n    self.deref()\n  }", "test": "fn ArrayVec_append() {\n  let mut av = array_vec!([i32; 8] => 1, 2, 3);\n  let mut av2 = array_vec!([i32; 8] => 4, 5, 6);\n  //\n  av.append(&mut av2);\n  assert_eq!(av.as_slice(), &[1_i32, 2, 3, 4, 5, 6]);\n  assert_eq!(av2.as_slice(), &[]);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_target_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_mv_target_dir_dir\";\n    let file_a = \"test_mv_target_dir_file_a\";\n    let file_b = \"test_mv_target_dir_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    at.mkdir(dir);\n    ucmd.arg(\"-t\")\n        .arg(dir)\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{dir}/{file_a}\")));\n    assert!(at.file_exists(format!(\"{dir}/{file_b}\")));\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_target_dir_from_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_ln_target_dir_dir\";\n    let from_dir = \"test_ln_target_dir_from_dir\";\n    let filename_a = \"test_ln_target_dir_file_a\";\n    let filename_b = \"test_ln_target_dir_file_b\";\n    let file_a = &format!(\"{from_dir}/{filename_a}\");\n    let file_b = &format!(\"{from_dir}/{filename_b}\");\n\n    at.mkdir(from_dir);\n    at.touch(file_a);\n    at.touch(file_b);\n    at.mkdir(dir);\n\n    ucmd.args(&[\"-s\", \"-t\", dir, file_a, file_b])\n        .succeeds()\n        .no_stderr();\n\n    let file_a_link = &format!(\"{dir}/{filename_a}\");\n    assert!(at.is_symlink(file_a_link));\n    assert_eq!(&at.resolve_link(file_a_link), file_a);\n\n    let file_b_link = &format!(\"{dir}/{filename_b}\");\n    assert!(at.is_symlink(file_b_link));\n    assert_eq!(&at.resolve_link(file_b_link), file_b);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date6() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"2000-01-01 00:00\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let expected = FileTime::from_unix_time(946_684_800, 0);\n\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, expected);\n    assert_eq!(mtime, expected);\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_relative_path() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_symlink_existing_dir\";\n    let file_a = \"test_symlink_relative_a\";\n    let link = \"test_symlink_relative_link\";\n    let multi_dir =\n        \"test_symlink_existing_dir/../test_symlink_existing_dir/../test_symlink_existing_dir/../\";\n    let p = PathBuf::from(multi_dir).join(file_a);\n    at.mkdir(dir);\n\n    // relative symlink\n    // Thanks to -r, all the ../ should be resolved to a single file\n    ucmd.args(&[\"-r\", \"-s\", \"-v\", &p.to_string_lossy(), link])\n        .succeeds()\n        .stdout_only(format!(\"'{link}' -> '{file_a}'\\n\"));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file_a);\n\n    // Run the same command without -r to verify that we keep the full\n    // crazy path\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-s\", \"-v\", &p.to_string_lossy(), link])\n        .succeeds()\n        .stdout_only(format!(\"'{}' -> '{}'\\n\", link, &p.to_string_lossy()));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), p.to_string_lossy());\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_non_existing_files() {\n    let scenario = TestScenario::new(util_name!());\n\n    let result = scenario\n        .ucmd()\n        .args(&[\"newer_file\", \"-nt\", \"regular_file\"])\n        .fails();\n    assert!(result.stderr().is_empty());\n}"}
{"code": "fn compute_error_scaled64(q: i32, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f64>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled64_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 10),\n        (1065 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 10),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 10),\n        (1065 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 10),\n        (1065 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 10),\n        (1065 + f64::INVALID_FP, 9223372036854779904)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 9),\n        (1066 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 9),\n        (1066 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 9),\n        (1066 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 9),\n        (1066 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 9),\n        (1066 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test a much closer set of examples.\n    assert_eq!(\n        compute_error_scaled64(0, 9223372036854774784, 11),\n        (1064 + f64::INVALID_FP, 18446744073709549568)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388415, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776830)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765748947, 10),\n        (925 + f64::INVALID_FP, 13021432563531497894)\n    );\n    assert_eq!(\n        compute_error_scaled64(-43, 6510716281765749303, 7),\n        (925 + f64::INVALID_FP, 13021432563531498606)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765749660, 10),\n        (925 + f64::INVALID_FP, 13021432563531499320)\n    );\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854775808, 1),\n        (1065 + f64::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854776832, 1),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854777856, 1),\n        (1065 + f64::INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854778880, 1),\n        (1065 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854779904, 1),\n        (1065 + f64::INVALID_FP, 9223372036854779904)\n    );\n\n    // Test from errors in atof.\n    assert_eq!(\n        compute_error_scaled64(-18, 9223373686122217470, 4),\n        (1012 + f64::INVALID_FP, 9223373686122217470)\n    );\n\n    // Check edge-cases from previous errors.\n    assert_eq!(\n        compute_error_scaled64(-342, 9223372036854775804, 2),\n        (-64 + f64::INVALID_FP, 18446744073709551608)\n    );\n}"}
{"code": "pub fn is_close(&self) -> bool {\n        matches!(*self, Message::Close(_))\n    }", "test": "fn test_server_close() {\n    do_test(\n        3012,\n        |mut cli_sock| {\n            cli_sock.send(Message::Text(\"Hello WebSocket\".into())).unwrap();\n\n            let message = cli_sock.read().unwrap(); // receive close from server\n            assert!(message.is_close());\n\n            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n        |mut srv_sock| {\n            let message = srv_sock.read().unwrap();\n            assert_eq!(message.into_data(), b\"Hello WebSocket\");\n\n            srv_sock.close(None).unwrap(); // send close to client\n\n            let message = srv_sock.read().unwrap(); // receive acknowledgement\n            assert!(message.is_close());\n\n            let err = srv_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n    );\n}"}
{"code": "fn validate_alignment_score(al: &Alignment, x: TextSlice, y: TextSlice, scoring: &Scoring<MatchParams>) -> bool {\n    use AlignmentOperation::*;\n    let path = al.path();\n    let mut score = 0;\n    if al.mode==AlignmentMode::Custom {\n        if al.xstart > 0 {\n            score += scoring.xclip_prefix;\n        }\n        if al.ystart > 0 {\n            score += scoring.yclip_prefix;\n        }\n        if al.xend < al.xlen {\n            score += scoring.xclip_suffix;\n        }\n        if al.yend < al.ylen {\n            score += scoring.yclip_suffix;\n        }\n    }\n    let mut last_op = None;\n    for (i, j, op) in path {\n        score += match op {\n            Match | Subst => scoring.match_fn.score(x[i-1], y[j-1]),\n            Del => if last_op==Some(Del) { scoring.gap_extend } else { scoring.gap_open + scoring.gap_extend },\n            Ins => if last_op==Some(Ins) { scoring.gap_extend } else { scoring.gap_open + scoring.gap_extend },\n            _ => 0,\n        };\n        last_op = Some(op);\n    }\n    al.score==score\n}", "test": "fn test_something() {\n    let data = [];\n    if data.len() < 50 || data.len() > 300 {\n        return;\n    }\n    let (split_byte, data) = data.split_first().unwrap();\n    let (kmer_byte, data) = data.split_first().unwrap();\n    let (window_byte, data) = data.split_first().unwrap();\n    let (match_score_byte, data) = data.split_first().unwrap();\n    let (mismatch_score_byte, data) = data.split_first().unwrap();\n    let (gap_open_byte, data) = data.split_first().unwrap();\n    let (gap_extend_byte, data) = data.split_first().unwrap();\n    let (xclip_prefix_byte, data) = data.split_first().unwrap();\n    let (xclip_suffix_byte, data) = data.split_first().unwrap();\n    let (yclip_prefix_byte, data) = data.split_first().unwrap();\n    let (yclip_suffix_byte, data) = data.split_first().unwrap();\n    let alphabets = b\"ACGT\";\n    let v: Vec<_> = data\n        .iter()\n        .map(|i| alphabets[(*i as usize) % alphabets.len()])\n        .collect();\n    let kmer_len: usize = 5 + (*kmer_byte as usize) % 10;\n    let window_size: usize = 5 + (*window_byte as usize) % 10;\n    let split_pos: usize = min(data.len() - 1, max(*split_byte as usize, 1));\n    let match_score = 1 + (*match_score_byte as i32) % 5;\n    let mismatch_score = -((*mismatch_score_byte as i32) % 10);\n    let gap_open = -((*gap_open_byte as i32) % 20);\n    let gap_extend = -((*gap_extend_byte as i32) % 10);\n    let (x, y) = v.split_at(split_pos);\n    println!(\n        \"x: {}, y: {}, k: {}, w: {}, scoring ({}, {}, {}, {})\",\n        String::from_utf8(x.to_vec()).unwrap(),\n        String::from_utf8(y.to_vec()).unwrap(),\n        kmer_len,\n        window_size,\n        gap_open,\n        gap_extend,\n        match_score,\n        mismatch_score\n    );\n    let base_score = Scoring::from_scores(gap_open, gap_extend, match_score, mismatch_score);\n    {\n        println!(\n            \"Clip scores ({}, {}, {}, {})\",\n            xclip_prefix_byte, xclip_suffix_byte, yclip_prefix_byte, yclip_suffix_byte\n        );\n        let scoring = Scoring {\n            xclip_prefix: -(*xclip_prefix_byte as i32),\n            xclip_suffix: -(*xclip_suffix_byte as i32),\n            yclip_prefix: -(*yclip_prefix_byte as i32),\n            yclip_suffix: -(*yclip_suffix_byte as i32),\n            ..base_score.clone()\n        };\n        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);\n        let b_alignment = b_aligner.custom(x, y);\n        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));\n        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());\n        let f_alignment = f_aligner.custom(x, y);\n        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));\n        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());\n        assert_eq!(band_all_alignment.score, f_alignment.score);\n    }\n    {\n        let scoring = Scoring {\n            xclip_prefix: 0,\n            xclip_suffix: 0,\n            yclip_suffix: 0,\n            ..base_score.clone()\n        };\n        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);\n        let b_alignment = b_aligner.custom(x, y);\n        assert_eq!(b_alignment.ystart, 0);\n        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));\n        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());\n        let f_alignment = f_aligner.custom(x, y);\n        assert_eq!(f_alignment.ystart, 0);\n        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));\n        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());\n        assert_eq!(band_all_alignment.score, f_alignment.score);\n    }\n    {\n        let scoring = Scoring {\n            xclip_prefix: 0,\n            xclip_suffix: 0,\n            yclip_prefix: 0,\n            ..base_score.clone()\n        };\n        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);\n        let b_alignment = b_aligner.custom(x, y);\n        assert_eq!(b_alignment.yend, b_alignment.ylen);\n        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));\n        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());\n        let f_alignment = f_aligner.custom(x, y);\n        assert_eq!(f_alignment.yend, f_alignment.ylen);\n        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));\n        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());\n        assert_eq!(band_all_alignment.score, f_alignment.score);\n    }\n    {\n        let scoring = Scoring {\n            xclip_suffix: 0,\n            yclip_prefix: 0,\n            yclip_suffix: 0,\n            ..base_score.clone()\n        };\n        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);\n        let b_alignment = b_aligner.custom(x, y);\n        assert_eq!(b_alignment.xstart, 0);\n        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));\n        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());\n        let f_alignment = f_aligner.custom(x, y);\n        assert_eq!(f_alignment.xstart, 0);\n        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));\n        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());\n        assert_eq!(band_all_alignment.score, f_alignment.score);\n    }\n    {\n        let scoring = Scoring {\n            xclip_prefix: 0,\n            yclip_prefix: 0,\n            yclip_suffix: 0,\n            ..base_score.clone()\n        };\n        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);\n        let b_alignment = b_aligner.custom(x, y);\n        assert_eq!(b_alignment.xend, b_alignment.xlen);\n        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));\n        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());\n        let f_alignment = f_aligner.custom(x, y);\n        assert_eq!(f_alignment.xend, f_alignment.xlen);\n        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));\n        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());\n        assert_eq!(band_all_alignment.score, f_alignment.score);\n    }\n    {\n        let mut aligner = banded::Aligner::with_scoring(base_score.clone(), kmer_len, window_size);\n        let alignment = aligner.local(x, y);\n        assert!(alignment.score >= 0);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n        let alignment = aligner.semiglobal(x, y);\n        assert_eq!(alignment.xstart, 0);\n        assert_eq!(alignment.xend, alignment.xlen);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n        let alignment = aligner.global(x, y);\n        assert_eq!(alignment.xstart, 0);\n        assert_eq!(alignment.xend, alignment.xlen);\n        assert_eq!(alignment.ystart, 0);\n        assert_eq!(alignment.yend, alignment.ylen);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n    }\n    {\n        let mut aligner = pairwise::Aligner::with_scoring(base_score.clone());\n        let alignment = aligner.local(x, y);\n        assert!(alignment.score >= 0);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n        let alignment = aligner.semiglobal(x, y);\n        assert_eq!(alignment.xstart, 0);\n        assert_eq!(alignment.xend, alignment.xlen);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n        let alignment = aligner.global(x, y);\n        assert_eq!(alignment.xstart, 0);\n        assert_eq!(alignment.xend, alignment.xlen);\n        assert_eq!(alignment.ystart, 0);\n        assert_eq!(alignment.yend, alignment.ylen);\n        assert!(validate_alignment_score(&alignment, x, y, &base_score));\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn drain_forget() {\n    // test mem::forgetting does not double-free\n\n    let mut headers = HeaderMap::<HeaderValue>::new();\n    headers.insert(\"hello\", \"world\".parse().unwrap());\n    headers.insert(\"zomg\", \"bar\".parse().unwrap());\n\n    assert_eq!(headers.len(), 2);\n\n    {\n        let mut iter = headers.drain();\n        assert_eq!(iter.size_hint(), (2, Some(2)));\n        let _ = iter.next().unwrap();\n        std::mem::forget(iter);\n    }\n\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_by_rdata() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // append a record\n    let mut record1 = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record1.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = io_loop\n        .block_on(client.delete_by_rdata(record1.clone(), origin.clone()))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = io_loop\n        .block_on(client.create(record1.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let mut record2 = record1.clone();\n    record2.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let result = io_loop\n        .block_on(client.append(record2.clone(), origin.clone(), true))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = io_loop\n        .block_on(client.delete_by_rdata(record2, origin))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(\n            record1.name().clone(),\n            record1.dns_class(),\n            record1.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert!(result.answers().iter().any(|rr| *rr == record1));\n}"}
{"code": "fn is_client_error() {\n    assert!(status_code(400).is_client_error());\n    assert!(status_code(499).is_client_error());\n\n    assert!(!status_code(399).is_client_error());\n    assert!(!status_code(500).is_client_error());\n}", "test": "fn is_client_error() {\n    assert!(status_code(400).is_client_error());\n    assert!(status_code(499).is_client_error());\n\n    assert!(!status_code(399).is_client_error());\n    assert!(!status_code(500).is_client_error());\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_update_all() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .arg(\"--update=all\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert_eq!(\n        at.read(TEST_HOW_ARE_YOU_SOURCE),\n        at.read(TEST_HELLO_WORLD_SOURCE)\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_rename_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file1 = \"test_mv_rename_file\";\n    let file2 = \"test_mv_rename_file2\";\n\n    at.touch(file1);\n\n    ucmd.arg(file1).arg(file2).succeeds().no_stderr();\n    assert!(at.file_exists(file2));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_ancestors_mode_directories() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ancestor1 = \"ancestor1\";\n    let ancestor2 = \"ancestor1/ancestor2\";\n    let target_dir = \"ancestor1/ancestor2/target_dir\";\n    let directories_arg = \"-d\";\n    let mode_arg = \"--mode=200\";\n    let probe = \"probe\";\n\n    at.mkdir(probe);\n    let default_perms = at.metadata(probe).permissions().mode();\n\n    ucmd.args(&[mode_arg, directories_arg, target_dir])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(ancestor1));\n    assert!(at.dir_exists(ancestor2));\n    assert!(at.dir_exists(target_dir));\n\n    assert_eq!(default_perms, at.metadata(ancestor1).permissions().mode());\n    assert_eq!(default_perms, at.metadata(ancestor2).permissions().mode());\n\n    // Expected mode only on the target_dir.\n    assert_eq!(0o40_200_u32, at.metadata(target_dir).permissions().mode());\n}"}
{"code": "pub(crate) fn next(&mut self) -> Option<(ResetToken, Range<u64>)> {\n        let (i, cid_data) = self.iter().nth(1)?;\n        self.buffer[self.cursor] = None;\n\n        let orig_offset = self.offset;\n        self.offset += i as u64;\n        self.cursor = (self.cursor + i) % Self::LEN;\n        Some((cid_data.1.unwrap(), orig_offset..self.offset))\n    }", "test": "fn finish_stream_flow_control_reordered() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive_client(); // Send stream data\n    pair.server.drive(pair.time, pair.client.addr); // Receive\n\n    // Issue flow control credit\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(\n        chunks.next(usize::MAX),\n        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG\n    );\n    let _ = chunks.finalize();\n\n    pair.server.drive(pair.time, pair.client.addr);\n    pair.server.delay_outbound(); // Delay it\n\n    pair.client_send(client_ch, s).finish().unwrap();\n    pair.drive_client(); // Send FIN\n    pair.server.drive(pair.time, pair.client.addr); // Acknowledge\n    pair.server.finish_delay(); // Add flow control packets after\n    pair.drive();\n\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::Stream(StreamEvent::Finished { id })) if id == s\n    );\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Ok(None));\n    let _ = chunks.finalize();\n}"}
{"code": "fn len(&self) -> Result<u64> {\n        let mut count = 0;\n        for item in self.iter()? {\n            let (_, values) = item?;\n            for v in values {\n                v?;\n                count += 1;\n            }\n        }\n        Ok(count)\n    }", "test": "fn len() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n        table.insert(\"hello\", \"world2\").unwrap();\n        table.insert(\"hi\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert_eq!(table.len().unwrap(), 3);\n}"}
{"code": "fn finish(&self) -> u64 {\n        self.inner.finish()\n    }", "test": "fn named_field_struct() {\n    #[derive(CacheKey, Hash)]\n    struct NamedFieldsStruct {\n        a: String,\n        b: String,\n    }\n\n    let mut key = CacheKeyHasher::new();\n\n    let named_fields = NamedFieldsStruct {\n        a: \"Hello\".into(),\n        b: \"World\".into(),\n    };\n\n    named_fields.cache_key(&mut key);\n\n    let mut hash = CacheKeyHasher::new();\n    named_fields.hash(&mut hash);\n\n    assert_eq!(hash.finish(), key.finish());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_target_new_file_with_owner() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"file\";\n    let dir = \"target_dir\";\n    let uid = geteuid();\n\n    at.touch(file);\n    at.mkdir(dir);\n    let result = ucmd\n        .arg(file)\n        .arg(\"--owner\")\n        .arg(uid.to_string())\n        .arg(format!(\"{dir}/{file}\"))\n        .run();\n\n    if is_ci() && result.stderr_str().contains(\"no such user:\") {\n        // In the CI, some server are failing to return the user id.\n        // As seems to be a configuration issue, ignoring it\n        return;\n    }\n\n    result.success();\n    assert!(at.file_exists(file));\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn print_verbose() {\n    let mut fs = MemoryFileSystem::default();\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), LINT_ERROR.as_bytes());\n\n    let mut console = BufferConsole::default();\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"ci\"),\n                (\"--verbose\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"print_verbose\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_starts_combined_shorts() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let name = \"obs-lines-starts-shorts\";\n    RandomFile::new(at, name).add_lines(400);\n\n    scene\n        .ucmd()\n        .args(&[\"-200xd\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(at, \".\", r\"x\\d\\d$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "fn encode<T: AsRef<[u8]>>(&self, input: T) -> String {\n        fn inner<E>(engine: &E, input_bytes: &[u8]) -> String\n        where\n            E: Engine + ?Sized,\n        {\n            let encoded_size = encoded_len(input_bytes.len(), engine.config().encode_padding())\n                .expect(\"integer overflow when calculating buffer size\");\n\n            let mut buf = vec![0; encoded_size];\n\n            encode_with_padding(input_bytes, &mut buf[..], engine, encoded_size);\n\n            String::from_utf8(buf).expect(\"Invalid UTF8\")\n        }\n\n        inner(self, input.as_ref())\n    }", "test": "fn encode_all_bytes_url() {\n    let bytes: Vec<u8> = (0..=255).collect();\n\n    assert_eq!(\n        \"AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0\\\n         -P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn\\\n         -AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq\\\n         -wsbKztLW2t7i5uru8vb6_wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t_g4eLj5OXm5-jp6uvs7e7v8PHy\\\n         8_T19vf4-fr7_P3-_w==\",\n        &engine::GeneralPurpose::new(&URL_SAFE, PAD).encode(bytes)\n    );\n}"}
{"code": "pub fn get_resolved_ts(&self, region_id: &u64) -> Option<u64> {\n        self.registry\n            .lock()\n            .unwrap()\n            .get(region_id)\n            .map(|rp| rp.resolved_ts())\n    }", "test": "fn test_resolved_ts_with_learners() {\n    let cluster = new_server_cluster(0, 2);\n    cluster.pd_client.disable_default_operator();\n    let mut suite = TestSuiteBuilder::new()\n        .cluster(cluster)\n        .build_with_cluster_runner(|cluster| {\n            let r = cluster.run_conf_change();\n            cluster.pd_client.must_add_peer(r, new_learner_peer(2, 2));\n        });\n\n    let rid = suite.cluster.get_region(&[]).id;\n    let req = suite.new_changedata_request(rid);\n    let (mut req_tx, _, receive_event) = new_event_feed(suite.get_region_cdc_client(rid));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n\n    for _ in 0..10 {\n        let event = receive_event(true);\n        if event.has_resolved_ts() {\n            assert!(event.get_resolved_ts().regions == vec![rid]);\n            drop(receive_event);\n            suite.stop();\n            return;\n        }\n    }\n    panic!(\"resolved timestamp should be advanced correctly\");\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn tuple2_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: TableDefinition<(&str, u8), (u16, u32)> = TableDefinition::new(\"table\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(table_def).unwrap();\n        table.insert(&(\"hello\", 5), &(0, 123)).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(table_def).unwrap();\n    assert_eq!(table.get(&(\"hello\", 5)).unwrap().unwrap().value(), (0, 123));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_multiple_a() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_3=value 3\".parse().unwrap());\n    headers.insert(VARY, \"*\".parse().unwrap());\n\n    assert_eq!(headers.len(), 6);\n\n    let cookie = headers.remove(SET_COOKIE);\n    assert_eq!(cookie, Some(\"cookie_1=value 1\".parse().unwrap()));\n    assert_eq!(headers.len(), 3);\n\n    let via = headers.remove(VIA);\n    assert_eq!(via, Some(\"1.1 example.com\".parse().unwrap()));\n    assert_eq!(headers.len(), 1);\n\n    let vary = headers.remove(VARY);\n    assert_eq!(vary, Some(\"*\".parse().unwrap()));\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mkdir_parent_mode_check_existing_parent() {\n    let _guard = TEST_MUTEX.lock();\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    at.mkdir(\"a\");\n\n    let default_umask: mode_t = 0o160;\n    let original_umask = unsafe { umask(default_umask) };\n\n    ucmd.arg(\"-p\")\n        .arg(\"a/b/c\")\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n\n    assert!(at.dir_exists(\"a\"));\n    // parent dirs that already exist do not get their permissions modified\n    assert_eq!(\n        at.metadata(\"a\").permissions().mode() as mode_t,\n        (!original_umask & 0o777) + 0o40000\n    );\n    assert!(at.dir_exists(\"a/b\"));\n    assert_eq!(\n        at.metadata(\"a/b\").permissions().mode() as mode_t,\n        ((!default_umask & 0o777) | 0o300) + 0o40000\n    );\n    assert!(at.dir_exists(\"a/b/c\"));\n    assert_eq!(\n        at.metadata(\"a/b/c\").permissions().mode() as mode_t,\n        (!default_umask & 0o777) + 0o40000\n    );\n\n    unsafe {\n        umask(original_umask);\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large_config_limit() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    fs.insert(PathBuf::from(\"biome.json\"), CONFIG_FILE_SIZE_LIMIT);\n\n    let file_path = Path::new(\"ci.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large_config_limit\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn strip_end_newline() {\n    assert_eq!(\"test\", normalize_html(\"test\\n\"));\n}"}
{"code": "fn code(&self, pc: usize) -> Option<(&LoadedCode, usize)> {\n        let (end, (start, code)) = self.loaded_code.range(pc..).next()?;\n        if pc < *start || *end < pc {\n            return None;\n        }\n        Some((code, pc - *start))\n    }", "test": "fn exit125_wasi_snapshot0() -> Result<()> {\n    let wasm = build_wasm(\"tests/all/cli_tests/exit125_wasi_snapshot0.wat\")?;\n    let output = run_wasmtime_for_output(&[\"-Ccache=n\", wasm.path().to_str().unwrap()], None)?;\n    if cfg!(windows) {\n        assert_eq!(output.status.code().unwrap(), 1);\n    } else {\n        assert_eq!(output.status.code().unwrap(), 125);\n    }\n    Ok(())\n}"}
{"code": "pub(crate) fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.page.memory()[self.value_range.clone()])\n    }", "test": "fn range_lifetime() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let definition: TableDefinition<&str, &str> = TableDefinition::new(\"x\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(definition).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(definition).unwrap();\n\n    let mut iter = {\n        let start = \"hello\".to_string();\n        table.range::<&str>(start.as_str()..).unwrap()\n    };\n    assert_eq!(iter.next().unwrap().unwrap().1.value(), \"world\");\n    assert!(iter.next().is_none());\n}"}
{"code": "fn is_ok(&self) -> bool {\n        let count = self.count.fetch_add(1, Ordering::SeqCst);\n        if count != 0 && count % self.retry == 0 {\n            // it's ok.\n            return true;\n        }\n        // let's sleep awhile, so that client will update its connection.\n        thread::sleep(REQUEST_RECONNECT_INTERVAL);\n        false\n    }", "test": "fn test_scheduler_pool_auto_switch_for_resource_ctl() {\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let resource_manager = ResourceGroupManager::default();\n    let resource_ctl = resource_manager.derive_controller(\"test\".to_string(), true);\n\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .config(cluster.cfg.tikv.storage.clone())\n        .build_for_resource_controller(resource_ctl)\n        .unwrap();\n\n    let region = cluster.get_region(b\"k1\");\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.id);\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(cluster.leader_of_region(region.id).unwrap());\n\n    let do_prewrite = |key: &[u8], val: &[u8]| {\n        // prewrite\n        let (prewrite_tx, prewrite_rx) = channel();\n        storage\n            .sched_txn_command(\n                commands::Prewrite::new(\n                    vec![Mutation::make_put(Key::from_raw(key), val.to_vec())],\n                    key.to_vec(),\n                    10.into(),\n                    100,\n                    false,\n                    2,\n                    TimeStamp::default(),\n                    TimeStamp::default(),\n                    None,\n                    false,\n                    AssertionLevel::Off,\n                    ctx.clone(),\n                ),\n                Box::new(move |res: storage::Result<_>| {\n                    let _ = prewrite_tx.send(res);\n                }),\n            )\n            .unwrap();\n        prewrite_rx.recv_timeout(Duration::from_secs(2))\n    };\n\n    let (sender, receiver) = channel();\n    let priority_queue_sender = Mutex::new(sender.clone());\n    let single_queue_sender = Mutex::new(sender);\n    fail::cfg_callback(\"priority_pool_task\", move || {\n        let sender = priority_queue_sender.lock().unwrap();\n        sender.send(\"priority_queue\").unwrap();\n    })\n    .unwrap();\n    fail::cfg_callback(\"single_queue_pool_task\", move || {\n        let sender = single_queue_sender.lock().unwrap();\n        sender.send(\"single_queue\").unwrap();\n    })\n    .unwrap();\n\n    // Default is use single queue\n    assert_eq!(do_prewrite(b\"k1\", b\"v1\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"single_queue\"\n    );\n\n    // Add group use priority queue\n    use kvproto::resource_manager::{GroupMode, GroupRequestUnitSettings, ResourceGroup};\n    let mut group = ResourceGroup::new();\n    group.set_name(\"rg1\".to_string());\n    group.set_mode(GroupMode::RuMode);\n    let mut ru_setting = GroupRequestUnitSettings::new();\n    ru_setting.mut_r_u().mut_settings().set_fill_rate(100000);\n    group.set_r_u_settings(ru_setting);\n    resource_manager.add_resource_group(group);\n    thread::sleep(Duration::from_millis(200));\n    assert_eq!(do_prewrite(b\"k2\", b\"v2\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"priority_queue\"\n    );\n\n    // Delete group use single queue\n    resource_manager.remove_resource_group(\"rg1\");\n    thread::sleep(Duration::from_millis(200));\n    assert_eq!(do_prewrite(b\"k3\", b\"v3\").is_ok(), true);\n    assert_eq!(\n        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),\n        \"single_queue\"\n    );\n\n    // Scale pool size\n    let scheduler = storage.get_scheduler();\n    let pool = scheduler.get_sched_pool();\n    assert_eq!(pool.get_pool_size(CommandPri::Normal), 1);\n    pool.scale_pool_size(2);\n    assert_eq!(pool.get_pool_size(CommandPri::Normal), 2);\n}"}
{"code": "pub const fn lossy(mut self, lossy: bool) -> Self {\n        self.lossy = lossy;\n        self\n    }", "test": "fn options_test() {\n    let mut opts = Options::new();\n\n    unsafe {\n        opts.set_lossy(true);\n        opts.set_exponent(b'^');\n        opts.set_decimal_point(b',');\n        opts.set_nan_string(Some(b\"nan\"));\n        opts.set_inf_string(Some(b\"Infinity\"));\n        opts.set_infinity_string(Some(b\"Infiniiiiiity\"));\n    }\n\n    assert_eq!(opts.lossy(), true);\n    assert_eq!(opts.exponent(), b'^');\n    assert_eq!(opts.decimal_point(), b',');\n    assert_eq!(opts.nan_string(), Some(\"nan\".as_bytes()));\n    assert_eq!(opts.inf_string(), Some(\"Infinity\".as_bytes()));\n    assert_eq!(opts.infinity_string(), Some(\"Infiniiiiiity\".as_bytes()));\n    assert!(opts.is_valid());\n\n    assert_eq!(Options::builder(), OptionsBuilder::new());\n    assert_eq!(opts.rebuild().build(), Ok(opts));\n}"}
{"code": "fn compute_error_scaled32(q: i32, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f32>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled32_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(\n        compute_error_scaled32(0, 4611686018427387904, 39),\n        (111 + f32::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686293305294848, 39),\n        (111 + f32::INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686568183201792, 39),\n        (111 + f32::INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686843061108736, 39),\n        (111 + f32::INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611687117939015680, 39),\n        (111 + f32::INVALID_FP, 9223374235878031360)\n    );\n\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372036854775808, 6),\n        (111 + f32::INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372586610589696, 6),\n        (111 + f32::INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373136366403584, 6),\n        (111 + f32::INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373686122217472, 6),\n        (111 + f32::INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223374235878031360, 6),\n        (111 + f32::INVALID_FP, 9223374235878031360)\n    );\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn drops_empty_tbody() {\n    assert_eq!(\n        \"<table><thead><tr><td>hi</td></tr></thead></table>\",\n        normalize_html(\"<table><thead><tr><td>hi</td></tr></thead><tbody>  </tbody></table>\")\n    )\n}"}
{"code": "pub fn parse<N: FromLexical, Bytes: AsRef<[u8]>>(bytes: Bytes) -> Result<N> {\n    N::from_lexical(bytes.as_ref())\n}", "test": "fn test_try_parse_4digits() {\n    let parse = |bytes: &[u8]| {\n        let mut digits = bytes.bytes::<{ STANDARD }>();\n        algorithm::try_parse_4digits::<u32, _, STANDARD>(&mut digits.integer_iter())\n    };\n    assert_eq!(parse(b\"1234\"), Some(1234));\n    assert_eq!(parse(b\"123\"), None);\n    assert_eq!(parse(b\"123\\x00\"), None);\n    assert_eq!(parse(b\"123.\"), None);\n    assert_eq!(parse(b\"123_\"), None);\n    assert_eq!(parse(b\"1234_\"), Some(1234));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn file_too_large() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"format.js\");\n    fs.insert(file_path.into(), \"statement();\\n\".repeat(80660).as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                file_path.as_os_str().to_str().unwrap(),\n                (\"--write\"),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    // Do not store the content of the file in the snapshot\n    fs.remove(file_path);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"file_too_large\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_bytes_prime_part_size() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"test_split_bytes_prime_part_size\";\n    RandomFile::new(&at, name).add_bytes(10000);\n    // 1753 is prime and greater than the buffer size, 1024.\n    ucmd.args(&[\"-b\", \"1753\", name, \"b\"]).succeeds();\n\n    let glob = Glob::new(&at, \".\", r\"b[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 6);\n    let mut fns = glob.collect();\n    // glob.collect() is not guaranteed to return in sorted order, so we sort.\n    fns.sort();\n    #[allow(clippy::needless_range_loop)]\n    for i in 0..5 {\n        assert_eq!(glob.directory.metadata(&fns[i]).len(), 1753);\n    }\n    assert_eq!(glob.directory.metadata(&fns[5]).len(), 1235);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_interactive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file = \"test_symlink_interactive_file\";\n    let link = \"test_symlink_interactive_file_link\";\n\n    at.touch(file);\n    at.touch(link);\n\n    scene\n        .ucmd()\n        .args(&[\"-i\", \"-s\", file, link])\n        .pipe_in(\"n\")\n        .fails()\n        .no_stdout();\n\n    assert!(at.file_exists(file));\n    assert!(!at.is_symlink(link));\n\n    scene\n        .ucmd()\n        .args(&[\"-i\", \"-s\", file, link])\n        .pipe_in(\"Yesh\") // spell-checker:disable-line\n        .succeeds()\n        .no_stdout();\n\n    assert!(at.file_exists(file));\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), file);\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn read_isolation2() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(STR_TABLE).unwrap();\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    {\n        let mut write_table = write_txn.open_table(STR_TABLE).unwrap();\n        write_table.remove(\"hello\").unwrap();\n        write_table.insert(\"hello2\", \"world2\").unwrap();\n        write_table.insert(\"hello3\", \"world3\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn2 = db.begin_read().unwrap();\n    let table2 = read_txn2.open_table(STR_TABLE).unwrap();\n    assert!(table2.get(\"hello\").unwrap().is_none());\n    assert_eq!(\"world2\", table2.get(\"hello2\").unwrap().unwrap().value());\n    assert_eq!(\"world3\", table2.get(\"hello3\").unwrap().unwrap().value());\n    assert_eq!(table2.len().unwrap(), 2);\n\n    assert_eq!(\"world\", table.get(\"hello\").unwrap().unwrap().value());\n    assert!(table.get(\"hello2\").unwrap().is_none());\n    assert!(table.get(\"hello3\").unwrap().is_none());\n    assert_eq!(table.len().unwrap(), 1);\n}"}
{"code": "pub fn is_inline(&self) -> bool {\n    !self.is_heap()\n  }", "test": "fn TinyVec_move_to_heap_and_shrink() {\n  let mut tv: TinyVec<[i32; 4]> = Default::default();\n  assert!(tv.is_inline());\n  tv.move_to_the_heap();\n  assert!(tv.is_heap());\n  assert_eq!(tv.capacity(), 0);\n\n  tv.push(1);\n  tv.shrink_to_fit();\n  assert!(tv.is_inline());\n  assert_eq!(tv.capacity(), 4);\n\n  tv.move_to_the_heap_and_reserve(3);\n  assert!(tv.is_heap());\n  assert_eq!(tv.capacity(), 4);\n  tv.extend(2..=4);\n  assert_eq!(tv.capacity(), 4);\n  assert_eq!(tv.as_slice(), [1, 2, 3, 4]);\n}"}
{"code": "fn method(s: &str) -> Header<Option<HeaderName>> {\n        Header::Method(Method::from_bytes(s.as_bytes()).unwrap())\n    }", "test": "async fn push_request_disabled() {\n    h2_support::trace_init!();\n    let (io, mut client) = mock::new();\n\n    let client = async move {\n        client\n            .assert_server_handshake_with_settings(frames::settings().disable_push())\n            .await;\n        client\n            .send_frame(\n                frames::headers(1)\n                    .request(\"GET\", \"https://example.com/\")\n                    .eos(),\n            )\n            .await;\n        client\n            .recv_frame(frames::headers(1).response(200).eos())\n            .await;\n    };\n\n    let srv = async move {\n        let mut srv = server::handshake(io).await.expect(\"handshake\");\n        let (req, mut stream) = srv.next().await.unwrap().unwrap();\n\n        assert_eq!(req.method(), &http::Method::GET);\n\n        // attempt to push - expect failure\n        let req = http::Request::builder()\n            .method(\"GET\")\n            .uri(\"https://http2.akamai.com/style.css\")\n            .body(())\n            .unwrap();\n        stream\n            .push_request(req)\n            .expect_err(\"push_request should error\");\n\n        // send normal response\n        let rsp = http::Response::builder().status(200).body(()).unwrap();\n        stream.send_response(rsp, true).unwrap();\n\n        assert!(srv.next().await.is_none());\n    };\n\n    join(client, srv).await;\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn test_trap_return() -> Result<()> {\n    let mut store = Store::<()>::default();\n    let wat = r#\"\n        (module\n        (func $hello (import \"\" \"hello\"))\n        (func (export \"run\") (call $hello))\n        )\n    \"#;\n\n    let module = Module::new(store.engine(), wat)?;\n    let hello_type = FuncType::new(None, None);\n    let hello_func = Func::new(&mut store, hello_type, |_, _, _| bail!(\"test 123\"));\n\n    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;\n    let run_func = instance.get_typed_func::<(), ()>(&mut store, \"run\")?;\n\n    let e = run_func.call(&mut store, ()).unwrap_err();\n    assert!(format!(\"{e:?}\").contains(\"test 123\"));\n\n    assert!(\n        e.downcast_ref::<WasmBacktrace>().is_some(),\n        \"error should contain a WasmBacktrace\"\n    );\n\n    Ok(())\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn apply_suggested_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"fix.js\");\n    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"check\"),\n                (\"--apply-unsafe\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"apply_suggested_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_delete_rrset() {\n    let io_loop = Runtime::new().unwrap();\n    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());\n    hickory_proto::spawn_bg(&io_loop, bg);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = io_loop\n        .block_on(client.delete_rrset(record.clone(), origin.clone()))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // next create to a non-existent RRset\n    let result = io_loop\n        .block_on(client.create(record.clone(), origin.clone()))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n    let result = io_loop\n        .block_on(client.append(record.clone(), origin.clone(), true))\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = io_loop\n        .block_on(client.delete_rrset(record.clone(), origin))\n        .expect(\"delete failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = io_loop\n        .block_on(client.query(\n            record.name().clone(),\n            record.dns_class(),\n            record.record_type(),\n        ))\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXDomain);\n    assert_eq!(result.answers().len(), 0);\n}"}
{"code": "fn len(&self) -> usize {\n        self.length\n    }", "test": "fn test_cdc_congest() {\n    let mut cluster = new_server_cluster(1, 1);\n    // Increase the Raft tick interval to make this test case running reliably.\n    configure_for_lease_read(&mut cluster.cfg, Some(100), None);\n    let memory_quota = 1024; // 1KB\n    let mut suite = TestSuiteBuilder::new()\n        .cluster(cluster)\n        .memory_quota(memory_quota)\n        .build();\n\n    let req = suite.new_changedata_request(1);\n    let (mut req_tx, _event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(1));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n    let event = receive_event(false);\n    event.events.into_iter().for_each(|e| {\n        match e.event.unwrap() {\n            // Even if there is no write,\n            // it should always outputs an Initialized event.\n            Event_oneof_event::Entries(es) => {\n                assert!(es.entries.len() == 1, \"{:?}\", es);\n                let e = &es.entries[0];\n                assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n            }\n            other => panic!(\"unknown event {:?}\", other),\n        }\n    });\n\n    // Client must receive messages when there is no congest error.\n    let value_size = memory_quota / 2;\n    let (k, v) = (\"key1\".to_owned(), vec![5; value_size]);\n    // Prewrite\n    let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k.clone().into_bytes();\n    mutation.value = v;\n    suite.must_kv_prewrite(1, vec![mutation], k.into_bytes(), start_ts);\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1, \"{:?}\", events);\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Entries(entries) => {\n            assert_eq!(entries.entries.len(), 1);\n            assert_eq!(entries.entries[0].get_type(), EventLogType::Prewrite);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    // Trigger congest error.\n    let value_size = memory_quota * 2;\n    let (k, v) = (\"key2\".to_owned(), vec![5; value_size]);\n    // Prewrite\n    let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();\n    let mut mutation = Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k.clone().into_bytes();\n    mutation.value = v;\n    suite.must_kv_prewrite(1, vec![mutation], k.into_bytes(), start_ts);\n    let mut events = receive_event(false).events.to_vec();\n    assert_eq!(events.len(), 1, \"{:?}\", events);\n    match events.pop().unwrap().event.unwrap() {\n        Event_oneof_event::Error(e) => {\n            // Unknown errors are translated into region_not_found.\n            assert!(e.has_region_not_found(), \"{:?}\", e);\n        }\n        other => panic!(\"unknown event {:?}\", other),\n    }\n\n    // The delegate must be removed.\n    let scheduler = suite.endpoints.values().next().unwrap().scheduler();\n    let (tx, rx) = mpsc::channel();\n    scheduler\n        .schedule(Task::Validate(Validate::Region(\n            1,\n            Box::new(move |delegate| {\n                tx.send(delegate.is_none()).unwrap();\n            }),\n        )))\n        .unwrap();\n\n    assert!(\n        rx.recv_timeout(Duration::from_millis(1000)).unwrap(),\n        \"find unexpected delegate\"\n    );\n    suite.stop();\n}"}
{"code": "pub fn len(&self) -> usize {\n        match self.values {\n            ForLoopValues::Array(ref values) => values.as_array().expect(\"Value is array\").len(),\n            ForLoopValues::String(ref values) => {\n                values.as_str().expect(\"Value is string\").chars().count()\n            }\n            ForLoopValues::Object(ref values) => values.len(),\n        }\n    }", "test": "fn parse_empty_template() {\n    let ast = parse(\"\").unwrap();\n    assert_eq!(ast.len(), 0);\n}"}
{"code": "pub const fn flags(&self) -> u128 {\n        FORMAT & flags::FLAG_MASK\n    }", "test": "fn format_properties_test() {\n    let format = NumberFormat::<{ STANDARD }> {};\n    assert_eq!(format.flags(), STANDARD & format::FLAG_MASK);\n    assert_eq!(format.interface_flags(), STANDARD & format::INTERFACE_FLAG_MASK);\n    assert_eq!(format.digit_separator(), b'\\x00');\n    assert_eq!(format.base_prefix(), b'\\x00');\n    assert_eq!(format.base_suffix(), b'\\x00');\n    assert_eq!(format.mantissa_radix(), 10);\n    assert_eq!(format.radix(), 10);\n    assert_eq!(format.exponent_base(), 10);\n    assert_eq!(format.exponent_radix(), 10);\n    assert_eq!(format.required_integer_digits(), false);\n    assert_eq!(format.required_fraction_digits(), false);\n    assert_eq!(format.required_exponent_digits(), true);\n    assert_eq!(format.required_mantissa_digits(), true);\n    assert_eq!(format.required_digits(), true);\n    assert_eq!(format.no_positive_mantissa_sign(), false);\n    assert_eq!(format.required_mantissa_sign(), false);\n    assert_eq!(format.no_exponent_notation(), false);\n    assert_eq!(format.no_positive_exponent_sign(), false);\n    assert_eq!(format.required_exponent_sign(), false);\n    assert_eq!(format.no_exponent_without_fraction(), false);\n    assert_eq!(format.no_special(), false);\n    assert_eq!(format.case_sensitive_special(), false);\n    assert_eq!(format.no_integer_leading_zeros(), false);\n    assert_eq!(format.no_float_leading_zeros(), false);\n    assert_eq!(format.required_exponent_notation(), false);\n    assert_eq!(format.case_sensitive_exponent(), false);\n    assert_eq!(format.case_sensitive_base_prefix(), false);\n    assert_eq!(format.case_sensitive_base_suffix(), false);\n    assert_eq!(format.integer_internal_digit_separator(), false);\n    assert_eq!(format.fraction_internal_digit_separator(), false);\n    assert_eq!(format.exponent_internal_digit_separator(), false);\n    assert_eq!(format.internal_digit_separator(), false);\n    assert_eq!(format.integer_leading_digit_separator(), false);\n    assert_eq!(format.fraction_leading_digit_separator(), false);\n    assert_eq!(format.exponent_leading_digit_separator(), false);\n    assert_eq!(format.leading_digit_separator(), false);\n    assert_eq!(format.integer_trailing_digit_separator(), false);\n    assert_eq!(format.fraction_trailing_digit_separator(), false);\n    assert_eq!(format.exponent_trailing_digit_separator(), false);\n    assert_eq!(format.trailing_digit_separator(), false);\n    assert_eq!(format.integer_consecutive_digit_separator(), false);\n    assert_eq!(format.fraction_consecutive_digit_separator(), false);\n    assert_eq!(format.exponent_consecutive_digit_separator(), false);\n    assert_eq!(format.consecutive_digit_separator(), false);\n    assert_eq!(format.special_digit_separator(), false);\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn reset_stream() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n\n    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();\n\n    const MSG: &[u8] = b\"hello\";\n    pair.client_send(client_ch, s).write(MSG).unwrap();\n    pair.drive();\n\n    info!(\"resetting stream\");\n    const ERROR: VarInt = VarInt(42);\n    pair.client_send(client_ch, s).reset(ERROR).unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))\n    );\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Err(ReadError::Reset(ERROR)));\n    let _ = chunks.finalize();\n    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);\n}"}
{"code": "fn expr(input: &[u8]) -> IResult<&[u8], i64> {\n  let (input, init) = term(input)?;\n  fold_many0(\n    pair(one_of(\"+-\"), term),\n    move || init,\n    |acc, (op, val)| {\n      if op == '+' {\n        acc + val\n      } else {\n        acc - val\n      }\n    },\n  )(input)\n}", "test": "fn expr_test() {\n  assert_eq!(expr(\" 1 +  2 \"), Ok((\"\", 3)));\n  assert_eq!(expr(\" 12 + 6 - 4+  3\"), Ok((\"\", 17)));\n  assert_eq!(expr(\" 1 + 2*3 + 4\"), Ok((\"\", 11)));\n}"}
{"code": "fn len(&self) -> Result<u64> {\n        let mut count = 0;\n        for item in self.iter()? {\n            let (_, values) = item?;\n            for v in values {\n                v?;\n                count += 1;\n            }\n        }\n        Ok(count)\n    }", "test": "fn non_page_size_multiple() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::create(tmpfile.path()).unwrap();\n    let txn = db.begin_write().unwrap();\n    let key = vec![0u8; 1024];\n    let value = vec![0u8; 1];\n    {\n        let mut table = txn.open_table(SLICE_TABLE).unwrap();\n        table.insert(key.as_slice(), value.as_slice()).unwrap();\n    }\n    txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(SLICE_TABLE).unwrap();\n    assert_eq!(table.len().unwrap(), 1);\n}"}
{"code": "pub fn contains<C: Comparator<K>>(&self, key: K, forest: &SetForest<K>, comp: &C) -> bool {\n        self.root\n            .expand()\n            .and_then(|root| Path::default().find(key, root, &forest.nodes, comp))\n            .is_some()\n    }", "test": "fn test_returns_incorrect_type() -> Result<()> {\n    const WAT: &str = r#\"\n    (module\n        (import \"env\" \"evil\" (func $evil (result i32)))\n        (func (export \"run\") (result i32)\n            (call $evil)\n        )\n    )\n    \"#;\n\n    let mut store = Store::<()>::default();\n    let module = Module::new(store.engine(), WAT)?;\n\n    let callback_func = Func::new(\n        &mut store,\n        FuncType::new(None, Some(ValType::I32)),\n        |_, _, results| {\n            // Evil! Returns I64 here instead of promised in the signature I32.\n            results[0] = Val::I64(228);\n            Ok(())\n        },\n    );\n\n    let imports = vec![callback_func.into()];\n    let instance = Instance::new(&mut store, &module, imports.as_slice())?;\n\n    let run_func = instance\n        .get_func(&mut store, \"run\")\n        .expect(\"expected a run func in the module\");\n\n    let mut result = [Val::I32(0)];\n    let trap = run_func\n        .call(&mut store, &[], &mut result)\n        .expect_err(\"the execution should fail\");\n    assert!(format!(\"{:?}\", trap).contains(\"function attempted to return an incompatible value\"));\n    Ok(())\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_if_files_are_listed_in_ignore_option() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_LINTER_AND_FILES_IGNORE.as_bytes());\n\n    let file_path_test1 = Path::new(\"test1.js\");\n    fs.insert(file_path_test1.into(), FIX_BEFORE.as_bytes());\n\n    let file_path_test2 = Path::new(\"test2.js\");\n    fs.insert(file_path_test2.into(), FIX_BEFORE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply\"),\n                file_path_test1.as_os_str().to_str().unwrap(),\n                file_path_test2.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path_test1)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    let mut buffer = String::new();\n    fs.open(file_path_test2)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_if_files_are_listed_in_ignore_option\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn is_empty(&self) -> bool {\n        self.entries.len() == 0\n    }", "test": "fn test_destroy_clean_up_logs_with_unfinished_log_gc() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(15);\n    cluster.cfg.raft_store.raft_log_gc_threshold = 15;\n    let pd_client = cluster.pd_client.clone();\n\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    cluster.run();\n    // Simulate raft log gc tasks are lost during shutdown.\n    let fp = \"worker_gc_raft_log\";\n    fail::cfg(fp, \"return\").unwrap();\n\n    let state = cluster.truncated_state(1, 3);\n    for i in 0..30 {\n        let b = format!(\"k{}\", i).into_bytes();\n        cluster.must_put(&b, &b);\n    }\n    must_get_equal(&cluster.get_engine(3), b\"k29\", b\"k29\");\n    cluster.wait_log_truncated(1, 3, state.get_index() + 1);\n    cluster.stop_node(3);\n    let truncated_index = cluster.truncated_state(1, 3).get_index();\n    let raft_engine = cluster.engines[&3].raft.clone();\n    // Make sure there are stale logs.\n    raft_engine.get_entry(1, truncated_index).unwrap().unwrap();\n\n    pd_client.must_remove_peer(1, new_peer(3, 3));\n    cluster.must_put(b\"k30\", b\"v30\");\n    must_get_equal(&cluster.get_engine(1), b\"k30\", b\"v30\");\n\n    fail::remove(fp);\n    // So peer (3, 3) will be destroyed by gc message. And all stale logs before\n    // first index should be cleaned up.\n    cluster.run_node(3).unwrap();\n    must_get_none(&cluster.get_engine(3), b\"k29\");\n\n    let mut dest = vec![];\n    raft_engine.get_all_entries_to(1, &mut dest).unwrap();\n    // All logs should be deleted.\n    assert!(dest.is_empty(), \"{:?}\", dest);\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn save_point_rollback_after_write() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_some());\n\n    db.engine.delete(b\"a\").unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n\n    wb.rollback_to_save_point().unwrap();\n    wb.write().unwrap();\n\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n    let max_keys = 256_usize;\n\n    wb.set_save_point();\n    for i in 0..max_keys {\n        wb.put(&i.to_be_bytes(), b\"\").unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n\n    db.engine.delete(b\"a\").unwrap();\n    for i in 0..max_keys {\n        db.engine.delete(&i.to_be_bytes()).unwrap();\n    }\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n\n    wb.rollback_to_save_point().unwrap();\n    wb.write().unwrap();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_none());\n    for i in 0..max_keys {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn regression14() {\n    let tmpfile = create_tempfile();\n\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: MultimapTableDefinition<u64, &[u8]> = MultimapTableDefinition::new(\"x\");\n\n    let mut tx = db.begin_write().unwrap();\n    tx.set_durability(Durability::None);\n    {\n        let mut t = tx.open_multimap_table(table_def).unwrap();\n        let value = vec![0; 1424];\n        t.insert(&539749, value.as_slice()).unwrap();\n    }\n    tx.commit().unwrap();\n\n    let mut tx = db.begin_write().unwrap();\n    tx.set_durability(Durability::None);\n    {\n        let mut t = tx.open_multimap_table(table_def).unwrap();\n        let value = vec![0; 2230];\n        t.insert(&776971, value.as_slice()).unwrap();\n\n        let mut iter = t.range(514043..(514043 + 514043)).unwrap().rev();\n        {\n            let (key, mut value_iter) = iter.next().unwrap().unwrap();\n            assert_eq!(key.value(), 776971);\n            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 2230]);\n        }\n        {\n            let (key, mut value_iter) = iter.next().unwrap().unwrap();\n            assert_eq!(key.value(), 539749);\n            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 1424]);\n        }\n    }\n    tx.abort().unwrap();\n}"}
{"code": "pub fn fuel_consumed(&self) -> u64 {\n        self.total.wrapping_sub(self.remaining)\n    }", "test": "fn metered_i32_add() {\n    let wasm = wat2wasm(\n        r#\"\n        (module\n            (func (export \"test\") (param $a i32) (param $b i32) (result i32)\n                (i32.add\n                    (local.get $a)\n                    (local.get $b)\n                )\n            )\n        )\n    \"#,\n    );\n    let (mut store, func) = default_test_setup(&wasm);\n    let func = func.typed::<(i32, i32), i32>(&store).unwrap();\n    // No fuel -> no success.\n    assert_out_of_fuel(func.call(&mut store, (1, 2)));\n    assert_eq!(store.fuel_consumed(), Some(0));\n    // Now add too little fuel for a start, so still no success.\n    store.add_fuel(1).unwrap();\n    assert_out_of_fuel(func.call(&mut store, (1, 2)));\n    assert_eq!(store.fuel_consumed(), Some(0));\n    // Now add enough fuel, so execution should succeed.\n    store.add_fuel(10).unwrap();\n    assert_success(func.call(&mut store, (1, 2)));\n    assert_eq!(store.fuel_consumed(), Some(5));\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn create_open() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        table.insert(&0, &1).unwrap();\n    }\n    write_txn.commit().unwrap();\n    drop(db);\n\n    let db2 = Database::open(tmpfile.path()).unwrap();\n\n    let read_txn = db2.begin_read().unwrap();\n    let table = read_txn.open_table(U64_TABLE).unwrap();\n    assert_eq!(1, table.get(&0).unwrap().unwrap().value());\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_update_region_in_local_reader() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n    assert_eq!(nodes[2], 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    // update region but the peer is not destroyed yet\n    fail::cfg(\"change_peer_after_update_region_store_3\", \"pause\").unwrap();\n\n    cluster\n        .pd_client\n        .must_remove_peer(region.get_id(), peer_on_store3.clone());\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let mut request = new_request(\n        region.get_id(),\n        region.get_region_epoch().clone(),\n        vec![new_get_cmd(b\"k0\")],\n        false,\n    );\n    request.mut_header().set_peer(peer_on_store3);\n    request.mut_header().set_replica_read(true);\n\n    let resp = cluster\n        .read(None, request.clone(), Duration::from_millis(100))\n        .unwrap();\n    assert_eq!(\n        resp.get_header().get_error().get_is_witness(),\n        &kvproto::errorpb::IsWitness {\n            region_id: region.get_id(),\n            ..Default::default()\n        }\n    );\n\n    fail::remove(\"change_peer_after_update_region_store_3\");\n}"}
{"code": "fn compute_error_scaled32(q: i64, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f32>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled32_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for single-precision floats.\n    assert_eq!(\n        compute_error_scaled32(0, 4611686018427387904, 39),\n        (111 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686293305294848, 39),\n        (111 + INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686568183201792, 39),\n        (111 + INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611686843061108736, 39),\n        (111 + INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(0, 4611687117939015680, 39),\n        (111 + INVALID_FP, 9223374235878031360)\n    );\n\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372036854775808, 6),\n        (111 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223372586610589696, 6),\n        (111 + INVALID_FP, 9223372586610589696)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373136366403584, 6),\n        (111 + INVALID_FP, 9223373136366403584)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223373686122217472, 6),\n        (111 + INVALID_FP, 9223373686122217472)\n    );\n    assert_eq!(\n        compute_error_scaled32(-10, 9223374235878031360, 6),\n        (111 + INVALID_FP, 9223374235878031360)\n    );\n}"}
{"code": "pub fn is_in_joint(&self, region_id: u64) -> bool {\n        let region = block_on(self.get_region_by_id(region_id))\n            .unwrap()\n            .expect(\"region not exist\");\n        region.get_peers().iter().any(|p| {\n            p.get_role() == PeerRole::IncomingVoter || p.get_role() == PeerRole::DemotingVoter\n        })\n    }", "test": "fn test_enter_joint_state() {\n    let mut cluster = new_node_cluster(0, 4);\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region_id = cluster.run_conf_change();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n\n    // normal confchange request will not enter joint state\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n    assert!(!pd_client.is_in_joint(region_id));\n    pd_client.must_add_peer(region_id, new_peer(3, 3));\n    assert!(!pd_client.is_in_joint(region_id));\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // confchange_v2 request with one conchange request will not enter joint state\n    pd_client.must_joint_confchange(\n        region_id,\n        vec![(ConfChangeType::RemoveNode, new_peer(3, 3))],\n    );\n    assert!(!pd_client.is_in_joint(region_id));\n    must_get_none(&cluster.get_engine(3), b\"k1\");\n    pd_client.must_joint_confchange(region_id, vec![(ConfChangeType::AddNode, new_peer(3, 3))]);\n    assert!(!pd_client.is_in_joint(region_id));\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    // Enter joint\n    pd_client.must_joint_confchange(\n        region_id,\n        vec![\n            (ConfChangeType::AddLearnerNode, new_learner_peer(3, 3)),\n            (ConfChangeType::AddNode, new_peer(4, 4)),\n        ],\n    );\n    assert!(pd_client.is_in_joint(region_id));\n\n    // In joint state any confchange request besides leave joint request\n    // will be rejected\n    let resp = call_conf_change(\n        &mut cluster,\n        region_id,\n        ConfChangeType::RemoveNode,\n        new_learner_peer(3, 3),\n    )\n    .unwrap();\n    must_contains_error(&resp, \"in joint\");\n\n    let resp = call_conf_change_v2(\n        &mut cluster,\n        region_id,\n        vec![change_peer(\n            ConfChangeType::RemoveNode,\n            new_learner_peer(3, 3),\n        )],\n    )\n    .unwrap();\n    must_contains_error(&resp, \"in joint\");\n\n    // Leave joint\n    pd_client.must_leave_joint(region_id);\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn test_skip_iter_ilc() {\n    // Test iterators that skip multiple, internal or leading digit separators.\n    pub const FORMAT: u128 = NumberFormatBuilder::new()\n        .digit_separator(num::NonZeroU8::new(b'_'))\n        .integer_internal_digit_separator(true)\n        .integer_leading_digit_separator(true)\n        .integer_consecutive_digit_separator(true)\n        .build();\n    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());\n\n    skip_iter_eq::<{ FORMAT }>(b\"123.45\", b\"123.45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e45\", b\"1e45\");\n    skip_iter_eq::<{ FORMAT }>(b\"1e\", b\"1e\");\n    skip_iter_eq::<{ FORMAT }>(b\"1\", b\"1\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45\", b\".45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5\", b\"45\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_\", b\"4_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__\", b\"4__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_.\", b\"4_.\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__.\", b\"4__.\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__5\", b\"455\");\n    skip_iter_eq::<{ FORMAT }>(b\"_.45_5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"__.45__5\", b\".455\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__\", b\"45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"4_5_.5\", b\"45_.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"4__5__.5\", b\"45__.5\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__\", b\"45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_45_.56\", b\"45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__45__.56\", b\"45__.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_\", b\"45_\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__\", b\"45__\");\n    skip_iter_eq::<{ FORMAT }>(b\"_4_5_.56\", b\"45_.56\");\n    skip_iter_eq::<{ FORMAT }>(b\"__4__5__.56\", b\"45__.56\");\n}"}
{"code": "pub const fn get_lossy(&self) -> bool {\n        self.lossy\n    }", "test": "fn builder_test() {\n    let mut builder = OptionsBuilder::default();\n\n    builder = builder.lossy(true);\n    builder = builder.exponent(b'^');\n    builder = builder.decimal_point(b',');\n    builder = builder.nan_string(Some(b\"nan\"));\n    builder = builder.inf_string(Some(b\"Infinity\"));\n    builder = builder.infinity_string(Some(b\"Infiniiiiiity\"));\n\n    assert_eq!(builder.get_lossy(), true);\n    assert_eq!(builder.get_exponent(), b'^');\n    assert_eq!(builder.get_decimal_point(), b',');\n    assert_eq!(builder.get_nan_string(), Some(\"nan\".as_bytes()));\n    assert_eq!(builder.get_inf_string(), Some(\"Infinity\".as_bytes()));\n    assert_eq!(builder.get_infinity_string(), Some(\"Infiniiiiiity\".as_bytes()));\n\n    assert!(builder.is_valid());\n    assert_eq!(builder.build(), Ok(unsafe { builder.build_unchecked() }));\n}"}
{"code": "async fn status(Extension(index): Extension<Arc<Index>>) -> (StatusCode, &'static str) {\n    if index.is_unrecoverably_reorged() {\n      (\n        StatusCode::OK,\n        \"unrecoverable reorg detected, please rebuild the database.\",\n      )\n    } else {\n      (\n        StatusCode::OK,\n        StatusCode::OK.canonical_reason().unwrap_or_default(),\n      )\n    }\n  }", "test": "fn splitting_merged_inscriptions_is_possible() {\n  let rpc_server = test_bitcoincore_rpc::spawn();\n  create_wallet(&rpc_server);\n  rpc_server.mine_blocks(3);\n\n  let inscription = envelope(&[b\"ord\", &[1], b\"text/plain;charset=utf-8\", &[], b\"bar\"]);\n\n  // merging 3 inscriptions into one utxo\n  let reveal_txid = rpc_server.broadcast_tx(TransactionTemplate {\n    inputs: &[\n      (1, 0, 0, inscription.clone()),\n      (2, 0, 0, inscription.clone()),\n      (3, 0, 0, inscription.clone()),\n    ],\n    outputs: 1,\n    ..Default::default()\n  });\n\n  rpc_server.mine_blocks(1);\n\n  let server =\n    TestServer::spawn_with_server_args(&rpc_server, &[\"--index-sats\"], &[\"--enable-json-api\"]);\n\n  let response = server.json_request(format!(\"/output/{}:0\", reveal_txid));\n  assert_eq!(response.status(), StatusCode::OK);\n\n  let output_json: OutputJson = serde_json::from_str(&response.text().unwrap()).unwrap();\n\n  pretty_assert_eq!(\n    output_json,\n    OutputJson {\n      value: 3 * 50 * COIN_VALUE,\n      script_pubkey: \"\".to_string(),\n      address: None,\n      transaction: reveal_txid.to_string(),\n      sat_ranges: Some(vec![\n        (5000000000, 10000000000,),\n        (10000000000, 15000000000,),\n        (15000000000, 20000000000,),\n      ],),\n      inscriptions: vec![\n        InscriptionId {\n          txid: reveal_txid,\n          index: 0\n        },\n        InscriptionId {\n          txid: reveal_txid,\n          index: 1\n        },\n        InscriptionId {\n          txid: reveal_txid,\n          index: 2\n        },\n      ],\n      runes: BTreeMap::new(),\n    }\n  );\n\n  // try and fail to send first\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {}i0\",\n    reveal_txid,\n  ))\n  .rpc_server(&rpc_server)\n  .expected_exit_code(1)\n  .expected_stderr(format!(\n    \"error: cannot send {reveal_txid}:0:0 without also sending inscription {reveal_txid}i2 at {reveal_txid}:0:{}\\n\", 100 * COIN_VALUE\n  ))\n  .run_and_extract_stdout();\n\n  // splitting out last\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {}i2\",\n    reveal_txid,\n  ))\n  .rpc_server(&rpc_server)\n  .run_and_deserialize_output::<Output>();\n\n  rpc_server.mine_blocks(1);\n\n  // splitting second to last\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {}i1\",\n    reveal_txid,\n  ))\n  .rpc_server(&rpc_server)\n  .run_and_deserialize_output::<Output>();\n\n  rpc_server.mine_blocks(1);\n\n  // splitting send first\n  CommandBuilder::new(format!(\n    \"wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {}i0\",\n    reveal_txid,\n  ))\n  .rpc_server(&rpc_server)\n  .run_and_deserialize_output::<Output>();\n}"}
{"code": "pub fn stdout_str(&self) -> &str {\n        std::str::from_utf8(&self.stdout).unwrap()\n    }", "test": "fn test_du_soft_link() {\n    let ts = TestScenario::new(util_name!());\n    let at = &ts.fixtures;\n\n    at.symlink_file(SUB_FILE, SUB_LINK);\n\n    let result = ts.ucmd().arg(SUB_DIR_LINKS).succeeds();\n\n    #[cfg(any(target_os = \"linux\", target_os = \"android\"))]\n    {\n        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));\n        if result_reference.succeeded() {\n            assert_eq!(result.stdout_str(), result_reference.stdout_str());\n            return;\n        }\n    }\n    _du_soft_link(result.stdout_str());\n}"}
{"code": "pub fn mode(&self) -> u32 {\n        match self.specified_mode {\n            Some(x) => x,\n            None => DEFAULT_MODE,\n        }\n    }", "test": "fn test_chmod_keep_setgid() {\n    for (from, arg, to) in [\n        (0o7777, \"777\", 0o46777),\n        (0o7777, \"=777\", 0o40777),\n        (0o7777, \"0777\", 0o46777),\n        (0o7777, \"=0777\", 0o40777),\n        (0o7777, \"00777\", 0o40777),\n        (0o2444, \"a+wx\", 0o42777),\n        (0o2444, \"a=wx\", 0o42333),\n        (0o1444, \"g+s\", 0o43444),\n        (0o4444, \"u-s\", 0o40444),\n        (0o7444, \"a-s\", 0o41444),\n    ] {\n        let (at, mut ucmd) = at_and_ucmd!();\n        at.mkdir(\"dir\");\n        set_permissions(at.plus(\"dir\"), Permissions::from_mode(from)).unwrap();\n        let r = ucmd.arg(arg).arg(\"dir\").succeeds();\n        println!(\"{}\", r.stderr_str());\n        assert_eq!(at.metadata(\"dir\").permissions().mode(), to);\n    }\n}"}
{"code": "pub fn into_data(self) -> Vec<u8> {\n        match self {\n            Message::Text(string) => string.into_bytes(),\n            Message::Binary(data) | Message::Ping(data) | Message::Pong(data) => data,\n            Message::Close(None) => Vec::new(),\n            Message::Close(Some(frame)) => frame.reason.into_owned().into_bytes(),\n            Message::Frame(frame) => frame.into_data(),\n        }\n    }", "test": "fn test_client_close() {\n    do_test(\n        3014,\n        |mut cli_sock| {\n            cli_sock.send(Message::Text(\"Hello WebSocket\".into())).unwrap();\n\n            let message = cli_sock.read().unwrap(); // receive answer from server\n            assert_eq!(message.into_data(), b\"From Server\");\n\n            cli_sock.close(None).unwrap(); // send close to server\n\n            let message = cli_sock.read().unwrap(); // receive acknowledgement from server\n            assert!(message.is_close());\n\n            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n        |mut srv_sock| {\n            let message = srv_sock.read().unwrap();\n            assert_eq!(message.into_data(), b\"Hello WebSocket\");\n\n            srv_sock.send(Message::Text(\"From Server\".into())).unwrap();\n\n            let message = srv_sock.read().unwrap(); // receive close from client\n            assert!(message.is_close());\n\n            let err = srv_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n    );\n}"}
{"code": "fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }", "test": "fn test_block_size_1024() {\n    fn get_header(block_size: u64) -> String {\n        let output = new_ucmd!()\n            .args(&[\"-B\", &format!(\"{block_size}\"), \"--output=size\"])\n            .succeeds()\n            .stdout_move_str();\n        output.lines().next().unwrap().trim().to_string()\n    }\n\n    assert_eq!(get_header(1024), \"1K-blocks\");\n    assert_eq!(get_header(2048), \"2K-blocks\");\n    assert_eq!(get_header(4096), \"4K-blocks\");\n    assert_eq!(get_header(1024 * 1024), \"1M-blocks\");\n    assert_eq!(get_header(2 * 1024 * 1024), \"2M-blocks\");\n    assert_eq!(get_header(1024 * 1024 * 1024), \"1G-blocks\");\n    assert_eq!(get_header(34 * 1024 * 1024 * 1024), \"34G-blocks\");\n\n    // multiples of both 1024 and 1000\n    assert_eq!(get_header(128_000), \"128kB-blocks\");\n    assert_eq!(get_header(1000 * 1024), \"1.1MB-blocks\");\n    assert_eq!(get_header(1_000_000_000_000), \"1TB-blocks\");\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_multiple_obs_lines_standalone() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let name = \"multiple-obs-lines\";\n    RandomFile::new(at, name).add_lines(400);\n\n    scene\n        .ucmd()\n        .args(&[\"-3000\", \"-200\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 2);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn send_streams(&self) -> usize {\n        self.state.send_streams\n    }", "test": "fn stop_opens_bidi() {\n    let _guard = subscribe();\n    let mut pair = Pair::default();\n    let (client_ch, server_ch) = pair.connect();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 0);\n    let s = pair.client_streams(client_ch).open(Dir::Bi).unwrap();\n    assert_eq!(pair.client_streams(client_ch).send_streams(), 1);\n    const ERROR: VarInt = VarInt(42);\n    pair.client\n        .connections\n        .get_mut(&server_ch)\n        .unwrap()\n        .recv_stream(s)\n        .stop(ERROR)\n        .unwrap();\n    pair.drive();\n\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))\n    );\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);\n    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);\n    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 1);\n\n    let mut recv = pair.server_recv(server_ch, s);\n    let mut chunks = recv.read(false).unwrap();\n    assert_matches!(chunks.next(usize::MAX), Err(ReadError::Blocked));\n    let _ = chunks.finalize();\n\n    assert_matches!(\n        pair.server_send(server_ch, s).write(b\"foo\"),\n        Err(WriteError::Stopped(ERROR))\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Stream(StreamEvent::Stopped {\n            id: _,\n            error_code: ERROR\n        }))\n    );\n    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);\n}"}
{"code": "pub fn render<S: Serialize>(&self, ctx: S) -> Result<String, Error> {\n        // reduce total amount of code faling under mono morphization into\n        // this function, and share the rest in _render.\n        self._render(Value::from_serializable(&ctx)).map(|x| x.0)\n    }", "test": "fn test_dynamic() {\n    let mut env = Environment::new();\n    let template = String::from(\"Hello World 2!\");\n    env.add_template_owned(\"hello2\", template).unwrap();\n    env.set_loader(|name| match name {\n        \"hello\" => Ok(Some(\"Hello World!\".into())),\n        _ => Ok(None),\n    });\n    let t = env.get_template(\"hello\").unwrap();\n    assert_eq!(t.render(()).unwrap(), \"Hello World!\");\n    let t = env.get_template(\"hello2\").unwrap();\n    assert_eq!(t.render(()).unwrap(), \"Hello World 2!\");\n    let err = env.get_template(\"missing\").unwrap_err();\n    assert_eq!(\n        err.to_string(),\n        \"template not found: template \\\"missing\\\" does not exist\"\n    );\n}"}
{"code": "pub fn to_string<T>(value: &T) -> Result<String, DeError>\nwhere\n    T: ?Sized + Serialize,\n{\n    let mut buffer = String::new();\n    to_writer(&mut buffer, value)?;\n    Ok(buffer)\n}", "test": "fn issue343() {\n    #[derive(Debug, Deserialize, Serialize, PartialEq)]\n    struct Users {\n        users: HashMap<String, User>,\n    }\n    #[derive(Debug, Deserialize, Serialize, PartialEq)]\n    struct Max(u16);\n\n    #[derive(Debug, Deserialize, Serialize, PartialEq)]\n    struct User {\n        max: Max,\n    }\n\n    let xml = \"<Users>\\\n                        <users>\\\n                            <roger>\\\n                                <max>10</max>\\\n                            </roger>\\\n                        </users>\\\n                    </Users>\";\n    let users: Users = from_str(xml).unwrap();\n\n    assert_eq!(\n        users,\n        Users {\n            users: HashMap::from([(\"roger\".to_string(), User { max: Max(10) })]),\n        }\n    );\n    assert_eq!(to_string(&users).unwrap(), xml);\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_twice_dir() {\n    let dir = \"dir\";\n    let scene = TestScenario::new(util_name!());\n\n    scene.ucmd().arg(\"-d\").arg(dir).succeeds();\n    scene.ucmd().arg(\"-d\").arg(dir).succeeds();\n    let at = &scene.fixtures;\n\n    assert!(at.dir_exists(dir));\n}"}
{"code": "fn get_vec(\n    table: &impl ReadableMultimapTable<&'static str, &'static str>,\n    key: &str,\n) -> Vec<String> {\n    let mut result = vec![];\n    let mut iter = table.get(key).unwrap();\n    loop {\n        let item = iter.next();\n        if let Some(item_value) = item {\n            result.push(item_value.unwrap().value().to_string());\n        } else {\n            return result;\n        }\n    }\n}", "test": "fn delete() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n        table.insert(\"hello\", \"world2\").unwrap();\n        table.insert(\"hello\", \"world3\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert_eq!(\n        vec![\n            \"world\".to_string(),\n            \"world2\".to_string(),\n            \"world3\".to_string()\n        ],\n        get_vec(&table, \"hello\")\n    );\n    assert_eq!(table.len().unwrap(), 3);\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        table.remove(\"hello\", \"world2\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert_eq!(\n        vec![\"world\".to_string(), \"world3\".to_string()],\n        get_vec(&table, \"hello\")\n    );\n    assert_eq!(table.len().unwrap(), 2);\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();\n        let mut iter = table.remove_all(\"hello\").unwrap();\n        assert_eq!(\"world\", iter.next().unwrap().unwrap().value());\n        assert_eq!(\"world3\", iter.next().unwrap().unwrap().value());\n        assert!(iter.next().is_none());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();\n    assert!(table.is_empty().unwrap());\n    let empty: Vec<String> = vec![];\n    assert_eq!(empty, get_vec(&table, \"hello\"));\n}"}
{"code": "pub fn contains<S>(&self, name: S) -> bool\n    where\n        S: Into<String>,\n    {\n        self.map.contains_key(&name.into())\n    }", "test": "fn gen_c_header_works_pirita() -> anyhow::Result<()> {\n    let temp_dir = tempfile::tempdir()?;\n    let operating_dir: PathBuf = temp_dir.path().to_owned();\n\n    let wasm_path = operating_dir.join(fixtures::wabt());\n    let out_path = temp_dir.path().join(\"header.h\");\n\n    let _ = Command::new(get_wasmer_path())\n        .arg(\"gen-c-header\")\n        .arg(&wasm_path)\n        .arg(\"-o\")\n        .arg(&out_path)\n        .arg(\"--atom\")\n        .arg(\"wasm-validate\")\n        .output()\n        .unwrap();\n\n    let file = std::fs::read_to_string(&out_path).expect(\"no header.h file\");\n    assert!(file.contains(\"wasmer_function_0f41d38dcfb5abc1fadb5e9acbc5c645e53fe4d0dd86270b72a09bfeee04d055_0\"), \"no wasmer_function_6f62a6bc5c8f8e3e12a54e2ecbc5674ccfe1c75f91d8e4dd6ebb3fec422a4d6c_0 in file\");\n\n    let cmd = Command::new(get_wasmer_path())\n        .arg(\"gen-c-header\")\n        .arg(&wasm_path)\n        .arg(\"-o\")\n        .arg(&out_path)\n        .output()\n        .unwrap();\n\n    assert!(!cmd.status.success());\n\n    Ok(())\n}"}
{"code": "fn compute_error_scaled64(q: i64, w: u64, lz: i32) -> (i32, u64) {\n    let fp = lemire::compute_error_scaled::<f64>(q, w, lz);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_error_scaled64_test() {\n    // These are the same examples above, just using pre-computed scaled values.\n\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 10),\n        (1065 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 10),\n        (1065 + INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 10),\n        (1065 + INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 10),\n        (1065 + INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 10),\n        (1065 + INVALID_FP, 9223372036854779904)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427387904, 9),\n        (1066 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 9),\n        (1066 + INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388928, 9),\n        (1066 + INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389440, 9),\n        (1066 + INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427389952, 9),\n        (1066 + INVALID_FP, 9223372036854779904)\n    );\n\n    // Test a much closer set of examples.\n    assert_eq!(\n        compute_error_scaled64(0, 9223372036854774784, 11),\n        (1064 + INVALID_FP, 18446744073709549568)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388415, 0),\n        (1075 + INVALID_FP, 9223372036854776830)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(0, 4611686018427388416, 0),\n        (1075 + INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765748947, 10),\n        (925 + INVALID_FP, 13021432563531497894)\n    );\n    assert_eq!(\n        compute_error_scaled64(-43, 6510716281765749303, 7),\n        (925 + INVALID_FP, 13021432563531498606)\n    );\n    assert_eq!(\n        compute_error_scaled64(-42, 6510716281765749660, 10),\n        (925 + INVALID_FP, 13021432563531499320)\n    );\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854775808, 1),\n        (1065 + INVALID_FP, 9223372036854775808)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854776832, 1),\n        (1065 + INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854777856, 1),\n        (1065 + INVALID_FP, 9223372036854777856)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854778880, 1),\n        (1065 + INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(\n        compute_error_scaled64(-3, 9223372036854779904, 1),\n        (1065 + INVALID_FP, 9223372036854779904)\n    );\n\n    // Test from errors in atof.\n    assert_eq!(\n        compute_error_scaled64(-18, 9223373686122217470, 4),\n        (1012 + INVALID_FP, 9223373686122217470)\n    );\n\n    // Check edge-cases from previous errors.\n    assert_eq!(\n        compute_error_scaled64(-342, 9223372036854775804, 2),\n        (-64 + INVALID_FP, 18446744073709551608)\n    );\n}"}
{"code": "fn get_name(&self) -> &'static str {\n        self.name\n    }", "test": "fn test_watch_global_config_on_closed_server() {\n    let (mut server, client) = new_test_server_and_client(ReadableDuration::millis(100));\n    let global_items = vec![(\"test1\", \"val1\"), (\"test2\", \"val2\"), (\"test3\", \"val3\")];\n    let items_clone = global_items.clone();\n\n    let client = Arc::new(client);\n    let cli_clone = client.clone();\n    use futures::StreamExt;\n    let background_worker = Builder::new(\"background\").thread_count(1).create();\n    background_worker.spawn_async_task(async move {\n        match cli_clone.watch_global_config(\"global\".into(), 0) {\n            Ok(mut stream) => {\n                let mut i: usize = 0;\n                while let Some(grpc_response) = stream.next().await {\n                    match grpc_response {\n                        Ok(r) => {\n                            for item in r.get_changes() {\n                                assert_eq!(item.get_name(), items_clone[i].0);\n                                assert_eq!(\n                                    from_utf8(item.get_payload()).unwrap(),\n                                    items_clone[i].1\n                                );\n                                i += 1;\n                            }\n                        }\n                        Err(err) => panic!(\"failed to get stream, err: {:?}\", err),\n                    }\n                }\n            }\n            Err(err) => {\n                if !err.to_string().contains(\"UNAVAILABLE\") {\n                    // Not 14-UNAVAILABLE\n                    panic!(\"other error occur {:?}\", err)\n                }\n            }\n        }\n    });\n\n    if let Err(err) = futures::executor::block_on(\n        client.store_global_config(\n            \"global\".into(),\n            global_items\n                .iter()\n                .map(|(name, value)| {\n                    let mut item = GlobalConfigItem::default();\n                    item.set_name(name.to_string());\n                    item.set_payload(value.as_bytes().into());\n                    item\n                })\n                .collect::<Vec<GlobalConfigItem>>(),\n        ),\n    ) {\n        panic!(\"error occur {:?}\", err);\n    }\n\n    thread::sleep(Duration::from_millis(100));\n    server.stop();\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn does_not_format_ignored_files() {\n    let mut console = BufferConsole::default();\n    let mut fs = MemoryFileSystem::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(file_path.into(), CONFIG_FORMATTER_IGNORED_FILES.as_bytes());\n\n    let file_path = Path::new(\"test.js\");\n    fs.insert(file_path.into(), UNFORMATTED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"format\"), (\"test.js\"), (\"--write\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut file = fs\n        .open(file_path)\n        .expect(\"formatting target file was removed by the CLI\");\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"failed to read file from memory FS\");\n\n    assert_eq!(content, UNFORMATTED);\n\n    drop(file);\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"does_not_format_ignored_files\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn is_none(&self) -> bool {\n        false\n    }", "test": "fn test_read_index_with_max_ts() {\n    let mut cluster = new_server_cluster(0, 3);\n    // Increase the election tick to make this test case running reliably.\n    // Use async apply prewrite to let tikv response before applying on the leader\n    // peer.\n    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));\n    cluster.cfg.storage.enable_async_apply_prewrite = true;\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    let k0 = b\"k0\";\n    let v0 = b\"v0\";\n    let r1 = cluster.run_conf_change();\n    let p2 = new_peer(2, 2);\n    cluster.pd_client.must_add_peer(r1, p2.clone());\n    let p3 = new_peer(3, 3);\n    cluster.pd_client.must_add_peer(r1, p3.clone());\n    cluster.must_put(k0, v0);\n    cluster.pd_client.must_none_pending_peer(p2.clone());\n    cluster.pd_client.must_none_pending_peer(p3.clone());\n\n    let region = cluster.get_region(k0);\n    cluster.must_transfer_leader(region.get_id(), p3.clone());\n\n    // Block all write cmd applying of Peer 3(leader), then start to write to it.\n    let k1 = b\"k1\";\n    let v1 = b\"v1\";\n    let mut ctx_p3 = Context::default();\n    ctx_p3.set_region_id(region.get_id());\n    ctx_p3.set_region_epoch(region.get_region_epoch().clone());\n    ctx_p3.set_peer(p3.clone());\n    let mut ctx_p2 = ctx_p3.clone();\n    ctx_p2.set_peer(p2.clone());\n\n    let start_ts = 10;\n    let mut mutation = pb::Mutation::default();\n    mutation.set_op(Op::Put);\n    mutation.key = k1.to_vec();\n    mutation.value = v1.to_vec();\n    let mut req = PrewriteRequest::default();\n    req.set_context(ctx_p3);\n    req.set_mutations(vec![mutation].into());\n    req.set_start_version(start_ts);\n    req.try_one_pc = true;\n    req.set_primary_lock(k1.to_vec());\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env.clone()).connect(&cluster.sim.rl().get_addr(p3.get_store_id()));\n    let client_p3 = TikvClient::new(channel);\n    fail::cfg(\"on_apply_write_cmd\", \"sleep(2000)\").unwrap();\n    client_p3.kv_prewrite(&req).unwrap();\n\n    // The apply is blocked on leader, so the read index request with max ts should\n    // see the memory lock as it would be dropped after finishing apply.\n    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(p2.get_store_id()));\n    let client_p2 = TikvClient::new(channel);\n    let mut req = GetRequest::new();\n    req.key = k1.to_vec();\n    req.version = u64::MAX;\n    ctx_p2.replica_read = true;\n    req.set_context(ctx_p2);\n    let resp = client_p2.kv_get(&req).unwrap();\n    assert!(resp.region_error.is_none());\n    assert_eq!(resp.error.unwrap().locked.unwrap().lock_version, start_ts);\n    fail::remove(\"on_apply_write_cmd\");\n}"}
{"code": "pub fn compute_float64(q: i32, w: u64) -> (i32, u64) {\n    let num = Number {\n        exponent: q,\n        mantissa: w,\n        many_digits: false,\n    };\n    let fp = bellerophon::<f64>(&num);\n    (fp.exp, fp.mant)\n}", "test": "fn compute_float_f64_test() {\n    // These test near-halfway cases for double-precision floats.\n    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));\n    assert_eq!(compute_float64(0, 9007199254740993), (1065 + f64::INVALID_FP, 9223372036854776832));\n    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));\n    assert_eq!(compute_float64(0, 9007199254740995), (1065 + f64::INVALID_FP, 9223372036854778880));\n    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));\n    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));\n    assert_eq!(\n        compute_float64(0, 18014398509481986),\n        (1066 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));\n    assert_eq!(\n        compute_float64(0, 18014398509481990),\n        (1066 + f64::INVALID_FP, 9223372036854778880)\n    );\n    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));\n\n    // These are examples of the above tests, with\n    // digits from the exponent shifted to the mantissa.\n    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));\n    assert_eq!(\n        compute_float64(-3, 9007199254740993000),\n        (1065 + f64::INVALID_FP, 9223372036854776832)\n    );\n    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));\n    assert_eq!(\n        compute_float64(-3, 9007199254740995000),\n        (1065 + f64::INVALID_FP, 9223372036854778879)\n    );\n    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));\n}"}
{"code": "pub fn map<I, O1, O2, E, F, G>(mut parser: F, mut f: G) -> impl FnMut(I) -> IResult<I, O2, E>\nwhere\n  F: Parser<I, O1, E>,\n  G: FnMut(O1) -> O2,\n{\n  move |input: I| {\n    let (input, o1) = parser.parse(input)?;\n    Ok((input, f(o1)))\n  }\n}", "test": "fn parens_test() {\n  assert_eq!(\n    expr(\" ( 1 + 2 ) *  3 \").map(|(i, x)| (i, format!(\"{:?}\", x))),\n    Ok((\"\", String::from(\"([(1 + 2)] * 3)\")))\n  );\n}"}
{"code": "pub fn data(&self) -> &[u8] {\n        // N.B.: we emit every section into the .text section as far as\n        // the `CodeSink` is concerned; we do not bother to segregate\n        // the contents into the actual program text, the jumptable and the\n        // rodata (constant pool). This allows us to generate code assuming\n        // that these will not be relocated relative to each other, and avoids\n        // having to designate each section as belonging in one of the three\n        // fixed categories defined by `CodeSink`. If this becomes a problem\n        // later (e.g. because of memory permissions or similar), we can\n        // add this designation and segregate the output; take care, however,\n        // to add the appropriate relocations in this case.\n\n        &self.data[..]\n    }", "test": "async fn call_linked_func_async() -> Result<(), Error> {\n    let mut config = Config::new();\n    config.async_support(true);\n    let engine = Engine::new(&config)?;\n    let mut store = Store::new(&engine, State::default());\n    store.call_hook(State::call_hook);\n\n    let f = Func::wrap4_async(\n        &mut store,\n        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {\n            Box::new(async move {\n                // Calling this func will switch context into wasm, then back to host:\n                assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);\n\n                assert_eq!(\n                    caller.data().calls_into_host,\n                    caller.data().returns_from_host + 1\n                );\n                assert_eq!(\n                    caller.data().calls_into_wasm,\n                    caller.data().returns_from_wasm + 1\n                );\n                assert_eq!(a, 1);\n                assert_eq!(b, 2);\n                assert_eq!(c, 3.0);\n                assert_eq!(d, 4.0);\n            })\n        },\n    );\n\n    let mut linker = Linker::new(&engine);\n\n    linker.define(&mut store, \"host\", \"f\", f)?;\n\n    let wat = r#\"\n        (module\n            (import \"host\" \"f\"\n                (func $f (param i32) (param i64) (param f32) (param f64)))\n            (func (export \"export\")\n                (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0)))\n        )\n    \"#;\n    let module = Module::new(&engine, wat)?;\n\n    let inst = linker.instantiate_async(&mut store, &module).await?;\n    let export = inst\n        .get_export(&mut store, \"export\")\n        .expect(\"get export\")\n        .into_func()\n        .expect(\"export is func\");\n\n    export.call_async(&mut store, &[], &mut []).await?;\n\n    // One switch from vm to host to call f, another in return from f.\n    assert_eq!(store.data().calls_into_host, 1);\n    assert_eq!(store.data().returns_from_host, 1);\n    assert_eq!(store.data().calls_into_wasm, 1);\n    assert_eq!(store.data().returns_from_wasm, 1);\n\n    export\n        .typed::<(), ()>(&store)?\n        .call_async(&mut store, ())\n        .await?;\n\n    assert_eq!(store.data().calls_into_host, 2);\n    assert_eq!(store.data().returns_from_host, 2);\n    assert_eq!(store.data().calls_into_wasm, 2);\n    assert_eq!(store.data().returns_from_wasm, 2);\n\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_witness_raftlog_gc_lagged_follower() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n\n    cluster.must_put(b\"k0\", b\"v0\");\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store1);\n    // nonwitness -> witness\n    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();\n    cluster.pd_client.must_switch_witnesses(\n        region.get_id(),\n        vec![peer_on_store3.get_id()],\n        vec![true],\n    );\n\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(200));\n    let mut before_states = HashMap::default();\n    for (&id, engines) in &cluster.engines {\n        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        before_states.insert(id, state.take_truncated_state());\n    }\n\n    // one follower is down\n    cluster.stop_node(nodes[1]);\n\n    // write some data to make log gap exceeds the gc limit\n    for i in 1..1000 {\n        let (k, v) = (format!(\"k{}\", i), format!(\"v{}\", i));\n        let key = k.as_bytes();\n        let value = v.as_bytes();\n        cluster.must_put(key, value);\n    }\n\n    // the witness truncated index is not advanced\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        if id == 2 {\n            assert_eq!(\n                state.get_truncated_state().get_index() - before_states[&id].get_index(),\n                0\n            );\n        } else {\n            assert_ne!(\n                900,\n                state.get_truncated_state().get_index() - before_states[&id].get_index()\n            );\n        }\n    }\n\n    // the follower is back online\n    cluster.run_node(nodes[1]).unwrap();\n    cluster.must_put(b\"k00\", b\"v00\");\n    must_get_equal(&cluster.get_engine(nodes[1]), b\"k00\", b\"v00\");\n    // make sure raft log gc is triggered\n    std::thread::sleep(Duration::from_millis(300));\n\n    // the truncated index is advanced now, as all the peers has replicated\n    for (&id, engines) in &cluster.engines {\n        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));\n        assert_ne!(\n            900,\n            state.get_truncated_state().get_index() - before_states[&id].get_index()\n        );\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn extends_should_raise_an_error_for_unresolved_configuration() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let rome_json = Path::new(\"biome.json\");\n    fs.insert(\n        rome_json.into(),\n        r#\"{ \"extends\": [\"formatTYPO.json\", \"linter.json\"] }\"#,\n    );\n    let format = Path::new(\"format.json\");\n    fs.insert(\n        format.into(),\n        r#\"{ \"javascript\": { \"formatter\": { \"quoteStyle\": \"single\" } } }\"#,\n    );\n    let lint = Path::new(\"linter.json\");\n    fs.insert(lint.into(), r#\"{ \"linter\": { \"enabled\": false } }\"#);\n\n    let test_file = Path::new(\"test.js\");\n    fs.insert(test_file.into(), r#\"debugger; console.log(\"string\"); \"#);\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), test_file.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"extends_should_raise_an_error_for_unresolved_configuration\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn len(&self) -> usize {\n        match_template_evaltype! {\n            TT, match self {\n                VectorValue::TT(v) => v.len(),\n            }\n        }\n    }", "test": "fn test_node_local_read_renew_lease() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(500);\n    let (base_tick_ms, election_ticks) = (50, 10);\n    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10));\n    cluster.pd_client.disable_default_operator();\n    let region_id = cluster.run_conf_change();\n\n    let key = b\"k\";\n    cluster.must_put(key, b\"v0\");\n    for id in 2..=3 {\n        cluster.pd_client.must_add_peer(region_id, new_peer(id, id));\n        must_get_equal(&cluster.get_engine(id), key, b\"v0\");\n    }\n\n    // Write the initial value for a key.\n    let key = b\"k\";\n    cluster.must_put(key, b\"v1\");\n    // Force `peer` to become leader.\n    let region = cluster.get_region(key);\n    let region_id = region.get_id();\n    let peer = new_peer(1, 1);\n    cluster.must_transfer_leader(region_id, peer.clone());\n\n    let detector = LeaseReadFilter::default();\n    cluster.add_send_filter(CloneFilterFactory(detector.clone()));\n\n    // election_timeout_ticks * base_tick_interval * 3\n    let hibernate_wait = election_ticks * Duration::from_millis(base_tick_ms) * 3;\n    let request_wait = Duration::from_millis(base_tick_ms);\n    let max_renew_lease_time = 3;\n    let round = hibernate_wait.as_millis() / request_wait.as_millis();\n    for i in 0..round {\n        // Issue a read request and check the value on response.\n        must_read_on_peer(&mut cluster, peer.clone(), region.clone(), key, b\"v1\");\n        // Plus 1 to prevent case failure when test machine is too slow.\n        assert_le!(detector.ctx.rl().len(), max_renew_lease_time + 1, \"{}\", i);\n        thread::sleep(request_wait);\n    }\n}"}
{"code": "pub fn stored_bytes(&self) -> u64 {\n        self.stored_leaf_bytes\n    }", "test": "fn stored_size() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(STR_TABLE).unwrap();\n        table.insert(\"hello\", \"world\").unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    assert_eq!(write_txn.stats().unwrap().stored_bytes(), 10);\n    assert!(write_txn.stats().unwrap().fragmented_bytes() > 0);\n    assert!(write_txn.stats().unwrap().metadata_bytes() > 0);\n    write_txn.abort().unwrap();\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_interactive() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file_a = \"test_mv_interactive_file_a\";\n    let file_b = \"test_mv_interactive_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n\n    scene\n        .ucmd()\n        .arg(\"-i\")\n        .arg(file_a)\n        .arg(file_b)\n        .pipe_in(\"n\")\n        .fails()\n        .no_stdout();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    scene\n        .ucmd()\n        .arg(\"-i\")\n        .arg(file_a)\n        .arg(file_b)\n        .pipe_in(\"Yesh\") // spell-checker:disable-line\n        .succeeds()\n        .no_stdout();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n}"}
{"code": "pub(crate) fn mantissa_exponent(exponent: i32, fraction_digits: usize, truncated: usize) -> i32 {\n    if fraction_digits > truncated {\n        exponent.saturating_sub(into_i32(fraction_digits - truncated))\n    } else {\n        exponent.saturating_add(into_i32(truncated - fraction_digits))\n    }\n}", "test": "fn mantissa_exponent_test() {\n    assert_eq!(mantissa_exponent(10, 5, 0), 5);\n    assert_eq!(mantissa_exponent(0, 5, 0), -5);\n    assert_eq!(\n        mantissa_exponent(i32::max_value(), 5, 0),\n        i32::max_value() - 5\n    );\n    assert_eq!(mantissa_exponent(i32::max_value(), 0, 5), i32::max_value());\n    assert_eq!(mantissa_exponent(i32::min_value(), 5, 0), i32::min_value());\n    assert_eq!(\n        mantissa_exponent(i32::min_value(), 0, 5),\n        i32::min_value() + 5\n    );\n}"}
{"code": "fn write(&mut self, bytes: &[u8]) -> io::Result<usize> {\n        self.tls_conn.writer().write(bytes)\n    }", "test": "fn exercise_key_log_file_for_client() {\n    serialized(|| {\n        let server_config = Arc::new(make_server_config(KeyType::Rsa));\n        env::set_var(\"SSLKEYLOGFILE\", \"./sslkeylogfile.txt\");\n\n        for version in rustls::ALL_VERSIONS {\n            let mut client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);\n            client_config.key_log = Arc::new(rustls::KeyLogFile::new());\n\n            let (mut client, mut server) =\n                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n\n            assert_eq!(5, client.writer().write(b\"hello\").unwrap());\n\n            do_handshake(&mut client, &mut server);\n            transfer(&mut client, &mut server);\n            server.process_new_packets().unwrap();\n        }\n    })\n}"}
{"code": "fn render_template(content: &str, context: &Context) -> Result<String> {\n    let mut tera = Tera::default();\n    tera.add_raw_template(\"hello.html\", content).unwrap();\n    tera.register_function(\"get_number\", |_: &HashMap<String, Value>| Ok(Value::Number(10.into())));\n    tera.register_function(\"get_true\", |_: &HashMap<String, Value>| Ok(Value::Bool(true)));\n    tera.register_function(\"get_string\", |_: &HashMap<String, Value>| {\n        Ok(Value::String(\"Hello\".to_string()))\n    });\n\n    tera.render(\"hello.html\", context)\n}", "test": "fn comments_are_ignored() {\n    let inputs = vec![\n        (\"Hello {# comment #}world\", \"Hello world\"),\n        (\"Hello {# comment {# nested #}world\", \"Hello world\"),\n        (\"My name {# was {{ name }} #}is No One.\", \"My name is No One.\"),\n    ];\n\n    for (input, expected) in inputs {\n        println!(\"{:?} -> {:?}\", input, expected);\n        assert_eq!(render_template(input, &Context::new()).unwrap(), expected);\n    }\n}"}
{"code": "fn is_cluster_bootstrapped(&self) -> Result<bool> {\n        let _timer = PD_REQUEST_HISTOGRAM_VEC\n            .is_cluster_bootstrapped\n            .start_coarse_timer();\n\n        let mut req = pdpb::IsBootstrappedRequest::default();\n        req.set_header(self.header());\n\n        let resp = sync_request(&self.pd_client, LEADER_CHANGE_RETRY, |client, option| {\n            client.is_bootstrapped_opt(&req, option)\n        })?;\n        check_resp_header(resp.get_header())?;\n\n        Ok(resp.get_bootstrapped())\n    }", "test": "fn test_reboot() {\n    let eps_count = 1;\n    let server = MockServer::with_case(eps_count, Arc::new(AlreadyBootstrapped));\n    let eps = server.bind_addrs();\n    let mut client = new_client_v2(eps, None);\n\n    assert!(!client.is_cluster_bootstrapped().unwrap());\n\n    match client.bootstrap_cluster(metapb::Store::default(), metapb::Region::default()) {\n        Err(PdError::ClusterBootstrapped(_)) => (),\n        _ => {\n            panic!(\"failed, should return ClusterBootstrapped\");\n        }\n    }\n}"}
{"code": "pub fn call(mut self) -> Self {\n        self.is_call = true;\n        self\n    }", "test": "fn post_return_all_types() -> Result<()> {\n    let component = r#\"\n        (component\n            (core module $m\n                (func (export \"i32\") (result i32)\n                    i32.const 1)\n                (func (export \"i64\") (result i64)\n                    i64.const 2)\n                (func (export \"f32\") (result f32)\n                    f32.const 3)\n                (func (export \"f64\") (result f64)\n                    f64.const 4)\n\n                (func (export \"post-i32\") (param i32)\n                    local.get 0\n                    i32.const 1\n                    i32.ne\n                    if unreachable end)\n                (func (export \"post-i64\") (param i64)\n                    local.get 0\n                    i64.const 2\n                    i64.ne\n                    if unreachable end)\n                (func (export \"post-f32\") (param f32)\n                    local.get 0\n                    f32.const 3\n                    f32.ne\n                    if unreachable end)\n                (func (export \"post-f64\") (param f64)\n                    local.get 0\n                    f64.const 4\n                    f64.ne\n                    if unreachable end)\n            )\n            (core instance $i (instantiate $m))\n            (func (export \"i32\") (result u32)\n                (canon lift (core func $i \"i32\") (post-return (func $i \"post-i32\")))\n            )\n            (func (export \"i64\") (result u64)\n                (canon lift (core func $i \"i64\") (post-return (func $i \"post-i64\")))\n            )\n            (func (export \"f32\") (result float32)\n                (canon lift (core func $i \"f32\") (post-return (func $i \"post-f32\")))\n            )\n            (func (export \"f64\") (result float64)\n                (canon lift (core func $i \"f64\") (post-return (func $i \"post-f64\")))\n            )\n        )\n    \"#;\n\n    let engine = super::engine();\n    let component = Component::new(&engine, component)?;\n    let mut store = Store::new(&engine, false);\n    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;\n    let i32 = instance.get_typed_func::<(), (u32,)>(&mut store, \"i32\")?;\n    let i64 = instance.get_typed_func::<(), (u64,)>(&mut store, \"i64\")?;\n    let f32 = instance.get_typed_func::<(), (f32,)>(&mut store, \"f32\")?;\n    let f64 = instance.get_typed_func::<(), (f64,)>(&mut store, \"f64\")?;\n\n    assert_eq!(i32.call(&mut store, ())?, (1,));\n    i32.post_return(&mut store)?;\n\n    assert_eq!(i64.call(&mut store, ())?, (2,));\n    i64.post_return(&mut store)?;\n\n    assert_eq!(f32.call(&mut store, ())?, (3.,));\n    f32.post_return(&mut store)?;\n\n    assert_eq!(f64.call(&mut store, ())?, (4.,));\n    f64.post_return(&mut store)?;\n\n    Ok(())\n}"}
{"code": "pub fn get(&mut self, key: &[u8]) -> Option<Vec<u8>> {\n        self.get_impl(CF_DEFAULT, key, false)\n    }", "test": "fn test_read_after_peer_destroyed() {\n    let mut cluster = new_node_cluster(0, 3);\n    let pd_client = cluster.pd_client.clone();\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n    let r1 = cluster.run_conf_change();\n\n    // Add 2 peers.\n    for i in 2..4 {\n        pd_client.must_add_peer(r1, new_peer(i, i));\n    }\n\n    // Make sure peer 1 leads the region.\n    cluster.must_transfer_leader(r1, new_peer(1, 1));\n    let (key, value) = (b\"k1\", b\"v1\");\n    cluster.must_put(key, value);\n    assert_eq!(cluster.get(key), Some(value.to_vec()));\n\n    let destroy_peer_fp = \"destroy_peer\";\n    fail::cfg(destroy_peer_fp, \"pause\").unwrap();\n    pd_client.must_remove_peer(r1, new_peer(1, 1));\n    sleep_ms(300);\n\n    // Try writing k2 to peer3\n    let mut request = new_request(\n        r1,\n        cluster.pd_client.get_region_epoch(r1),\n        vec![new_get_cmd(b\"k1\")],\n        false,\n    );\n    request.mut_header().set_peer(new_peer(1, 1));\n    let (cb, mut rx) = make_cb(&request);\n    cluster\n        .sim\n        .rl()\n        .async_command_on_node(1, request, cb)\n        .unwrap();\n    // Wait for raftstore receives the read request.\n    sleep_ms(200);\n    fail::remove(destroy_peer_fp);\n\n    let resp = rx.recv_timeout(Duration::from_millis(200)).unwrap();\n    assert!(\n        resp.get_header().get_error().has_region_not_found(),\n        \"{:?}\",\n        resp\n    );\n}"}
{"code": "fn disk_full_stores(resp: &RaftCmdResponse) -> Vec<u64> {\n    let region_error = resp.get_header().get_error();\n    assert!(region_error.has_disk_full());\n    let mut stores = region_error.get_disk_full().get_store_id().to_vec();\n    stores.sort_unstable();\n    stores\n}", "test": "fn test_majority_disk_full() {\n    let mut cluster = new_node_cluster(0, 3);\n    // To ensure the thread has full store disk usage infomation.\n    cluster.cfg.raft_store.store_batch_system.pool_size = 1;\n    cluster.pd_client.disable_default_operator();\n    cluster.run();\n\n    // To ensure all replicas are not pending.\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(1), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n\n    cluster.must_transfer_leader(1, new_peer(1, 1));\n    let region = cluster.get_region(b\"k1\");\n    let epoch = region.get_region_epoch().clone();\n\n    // To ensure followers have reported disk usages to the leader.\n    for i in 1..3 {\n        fail::cfg(get_fp(DiskUsage::AlmostFull, i + 1), \"return\").unwrap();\n        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);\n    }\n\n    // Normal proposals will be rejected because of majority peers' disk full.\n    let mut ch = cluster.async_put(b\"k2\", b\"v2\").unwrap();\n    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();\n    assert_eq!(disk_full_stores(&resp), vec![2, 3]);\n\n    // Proposals with special `DiskFullOpt`s can be accepted even if all peers are\n    // disk full.\n    fail::cfg(get_fp(DiskUsage::AlmostFull, 1), \"return\").unwrap();\n    let reqs = vec![new_put_cmd(b\"k3\", b\"v3\")];\n    let put = new_request(1, epoch.clone(), reqs, false);\n    let mut opts = RaftCmdExtraOpts::default();\n    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;\n    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();\n    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();\n    assert!(!resp.get_header().has_error());\n\n    // Reset disk full status for peer 2 and 3. 2 follower reads must success\n    // because the leader will continue to append entries to followers after the\n    // new disk usages are reported.\n    for i in 1..3 {\n        fail::remove(get_fp(DiskUsage::AlmostFull, i + 1));\n        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);\n        must_get_equal(&cluster.get_engine(i + 1), b\"k3\", b\"v3\");\n    }\n\n    // To ensure followers have reported disk usages to the leader.\n    for i in 1..3 {\n        fail::cfg(get_fp(DiskUsage::AlreadyFull, i + 1), \"return\").unwrap();\n        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);\n    }\n\n    // Proposals with special `DiskFullOpt`s will still be rejected if majority\n    // peers are already disk full.\n    let reqs = vec![new_put_cmd(b\"k3\", b\"v3\")];\n    let put = new_request(1, epoch.clone(), reqs, false);\n    let mut opts = RaftCmdExtraOpts::default();\n    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;\n    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();\n    let resp = ch.recv_timeout(Duration::from_secs(10)).unwrap();\n    assert_eq!(disk_full_stores(&resp), vec![2, 3]);\n\n    // Peer 2 disk usage changes from already full to almost full.\n    fail::remove(get_fp(DiskUsage::AlreadyFull, 2));\n    fail::cfg(get_fp(DiskUsage::AlmostFull, 2), \"return\").unwrap();\n    ensure_disk_usage_is_reported(&mut cluster, 2, 2, &region);\n\n    // Configuration change should be alloed.\n    cluster.pd_client.must_remove_peer(1, new_peer(2, 2));\n\n    // After the last configuration change is applied, the raft group will be like\n    // `[(1, DiskUsage::AlmostFull), (3, DiskUsage::AlreadyFull)]`. So no more\n    // proposals should be allowed.\n    let reqs = vec![new_put_cmd(b\"k4\", b\"v4\")];\n    let put = new_request(1, epoch, reqs, false);\n    let mut opts = RaftCmdExtraOpts::default();\n    opts.disk_full_opt = DiskFullOpt::AllowedOnAlmostFull;\n    let mut ch = cluster.async_request_with_opts(put, opts).unwrap();\n    let resp = ch.recv_timeout(Duration::from_secs(1)).unwrap();\n    assert_eq!(disk_full_stores(&resp), vec![3]);\n\n    for i in 0..3 {\n        fail::remove(get_fp(DiskUsage::AlreadyFull, i + 1));\n        fail::remove(get_fp(DiskUsage::AlmostFull, i + 1));\n    }\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn upgrade_severity() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n    let file_path = Path::new(\"biome.json\");\n    fs.insert(\n        file_path.into(),\n        CONFIG_LINTER_UPGRADE_DIAGNOSTIC.as_bytes(),\n    );\n\n    let file_path = Path::new(\"file.js\");\n    fs.insert(file_path.into(), UPGRADE_SEVERITY_CODE.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"check\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let messages = &console.out_buffer;\n\n    let error_count = messages\n        .iter()\n        .filter(|m| m.level == LogLevel::Error)\n        .filter(|m| {\n            let content = format!(\"{:?}\", m.content);\n            content.contains(\"style/noNegationElse\")\n        })\n        .count();\n\n    assert_eq!(\n        error_count, 1,\n        \"expected 1 error-level message in console buffer, found {error_count:?}:\\n{:?}\",\n        console.out_buffer\n    );\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"upgrade_severity\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub const fn to_bits(self) -> u16 {\n        self.bits\n    }", "test": "fn from_f32_test() {\n    assert_eq!(bf16::from_f32(4.5917e-41f32).to_bits(), 0);\n    assert_eq!(bf16::from_f32(4.5918e-41f32).to_bits(), 0);\n    assert_eq!(bf16::from_f32(4.5919e-41f32).to_bits(), 1);\n    assert_eq!(bf16::from_f32(9.18354e-41f32).to_bits(), 1);\n    assert_eq!(bf16::from_f32(9.18355e-41f32).to_bits(), 1);\n    assert_eq!(bf16::from_f32(9.18356e-41f32).to_bits(), 1);\n    assert_eq!(bf16::from_f32(1.37752e-40f32).to_bits(), 1);\n    assert_eq!(bf16::from_f32(1.37753e-40f32).to_bits(), 2);\n    assert_eq!(bf16::from_f32(1.37754e-40f32).to_bits(), 2);\n    assert!(bf16::from_f32(f32::NAN).is_nan());\n    assert!(bf16::from_f32(f32::INFINITY).is_inf());\n    assert!(bf16::from_f32(f32::NEG_INFINITY).is_inf());\n}"}
{"code": "pub fn answers(answers: LookupRecords, additionals: Option<LookupRecords>) -> Self {\n        Self::Records {\n            answers,\n            additionals,\n        }\n    }", "test": "fn test_datagram_stream_upgrade_on_truncation_despite_udp() {\n    // Lookup to UDP should return a truncated message, then we expect lookup on TCP.\n    // This should occur even though `try_tcp_on_error` is set to false.\n\n    let query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n\n    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));\n    let tcp_record1 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));\n    let tcp_record2 = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 3));\n\n    let mut udp_message = message(query.clone(), vec![udp_record], vec![], vec![]);\n    udp_message.set_truncated(true);\n\n    let tcp_message = message(\n        query.clone(),\n        vec![tcp_record1.clone(), tcp_record2.clone()],\n        vec![],\n        vec![],\n    );\n\n    let udp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],\n        Default::default(),\n    );\n    let tcp_nameserver = mock_nameserver(\n        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],\n        Default::default(),\n    );\n\n    let pool = mock_nameserver_pool(\n        vec![udp_nameserver],\n        vec![tcp_nameserver],\n        None,\n        Default::default(),\n    );\n\n    // lookup on UDP succeeds, any other would fail\n    let request = message(query, vec![], vec![], vec![]);\n    let future = pool.send(request).first_answer();\n\n    let response = block_on(future).unwrap();\n    assert_eq!(response.answers(), &[tcp_record1, tcp_record2]);\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_numbered_if_existing_backup_existing() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let existing_backup = &format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~1~\");\n    at.touch(existing_backup);\n\n    ucmd.arg(\"--backup=existing\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(TEST_HOW_ARE_YOU_SOURCE));\n    assert!(at.file_exists(existing_backup));\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~2~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_entry_multi_0() {\n    let mut headers = HeaderMap::new();\n    let cookies = remove_all_values(&mut headers, SET_COOKIE);\n    assert_eq!(cookies.len(), 0);\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn tuple3_type() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n\n    let table_def: TableDefinition<(&str, u8, u16), (u16, u32)> = TableDefinition::new(\"table\");\n\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(table_def).unwrap();\n        table.insert(&(\"hello\", 5, 6), &(0, 123)).unwrap();\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(table_def).unwrap();\n    assert_eq!(\n        table.get(&(\"hello\", 5, 6)).unwrap().unwrap().value(),\n        (0, 123)\n    );\n}"}
{"code": "fn as_bytes<'a, 'b: 'a>(value: &'a Self::SelfType<'b>) -> &'a [u8]\n    where\n        Self: 'a,\n        Self: 'b,\n    {\n        &value.data\n    }", "test": "fn insert_reserve() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let def: TableDefinition<&str, &[u8]> = TableDefinition::new(\"x\");\n    let value = \"world\";\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(def).unwrap();\n        let mut reserved = table\n            .insert_reserve(\"hello\", value.len().try_into().unwrap())\n            .unwrap();\n        reserved.as_mut().copy_from_slice(value.as_bytes());\n    }\n    write_txn.commit().unwrap();\n\n    let read_txn = db.begin_read().unwrap();\n    let table = read_txn.open_table(def).unwrap();\n    assert_eq!(\n        value.as_bytes(),\n        table.get(\"hello\").unwrap().unwrap().value()\n    );\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_duplicate_files() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_COPY_TO_FOLDER)\n        .succeeds()\n        .stderr_contains(\"specified more than once\");\n    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), \"Hello, World!\\n\");\n}"}
{"code": "fn get_pool_size(&self, priority_level: CommandPri) -> usize {\n        if priority_level == CommandPri::High {\n            self.high_worker_pool.get_pool_size()\n        } else {\n            self.worker_pool.get_pool_size()\n        }\n    }", "test": "fn test_scale_scheduler_pool() {\n    let snapshot_fp = \"scheduler_start_execute\";\n    let mut cluster = new_server_cluster(0, 1);\n    cluster.run();\n    let origin_pool_size = cluster.cfg.storage.scheduler_worker_pool_size;\n\n    let engine = cluster\n        .sim\n        .read()\n        .unwrap()\n        .storages\n        .get(&1)\n        .unwrap()\n        .clone();\n    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())\n        .config(cluster.cfg.tikv.storage.clone())\n        .build()\n        .unwrap();\n\n    let cfg = new_tikv_config(1);\n    let kv_engine = storage.get_engine().kv_engine().unwrap();\n    let (_tx, rx) = std::sync::mpsc::channel();\n    let flow_controller = Arc::new(FlowController::Singleton(EngineFlowController::new(\n        &cfg.storage.flow_control,\n        kv_engine.clone(),\n        rx,\n    )));\n\n    let cfg_controller = ConfigController::new(cfg);\n    let (scheduler, _receiver) = dummy_scheduler();\n    cfg_controller.register(\n        Module::Storage,\n        Box::new(StorageConfigManger::new(\n            kv_engine,\n            scheduler,\n            flow_controller,\n            storage.get_scheduler(),\n        )),\n    );\n    let scheduler = storage.get_scheduler();\n\n    let region = cluster.get_region(b\"k1\");\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.id);\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(cluster.leader_of_region(region.id).unwrap());\n    let do_prewrite = |key: &[u8], val: &[u8]| {\n        // prewrite\n        let (prewrite_tx, prewrite_rx) = channel();\n        storage\n            .sched_txn_command(\n                commands::Prewrite::new(\n                    vec![Mutation::make_put(Key::from_raw(key), val.to_vec())],\n                    key.to_vec(),\n                    10.into(),\n                    100,\n                    false,\n                    2,\n                    TimeStamp::default(),\n                    TimeStamp::default(),\n                    None,\n                    false,\n                    AssertionLevel::Off,\n                    ctx.clone(),\n                ),\n                Box::new(move |res: storage::Result<_>| {\n                    let _ = prewrite_tx.send(res);\n                }),\n            )\n            .unwrap();\n        prewrite_rx.recv_timeout(Duration::from_secs(2))\n    };\n\n    let scale_pool = |size: usize| {\n        cfg_controller\n            .update_config(\"storage.scheduler-worker-pool-size\", &format!(\"{}\", size))\n            .unwrap();\n        assert_eq!(\n            scheduler.get_sched_pool().get_pool_size(CommandPri::Normal),\n            size\n        );\n    };\n\n    scale_pool(1);\n    fail::cfg(snapshot_fp, \"1*pause\").unwrap();\n    // propose one prewrite to block the only worker\n    do_prewrite(b\"k1\", b\"v1\").unwrap_err();\n\n    scale_pool(2);\n\n    // do prewrite again, as we scale another worker, this request should success\n    do_prewrite(b\"k2\", b\"v2\").unwrap().unwrap();\n\n    // restore to original config.\n    scale_pool(origin_pool_size);\n    fail::remove(snapshot_fp);\n}"}
{"code": "pub fn is_nfc(s: &str) -> bool {\n    match is_nfc_quick(s.chars()) {\n        IsNormalized::Yes => true,\n        IsNormalized::No => false,\n        IsNormalized::Maybe => s.chars().eq(s.chars().nfc()),\n    }\n}", "test": "fn test_streamsafe_regression(){\n    let input = \"\\u{342}\".repeat(55) + &\"\\u{344}\".repeat(3);\n    let nfc_ss = input.chars().nfc().stream_safe().collect::<String>();\n\n    // The result should be NFC:\n    assert!(is_nfc(&nfc_ss));\n    // and should be stream-safe:\n    assert!(is_nfc_stream_safe(&nfc_ss))\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_if_linter_is_disabled_when_run_apply() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"fix.js\");\n    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());\n\n    let config_path = Path::new(\"biome.json\");\n    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"lint\"),\n                (\"--apply\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_if_linter_is_disabled_when_run_apply\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn alpn_success() {\n    let _guard = subscribe();\n    let mut server_crypto = server_crypto();\n    server_crypto.alpn_protocols = vec![\"foo\".into(), \"bar\".into(), \"baz\".into()];\n    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);\n    let mut client_crypto = client_crypto();\n    client_crypto.alpn_protocols = vec![\"bar\".into(), \"quux\".into(), \"corge\".into()];\n    let client_config = ClientConfig::new(Arc::new(client_crypto));\n\n    // Establish normal connection\n    let client_ch = pair.begin_connect(client_config);\n    pair.drive();\n    let server_ch = pair.server.assert_accept();\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::HandshakeDataReady)\n    );\n    assert_matches!(\n        pair.server_conn_mut(server_ch).poll(),\n        Some(Event::Connected)\n    );\n\n    let hd = pair\n        .client_conn_mut(client_ch)\n        .crypto_session()\n        .handshake_data()\n        .unwrap()\n        .downcast::<crate::crypto::rustls::HandshakeData>()\n        .unwrap();\n    assert_eq!(hd.protocol.unwrap(), &b\"bar\"[..]);\n}"}
{"code": "fn write(&mut self, buf: &[u8]) -> Result<usize> {\n        self.complete_prior_io()?;\n\n        let len = self.conn.writer().write(buf)?;\n\n        // Try to write the underlying transport here, but don't let\n        // any errors mask the fact we've consumed `len` bytes.\n        // Callers will learn of permanent errors on the next call.\n        let _ = self.conn.complete_io(self.sock);\n\n        Ok(len)\n    }", "test": "fn server_closes_uncleanly() {\n    let kt = KeyType::Rsa;\n    let server_config = Arc::new(make_server_config(kt));\n\n    for version in rustls::ALL_VERSIONS {\n        let client_config = make_client_config_with_versions(kt, &[version]);\n        let (mut client, mut server) =\n            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);\n        do_handshake(&mut client, &mut server);\n\n        // check that unclean EOF reporting does not overtake appdata\n        assert_eq!(\n            12,\n            server\n                .writer()\n                .write(b\"from-server!\")\n                .unwrap()\n        );\n        assert_eq!(\n            12,\n            client\n                .writer()\n                .write(b\"from-client!\")\n                .unwrap()\n        );\n\n        transfer(&mut server, &mut client);\n        transfer_eof(&mut client);\n        let io_state = client.process_new_packets().unwrap();\n        assert!(!io_state.peer_has_closed());\n        check_read(&mut client.reader(), b\"from-server!\");\n\n        check_read_err(\n            &mut client.reader() as &mut dyn io::Read,\n            io::ErrorKind::UnexpectedEof,\n        );\n\n        // may still transmit pending frames\n        transfer(&mut client, &mut server);\n        server.process_new_packets().unwrap();\n        check_read(&mut server.reader(), b\"from-client!\");\n    }\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_numeric_suffix_no_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    ucmd.args(&[\"-l\", \"9\", \"--numeric-suffixes\", \"onehundredlines.txt\"])\n        .succeeds()\n        .no_stdout()\n        .no_stderr();\n    assert_eq!(at.read(\"x00\"), \"00\\n01\\n02\\n03\\n04\\n05\\n06\\n07\\n08\\n\");\n    assert_eq!(at.read(\"x01\"), \"09\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n\");\n    assert_eq!(at.read(\"x02\"), \"18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n\");\n    assert_eq!(at.read(\"x03\"), \"27\\n28\\n29\\n30\\n31\\n32\\n33\\n34\\n35\\n\");\n    assert_eq!(at.read(\"x04\"), \"36\\n37\\n38\\n39\\n40\\n41\\n42\\n43\\n44\\n\");\n    assert_eq!(at.read(\"x05\"), \"45\\n46\\n47\\n48\\n49\\n50\\n51\\n52\\n53\\n\");\n    assert_eq!(at.read(\"x06\"), \"54\\n55\\n56\\n57\\n58\\n59\\n60\\n61\\n62\\n\");\n    assert_eq!(at.read(\"x07\"), \"63\\n64\\n65\\n66\\n67\\n68\\n69\\n70\\n71\\n\");\n    assert_eq!(at.read(\"x08\"), \"72\\n73\\n74\\n75\\n76\\n77\\n78\\n79\\n80\\n\");\n    assert_eq!(at.read(\"x09\"), \"81\\n82\\n83\\n84\\n85\\n86\\n87\\n88\\n89\\n\");\n    assert_eq!(at.read(\"x10\"), \"90\\n91\\n92\\n93\\n94\\n95\\n96\\n97\\n98\\n\");\n    assert_eq!(at.read(\"x11\"), \"99\\n\");\n}"}
{"code": "fn len(&self) -> usize {\n        self.length\n    }", "test": "fn test_cdc_rawkv_resolved_ts() {\n    let mut suite = TestSuite::new(1, ApiVersion::V2);\n    let cluster = &suite.cluster;\n\n    let region = cluster.get_region(b\"\");\n    let region_id = region.get_id();\n    let leader = region.get_peers()[0].clone();\n    let node_id = leader.get_id();\n    let ts_provider = cluster.sim.rl().get_causal_ts_provider(node_id).unwrap();\n\n    let env = Arc::new(Environment::new(1));\n    let channel =\n        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));\n    let client = TikvClient::new(channel);\n\n    let mut req = suite.new_changedata_request(region_id);\n    req.set_kv_api(ChangeDataRequestKvApi::RawKv);\n    let (mut req_tx, _event_feed_wrap, receive_event) =\n        new_event_feed(suite.get_region_cdc_client(region_id));\n    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();\n\n    let event = receive_event(false);\n    event\n        .events\n        .into_iter()\n        .for_each(|e| match e.event.unwrap() {\n            Event_oneof_event::Entries(es) => {\n                assert!(es.entries.len() == 1, \"{:?}\", es);\n                let e = &es.entries[0];\n                assert_eq!(e.get_type(), EventLogType::Initialized, \"{:?}\", es);\n            }\n            other => panic!(\"unknown event {:?}\", other),\n        });\n    // Sleep a while to make sure the stream is registered.\n    sleep_ms(1000);\n\n    let mut ctx = Context::default();\n    ctx.set_region_id(region.get_id());\n    ctx.set_region_epoch(region.get_region_epoch().clone());\n    ctx.set_peer(leader);\n    ctx.set_api_version(ApiVersion::V2);\n    let mut put_req = RawPutRequest::default();\n    put_req.set_context(ctx);\n    put_req.key = b\"rk3\".to_vec();\n    put_req.value = b\"v3\".to_vec();\n\n    let pause_write_fp = \"raftkv_async_write\";\n    fail::cfg(pause_write_fp, \"pause\").unwrap();\n    let ts = block_on(ts_provider.async_get_ts()).unwrap();\n    let handle = thread::spawn(move || {\n        let _ = client.raw_put(&put_req).unwrap();\n    });\n\n    sleep_ms(100);\n\n    let event = receive_event(true).resolved_ts.unwrap();\n    assert!(\n        ts.next() >= TimeStamp::from(event.ts),\n        \"{} {}\",\n        ts,\n        TimeStamp::from(event.ts)\n    );\n    // Receive again to make sure resolved ts <= ongoing request's ts.\n    let event = receive_event(true).resolved_ts.unwrap();\n    assert!(\n        ts.next() >= TimeStamp::from(event.ts),\n        \"{} {}\",\n        ts,\n        TimeStamp::from(event.ts)\n    );\n\n    fail::remove(pause_write_fp);\n    handle.join().unwrap();\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_obs_lines_standalone_overflow() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"obs-lines-standalone\";\n    RandomFile::new(&at, name).add_lines(4);\n    ucmd.args(&[\"-99999999999999999991\", name])\n        .succeeds()\n        .no_stderr()\n        .no_stdout();\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 1);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "fn success() -> Self {\n        Self::Success\n    }", "test": "fn name_same_as_builtin_command() -> Result<()> {\n    // a bare subcommand shouldn't run successfully\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"run\")\n        .output()?;\n    assert!(!output.status.success());\n\n    // a `--` prefix should let everything else get interpreted as a wasm\n    // module and arguments, even if the module has a name like `run`\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"--\")\n        .arg(\"run\")\n        .output()?;\n    assert!(output.status.success(), \"expected success got {output:#?}\");\n\n    // Passing options before the subcommand should work and doesn't require\n    // `--` to disambiguate\n    let output = get_wasmtime_command()?\n        .current_dir(\"tests/all/cli_tests\")\n        .arg(\"-Ccache=n\")\n        .arg(\"run\")\n        .output()?;\n    assert!(output.status.success(), \"expected success got {output:#?}\");\n    Ok(())\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.vec.len()\n    }", "test": "fn remove_multiple_b() {\n    let mut headers = HeaderMap::new();\n    headers.insert(VIA, \"1.1 example.com\".parse().unwrap());\n    headers.insert(SET_COOKIE, \"cookie_1=value 1\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_2=value 2\".parse().unwrap());\n    headers.append(VIA, \"1.1 other.com\".parse().unwrap());\n    headers.append(SET_COOKIE, \"cookie_3=value 3\".parse().unwrap());\n    headers.insert(VARY, \"*\".parse().unwrap());\n\n    assert_eq!(headers.len(), 6);\n\n    let vary = headers.remove(VARY);\n    assert_eq!(vary, Some(\"*\".parse().unwrap()));\n    assert_eq!(headers.len(), 5);\n\n    let via = headers.remove(VIA);\n    assert_eq!(via, Some(\"1.1 example.com\".parse().unwrap()));\n    assert_eq!(headers.len(), 3);\n\n    let cookie = headers.remove(SET_COOKIE);\n    assert_eq!(cookie, Some(\"cookie_1=value 1\".parse().unwrap()));\n    assert_eq!(headers.len(), 0);\n}"}
{"code": "fn count(&self) -> usize {\n        self.collect().len()\n    }", "test": "fn test_split_overflow_bytes_size() {\n    #[cfg(not(target_pointer_width = \"128\"))]\n    let (at, mut ucmd) = at_and_ucmd!();\n    let name = \"test_split_overflow_bytes_size\";\n    RandomFile::new(&at, name).add_bytes(1000);\n    ucmd.args(&[\"-b\", \"1Y\", name]).succeeds();\n    let glob = Glob::new(&at, \".\", r\"x[[:alpha:]][[:alpha:]]$\");\n    assert_eq!(glob.count(), 1);\n    assert_eq!(glob.collate(), at.read_bytes(name));\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn no_lint_if_linter_is_disabled() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"fix.js\");\n    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());\n\n    let config_path = Path::new(\"biome.json\");\n    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"lint\"), file_path.as_os_str().to_str().unwrap()].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut buffer = String::new();\n    fs.open(file_path)\n        .unwrap()\n        .read_to_string(&mut buffer)\n        .unwrap();\n\n    assert_eq!(buffer, FIX_BEFORE);\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"no_lint_if_linter_is_disabled\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn is_unified_pool_enabled(&self) -> bool {\n        self.storage.use_unified_pool() || self.coprocessor.use_unified_pool()\n    }", "test": "fn test_do_not_use_unified_readpool_with_legacy_config() {\n    let content = r#\"\n        [readpool.storage]\n        normal-concurrency = 1\n\n        [readpool.coprocessor]\n        normal-concurrency = 1\n    \"#;\n    let cfg: TikvConfig = toml::from_str(content).unwrap();\n    assert!(!cfg.readpool.is_unified_pool_enabled());\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        match self.state.next(self.bytes) {\n            None => None,\n            Some(Ok(a)) => Some(Ok(a.map(|range| &self.bytes[range]).into())),\n            Some(Err(e)) => Some(Err(e)),\n        }\n    }", "test": "fn attributes_empty_ns_expanded() {\n    let src = \"<a att1='a' r:att2='b' xmlns:r='urn:example:r' />\";\n\n    let mut r = NsReader::from_str(src);\n    r.trim_text(true).expand_empty_elements(true);\n    {\n        let e = match r.read_resolved_event() {\n            Ok((Unbound, Start(e))) => e,\n            e => panic!(\"Expecting Empty event, got {:?}\", e),\n        };\n\n        let mut attrs = e\n            .attributes()\n            .map(|ar| ar.expect(\"Expecting attribute parsing to succeed.\"))\n            // we don't care about xmlns attributes for this test\n            .filter(|kv| kv.key.as_namespace_binding().is_none())\n            .map(|Attribute { key: name, value }| {\n                let (opt_ns, local_name) = r.resolve_attribute(name);\n                (opt_ns, local_name.into_inner(), value)\n            });\n        assert_eq!(\n            attrs.next(),\n            Some((Unbound, &b\"att1\"[..], Cow::Borrowed(&b\"a\"[..])))\n        );\n        assert_eq!(\n            attrs.next(),\n            Some((\n                Bound(Namespace(b\"urn:example:r\")),\n                &b\"att2\"[..],\n                Cow::Borrowed(&b\"b\"[..])\n            ))\n        );\n        assert_eq!(attrs.next(), None);\n    }\n\n    match r.read_resolved_event() {\n        Ok((Unbound, End(e))) => assert_eq!(e.name(), QName(b\"a\")),\n        e => panic!(\"Expecting End event, got {:?}\", e),\n    }\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_demote_non_exist_voters() {\n    let mut cluster = new_server_cluster(0, 3);\n    cluster.run();\n    let nodes = Vec::from_iter(cluster.get_node_ids());\n    assert_eq!(nodes.len(), 3);\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer number check.\n    pd_client.disable_default_operator();\n\n    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();\n\n    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();\n    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());\n    cluster.stop_node(nodes[1]);\n    cluster.stop_node(nodes[2]);\n\n    confirm_quorum_is_lost(&mut cluster, &region);\n    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);\n\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(region.get_id());\n    let mut peer = metapb::Peer::default();\n    peer.set_id(12345);\n    peer.set_store_id(region.get_id());\n    peer.set_role(metapb::PeerRole::Voter);\n    demote.mut_failed_voters().push(peer);\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);\n    cluster.must_send_store_heartbeat(nodes[0]);\n\n    let mut store_report = None;\n    for _ in 0..20 {\n        store_report = pd_client.must_get_store_report(nodes[0]);\n        if store_report.is_some() {\n            break;\n        }\n        sleep_ms(100);\n    }\n    assert_ne!(store_report, None);\n    let report = store_report.unwrap();\n    let peer_reports = report.get_peer_reports();\n    assert_eq!(peer_reports.len(), 1);\n    let reported_region = peer_reports[0].get_region_state().get_region();\n    assert_eq!(reported_region.get_id(), region.get_id());\n    assert_eq!(reported_region.get_peers().len(), 3);\n    let demoted = reported_region\n        .get_peers()\n        .iter()\n        .any(|peer| peer.get_role() != metapb::PeerRole::Voter);\n    assert_eq!(demoted, false);\n\n    let region_in_pd = block_on(pd_client.get_region_by_id(region.get_id()))\n        .unwrap()\n        .unwrap();\n    assert_eq!(region_in_pd.get_peers().len(), 3);\n    let demoted = region_in_pd\n        .get_peers()\n        .iter()\n        .any(|peer| peer.get_role() != metapb::PeerRole::Voter);\n    assert_eq!(demoted, false);\n}"}
{"code": "pub fn payload(&self) -> &T {\n        &self.data\n    }", "test": "async fn update_max_frame_len_at_rest() {\n    use futures::StreamExt;\n    use tokio::io::AsyncReadExt;\n\n    h2_support::trace_init!();\n    // TODO: add test for updating max frame length in flight as well?\n    let mut codec = raw_codec! {\n        read => [\n            0, 0, 5, 0, 0, 0, 0, 0, 1,\n            \"hello\",\n            0, 64, 1, 0, 0, 0, 0, 0, 1,\n            vec![0; 16_385],\n        ];\n    };\n\n    assert_eq!(poll_frame!(Data, codec).payload(), &b\"hello\"[..]);\n\n    codec.set_max_recv_frame_size(16_384);\n\n    assert_eq!(codec.max_recv_frame_size(), 16_384);\n    assert_eq!(\n        codec.next().await.unwrap().unwrap_err().to_string(),\n        \"frame with invalid size\"\n    );\n\n    // drain codec buffer\n    let mut buf = Vec::new();\n    codec.get_mut().read_to_end(&mut buf).await.unwrap();\n}"}
{"code": "pub const fn is_valid(&self) -> bool {\n        self.error().is_success()\n    }", "test": "fn invalid_decimal_point_test() {\n    let mut builder = OptionsBuilder::default();\n    builder = builder.decimal_point(b'\\x00');\n    assert!(!builder.is_valid());\n    builder = builder.decimal_point(b'\\x7f');\n    assert!(!builder.is_valid());\n    assert!(builder.build().is_err());\n    builder = builder.decimal_point(b',');\n    assert!(builder.is_valid());\n    assert!(builder.build().is_ok());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_update_option() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file_a = \"test_mv_update_option_file_a\";\n    let file_b = \"test_mv_update_option_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    let ts = time::OffsetDateTime::now_utc();\n    let now = FileTime::from_unix_time(ts.unix_timestamp(), ts.nanosecond());\n    let later = FileTime::from_unix_time(ts.unix_timestamp() + 3600, ts.nanosecond());\n    filetime::set_file_times(at.plus_as_string(file_a), now, now).unwrap();\n    filetime::set_file_times(at.plus_as_string(file_b), now, later).unwrap();\n\n    scene.ucmd().arg(\"--update\").arg(file_a).arg(file_b).run();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n\n    scene\n        .ucmd()\n        .arg(\"--update\")\n        .arg(file_b)\n        .arg(file_a)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(!at.file_exists(file_b));\n}"}
{"code": "fn count(&self) -> usize {\n        panic!()\n    }", "test": "fn test_error_in_compaction_filter() {\n    let mut engine = TestEngineBuilder::new().build().unwrap();\n    let raw_engine = engine.get_rocksdb();\n\n    let large_value = vec![b'x'; 300];\n    must_prewrite_put(&mut engine, b\"zkey\", &large_value, b\"zkey\", 101);\n    must_commit(&mut engine, b\"zkey\", 101, 102);\n    must_prewrite_put(&mut engine, b\"zkey\", &large_value, b\"zkey\", 103);\n    must_commit(&mut engine, b\"zkey\", 103, 104);\n    must_prewrite_delete(&mut engine, b\"zkey\", b\"zkey\", 105);\n    must_commit(&mut engine, b\"zkey\", 105, 106);\n\n    let fp = \"write_compaction_filter_flush_write_batch\";\n    fail::cfg(fp, \"return\").unwrap();\n\n    let mut gc_runner = TestGcRunner::new(200);\n    gc_runner.gc(&raw_engine);\n\n    match gc_runner.gc_receiver.recv().unwrap() {\n        GcTask::OrphanVersions { wb, .. } => assert_eq!(wb.count(), 2),\n        GcTask::GcKeys { .. } => {}\n        _ => unreachable!(),\n    }\n\n    // Although versions on default CF is not cleaned, write CF is GCed correctly.\n    must_get_none(&mut engine, b\"zkey\", 102);\n    must_get_none(&mut engine, b\"zkey\", 104);\n\n    fail::remove(fp);\n}"}
{"code": "pub fn from_str<'a, T>(&self, s: &'a str) -> SpannedResult<T>\n    where\n        T: de::Deserialize<'a>,\n    {\n        self.from_bytes(s.as_bytes())\n    }", "test": "fn test_inf_and_nan() {\n    assert_eq!(from_str(\"inf\"), Ok(std::f64::INFINITY));\n    assert_eq!(from_str(\"-inf\"), Ok(std::f64::NEG_INFINITY));\n    assert_eq!(from_str::<f64>(\"NaN\").map(|n| n.is_nan()), Ok(true))\n}"}
{"code": "pub fn buffer_position(&self) -> usize {\n        // when internal state is OpenedTag, we have actually read until '<',\n        // which we don't want to show\n        if let ParseState::OpenedTag = self.state.state {\n            self.state.offset - 1\n        } else {\n            self.state.offset\n        }\n    }", "test": "fn test_offset_err_comment() {\n    let mut r = Reader::from_str(\"<a><!--b>\");\n    r.trim_text(true);\n\n    next_eq!(r, Start, b\"a\");\n    assert_eq!(r.buffer_position(), 3);\n\n    match r.read_event() {\n        // error at char 4: no closing --> tag found\n        Err(e) => assert_eq!(\n            r.buffer_position(),\n            4,\n            \"expecting buf_pos = 4, found {}, err {:?}\",\n            r.buffer_position(),\n            e\n        ),\n        e => panic!(\"expecting error, found {:?}\", e),\n    }\n}"}
{"code": "pub fn is_close(&self) -> bool {\n        matches!(*self, Message::Close(_))\n    }", "test": "fn test_evil_server_close() {\n    do_test(\n        3013,\n        |mut cli_sock| {\n            cli_sock.send(Message::Text(\"Hello WebSocket\".into())).unwrap();\n\n            sleep(Duration::from_secs(1));\n\n            let message = cli_sock.read().unwrap(); // receive close from server\n            assert!(message.is_close());\n\n            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed\n            match err {\n                Error::ConnectionClosed => {}\n                _ => panic!(\"unexpected error: {:?}\", err),\n            }\n        },\n        |mut srv_sock| {\n            let message = srv_sock.read().unwrap();\n            assert_eq!(message.into_data(), b\"Hello WebSocket\");\n\n            srv_sock.close(None).unwrap(); // send close to client\n\n            let message = srv_sock.read().unwrap(); // receive acknowledgement\n            assert!(message.is_close());\n            // and now just drop the connection without waiting for `ConnectionClosed`\n            srv_sock.get_mut().set_linger(Some(Duration::from_secs(0))).unwrap();\n            drop(srv_sock);\n        },\n    );\n}"}
{"code": "fn get_header(s: &str) -> String {\n        s.lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }", "test": "fn test_block_size_in_posix_portability_mode() {\n    fn get_header(block_size: &str) -> String {\n        let output = new_ucmd!()\n            .args(&[\"-P\", \"-B\", block_size])\n            .succeeds()\n            .stdout_move_str();\n        output\n            .lines()\n            .next()\n            .unwrap()\n            .to_string()\n            .split_whitespace()\n            .nth(1)\n            .unwrap()\n            .trim()\n            .to_string()\n    }\n\n    assert_eq!(get_header(\"1024\"), \"1024-blocks\");\n    assert_eq!(get_header(\"1K\"), \"1024-blocks\");\n    assert_eq!(get_header(\"1KB\"), \"1000-blocks\");\n    assert_eq!(get_header(\"1M\"), \"1048576-blocks\");\n    assert_eq!(get_header(\"1MB\"), \"1000000-blocks\");\n}"}
{"code": "pub fn render(&self, template_name: &str, context: &Context) -> Result<String> {\n        let template = self.get_template(template_name)?;\n        let renderer = Renderer::new(template, self, context);\n        renderer.render()\n    }", "test": "fn can_remove_whitespace_basic() {\n    let mut context = Context::new();\n    context.insert(\"numbers\", &vec![1, 2, 3]);\n\n    let inputs = vec![\n        (\"  {%- for n in numbers %}{{n}}{% endfor -%} \", \"123\"),\n        (\"{%- for n in numbers %} {{n}}{%- endfor -%} \", \" 1 2 3\"),\n        (\"{%- for n in numbers -%}\\n {{n}}\\n {%- endfor -%} \", \"123\"),\n        (\"{%- if true -%}\\n {{numbers}}\\n {%- endif -%} \", \"[1, 2, 3]\"),\n        (\"{%- if false -%}\\n {{numbers}}\\n {% else %} Nope{%- endif -%} \", \" Nope\"),\n        (\"  {%- if false -%}\\n {{numbers}}\\n {% else -%} Nope {%- endif -%} \", \"Nope\"),\n        (\"  {%- if false -%}\\n {{numbers}}\\n {% elif true -%} Nope {%- endif -%} \", \"Nope\"),\n        (\"  {%- if false -%}\\n {{numbers}}\\n {% elif false -%} Nope {% else %} else {%- endif -%} \", \" else\"),\n        (\"  {%- set var = 2 -%} {{var}}\", \"2\"),\n        (\"  {% set var = 2 -%} {{var}}\", \"  2\"),\n        (\" {% raw -%} {{2}} {% endraw -%} \", \" {{2}} \"),\n        (\"  {% filter upper -%} hey {%- endfilter -%} \", \"  HEY\"),\n        (\"  {{ \\\"hello\\\" -}} \", \"  hello\"),\n        (\"  {{- \\\"hello\\\" }} \", \"hello \"),\n        (\"  {{- \\\"hello\\\" -}} \", \"hello\"),\n        // Comments are not rendered so it should be just whitespace if anything\n        (\"  {#- \\\"hello\\\" -#} \", \"\"),\n        (\"  {# \\\"hello\\\" -#} \", \"  \"),\n        (\"  {#- \\\"hello\\\" #} \", \" \"),\n    ];\n\n    for (input, expected) in inputs {\n        let mut tera = Tera::default();\n        tera.add_raw_template(\"tpl\", input).unwrap();\n        println!(\"{} -> {:?}\", input, expected);\n        assert_eq!(tera.render(\"tpl\", &context).unwrap(), expected);\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_move_file_into_dir() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let dir = \"test_mv_move_file_into_dir_dir\";\n    let file = \"test_mv_move_file_into_dir_file\";\n\n    at.mkdir(dir);\n    at.touch(file);\n\n    ucmd.arg(file).arg(dir).succeeds().no_stderr();\n\n    assert!(at.file_exists(format!(\"{dir}/{file}\")));\n}"}
{"code": "fn is_none(&self) -> bool {\n        self.index == !0\n    }", "test": "fn get_invalid() {\n    let mut headers = HeaderMap::new();\n    headers.insert(\"foo\", \"bar\".parse().unwrap());\n    assert!(headers.get(\"Evil\\r\\nKey\").is_none());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date5() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"1970-01-01 18:43:33.023456789\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    // Slightly different result on Windows for nano seconds\n    // TODO: investigate\n    #[cfg(windows)]\n    let expected = FileTime::from_unix_time(67413, 23_456_700);\n    #[cfg(not(windows))]\n    let expected = FileTime::from_unix_time(67413, 23_456_789);\n\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, expected);\n    assert_eq!(mtime, expected);\n}"}
{"code": "pub fn response_code(&self) -> ResponseCode {\n        self.response_code\n    }", "test": "fn test_append() {\n    let catalog = Catalog::new();\n    let (client, origin) = create_sig0_ready_client(catalog);\n\n    // append a record\n    let mut record = Record::with(\n        Name::from_str(\"new.example.com\").unwrap(),\n        RecordType::A,\n        Duration::minutes(5).whole_seconds() as u32,\n    );\n    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));\n\n    // first check the must_exist option\n    let result = client\n        .append(record.clone(), origin.clone(), true)\n        .expect(\"append failed\");\n    assert_eq!(result.response_code(), ResponseCode::NXRRSet);\n\n    // next append to a non-existent RRset\n    let result = client\n        .append(record.clone(), origin.clone(), false)\n        .expect(\"append failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    // verify record contents\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 1);\n    assert_eq!(result.answers()[0], record);\n\n    // will fail if already set and not the same value.\n    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));\n\n    let result = client\n        .append(record.clone(), origin.clone(), true)\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 2);\n\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = *rr.data().unwrap() {\n            ip == A::new(100, 10, 100, 10)\n        } else {\n            false\n        }));\n    assert!(result\n        .answers()\n        .iter()\n        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {\n            *ip == A::new(101, 11, 101, 11)\n        } else {\n            false\n        }));\n\n    // show that appending the same thing again is ok, but doesn't add any records\n    let result = client\n        .append(record.clone(), origin, true)\n        .expect(\"create failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n\n    let result = client\n        .query(record.name(), record.dns_class(), record.record_type())\n        .expect(\"query failed\");\n    assert_eq!(result.response_code(), ResponseCode::NoError);\n    assert_eq!(result.answers().len(), 2);\n}"}
{"code": "fn to_string(lit: Literal) -> String {\n    let formatted = lit.to_string();\n\n    let mut it = formatted.chars();\n    assert_eq!(it.next(), Some('\"'));\n\n    let mut rv = String::new();\n    loop {\n        match it.next() {\n            Some('\"') => match it.next() {\n                Some(_) => panic!(),\n                None => break,\n            },\n            Some('\\\\') => match it.next() {\n                Some('x') => {\n                    let hi = it.next().unwrap().to_digit(16).unwrap();\n                    let lo = it.next().unwrap().to_digit(16).unwrap();\n                    let v = (hi << 16) | lo;\n                    rv.push(v as u8 as char);\n                }\n                Some('u') => {\n                    assert_eq!(it.next(), Some('{'));\n                    let mut c = it.next().unwrap();\n                    let mut ch = 0;\n                    while let Some(v) = c.to_digit(16) {\n                        ch *= 16;\n                        ch |= v;\n                        c = it.next().unwrap();\n                    }\n                    assert_eq!(c, '}');\n                    rv.push(::std::char::from_u32(ch).unwrap());\n                }\n                Some('0') => rv.push('\\0'),\n                Some('\\\\') => rv.push('\\\\'),\n                Some('\\\"') => rv.push('\\\"'),\n                Some('r') => rv.push('\\r'),\n                Some('n') => rv.push('\\n'),\n                Some('t') => rv.push('\\t'),\n                Some(_) => panic!(),\n                None => panic!(),\n            },\n            Some(c) => rv.push(c),\n            None => panic!(),\n        }\n    }\n\n    rv\n}", "test": "fn copy_wrong() {\n    let mut store = Store::<()>::default();\n    let ty = TableType::new(ValType::FuncRef, 1, None);\n    let table1 = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();\n    let ty = TableType::new(ValType::ExternRef, 1, None);\n    let table2 = Table::new(&mut store, ty, Val::ExternRef(None)).unwrap();\n    assert_eq!(\n        Table::copy(&mut store, &table1, 0, &table2, 0, 1)\n            .map_err(|e| e.to_string())\n            .unwrap_err(),\n        \"tables do not have the same element type\"\n    );\n}"}
{"code": "pub fn new_peer(store_id: u64, peer_id: u64) -> Peer {\n    let mut peer = Peer::default();\n    peer.set_store_id(store_id);\n    peer.set_id(peer_id);\n    peer.set_role(PeerRole::Voter);\n    peer\n}", "test": "fn test_pending_peers() {\n    let mut cluster = new_node_cluster(0, 3);\n    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);\n\n    let region_worker_fp = \"region_apply_snap\";\n\n    let pd_client = Arc::clone(&cluster.pd_client);\n    // Disable default max peer count check.\n    pd_client.disable_default_operator();\n\n    let region_id = cluster.run_conf_change();\n    pd_client.must_add_peer(region_id, new_peer(2, 2));\n\n    // To ensure peer 2 is not pending.\n    cluster.must_put(b\"k1\", b\"v1\");\n    must_get_equal(&cluster.get_engine(2), b\"k1\", b\"v1\");\n\n    fail::cfg(region_worker_fp, \"sleep(2000)\").unwrap();\n    pd_client.must_add_peer(region_id, new_peer(3, 3));\n    sleep_ms(1000);\n    let pending_peers = pd_client.get_pending_peers();\n    // Region worker is not started, snapshot should not be applied yet.\n    assert_eq!(pending_peers[&3], new_peer(3, 3));\n    // But it will be applied finally.\n    must_get_equal(&cluster.get_engine(3), b\"k1\", b\"v1\");\n    sleep_ms(100);\n    let pending_peers = pd_client.get_pending_peers();\n    assert!(pending_peers.is_empty());\n}"}
{"code": "fn len(&self) -> usize {\n            self.hash_table.len()\n        }", "test": "async fn async_then_sync_trap() -> Result<()> {\n    // Test the trapping and capturing the stack with the following sequence of\n    // calls:\n    //\n    // a[async] ---> b[host] ---> c[sync]\n\n    drop(env_logger::try_init());\n\n    let wat = r#\"\n        (module\n            (import \"\" \"b\" (func $b))\n            (func $a (export \"a\")\n                call $b\n            )\n            (func $c (export \"c\")\n                unreachable\n            )\n        )\n    \"#;\n\n    let mut sync_store = Store::new(&Engine::default(), ());\n\n    let sync_module = Module::new(sync_store.engine(), wat)?;\n\n    let mut sync_linker = Linker::new(sync_store.engine());\n    sync_linker.func_wrap(\"\", \"b\", |_caller: Caller<_>| unreachable!())?;\n\n    let sync_instance = sync_linker.instantiate(&mut sync_store, &sync_module)?;\n\n    struct AsyncCtx {\n        sync_instance: Instance,\n        sync_store: Store<()>,\n    }\n\n    let mut async_store = Store::new(\n        &Engine::new(Config::new().async_support(true)).unwrap(),\n        AsyncCtx {\n            sync_instance,\n            sync_store,\n        },\n    );\n\n    let async_module = Module::new(async_store.engine(), wat)?;\n\n    let mut async_linker = Linker::new(async_store.engine());\n    async_linker.func_wrap(\"\", \"b\", move |mut caller: Caller<AsyncCtx>| {\n        log::info!(\"Called `b`...\");\n        let sync_instance = caller.data().sync_instance;\n        let sync_store = &mut caller.data_mut().sync_store;\n\n        log::info!(\"Calling `c`...\");\n        let c = sync_instance\n            .get_typed_func::<(), ()>(&mut *sync_store, \"c\")\n            .unwrap();\n        c.call(sync_store, ())?;\n        Ok(())\n    })?;\n\n    let async_instance = async_linker\n        .instantiate_async(&mut async_store, &async_module)\n        .await?;\n\n    log::info!(\"Calling `a`...\");\n    let a = async_instance\n        .get_typed_func::<(), ()>(&mut async_store, \"a\")\n        .unwrap();\n    let trap = a.call_async(&mut async_store, ()).await.unwrap_err();\n\n    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();\n    // We don't support cross-store or cross-engine symbolication currently, so\n    // the other frames are ignored.\n    assert_eq!(trace.len(), 1);\n    assert_eq!(trace[0].func_name(), Some(\"c\"));\n\n    Ok(())\n}"}
{"code": "fn next(&mut self) -> Option<Self::Item> {\n        self.0.next()\n    }", "test": "fn test_chained_cname_lookup_preserve() {\n    let resp_query = Query::query(Name::from_str(\"www.example.com.\").unwrap(), RecordType::A);\n    let cname_record = cname_record(\n        Name::from_str(\"www.example.com.\").unwrap(),\n        Name::from_str(\"v4.example.com.\").unwrap(),\n    );\n    let v4_record = v4_record(\n        Name::from_str(\"v4.example.com.\").unwrap(),\n        Ipv4Addr::new(93, 184, 216, 34),\n    );\n\n    // The first response should be a cname, the second will be the actual record\n    let message1 = message(\n        resp_query.clone(),\n        vec![cname_record.clone()],\n        vec![],\n        vec![],\n    );\n    let message2 = message(resp_query, vec![v4_record], vec![], vec![]);\n\n    // the mock pops messages...\n    let client: MockClientHandle<_, ResolveError> = MockClientHandle::mock(vec![\n        Ok(DnsResponse::from_message(message2).unwrap()),\n        Ok(DnsResponse::from_message(message1).unwrap()),\n    ]);\n\n    let lookup = LookupFuture::lookup(\n        vec![Name::from_str(\"www.example.com.\").unwrap()],\n        RecordType::A,\n        Default::default(),\n        CachingClient::new(0, client, true),\n    );\n\n    let io_loop = Runtime::new().unwrap();\n    let lookup = io_loop.block_on(lookup).unwrap();\n\n    let mut iter = lookup.iter();\n    assert_eq!(iter.next().unwrap(), cname_record.data().unwrap());\n    assert_eq!(*iter.next().unwrap(), RData::A(A::new(93, 184, 216, 34)));\n}"}
{"code": "fn poll(mut self: Pin<&mut Self>, cx: &mut Context) -> Poll<Self::Output> {\n        let mut endpoint = self.0.state.lock().unwrap();\n        if endpoint.driver.is_none() {\n            endpoint.driver = Some(cx.waker().clone());\n        }\n\n        let now = Instant::now();\n        let mut keep_going = false;\n        keep_going |= endpoint.drive_recv(cx, now)?;\n        keep_going |= endpoint.handle_events(cx, &self.0.shared);\n        keep_going |= endpoint.drive_send(cx)?;\n\n        if !endpoint.incoming.is_empty() {\n            self.0.shared.incoming.notify_waiters();\n        }\n\n        if endpoint.ref_count == 0 && endpoint.connections.is_empty() {\n            Poll::Ready(Ok(()))\n        } else {\n            drop(endpoint);\n            // If there is more work to do schedule the endpoint task again.\n            // `wake_by_ref()` is called outside the lock to minimize\n            // lock contention on a multithreaded runtime.\n            if keep_going {\n                cx.waker().wake_by_ref();\n            }\n            Poll::Pending\n        }\n    }", "test": "fn client_alpn_unset() {\n    let _guard = subscribe();\n    let mut server_crypto = server_crypto();\n    server_crypto.alpn_protocols = vec![\"foo\".into(), \"bar\".into(), \"baz\".into()];\n    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));\n    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);\n\n    let client_ch = pair.begin_connect(client_config());\n    pair.drive();\n    assert_matches!(\n        pair.client_conn_mut(client_ch).poll(),\n        Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(err) }) if err.error_code == TransportErrorCode::crypto(0x78)\n    );\n}"}
{"code": "pub fn read_lines(input: &str) -> IResult<&str, Vec<&str>> {\n  many0(read_line)(input)\n}", "test": "fn read_lines_test() {\n  let res = Ok((\"\", vec![\"Duck\", \"Dog\", \"Cow\"]));\n\n  assert_eq!(read_lines(\"Duck\\nDog\\nCow\\n\"), res);\n  assert_eq!(read_lines(\"Duck\\nDog\\nCow\"), res);\n}"}
{"code": "pub fn on_cluster(mut self, on_cluster: Option<String>) -> Self {\n        self.on_cluster = on_cluster;\n        self\n    }", "test": "fn parse_create_table_on_cluster() {\n    // Using single-quote literal to define current cluster\n    let sql = \"CREATE TABLE t ON CLUSTER '{cluster}' (a INT, b INT)\";\n    match verified_stmt(sql) {\n        Statement::CreateTable { on_cluster, .. } => {\n            assert_eq!(on_cluster.unwrap(), \"{cluster}\".to_string());\n        }\n        _ => unreachable!(),\n    }\n\n    // Using explicitly declared cluster name\n    let sql = \"CREATE TABLE t ON CLUSTER my_cluster (a INT, b INT)\";\n    match verified_stmt(sql) {\n        Statement::CreateTable { on_cluster, .. } => {\n            assert_eq!(on_cluster.unwrap(), \"my_cluster\".to_string());\n        }\n        _ => unreachable!(),\n    }\n}"}
{"code": "pub fn s2d(buffer: &[u8]) -> Result<f64, Error> {\n    let len = buffer.len();\n    if len == 0 {\n        return Err(Error::InputTooShort);\n    }\n\n    let mut m10digits = 0;\n    let mut e10digits = 0;\n    let mut dot_index = len;\n    let mut e_index = len;\n    let mut m10 = 0u64;\n    let mut e10 = 0i32;\n    let mut signed_m = false;\n    let mut signed_e = false;\n\n    let mut i = 0;\n    if unsafe { *buffer.get_unchecked(0) } == b'-' {\n        signed_m = true;\n        i += 1;\n    }\n\n    while let Some(c) = buffer.get(i).copied() {\n        if c == b'.' {\n            if dot_index != len {\n                return Err(Error::MalformedInput);\n            }\n            dot_index = i;\n            i += 1;\n            continue;\n        }\n        if c < b'0' || c > b'9' {\n            break;\n        }\n        if m10digits >= 17 {\n            return Err(Error::InputTooLong);\n        }\n        m10 = 10 * m10 + (c - b'0') as u64;\n        if m10 != 0 {\n            m10digits += 1;\n        }\n        i += 1;\n    }\n\n    if let Some(b'e') | Some(b'E') = buffer.get(i) {\n        e_index = i;\n        i += 1;\n        match buffer.get(i) {\n            Some(b'-') => {\n                signed_e = true;\n                i += 1;\n            }\n            Some(b'+') => i += 1,\n            _ => {}\n        }\n        while let Some(c) = buffer.get(i).copied() {\n            if c < b'0' || c > b'9' {\n                return Err(Error::MalformedInput);\n            }\n            if e10digits > 3 {\n                // TODO: Be more lenient. Return +/-Infinity or +/-0 instead.\n                return Err(Error::InputTooLong);\n            }\n            e10 = 10 * e10 + (c - b'0') as i32;\n            if e10 != 0 {\n                e10digits += 1;\n            }\n            i += 1;\n        }\n    }\n\n    if i < len {\n        return Err(Error::MalformedInput);\n    }\n    if signed_e {\n        e10 = -e10;\n    }\n    e10 -= if dot_index < e_index {\n        (e_index - dot_index - 1) as i32\n    } else {\n        0\n    };\n    if m10 == 0 {\n        return Ok(if signed_m { -0.0 } else { 0.0 });\n    }\n\n    if m10digits + e10 <= -324 || m10 == 0 {\n        // Number is less than 1e-324, which should be rounded down to 0; return\n        // +/-0.0.\n        let ieee = (signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n    if m10digits + e10 >= 310 {\n        // Number is larger than 1e+309, which should be rounded to +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // Convert to binary float m2 * 2^e2, while retaining information about\n    // whether the conversion was exact (trailing_zeros).\n    let e2: i32;\n    let m2: u64;\n    let mut trailing_zeros: bool;\n    if e10 >= 0 {\n        // The length of m * 10^e in bits is:\n        //   log2(m10 * 10^e10) = log2(m10) + e10 log2(10) = log2(m10) + e10 + e10 * log2(5)\n        //\n        // We want to compute the DOUBLE_MANTISSA_BITS + 1 top-most bits (+1 for\n        // the implicit leading one in IEEE format). We therefore choose a\n        // binary output exponent of\n        //   log2(m10 * 10^e10) - (DOUBLE_MANTISSA_BITS + 1).\n        //\n        // We use floor(log2(5^e10)) so that we get at least this many bits;\n        // better to have an additional bit than to not have enough bits.\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_add(log2_pow5(e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n\n        // We now compute [m10 * 10^e10 / 2^e2] = [m10 * 5^e10 / 2^(e2-e10)].\n        // To that end, we use the DOUBLE_POW5_SPLIT table.\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_sub(ceil_log2_pow5(e10))\n            .wrapping_add(d2s::DOUBLE_POW5_BITCOUNT);\n        debug_assert!(j >= 0);\n        debug_assert!(e10 < d2s::DOUBLE_POW5_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_SPLIT.get_unchecked(e10 as usize) },\n            j as u32,\n        );\n\n        // We also compute if the result is exact, i.e.,\n        //   [m10 * 10^e10 / 2^e2] == m10 * 10^e10 / 2^e2.\n        // This can only be the case if 2^e2 divides m10 * 10^e10, which in turn\n        // requires that the largest power of 2 that divides m10 + e10 is\n        // greater than e2. If e2 is less than e10, then the result must be\n        // exact. Otherwise we use the existing multiple_of_power_of_2 function.\n        trailing_zeros =\n            e2 < e10 || e2 - e10 < 64 && multiple_of_power_of_2(m10, (e2 - e10) as u32);\n    } else {\n        e2 = floor_log2(m10)\n            .wrapping_add(e10 as u32)\n            .wrapping_sub(ceil_log2_pow5(-e10) as u32)\n            .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS + 1) as i32;\n        let j = e2\n            .wrapping_sub(e10)\n            .wrapping_add(ceil_log2_pow5(-e10))\n            .wrapping_sub(1)\n            .wrapping_add(d2s::DOUBLE_POW5_INV_BITCOUNT);\n        debug_assert!(-e10 < d2s::DOUBLE_POW5_INV_SPLIT.len() as i32);\n        m2 = mul_shift_64(\n            m10,\n            unsafe { d2s::DOUBLE_POW5_INV_SPLIT.get_unchecked(-e10 as usize) },\n            j as u32,\n        );\n        trailing_zeros = multiple_of_power_of_5(m10, -e10 as u32);\n    }\n\n    // Compute the final IEEE exponent.\n    let mut ieee_e2 = i32::max(0, e2 + DOUBLE_EXPONENT_BIAS as i32 + floor_log2(m2) as i32) as u32;\n\n    if ieee_e2 > 0x7fe {\n        // Final IEEE exponent is larger than the maximum representable; return +/-Infinity.\n        let ieee = ((signed_m as u64) << (d2s::DOUBLE_EXPONENT_BITS + d2s::DOUBLE_MANTISSA_BITS))\n            | (0x7ff_u64 << d2s::DOUBLE_MANTISSA_BITS);\n        return Ok(f64::from_bits(ieee));\n    }\n\n    // We need to figure out how much we need to shift m2. The tricky part is\n    // that we need to take the final IEEE exponent into account, so we need to\n    // reverse the bias and also special-case the value 0.\n    let shift = if ieee_e2 == 0 { 1 } else { ieee_e2 as i32 }\n        .wrapping_sub(e2)\n        .wrapping_sub(DOUBLE_EXPONENT_BIAS as i32)\n        .wrapping_sub(d2s::DOUBLE_MANTISSA_BITS as i32);\n    debug_assert!(shift >= 0);\n\n    // We need to round up if the exact value is more than 0.5 above the value\n    // we computed. That's equivalent to checking if the last removed bit was 1\n    // and either the value was not just trailing zeros or the result would\n    // otherwise be odd.\n    //\n    // We need to update trailing_zeros given that we have the exact output\n    // exponent ieee_e2 now.\n    trailing_zeros &= (m2 & ((1_u64 << (shift - 1)) - 1)) == 0;\n    let last_removed_bit = (m2 >> (shift - 1)) & 1;\n    let round_up = last_removed_bit != 0 && (!trailing_zeros || ((m2 >> shift) & 1) != 0);\n\n    let mut ieee_m2 = (m2 >> shift).wrapping_add(round_up as u64);\n    debug_assert!(ieee_m2 <= 1_u64 << (d2s::DOUBLE_MANTISSA_BITS + 1));\n    ieee_m2 &= (1_u64 << d2s::DOUBLE_MANTISSA_BITS) - 1;\n    if ieee_m2 == 0 && round_up {\n        // Due to how the IEEE represents +/-Infinity, we don't need to check\n        // for overflow here.\n        ieee_e2 += 1;\n    }\n    let ieee = ((((signed_m as u64) << d2s::DOUBLE_EXPONENT_BITS) | ieee_e2 as u64)\n        << d2s::DOUBLE_MANTISSA_BITS)\n        | ieee_m2;\n    Ok(f64::from_bits(ieee))\n}", "test": "fn test_basic() {\n    assert_eq!(0.0, s2d(b\"0\").unwrap());\n    assert_eq!(-0.0, s2d(b\"-0\").unwrap());\n    assert_eq!(1.0, s2d(b\"1\").unwrap());\n    assert_eq!(2.0, s2d(b\"2\").unwrap());\n    assert_eq!(123456789.0, s2d(b\"123456789\").unwrap());\n    assert_eq!(123.456, s2d(b\"123.456\").unwrap());\n    assert_eq!(123.456, s2d(b\"123456e-3\").unwrap());\n    assert_eq!(123.456, s2d(b\"1234.56e-1\").unwrap());\n    assert_eq!(1.453, s2d(b\"1.453\").unwrap());\n    assert_eq!(1453.0, s2d(b\"1.453e+3\").unwrap());\n    assert_eq!(0.0, s2d(b\".0\").unwrap());\n    assert_eq!(1.0, s2d(b\"1e0\").unwrap());\n    assert_eq!(1.0, s2d(b\"1E0\").unwrap());\n    assert_eq!(1.0, s2d(b\"000001.000000\").unwrap());\n    assert_eq!(0.2316419, s2d(b\"0.2316419\").unwrap());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn max_diagnostics() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    for i in 0..60 {\n        let file_path = PathBuf::from(format!(\"src/file_{i}.js\"));\n        fs.insert(file_path, UNFORMATTED.as_bytes());\n    }\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from([(\"ci\"), (\"--max-diagnostics\"), (\"10\"), (\"src\")].as_slice()),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    let mut diagnostic_count = 0;\n    let mut filtered_messages = Vec::new();\n\n    for msg in console.out_buffer {\n        let MarkupBuf(nodes) = &msg.content;\n        let is_diagnostic = nodes.iter().any(|node| {\n            node.content\n                .contains(\"File content differs from formatting output\")\n                || node.content.contains(\"format\")\n                || node.content.contains(\"ci\")\n        });\n\n        if is_diagnostic {\n            diagnostic_count += 1;\n        } else {\n            filtered_messages.push(msg);\n        }\n    }\n\n    console.out_buffer = filtered_messages;\n\n    for i in 0..60 {\n        let file_path = format!(\"src/file_{i}.js\");\n        fs.remove(Path::new(&file_path));\n    }\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"max_diagnostics\",\n        fs,\n        console,\n        result,\n    ));\n\n    assert_eq!(diagnostic_count, 10);\n}"}
{"code": "fn is_empty(&self) -> bool {\n        self.pending_writes.is_empty() && self.unpacked_size == 0\n    }", "test": "fn test_analyze_index_with_lock() {\n    let data = vec![\n        (1, Some(\"name:0\"), 2),\n        (2, Some(\"name:4\"), 3),\n        (4, Some(\"name:3\"), 1),\n        (5, Some(\"name:1\"), 4),\n    ];\n\n    let product = ProductTable::new();\n    for &iso_level in &[IsolationLevel::Si, IsolationLevel::Rc] {\n        let (_, endpoint, _) = init_data_with_commit(&product, &data, false);\n\n        let mut req = new_analyze_index_req(&product, 3, product[\"name\"].index, 4, 32, 0, 1);\n        let mut ctx = Context::default();\n        ctx.set_isolation_level(iso_level);\n        req.set_context(ctx);\n\n        let resp = handle_request(&endpoint, req);\n        match iso_level {\n            IsolationLevel::Si => {\n                assert!(resp.get_data().is_empty(), \"{:?}\", resp);\n                assert!(resp.has_locked(), \"{:?}\", resp);\n            }\n            IsolationLevel::Rc => {\n                let mut analyze_resp = AnalyzeIndexResp::default();\n                analyze_resp.merge_from_bytes(resp.get_data()).unwrap();\n                let hist = analyze_resp.get_hist();\n                assert!(hist.get_buckets().is_empty());\n                assert_eq!(hist.get_ndv(), 0);\n            }\n            IsolationLevel::RcCheckTs => unimplemented!(),\n        }\n    }\n}"}
{"code": "pub fn buffer_position(&self) -> usize {\n        // when internal state is OpenedTag, we have actually read until '<',\n        // which we don't want to show\n        if let ParseState::OpenedTag = self.state.state {\n            self.state.offset - 1\n        } else {\n            self.state.offset\n        }\n    }", "test": "fn test_offset_err_comment_trim_text() {\n    let mut r = Reader::from_str(\"<a>\\r\\n <!--b>\");\n    r.trim_text(true);\n\n    next_eq!(r, Start, b\"a\");\n    assert_eq!(r.buffer_position(), 3);\n\n    match r.read_event() {\n        // error at char 7: no closing --> tag found\n        Err(e) => assert_eq!(\n            r.buffer_position(),\n            7,\n            \"expecting buf_pos = 7, found {}, err {:?}\",\n            r.buffer_position(),\n            e\n        ),\n        e => panic!(\"expecting error, found {:?}\", e),\n    }\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_prompt_write_protected_yes() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n    let file_1 = \"test_rm_prompt_write_protected_1\";\n\n    at.touch(file_1);\n\n    scene.ccmd(\"chmod\").arg(\"0\").arg(file_1).succeeds();\n\n    scene.ucmd().arg(file_1).pipe_in(\"y\").succeeds();\n    assert!(!at.file_exists(file_1));\n}"}
{"code": "pub(crate) fn from_u32(x: &[u32]) -> Vec<Limb> {\n    x.iter().cloned().collect()\n}", "test": "fn iadd_small_test() {\n    // Overflow check (single)\n    // This should set all the internal data values to 0, the top\n    // value to (1<<31), and the bottom value to (4>>1).\n    // This is because the max_value + 1 leads to all 0s, we set the\n    // topmost bit to 1.\n    let mut x = Bigint {\n        data: from_u32(&[4294967295]),\n    };\n    x.iadd_small(5);\n    assert_eq!(x.data, from_u32(&[4, 1]));\n\n    // No overflow, single value\n    let mut x = Bigint {\n        data: from_u32(&[5]),\n    };\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[12]));\n\n    // Single carry, internal overflow\n    let mut x = Bigint::from_u64(0x80000000FFFFFFFF);\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[6, 0x80000001]));\n\n    // Double carry, overflow\n    let mut x = Bigint::from_u64(0xFFFFFFFFFFFFFFFF);\n    x.iadd_small(7);\n    assert_eq!(x.data, from_u32(&[6, 0, 1]));\n}"}
{"code": "pub fn dir_exists(&self, path: &str) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_dir(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_ancestors_mode_directories_with_file() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let ancestor1 = \"ancestor1\";\n    let ancestor2 = \"ancestor1/ancestor2\";\n    let target_file = \"ancestor1/ancestor2/target_file\";\n    let directories_arg = \"-D\";\n    let mode_arg = \"--mode=200\";\n    let file = \"file\";\n    let probe = \"probe\";\n\n    at.mkdir(probe);\n    let default_perms = at.metadata(probe).permissions().mode();\n\n    at.touch(file);\n\n    ucmd.args(&[mode_arg, directories_arg, file, target_file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.dir_exists(ancestor1));\n    assert!(at.dir_exists(ancestor2));\n    assert!(at.file_exists(target_file));\n\n    assert_eq!(default_perms, at.metadata(ancestor1).permissions().mode());\n    assert_eq!(default_perms, at.metadata(ancestor2).permissions().mode());\n\n    // Expected mode only on the target_file.\n    assert_eq!(0o100_200_u32, at.metadata(target_file).permissions().mode());\n}"}
{"code": "fn is_cluster_bootstrapped(&self) -> Result<bool> {\n        let _timer = PD_REQUEST_HISTOGRAM_VEC\n            .is_cluster_bootstrapped\n            .start_coarse_timer();\n\n        let mut req = pdpb::IsBootstrappedRequest::default();\n        req.set_header(self.header());\n\n        let resp = sync_request(&self.pd_client, LEADER_CHANGE_RETRY, |client, option| {\n            client.is_bootstrapped_opt(&req, option)\n        })?;\n        check_resp_header(resp.get_header())?;\n\n        Ok(resp.get_bootstrapped())\n    }", "test": "fn test_reboot() {\n    let eps_count = 1;\n    let server = MockServer::with_case(eps_count, Arc::new(AlreadyBootstrapped));\n    let eps = server.bind_addrs();\n    let client = new_client(eps, None);\n\n    assert!(!client.is_cluster_bootstrapped().unwrap());\n\n    match client.bootstrap_cluster(metapb::Store::default(), metapb::Region::default()) {\n        Err(PdError::ClusterBootstrapped(_)) => (),\n        _ => {\n            panic!(\"failed, should return ClusterBootstrapped\");\n        }\n    }\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        self.0.is_reserved_value()\n    }", "test": "fn get_none() {\n    let mut store = Store::<()>::default();\n    let ty = TableType::new(ValType::FuncRef, 1, None);\n    let table = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();\n    match table.get(&mut store, 0) {\n        Some(Val::FuncRef(None)) => {}\n        _ => panic!(),\n    }\n    assert!(table.get(&mut store, 1).is_none());\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_install_backup_numbered_if_existing_backup_existing() {\n    let scene = TestScenario::new(util_name!());\n    let at = &scene.fixtures;\n\n    let file_a = \"test_install_backup_numbering_file_a\";\n    let file_b = \"test_install_backup_numbering_file_b\";\n    let file_b_backup = \"test_install_backup_numbering_file_b.~1~\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    at.touch(file_b_backup);\n    scene\n        .ucmd()\n        .arg(\"--backup=existing\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(file_b_backup));\n    assert!(at.file_exists(format!(\"{file_b}.~2~\")));\n}"}
{"code": "fn is_nan(self) -> bool {\n        self.is_special() && (self.to_bits() & Self::MANTISSA_MASK) != Self::Unsigned::ZERO\n    }", "test": "fn sqrtd_spec_test() {\n    // Not Asserted: FE_INVALID exception is raised if argument is negative.\n    assert!(libm::sqrtd(-1.0).is_nan());\n    assert!(libm::sqrtd(f64::NAN).is_nan());\n    for f in [0.0, -0.0, f64::INFINITY].iter().copied() {\n        assert_eq!(libm::sqrtd(f), f);\n    }\n}"}
{"code": "pub fn remove_whitespace(nodes: Vec<Node>, body_ws: Option<WS>) -> Vec<Node> {\n    let mut res = Vec::with_capacity(nodes.len());\n\n    // Whether the node we just added to res is a Text node\n    let mut previous_was_text = false;\n    // Whether the previous block ended wth `-%}` and we need to trim left the next text node\n    let mut trim_left_next = body_ws.map_or(false, |ws| ws.left);\n\n    for n in nodes {\n        match n {\n            Node::Text(s) => {\n                previous_was_text = true;\n\n                if !trim_left_next {\n                    res.push(Node::Text(s));\n                    continue;\n                }\n                trim_left_next = false;\n\n                let new_val = s.trim_start();\n                if !new_val.is_empty() {\n                    res.push(Node::Text(new_val.to_string()));\n                }\n                // empty text nodes will be skipped\n                continue;\n            }\n            Node::VariableBlock(ws, _)\n            | Node::ImportMacro(ws, _, _)\n            | Node::Extends(ws, _)\n            | Node::Include(ws, _, _)\n            | Node::Set(ws, _)\n            | Node::Break(ws)\n            | Node::Comment(ws, _)\n            | Node::Continue(ws) => {\n                trim_right_previous!(previous_was_text && ws.left, res);\n                trim_left_next = ws.right;\n            }\n            Node::Raw(start_ws, ref s, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                if start_ws.right || end_ws.left {\n                    let val = if start_ws.right && end_ws.left {\n                        s.trim()\n                    } else if start_ws.right {\n                        s.trim_start()\n                    } else {\n                        s.trim_end()\n                    };\n\n                    res.push(Node::Raw(start_ws, val.to_string(), end_ws));\n                    continue;\n                }\n            }\n            // Those nodes have a body surrounded by 2 tags\n            Node::Forloop(start_ws, _, end_ws)\n            | Node::MacroDefinition(start_ws, _, end_ws)\n            | Node::FilterSection(start_ws, _, end_ws)\n            | Node::Block(start_ws, _, end_ws) => {\n                trim_right_previous!(previous_was_text && start_ws.left, res);\n                previous_was_text = false;\n                trim_left_next = end_ws.right;\n\n                // let's remove ws from the bodies now and append the cleaned up node\n                let body_ws = WS { left: start_ws.right, right: end_ws.left };\n                match n {\n                    Node::Forloop(_, mut forloop, _) => {\n                        forloop.body = remove_whitespace(forloop.body, Some(body_ws));\n                        res.push(Node::Forloop(start_ws, forloop, end_ws));\n                    }\n                    Node::MacroDefinition(_, mut macro_def, _) => {\n                        macro_def.body = remove_whitespace(macro_def.body, Some(body_ws));\n                        res.push(Node::MacroDefinition(start_ws, macro_def, end_ws));\n                    }\n                    Node::FilterSection(_, mut filter_section, _) => {\n                        filter_section.body = remove_whitespace(filter_section.body, Some(body_ws));\n                        res.push(Node::FilterSection(start_ws, filter_section, end_ws));\n                    }\n                    Node::Block(_, mut block, _) => {\n                        block.body = remove_whitespace(block.body, Some(body_ws));\n                        res.push(Node::Block(start_ws, block, end_ws));\n                    }\n                    _ => unreachable!(),\n                };\n                continue;\n            }\n            // The ugly one\n            Node::If(If { conditions, otherwise }, end_ws) => {\n                trim_left_next = end_ws.right;\n                let mut new_conditions: Vec<(_, _, Vec<_>)> = Vec::with_capacity(conditions.len());\n\n                for mut condition in conditions {\n                    if condition.0.left {\n                        // We need to trim the text node before the if tag\n                        if new_conditions.is_empty() && previous_was_text {\n                            trim_right_previous!(res);\n                        } else if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n\n                    // we can't peek at the next one to know whether we need to trim right since\n                    // are consuming conditions. We'll find out at the next iteration.\n                    condition.2 = remove_whitespace(\n                        condition.2,\n                        Some(WS { left: condition.0.right, right: false }),\n                    );\n                    new_conditions.push(condition);\n                }\n\n                previous_was_text = false;\n\n                // We now need to look for the last potential `{%-` bit for if/elif\n\n                // That can be a `{%- else`\n                if let Some((else_ws, body)) = otherwise {\n                    if else_ws.left {\n                        if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                            trim_right_previous!(body);\n                        }\n                    }\n                    let mut else_body =\n                        remove_whitespace(body, Some(WS { left: else_ws.right, right: false }));\n                    // if we have an `else`, the `endif` will affect the else node so we need to check\n                    if end_ws.left {\n                        trim_right_previous!(else_body);\n                    }\n                    res.push(Node::If(\n                        If { conditions: new_conditions, otherwise: Some((else_ws, else_body)) },\n                        end_ws,\n                    ));\n                    continue;\n                }\n\n                // Or `{%- endif`\n                if end_ws.left {\n                    if let Some(&mut (_, _, ref mut body)) = new_conditions.last_mut() {\n                        trim_right_previous!(true, body);\n                    }\n                }\n\n                res.push(Node::If(If { conditions: new_conditions, otherwise }, end_ws));\n                continue;\n            }\n            Node::Super => (),\n        };\n\n        // If we are there, that means it's not a text node and we didn't have to modify the node\n        previous_was_text = false;\n        res.push(n);\n    }\n\n    if let Some(whitespace) = body_ws {\n        trim_right_previous!(whitespace.right, res);\n    }\n\n    res\n}", "test": "fn remove_previous_ws_if_single_opening_tag_requires_it() {\n    let ws = WS { left: true, right: false };\n    let ast = vec![\n        Node::Text(\"hey \".to_string()),\n        Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n    ];\n\n    assert_eq!(\n        remove_whitespace(ast, None),\n        vec![\n            Node::Text(\"hey\".to_string()), // it removed the trailing space\n            Node::ImportMacro(ws, \"hey \".to_string(), \"ho\".to_string()),\n        ]\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_touch_set_date4() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file = \"test_touch_set_date\";\n\n    ucmd.args(&[\"-d\", \"1970-01-01 18:43:33\", file])\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(file));\n\n    let expected = FileTime::from_unix_time(67413, 0);\n    let (atime, mtime) = get_file_times(&at, file);\n    assert_eq!(atime, mtime);\n    assert_eq!(atime, expected);\n    assert_eq!(mtime, expected);\n}"}
{"code": "pub fn as_slice(self) -> &'static [u8] {\n        match self {\n            MetadataMethod::Plaintext => METADATA_METHOD_PLAINTEXT,\n            MetadataMethod::Aes256Gcm => METADATA_METHOD_AES256_GCM,\n        }\n    }", "test": "fn test_get() {\n    let tag = \"tag_get\";\n\n    let (test_suite, mut store, _) = setup_test_suite();\n    fail::cfg_callback(\"point_getter_get\", || cpu_load(Duration::from_millis(100))).unwrap();\n    defer!(fail::remove(\"point_getter_get\"));\n\n    let jh = test_suite\n        .rt\n        .spawn(require_cpu_time_not_zero(&test_suite, tag));\n\n    let table = ProductTable::new();\n    let insert = prepare_insert(&mut store, &table);\n    insert.execute();\n    store.commit();\n\n    let storage = store.get_storage();\n    for (k, v) in store.export() {\n        let mut ctx = Context::default();\n        ctx.set_resource_group_tag(tag.as_bytes().to_vec());\n        assert_eq!(\n            storage\n                .get(ctx, &Key::from_raw(&k), TimeStamp::max())\n                .unwrap()\n                .0\n                .unwrap()\n                .as_slice(),\n            v.as_slice()\n        );\n    }\n\n    assert!(block_on(jh).unwrap());\n}"}
{"code": "pub fn is_err(&self) -> bool {\n        if let Self::WithOptions(rule) = self {\n            rule.level == RulePlainConfiguration::Error\n        } else {\n            matches!(self, Self::Plain(RulePlainConfiguration::Error))\n        }\n    }", "test": "fn files_max_size_parse_error() {\n    let mut fs = MemoryFileSystem::default();\n    let mut console = BufferConsole::default();\n\n    let file_path = Path::new(\"format.js\");\n    fs.insert(file_path.into(), \"statement1();\\nstatement2();\");\n\n    let result = run_cli(\n        DynRef::Borrowed(&mut fs),\n        &mut console,\n        Args::from(\n            [\n                (\"format\"),\n                (\"--files-max-size=-1\"),\n                file_path.as_os_str().to_str().unwrap(),\n            ]\n            .as_slice(),\n        ),\n    );\n\n    assert!(result.is_err(), \"run_cli returned {result:?}\");\n\n    assert_cli_snapshot(SnapshotPayload::new(\n        module_path!(),\n        \"files_max_size_parse_error\",\n        fs,\n        console,\n        result,\n    ));\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_rm_interactive_once_prompt() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file1 = \"test_rm_interactive_once_recursive_prompt_file1\";\n    let file2 = \"test_rm_interactive_once_recursive_prompt_file2\";\n    let file3 = \"test_rm_interactive_once_recursive_prompt_file3\";\n    let file4 = \"test_rm_interactive_once_recursive_prompt_file4\";\n\n    at.touch(file1);\n    at.touch(file2);\n    at.touch(file3);\n    at.touch(file4);\n\n    ucmd.arg(\"--interactive=once\")\n        .arg(file1)\n        .arg(file2)\n        .arg(file3)\n        .arg(file4)\n        .pipe_in(\"y\")\n        .succeeds()\n        .stderr_contains(\"remove 4 arguments?\");\n\n    assert!(!at.file_exists(file1));\n    assert!(!at.file_exists(file2));\n    assert!(!at.file_exists(file3));\n    assert!(!at.file_exists(file4));\n}"}
{"code": "pub fn is_none(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_none(),\n            }\n        }\n    }", "test": "fn save_point_rollback_one() {\n    let db = default_engine();\n    let mut wb = db.engine.write_batch();\n\n    wb.set_save_point();\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n\n    let db = multi_batch_write_engine();\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.set_save_point();\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        wb.put(&x, &x).unwrap();\n    }\n    wb.put(b\"a\", b\"\").unwrap();\n\n    wb.rollback_to_save_point().unwrap();\n\n    let err = wb.rollback_to_save_point();\n    assert_engine_error(err);\n    let err = wb.pop_save_point();\n    assert_engine_error(err);\n    wb.write().unwrap();\n    for i in 0..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());\n    }\n    let val = db.engine.get_value(b\"a\").unwrap();\n    assert!(val.is_none());\n}"}
{"code": "fn normalize_html(s: &str) -> String {\n    let parser = make_html_parser();\n    let dom = parser.one(s);\n    let body: SerializableHandle = normalize_dom(&dom).into();\n    let opts = SerializeOpts::default();\n    let mut ret_val = Vec::new();\n    serialize(&mut ret_val, &body, opts)\n        .expect(\"Writing to a string shouldn't fail (expect on OOM)\");\n    String::from_utf8(ret_val).expect(\"html5ever should always produce UTF8\")\n}", "test": "fn leaves_nonempty_tbody() {\n    let input = \"<table><thead><tr><td>hi</td></tr></thead><tbody><tr></tr></tbody></table>\";\n    assert_eq!(input, normalize_html(input))\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_arg_suffix_hyphen_value() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(\"-b\")\n        .arg(\"--suffix\")\n        .arg(\"-v\")\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}-v\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "fn file_read(at: &AtPath, filename: &str) -> String {\n    let mut s = String::new();\n    at.open(filename).read_to_string(&mut s).unwrap();\n    s\n}", "test": "fn test_round_robin() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    let file_read = |f| {\n        let mut s = String::new();\n        at.open(f).read_to_string(&mut s).unwrap();\n        s\n    };\n\n    ucmd.args(&[\"-n\", \"r/2\", \"fivelines.txt\"]).succeeds();\n\n    assert_eq!(file_read(\"xaa\"), \"1\\n3\\n5\\n\");\n    assert_eq!(file_read(\"xab\"), \"2\\n4\\n\");\n}"}
{"code": "pub fn recv_timeout<S, I>(s: &mut S, dur: std::time::Duration) -> Result<Option<I>, ()>\nwhere\n    S: Stream<Item = I> + Unpin,\n{\n    poll_timeout(&mut s.next(), dur)\n}", "test": "fn test_priority() {\n    let (control_tx, control_fsm) = Runner::new(10);\n    let (router, mut system) =\n        batch_system::create_system(&Config::default(), control_tx, control_fsm, None);\n    let builder = Builder::new();\n    system.spawn(\"test\".to_owned(), builder);\n    let (tx, rx) = mpsc::unbounded();\n    let tx_ = tx.clone();\n    let r = router.clone();\n    let state_cnt = Arc::new(AtomicUsize::new(0));\n    router\n        .send_control(Message::Callback(Box::new(\n            move |_: &Handler, _: &mut Runner| {\n                let (tx, runner) = Runner::new(10);\n                r.register(1, BasicMailbox::new(tx, runner, state_cnt.clone()));\n                let (tx2, mut runner2) = Runner::new(10);\n                runner2.set_priority(Priority::Low);\n                r.register(2, BasicMailbox::new(tx2, runner2, state_cnt));\n                tx_.send(1).unwrap();\n            },\n        )))\n        .unwrap();\n    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(1));\n\n    let tx_ = tx.clone();\n    router\n        .send(\n            1,\n            Message::Callback(Box::new(move |h: &Handler, r: &mut Runner| {\n                assert_eq!(h.get_priority(), Priority::Normal);\n                assert_eq!(h.get_priority(), r.get_priority());\n                tx_.send(2).unwrap();\n            })),\n        )\n        .unwrap();\n    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(2));\n\n    router\n        .send(\n            2,\n            Message::Callback(Box::new(move |h: &Handler, r: &mut Runner| {\n                assert_eq!(h.get_priority(), Priority::Low);\n                assert_eq!(h.get_priority(), r.get_priority());\n                tx.send(3).unwrap();\n            })),\n        )\n        .unwrap();\n    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(3));\n}"}
{"code": "pub fn len(&self) -> usize {\n        self.events.len()\n    }", "test": "fn test_unsafe_recovery_during_merge() {\n    let mut cluster = new_node_cluster(0, 3);\n    configure_for_merge(&mut cluster.cfg);\n\n    cluster.run();\n\n    cluster.must_put(b\"k1\", b\"v1\");\n    cluster.must_put(b\"k3\", b\"v3\");\n    let pd_client = Arc::clone(&cluster.pd_client);\n    pd_client.disable_default_operator();\n    let region = pd_client.get_region(b\"k1\").unwrap();\n    cluster.must_split(&region, b\"k2\");\n\n    let left = pd_client.get_region(b\"k1\").unwrap();\n    let right = pd_client.get_region(b\"k3\").unwrap();\n\n    let left_on_store1 = find_peer(&left, 1).unwrap();\n    cluster.must_transfer_leader(left.get_id(), left_on_store1.clone());\n    let right_on_store1 = find_peer(&right, 1).unwrap();\n    cluster.must_transfer_leader(right.get_id(), right_on_store1.clone());\n\n    // Blocks the replication of prepare merge message, so that the commit merge\n    // back fills it in CatchUpLogs.\n    let append_filter = Box::new(\n        RegionPacketFilter::new(left.get_id(), 2)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppend),\n    );\n    // Blocks the target region from receiving MsgAppendResponse, so that the commit\n    // merge message will only be replicated but not committed.\n    let commit_filter = Box::new(\n        RegionPacketFilter::new(right.get_id(), 1)\n            .direction(Direction::Recv)\n            .msg_type(MessageType::MsgAppendResponse),\n    );\n    cluster.sim.wl().add_recv_filter(1, append_filter);\n    cluster.sim.wl().add_recv_filter(1, commit_filter);\n\n    pd_client.merge_region(left.get_id(), right.get_id());\n    // Wait until the commit merge is proposed.\n    sleep_ms(300);\n\n    cluster.stop_node(1);\n    cluster.stop_node(3);\n    confirm_quorum_is_lost(&mut cluster, &region);\n\n    let report = cluster.must_enter_force_leader(right.get_id(), 2, vec![1, 3]);\n    assert_eq!(report.get_peer_reports().len(), 1);\n    let peer_report = &report.get_peer_reports()[0];\n    assert_eq!(peer_report.get_has_commit_merge(), false);\n    let region = peer_report.get_region_state().get_region();\n    assert_eq!(region.get_id(), right.get_id());\n    assert_eq!(region.get_start_key().len(), 0);\n    assert_eq!(region.get_end_key().len(), 0);\n\n    let to_be_removed: Vec<metapb::Peer> = right\n        .get_peers()\n        .iter()\n        .filter(|&peer| peer.get_store_id() != 2)\n        .cloned()\n        .collect();\n    let mut plan = pdpb::RecoveryPlan::default();\n    let mut demote = pdpb::DemoteFailedVoters::default();\n    demote.set_region_id(right.get_id());\n    demote.set_failed_voters(to_be_removed.into());\n    plan.mut_demotes().push(demote);\n    pd_client.must_set_unsafe_recovery_plan(2, plan);\n    cluster.must_send_store_heartbeat(2);\n\n    let mut demoted = true;\n    for _ in 0..10 {\n        let region = block_on(pd_client.get_region_by_id(right.get_id()))\n            .unwrap()\n            .unwrap();\n\n        demoted = true;\n        for peer in region.get_peers() {\n            if peer.get_id() != 2 && peer.get_role() == metapb::PeerRole::Voter {\n                demoted = false;\n            }\n        }\n        if demoted {\n            break;\n        }\n        sleep_ms(200);\n    }\n    assert!(demoted);\n}"}
{"code": "pub fn is_symlink(&self, path: &str) -> bool {\n        log_info(\"is_symlink\", self.plus_as_string(path));\n        match fs::symlink_metadata(self.plus(path)) {\n            Ok(m) => m.file_type().is_symlink(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_symlink_circular() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let link = \"test_symlink_circular\";\n\n    ucmd.args(&[\"-s\", link]).succeeds().no_stderr();\n    assert!(at.is_symlink(link));\n    assert_eq!(at.resolve_link(link), link);\n}"}
{"code": "pub fn name(&self) -> &str {\n        &self.data.file_name\n    }", "test": "fn aes256_encrypted_uncompressed_file() {\n    let mut v = Vec::new();\n    v.extend_from_slice(include_bytes!(\"data/aes_archive.zip\"));\n    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect(\"couldn't open test zip file\");\n\n    let mut file = archive\n        .by_name_decrypt(\"secret_data_256_uncompressed\", PASSWORD)\n        .expect(\"couldn't find file in archive\")\n        .expect(\"invalid password\");\n    assert_eq!(\"secret_data_256_uncompressed\", file.name());\n\n    let mut content = String::new();\n    file.read_to_string(&mut content)\n        .expect(\"couldn't read encrypted file\");\n    assert_eq!(SECRET_CONTENT, content);\n}"}
{"code": "pub fn is_some(&self) -> bool {\n        match_template_evaltype! {\n            TT, match self {\n                ScalarValue::TT(v) => v.is_some(),\n            }\n        }\n    }", "test": "fn write_batch_delete_range_backward_range() {\n    let db = default_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n\n    let mut wb = db.engine.write_batch();\n\n    wb.delete_range(b\"c\", b\"a\").unwrap();\n    recover_safe(|| {\n        wb.write().unwrap();\n    })\n    .unwrap_err();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_some());\n\n    let db = multi_batch_write_engine();\n\n    db.engine.put(b\"a\", b\"\").unwrap();\n    db.engine.put(b\"b\", b\"\").unwrap();\n    db.engine.put(b\"c\", b\"\").unwrap();\n\n    for i in 0..256_usize {\n        let x = i.to_be_bytes();\n        db.engine.put(&x, &x).unwrap();\n    }\n\n    let mut wb = db.engine.write_batch_with_cap(1024);\n\n    wb.delete_range(b\"c\", b\"a\").unwrap();\n    wb.delete_range(&256_usize.to_be_bytes(), &0_usize.to_be_bytes())\n        .unwrap();\n\n    recover_safe(|| {\n        wb.write().unwrap();\n    })\n    .unwrap_err();\n\n    assert!(db.engine.get_value(b\"a\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"b\").unwrap().is_some());\n    assert!(db.engine.get_value(b\"c\").unwrap().is_some());\n    for i in 0..256_usize {\n        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());\n    }\n}"}
{"code": "fn value(&self) -> V::SelfType<'_> {\n        V::from_bytes(&self.data)\n    }", "test": "fn drain_next_back() {\n    let tmpfile = create_tempfile();\n    let db = Database::create(tmpfile.path()).unwrap();\n    let write_txn = db.begin_write().unwrap();\n    {\n        let mut table = write_txn.open_table(U64_TABLE).unwrap();\n        for i in 0..10 {\n            table.insert(&i, &i).unwrap();\n        }\n    }\n    write_txn.commit().unwrap();\n\n    let write_txn = db.begin_write().unwrap();\n    let mut table = write_txn.open_table(U64_TABLE).unwrap();\n    let mut iter = table.drain(0..10).unwrap();\n    for i in (0..10).rev() {\n        let (k, v) = iter.next_back().unwrap().unwrap();\n        assert_eq!(i, k.value());\n        assert_eq!(i, v.value());\n    }\n}"}
{"code": "pub(crate) fn is_empty(&self) -> bool {\n        self.reads_complete == 0 && self.reads_partial == 0\n    }", "test": "fn test_root_preserve() {\n    let scene = TestScenario::new(util_name!());\n\n    let result = scene.cmd(\"whoami\").run();\n    if skipping_test_is_okay(&result, \"whoami: cannot find name for user ID\") {\n        return;\n    }\n    let user_name = String::from(result.stdout_str().trim());\n    assert!(!user_name.is_empty());\n\n    let result = scene\n        .ucmd()\n        .arg(\"--preserve-root\")\n        .arg(\"-R\")\n        .arg(user_name)\n        .arg(\"/\")\n        .fails();\n    result.stderr_contains(\"chown: it is dangerous to operate recursively\");\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_cp_numbered_if_existing_backup_nil() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let existing_backup = &format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~1~\");\n\n    at.touch(existing_backup);\n    ucmd.arg(\"--backup=nil\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert!(at.file_exists(TEST_HOW_ARE_YOU_SOURCE));\n    assert!(at.file_exists(existing_backup));\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~2~\")),\n        \"How are you?\\n\"\n    );\n}"}
{"code": "pub fn file_exists<P: AsRef<Path>>(&self, path: P) -> bool {\n        match fs::metadata(self.plus(path)) {\n            Ok(m) => m.is_file(),\n            Err(_) => false,\n        }\n    }", "test": "fn test_mv_backup_never() {\n    let (at, mut ucmd) = at_and_ucmd!();\n    let file_a = \"test_mv_backup_numbering_file_a\";\n    let file_b = \"test_mv_backup_numbering_file_b\";\n\n    at.touch(file_a);\n    at.touch(file_b);\n    ucmd.arg(\"--backup=never\")\n        .arg(file_a)\n        .arg(file_b)\n        .succeeds()\n        .no_stderr();\n\n    assert!(!at.file_exists(file_a));\n    assert!(at.file_exists(file_b));\n    assert!(at.file_exists(format!(\"{file_b}~\")));\n}"}
{"code": "pub fn get_module(&self, name: &str) -> Result<String, VbaError> {\n        debug!(\"read module {}\", name);\n        let data = self.get_module_raw(name)?;\n        Ok(self.encoding.decode_all(data))\n    }", "test": "fn vba() {\n    setup();\n\n    let path = format!(\"{}/tests/vba.xlsm\", env!(\"CARGO_MANIFEST_DIR\"));\n    let mut excel: Xlsx<_> = open_workbook(&path).unwrap();\n\n    let mut vba = excel.vba_project().unwrap().unwrap();\n    assert_eq!(\n        vba.to_mut().get_module(\"testVBA\").unwrap(),\n        \"Attribute VB_Name = \\\"testVBA\\\"\\r\\nPublic Sub test()\\r\\n    MsgBox \\\"Hello from \\\n         vba!\\\"\\r\\nEnd Sub\\r\\n\"\n    );\n}"}
{"code": "fn write(&mut self, bytes: &[u8]) -> io::Result<usize> {\n        self.tls_conn.writer().write(bytes)\n    }", "test": "fn client_respects_buffer_limit_pre_handshake() {\n    let (mut client, mut server) = make_pair(KeyType::Rsa);\n\n    client.set_buffer_limit(Some(32));\n\n    assert_eq!(\n        client\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        20\n    );\n    assert_eq!(\n        client\n            .writer()\n            .write(b\"01234567890123456789\")\n            .unwrap(),\n        12\n    );\n\n    do_handshake(&mut client, &mut server);\n    transfer(&mut client, &mut server);\n    server.process_new_packets().unwrap();\n\n    check_read(&mut server.reader(), b\"01234567890123456789012345678901\");\n}"}
{"code": "pub(crate) fn read(mut self, operands: &[&str]) -> Result<Self, ParseError> {\n        for operand in operands {\n            self.parse_operand(operand)?;\n        }\n\n        Ok(self)\n    }", "test": "fn test_cp_backup_numbered() {\n    let (at, mut ucmd) = at_and_ucmd!();\n\n    ucmd.arg(\"--backup=numbered\")\n        .arg(TEST_HELLO_WORLD_SOURCE)\n        .arg(TEST_HOW_ARE_YOU_SOURCE)\n        .succeeds()\n        .no_stderr();\n\n    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), \"Hello, World!\\n\");\n    assert_eq!(\n        at.read(&format!(\"{TEST_HOW_ARE_YOU_SOURCE}.~1~\")),\n        \"How are you?\\n\"\n    );\n}"}
