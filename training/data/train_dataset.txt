fn default_filter_works_in_condition() {
    let mut tera = Tera::default();
    tera.add_raw_template("test.html", r#"{% if frobnicate|default(value=True) %}here{% endif %}"#)
        .unwrap();
    let res = tera.render("test.html", &Context::new());
    assert_eq!(res.unwrap(), "here");
}
fn test_system_time_out_of_range() {
    let input = [0xfd, 0x90, 0x0c, 0xfd, 0xfd, 0x90, 0x0c, 0xfd, 0x90, 0x90];

    let result: Result<(std::time::SystemTime, usize), _> =
        bincode::decode_from_slice(&input, bincode::config::standard());

    match result {
        Ok(_) => panic!("Expected the decode to fail, but it succeeded"),
        Err(DecodeError::InvalidSystemTime { duration }) => {
            assert_eq!(
                duration,
                std::time::Duration::new(10447520527445462160, 144)
            )
        }
        Err(e) => panic!("Expected DecodeError::InvalidSystemTime, got {e:?}"),
    }
}
fn extends_resolves_when_using_config_path() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = Path::new("config/biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["format.json", "linter.json"] }"#,
    );
    let format = Path::new("config/format.json");
    fs.insert(
        format.into(),
        r#"{ "javascript": { "formatter": { "quoteStyle": "single" } } }"#,
    );
    let lint = Path::new("config/linter.json");
    fs.insert(lint.into(), r#"{ "linter": { "enabled": true } }"#);

    let test_file = Path::new("test.js");
    fs.insert(test_file.into(), r#"debugger; console.log("string"); "#);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                "--config-path=config/",
                test_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "extends_resolves_when_using_config_path",
        fs,
        console,
        result,
    ));
}
fn upgrade_severity() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_LINTER_UPGRADE_DIAGNOSTIC.as_bytes(),
    );

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), UPGRADE_SEVERITY_CODE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    let error_count = messages
        .iter()
        .filter(|m| m.level == LogLevel::Error)
        .filter(|m| {
            let content = format!("{:?}", m.content);
            content.contains("style/noNegationElse")
        })
        .count();

    assert_eq!(
        error_count, 1,
        "expected 1 error-level message in console buffer, found {error_count:?}:\n{:?}",
        console.out_buffer
    );

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "upgrade_severity",
        fs,
        console,
        result,
    ));
}
fn parse_create_table_with_strict() {
    let sql = "CREATE TABLE Fruits (id TEXT NOT NULL PRIMARY KEY) STRICT";
    if let Statement::CreateTable { name, strict, .. } = sqlite().verified_stmt(sql) {
        assert_eq!(name.to_string(), "Fruits");
        assert!(strict);
    }
}
fn number() {
    assert_eq!("42".parse(), Ok(Value::Number(Number::new(42))));
    assert_eq!(
        "3.141592653589793".parse(),
        Ok(Value::Number(Number::new(f64::consts::PI)))
    );
}
fn test_table_does_not_grow_on_limited_growth() -> Result<(), Error> {
    let limits = StoreLimitsBuilder::new().table_elements(100).build();
    let mut test = Test::new(0x20, 99, limits)?;
    // By default the policy of a table.grow failure is just for the instruction
    // to return -1 and not-grow the underlying table. We also have the option to
    // trap on failure, which is exercised by the next test below.

    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 99);
    // First table.grow doesn't hit the limit, so succeeds, returns previous size.
    assert_eq!(test.table_grow.call(&mut test.store, (1,))?, 99);
    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 100);
    // Second call goes past the limit, so fails to grow the table, but returns Ok(-1)
    assert_eq!(test.table_grow.call(&mut test.store, (1,))?, -1);
    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 100);
    Ok(())
}
fn parse_variable_tag_simple_negated_expr() {
    let ast = parse("{{ not id }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(WS::default(), Expr::new_negated(ExprVal::Ident("id".to_string())))
    );
}
fn parse_binary_all() {
    let select = verified_only_select("SELECT a = ALL(b)");
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::AllOp {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            compare_op: BinaryOperator::Eq,
            right: Box::new(Expr::Identifier(Ident::new("b"))),
        }),
        select.projection[0]
    );
}
async fn read_goaway_with_debug_data() {
    let mut codec = raw_codec! {
        read => [
            // head
            0, 0, 22, 7, 0, 0, 0, 0, 0,
            // last_stream_id
            0, 0, 0, 1,
            // error_code
            0, 0, 0, 11,
            // debug_data
            "too_many_pings",
        ];
    };

    let data = poll_frame!(GoAway, codec);
    assert_eq!(data.reason(), Reason::ENHANCE_YOUR_CALM);
    assert_eq!(data.last_stream_id(), 1);
    assert_eq!(&**data.debug_data(), b"too_many_pings");

    assert_closed!(codec);
}
fn test_cp_custom_backup_suffix_via_env() {
    let (at, mut ucmd) = at_and_ucmd!();
    let suffix = "super-suffix-of-the-century";

    ucmd.arg("-b")
        .env("SIMPLE_BACKUP_SUFFIX", suffix)
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}{suffix}")),
        "How are you?\n"
    );
}
fn parse_literal_date() {
    let sql = "SELECT DATE '1999-01-01'";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::Date,
            value: "1999-01-01".into(),
        },
        expr_from_projection(only(&select.projection)),
    );
}
fn batch_inscribe_respects_dry_run_flag() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet inscribe --fee-rate 2.1 --batch batch.yaml --dry-run")
    .write("inscription.txt", "Hello World")
    .write(
      "batch.yaml",
      "mode: shared-output\ninscriptions:\n- file: inscription.txt\n",
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert!(rpc_server.mempool().is_empty());

  let request = TestServer::spawn_with_args(&rpc_server, &[])
    .request(format!("/content/{}", output.inscriptions[0].id));

  assert_eq!(request.status(), 404);
}
fn test_cp_arg_update_older_dest_not_older_than_src() {
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_dest_not_older_file1";
    let new = "test_cp_arg_update_dest_not_older_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);
    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("--update=older")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), "new content\n");
}
fn test_where_clause_at_end_of_input() {
    let input = quote! {
        where
    };

    snapshot!(input as WhereClause, @"WhereClause");

    assert_eq!(input.predicates.len(), 0);
}
fn f32_roundtrip_test() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let options = Options::builder().build().unwrap();
    for &float in F32_DATA.iter() {
        let count = unsafe { compact::write_float::<_, DECIMAL>(float, &mut buffer, &options) };
        let actual = unsafe { std::str::from_utf8_unchecked(&buffer[..count]) };
        let roundtrip = actual.parse::<f32>();
        assert_eq!(roundtrip, Ok(float));
    }
}
fn test_cache_write_default_config() {
    let dir = tempfile::tempdir().expect("Can't create temporary directory");
    let config_path = dir.path().join("cache-config.toml");

    let result = create_new_config(Some(&config_path));
    assert!(result.is_ok());
    assert!(config_path.exists());
    assert_eq!(config_path, result.unwrap());
}
fn test_region_error_in_scan() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_cluster, raft_engine, mut ctx) = new_raft_engine(1, "");
    ctx.set_isolation_level(IsolationLevel::Si);

    let (_, endpoint, _) =
        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &data, true);

    fail::cfg("region_snapshot_seek", "return()").unwrap();
    let req = DagSelect::from(&product).build_with(ctx, &[0]);
    let resp = handle_request(&endpoint, req);

    assert!(
        resp.get_region_error()
            .get_message()
            .contains("region seek error")
    );
}
fn test_twice_parenthesized_argument() {
    let source_code = r#"f(((a + 1)))"#;
    let expr = parse_expression(source_code, "<filename>").unwrap();

    let call = expr.as_call_expr().unwrap();
    let arguments = &call.arguments;
    let argument = arguments.args.first().unwrap();

    let parenthesized = parenthesized_range(
        argument.into(),
        arguments.into(),
        &CommentRanges::default(),
        source_code,
    );
    assert_eq!(parenthesized, Some(TextRange::new(2.into(), 11.into())));
}
fn builtins_off() {
    let f = Path::new("/");
    let resolver = Resolver::default();
    let resolved_path = resolver.resolve(f, "zlib").map(|r| r.full_path());
    assert_eq!(resolved_path, Err(ResolveError::NotFound(PathBuf::from("/"))));
}
fn creates_config_file_when_biome_installed_via_package_manager() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("./node_modules/@biomejs/biome/configuration_schema.json");
    fs.insert(file_path.into(), *b"{}");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("init")].as_slice()),
    );
    assert!(result.is_ok(), "run_cli returned {result:?}");

    let file_path = Path::new("biome.json");

    let mut file = fs
        .open(file_path)
        .expect("configuration file was not written on disk");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");
    let parsed = parse_json(
        CONFIG_INIT_DEFAULT_WHEN_INSTALLED,
        JsonParserOptions::default(),
    );
    let formatted =
        biome_json_formatter::format_node(JsonFormatOptions::default(), &parsed.syntax())
            .expect("valid format document")
            .print()
            .expect("valid format document");
    assert_eq!(content, formatted.as_code());

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "creates_config_file_when_biome_installed_via_package_manager",
        fs,
        console,
        result,
    ));
}
fn test_dispatch_change() {
    use std::{error::Error, result::Result};

    use online_config::ConfigManager;

    #[derive(Clone)]
    struct CfgManager(Arc<Mutex<RaftstoreConfig>>);

    impl ConfigManager for CfgManager {
        fn dispatch(&mut self, c: ConfigChange) -> Result<(), Box<dyn Error>> {
            self.0.lock().unwrap().update(c)
        }
    }

    let (mut cfg, _dir) = TikvConfig::with_tmp().unwrap();
    cfg.validate().unwrap();
    let cfg_controller = ConfigController::new(cfg);
    let mut cfg = cfg_controller.get_current();
    let mgr = CfgManager(Arc::new(Mutex::new(cfg.raft_store.clone())));
    cfg_controller.register(Module::Raftstore, Box::new(mgr.clone()));

    cfg_controller
        .update(change("raftstore.raft-log-gc-threshold", "2000"))
        .unwrap();

    // config update
    cfg.raft_store.raft_log_gc_threshold = 2000;
    assert_eq!(cfg_controller.get_current(), cfg);

    // config change should also dispatch to raftstore config manager
    assert_eq!(mgr.0.lock().unwrap().raft_log_gc_threshold, 2000);
}
fn test_expression_undeclared_variables() {
    let env = Environment::new();
    let expr = env.compile_expression("[foo, bar.baz]").unwrap();
    let undeclared = expr.undeclared_variables(false);
    assert_eq!(
        undeclared,
        ["bar", "foo"].into_iter().map(|x| x.to_string()).collect()
    );
    let undeclared = expr.undeclared_variables(true);
    assert_eq!(
        undeclared,
        ["foo", "bar.baz"]
            .into_iter()
            .map(|x| x.to_string())
            .collect()
    );
}
fn test_multi_memory() -> Result<()> {
    let wat = r#"(module
        (import "env" "imported" (memory $imported 5 10 shared))
        (memory (export "owned") 10 20)
        (memory (export "shared") 1 2 shared)
        (export "imported" (memory $imported))
    )"#;
    let mut config = Config::new();
    config.wasm_threads(true);
    config.wasm_multi_memory(true);
    let engine = Engine::new(&config)?;
    let module = Module::new(&engine, wat)?;
    let mut store = Store::new(&engine, ());
    let incoming_shared_memory = SharedMemory::new(&engine, MemoryType::shared(5, 10))?;
    let instance = Instance::new(&mut store, &module, &[incoming_shared_memory.into()])?;
    let owned_memory = instance.get_memory(&mut store, "owned").unwrap();
    let shared_memory = instance.get_shared_memory(&mut store, "shared").unwrap();
    let imported_memory = instance.get_shared_memory(&mut store, "imported").unwrap();

    assert_eq!(owned_memory.size(&store), 10);
    assert_eq!(owned_memory.ty(&store).minimum(), 10);
    assert_eq!(owned_memory.ty(&store).maximum(), Some(20));
    assert_eq!(owned_memory.ty(&store).is_shared(), false);
    assert_eq!(shared_memory.size(), 1);
    assert_eq!(shared_memory.ty().minimum(), 1);
    assert_eq!(shared_memory.ty().maximum(), Some(2));
    assert_eq!(shared_memory.ty().is_shared(), true);
    assert_eq!(imported_memory.size(), 5);
    assert_eq!(imported_memory.ty().minimum(), 5);
    assert_eq!(imported_memory.ty().maximum(), Some(10));
    assert_eq!(imported_memory.ty().is_shared(), true);

    Ok(())
}
fn can_load_parent_macro_in_child() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 }}{% endmacro hello %}"),
        ("parent", "{% import \"macros\" as macros %}{{ macros::hello() }}{% block bob %}{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{ super() }}Hey{% endblock bob %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "1Hey".to_string());
}
fn simple_test() {
    // Test the simple properties of the stack vector.
    let mut x = VecType::from_u64(1);
    assert_eq!(x.len(), 1);
    assert_eq!(x.is_empty(), false);
    assert_eq!(x.capacity(), bigint::BIGINT_LIMBS);
    x.try_push(5).unwrap();
    assert_eq!(x.len(), 2);
    assert_eq!(x.pop(), Some(5));
    assert_eq!(x.len(), 1);
    assert_eq!(&*x, &[1]);
    x.try_extend(&[2, 3, 4]).unwrap();
    assert_eq!(x.len(), 4);
    assert_eq!(&*x, &[1, 2, 3, 4]);
    x.try_resize(6, 0).unwrap();
    assert_eq!(x.len(), 6);
    assert_eq!(&*x, &[1, 2, 3, 4, 0, 0]);
    x.try_resize(0, 0).unwrap();
    assert_eq!(x.len(), 0);
    assert_eq!(x.is_empty(), true);

    let x = VecType::try_from(&[5, 1]).unwrap();
    assert_eq!(x.len(), 2);
    assert_eq!(x.is_empty(), false);
    if bigint::LIMB_BITS == 32 {
        assert_eq!(x.hi64(), (0x8000000280000000, false));
    } else {
        assert_eq!(x.hi64(), (0x8000000000000002, true));
    }
    let rview = bigint::rview(&x);
    assert_eq!(x[0], 5);
    assert_eq!(x[1], 1);
    assert_eq!(rview[0], 1);
    assert_eq!(rview[1], 5);
    assert_eq!(x.len(), 2);

    assert_eq!(VecType::from_u64(U64_MAX).hi64(), (U64_MAX, false));
}
fn test_mv_custom_backup_suffix_via_env() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_custom_backup_suffix_file_a";
    let file_b = "test_mv_custom_backup_suffix_file_b";
    let suffix = "super-suffix-of-the-century";
    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("-b")
        .env("SIMPLE_BACKUP_SUFFIX", suffix)
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn files_max_size_parse_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                ("--files-max-size=-1"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "files_max_size_parse_error",
        fs,
        console,
        result,
    ));
}
fn test_append_multi() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = io_loop
        .block_on(client.append(record.clone(), origin.clone(), true))
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NXRRSet);

    // next append to a non-existent RRset
    let result = io_loop
        .block_on(client.append(record.clone(), origin.clone(), false))
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert_eq!(result.answers()[0], record);

    // will fail if already set and not the same value.
    let mut record2 = record.clone();
    record2.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let mut record3 = record.clone();
    record3.set_data(Some(RData::A(A::new(101, 11, 101, 12))));

    // build the append set
    let mut rrset = RecordSet::from(record2.clone());
    rrset.insert(record3.clone(), 0);

    let result = io_loop
        .block_on(client.append(rrset, origin.clone(), true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 3);

    assert!(result.answers().iter().any(|rr| *rr == record));
    assert!(result.answers().iter().any(|rr| *rr == record2));
    assert!(result.answers().iter().any(|rr| *rr == record3));

    // show that appending the same thing again is ok, but doesn't add any records
    // TODO: technically this is a test for the Server, not client...
    let result = io_loop
        .block_on(client.append(record.clone(), origin, true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 3);
}
fn test_inconsistent_configuration() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_hibernate(&mut cluster.cfg);
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");

    // Wait till leader peer goes to sleep.
    thread::sleep(
        cluster.cfg.raft_store.raft_base_tick_interval.0
            * 3
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,
    );

    // Ensure leader can sleep if all nodes enable hibernate region.
    let awakened = Arc::new(AtomicBool::new(false));
    let filter = Arc::new(AtomicBool::new(true));
    let a = awakened.clone();
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 1)
            .direction(Direction::Send)
            .set_msg_callback(Arc::new(move |_| {
                a.store(true, Ordering::SeqCst);
            }))
            .when(filter.clone()),
    ));
    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);
    assert!(!awakened.load(Ordering::SeqCst));

    // Simulate rolling disable hibernate region in followers
    filter.store(false, Ordering::SeqCst);
    cluster.cfg.raft_store.hibernate_regions = false;
    cluster.stop_node(3);
    cluster.run_node(3).unwrap();
    cluster.must_put(b"k2", b"v2");
    // In case leader changes.
    cluster.must_transfer_leader(1, new_peer(1, 1));
    must_get_equal(&cluster.get_engine(3), b"k2", b"v2");
    // Wait till leader peer goes to sleep.
    thread::sleep(
        cluster.cfg.raft_store.raft_base_tick_interval.0
            * 3
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,
    );
    awakened.store(false, Ordering::SeqCst);
    filter.store(true, Ordering::SeqCst);
    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);
    // Leader should keep awake as peer 3 won't agree to sleep.
    assert!(awakened.load(Ordering::SeqCst));
    cluster.reset_leader_of_region(1);
    assert_eq!(cluster.leader_of_region(1), Some(new_peer(1, 1)));

    // Simulate rolling disable hibernate region in leader
    cluster.clear_send_filters();
    cluster.must_transfer_leader(1, new_peer(3, 3));
    cluster.must_put(b"k3", b"v3");
    must_get_equal(&cluster.get_engine(1), b"k3", b"v3");
    // Wait till leader peer goes to sleep.
    thread::sleep(
        cluster.cfg.raft_store.raft_base_tick_interval.0
            * 3
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,
    );
    awakened.store(false, Ordering::SeqCst);
    let a = awakened.clone();
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 3)
            .direction(Direction::Send)
            .set_msg_callback(Arc::new(move |_| {
                a.store(true, Ordering::SeqCst);
            })),
    ));
    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);
    // Leader should keep awake as hibernate region is disabled.
    assert!(awakened.load(Ordering::SeqCst));
    cluster.reset_leader_of_region(1);
    assert_eq!(cluster.leader_of_region(1), Some(new_peer(3, 3)));
}
fn extract_elif_else_range() -> Result<(), ParseError> {
    let contents = "if a:
    ...
elif b:
    ...
";
    let mut stmts = parse_suite(contents, "<filename>")?;
    let stmt = stmts
        .pop()
        .and_then(ruff_python_ast::Stmt::if_stmt)
        .unwrap();
    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();
    assert_eq!(range.start(), TextSize::from(14));
    assert_eq!(range.end(), TextSize::from(18));

    let contents = "if a:
    ...
else:
    ...
";
    let mut stmts = parse_suite(contents, "<filename>")?;
    let stmt = stmts
        .pop()
        .and_then(ruff_python_ast::Stmt::if_stmt)
        .unwrap();
    let range = elif_else_range(&stmt.elif_else_clauses[0], contents).unwrap();
    assert_eq!(range.start(), TextSize::from(14));
    assert_eq!(range.end(), TextSize::from(18));

    Ok(())
}
fn non_page_size_multiple() {
    let tmpfile = create_tempfile();

    let db = Database::create(tmpfile.path()).unwrap();
    let txn = db.begin_write().unwrap();
    let key = vec![0u8; 1024];
    let value = vec![0u8; 1];
    {
        let mut table = txn.open_table(SLICE_TABLE).unwrap();
        table.insert(key.as_slice(), value.as_slice()).unwrap();
    }
    txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(SLICE_TABLE).unwrap();
    assert_eq!(table.len().unwrap(), 1);
}
fn test_mv_simple_backup() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_simple_backup_file_a";
    let file_b = "test_mv_simple_backup_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("-b")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn downgrade_severity() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_LINTER_DOWNGRADE_DIAGNOSTIC.as_bytes(),
    );

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), NO_DEBUGGER.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    println!("{console:?}");

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    assert_eq!(
        messages
            .iter()
            .filter(|m| m.level == LogLevel::Error)
            .filter(|m| {
                let content = format!("{:#?}", m.content);
                content.contains("suspicious/noDebugger")
            })
            .count(),
        1
    );

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "downgrade_severity",
        fs,
        console,
        result,
    ));
}
fn test_basic() {
    assert_eq!(0.0, s2f(b"0").unwrap());
    assert_eq!(-0.0, s2f(b"-0").unwrap());
    assert_eq!(1.0, s2f(b"1").unwrap());
    assert_eq!(-1.0, s2f(b"-1").unwrap());
    assert_eq!(123456792.0, s2f(b"123456789").unwrap());
    assert_eq!(299792448.0, s2f(b"299792458").unwrap());
}
fn index_runs_with_rpc_user_and_pass_as_env_vars() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  let tempdir = TempDir::new().unwrap();

  let ord = Command::new(executable_path("ord"))
    .args(
      format!(
        "--rpc-url {} --bitcoin-data-dir {} --data-dir {} index update",
        rpc_server.url(),
        tempdir.path().display(),
        tempdir.path().display()
      )
      .to_args(),
    )
    .env("ORD_BITCOIN_RPC_PASS", "bar")
    .env("ORD_BITCOIN_RPC_USER", "foo")
    .env("ORD_INTEGRATION_TEST", "1")
    .current_dir(&tempdir)
    .spawn()
    .unwrap();

  rpc_server.mine_blocks(1);

  assert_eq!(ord.wait_with_output().unwrap().status.code(), Some(0));
}
fn test_install_target_new_file_with_group() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "file";
    let dir = "target_dir";
    let gid = getegid();

    at.touch(file);
    at.mkdir(dir);
    let result = ucmd
        .arg(file)
        .arg("--group")
        .arg(gid.to_string())
        .arg(format!("{dir}/{file}"))
        .run();

    if is_ci() && result.stderr_str().contains("no such group:") {
        // In the CI, some server are failing to return the group.
        // As seems to be a configuration issue, ignoring it
        return;
    }

    result.success();
    assert!(at.file_exists(file));
    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn prefer_absolute() {
    let f = super::fixture();
    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        alias: vec![("foo".into(), vec![AliasValue::Path("/fixtures".into())])],
        roots: vec![dirname(), f.clone()],
        prefer_absolute: true,
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("should resolve an absolute path (prefer absolute)", f.join("b.js").to_string_lossy().to_string(), f.join("b.js")),
    ];

    for (comment, request, expected) in pass {
        let resolved_path = resolver.resolve(&f, &request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {request}");
    }
}
fn test_match_directive() {
    assert_eq!(match_directive("; foo: bar  ", "foo:"), Some("bar"));
    assert_eq!(match_directive(" foo:bar", "foo:"), Some("bar"));
    assert_eq!(match_directive("foo:bar", "foo:"), Some("bar"));
    assert_eq!(match_directive(";x foo: bar", "foo:"), None);
    assert_eq!(match_directive(";;; foo: bar", "foo:"), Some("bar"));
}
fn static_forced_max() -> Result<()> {
    let mut config = Config::new();
    config.static_memory_maximum_size(5 * 65536);
    config.static_memory_forced(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, ());

    let mem = Memory::new(&mut store, MemoryType::new(0, None))?;
    mem.grow(&mut store, 5).unwrap();
    assert!(mem.grow(&mut store, 1).is_err());
    Ok(())
}
fn parse_literal_decimal() {
    // These numbers were explicitly chosen to not roundtrip if represented as
    // f64s (i.e., as 64-bit binary floating point numbers).
    let sql = "SELECT 0.300000000000000004, 9007199254740993.0";
    let select = verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Value(number("0.300000000000000004")),
        expr_from_projection(&select.projection[0]),
    );
    assert_eq!(
        &Expr::Value(number("9007199254740993.0")),
        expr_from_projection(&select.projection[1]),
    )
}
fn sni_resolver_rejects_wrong_names() {
    let kt = KeyType::Rsa;
    let mut resolver = rustls::server::ResolvesServerCertUsingSni::new();
    let signing_key = sign::RsaSigningKey::new(&kt.get_key()).unwrap();
    let signing_key: Arc<dyn sign::SigningKey> = Arc::new(signing_key);

    assert_eq!(
        Ok(()),
        resolver.add(
            "localhost",
            sign::CertifiedKey::new(kt.get_chain(), signing_key.clone())
        )
    );
    assert_eq!(
        Err(Error::General(
            "The server certificate is not valid for the given name".into()
        )),
        resolver.add(
            "not-localhost",
            sign::CertifiedKey::new(kt.get_chain(), signing_key.clone())
        )
    );
    assert_eq!(
        Err(Error::General("Bad DNS name".into())),
        resolver.add(
            "not ascii ðŸ¦€",
            sign::CertifiedKey::new(kt.get_chain(), signing_key.clone())
        )
    );
}

#
fn test_from_mixed() {
    let temp = env::temp_dir();
    let tmpdir = Path::new(&temp);
    let file1 = tmpdir.join("test-1");
    let file3 = tmpdir.join("test-3");

    // spell-checker:disable-next-line
    let (data1, data2, data3) = ("abcdefg", "hijklmnop", "qrstuvwxyz\n");
    for (path, data) in [(&file1, data1), (&file3, data3)] {
        let mut f = File::create(path).unwrap();
        assert!(
            f.write_all(data.as_bytes()).is_ok(),
            "Test setup failed - could not write file"
        );
    }

    new_ucmd!()
        .arg("--endian=little")
        .arg(file1.as_os_str())
        .arg("-")
        .arg(file3.as_os_str())
        .run_piped_stdin(data2.as_bytes())
        .success()
        .no_stderr()
        .stdout_is(unindent(ALPHA_OUT));
}
fn test_delete_by_rdata() {
    let catalog = Catalog::new();
    let (client, origin) = create_sig0_ready_client(catalog);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = client
        .delete_by_rdata(record.clone(), origin.clone())
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let result = client
        .append(record.clone(), origin.clone(), true)
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = client
        .delete_by_rdata(record.clone(), origin)
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert!(result
        .answers()
        .iter()
        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {
            *ip == A::new(100, 10, 100, 10)
        } else {
            false
        }));
}
fn save_point_pop_rollback() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    wb.put(b"a", b"").unwrap();

    wb.pop_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());
    let val = db.engine.get_value(b"b").unwrap();
    assert!(val.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);

    wb.set_save_point();
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();

    wb.pop_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());
    let val = db.engine.get_value(b"b").unwrap();
    assert!(val.is_none());
    for i in 0..512_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn alpn_success() {
    let _guard = subscribe();
    let mut server_crypto = server_crypto();
    server_crypto.alpn_protocols = vec!["foo".into(), "bar".into(), "baz".into()];
    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));
    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);
    let mut client_crypto = client_crypto();
    client_crypto.alpn_protocols = vec!["bar".into(), "quux".into(), "corge".into()];
    let client_config = ClientConfig::new(Arc::new(client_crypto));

    // Establish normal connection
    let client_ch = pair.begin_connect(client_config);
    pair.drive();
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Connected)
    );

    let hd = pair
        .client_conn_mut(client_ch)
        .crypto_session()
        .handshake_data()
        .unwrap()
        .downcast::<crate::crypto::rustls::HandshakeData>()
        .unwrap();
    assert_eq!(hd.protocol.unwrap(), &b"bar"[..]);
}
fn write_batch_delete_range_after_put() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.delete_range(&1_usize.to_be_bytes(), &255_usize.to_be_bytes())
        .unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.write().unwrap();

    assert!(
        db.engine
            .get_value(&0_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    for i in 1..255_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
    assert!(
        db.engine
            .get_value(&255_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());
}
fn read_icc_profile_random_order() {
    let path = Path::new("tests")
        .join("icc")
        .join("icc_chunk_order.jpeg");

    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    decoder.decode().unwrap();

    let profile = decoder.icc_profile().unwrap();

    assert_eq!(profile.len(), 254);

    for i in 1..=254 {
        assert_eq!(profile[i - 1], i as u8);
    }
}
fn test_node_cluster_region_info_accessor() {
    let mut cluster = new_node_cluster(1, 3);
    configure_for_merge(&mut cluster.cfg);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    // Create a RegionInfoAccessor on node 1
    let (tx, rx) = channel();
    cluster
        .sim
        .wl()
        .post_create_coprocessor_host(Box::new(move |id, host| {
            if id == 1 {
                let c = RegionInfoAccessor::new(host);
                tx.send(c).unwrap();
            }
        }));
    cluster.run_conf_change();
    let c = rx.recv().unwrap();
    // We only created it on the node whose id == 1 so we shouldn't receive more
    // than one item.
    assert!(rx.try_recv().is_err());

    test_region_info_accessor_impl(&mut cluster, &c);

    drop(cluster);
    c.stop();
}
fn backwards_call_works() -> Result<()> {
    let mut store = store_with_padding(128 * MB)?;
    let module = Module::new(
        store.engine(),
        r#"
            (module
                (func (result i32)
                    i32.const 4)
                (func (export "foo") (result i32)
                    call 0)
            )
        "#,
    )?;

    let i = Instance::new(&mut store, &module, &[])?;
    let foo = i.get_typed_func::<(), i32>(&mut store, "foo")?;
    assert_eq!(foo.call(&mut store, ())?, 4);
    Ok(())
}
fn parse_simple_case_expr() {
    // ANSI calls a CASE expression with an operand "<simple case>"
    let sql = "SELECT CASE foo WHEN 1 THEN 'Y' ELSE 'N' END";
    let select = verified_only_select(sql);
    use self::Expr::{Case, Identifier};
    assert_eq!(
        &Case {
            operand: Some(Box::new(Identifier(Ident::new("foo")))),
            conditions: vec![Expr::Value(number("1"))],
            results: vec![Expr::Value(Value::SingleQuotedString("Y".to_string()))],
            else_result: Some(Box::new(Expr::Value(Value::SingleQuotedString(
                "N".to_string()
            )))),
        },
        expr_from_projection(only(&select.projection)),
    );
}
fn test_node_callback_when_destroyed() {
    let count = 3;
    let mut cluster = new_node_cluster(0, count);
    // Increase the election tick to make this test case running reliably.
    configure_for_lease_read(&mut cluster.cfg, None, Some(50));
    cluster.run();
    cluster.must_put(b"k1", b"v1");
    let leader = cluster.leader_of_region(1).unwrap();
    let cc = new_change_peer_request(ConfChangeType::RemoveNode, leader.clone());
    let epoch = cluster.get_region_epoch(1);
    let req = new_admin_request(1, &epoch, cc);
    // so the leader can't commit the conf change yet.
    let block = Arc::new(AtomicBool::new(true));
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, leader.get_store_id())
            .msg_type(MessageType::MsgAppendResponse)
            .direction(Direction::Recv)
            .when(Arc::clone(&block)),
    ));
    let mut filter = LeaseReadFilter::default();
    filter.take = true;
    // so the leader can't perform read index.
    cluster.add_send_filter(CloneFilterFactory(filter.clone()));
    // it always timeout, no need to wait.
    let _ = cluster.call_command_on_leader(req, Duration::from_millis(500));

    // To make sure `get` is handled before destroy leader, we must issue
    // `get` then unblock append responses.
    let leader_node_id = leader.get_store_id();
    let get = new_get_cmd(b"k1");
    let mut req = new_request(1, epoch, vec![get], true);
    req.mut_header().set_peer(leader);
    let (cb, mut rx) = make_cb(&req);
    cluster
        .sim
        .rl()
        .async_command_on_node(leader_node_id, req, cb)
        .unwrap();
    // Unblock append responses after we issue the req.
    block.store(false, Ordering::SeqCst);
    let resp = rx.recv_timeout(Duration::from_secs(3)).unwrap();

    assert!(
        !filter.ctx.rl().is_empty(),
        "read index should be performed"
    );
    assert!(
        resp.get_header().get_error().has_region_not_found(),
        "{:?}",
        resp
    );
}
fn inscribe_no_backup() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  create_wallet(&rpc_server);
  assert_eq!(rpc_server.descriptors().len(), 2);

  CommandBuilder::new("wallet inscribe --file hello.txt --no-backup --fee-rate 1")
    .write("hello.txt", "HELLOWORLD")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  assert_eq!(rpc_server.descriptors().len(), 2);
}
fn test_install_target_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "source_file";
    let file2 = "target_file";

    at.touch(file1);
    at.touch(file2);
    ucmd.arg(file1).arg(file2).succeeds().no_stderr();

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
}
fn test_macro_passing() {
    let env = Environment::new();
    let tmpl = env
        .template_from_str("{% macro m(a) %}{{ a }}{% endmacro %}")
        .unwrap();
    let (_, state) = tmpl.render_and_return_state(()).unwrap();
    let m = state.lookup("m").unwrap();
    assert_eq!(m.get_attr("name").unwrap().as_str(), Some("m"));
    let rv = m.call(&state, args!(42)).unwrap();
    assert_eq!(rv.as_str(), Some("42"));

    // if we call the macro on an empty state it errors
    let empty_state = env.empty_state();
    let err = m.call(&empty_state, args!(42)).unwrap_err();
    assert_eq!(err.kind(), ErrorKind::InvalidOperation);
    assert_eq!(
        err.detail(),
        Some("cannot call this macro. template state went away.")
    );
}
fn test_cluster_version() {
    let server = MockServer::<Service>::new(3);
    let eps = server.bind_addrs();

    let feature_a = Feature::require(0, 0, 1);
    let feature_b = Feature::require(5, 0, 0);
    let feature_c = Feature::require(5, 0, 1);

    let client = new_client(eps, None);
    let feature_gate = client.feature_gate();
    assert!(!feature_gate.can_enable(feature_a));

    let emit_heartbeat = || {
        let req = pdpb::StoreStats::default();
        block_on(client.store_heartbeat(req, /* store_report= */ None, None)).unwrap();
    };

    let set_cluster_version = |version: &str| {
        let h = server.default_handler();
        h.set_cluster_version(version.to_owned());
    };

    // Empty version string will be treated as invalid.
    emit_heartbeat();
    assert!(!feature_gate.can_enable(feature_a));

    // Explicitly invalid version string.
    set_cluster_version("invalid-version");
    emit_heartbeat();
    assert!(!feature_gate.can_enable(feature_a));

    // Correct version string.
    set_cluster_version("5.0.0");
    emit_heartbeat();
    assert!(feature_gate.can_enable(feature_a));
    assert!(feature_gate.can_enable(feature_b));
    assert!(!feature_gate.can_enable(feature_c));

    // Version can't go backwards.
    set_cluster_version("4.99");
    emit_heartbeat();
    assert!(feature_gate.can_enable(feature_b));
    assert!(!feature_gate.can_enable(feature_c));

    // After reconnect the version should be still accessable.
    // The GLOBAL_RECONNECT_INTERVAL is 0.1s so sleeps 0.2s here.
    thread::sleep(Duration::from_millis(200));
    client.reconnect().unwrap();
    assert!(feature_gate.can_enable(feature_b));
    assert!(!feature_gate.can_enable(feature_c));

    // Version can go forwards.
    set_cluster_version("5.0.1");
    emit_heartbeat();
    assert!(feature_gate.can_enable(feature_c));
}
fn eph_allocation_chains() {
    run_test(|| {
        let gc_value = Gc::new(String::from("foo"));

        {
            let cloned_gc = gc_value.clone();
            let weak = WeakGc::new(&cloned_gc);
            let wrap = Gc::new(weak);

            assert_eq!(wrap.upgrade().as_deref().map(String::as_str), Some("foo"));

            let eph = Ephemeron::new(&wrap, 3);

            drop(cloned_gc);
            force_collect();
            assert_eq!(wrap.upgrade().as_deref().map(String::as_str), Some("foo"));
            assert_eq!(eph.value(), Some(3));

            drop(gc_value);
            force_collect();
            assert!(wrap.upgrade().is_none());
            assert_eq!(eph.value(), Some(3));

            drop(wrap);
            force_collect();
            assert!(eph.value().is_none());
        }
    });
}
fn test_date_for_invalid_file() {
    let result = new_ucmd!().arg("--file").arg("invalid_file").fails();
    result.no_stdout();
    assert_eq!(
        result.stderr_str().trim(),
        "date: invalid_file: No such file or directory",
    );
}
fn test_atomic_getting_max_ts_and_storing_memory_lock() {
    let engine = TestEngineBuilder::new().build().unwrap();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .build()
        .unwrap();

    let (prewrite_tx, prewrite_rx) = channel();
    let (fp_tx, fp_rx) = sync_channel(1);
    // sleep a while between getting max ts and store the lock in memory
    fail::cfg_callback("before-set-lock-in-memory", move || {
        fp_tx.send(()).unwrap();
        thread::sleep(Duration::from_millis(200));
    })
    .unwrap();
    storage
        .sched_txn_command(
            commands::Prewrite::new(
                vec![Mutation::make_put(Key::from_raw(b"k"), b"v".to_vec())],
                b"k".to_vec(),
                40.into(),
                20000,
                false,
                1,
                TimeStamp::default(),
                TimeStamp::default(),
                Some(vec![]),
                false,
                AssertionLevel::Off,
                Context::default(),
            ),
            Box::new(move |res| {
                prewrite_tx.send(res).unwrap();
            }),
        )
        .unwrap();
    fp_rx.recv().unwrap();
    match block_on(storage.get(Context::default(), Key::from_raw(b"k"), 100.into())) {
        // In this case, min_commit_ts is smaller than the start ts, but the lock is visible
        // to the get.
        Err(storage::Error(box storage::ErrorInner::Txn(txn::Error(
            box txn::ErrorInner::Mvcc(mvcc::Error(box mvcc::ErrorInner::KeyIsLocked(lock))),
        )))) => {
            assert_eq!(lock.get_min_commit_ts(), 41);
        }
        res => panic!("unexpected result: {:?}", res),
    }
    let res = prewrite_rx.recv().unwrap().unwrap();
    assert_eq!(res.min_commit_ts, 41.into());
}
fn test_numeric_suffix_alias() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n", "4", "--numeric=9", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x10"), "b");
    assert_eq!(at.read("x11"), "c");
    assert_eq!(at.read("x12"), "");
}
fn with_invalid_semicolons_option() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--semicolons"), ("asneed"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "with_invalid_semicolons_option",
        fs,
        console,
        result,
    ));
}
fn test_update_server_config() {
    let (mut config, _dir) = TikvConfig::with_tmp().unwrap();
    config.validate().unwrap();
    let (cfg_controller, snap_worker, snap_mgr) = start_server(config.clone(), &_dir);
    let mut svr_cfg = config.server.clone();
    // dispatch updated config
    let change = {
        let mut m = std::collections::HashMap::new();
        m.insert(
            "server.snap-io-max-bytes-per-sec".to_owned(),
            "512MB".to_owned(),
        );
        m.insert(
            "server.concurrent-send-snap-limit".to_owned(),
            "100".to_owned(),
        );
        m
    };
    cfg_controller.update(change).unwrap();

    svr_cfg.snap_io_max_bytes_per_sec = ReadableSize::mb(512);
    svr_cfg.concurrent_send_snap_limit = 100;
    // config should be updated
    assert_eq!(snap_mgr.get_speed_limit() as u64, 536870912);
    validate(&snap_worker.scheduler(), move |cfg: &ServerConfig| {
        assert_eq!(cfg, &svr_cfg);
    });
}
fn server_hs_retransmit() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let client_ch = pair.begin_connect(client_config());
    pair.step();
    assert!(!pair.client.inbound.is_empty()); // Initial + Handshakes
    pair.client.inbound.clear();
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected { .. })
    );
}
fn connect_runs_mtud_again_after_600_seconds() {
    let _guard = subscribe();
    let mut server_config = server_config();
    let mut client_config = client_config();

    // Note: we use an infinite idle timeout to ensure we can wait 600 seconds without the
    // connection closing
    Arc::get_mut(&mut server_config.transport)
        .unwrap()
        .max_idle_timeout(None);
    Arc::get_mut(&mut client_config.transport)
        .unwrap()
        .max_idle_timeout(None);

    let mut pair = Pair::new(Default::default(), server_config);
    pair.mtu = 1400;
    let (client_ch, server_ch) = pair.connect_with(client_config);
    pair.drive();

    // Sanity check: the mtu has been discovered
    let client_conn = pair.client_conn_mut(client_ch);
    assert_eq!(client_conn.path_mtu(), 1389);
    assert_eq!(client_conn.stats().path.sent_plpmtud_probes, 5);
    assert_eq!(client_conn.stats().path.lost_plpmtud_probes, 3);
    let server_conn = pair.server_conn_mut(server_ch);
    assert_eq!(server_conn.path_mtu(), 1389);
    assert_eq!(server_conn.stats().path.sent_plpmtud_probes, 5);
    assert_eq!(server_conn.stats().path.lost_plpmtud_probes, 3);

    // Sanity check: the mtu does not change after the fact, even though the link now supports a
    // higher udp payload size
    pair.mtu = 1500;
    pair.drive();
    assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), 1389);
    assert_eq!(pair.server_conn_mut(server_ch).path_mtu(), 1389);

    // The MTU changes after 600 seconds, because now MTUD runs for the second time
    pair.time += Duration::from_secs(600);
    pair.drive();
    assert!(!pair.client_conn_mut(client_ch).is_closed());
    assert!(!pair.server_conn_mut(client_ch).is_closed());
    assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), 1452);
    assert_eq!(pair.server_conn_mut(server_ch).path_mtu(), 1452);
}
fn test_force_leader_on_hibernated_follower() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    // wait a while to hibernate
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 3,
    ));

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), None);
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn cmp_test() {
    // Simple
    let x = VecType::from_u64(1);
    let y = VecType::from_u64(2);
    assert_eq!(x.partial_cmp(&x), Some(cmp::Ordering::Equal));
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Less);

    // Check asymmetric
    let x = VecType::try_from(&[5, 1]).unwrap();
    let y = VecType::from_u64(2);
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);

    // Check when we use reverse ordering properly.
    let x = VecType::try_from(&[5, 1, 9]).unwrap();
    let y = VecType::try_from(&[6, 2, 8]).unwrap();
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);

    // Complex scenario, check it properly uses reverse ordering.
    let x = VecType::try_from(&[0, 1, 9]).unwrap();
    let y = VecType::try_from(&[4294967295, 0, 9]).unwrap();
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);
}
fn test_chown_only_owner_colon() {
    // test chown username: file.txt

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    let file1 = "test_chown_file1";
    at.touch(file1);

    scene
        .ucmd()
        .arg(format!("{user_name}:"))
        .arg("--verbose")
        .arg(file1)
        .succeeds()
        .stderr_contains("retained as");

    scene
        .ucmd()
        .arg(format!("{user_name}."))
        .arg("--verbose")
        .arg(file1)
        .succeeds()
        .stderr_contains("retained as");

    scene
        .ucmd()
        .arg("root:")
        .arg("--verbose")
        .arg(file1)
        .fails()
        .stderr_contains("failed to change");
}
fn test_rm_silently_accepts_presume_input_tty2() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_2 = "test_rm_silently_accepts_presume_input_tty2";

    at.touch(file_2);

    ucmd.arg("---presume-input-tty").arg(file_2).succeeds();

    assert!(!at.file_exists(file_2));
}
fn test_cp_backup_simple() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=simple")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
fn issue_655() {
    use winnow::ascii::{line_ending, not_line_ending};
    fn twolines(i: Partial<&str>) -> IResult<Partial<&str>, (&str, &str)> {
        let (i, l1) = not_line_ending.parse_peek(i)?;
        let (i, _) = line_ending.parse_peek(i)?;
        let (i, l2) = not_line_ending.parse_peek(i)?;
        let (i, _) = line_ending.parse_peek(i)?;

        Ok((i, (l1, l2)))
    }

    assert_eq!(
        twolines(Partial::new("foo\nbar\n")),
        Ok((Partial::new(""), ("foo", "bar")))
    );
    assert_eq!(
        twolines(Partial::new("fÃ©o\nbar\n")),
        Ok((Partial::new(""), ("fÃ©o", "bar")))
    );
    assert_eq!(
        twolines(Partial::new("foÃ©\nbar\n")),
        Ok((Partial::new(""), ("foÃ©", "bar")))
    );
    assert_eq!(
        twolines(Partial::new("foÃ©\r\nbar\n")),
        Ok((Partial::new(""), ("foÃ©", "bar")))
    );
}

#[cf
fn write_batch_delete_range_twice_1() {
    let db = default_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();

    let mut wb = db.engine.write_batch();

    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());

    let db = multi_batch_write_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        db.engine.put(&x, &x).unwrap();
    }

    let mut wb = db.engine.write_batch_with_cap(1024);

    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())
        .unwrap();
    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())
        .unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());
    assert!(
        db.engine
            .get_value(&0_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    for i in 1..256_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn test_read_on_replica_check_memory_locks() {
    let count = 3;
    let mut cluster = new_server_cluster(0, count);
    cluster.cfg.raft_store.hibernate_regions = false;
    cluster.run();

    let raw_key = b"key";
    let encoded_key = Key::from_raw(raw_key);

    // make sure leader has been elected.
    assert_eq!(cluster.must_get(raw_key), None);

    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let leader_cm = cluster.sim.rl().get_concurrency_manager(leader.get_id());

    let lock = Lock::new(
        LockType::Put,
        raw_key.to_vec(),
        10.into(),
        20000,
        None,
        10.into(),
        1,
        20.into(),
    );
    let guard = block_on(leader_cm.lock_key(&encoded_key));
    guard.with_lock(|l| *l = Some(lock.clone()));

    // read on follower
    let mut follower_peer = None;
    let mut follower_id = 0;
    let peers = region.get_peers();
    for p in peers {
        if p.get_id() != leader.get_id() {
            follower_id = p.get_id();
            follower_peer = Some(p.clone());
            break;
        }
    }

    assert!(follower_peer.is_some());
    let mut follower_ctx = Context::default();
    follower_ctx.set_region_id(region.get_id());
    follower_ctx.set_region_epoch(region.get_region_epoch().clone());
    follower_ctx.set_peer(follower_peer.as_ref().unwrap().clone());
    follower_ctx.set_replica_read(true);
    for use_max_ts in [false, true] {
        let mut range = KeyRange::default();
        range.set_start_key(encoded_key.as_encoded().to_vec());
        let ts = if use_max_ts {
            Some(TimeStamp::max())
        } else {
            Some(100.into())
        };
        let follower_snap_ctx = SnapContext {
            pb_ctx: &follower_ctx,
            start_ts: ts,
            key_ranges: vec![range],
            ..Default::default()
        };
        let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();
        match follower_storage.snapshot(follower_snap_ctx) {
            Err(Error(box ErrorInner::KeyIsLocked(lock_info))) => {
                assert_eq!(lock_info, lock.clone().into_lock_info(raw_key.to_vec()))
            }
            other => panic!("unexpected result: {:?}", other),
        }
    }
}
fn u128_pow10_test() {
    let values: &[u128] = &[
        0,
        1,
        5,
        9,
        10,
        11,
        15,
        99,
        100,
        101,
        105,
        999,
        1000,
        1001,
        1005,
        9999,
        10000,
        10001,
        10005,
        99999,
        100000,
        100001,
        100005,
        999999,
        1000000,
        1000001,
        1000005,
        9999999,
        10000000,
        10000001,
        10000005,
        99999999,
        100000000,
        100000001,
        100000005,
        999999999,
        1000000000,
        1000000001,
        1000000005,
        9999999999,
        10000000000,
        10000000001,
        10000000005,
        99999999999,
        100000000000,
        100000000001,
        100000000005,
        999999999999,
        1000000000000,
        1000000000001,
        1000000000005,
        9999999999999,
        10000000000000,
        10000000000001,
        10000000000005,
        99999999999999,
        100000000000000,
        100000000000001,
        100000000000005,
        999999999999999,
        1000000000000000,
        1000000000000001,
        1000000000000005,
        9999999999999999,
        10000000000000000,
        10000000000000001,
        10000000000000005,
        99999999999999999,
        100000000000000000,
        100000000000000001,
        100000000000000005,
        999999999999999999,
        1000000000000000000,
        1000000000000000001,
        1000000000000000005,
        9999999999999999999,
        10000000000000000000,
        10000000000000000001,
        10000000000000000005,
        99999999999999999999,
        100000000000000000000,
        100000000000000000001,
        100000000000000000005,
        999999999999999999999,
        1000000000000000000000,
        1000000000000000000001,
        1000000000000000000005,
        9999999999999999999999,
        10000000000000000000000,
        10000000000000000000001,
        10000000000000000000005,
        99999999999999999999999,
        100000000000000000000000,
        100000000000000000000001,
        100000000000000000000005,
        999999999999999999999999,
        1000000000000000000000000,
        1000000000000000000000001,
        1000000000000000000000005,
        9999999999999999999999999,
        10000000000000000000000000,
        10000000000000000000000001,
        10000000000000000000000005,
        99999999999999999999999999,
        100000000000000000000000000,
        100000000000000000000000001,
        100000000000000000000000005,
        999999999999999999999999999,
        1000000000000000000000000000,
        1000000000000000000000000001,
        1000000000000000000000000005,
        9999999999999999999999999999,
        10000000000000000000000000000,
        10000000000000000000000000001,
        10000000000000000000000000005,
        99999999999999999999999999999,
        100000000000000000000000000000,
        100000000000000000000000000001,
        100000000000000000000000000005,
        999999999999999999999999999999,
        1000000000000000000000000000000,
        1000000000000000000000000000001,
        1000000000000000000000000000005,
        9999999999999999999999999999999,
        10000000000000000000000000000000,
        10000000000000000000000000000001,
        10000000000000000000000000000005,
        99999999999999999999999999999999,
        100000000000000000000000000000000,
        100000000000000000000000000000001,
        100000000000000000000000000000005,
        999999999999999999999999999999999,
        1000000000000000000000000000000000,
        1000000000000000000000000000000001,
        1000000000000000000000000000000005,
        9999999999999999999999999999999999,
        10000000000000000000000000000000000,
        10000000000000000000000000000000001,
        10000000000000000000000000000000005,
        99999999999999999999999999999999999,
        100000000000000000000000000000000000,
        100000000000000000000000000000000001,
        100000000000000000000000000000000005,
        999999999999999999999999999999999999,
        1000000000000000000000000000000000000,
        1000000000000000000000000000000000001,
        1000000000000000000000000000000000005,
        9999999999999999999999999999999999999,
        10000000000000000000000000000000000000,
        10000000000000000000000000000000000001,
        10000000000000000000000000000000000005,
        99999999999999999999999999999999999999,
        100000000000000000000000000000000000000,
        100000000000000000000000000000000000001,
        100000000000000000000000000000000000005,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn write_batch_count_2() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    assert_eq!(wb.count(), 0);
    wb.put(b"a", b"").unwrap();
    assert_eq!(wb.count(), 1);
    wb.delete(b"a").unwrap();
    assert_eq!(wb.count(), 2);
    wb.delete_range(b"a", b"b").unwrap();
    assert_eq!(wb.count(), 3);
    wb.write().unwrap();
    assert_eq!(wb.count(), 3);

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);

    assert_eq!(wb.count(), 0);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    assert_eq!(wb.count(), 257);
    wb.delete(b"a").unwrap();
    assert_eq!(wb.count(), 258);
    wb.delete_range(b"a", b"b").unwrap();
    assert_eq!(wb.count(), 259);
    wb.write().unwrap();
    assert_eq!(wb.count(), 259);
}
fn parse_set_array_with_filter() {
    let ast = parse("{% set hello = [1, true, 'hello'] | length %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Set(
            WS::default(),
            Set {
                key: "hello".to_string(),
                value: Expr::with_filters(
                    ExprVal::Array(vec![
                        Expr::new(ExprVal::Int(1)),
                        Expr::new(ExprVal::Bool(true)),
                        Expr::new(ExprVal::String("hello".to_string())),
                    ]),
                    vec![FunctionCall { name: "length".to_string(), args: HashMap::new() },],
                ),
                global: false,
            },
        )
    );
}
fn test_error_in_grandchild_template_location() {
    let result = render_tpl("error-location/error_in_grand_child.html");

    assert!(result.is_err());
    let errs = result.unwrap_err();
    assert_eq!(errs.to_string(), "Failed to render 'error-location/error_in_grand_child.html'");
}
fn write_batch_clear() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.clear();
    assert!(wb.is_empty());
    assert_eq!(wb.count(), 0);
    wb.write().unwrap();
    assert!(db.engine.get_value(b"a").unwrap().is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);

    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.clear();
    assert!(wb.is_empty());
    assert_eq!(wb.count(), 0);
    wb.write().unwrap();
    for i in 0..256_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn test_rm_force_prompts_order() {
    // Needed for talking with stdin on platforms where CRLF or LF matters
    const END_OF_LINE: &str = if cfg!(windows) { "\r\n" } else { "\n" };

    let yes = format!("y{END_OF_LINE}");

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let empty_file = "empty";

    at.touch(empty_file);

    // This should cause rm to prompt to remove regular empty file
    let mut child = scene
        .ucmd()
        .set_stdin(Stdio::piped())
        .arg("-fi")
        .arg(empty_file)
        .run_no_wait();
    child.try_write_in(yes.as_bytes()).unwrap();

    let result = child.wait().unwrap();
    result.stderr_only("rm: remove regular empty file 'empty'? ");

    assert!(!at.file_exists(empty_file));

    at.touch(empty_file);

    // This should not cause rm to prompt to remove regular empty file
    scene
        .ucmd()
        .arg("-if")
        .arg(empty_file)
        .succeeds()
        .no_stderr();
    assert!(!at.file_exists(empty_file));
}
fn pair_ints_offsets() {
    assert_eq!(types::PairInts::offset_of_first(), 0);
    assert_eq!(types::PairInts::offset_of_second(), 4);
}
fn brackets_over_db_schema_table_name_with_whites_paces() {
    match redshift().parse_sql_statements("SELECT [   col1  ] FROM [  test_schema].[ test_table]") {
        Ok(statements) => {
            assert_eq!(statements.len(), 1);
        }
        _ => unreachable!(),
    }
}
fn create_open() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        table.insert(&0, &1).unwrap();
    }
    write_txn.commit().unwrap();
    drop(db);

    let db2 = Database::open(tmpfile.path()).unwrap();

    let read_txn = db2.begin_read().unwrap();
    let table = read_txn.open_table(U64_TABLE).unwrap();
    assert_eq!(1, table.get(&0).unwrap().unwrap().value());
}
fn instant_close_2() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    info!("connecting");
    let client_ch = pair.begin_connect(client_config());
    // Unlike `instant_close`, the server sees a valid Initial packet first.
    pair.drive_client();
    pair.client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .close(pair.time, VarInt(42), Bytes::new());
    pair.drive();
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::ConnectionClosed(ConnectionClose {
                error_code: TransportErrorCode::APPLICATION_ERROR,
                ..
            }),
        })
    );
}
fn parse_cross_join() {
    let sql = "SELECT * FROM t1 CROSS JOIN t2";
    let select = verified_only_select(sql);
    assert_eq!(
        Join {
            relation: TableFactor::Table {
                name: ObjectName(vec![Ident::new("t2")]),
                alias: None,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            join_operator: JoinOperator::CrossJoin,
        },
        only(only(select.from).joins),
    );
}
fn test_big_memory_fails_to_instantiate() {
    let loose_limits = StoreLimitsBuilder::new().memory_size(0x30_0000).build();
    let tight_limits = StoreLimitsBuilder::new().memory_size(0x20_0000).build();
    assert!(Test::new(0x30, 0, loose_limits).is_ok());
    assert!(Test::new(0x30, 0, tight_limits).is_err());
}
fn render_variable_block_autoescaping_disabled() {
    let mut context = Context::new();
    context.insert("name", &"john");
    context.insert("malicious", &"<html>");

    let inputs = vec![
        ("{{ name }}", "john"),
        ("{{ malicious }}", "<html>"),
        ("{{ malicious | safe }}", "<html>"),
        ("{{ malicious | upper }}", "<HTML>"),
        ("{{ malicious | upper | safe }}", "<HTML>"),
        ("{{ malicious | safe | upper }}", "<HTML>"),
    ];

    for (input, expected) in inputs {
        let mut tera = Tera::default();
        tera.add_raw_template("hello.sql", input).unwrap();
        assert_eq!(tera.render("hello.sql", &context).unwrap(), expected);
    }
}
fn render_super_in_grandchild_without_redefining_works() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("grandparent", "{% block title %}Title{% endblock %}"),
        (
            "parent",
            "{% extends \"grandparent\" %}{% block title %}{{ super() }} - More{% endblock %}",
        ),
        ("child", "{% extends \"parent\" %}"),
    ])
    .unwrap();

    let result = tera.render("child", &Context::new());
    assert_eq!(result.unwrap(), "Title - More".to_string());
}
fn delete() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
        table.insert("hello2", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    assert_eq!(table.len().unwrap(), 2);

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        assert_eq!("world", table.remove("hello").unwrap().unwrap().value());
        assert!(table.remove("hello").unwrap().is_none());
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert!(table.get("hello").unwrap().is_none());
    assert_eq!(table.len().unwrap(), 1);
}
fn u32_pow2_test() {
    let values: &[u32] = &[
        0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255, 256,
        257, 511, 512, 513, 1023, 1024, 1025, 2047, 2048, 2049, 4095, 4096, 4097, 8191, 8192, 8193,
        16383, 16384, 16385, 32767, 32768, 32769, 65535, 65536, 65537, 131071, 131072, 131073,
        262143, 262144, 262145, 524287, 524288, 524289, 1048575, 1048576, 1048577, 2097151,
        2097152, 2097153, 4194303, 4194304, 4194305, 8388607, 8388608, 8388609, 16777215, 16777216,
        16777217, 33554431, 33554432, 33554433, 67108863, 67108864, 67108865, 134217727, 134217728,
        134217729, 268435455, 268435456, 268435457, 536870911, 536870912, 536870913, 1073741823,
        1073741824, 1073741825, 2147483647, 2147483648, 2147483649, 4294967295,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn ci_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_help",
        fs,
        console,
        result,
    ));
}
fn parse_simple_select() {
    let sql = "SELECT id, fname, lname FROM customer WHERE id = 1 LIMIT 5";
    let select = verified_only_select(sql);
    assert!(select.distinct.is_none());
    assert_eq!(3, select.projection.len());
    let select = verified_query(sql);
    assert_eq!(Some(Expr::Value(number("5"))), select.limit);
}
fn transactions() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  assert!(rpc_server.loaded_wallets().is_empty());

  CommandBuilder::new("wallet transactions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  assert_eq!(rpc_server.loaded_wallets().len(), 1);
  assert_eq!(rpc_server.loaded_wallets().first().unwrap(), "ord");

  rpc_server.mine_blocks(1);

  let output = CommandBuilder::new("wallet transactions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  assert_regex_match!(output[0].transaction.to_string(), "[[:xdigit:]]{64}");
  assert_eq!(output[0].confirmations, 1);
}
fn test_symlink_remove_existing_same_src_and_dest() {
    let (at, mut ucmd) = at_and_ucmd!();
    at.touch("a");
    at.write("a", "sample");
    ucmd.args(&["-sf", "a", "a"])
        .fails()
        .code_is(1)
        .stderr_contains("'a' and 'a' are the same file");
    assert!(at.file_exists("a") && !at.symlink_exists("a"));
    assert_eq!(at.read("a"), "sample");
}
fn test_cp_deref() {
    let (at, mut ucmd) = at_and_ucmd!();

    #[cfg(not(windows))]
    let _r = fs::symlink(
        TEST_HELLO_WORLD_SOURCE,
        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),
    );
    #[cfg(windows)]
    let _r = symlink_file(
        TEST_HELLO_WORLD_SOURCE,
        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),
    );
    //using -L option
    ucmd.arg("-L")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HELLO_WORLD_SOURCE_SYMLINK)
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    let path_to_new_symlink = at
        .subdir
        .join(TEST_COPY_TO_FOLDER)
        .join(TEST_HELLO_WORLD_SOURCE_SYMLINK);
    // unlike -P/--no-deref, we expect a file, not a link
    assert!(at.file_exists(
        path_to_new_symlink
            .clone()
            .into_os_string()
            .into_string()
            .unwrap()
    ));
    // Check the content of the destination file that was copied.
    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), "Hello, World!\n");
    let path_to_check = path_to_new_symlink.to_str().unwrap();
    assert_eq!(at.read(path_to_check), "Hello, World!\n");
}
fn does_not_format_if_files_are_listed_in_ignore_option() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_FORMATTER_AND_FILES_IGNORE.as_bytes(),
    );

    let file_path_test1 = Path::new("test1.js");
    fs.insert(file_path_test1.into(), UNFORMATTED.as_bytes());

    let file_path_test2 = Path::new("test2.js");
    fs.insert(file_path_test2.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                file_path_test1.as_os_str().to_str().unwrap(),
                file_path_test2.as_os_str().to_str().unwrap(),
                ("--write"),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path_test1)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, UNFORMATTED);

    let mut buffer = String::new();
    fs.open(file_path_test2)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, UNFORMATTED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_format_if_files_are_listed_in_ignore_option",
        fs,
        console,
        result,
    ));
}
fn literal_string() {
    assert_eq!(Literal::string("foo").to_string(), "\"foo\"");
    assert_eq!(Literal::string("\"").to_string(), "\"\\\"\"");
    assert_eq!(Literal::string("didn't").to_string(), "\"didn't\"");
    assert_eq!(
        Literal::string("a\00b\07c\08d\0e\0").to_string(),
        "\"a\\x000b\\x007c\\08d\\0e\\0\"",
    );

    "\"\\\r\n    x\"".parse::<TokenStream>().unwrap();
    "\"\\\r\n  \rx\"".parse::<TokenStream>().unwrap_err();
}
fn persistent_savepoint() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let definition: TableDefinition<u32, &str> = TableDefinition::new("x");

    let txn = db.begin_write().unwrap();
    {
        let mut table = txn.open_table(definition).unwrap();
        table.insert(&0, "hello").unwrap();
    }
    txn.commit().unwrap();

    let txn = db.begin_write().unwrap();
    let savepoint_id = txn.persistent_savepoint().unwrap();
    {
        let mut table = txn.open_table(definition).unwrap();
        table.remove(&0).unwrap();
    }
    txn.commit().unwrap();

    drop(db);
    let db = Database::create(tmpfile.path()).unwrap();
    // Make sure running the GC doesn't invalidate the savepoint
    let txn = db.begin_write().unwrap();
    txn.commit().unwrap();
    let txn = db.begin_write().unwrap();
    txn.commit().unwrap();

    let mut txn = db.begin_write().unwrap();
    let savepoint = txn.get_persistent_savepoint(savepoint_id).unwrap();

    txn.restore_savepoint(&savepoint).unwrap();
    txn.commit().unwrap();

    let txn = db.begin_read().unwrap();
    let table = txn.open_table(definition).unwrap();
    assert_eq!(table.get(&0).unwrap().unwrap().value(), "hello");
}
fn test() {
    let f = super::fixture().join("restrictions");

    let resolver = Resolver::new(ResolveOptions {
        main_fields: vec!["style".into()],
        ..ResolveOptions::default()
    });

    let resolution = resolver.resolve(&f, "pck2").map(|r| r.full_path());
    assert_eq!(resolution, Ok(f.join("node_modules/pck2/index.css")));

    let resolver = Resolver::new(ResolveOptions {
        main_fields: vec!["module".into(), "main".into()],
        ..ResolveOptions::default()
    });

    let resolution = resolver.resolve(&f, "pck2").map(|r| r.full_path());
    assert_eq!(resolution, Ok(f.join("node_modules/pck2/module.js")));
}
fn parse_text_with_whitespace() {
    let ast = parse(" hello world ").unwrap();
    assert_eq!(ast[0], Node::Text(" hello world ".to_string()));
}
fn test_globals() {
    let mut env = Environment::new();
    env.add_global("a", Value::from(42));
    env.add_template("test", "{{ a }}").unwrap();
    let tmpl = env.get_template("test").unwrap();
    assert_eq!(tmpl.render(()).unwrap(), "42");
}
fn test_anyhow_error_return() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module
        (func $hello (import "" "hello"))
        (func (export "run") (call $hello))
        )
    "#;

    let module = Module::new(store.engine(), wat)?;
    let hello_type = FuncType::new(None, None);
    let hello_func = Func::new(&mut store, hello_type, |_, _, _| {
        Err(anyhow::Error::msg("test 1234"))
    });

    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();
    assert!(!e.to_string().contains("test 1234"));
    assert!(format!("{:?}", e).contains("Caused by:\n    test 1234"));

    assert!(e.downcast_ref::<Trap>().is_none());
    assert!(e.downcast_ref::<WasmBacktrace>().is_some());

    Ok(())
}
fn test_error_macros_self_inexisting() {
    let result = render_tpl("macro_self_inexisting.html");

    assert!(result.is_err());
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Macro `self::inexisting` not found in template `macros.html`"
    );
}
fn test_when_warmup_succeed_and_not_become_leader() {
    let mut cluster = run_cluster_and_warm_up_cache_for_store2();

    let (sx, rx) = channel::unbounded();
    fail::cfg_callback("worker_async_fetch_raft_log", move || {
        sx.send(true).unwrap()
    })
    .unwrap();
    fail::cfg("entry_cache_warmed_up_state_is_stale", "return").unwrap();

    // Since the warmup state is stale, the peer should exit warmup state,
    // and the entry cache should be compacted during post_apply.
    let applied_index = cluster.apply_state(1, 2).applied_index;
    cluster.must_put(b"kk1", b"vv1");
    cluster.wait_applied_index(1, 2, applied_index + 1);
    // The peer should warm up cache again when it receives a new TransferLeaderMsg.
    cluster.transfer_leader(1, new_peer(2, 2));
    assert!(rx.recv_timeout(Duration::from_millis(500)).unwrap());
}
fn test_install_ancestors_mode_directories_with_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ancestor1 = "ancestor1";
    let ancestor2 = "ancestor1/ancestor2";
    let target_file = "ancestor1/ancestor2/target_file";
    let directories_arg = "-D";
    let mode_arg = "--mode=200";
    let file = "file";
    let probe = "probe";

    at.mkdir(probe);
    let default_perms = at.metadata(probe).permissions().mode();

    at.touch(file);

    ucmd.args(&[mode_arg, directories_arg, file, target_file])
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(ancestor1));
    assert!(at.dir_exists(ancestor2));
    assert!(at.file_exists(target_file));

    assert_eq!(default_perms, at.metadata(ancestor1).permissions().mode());
    assert_eq!(default_perms, at.metadata(ancestor2).permissions().mode());

    // Expected mode only on the target_file.
    assert_eq!(0o100_200_u32, at.metadata(target_file).permissions().mode());
}
fn test_rmdir_ignore_nonempty_directory_no_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir(DIR);
    at.touch(DIR_FILE);

    ucmd.arg("--ignore-fail-on-non-empty")
        .arg(DIR)
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(DIR));
}
fn parse_select_qualify() {
    let sql = "SELECT i, p, o FROM qt QUALIFY ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) = 1";
    let select = verified_only_select(sql);
    assert_eq!(
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Function(Function {
                name: ObjectName(vec![Ident::new("ROW_NUMBER")]),
                args: vec![],
                null_treatment: None,
                filter: None,
                over: Some(WindowType::WindowSpec(WindowSpec {
                    partition_by: vec![Expr::Identifier(Ident::new("p"))],
                    order_by: vec![OrderByExpr {
                        expr: Expr::Identifier(Ident::new("o")),
                        asc: None,
                        nulls_first: None,
                    }],
                    window_frame: None,
                })),
                distinct: false,
                special: false,
                order_by: vec![],
            })),
            op: BinaryOperator::Eq,
            right: Box::new(Expr::Value(number("1"))),
        }),
        select.qualify
    );

    let sql = "SELECT i, p, o, ROW_NUMBER() OVER (PARTITION BY p ORDER BY o) AS row_num FROM qt QUALIFY row_num = 1";
    let select = verified_only_select(sql);
    assert_eq!(
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Identifier(Ident::new("row_num"))),
            op: BinaryOperator::Eq,
            right: Box::new(Expr::Value(number("1"))),
        }),
        select.qualify
    );
}
fn test_shred_force() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file = "test_shred_force";

    // Create file_a.
    at.touch(file);
    assert!(at.file_exists(file));

    // Make file_a readonly.
    at.set_readonly(file);

    // Try shred -u.
    scene.ucmd().arg("-u").arg(file).run();

    // file_a was not deleted because it is readonly.
    assert!(at.file_exists(file));

    // Try shred -u -f.
    scene.ucmd().arg("-u").arg("-f").arg(file).run();

    // file_a was deleted.
    assert!(!at.file_exists(file));
}
fn default_enforce_extension() {
    let f = super::fixture().join("extensions");

    let resolved = Resolver::new(ResolveOptions {
        extensions: vec![".ts".into(), String::new(), ".js".into()],
        ..ResolveOptions::default()
    })
    .resolve(&f, "./foo");

    assert_eq!(resolved.map(Resolution::into_path_buf), Ok(f.join("foo.ts")));
    // TODO: need to match missingDependencies returned from the resolve function
}
fn test_stale_read_basic_flow_lock() {
    let (cluster, pd_client, leader_client) = prepare_for_stale_read(new_peer(1, 1));
    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));
    follower_client2.ctx.set_stale_read(true);

    // Write `(key1, value1)`
    let commit_ts1 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );

    // Prewrite on `key2` but not commit yet
    let k2_prewrite_ts = get_tso(&pd_client);
    leader_client.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key2"[..], &b"value1"[..])],
        b"key2".to_vec(),
        k2_prewrite_ts,
    );
    // Update `key1`
    let commit_ts2 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value2"[..])],
        b"key1".to_vec(),
    );

    // Assert `(key1, value2)` can't be read with `commit_ts2` due to it's larger
    // than the `start_ts` of `key2`.
    let resp = follower_client2.kv_read(b"key1".to_vec(), commit_ts2);
    assert!(resp.get_region_error().has_data_is_not_ready());
    // Still can read `(key1, value1)` since `commit_ts1` is less than the `key2`
    // lock's `start_ts`
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), commit_ts1);

    // Prewrite on `key3` but not commit yet
    let k3_prewrite_ts = get_tso(&pd_client);
    leader_client.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key3"[..], &b"value1"[..])],
        b"key3".to_vec(),
        k3_prewrite_ts,
    );
    // Commit on `key2`
    let k2_commit_ts = get_tso(&pd_client);
    leader_client.must_kv_commit(vec![b"key2".to_vec()], k2_prewrite_ts, k2_commit_ts);

    // Although there is still lock on the region, but the min lock is refreshed
    // to the `key3`'s lock, now we can read `(key1, value2)` but not `(key2,
    // value1)`
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value2".to_vec(), commit_ts2);
    let resp = follower_client2.kv_read(b"key2".to_vec(), k2_commit_ts);
    assert!(resp.get_region_error().has_data_is_not_ready());

    // Commit on `key3`
    let k3_commit_ts = get_tso(&pd_client);
    leader_client.must_kv_commit(vec![b"key3".to_vec()], k3_prewrite_ts, k3_commit_ts);

    // Now there is not lock on the region, we can read any
    // up to date data
    follower_client2.must_kv_read_equal(b"key2".to_vec(), b"value1".to_vec(), get_tso(&pd_client));
    follower_client2.must_kv_read_equal(b"key3".to_vec(), b"value1".to_vec(), get_tso(&pd_client));
}
fn render_super_multiple_inheritance_nested_block() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        (
            "grandparent",
            "{% block hey %}hello{% endblock hey %}",
        ),
        (
            "parent",
            "{% extends \"grandparent\" %}{% block hey %}hi and grandma says {{ super() }} {% block ending %}sincerely{% endblock ending %}{% endblock hey %}",
        ),
        (
            "child", "{% extends \"parent\" %}{% block hey %}dad says {{ super() }}{% endblock hey %}{% block ending %}{{ super() }} with love{% endblock ending %}",
        ),
    ]).unwrap();
    let result = tera.render("child", &Context::new());

    assert_eq!(
        result.unwrap(),
        "dad says hi and grandma says hello sincerely with love".to_string()
    );
}
fn lex_include_tag() {
    assert!(TeraParser::parse(Rule::include_tag, "{% include \"index.html\" %}").is_ok());
    assert!(TeraParser::parse(Rule::include_tag, "{% include [\"index.html\"] %}").is_ok());
    assert!(TeraParser::parse(Rule::include_tag, "{% include [\"index.html\"] ignore missing %}")
        .is_ok());
}
fn hi64_test() {
    assert_eq!(VecType::from_u64(0xA).hi64(), (0xA000000000000000, false));
    assert_eq!(VecType::from_u64(0xAB).hi64(), (0xAB00000000000000, false));
    assert_eq!(VecType::from_u64(0xAB00000000).hi64(), (0xAB00000000000000, false));
    assert_eq!(VecType::from_u64(0xA23456789A).hi64(), (0xA23456789A000000, false));
}
fn test_server_form_error_on_multiple_queries() {
    let runtime = Runtime::new().expect("failed to create Tokio Runtime");
    let addr = SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(127, 0, 0, 1), 0));
    let udp_socket = runtime.block_on(UdpSocket::bind(&addr)).unwrap();

    let ipaddr = udp_socket.local_addr().unwrap();
    println!("udp_socket on port: {ipaddr}");
    let server_continue = Arc::new(AtomicBool::new(true));
    let server_continue2 = server_continue.clone();

    let server_thread = thread::Builder::new()
        .name("test_server:udp:server".to_string())
        .spawn(move || server_thread_udp(runtime, udp_socket, server_continue2))
        .unwrap();

    let conn = UdpClientConnection::new(ipaddr).unwrap();
    let client = SyncClient::new(conn);

    // build the message
    let query_a = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let query_aaaa = Query::query(
        Name::from_str("www.example.com.").unwrap(),
        RecordType::AAAA,
    );
    let mut message: Message = Message::new();
    message
        .add_query(query_a)
        .add_query(query_aaaa)
        .set_message_type(MessageType::Query)
        .set_op_code(OpCode::Query)
        .set_recursion_desired(true);

    let mut client_result = client.send(message);

    assert_eq!(client_result.len(), 1);
    let client_result = client_result
        .pop()
        .expect("there should be one response")
        .expect("should have been a successful network request");

    assert_eq!(client_result.response_code(), ResponseCode::FormErr);

    server_continue.store(false, Ordering::Relaxed);
    server_thread.join().unwrap();
}
fn table_zeroed() -> Result<()> {
    if skip_pooling_allocator_tests() {
        return Ok(());
    }

    let pool = crate::small_pool_config();
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    config.dynamic_memory_guard_size(0);
    config.static_memory_guard_size(0);
    config.static_memory_maximum_size(65536);

    let engine = Engine::new(&config)?;

    let module = Module::new(&engine, r#"(module (table (export "t") 10 funcref))"#)?;

    // Instantiate the module repeatedly after filling table elements
    for _ in 0..10 {
        let mut store = Store::new(&engine, ());
        let instance = Instance::new(&mut store, &module, &[])?;
        let table = instance.get_table(&mut store, "t").unwrap();
        let f = Func::wrap(&mut store, || {});

        assert_eq!(table.size(&store), 10);

        for i in 0..10 {
            match table.get(&mut store, i).unwrap() {
                Val::FuncRef(r) => assert!(r.is_none()),
                _ => panic!("expected a funcref"),
            }
            table
                .set(&mut store, i, Val::FuncRef(Some(f.clone())))
                .unwrap();
        }
    }

    Ok(())
}
fn test_dnssec_restart_with_update_journal() {
    // TODO: make journal path configurable, it should be in target/tests/...
    let server_path = env::var("TDNS_WORKSPACE_ROOT").unwrap_or_else(|_| "..".to_owned());
    let server_path = Path::new(&server_path);
    let journal = server_path.join("tests/test-data/test_configs/example.com_dnssec_update.jrnl");
    std::fs::remove_file(&journal).ok();

    generic_test(
        "dnssec_with_update.toml",
        "tests/test-data/test_configs/dnssec/rsa_2048.pem",
        KeyFormat::Pem,
        Algorithm::RSASHA256,
    );

    // after running the above test, the journal file should exist
    assert!(journal.exists());

    // and all dnssec tests should still pass
    generic_test(
        "dnssec_with_update.toml",
        "tests/test-data/test_configs/dnssec/rsa_2048.pem",
        KeyFormat::Pem,
        Algorithm::RSASHA256,
    );

    // and journal should still exist
    assert!(journal.exists());

    // cleanup...
    // TODO: fix journal path so that it doesn't leave the dir dirty... this might make windows an option after that
    std::fs::remove_file(&journal).expect("failed to cleanup after test");
}
fn test_resize_async_ios_failed_2() {
    let mut cluster = new_node_cluster(0, 1);
    cluster.cfg.raft_store.store_io_pool_size = 0;
    cluster.pd_client.disable_default_operator();
    let _ = cluster.run_conf_change();

    // Save current async-io tids before shrinking
    let org_writers_tids = get_async_writers_tids();
    assert_eq!(0, org_writers_tids.len());
    // Request can be handled as usual
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");

    // Update config, expand from sync-mode(async-ios == 0) to
    // async-mode(async-ios == 2).
    {
        let sim = cluster.sim.rl();
        let cfg_controller = sim.get_cfg_controller().unwrap();

        let change = {
            let mut change = HashMap::new();
            change.insert("raftstore.store-io-pool-size".to_owned(), "2".to_owned());
            change
        };

        assert!(cfg_controller.update(change).is_err());
        assert_eq!(
            cfg_controller.get_current().raft_store.store_io_pool_size,
            0
        );
    }
    // Save current async-io tids after scaling up, and compared with the
    // orginial one before scaling up, the thread num should be added up to TWO.
    let cur_writers_tids = get_async_writers_tids();
    assert_eq!(cur_writers_tids.len(), org_writers_tids.len());

    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
}
fn test_mv_arg_update_older_dest_older() {
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_mv_arg_update_none_file1";
    let new = "test_mv_arg_update_none_file2";
    let old_content = "file1 content\n";
    let new_content = "file2 content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(new)
        .arg(old)
        .arg("--update=all")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(old), new_content);
}
fn test_create_index_with_using_function() {
    let sql = "CREATE UNIQUE INDEX IF NOT EXISTS idx_name ON test USING btree (name,age DESC)";
    let indexed_columns = vec![
        OrderByExpr {
            expr: Expr::Identifier(Ident::new("name")),
            asc: None,
            nulls_first: None,
        },
        OrderByExpr {
            expr: Expr::Identifier(Ident::new("age")),
            asc: Some(false),
            nulls_first: None,
        },
    ];
    match verified_stmt(sql) {
        Statement::CreateIndex {
            name: Some(name),
            table_name,
            using,
            columns,
            unique,
            concurrently,
            if_not_exists,
            include,
            nulls_distinct: None,
            predicate: None,
        } => {
            assert_eq!("idx_name", name.to_string());
            assert_eq!("test", table_name.to_string());
            assert_eq!("btree", using.unwrap().to_string());
            assert_eq!(indexed_columns, columns);
            assert!(unique);
            assert!(!concurrently);
            assert!(if_not_exists);
            assert!(include.is_empty());
        }
        _ => unreachable!(),
    }
}
fn show_statistics() {
    let args = ["--select", "F401", "--statistics"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("import sys\nimport os\n\nprint(os.getuid())\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    1    F401    [*] `sys` imported but unused

    ----- stderr -----
    "###);
}
fn custom_limiter_detect_grow_failure() -> Result<()> {
    if std::env::var("WASMTIME_TEST_NO_HOG_MEMORY").is_ok() {
        return Ok(());
    }
    let mut pool = crate::small_pool_config();
    pool.memory_pages(10).table_elements(10);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    let engine = Engine::new(&config).unwrap();
    let linker = Linker::new(&engine);

    let module = Module::new(
        &engine,
        r#"(module (memory (export "m") 0) (table (export "t") 0 anyfunc))"#,
    )?;

    let context = FailureDetector::default();

    let mut store = Store::new(&engine, context);
    store.limiter(|s| s as &mut dyn ResourceLimiter);
    let instance = linker.instantiate(&mut store, &module)?;
    let memory = instance.get_memory(&mut store, "m").unwrap();

    // Grow the memory by 640 KiB (10 pages)
    memory.grow(&mut store, 10)?;

    assert!(store.data().memory_error.is_none());
    assert_eq!(store.data().memory_current, 0);
    assert_eq!(store.data().memory_desired, 10 * 64 * 1024);

    // Grow past the static limit set by ModuleLimits.
    // The ResourceLimiter will permit this, but the grow will fail.
    assert_eq!(
        memory.grow(&mut store, 1).unwrap_err().to_string(),
        "failed to grow memory by `1`"
    );

    assert_eq!(store.data().memory_current, 10 * 64 * 1024);
    assert_eq!(store.data().memory_desired, 11 * 64 * 1024);
    assert_eq!(
        store.data().memory_error.as_ref().unwrap(),
        "Memory maximum size exceeded"
    );

    let table = instance.get_table(&mut store, "t").unwrap();
    // Grow the table 10 elements
    table.grow(&mut store, 10, Val::FuncRef(None))?;

    assert!(store.data().table_error.is_none());
    assert_eq!(store.data().table_current, 0);
    assert_eq!(store.data().table_desired, 10);

    // Grow past the static limit set by ModuleLimits.
    // The ResourceLimiter will permit this, but the grow will fail.
    assert_eq!(
        table
            .grow(&mut store, 1, Val::FuncRef(None))
            .unwrap_err()
            .to_string(),
        "failed to grow table by `1`"
    );

    assert_eq!(store.data().table_current, 10);
    assert_eq!(store.data().table_desired, 11);
    assert_eq!(
        store.data().table_error.as_ref().unwrap(),
        "Table maximum size exceeded"
    );

    drop(store);

    Ok(())
}
fn test_mv_interactive() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let file_a = "test_mv_interactive_file_a";
    let file_b = "test_mv_interactive_file_b";

    at.touch(file_a);
    at.touch(file_b);

    scene
        .ucmd()
        .arg("-i")
        .arg(file_a)
        .arg(file_b)
        .pipe_in("n")
        .fails()
        .no_stdout();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    scene
        .ucmd()
        .arg("-i")
        .arg(file_a)
        .arg(file_b)
        .pipe_in("Yesh") // spell-checker:disable-line
        .succeeds()
        .no_stdout();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
}
fn test_write_update_to_file() {
    let (mut cfg, tmp_dir) = TikvConfig::with_tmp().unwrap();
    cfg.cfg_path = tmp_dir.path().join("cfg_file").to_str().unwrap().to_owned();
    {
        let c = r#"
## comment should be reserve
[raftstore]

# config that comment out by one `#` should be update in place
## pd-heartbeat-tick-interval = "30s"
# pd-heartbeat-tick-interval = "30s"

[rocksdb.defaultcf]
## config should be update in place
block-cache-size = "10GB"

[rocksdb.lockcf]
## this config will not update even it has the same last 
## name as `rocksdb.defaultcf.block-cache-size`
block-cache-size = "512MB"

[coprocessor]
## the update to `coprocessor.region-split-keys`, which do not show up 
## as key-value pair after [coprocessor], will be written at the end of [coprocessor]

[gc]
## config should be update in place
max-write-bytes-per-sec = "1KB"

[rocksdb.defaultcf.titan]
blob-run-mode = "normal"
"#;
        let mut f = File::create(&cfg.cfg_path).unwrap();
        f.write_all(c.as_bytes()).unwrap();
        f.sync_all().unwrap();
    }
    let cfg_controller = ConfigController::new(cfg);
    let change = {
        let mut change = HashMap::new();
        change.insert(
            "raftstore.pd-heartbeat-tick-interval".to_owned(),
            "1h".to_owned(),
        );
        change.insert(
            "coprocessor.region-split-keys".to_owned(),
            "10000".to_owned(),
        );
        change.insert("gc.max-write-bytes-per-sec".to_owned(), "100MB".to_owned());
        change.insert(
            "rocksdb.defaultcf.block-cache-size".to_owned(),
            "1GB".to_owned(),
        );
        change.insert(
            "rocksdb.defaultcf.titan.blob-run-mode".to_owned(),
            "read-only".to_owned(),
        );
        change
    };
    cfg_controller.update(change).unwrap();
    let res = {
        let mut buf = Vec::new();
        let mut f = File::open(cfg_controller.get_current().cfg_path).unwrap();
        f.read_to_end(&mut buf).unwrap();
        buf
    };

    let expect = r#"
## comment should be reserve
[raftstore]

# config that comment out by one `#` should be update in place
## pd-heartbeat-tick-interval = "30s"
pd-heartbeat-tick-interval = "1h"

[rocksdb.defaultcf]
## config should be update in place
block-cache-size = "1GB"

[rocksdb.lockcf]
## this config will not update even it has the same last 
## name as `rocksdb.defaultcf.block-cache-size`
block-cache-size = "512MB"

[coprocessor]
## the update to `coprocessor.region-split-keys`, which do not show up 
## as key-value pair after [coprocessor], will be written at the end of [coprocessor]

region-split-keys = 10000
[gc]
## config should be update in place
max-write-bytes-per-sec = "100MB"

[rocksdb.defaultcf.titan]
blob-run-mode = "read-only"
"#;
    assert_eq!(expect.as_bytes(), res.as_slice());
}
fn mantissa_limit_test() {
    assert_eq!(f32::mantissa_limit(10), 7);
    assert_eq!(f64::mantissa_limit(10), 15);
}
fn test_put_delete() {
    let mut cluster = Cluster::default();
    let router = &mut cluster.routers[0];
    let header = Box::new(router.new_request_for(2).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");

    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    let snap = router.stale_snapshot(2);
    assert!(snap.get_value(b"key").unwrap().is_none());
    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub.wait_proposed()));
    assert!(block_on(sub.wait_committed()));
    let resp = block_on(sub.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let snap = router.stale_snapshot(2);
    assert_eq!(snap.get_value(b"key").unwrap().unwrap(), b"value");

    let mut delete = SimpleWriteEncoder::with_capacity(64);
    delete.delete(CF_DEFAULT, b"key");
    let (msg, mut sub) = PeerMsg::simple_write(header, delete.encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub.wait_proposed()));
    assert!(block_on(sub.wait_committed()));
    let resp = block_on(sub.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let snap = router.stale_snapshot(2);
    assert_matches!(snap.get_value(b"key"), Ok(None));

    // Check if WAL is skipped for basic writes.
    let mut cached = cluster.node(0).tablet_registry().get(2).unwrap();
    check_skip_wal(cached.latest().unwrap().as_inner().path());
}
fn test_root_preserve() {
    let scene = TestScenario::new(util_name!());

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    let result = scene
        .ucmd()
        .arg("--preserve-root")
        .arg("-R")
        .arg(user_name)
        .arg("/")
        .fails();
    result.stderr_contains("chown: it is dangerous to operate recursively");
}
fn test_region_detail() {
    let count = 5;
    let mut cluster = new_server_cluster(0, count);
    cluster.run();

    let leader = cluster.leader_of_region(1).unwrap();
    let region_detail = cluster.region_detail(1, 1);
    assert!(region_detail.has_region());
    let region = region_detail.get_region();
    assert_eq!(region.get_id(), 1);
    assert!(region.get_start_key().is_empty());
    assert!(region.get_end_key().is_empty());
    assert_eq!(region.get_peers().len(), 5);
    let epoch = region.get_region_epoch();
    assert_eq!(epoch.get_conf_ver(), 1);
    assert_eq!(epoch.get_version(), 1);

    assert!(region_detail.has_leader());
    assert_eq!(region_detail.get_leader(), &leader);
}
fn range_query_reversed() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(U64_TABLE).unwrap();
    let mut iter = table.range(3..7).unwrap().rev();
    for i in (3..7u64).rev() {
        let (key, value) = iter.next().unwrap().unwrap();
        assert_eq!(i, key.value());
        assert_eq!(i, value.value());
    }
    assert!(iter.next().is_none());

    // Test reversing multiple times
    let mut iter = table.range(3..7).unwrap();
    let (key, _) = iter.next().unwrap().unwrap();
    assert_eq!(3, key.value());

    let mut iter = iter.rev();
    let (key, _) = iter.next().unwrap().unwrap();
    assert_eq!(6, key.value());
    let (key, _) = iter.next().unwrap().unwrap();
    assert_eq!(5, key.value());

    let mut iter = iter.rev();
    let (key, _) = iter.next().unwrap().unwrap();
    assert_eq!(4, key.value());

    assert!(iter.next().is_none());
}
fn test_basic() {
    let mut env = Environment::new();
    assert_eq!(env.fuel(), None);
    env.set_fuel(Some(100));
    assert_eq!(env.fuel(), Some(100));
    env.add_template("test", "{% for x in seq %}{{ x }}\n{% endfor %}")
        .unwrap();
    let t = env.get_template("test").unwrap();

    // this will still manage to run with 100 fuel
    let rv = t
        .render(context!(seq => (0..15).collect::<Vec<_>>()))
        .unwrap();
    assert_eq!(rv.lines().count(), 15);

    // this is above the limit
    let rv = t
        .render(context!(seq => (0..20).collect::<Vec<_>>()))
        .unwrap_err();
    assert_eq!(rv.kind(), ErrorKind::OutOfFuel);
}
fn test_unsafe_recovery_timeout_abort() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::millis(150);
    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::millis(100);
    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::millis(100);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);
    cluster.put(b"random_key1", b"random_val1").unwrap();

    // Blocks the raft apply process on store 1 entirely.
    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);
    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("on_handle_apply_store_1", move || {
        let _ = apply_triggered_tx.send(());
        let _ = apply_released_rx.recv();
    })
    .unwrap();

    // Manually makes an update, and wait for the apply to be triggered, to
    // simulate "some entries are committed but not applied" scenario.
    cluster.put(b"random_key2", b"random_val2").unwrap();
    apply_triggered_rx
        .recv_timeout(Duration::from_secs(1))
        .unwrap();

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);

    // Triggers the unsafe recovery store reporting process.
    let plan = pdpb::RecoveryPlan::default();
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    // sleep for a while to trigger timeout
    fail::cfg("unsafe_recovery_state_timeout", "return").unwrap();
    sleep_ms(200);
    fail::remove("unsafe_recovery_state_timeout");

    // Unblocks the apply process.
    drop(apply_released_tx);

    // No store report is sent, cause the plan is aborted.
    for _ in 0..20 {
        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);
        sleep_ms(100);
    }

    // resend the plan
    let plan = pdpb::RecoveryPlan::default();
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    // Store reports are sent once the entries are applied.
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    fail::remove("on_handle_apply_store_1");
}
fn remove_entry_multi_1_other() {
    let mut headers = HeaderMap::new();
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.insert(VIA, "1.1 example.com".parse().unwrap());

    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 1);
    assert_eq!(headers.len(), 1);

    let vias = remove_all_values(&mut headers, VIA);
    assert_eq!(vias.len(), 1);
    assert_eq!(headers.len(), 0);
}
fn test_async_host_func() {
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    integration::add_atoms_to_linker(&mut linker, |cx| cx).unwrap();
    let mut store = store(&engine);

    let shim_mod = shim_module(&engine);
    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();

    let input: i32 = 123;
    let result_location: i32 = 0;

    let mut results = [Val::I32(0)];
    shim_inst
        .get_func(&mut store, "double_int_return_float_shim")
        .unwrap()
        .call(
            &mut store,
            &[input.into(), result_location.into()],
            &mut results,
        )
        .unwrap();

    assert_eq!(
        results[0].unwrap_i32(),
        types::Errno::Ok as i32,
        "double_int_return_float errno"
    );

    // The actual result is in memory:
    let mem = shim_inst.get_memory(&mut store, "memory").unwrap();
    let mut result_bytes: [u8; 4] = [0, 0, 0, 0];
    mem.read(&store, result_location as usize, &mut result_bytes)
        .unwrap();
    let result = f32::from_le_bytes(result_bytes);
    assert_eq!((input * 2) as f32, result);
}
fn fix_applies_safe_fixes_by_default() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601,UP034",
                "--fix",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    x = {'a': 1, 'a': 1}
    print('foo')

    ----- stderr -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    Found 2 errors (1 fixed, 1 remaining).
    No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
    "###);
}
fn f64_decimal_test() {
    // integer test
    assert_eq!(0.0, f64::from_lexical(b"0").unwrap());
    assert_eq!(1.0, f64::from_lexical(b"1").unwrap());
    assert_eq!(12.0, f64::from_lexical(b"12").unwrap());
    assert_eq!(123.0, f64::from_lexical(b"123").unwrap());
    assert_eq!(1234.0, f64::from_lexical(b"1234").unwrap());
    assert_eq!(12345.0, f64::from_lexical(b"12345").unwrap());
    assert_eq!(123456.0, f64::from_lexical(b"123456").unwrap());
    assert_eq!(1234567.0, f64::from_lexical(b"1234567").unwrap());
    assert_eq!(12345678.0, f64::from_lexical(b"12345678").unwrap());

    // No fraction after decimal point test
    assert_eq!(1.0, f64::from_lexical(b"1.").unwrap());
    assert_eq!(12.0, f64::from_lexical(b"12.").unwrap());
    assert_eq!(1234567.0, f64::from_lexical(b"1234567.").unwrap());

    // No integer before decimal point test
    assert_eq!(0.1, f64::from_lexical(b".1").unwrap());
    assert_eq!(0.12, f64::from_lexical(b".12").unwrap());
    assert_eq!(0.1234567, f64::from_lexical(b".1234567").unwrap());

    // decimal test
    assert_eq!(123456789.0, f64::from_lexical(b"123456789").unwrap());
    assert_eq!(123456789.1, f64::from_lexical(b"123456789.1").unwrap());
    assert_eq!(123456789.12, f64::from_lexical(b"123456789.12").unwrap());
    assert_eq!(123456789.123, f64::from_lexical(b"123456789.123").unwrap());
    assert_eq!(123456789.1234, f64::from_lexical(b"123456789.1234").unwrap());
    assert_eq!(123456789.12345, f64::from_lexical(b"123456789.12345").unwrap());
    assert_eq!(123456789.123456, f64::from_lexical(b"123456789.123456").unwrap());
    assert_eq!(123456789.1234567, f64::from_lexical(b"123456789.1234567").unwrap());
    assert_eq!(123456789.12345678, f64::from_lexical(b"123456789.12345678").unwrap());

    // rounding test
    assert_eq!(123456789.12345679, f64::from_lexical(b"123456789.123456789").unwrap());
    assert_eq!(123456789.12345679, f64::from_lexical(b"123456789.1234567890").unwrap());
    assert_eq!(123456789.12345679, f64::from_lexical(b"123456789.123456789012").unwrap());
    assert_eq!(123456789.12345679, f64::from_lexical(b"123456789.1234567890123").unwrap());
    assert_eq!(123456789.12345679, f64::from_lexical(b"123456789.12345678901234").unwrap());

    // exponent test
    assert_eq!(123456789.12345, f64::from_lexical(b"1.2345678912345e8").unwrap());
    assert_eq!(123450000.0, f64::from_lexical(b"1.2345e+8").unwrap());
    assert_eq!(1.2345e+11, f64::from_lexical(b"123450000000").unwrap());
    assert_eq!(1.2345e+11, f64::from_lexical(b"1.2345e+11").unwrap());
    assert_eq!(1.2345e+38, f64::from_lexical(b"1.2345e+38").unwrap());
    assert_eq!(1.2345e+38, f64::from_lexical(b"123450000000000000000000000000000000000").unwrap());
    assert_eq!(1.2345e+308, f64::from_lexical(b"1.2345e+308").unwrap());
    assert_eq!(1.2345e+308, f64::from_lexical(b"123450000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000").unwrap());
    assert_eq!(0.000000012345, f64::from_lexical(b"1.2345e-8").unwrap());
    assert_eq!(1.2345e-8, f64::from_lexical(b"0.000000012345").unwrap());
    assert_eq!(1.2345e-38, f64::from_lexical(b"1.2345e-38").unwrap());
    assert_eq!(
        1.2345e-38,
        f64::from_lexical(b"0.000000000000000000000000000000000000012345").unwrap()
    );

    // denormalized (try extremely low values)
    assert_eq!(1.2345e-308, f64::from_lexical(b"1.2345e-308").unwrap());

    // due to issues in how the data is parsed, manually extracting
    // non-exponents of 1.<e-299 is prone to error
    // test the limit of our ability
    // We tend to get relative errors of 1e-16, even at super low values.
    assert_eq!(1.2345e-299, f64::from_lexical(b"0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000012345").unwrap());

    // Keep pushing from -300 to -324
    assert_eq!(1.2345e-300, f64::from_lexical(b"0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000012345").unwrap());

    assert_eq!(1.2345e-310, f64::from_lexical(b"0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000012345").unwrap());
    assert_eq!(1.2345e-320, f64::from_lexical(b"0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000012345").unwrap());
    assert_eq!(1.2345e-321, f64::from_lexical(b"0.0000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000012345").unwrap());
    assert_eq!(1.24e-322, f64::from_lexical(b"0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000124").unwrap());
    assert_eq!(Ok(1e-323), f64::from_lexical(b"0.00000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000001"));
    assert_eq!(Ok(5e-324), f64::from_lexical(b"0.000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000005"));

    assert!(f64::from_lexical(b"NaN").unwrap().is_nan());
    assert!(f64::from_lexical(b"nan").unwrap().is_nan());
    assert!(f64::from_lexical(b"NAN").unwrap().is_nan());
    assert!(f64::from_lexical(b"inf").unwrap().is_infinite());
    assert!(f64::from_lexical(b"INF").unwrap().is_infinite());
    assert!(f64::from_lexical(b"+inf").unwrap().is_infinite());
    assert!(f64::from_lexical(b"-inf").unwrap().is_infinite());

    // Check various expected failures.
    assert_eq!(Err(Error::Empty(0)), f64::from_lexical(b""));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"e"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"E"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f64::from_lexical(b".e1"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f64::from_lexical(b".e-1"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"e1"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"e-1"));

    // Check various reports from a fuzzer.
    assert_eq!(Err(Error::EmptyExponent(2)), f64::from_lexical(b"0e"));
    assert_eq!(Err(Error::EmptyExponent(4)), f64::from_lexical(b"0.0e"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f64::from_lexical(b".E"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f64::from_lexical(b".e"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"E2252525225"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f64::from_lexical(b"e2252525225"));
    assert_eq!(Ok(f64::INFINITY), f64::from_lexical(b"2E200000000000"));

    // Add various unittests from proptests.
    assert_eq!(Err(Error::EmptyExponent(2)), f64::from_lexical(b"0e"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f64::from_lexical(b"."));
    assert_eq!(Err(Error::EmptyMantissa(2)), f64::from_lexical(b"+."));
    assert_eq!(Err(Error::EmptyMantissa(2)), f64::from_lexical(b"-."));
    assert_eq!(Err(Error::Empty(1)), f64::from_lexical(b"+"));
    assert_eq!(Err(Error::Empty(1)), f64::from_lexical(b"-"));

    // Bug fix for Issue #8
    assert_eq!(Ok(5.002868148396374), f64::from_lexical(b"5.002868148396374"));

    // Other bug fixes
    assert_eq!(Ok(1.620515050981309e+308), f64::from_lexical(b"162051505098130900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"));
    assert_eq!(Ok(1.620515050981309e+308), f64::from_lexical(b"162051505098130900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.0"));
    assert_eq!(Ok(-1.620515050981309e+308), f64::from_lexical(b"-162051505098130900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"));
    assert_eq!(Ok(-1.620515050981309e+308), f64::from_lexical(b"-162051505098130900000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.0"));
}
fn grow_funcref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::FuncRef, 10, None);
    let table = Table::new(&mut store, table_ty, Val::FuncRef(None))?;

    assert_eq!(table.size(&store), 10);
    table.grow(&mut store, 3, Val::FuncRef(None))?;
    assert_eq!(table.size(&store), 13);

    Ok(())
}
fn test_install_unimplemented_arg() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "target_dir";
    let file = "source_file";
    let context_arg = "--context";

    at.touch(file);
    at.mkdir(dir);
    ucmd.arg(context_arg)
        .arg(file)
        .arg(dir)
        .fails()
        .stderr_contains("Unimplemented");

    assert!(!at.file_exists(format!("{dir}/{file}")));
}
fn depth_limit() {
    let data = Config {
        float: (2.18, -1.1),
        tuple: TupleStruct((), false),
        map: vec![(8, '1')].into_iter().collect(),
        nested: Nested {
            a: "a".to_owned(),
            b: 'b',
        },
        var: Variant::A(!0, ""),
        array: vec![(); 3],
    };

    let pretty = ron::ser::PrettyConfig::new()
        .depth_limit(1)
        .separate_tuple_members(true)
        .enumerate_arrays(true)
        .new_line("\n".to_string());
    let s = ron::ser::to_string_pretty(&data, pretty);

    assert_eq!(s, Ok(EXPECTED.to_string()));
}
fn term_test() {
  assert_eq!(
    term(" 3 *  5   ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("(3 * 5)")))
  );
}
fn test_read_index_with_max_ts() {
    let mut cluster = new_server_cluster(0, 3);
    // Increase the election tick to make this test case running reliably.
    // Use async apply prewrite to let tikv response before applying on the leader
    // peer.
    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));
    cluster.cfg.storage.enable_async_apply_prewrite = true;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let k0 = b"k0";
    let v0 = b"v0";
    let r1 = cluster.run_conf_change();
    let p2 = new_peer(2, 2);
    cluster.pd_client.must_add_peer(r1, p2.clone());
    let p3 = new_peer(3, 3);
    cluster.pd_client.must_add_peer(r1, p3.clone());
    cluster.must_put(k0, v0);
    cluster.pd_client.must_none_pending_peer(p2.clone());
    cluster.pd_client.must_none_pending_peer(p3.clone());

    let region = cluster.get_region(k0);
    cluster.must_transfer_leader(region.get_id(), p3.clone());

    // Block all write cmd applying of Peer 3(leader), then start to write to it.
    let k1 = b"k1";
    let v1 = b"v1";
    let mut ctx_p3 = Context::default();
    ctx_p3.set_region_id(region.get_id());
    ctx_p3.set_region_epoch(region.get_region_epoch().clone());
    ctx_p3.set_peer(p3.clone());
    let mut ctx_p2 = ctx_p3.clone();
    ctx_p2.set_peer(p2.clone());

    let start_ts = 10;
    let mut mutation = pb::Mutation::default();
    mutation.set_op(Op::Put);
    mutation.key = k1.to_vec();
    mutation.value = v1.to_vec();
    let mut req = PrewriteRequest::default();
    req.set_context(ctx_p3);
    req.set_mutations(vec![mutation].into());
    req.set_start_version(start_ts);
    req.try_one_pc = true;
    req.set_primary_lock(k1.to_vec());

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env.clone()).connect(&cluster.sim.rl().get_addr(p3.get_store_id()));
    let client_p3 = TikvClient::new(channel);
    fail::cfg("on_apply_write_cmd", "sleep(2000)").unwrap();
    client_p3.kv_prewrite(&req).unwrap();

    // The apply is blocked on leader, so the read index request with max ts should
    // see the memory lock as it would be dropped after finishing apply.
    let channel = ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(p2.get_store_id()));
    let client_p2 = TikvClient::new(channel);
    let mut req = GetRequest::new();
    req.key = k1.to_vec();
    req.version = u64::MAX;
    ctx_p2.replica_read = true;
    req.set_context(ctx_p2);
    let resp = client_p2.kv_get(&req).unwrap();
    assert!(resp.region_error.is_none());
    assert_eq!(resp.error.unwrap().locked.unwrap().lock_version, start_ts);
    fail::remove("on_apply_write_cmd");
}
fn borrowing_with_duplication() -> Result<()> {
    wasmtime::component::bindgen!({
        inline: "
        package inline:inline;
        world test {
            export lists: interface {
                foo: func(a: list<list<string>>) -> list<list<string>>;
            }

            export thing-in: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                bar: func(a: thing);
            }

            export thing-in-and-out: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                baz: func(a: thing) -> thing;
            }
        }",
        ownership: Borrowing {
            duplicate_if_necessary: true
        }
    });

    impl PartialEq for exports::thing_in::Thing<'_> {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    impl PartialEq for exports::thing_in_and_out::ThingResult {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    let engine = engine();
    let component = Component::new(&engine, component())?;

    let linker = Linker::new(&engine);
    let mut store = Store::new(&engine, ());
    let (test, _) = Test::instantiate(&mut store, &component, &linker)?;

    let value = &[&["a", "b"] as &[_]] as &[_];
    assert_eq!(value, test.lists().call_foo(&mut store, value)?);

    let value = exports::thing_in::Thing {
        name: "thing 1",
        value: &["some value", "another value"],
    };
    test.thing_in().call_bar(&mut store, value)?;

    let value = exports::thing_in_and_out::ThingParam {
        name: "thing 1",
        value: &["some value", "another value"],
    };
    assert_eq!(
        exports::thing_in_and_out::ThingResult {
            name: "thing 1".to_owned(),
            value: vec!["some value".to_owned(), "another value".to_owned()],
        },
        test.thing_in_and_out().call_baz(&mut store, value)?
    );

    Ok(())
}
fn test_sst_recovery_basic() {
    let (mut cluster, pd_client, engine1) = create_tikv_cluster_with_one_node_damaged();

    // Test that only sst recovery can delete the sst file, remove peer don't delete
    // it.
    fail::cfg("sst_recovery_before_delete_files", "pause").unwrap();

    let store_meta = cluster.store_metas.get(&1).unwrap().clone();
    std::thread::sleep(CHECK_DURATION);
    assert_eq!(
        store_meta
            .lock()
            .unwrap()
            .get_all_damaged_region_ids()
            .len(),
        2
    );

    // Remove peers for safe deletion of files in sst recovery.
    let region = cluster.get_region(b"2");
    let peer = find_peer(&region, 1).unwrap();
    pd_client.must_remove_peer(region.id, peer.clone());
    let region = cluster.get_region(b"4");
    let peer = find_peer(&region, 1).unwrap();
    pd_client.must_remove_peer(region.id, peer.clone());

    // Read from other store must success.
    assert_eq!(cluster.must_get(b"4").unwrap(), b"val");

    std::thread::sleep(CHECK_DURATION);

    must_get_equal(&engine1, b"1", b"val");
    must_get_equal(&engine1, b"7", b"val");
    assert_corruption(engine1.get_value(b"z4"));

    fail::remove("sst_recovery_before_delete_files");
    std::thread::sleep(CHECK_DURATION);

    must_get_equal(&engine1, b"1", b"val");
    must_get_equal(&engine1, b"7", b"val");
    assert!(engine1.get_value(b"z4").unwrap().is_none());

    // Damaged file has been deleted.
    let files = engine1.as_inner().get_live_files();
    assert_eq!(files.get_files_count(), 2);
    assert_eq!(store_meta.lock().unwrap().damaged_ranges.len(), 0);

    // only store 1 remove peer so key "4" should be accessed by cluster.
    assert_eq!(cluster.must_get(b"4").unwrap(), b"val");
}
fn test_migrate_replication_mode() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.pd_client.disable_default_operator();
    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(50);
    cluster.cfg.raft_store.raft_log_gc_threshold = 10;
    cluster.add_label(1, "zone", "ES");
    cluster.add_label(2, "zone", "ES");
    cluster.add_label(3, "zone", "WS");
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.add_send_filter(IsolationFilterFactory::new(2));
    cluster.must_put(b"k1", b"v0");
    // Non exists label key can't tolerate any node unavailable.
    cluster.pd_client.configure_dr_auto_sync("host");
    thread::sleep(Duration::from_millis(100));
    let region = cluster.get_region(b"k1");
    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_put_cf_cmd("default", b"k2", b"v2")],
        false,
    );
    request.mut_header().set_peer(new_peer(1, 1));
    let (cb, mut rx) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, request, cb)
        .unwrap();
    assert_eq!(
        rx.recv_timeout(Duration::from_millis(100)),
        Err(future::RecvTimeoutError::Timeout)
    );
    must_get_none(&cluster.get_engine(1), b"k2");
    let state = cluster.pd_client.region_replication_status(region.get_id());
    assert_eq!(state.state_id, 1);
    assert_eq!(state.state, RegionReplicationState::SimpleMajority);

    // Correct label key should resume committing log
    cluster.pd_client.configure_dr_auto_sync("zone");
    rx.recv_timeout(Duration::from_millis(100)).unwrap();
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
    thread::sleep(Duration::from_millis(100));
    let state = cluster.pd_client.region_replication_status(region.get_id());
    assert_eq!(state.state_id, 2);
    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);
}
fn stream_write_reports_underlying_io_error_before_plaintext_processed() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);
    do_handshake(&mut client, &mut server);

    let mut pipe = FailsWrites {
        errkind: io::ErrorKind::ConnectionAborted,
        after: 0,
    };
    client
        .writer()
        .write_all(b"hello")
        .unwrap();
    let mut client_stream = Stream::new(&mut client, &mut pipe);
    let rc = client_stream.write(b"world");
    assert!(rc.is_err());
    let err = rc.err().unwrap();
    assert_eq!(err.kind(), io::ErrorKind::ConnectionAborted);
}
fn test_ceil_log2_pow5() {
    assert_eq!(1, ceil_log2_pow5(0));
    assert_eq!(3, ceil_log2_pow5(1));
    assert_eq!(5, ceil_log2_pow5(2));
    assert_eq!(7, ceil_log2_pow5(3));
    assert_eq!(10, ceil_log2_pow5(4));
    assert_eq!(8192, ceil_log2_pow5(3528));
}
fn call_array_to_native() -> Result<()> {
    let mut store = Store::<()>::default();
    let func = Func::wrap(&mut store, |a: i32, b: i32, c: i32| -> (i32, i32, i32) {
        (a * 10, b * 10, c * 10)
    });
    let mut results = [Val::I32(0), Val::I32(0), Val::I32(0)];
    func.call(
        &mut store,
        &[Val::I32(10), Val::I32(20), Val::I32(30)],
        &mut results,
    )?;
    assert_eq!(results[0].i32(), Some(100));
    assert_eq!(results[1].i32(), Some(200));
    assert_eq!(results[2].i32(), Some(300));
    Ok(())
}
fn cover() {
    assert_eq!(range(1..2).cover(range(2..3)), range(1..3));
    assert_eq!(range(1..5).cover(range(2..3)), range(1..5));
    assert_eq!(range(1..2).cover(range(4..5)), range(1..5));
}
fn into_header_name() {
    let mut m = HeaderMap::new();
    m.insert(HOST, "localhost".parse().unwrap());
    m.insert(&ACCEPT, "*/*".parse().unwrap());
    m.insert("connection", "keep-alive".parse().unwrap());

    m.append(LOCATION, "/".parse().unwrap());
    m.append(&VIA, "bob".parse().unwrap());
    m.append("transfer-encoding", "chunked".parse().unwrap());

    assert_eq!(m.len(), 6);
}
fn test_writer_indent_cdata() -> Result<()> {
    let txt = include_str!("../tests/documents/test_writer_indent_cdata.xml");
    let mut reader = Reader::from_str(txt);
    reader.trim_text(true);
    let mut writer = Writer::new_with_indent(Cursor::new(Vec::new()), b' ', 4);
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(result, txt.as_bytes());

    Ok(())
}
fn wasm_flags_without_subcommand() -> Result<()> {
    let output = get_wasmtime_command()?
        .current_dir("tests/all/cli_tests/")
        .arg("print-arguments.wat")
        .arg("-foo")
        .arg("bar")
        .output()?;
    assert!(output.status.success());
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "\
            print-arguments.wat\n\
            -foo\n\
            bar\n\
        "
    );
    Ok(())
}
fn high_latency_handshake() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    pair.latency = Duration::from_micros(200 * 1000);
    let (client_ch, server_ch) = pair.connect();
    assert_eq!(pair.client_conn_mut(client_ch).bytes_in_flight(), 0);
    assert_eq!(pair.server_conn_mut(server_ch).bytes_in_flight(), 0);
    assert!(pair.client_conn_mut(client_ch).using_ecn());
    assert!(pair.server_conn_mut(server_ch).using_ecn());
}
fn quick_test() {
    let source = r#"{
        "javascript": {
            "formatter": {
                "overrides": [
                {}]
            }
        }
    }"#;
    let result = deserialize_from_json_str::<Configuration>(source, JsonParserOptions::default());

    dbg!(result.diagnostics());
    assert!(!result.has_errors());
}
fn memory_init() -> Result<()> {
    let mut pool = crate::small_pool_config();
    pool.memory_pages(2).table_elements(0);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));

    let engine = Engine::new(&config)?;

    let module = Module::new(
        &engine,
        r#"
            (module
                (memory (export "m") 2)
                (data (i32.const 65530) "this data spans multiple pages")
                (data (i32.const 10) "hello world")
            )
        "#,
    )?;

    let mut store = Store::new(&engine, ());
    let instance = Instance::new(&mut store, &module, &[])?;
    let memory = instance.get_memory(&mut store, "m").unwrap();

    assert_eq!(
        &memory.data(&store)[65530..65560],
        b"this data spans multiple pages"
    );
    assert_eq!(&memory.data(&store)[10..21], b"hello world");

    Ok(())
}
fn i16_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0i16.to_lexical(&mut buffer));
    assert_eq!(b"1", 1i16.to_lexical(&mut buffer));
    assert_eq!(b"5", 5i16.to_lexical(&mut buffer));
    assert_eq!(b"32767", 32767i16.to_lexical(&mut buffer));
    assert_eq!(b"-32768", (32768u16 as i16).to_lexical(&mut buffer));
    assert_eq!(b"-1", (65535u16 as i16).to_lexical(&mut buffer));
    assert_eq!(b"-1", (-1i16).to_lexical(&mut buffer));
}
fn test_unsafe_recovery_demotion_reentrancy() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[2]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    {
        let put = new_put_cmd(b"k2", b"v2");
        let req = new_request(
            region.get_id(),
            region.get_region_epoch().clone(),
            vec![put],
            true,
        );
        // marjority is lost, can't propose command successfully.
        cluster
            .call_command_on_leader(req, Duration::from_millis(10))
            .unwrap_err();
    }

    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    // Construct recovery plan.
    let mut plan = pdpb::RecoveryPlan::default();

    let to_be_removed: Vec<metapb::Peer> = region
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);

    // Blocks the raft apply process on store 1 entirely .
    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("on_handle_apply_store_1", move || {
        let _ = apply_released_rx.recv();
    })
    .unwrap();

    // Triggers the unsafe recovery plan execution.
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());
    cluster.must_send_store_heartbeat(nodes[0]);

    // No store report is sent, since there are peers have unapplied entries.
    for _ in 0..10 {
        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);
        sleep_ms(100);
    }

    // Send the plan again.
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    // Unblocks the apply process.
    drop(apply_released_tx);

    let mut demoted = false;
    for _ in 0..10 {
        let region_in_pd = block_on(pd_client.get_region_by_id(region.get_id()))
            .unwrap()
            .unwrap();
        assert_eq!(region_in_pd.get_peers().len(), 3);
        demoted = region_in_pd
            .get_peers()
            .iter()
            .filter(|peer| peer.get_store_id() != nodes[0])
            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);
        sleep_ms(100);
    }
    assert_eq!(demoted, true);
    fail::remove("on_handle_apply_store_1");
}
fn test_square_brackets_over_db_schema_table_name() {
    let select = redshift().verified_only_select("SELECT [col1] FROM [test_schema].[test_table]");
    assert_eq!(
        select.projection[0],
        SelectItem::UnnamedExpr(Expr::Identifier(Ident {
            value: "col1".to_string(),
            quote_style: Some('[')
        })),
    );
    assert_eq!(
        select.from[0],
        TableWithJoins {
            relation: TableFactor::Table {
                name: ObjectName(vec![
                    Ident {
                        value: "test_schema".to_string(),
                        quote_style: Some('[')
                    },
                    Ident {
                        value: "test_table".to_string(),
                        quote_style: Some('[')
                    }
                ]),
                alias: None,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            joins: vec![],
        }
    );
}
fn pragma_eq_style() {
    let sql = "PRAGMA cache_size = 10";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::Pragma {
            name,
            value: Some(val),
            is_eq: true,
        } => {
            assert_eq!("cache_size", name.to_string());
            assert_eq!("10", val.to_string());
        }
        _ => unreachable!(),
    }
}
fn test_do_not_use_unified_readpool_with_legacy_config() {
    let content = r#"
        [readpool.storage]
        normal-concurrency = 1

        [readpool.coprocessor]
        normal-concurrency = 1
    "#;
    let cfg: TikvConfig = toml::from_str(content).unwrap();
    assert!(!cfg.readpool.is_unified_pool_enabled());
}
fn emit_diagnostic_for_rome_json() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let configuration = r#"{ "linter": { "enabled": true } }"#;

    let configuration_path = Path::new("rome.json");
    fs.insert(configuration_path.into(), configuration.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("migrate")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "emit_diagnostic_for_rome_json",
        fs,
        console,
        result,
    ));
}
fn u64_decimal_test() {
    assert_eq!(Ok(0), u64::from_lexical(b"0"));
    assert_eq!(Ok(9223372036854775807), u64::from_lexical(b"9223372036854775807"));
    assert_eq!(Ok(9223372036854775808), u64::from_lexical(b"9223372036854775808"));
    assert_eq!(Ok(18446744073709551615), u64::from_lexical(b"18446744073709551615"));
    assert_eq!(Err(Error::InvalidDigit(0)), u64::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), u64::from_lexical(b"1a"));
}
fn test_cp_arg_update_older_dest_older_than_src() {
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_dest_older_file1";
    let new = "test_cp_arg_update_dest_older_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(new)
        .arg(old)
        .arg("--update=older")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(old), "new content\n");
}
fn test_read_leader_in_lease() {
    let count = 3;
    let mut cluster = new_server_cluster(0, count);
    cluster.run();

    let k1 = b"k1";
    let (k2, v2) = (b"k2", b"v2");

    // make sure leader has been elected.
    assert_eq!(cluster.must_get(k1), None);

    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let mut storage = cluster.sim.rl().storages[&leader.get_id()].clone();

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader.clone());
    let snap_ctx = SnapContext {
        pb_ctx: &ctx,
        ..Default::default()
    };

    // write some data
    assert_none(snap_ctx.clone(), &mut storage, k2);
    must_put(&ctx, &storage, k2, v2);

    // isolate leader
    cluster.add_send_filter(IsolationFilterFactory::new(leader.get_store_id()));

    // leader still in lease, check if can read on leader
    assert_eq!(can_read(snap_ctx, &mut storage, k2, v2), true);
}
fn test_mv_move_file_into_dir_with_target_arg() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_mv_move_file_into_dir_with_target_arg_dir";
    let file = "test_mv_move_file_into_dir_with_target_arg_file";

    at.mkdir(dir);
    at.touch(file);

    ucmd.arg("--target")
        .arg(dir)
        .arg(file)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn bindgen_test_layout_max_align_t() {
    const UNINIT: ::std::mem::MaybeUninit<max_align_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<max_align_t>(),
        32usize,
        concat!("Size of: ", stringify!(max_align_t))
    );
    assert_eq!(
        ::std::mem::align_of::<max_align_t>(),
        16usize,
        concat!("Alignment of ", stringify!(max_align_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce1) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce1)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).__clang_max_align_nonce2) as usize - ptr as usize },
        16usize,
        concat!(
            "Offset of field: ",
            stringify!(max_align_t),
            "::",
            stringify!(__clang_max_align_nonce2)
        )
    );
}
fn roundtrip_value_float_with_decimals() {
    let v: ron::Value = ron::from_str("1.0").unwrap();

    assert_eq!(v, ron::Value::Number(1.0_f64.into()));

    let ser = ron::ser::to_string(&v).unwrap();

    let roundtrip = ron::from_str(&ser).unwrap();

    assert_eq!(v, roundtrip);
}
fn path() {
    let db = default_engine();
    let path = db.tempdir.path().to_str().unwrap();
    assert_eq!(db.engine.path(), path);
}
fn test_value_serialization() {
    // make sure if we serialize to json we get regular values
    assert_eq!(serde_json::to_string(&Value::UNDEFINED).unwrap(), "null");
    assert_eq!(
        serde_json::to_string(&Value::from_safe_string("foo".to_string())).unwrap(),
        "\"foo\""
    );
}
fn range_lifetime() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<&str, &str> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();

    let mut iter = {
        let start = "hello".to_string();
        table.range::<&str>(start.as_str()..).unwrap()
    };
    assert_eq!(iter.next().unwrap().unwrap().1.value(), "world");
    assert!(iter.next().is_none());
}
fn store_with_context() -> Result<()> {
    struct Ctx {
        called: bool,
    }

    let engine = Engine::default();
    let mut linker = Linker::new(&engine);

    linker.func_wrap("", "", |mut caller: Caller<'_, Ctx>| {
        caller.data_mut().called = true;
    })?;

    let mut store = Store::new(&engine, Ctx { called: false });

    let f = linker.get(&mut store, "", "").unwrap().into_func().unwrap();
    f.call(&mut store, &[], &mut [])?;

    assert!(store.data().called);

    Ok(())
}
fn test_snap_with_invalid_parameter() {
    let cluster = Cluster::default();
    let router = &cluster.routers[0];
    std::thread::sleep(std::time::Duration::from_millis(200));
    let region_id = 2;
    let mut req = router.new_request_for(region_id);
    let mut request_inner = Request::default();
    request_inner.set_cmd_type(CmdType::Snap);
    req.mut_requests().push(request_inner);

    // store_id is incorrect;
    let mut invalid_req = req.clone();
    invalid_req.mut_header().set_peer(new_peer(2, 3));
    let res = router.query(region_id, invalid_req).unwrap();
    let error_resp = res.response().unwrap();
    assert!(error_resp.get_header().has_error());

    // run again, with incorrect peer_id
    let mut invalid_req = req.clone();
    invalid_req.mut_header().set_peer(new_peer(1, 4));
    let res = router.query(region_id, invalid_req).unwrap();
    let error_resp = res.response().unwrap();
    assert!(error_resp.get_header().has_error());

    // run with stale term
    let mut invalid_req = req.clone();
    invalid_req.mut_header().set_term(1);
    let res = router.query(region_id, invalid_req).unwrap();
    let error_resp = res.response().unwrap();
    assert!(error_resp.get_header().has_error());

    // run with stale read
    let mut invalid_req = req.clone();
    invalid_req
        .mut_header()
        .set_flags(WriteBatchFlags::STALE_READ.bits());
    let res = router.query(region_id, invalid_req).unwrap();
    let error_resp = res.response().unwrap();
    assert!(error_resp.get_header().has_error());

    // run again with invalid region_epoch
    let mut invalid_req = req.clone();
    let invalid_ver = req.get_header().get_region_epoch().get_version() + 1;
    invalid_req
        .mut_header()
        .mut_region_epoch()
        .set_version(invalid_ver);
    let res = router.query(region_id, invalid_req).unwrap();
    let error_resp = res.response().unwrap();
    assert!(error_resp.get_header().has_error());
}
fn test_scheduler_leader_change_twice() {
    let snapshot_fp = "scheduler_async_snapshot_finish";
    let mut cluster = new_server_cluster(0, 2);
    cluster.run();
    let region0 = cluster.get_region(b"");
    let peers = region0.get_peers();
    cluster.must_transfer_leader(region0.get_id(), peers[0].clone());
    let engine0 = cluster.sim.rl().storages[&peers[0].get_id()].clone();
    let storage0 =
        TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine0, MockLockManager::new())
            .build()
            .unwrap();

    let mut ctx0 = Context::default();
    ctx0.set_region_id(region0.get_id());
    ctx0.set_region_epoch(region0.get_region_epoch().clone());
    ctx0.set_peer(peers[0].clone());
    let (prewrite_tx, prewrite_rx) = channel();
    fail::cfg(snapshot_fp, "pause").unwrap();
    storage0
        .sched_txn_command(
            commands::Prewrite::new(
                vec![Mutation::make_put(Key::from_raw(b"k"), b"v".to_vec())],
                b"k".to_vec(),
                10.into(),
                0,
                false,
                0,
                TimeStamp::default(),
                TimeStamp::default(),
                None,
                false,
                AssertionLevel::Off,
                ctx0,
            ),
            Box::new(move |res: storage::Result<_>| {
                prewrite_tx.send(res).unwrap();
            }),
        )
        .unwrap();
    // Sleep to make sure the failpoint is triggered.
    thread::sleep(Duration::from_millis(2000));
    // Transfer leader twice, then unblock snapshot.
    cluster.must_transfer_leader(region0.get_id(), peers[1].clone());
    cluster.must_transfer_leader(region0.get_id(), peers[0].clone());
    fail::remove(snapshot_fp);

    match prewrite_rx.recv_timeout(Duration::from_secs(5)).unwrap() {
        Err(Error(box ErrorInner::Txn(TxnError(box TxnErrorInner::Engine(KvError(
            box KvErrorInner::Request(ref e),
        ))))))
        | Err(Error(box ErrorInner::Txn(TxnError(box TxnErrorInner::Mvcc(MvccError(
            box MvccErrorInner::Kv(KvError(box KvErrorInner::Request(ref e))),
        ))))))
        | Err(Error(box ErrorInner::Kv(KvError(box KvErrorInner::Request(ref e))))) => {
            assert!(e.has_stale_command(), "{:?}", e);
        }
        res => {
            panic!("expect stale command, but got {:?}", res);
        }
    }
}
fn ci_errors_for_all_disabled_checks() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CI_CONFIGURATION.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), UNFORMATTED_AND_INCORRECT.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                ("--linter-enabled=false"),
                ("--formatter-enabled=false"),
                ("--organize-imports-enabled=false"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED_AND_INCORRECT);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_errors_for_all_disabled_checks",
        fs,
        console,
        result,
    ));
}
pub fn test_wildcard() {
    let err = req_err("");
    assert_to_string(
        err,
        "unexpected end of input while parsing major version number",
    );

    let ref r = req("*");
    assert_match_all(r, &["0.9.1", "2.9.0", "0.0.9", "1.0.1", "1.1.1"]);
    assert_match_none(r, &["1.0.0-pre"]);

    for s in &["x", "X"] {
        assert_eq!(*r, req(s));
    }

    let ref r = req("1.*");
    assert_match_all(r, &["1.2.0", "1.2.1", "1.1.1", "1.3.0"]);
    assert_match_none(r, &["0.0.9", "1.2.0-pre"]);

    for s in &["1.x", "1.X", "1.*.*"] {
        assert_eq!(*r, req(s));
    }

    let ref r = req("1.2.*");
    assert_match_all(r, &["1.2.0", "1.2.2", "1.2.4"]);
    assert_match_none(r, &["1.9.0", "1.0.9", "2.0.1", "0.1.3", "1.2.2-pre"]);

    for s in &["1.2.x", "1.2.X"] {
        assert_eq!(*r, req(s));
    }
}
fn test_consistency_after_lease_pass() {
    let mut cluster = new_server_cluster(0, 3);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    cluster.run();
    let leader = new_peer(1, 1);
    cluster.must_transfer_leader(1, leader);

    // Create clients.
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(Arc::clone(&env)).connect(&cluster.sim.rl().get_addr(1));
    let client = TikvClient::new(channel);

    let region = cluster.get_region(&b"key1"[..]);
    let region_id = region.id;
    let leader = cluster.leader_of_region(region_id).unwrap();

    let mut ctx = Context::default();
    ctx.set_region_id(region_id);
    ctx.set_peer(leader.clone());
    ctx.set_region_epoch(region.get_region_epoch().clone());

    must_raw_put(&client, ctx.clone(), b"key1".to_vec(), b"value1".to_vec());
    must_get_equal(&cluster.get_engine(1), b"key1", b"value1");

    // Ensure the request is executed by the local reader
    fail::cfg("localreader_before_redirect", "panic").unwrap();

    // Lease read works correctly
    assert_eq!(
        must_raw_get(&client, ctx.clone(), b"key1".to_vec()).unwrap(),
        b"value1".to_vec()
    );

    // we pause just after pass the lease check, and then remove the peer. We can
    // still read the relevant value as we should have already got the snapshot when
    // passing the lease check.
    fail::cfg("after_pass_lease_check", "pause").unwrap();

    let mut get_req = RawGetRequest::default();
    get_req.set_context(ctx);
    get_req.key = b"key1".to_vec();
    let mut receiver = client.raw_get_async(&get_req).unwrap();

    thread::sleep(Duration::from_millis(200));

    let mut peer = leader.clone();
    cluster.must_transfer_leader(1, new_peer(2, 2));
    pd_client.must_remove_peer(region_id, leader);
    peer.id = 1000;
    // After we pass the lease check, we should have got the snapshot, so the data
    // that the region contains cannot be deleted.
    // So we need to add the new peer for this region and stop before applying the
    // snapshot so that the old data will be deleted and the snapshot data has not
    // been written.
    fail::cfg("apply_snap_cleanup_range", "pause").unwrap();
    pd_client.must_add_peer(region_id, peer);

    // Wait for data to be cleaned
    must_get_none(&cluster.get_engine(1), b"key1");
    fail::cfg("after_pass_lease_check", "off").unwrap();

    assert_eq!(b"value1", receiver.receive_sync().unwrap().1.get_value());
}
fn test_byte_buf_ser() {
    let bytes = ByteBuf::new();
    assert_eq!(to_string(&bytes).unwrap(), "[]".to_string());

    let bytes = ByteBuf::from(vec![1, 2, 3]);
    assert_eq!(to_string(&bytes).unwrap(), "[1,2,3]".to_string());
}
fn parse_set_global_tag() {
    let ast = parse("{% set_global hello = utcnow() %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Set(
            WS::default(),
            Set {
                key: "hello".to_string(),
                value: Expr::new(ExprVal::FunctionCall(FunctionCall {
                    name: "utcnow".to_string(),
                    args: HashMap::new(),
                },)),
                global: true,
            },
        )
    );
}
fn test_quick_check() {
    use unicode_normalization::__test_api::quick_check;
    for test in NORMALIZATION_TESTS {
        assert!(quick_check::is_nfc(test.nfc));
        assert!(quick_check::is_nfd(test.nfd));
        assert!(quick_check::is_nfkc(test.nfkc));
        assert!(quick_check::is_nfkd(test.nfkd));
        if test.nfc != test.nfd {
            assert!(!quick_check::is_nfc(test.nfd));
            assert!(!quick_check::is_nfd(test.nfc));
        }
        if test.nfkc != test.nfc {
            assert!(!quick_check::is_nfkc(test.nfc));
            assert!(quick_check::is_nfc(test.nfkc));
        }
        if test.nfkd != test.nfd {
            assert!(!quick_check::is_nfkd(test.nfd));
            assert!(quick_check::is_nfd(test.nfkd));
        }
    }
}
async fn extended_connect_protocol_disabled_by_default() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;

        assert_eq!(settings.is_extended_connect_protocol_enabled(), None);

        client
            .send_frame(
                frames::headers(1)
                    .request("CONNECT", "http://bread/baguette")
                    .protocol("the-bread-protocol"),
            )
            .await;

        client.recv_frame(frames::reset(1).protocol_error()).await;
    };

    let srv = async move {
        let mut srv = server::handshake(io).await.expect("handshake");

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn test_install_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "target_dir";
    let file1 = "source_file1";
    let file2 = "source_file2";

    at.touch(file1);
    at.touch(file2);
    at.mkdir(dir);
    ucmd.arg(file1)
        .arg(file2)
        .arg(&format!("--target-directory={dir}"))
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
    assert!(at.file_exists(format!("{dir}/{file1}")));
    assert!(at.file_exists(format!("{dir}/{file2}")));
}
fn is_fast_path_test() {
    let mut number = Number {
        exponent: -4,
        mantissa: 12345,
        many_digits: false,
    };
    assert_eq!(number.is_fast_path::<f32>(), true);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.exponent = -15;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.exponent = -25;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), false);

    number.exponent = 25;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.exponent = 36;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.exponent = 38;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), false);

    number.mantissa = 1 << 25;
    number.exponent = 0;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.mantissa = 1 << 54;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), false);

    number.mantissa = 1 << 52;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), true);

    number.many_digits = true;
    assert_eq!(number.is_fast_path::<f32>(), false);
    assert_eq!(number.is_fast_path::<f64>(), false);
}
fn enum_unit_variant() {
    let mut key = CacheKeyHasher::new();

    let variant = Enum::Unit;
    variant.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    variant.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn print_incomplete_qpath() {
    // qpath with `as` token
    let mut ty: TypePath = parse_quote!(<Self as A>::Q);
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self as A > :: Q`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self as A > ::`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self >`)
    "###);
    assert!(ty.path.segments.pop().is_none());

    // qpath without `as` token
    let mut ty: TypePath = parse_quote!(<Self>::A::B);
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self > :: A :: B`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self > :: A ::`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`< Self > ::`)
    "###);
    assert!(ty.path.segments.pop().is_none());

    // normal path
    let mut ty: TypePath = parse_quote!(Self::A::B);
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`Self :: A :: B`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`Self :: A ::`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(`Self ::`)
    "###);
    assert!(ty.path.segments.pop().is_some());
    snapshot!(ty.to_token_stream(), @r###"
    TokenStream(``)
    "###);
    assert!(ty.path.segments.pop().is_none());
}
fn test_unsafe_recovery_demote_non_exist_voters() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);

    confirm_quorum_is_lost(&mut cluster, &region);
    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    let mut peer = metapb::Peer::default();
    peer.set_id(12345);
    peer.set_store_id(region.get_id());
    peer.set_role(metapb::PeerRole::Voter);
    demote.mut_failed_voters().push(peer);
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    let report = store_report.unwrap();
    let peer_reports = report.get_peer_reports();
    assert_eq!(peer_reports.len(), 1);
    let reported_region = peer_reports[0].get_region_state().get_region();
    assert_eq!(reported_region.get_id(), region.get_id());
    assert_eq!(reported_region.get_peers().len(), 3);
    let demoted = reported_region
        .get_peers()
        .iter()
        .any(|peer| peer.get_role() != metapb::PeerRole::Voter);
    assert_eq!(demoted, false);

    let region_in_pd = block_on(pd_client.get_region_by_id(region.get_id()))
        .unwrap()
        .unwrap();
    assert_eq!(region_in_pd.get_peers().len(), 3);
    let demoted = region_in_pd
        .get_peers()
        .iter()
        .any(|peer| peer.get_role() != metapb::PeerRole::Voter);
    assert_eq!(demoted, false);
}
fn render_simple_string() {
    let result = render_template("<h1>Hello world</h1>", &Context::new());
    assert_eq!(result.unwrap(), "<h1>Hello world</h1>".to_owned());
}
fn test_multiple_of_input_chunk() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "multiple_of_input_chunk";
    RandomFile::new(&at, name).add_bytes(16 * 1024);
    ucmd.args(&["-b", "8K", name, "b"]).succeeds();

    let glob = Glob::new(&at, ".", r"b[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 2);
    for filename in glob.collect() {
        assert_eq!(glob.directory.metadata(&filename).len(), 8 * 1024);
    }
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn line_width_parse_errors_negative() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(["format", "--line-width=-1", "file.js"].as_slice()),
    );
    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "line_width_parse_errors_negative",
        fs,
        console,
        result,
    ));
}
fn apply_unsafe_with_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    // last line doesn't have code fix
    let source = "let a = 4;
debugger;
console.log(a);
function f() { arguments; }
";

    let expected = "const a = 4;
console.log(a);
function f() { arguments; }
";

    let test1 = Path::new("test1.js");
    fs.insert(test1.into(), source.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), source.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                test1.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test1)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, expected);
    drop(file);

    content.clear();

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_unsafe_with_error",
        fs,
        console,
        result,
    ));
}
fn extension_alias_throw_error() {
    let f = super::fixture().join("exports-field-and-extension-alias");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        extension_alias: vec![(".js".into(), vec![".ts".into()])],
        fully_specified: true,
        condition_names: vec!["webpack".into(), "default".into()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let fail = [
        // enhanced-resolve has two test cases that are exactly the same here
        // https://github.com/webpack/enhanced-resolve/blob/a998c7d218b7a9ec2461fc4fddd1ad5dd7687485/test/exportsField.test.js#L2976-L3024
        ("should throw error with the `extensionAlias` option", f, "pkg/string.js", ResolveError::ExtensionAlias),
        // TODO: The error is PackagePathNotExported in enhanced-resolve
        // ("should throw error with the `extensionAlias` option", f.clone(), "pkg/string.js", ResolveError::PackagePathNotExported("node_modules/pkg/dist/string.ts".to_string())),
    ];

    for (comment, path, request, error) in fail {
        let resolution = resolver.resolve(&path, request);
        assert_eq!(resolution, Err(error), "{comment} {path:?} {request}");
    }
}
fn incomplete() {
    assert!("/*/".parse::<TokenStream>().is_err());
}
fn static_add2_works() {
    let (mut store, add2, add2_dyn) = setup_add2();
    let add2 = add2.typed::<(i32, i32), i32>(&mut store).unwrap();
    let add2_dyn = add2_dyn.typed::<(i32, i32), i32>(&mut store).unwrap();
    for a in 0..10 {
        for b in 0..10 {
            let expected = a + b;
            assert_eq!(add2.call(&mut store, (a, b)).unwrap(), expected);
            assert_eq!(add2_dyn.call(&mut store, (a, b)).unwrap(), expected);
        }
    }
}
fn ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("--version")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "version_ok",
        fs,
        console,
        result,
    ));
}
fn test_readpool_full() {
    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    fail::cfg("future_pool_spawn_full", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_region_error().has_server_is_busy());
}
fn test_returns_incorrect_type() -> Result<()> {
    const WAT: &str = r#"
    (module
        (import "env" "evil" (func $evil (result i32)))
        (func (export "run") (result i32)
            (call $evil)
        )
    )
    "#;

    let mut store = Store::<()>::default();
    let module = Module::new(store.engine(), WAT)?;

    let callback_func = Func::new(
        &mut store,
        FuncType::new(None, Some(ValType::I32)),
        |_, _, results| {
            // Evil! Returns I64 here instead of promised in the signature I32.
            results[0] = Val::I64(228);
            Ok(())
        },
    );

    let imports = vec![callback_func.into()];
    let instance = Instance::new(&mut store, &module, imports.as_slice())?;

    let run_func = instance
        .get_func(&mut store, "run")
        .expect("expected a run func in the module");

    let mut result = [Val::I32(0)];
    let trap = run_func
        .call(&mut store, &[], &mut result)
        .expect_err("the execution should fail");
    assert!(format!("{:?}", trap).contains("function attempted to return an incompatible value"));
    Ok(())
}
fn parent_macro_cant_access_child_macro_context() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("parent", "{% import \"macros\" as macros %}{{ macros::test_global() }}"),
        ("macros", r#"{% import "moremacros" as moremacros %}{% macro test_global() %}{% set_global value1 = "ACAB" %}{{ moremacros::another_one() }}{{ value1 }}-{{ value2 | default(value="ACAB") }}{% endmacro test_global %}"#),
        ("moremacros", r#"{% macro another_one() %}{% set_global value2 = "1312" %}{% endmacro another_one %}"#)
    ]).unwrap();

    let result = tera.render("parent", &Context::new());
    assert_eq!(result.unwrap(), "ACAB-ACAB".to_string());
}
fn exclude() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-exclude = ["out"]

[format]
exclude = ["test.py", "generated.py"]
"#,
    )?;

    fs::write(
        tempdir.path().join("main.py"),
        r#"
from test import say_hy

if __name__ == "__main__":
    say_hy("dear Ruff contributor")
"#,
    )?;

    // Excluded file but passed to the CLI directly, should be formatted
    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    fs::write(
        tempdir.path().join("generated.py"),
        r#"NUMBERS = [
     0,  1,  2,  3,  4,  5,  6,  7,  8,  9,
    10, 11, 12, 13, 14, 15, 16, 17, 18, 19
]
OTHER = "OTHER"
"#,
    )?;

    let out_dir = tempdir.path().join("out");
    fs::create_dir(&out_dir)?;

    fs::write(out_dir.join("a.py"), "a = a")?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .args(["format", "--no-cache", "--check", "--config"])
        .arg(ruff_toml.file_name().unwrap())
        // Explicitly pass test.py, should be formatted regardless of it being excluded by format.exclude
        .arg(test_path.file_name().unwrap())
        // Format all other files in the directory, should respect the `exclude` and `format.exclude` options
        .arg("."), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    Would reformat: main.py
    Would reformat: test.py
    2 files would be reformatted

    ----- stderr -----
    "###);
    Ok(())
}
fn migrate_detects_new_mtu_and_respects_original_peer_max_udp_payload_size() {
    let _guard = subscribe();

    let client_max_udp_payload_size: u16 = 1400;

    // Set up a client with a max payload size of 1400 (and use the defaults for the server)
    let server_endpoint_config = EndpointConfig::default();
    let server = Endpoint::new(
        Arc::new(server_endpoint_config),
        Some(Arc::new(server_config())),
        true,
    );
    let client_endpoint_config = EndpointConfig {
        max_udp_payload_size: VarInt::from(client_max_udp_payload_size),
        ..EndpointConfig::default()
    };
    let client = Endpoint::new(Arc::new(client_endpoint_config), None, true);
    let mut pair = Pair::new_from_endpoint(client, server);
    pair.mtu = 1300;

    // Connect
    let (client_ch, server_ch) = pair.connect();
    pair.drive();

    // Sanity check: MTUD ran to completion (the numbers differ because binary search stops when
    // changes are smaller than 20, otherwise both endpoints would converge at the same MTU of 1300)
    assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), 1293);
    assert_eq!(pair.server_conn_mut(server_ch).path_mtu(), 1300);

    // Migrate client to a different port (and simulate a higher path MTU)
    pair.mtu = 1500;
    pair.client.addr = SocketAddr::new(
        Ipv4Addr::new(127, 0, 0, 1).into(),
        CLIENT_PORTS.lock().unwrap().next().unwrap(),
    );
    pair.client_conn_mut(client_ch).ping();
    pair.drive();

    // Sanity check: the server saw that the client address was updated
    assert_eq!(
        pair.server_conn_mut(server_ch).remote_address(),
        pair.client.addr
    );

    // MTU detection has successfully run after migrating
    assert_eq!(
        pair.server_conn_mut(server_ch).path_mtu(),
        client_max_udp_payload_size
    );

    // Sanity check: the client keeps the old MTU, because migration is triggered by incoming
    // packets from a different address
    assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), 1293);
}
fn cap_zero() {
    let db = default_engine();
    let mut wb = db.engine.write_batch_with_cap(0);
    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.put(b"f", b"").unwrap();
    wb.write().unwrap();
    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"f").unwrap().is_some());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(0);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.put(b"f", b"").unwrap();
    wb.write().unwrap();
    assert!(
        db.engine
            .get_value(&0_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(
        db.engine
            .get_value(&123_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(
        db.engine
            .get_value(&255_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"f").unwrap().is_some());
}
fn test_symlink_custom_backup_suffix_hyphen_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_custom_backup_suffix";
    let link = "test_symlink_custom_backup_suffix_link";
    let suffix = "-v";

    at.touch(file);
    at.symlink_file(file, link);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let arg = &format!("--suffix={suffix}");
    ucmd.args(&["-b", arg, "-s", file, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file));

    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let backup = &format!("{link}{suffix}");
    assert!(at.is_symlink(backup));
    assert_eq!(at.resolve_link(backup), file);
}
fn dynamic_many_results_works() {
    let (mut store, func) = setup_many_results();
    let mut results = [0; 16].map(Value::I32);
    func.call(&mut store, &[], &mut results).unwrap();
    let mut i = 0;
    let expected = [0; 16].map(|_| {
        let value = Value::I32(i as _);
        i += 1;
        value
    });
    assert_eq!(
        results.map(|result| result.i32().unwrap()),
        expected.map(|expected| expected.i32().unwrap())
    )
}
fn test_check_conf_change() {
    let mut cluster = prepare_cluster();
    run_cluster(&mut cluster);
    let pd_client = cluster.pd_client.clone();
    pd_client.must_remove_peer(1, new_peer(2, 2));
    must_get_none(&cluster.get_engine(2), b"k1");
    cluster.add_send_filter(IsolationFilterFactory::new(2));
    pd_client.must_add_peer(1, new_learner_peer(2, 4));
    let region = cluster.get_region(b"k1");
    // Peer 4 can be promoted as there will be enough quorum alive.
    let cc = new_change_peer_request(ConfChangeType::AddNode, new_peer(2, 4));
    let req = new_admin_request(region.get_id(), region.get_region_epoch(), cc);
    let res = cluster
        .call_command_on_leader(req, Duration::from_secs(3))
        .unwrap();
    assert!(!res.get_header().has_error(), "{:?}", res);
    must_get_none(&cluster.get_engine(2), b"k1");
    cluster.clear_send_filters();
    must_get_equal(&cluster.get_engine(2), b"k1", b"v0");

    pd_client.must_remove_peer(1, new_peer(3, 3));
    must_get_none(&cluster.get_engine(3), b"k1");
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    pd_client.must_add_peer(1, new_learner_peer(3, 5));
    let region = cluster.get_region(b"k1");
    // Peer 5 can not be promoted as there is no enough quorum alive.
    let cc = new_change_peer_request(ConfChangeType::AddNode, new_peer(3, 5));
    let req = new_admin_request(region.get_id(), region.get_region_epoch(), cc);
    let res = cluster
        .call_command_on_leader(req, Duration::from_secs(3))
        .unwrap();
    assert!(
        res.get_header()
            .get_error()
            .get_message()
            .contains("promoted commit index"),
        "{:?}",
        res
    );
}
fn wrong_import_numbers() -> Result<()> {
    let mut store = Store::<()>::default();
    let module = Module::new(store.engine(), r#"(module (import "" "" (func)))"#)?;

    assert!(Instance::new(&mut store, &module, &[]).is_err());
    let func = Func::wrap(&mut store, || {});
    assert!(Instance::new(&mut store, &module, &[func.clone().into(), func.into()]).is_err());
    Ok(())
}
fn test_eof_after_as() {
    let res = parse_sql_statements("SELECT foo AS");
    assert_eq!(
        ParserError::ParserError("Expected an identifier after AS, found: EOF".to_string()),
        res.unwrap_err()
    );

    let res = parse_sql_statements("SELECT 1 FROM foo AS");
    assert_eq!(
        ParserError::ParserError("Expected an identifier after AS, found: EOF".to_string()),
        res.unwrap_err()
    );
}
fn rust_panic_start_function() -> Result<()> {
    let mut store = Store::<()>::default();
    let binary = wat::parse_str(
        r#"
            (module $a
                (import "" "" (func $foo))
                (start $foo)
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let sig = FuncType::new(None, None);
    let func = Func::new(&mut store, sig, |_, _, _| panic!("this is a panic"));
    let err = panic::catch_unwind(AssertUnwindSafe(|| {
        drop(Instance::new(&mut store, &module, &[func.into()]));
    }))
    .unwrap_err();
    assert_eq!(err.downcast_ref::<&'static str>(), Some(&"this is a panic"));

    let func = Func::wrap(&mut store, || panic!("this is another panic"));
    let err = panic::catch_unwind(AssertUnwindSafe(|| {
        drop(Instance::new(&mut store, &module, &[func.into()]));
    }))
    .unwrap_err();
    assert_eq!(
        err.downcast_ref::<&'static str>(),
        Some(&"this is another panic")
    );
    Ok(())
}
fn u128_digit_count_test() {
    assert_eq!(u128::digit_count(u128::MAX), 39);
}
fn parse_category_test() {
  let ini_file = &b"[category]

parameter=value
key = value2"[..];

  let ini_without_category = &b"\n\nparameter=value
key = value2"[..];

  let res = category(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, o)) => println!("i: {:?} | o: {:?}", str::from_utf8(i), o),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_category, "category")));
}
fn restore_generates_same_descriptors_with_passphrase() {
  let passphrase = "foo";
  let (mnemonic, descriptors) = {
    let rpc_server = test_bitcoincore_rpc::spawn();

    let create::Output { mnemonic, .. } =
      CommandBuilder::new(["wallet", "create", "--passphrase", passphrase])
        .rpc_server(&rpc_server)
        .run_and_deserialize_output();

    (mnemonic, rpc_server.descriptors())
  };

  let rpc_server = test_bitcoincore_rpc::spawn();

  CommandBuilder::new([
    "wallet",
    "restore",
    "--passphrase",
    passphrase,
    &mnemonic.to_string(),
  ])
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Empty>();

  assert_eq!(rpc_server.descriptors(), descriptors);
}
fn test_cdc_rawkv_basic() {
    let mut suite = TestSuite::new(1, ApiVersion::V2);

    // rawkv
    let mut req = suite.new_changedata_request(1);
    req.set_kv_api(ChangeDataRequestKvApi::RawKv);
    let (mut req_tx, _event_feed_wrap, receive_event) =
        new_event_feed(suite.get_region_cdc_client(1));
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();

    let event = receive_event(false);
    event.events.into_iter().for_each(|e| {
        match e.event.unwrap() {
            // Even if there is no write,
            // it should always outputs an Initialized event.
            Event_oneof_event::Entries(es) => {
                assert!(es.entries.len() == 1, "{:?}", es);
                let e = &es.entries[0];
                assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
            }
            other => panic!("unknown event {:?}", other),
        }
    });
    // Sleep a while to make sure the stream is registered.
    sleep_ms(1000);
    // There must be a delegate.
    let scheduler = suite.endpoints.values().next().unwrap().scheduler();
    scheduler
        .schedule(Task::Validate(Validate::Region(
            1,
            Box::new(|delegate| {
                let d = delegate.unwrap();
                assert_eq!(d.downstreams().len(), 1);
            }),
        )))
        .unwrap();

    // If tikv enable ApiV2, raw key needs to start with 'r';
    let (k, v) = (b"rkey1".to_vec(), b"value".to_vec());
    suite.must_kv_put(1, k, v);
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1, "{:?}", events);

    match events.pop().unwrap().event.unwrap() {
        Event_oneof_event::Entries(entries) => {
            assert_eq!(entries.entries.len(), 1);
            assert_eq!(entries.entries[0].get_type(), EventLogType::Committed);
        }
        other => panic!("unknown event {:?}", other),
    }

    // boundary case
    let (k, v) = (b"r\0".to_vec(), b"value".to_vec());
    suite.must_kv_put(1, k, v);
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1, "{:?}", events);

    match events.pop().unwrap().event.unwrap() {
        Event_oneof_event::Entries(entries) => {
            assert_eq!(entries.entries.len(), 1);
            assert_eq!(entries.entries[0].get_type(), EventLogType::Committed);
        }
        other => panic!("unknown event {:?}", other),
    }
}
fn log2_test() {
    assert_eq!(shared::log2(2), 1);
    assert_eq!(shared::log2(4), 2);
    assert_eq!(shared::log2(10), 1);
}
fn test_trap_trace_cb() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module $hello_mod
            (import "" "throw" (func $throw))
            (func (export "run") (call $hello))
            (func $hello (call $throw))
        )
    "#;

    let fn_type = FuncType::new(None, None);
    let fn_func = Func::new(&mut store, fn_type, |_, _, _| bail!("cb throw"));

    let module = Module::new(store.engine(), wat)?;
    let instance = Instance::new(&mut store, &module, &[fn_func.into()])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();

    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 2);
    assert_eq!(trace[0].module().name().unwrap(), "hello_mod");
    assert_eq!(trace[0].func_index(), 2);
    assert_eq!(trace[1].module().name().unwrap(), "hello_mod");
    assert_eq!(trace[1].func_index(), 1);
    assert!(format!("{e:?}").contains("cb throw"));

    Ok(())
}
fn test_fields_on_unit_struct() {
    let input = quote! {
        struct S;
    };

    snapshot!(input as DeriveInput, @r###"
    DeriveInput {
        vis: Visibility::Inherited,
        ident: "S",
        generics: Generics,
        data: Data::Struct {
            fields: Fields::Unit,
            semi_token: Some,
        },
    }
    "###);

    let data = match input.data {
        Data::Struct(data) => data,
        _ => panic!("expected a struct"),
    };

    assert_eq!(0, data.fields.iter().count());
}
fn get_sat_without_sat_index() {
  let rpc_server = test_bitcoincore_rpc::spawn();

  let response = TestServer::spawn_with_server_args(&rpc_server, &[], &["--enable-json-api"])
    .json_request("/sat/2099999997689999");

  assert_eq!(response.status(), StatusCode::OK);

  let mut sat_json: SatJson = serde_json::from_str(&response.text().unwrap()).unwrap();

  // this is a hack to ignore the timestamp, since it changes for every request
  sat_json.timestamp = 0;

  pretty_assert_eq!(
    sat_json,
    SatJson {
      number: 2099999997689999,
      decimal: "6929999.0".into(),
      degree: "5Â°209999â€²1007â€³0â€´".into(),
      name: "a".into(),
      block: 6929999,
      cycle: 5,
      epoch: 32,
      period: 3437,
      offset: 0,
      rarity: Rarity::Uncommon,
      percentile: "100%".into(),
      satpoint: None,
      timestamp: 0,
      inscriptions: vec![],
    }
  )
}

#[tes
fn test_concurrent_requests_1_conn() {
    let mut options = ResolverOpts::default();

    // there are two connections, but no concurrency requested
    options.num_concurrent_reqs = 1;

    // we want to make sure that both udp connections are called
    //   this will count down to 0 only if both are called.
    let on_send = OnSendBarrier::new(1);

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));

    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);

    let udp1_nameserver = mock_nameserver_on_send(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        options.clone(),
        on_send,
    );
    let udp2_nameserver = udp1_nameserver.clone();

    let pool = mock_nameserver_pool_on_send(
        vec![udp2_nameserver, udp1_nameserver],
        vec![],
        None,
        options,
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    // there's no actual network traffic happening, 1 sec should be plenty
    //   TODO: for some reason this timeout doesn't work, not clear why...
    // let future = Timeout::new(future, Duration::from_secs(1));

    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], udp_record);
}
fn test_mv_simple_backup_with_file_extension() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_simple_backup_file_a.txt";
    let file_b = "test_mv_simple_backup_file_b.txt";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("-b")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_comment_starting_with_gt() {
    let src = "<a /><!-->-->";
    let mut r = Reader::from_str(src);
    r.trim_text(true);
    loop {
        match r.read_event() {
            Ok(Comment(e)) => {
                assert_eq!(e.as_ref(), b">");
                break;
            }
            Ok(Eof) => panic!("Expecting Comment"),
            _ => (),
        }
    }
}
fn applies_custom_configuration() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), CUSTOM_CONFIGURATION_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--line-width"),
                ("10"),
                ("--indent-style"),
                ("space"),
                ("--indent-size"),
                ("8"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, CUSTOM_CONFIGURATION_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_configuration",
        fs,
        console,
        result,
    ));
}
fn default_names() {
    let db = default_engine();
    let names = db.engine.cf_names();
    assert_eq!(names.len(), 1);
    assert_eq!(names[0], CF_DEFAULT);
}
fn backup_blocked_by_memory_lock() {
    let suite = TestSuite::new(1, 144 * 1024 * 1024, ApiVersion::V1);

    fail::cfg("raftkv_async_write_finish", "pause").unwrap();
    let tikv_cli = suite.tikv_cli.clone();
    let (k, v) = (b"my_key", b"my_value");
    let mut mutation = Mutation::default();
    mutation.set_op(Op::Put);
    mutation.key = k.to_vec();
    mutation.value = v.to_vec();
    let mut prewrite_req = PrewriteRequest::default();
    prewrite_req.set_context(suite.context.clone());
    prewrite_req.mut_mutations().push(mutation);
    prewrite_req.set_primary_lock(k.to_vec());
    prewrite_req.set_start_version(20);
    prewrite_req.set_lock_ttl(2000);
    prewrite_req.set_use_async_commit(true);
    let th = thread::spawn(move || tikv_cli.kv_prewrite(&prewrite_req).unwrap());

    thread::sleep(Duration::from_millis(200));

    // Trigger backup request.
    let tmp = Builder::new().tempdir().unwrap();
    let backup_ts = TimeStamp::from(21);
    let storage_path = make_unique_dir(tmp.path());
    let rx = suite.backup(
        b"a".to_vec(), // start
        b"z".to_vec(), // end
        0.into(),      // begin_ts
        backup_ts,
        &storage_path,
    );
    let resp = block_on(rx.collect::<Vec<_>>());
    match &resp[0].get_error().detail {
        Some(Error_oneof_detail::KvError(key_error)) => {
            assert!(key_error.has_locked());
        }
        _ => panic!("unexpected response"),
    }

    fail::remove("raftkv_async_write_finish");
    th.join().unwrap();

    suite.stop();
}
fn test_update_raftstore_io_config() {
    // Test update raftstore configurations on io settings.
    // Start from SYNC mode.
    {
        let (mut resize_config, _dir) = TikvConfig::with_tmp().unwrap();
        resize_config.validate().unwrap();
        let (cfg_controller, _, _, mut system) = start_raftstore(resize_config, &_dir);

        // not allowed to resize from SYNC mode to ASYNC mode
        let resize_store_writers_cfg = vec![("raftstore.store-io-pool-size", "2")];
        assert!(
            cfg_controller
                .update(new_changes(resize_store_writers_cfg))
                .is_err()
        );
        system.shutdown();
    }
    // Start from ASYNC mode.
    {
        let (mut resize_config, _dir) = TikvConfig::with_tmp().unwrap();
        resize_config.raft_store.store_io_pool_size = 2;
        resize_config.validate().unwrap();
        let (cfg_controller, _, _, mut system) = start_raftstore(resize_config, &_dir);

        // not allowed to resize from ASYNC mode to SYNC mode
        let resize_store_writers_cfg = vec![("raftstore.store-io-pool-size", "0")];
        assert!(
            cfg_controller
                .update(new_changes(resize_store_writers_cfg))
                .is_err()
        );
        system.shutdown();
    }
    // Modify the size of async-ios.
    {
        let (mut resize_config, _dir) = TikvConfig::with_tmp().unwrap();
        resize_config.raft_store.store_io_pool_size = 2;
        resize_config.validate().unwrap();
        let (cfg_controller, _, _, mut system) = start_raftstore(resize_config, &_dir);

        // resize the count of ios to 1 by decreasing.
        let resize_store_writers_cfg = vec![("raftstore.store-io-pool-size", "1")];
        cfg_controller
            .update(new_changes(resize_store_writers_cfg))
            .unwrap();
        // resize the count of ios to 4 by increasing.
        let resize_store_writers_cfg = vec![("raftstore.store-io-pool-size", "4")];
        cfg_controller
            .update(new_changes(resize_store_writers_cfg))
            .unwrap();
        system.shutdown();
    }
}
fn test_newtype_enum_fields() {
    assert_eq!(
        ron::from_str::<TestEnum>("#![enable(unwrap_variant_newtypes)] NewtypeVariant(a: true, b: 'b', c: -42, d: \"gotcha\")"),
        Err(SpannedError {
            code: Error::NoSuchStructField {
                expected: &["a", "b", "c"],
                found: String::from("d"),
                outer: Some(String::from("NewtypeVariant")),
            },
            position: Position { line: 1, col: 78 },
        })
    );

    assert_eq!(
        ron::from_str::<TestEnum>(
            "#![enable(unwrap_variant_newtypes)] NewtypeVariant(a: true, c: -42)"
        ),
        Err(SpannedError {
            code: Error::MissingStructField {
                field: "b",
                outer: Some(String::from("NewtypeVariant")),
            },
            position: Position { line: 1, col: 67 },
        })
    );

    assert_eq!(
        ron::from_str::<TestEnum>(
            "#![enable(unwrap_variant_newtypes)] NewtypeVariant(a: true, b: 'b', a: false, c: -42)"
        ),
        Err(SpannedError {
            code: Error::DuplicateStructField {
                field: "a",
                outer: Some(String::from("NewtypeVariant")),
            },
            position: Position { line: 1, col: 70 },
        })
    );
}
fn test_cp_arg_update_all_then_none() {
    // take last if multiple update args are supplied,
    // update=none wins in this case
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_all_then_none_file1";
    let new = "test_cp_arg_update_all_then_none_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("--update=all")
        .arg("--update=none")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), "new content\n");
}
fn sqrtd_spec_test() {
    // Not Asserted: FE_INVALID exception is raised if argument is negative.
    assert!(libm::sqrtd(-1.0).is_nan());
    assert!(libm::sqrtd(f64::NAN).is_nan());
    for f in [0.0, -0.0, f64::INFINITY].iter().copied() {
        assert_eq!(libm::sqrtd(f), f);
    }
}
fn test_error_positions() {
    assert_eq!(
        ron::from_str::<TypeError>("  ()"),
        Err(SpannedError {
            code: Error::InvalidValueForType {
                expected: String::from("impossible"),
                found: String::from("a unit value"),
            },
            position: Position { line: 1, col: 3 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("StructVariant(a: true, b: 0, c: -42)"),
        Err(SpannedError {
            code: Error::InvalidValueForType {
                expected: String::from("a nonzero u32"),
                found: String::from("the unsigned integer `0`"),
            },
            position: Position { line: 1, col: 28 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("TupleVariant(42)"),
        Err(SpannedError {
            code: Error::ExpectedDifferentLength {
                expected: String::from("tuple variant Test::TupleVariant with 2 elements"),
                found: 1,
            },
            position: Position { line: 1, col: 16 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("NotAVariant"),
        Err(SpannedError {
            code: Error::NoSuchEnumVariant {
                expected: &["TupleVariant", "StructVariant"],
                found: String::from("NotAVariant"),
                outer: Some(String::from("Test")),
            },
            position: Position { line: 1, col: 12 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("StructVariant(a: true, b: 1, c: -42, d: \"gotcha\")"),
        Err(SpannedError {
            code: Error::NoSuchStructField {
                expected: &["a", "b", "c"],
                found: String::from("d"),
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 39 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("StructVariant(a: true, c: -42)"),
        Err(SpannedError {
            code: Error::MissingStructField {
                field: "b",
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 30 },
        })
    );

    assert_eq!(
        ron::from_str::<Test>("StructVariant(a: true, b: 1, a: false, c: -42)"),
        Err(SpannedError {
            code: Error::DuplicateStructField {
                field: "a",
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 31 },
        })
    );
}
fn test_tables_count_limit() {
    let limits = StoreLimitsBuilder::new().tables(0).build();
    assert!(Test::new(0x30, 100, limits).is_err());
}
fn test_update_internal_apply_index() {
    let mut cluster = new_node_cluster(0, 4);
    cluster.pd_client.disable_default_operator();
    // So compact log will not be triggered automatically.
    configure_for_request_snapshot(&mut cluster);
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(3, 3));
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");

    let filter = RegionPacketFilter::new(1, 3)
        .msg_type(MessageType::MsgAppendResponse)
        .direction(Direction::Recv);
    cluster.add_send_filter(CloneFilterFactory(filter));
    let last_index = cluster.raft_local_state(1, 1).get_last_index();
    cluster.async_remove_peer(1, new_peer(4, 4)).unwrap();
    cluster.async_put(b"k2", b"v2").unwrap();
    let mut snaps = Vec::new();
    for id in 1..3 {
        cluster.wait_last_index(1, id, last_index + 2, Duration::from_secs(3));
        snaps.push((id, cluster.get_raft_engine(id).dump_all_data(id)));
    }
    cluster.clear_send_filters();
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
    must_get_equal(&cluster.get_engine(2), b"k2", b"v2");

    // Simulate data lost in raft cf.
    for (id, mut batch) in snaps {
        cluster.stop_node(id);
        delete_old_data(&cluster.get_raft_engine(id), id);
        cluster
            .get_raft_engine(id)
            .consume(&mut batch, true /* sync */)
            .unwrap();
        cluster.run_node(id).unwrap();
    }

    let region = cluster.get_region(b"k1");
    // Issues a heartbeat to followers so they will re-commit the logs.
    let resp = read_on_peer(
        &mut cluster,
        new_peer(3, 3),
        region,
        b"k1",
        true,
        Duration::from_secs(3),
    )
    .unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    cluster.stop_node(3);
    cluster.must_put(b"k3", b"v3");
}
fn bad_text_syntax() -> Result<()> {
    let output = get_wasmtime_command()?
        .arg("-Ccache=n")
        .arg("tests/all/cli_tests/bad-syntax.wat")
        .output()?;
    assert!(!output.status.success());
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("--> tests/all/cli_tests/bad-syntax.wat"),
        "bad stderr: {stderr}"
    );
    Ok(())
}
fn test_analyze_index_with_lock() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    for &iso_level in &[IsolationLevel::Si, IsolationLevel::Rc] {
        let (_, endpoint, _) = init_data_with_commit(&product, &data, false);

        let mut req = new_analyze_index_req(&product, 3, product["name"].index, 4, 32, 0, 1);
        let mut ctx = Context::default();
        ctx.set_isolation_level(iso_level);
        req.set_context(ctx);

        let resp = handle_request(&endpoint, req);
        match iso_level {
            IsolationLevel::Si => {
                assert!(resp.get_data().is_empty(), "{:?}", resp);
                assert!(resp.has_locked(), "{:?}", resp);
            }
            IsolationLevel::Rc => {
                let mut analyze_resp = AnalyzeIndexResp::default();
                analyze_resp.merge_from_bytes(resp.get_data()).unwrap();
                let hist = analyze_resp.get_hist();
                assert!(hist.get_buckets().is_empty());
                assert_eq!(hist.get_ndv(), 0);
            }
            IsolationLevel::RcCheckTs => unimplemented!(),
        }
    }
}
fn stdin_override_parser_py() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(["--extension", "ipynb:python", "--stdin-filename", "F401.ipynb"])
        .pass_stdin("import os\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    F401.ipynb:1:8: F401 [*] `os` imported but unused
    Found 1 error.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn is_valid_ascii_slice_test() {
    assert_eq!(ascii::is_valid_ascii_slice(b" 09a"), true);
    assert_eq!(ascii::is_valid_ascii_slice(b" 09a\x1b"), false);
}
fn test_help_flag() {
    let help_short = new_ucmd!().arg("-h").succeeds();
    let help_long = new_ucmd!().arg("--help").succeeds();

    assert_eq!(help_short.stdout_str(), help_long.stdout_str());
}
fn test_lock_manager_cfg_update() {
    const DEFAULT_TIMEOUT: u64 = 3000;
    const DEFAULT_DELAY: u64 = 100;
    let (mut cfg, _dir) = TikvConfig::with_tmp().unwrap();
    cfg.pessimistic_txn.wait_for_lock_timeout = ReadableDuration::millis(DEFAULT_TIMEOUT);
    cfg.pessimistic_txn.wake_up_delay_duration = ReadableDuration::millis(DEFAULT_DELAY);
    cfg.pessimistic_txn.pipelined = false;
    cfg.pessimistic_txn.in_memory = false;
    cfg.validate().unwrap();
    let (cfg_controller, waiter, deadlock, mut lock_mgr) = setup(cfg);

    // update of other module's config should not effect lock manager config
    cfg_controller
        .update_config("raftstore.raft-log-gc-threshold", "2000")
        .unwrap();
    validate_waiter(&waiter, move |timeout: ReadableDuration| {
        assert_eq!(timeout.as_millis(), DEFAULT_TIMEOUT);
    });
    validate_dead_lock(&deadlock, move |ttl: u64| {
        assert_eq!(ttl, DEFAULT_TIMEOUT);
    });

    // only update wait_for_lock_timeout
    cfg_controller
        .update_config("pessimistic-txn.wait-for-lock-timeout", "4000ms")
        .unwrap();
    validate_waiter(&waiter, move |timeout: ReadableDuration| {
        assert_eq!(timeout.as_millis(), 4000);
    });
    validate_dead_lock(&deadlock, move |ttl: u64| {
        assert_eq!(ttl, 4000);
    });

    // update pipelined
    assert!(
        !lock_mgr
            .get_storage_dynamic_configs()
            .pipelined_pessimistic_lock
            .load(Ordering::SeqCst)
    );
    cfg_controller
        .update_config("pessimistic-txn.pipelined", "true")
        .unwrap();
    assert!(
        lock_mgr
            .get_storage_dynamic_configs()
            .pipelined_pessimistic_lock
            .load(Ordering::SeqCst)
    );

    // update in-memory
    assert!(
        !lock_mgr
            .get_storage_dynamic_configs()
            .in_memory_pessimistic_lock
            .load(Ordering::SeqCst)
    );
    cfg_controller
        .update_config("pessimistic-txn.in-memory", "true")
        .unwrap();
    assert!(
        lock_mgr
            .get_storage_dynamic_configs()
            .in_memory_pessimistic_lock
            .load(Ordering::SeqCst)
    );

    // update wake-up-delay-duration
    assert_eq!(
        lock_mgr
            .get_storage_dynamic_configs()
            .wake_up_delay_duration_ms
            .load(Ordering::SeqCst),
        DEFAULT_DELAY
    );
    cfg_controller
        .update_config("pessimistic-txn.wake-up-delay-duration", "500ms")
        .unwrap();
    assert_eq!(
        lock_mgr
            .get_storage_dynamic_configs()
            .wake_up_delay_duration_ms
            .load(Ordering::SeqCst),
        500
    );

    lock_mgr.stop();
}
fn test_unsafe_recovery_create_destroy_reentrancy() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);
    cluster.put(b"random_key1", b"random_val1").unwrap();

    // Split the region into 2, and remove one of them, so that we can test both
    // region peer list update and region creation.
    pd_client.must_split_region(
        region,
        pdpb::CheckPolicy::Usekey,
        vec![b"random_key1".to_vec()],
    );
    let region1 = pd_client.get_region(b"random_key".as_ref()).unwrap();
    let region2 = pd_client.get_region(b"random_key1".as_ref()).unwrap();
    let region1_store0_peer = find_peer(&region1, nodes[0]).unwrap().to_owned();
    pd_client.must_remove_peer(region1.get_id(), region1_store0_peer);
    cluster.must_remove_region(nodes[0], region1.get_id());

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    {
        let put = new_put_cmd(b"k2", b"v2");
        let req = new_request(
            region2.get_id(),
            region2.get_region_epoch().clone(),
            vec![put],
            true,
        );
        // marjority is lost, can't propose command successfully.
        cluster
            .call_command_on_leader(req, Duration::from_millis(10))
            .unwrap_err();
    }

    cluster.must_enter_force_leader(region2.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    // Construct recovery plan.
    let mut plan = pdpb::RecoveryPlan::default();

    let mut create = metapb::Region::default();
    create.set_id(101);
    create.set_end_key(b"random_key1".to_vec());
    let mut peer = metapb::Peer::default();
    peer.set_id(102);
    peer.set_store_id(nodes[0]);
    create.mut_peers().push(peer);
    plan.mut_creates().push(create);

    plan.mut_tombstones().push(region2.get_id());

    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());
    cluster.must_send_store_heartbeat(nodes[0]);
    sleep_ms(100);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());
    cluster.must_send_store_heartbeat(nodes[0]);

    // Store reports are sent once the entries are applied.
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    let report = store_report.unwrap();
    let peer_reports = report.get_peer_reports();
    assert_eq!(peer_reports.len(), 1);
    let reported_region = peer_reports[0].get_region_state().get_region();
    assert_eq!(reported_region.get_id(), 101);
    assert_eq!(reported_region.get_peers().len(), 1);
    assert_eq!(reported_region.get_peers()[0].get_id(), 102);
    fail::remove("on_handle_apply_store_1");
}
fn aes192_encrypted_file() {
    let mut v = Vec::new();
    v.extend_from_slice(include_bytes!("data/aes_archive.zip"));
    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect("couldn't open test zip file");

    let mut file = archive
        .by_name_decrypt("secret_data_192", PASSWORD)
        .expect("couldn't find file in archive")
        .expect("invalid password");
    assert_eq!("secret_data_192", file.name());

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("couldn't read encrypted file");
    assert_eq!(SECRET_CONTENT, content);
}
fn test_analyze_column_with_lock() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    for &iso_level in &[IsolationLevel::Si, IsolationLevel::Rc] {
        let (_, endpoint, _) = init_data_with_commit(&product, &data, false);

        let mut req = new_analyze_column_req(&product, 3, 3, 3, 3, 4, 32);
        let mut ctx = Context::default();
        ctx.set_isolation_level(iso_level);
        req.set_context(ctx);

        let resp = handle_request(&endpoint, req);
        match iso_level {
            IsolationLevel::Si => {
                assert!(resp.get_data().is_empty(), "{:?}", resp);
                assert!(resp.has_locked(), "{:?}", resp);
            }
            IsolationLevel::Rc => {
                let mut analyze_resp = AnalyzeColumnsResp::default();
                analyze_resp.merge_from_bytes(resp.get_data()).unwrap();
                let hist = analyze_resp.get_pk_hist();
                assert!(hist.get_buckets().is_empty());
                assert_eq!(hist.get_ndv(), 0);
            }
            IsolationLevel::RcCheckTs => unimplemented!(),
        }
    }
}
fn parse_ilike() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}ILIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::ILike {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}ILIKE '%a' ESCAPE '^'",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::ILike {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('^'),
            },
            select.selection.unwrap()
        );

        // This statement tests that ILIKE and NOT ILIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}ILIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::ILike {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_missing_in() {
    assert_vis_parse!("pub(foo::bar)", Ok(Visibility::Public(_)) + "(foo::bar)");
}
fn parse_value_forloop_array() {
    let ast = parse("{% for item in [1,2,] %}A{%- endfor %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Forloop(
            start_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::new(ExprVal::Array(vec![
                    Expr::new(ExprVal::Int(1)),
                    Expr::new(ExprVal::Int(2)),
                ])),
                body: vec![Node::Text("A".to_string())],
                empty_body: None,
            },
            end_ws,
        )
    );
}
fn test_cache() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_cluster, raft_engine, ctx) = new_raft_engine(1, "");

    let (_, endpoint, _) =
        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &data, true);

    let req = DagSelect::from(&product).build_with(ctx, &[0]);
    let resp = handle_request(&endpoint, req.clone());

    assert!(!resp.get_is_cache_hit());
    let cache_version = resp.get_cache_last_version();

    // Cache version must be >= 5 because Raft apply index must be >= 5.
    assert!(cache_version >= 5);

    // Send the request again using is_cache_enabled == false (default) and a
    // matching version. The request should be processed as usual.

    let mut req2 = req.clone();
    req2.set_cache_if_match_version(cache_version);
    let resp2 = handle_request(&endpoint, req2);

    assert!(!resp2.get_is_cache_hit());
    assert_eq!(
        resp.get_cache_last_version(),
        resp2.get_cache_last_version()
    );
    assert_eq!(resp.get_data(), resp2.get_data());

    // Send the request again using is_cached_enabled == true and a matching
    // version. The request should be skipped.

    let mut req3 = req.clone();
    req3.set_is_cache_enabled(true);
    req3.set_cache_if_match_version(cache_version);
    let resp3 = handle_request(&endpoint, req3);

    assert!(resp3.get_is_cache_hit());
    assert!(resp3.get_data().is_empty());

    // Send the request using a non-matching version. The request should be
    // processed.

    let mut req4 = req;
    req4.set_is_cache_enabled(true);
    req4.set_cache_if_match_version(cache_version + 1);
    let resp4 = handle_request(&endpoint, req4);

    assert!(!resp4.get_is_cache_hit());
    assert_eq!(
        resp.get_cache_last_version(),
        resp4.get_cache_last_version()
    );
    assert_eq!(resp.get_data(), resp4.get_data());
}
fn parse_exists_subquery() {
    let expected_inner = verified_query("SELECT 1");
    let sql = "SELECT * FROM t WHERE EXISTS (SELECT 1)";
    let select = verified_only_select(sql);
    assert_eq!(
        Expr::Exists {
            negated: false,
            subquery: Box::new(expected_inner.clone()),
        },
        select.selection.unwrap(),
    );

    let sql = "SELECT * FROM t WHERE NOT EXISTS (SELECT 1)";
    let select = verified_only_select(sql);
    assert_eq!(
        Expr::Exists {
            negated: true,
            subquery: Box::new(expected_inner),
        },
        select.selection.unwrap(),
    );

    verified_stmt("SELECT * FROM t WHERE EXISTS (WITH u AS (SELECT 1) SELECT * FROM u)");
    verified_stmt("SELECT EXISTS (SELECT 1)");

    let res = parse_sql_statements("SELECT EXISTS (");
    assert_eq!(
        ParserError::ParserError(
            "Expected SELECT, VALUES, or a subquery in the query body, found: EOF".to_string()
        ),
        res.unwrap_err(),
    );

    let res = parse_sql_statements("SELECT EXISTS (NULL)");
    assert_eq!(
        ParserError::ParserError(
            "Expected SELECT, VALUES, or a subquery in the query body, found: NULL".to_string()
        ),
        res.unwrap_err(),
    );
}
fn parse_joins_using() {
    fn join_with_constraint(
        relation: impl Into<String>,
        alias: Option<TableAlias>,
        f: impl Fn(JoinConstraint) -> JoinOperator,
    ) -> Join {
        Join {
            relation: TableFactor::Table {
                name: ObjectName(vec![Ident::new(relation.into())]),
                alias,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            join_operator: f(JoinConstraint::Using(vec!["c1".into()])),
        }
    }
    // Test parsing of aliases
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 JOIN t2 AS foo USING(c1)").from).joins,
        vec![join_with_constraint(
            "t2",
            table_alias("foo"),
            JoinOperator::Inner,
        )]
    );
    one_statement_parses_to(
        "SELECT * FROM t1 JOIN t2 foo USING(c1)",
        "SELECT * FROM t1 JOIN t2 AS foo USING(c1)",
    );
    // Test parsing of different join operators
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::Inner)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftOuter)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightOuter)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT SEMI JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftSemi)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT SEMI JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightSemi)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT ANTI JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftAnti)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT ANTI JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightAnti)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 FULL JOIN t2 USING(c1)").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::FullOuter)]
    );
}
fn halfway_round_down_test() {
    // Halfway, round-down tests
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740992, false), (1076, 0));
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740993, false), (1076, 0));
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740994, false), (1076, 1));

    assert_eq!(compute_float64::<BINARY>(0, 18014398509481984, false), (1077, 0));
    assert_eq!(compute_float64::<BINARY>(0, 18014398509481986, false), (1077, 0));
    assert_eq!(compute_float64::<BINARY>(0, 18014398509481988, false), (1077, 1));

    assert_eq!(compute_float64::<BINARY>(0, 9223372036854775808, false), (1086, 0));
    assert_eq!(compute_float64::<BINARY>(0, 9223372036854776832, false), (1086, 0));
    assert_eq!(compute_float64::<BINARY>(0, 9223372036854777856, false), (1086, 1));

    // Add a 0 but say we're truncated.
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854775808, true), (1076, 0));
    assert_eq!(
        compute_float64::<BINARY>(-10, 9223372036854776832, true),
        (-31703, 9223372036854776832)
    );
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854777856, true), (1076, 1));

    // Check other bases.
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855872, false), (1076, 0));
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855888, false), (1076, 0));
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855904, false), (1076, 1));

    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423488, false), (1076, 0));
    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423552, false), (1076, 0));
    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423616, false), (1076, 1));

    assert_eq!(compute_float64::<HEX>(-1, 144115188075855872, false), (1076, 0));
    assert_eq!(compute_float64::<HEX>(-1, 144115188075855888, false), (1076, 0));
    assert_eq!(compute_float64::<HEX>(-1, 144115188075855904, false), (1076, 1));

    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711744, false), (1076, 0));
    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711776, false), (1076, 0));
    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711808, false), (1076, 1));
}
fn test_write_attrs() -> Result<()> {
    type AttrResult<T> = std::result::Result<T, AttrError>;

    let str_from = r#"<source attr="val"></source>"#;
    let expected = r#"<copy attr="val" a="b" c="d" x="y&quot;z"></copy>"#;
    let mut reader = Reader::from_str(str_from);
    reader.trim_text(true);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        let event = match reader.read_event()? {
            Eof => break,
            Start(elem) => {
                let mut attrs = elem.attributes().collect::<AttrResult<Vec<_>>>()?;
                attrs.extend_from_slice(&[("a", "b").into(), ("c", "d").into()]);
                let mut elem = BytesStart::new("copy");
                elem.extend_attributes(attrs);
                elem.push_attribute(("x", "y\"z"));
                Start(elem)
            }
            End(_) => End(BytesEnd::new("copy")),
            e => e,
        };
        assert!(writer.write_event(event).is_ok());
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(result, expected.as_bytes());

    Ok(())
}
fn as_header_name() {
    let mut m = HeaderMap::new();
    let v: HeaderValue = "localhost".parse().unwrap();
    m.insert(HOST, v.clone());

    let expected = Some(&v);

    assert_eq!(m.get("host"), expected);
    assert_eq!(m.get(&HOST), expected);

    let s = String::from("host");
    assert_eq!(m.get(&s), expected);
    assert_eq!(m.get(s.as_str()), expected);
}
fn weak_map_key_live() {
    run_test(|| {
        let key = Gc::new(String::from("key"));
        let key_copy = key.clone();

        let mut map = WeakMap::new();

        map.insert(&key, ());

        assert!(map.contains_key(&key));
        assert!(map.contains_key(&key_copy));

        assert_eq!(map.remove(&key), Some(()));

        map.insert(&key, ());

        drop(key);

        force_collect();

        assert!(map.contains_key(&key_copy));
    });
}
fn test_ingest_reentrant() {
    let (cluster, ctx, _tikv, import) = new_cluster_and_tikv_import_client();

    let temp_dir = Builder::new()
        .prefix("test_ingest_reentrant")
        .tempdir()
        .unwrap();

    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());
    upload_sst(&import, &meta, &data).unwrap();

    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx);
    ingest.set_sst(meta.clone());

    // Don't delete ingested sst file or we cannot find sst file in next ingest.
    fail::cfg("dont_delete_ingested_sst", "1*return").unwrap();

    let node_id = *cluster.sim.rl().get_node_ids().iter().next().unwrap();
    // Use sst save path to track the sst file checksum.
    let save_path = cluster
        .sim
        .rl()
        .importers
        .get(&node_id)
        .unwrap()
        .get_path(&meta);

    let checksum1 = calc_crc32(save_path.clone()).unwrap();
    // Do ingest and it will ingest successs.
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error());

    let checksum2 = calc_crc32(save_path).unwrap();
    // TODO: Remove this once write_global_seqno is deprecated.
    // Checksums are the same since the global seqno in the SST file no longer gets
    // updated with the default setting, which is write_global_seqno=false.
    assert_eq!(checksum1, checksum2);
    // Do ingest again and it can be reentrant
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error());
}
fn initial_retransmit() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let client_ch = pair.begin_connect(client_config());
    pair.client.drive(pair.time, pair.server.addr);
    pair.client.outbound.clear(); // Drop initial
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected { .. })
    );
}
fn scientific_exponent_test() {
    // 0 digits in the integer
    assert_eq!(scientific_exponent(0, 0, 5), -6);
    assert_eq!(scientific_exponent(10, 0, 5), 4);
    assert_eq!(scientific_exponent(-10, 0, 5), -16);

    // >0 digits in the integer
    assert_eq!(scientific_exponent(0, 1, 5), 0);
    assert_eq!(scientific_exponent(0, 2, 5), 1);
    assert_eq!(scientific_exponent(0, 2, 20), 1);
    assert_eq!(scientific_exponent(10, 2, 20), 11);
    assert_eq!(scientific_exponent(-10, 2, 20), -9);

    // Underflow
    assert_eq!(
        scientific_exponent(i32::min_value(), 0, 0),
        i32::min_value()
    );
    assert_eq!(
        scientific_exponent(i32::min_value(), 0, 5),
        i32::min_value()
    );

    // Overflow
    assert_eq!(
        scientific_exponent(i32::max_value(), 0, 0),
        i32::max_value() - 1
    );
    assert_eq!(
        scientific_exponent(i32::max_value(), 5, 0),
        i32::max_value()
    );
}
fn parse_similar_to() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that SIMILAR TO and NOT SIMILAR TO have the same precedence.
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_debug_region_size() {
    let (cluster, debug_client, store_id) = must_new_cluster_and_debug_client();
    let engine = cluster.get_engine(store_id);

    // Put some data.
    let region_id = 100;
    let region_state_key = keys::region_state_key(region_id);
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    region.set_start_key(b"a".to_vec());
    region.set_end_key(b"z".to_vec());
    let mut state = RegionLocalState::default();
    state.set_region(region);
    engine
        .put_msg_cf(CF_RAFT, &region_state_key, &state)
        .unwrap();

    let cfs = vec![CF_DEFAULT, CF_LOCK, CF_WRITE];
    // At lease 8 bytes for the WRITE cf.
    let (k, v) = (keys::data_key(b"kkkk_kkkk"), b"v");
    for cf in &cfs {
        engine.put_cf(cf, k.as_slice(), v).unwrap();
    }

    let mut req = debugpb::RegionSizeRequest::default();
    req.set_region_id(region_id);
    req.set_cfs(cfs.iter().map(|s| s.to_string()).collect());
    let entries: Vec<_> = debug_client
        .region_size(&req)
        .unwrap()
        .take_entries()
        .into();
    assert_eq!(entries.len(), 3);
    for e in entries {
        cfs.iter().find(|&&c| c == e.cf).unwrap();
        assert!(e.size > 0);
    }

    req.set_region_id(region_id + 1);
    match debug_client.region_size(&req).unwrap_err() {
        Error::RpcFailure(status) => {
            assert_eq!(status.code(), RpcStatusCode::NOT_FOUND);
        }
        _ => panic!("expect NotFound"),
    }
}
fn pair_record_of_list_offset() {
    assert_eq!(types::RecordOfList::offset_of_arr(), 0);
}
fn parse_typed_struct_with_field_name() {
    let sql = r#"SELECT STRUCT<x INT64>(5), STRUCT<y STRING>("foo")"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(number("5")),],
            fields: vec![StructField {
                field_name: Some(Ident::from("x")),
                field_type: DataType::Int64
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::DoubleQuotedString("foo".to_string())),],
            fields: vec![StructField {
                field_name: Some(Ident::from("y")),
                field_type: DataType::String(None)
            }]
        },
        expr_from_projection(&select.projection[1])
    );

    let sql = r#"SELECT STRUCT<x INT64, y INT64>(5, 5)"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(1, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(number("5")), Expr::Value(number("5")),],
            fields: vec![
                StructField {
                    field_name: Some(Ident::from("x")),
                    field_type: DataType::Int64
                },
                StructField {
                    field_name: Some(Ident::from("y")),
                    field_type: DataType::Int64
                }
            ]
        },
        expr_from_projection(&select.projection[0])
    );
}
fn exit126_wasi_snapshot0() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit126_wasi_snapshot0.wat")?;
    let output = run_wasmtime_for_output(&["-Ccache=n", wasm.path().to_str().unwrap()], None)?;
    assert_eq!(output.status.code().unwrap(), 1);
    assert!(output.stdout.is_empty());
    assert!(String::from_utf8_lossy(&output.stderr).contains("invalid exit status"));
    Ok(())
}
fn test_inserts() {
    const N: usize = 2000;
    let mut v = Vector::new();
    for i in 0..N {
        v.insert(v.len() / 2, i);
    }
    let mut rv: Vec<usize> = Vec::new();
    rv.extend((0..N).skip(1).step_by(2));
    rv.extend((0..N).step_by(2).rev());
    assert_eq!(rv.iter().cloned().collect::<Vector<_>>(), v);
}
fn create_get_set_funcref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::FuncRef, 10, None);
    let init = Val::FuncRef(Some(Func::wrap(&mut store, || {})));
    let table = Table::new(&mut store, table_ty, init)?;

    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_some());
    table.set(&mut store, 5, Val::FuncRef(None))?;
    assert!(table.get(&mut store, 5).unwrap().unwrap_funcref().is_none());

    Ok(())
}
fn test_force_leader_on_hibernated_leader() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store1 = find_peer(&region, 1).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // wait a while to hibernate
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 3,
    ));

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), None);
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn test_delete_rrset() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = io_loop
        .block_on(client.delete_rrset(record.clone(), origin.clone()))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = io_loop
        .block_on(client.create(record.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let result = io_loop
        .block_on(client.append(record.clone(), origin.clone(), true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = io_loop
        .block_on(client.delete_rrset(record.clone(), origin))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);
}
fn test_create_exe_with_pirita_works_1() {
    let tempdir = TempDir::new().unwrap();
    let path = tempdir.path();
    let wasm_out = path.join("out.obj");
    let cmd = Command::new(get_wasmer_path())
        .arg("create-obj")
        .arg(fixtures::wabt())
        .arg("-o")
        .arg(&wasm_out)
        .output()
        .unwrap();

    let stderr = String::from_utf8_lossy(&cmd.stderr);

    assert_eq!(stderr.lines().map(|s| s.trim().to_string()).collect::<Vec<_>>(), vec![
        format!("error: cannot compile more than one atom at a time"),
        format!("â”‚   1: note: use --atom <ATOM> to specify which atom to compile"),
        format!("â•°â”€â–¶ 2: where <ATOM> is one of: wabt, wasm-interp, wasm-strip, wasm-validate, wasm2wat, wast2json, wat2wasm"),
    ]);

    assert!(!cmd.status.success());

    let cmd = Command::new(get_wasmer_path())
        .arg("create-obj")
        .arg(fixtures::wabt())
        .arg("--atom")
        .arg("wasm2wat")
        .arg("-o")
        .arg(&wasm_out)
        .output()
        .unwrap();

    let stderr = String::from_utf8_lossy(&cmd.stderr);

    let real_out = wasm_out.canonicalize().unwrap().display().to_string();
    let real_out = real_out
        .strip_prefix(r"\\?\")
        .unwrap_or(&real_out)
        .to_string();
    assert_eq!(
        stderr
            .lines()
            .map(|s| s.trim().to_string())
            .collect::<Vec<_>>(),
        vec![format!("âœ” Object compiled successfully to `{real_out}`"),]
    );

    assert!(cmd.status.success());
}

#[test]

fn compute_right_closed_directed_test() {
    assert_eq!(compute_right_closed_directed(1.23456), (123456, -5));
    assert_eq!(
        compute_right_closed_directed(13.9999999999999982236431606),
        (13999999999999982, -15)
    );
}
fn test_something() {
    let data = [];
    let from_bytes: Vec<_> = data.iter().to_utf8chars().collect();
    let mut byte_start = 0;
    let mut item_start = 0;
    loop {
        let (valid_up_to, error_length) = match str::from_utf8(&data[byte_start..]) {
            Ok(s) => (s.len(), None),
            Err(e) => (e.valid_up_to(), e.error_len()),
        };
        let valid_range = byte_start..byte_start + valid_up_to;
        let good_part = str::from_utf8(&data[valid_range]).unwrap();
        let mut chars = 0;
        for (i, c) in good_part.chars().enumerate() {
            chars += 1;
            assert_eq!(from_bytes.get(item_start + i), Some(&Ok(Utf8Char::from(c))));
        }
        let error_start = item_start + chars;
        if let Some(error_length) = error_length {
            let error_end = error_start + error_length;
            assert!(from_bytes[error_start..error_end]
                .iter()
                .all(|r| r.is_err()));
            item_start = error_end;
            byte_start = byte_start + valid_up_to + error_length;
        } else if byte_start + valid_up_to == data.len() {
            assert_eq!(from_bytes.len(), error_start);
            break;
        } else {
            data[byte_start + valid_up_to].extra_utf8_bytes().unwrap();
            assert_eq!(
                from_bytes.len() - error_start,
                data.len() - valid_up_to - byte_start
            );
            assert_eq!(
                from_bytes[error_start].map_err(|e| e.kind()),
                Err(TooFewBytes)
            );
            break;
        }
    }
    let from_slice: Vec<_> = data.utf8char_indices().map(|(_, r, _)| r).collect();
    for (i, (&br, &sr)) in from_bytes.iter().zip(&from_slice).enumerate() {
        match sr {
            Err(e) if e.kind() == TooFewBytes || e.kind() == InterruptedSequence => {
                assert!(br.is_err(), "byte {}", i)
            }
            _ => assert_eq!(sr, br, "byte {}", i),
        }
    }
    assert_eq!(from_slice.len(), from_bytes.len());
}
fn show_source() {
    let args = ["--show-source"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("l = 1"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `l`
      |
    1 | l = 1
      | ^ E741
      |

    Found 1 error.

    ----- stderr -----
    "###);
}
fn test_txn_create_compaction_filter() {
    GC_COMPACTION_FILTER_PERFORM.reset();
    GC_COMPACTION_FILTER_SKIP.reset();

    let mut cfg = DbConfig::default();
    cfg.writecf.disable_auto_compactions = true;
    cfg.writecf.dynamic_level_bytes = false;
    let dir = tempfile::TempDir::new().unwrap();
    let builder = TestEngineBuilder::new().path(dir.path());
    let mut engine = builder.build_with_cfg(&cfg).unwrap();
    let raw_engine = engine.get_rocksdb();

    let mut gc_runner = TestGcRunner::new(0);
    let value = vec![b'v'; 512];

    must_prewrite_put(&mut engine, b"zkey", &value, b"zkey", 100);
    must_commit(&mut engine, b"zkey", 100, 110);

    gc_runner
        .safe_point(TimeStamp::new(1).into_inner())
        .gc(&raw_engine);
    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get(),
        1
    );
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get(),
        1
    );

    GC_COMPACTION_FILTER_PERFORM.reset();
    GC_COMPACTION_FILTER_SKIP.reset();
}
fn parse_variable_tag_simple_test() {
    let ast = parse("{{ id is defined }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Test(Test {
                ident: "id".to_string(),
                negated: false,
                name: "defined".to_string(),
                args: vec![],
            },))
        )
    );
}
fn test_output_file_all_filesystems() {
    // When run with no positional arguments, `df` lets "-" represent
    // the "File" entry for each row.
    let output = new_ucmd!()
        .arg("--output=file")
        .succeeds()
        .stdout_move_str();
    let mut lines = output.lines();
    assert_eq!(lines.next().unwrap(), "File");
    for line in lines {
        assert_eq!(line, "-");
    }
}
fn eph_basic_alloc_dump_test() {
    run_test(|| {
        let gc_value = Gc::new(String::from("gc here"));
        let _gc_two = Gc::new("hmmm");

        let eph = Ephemeron::new(&gc_value, 4);
        let _fourth = Gc::new("tail");

        assert_eq!(eph.value(), Some(4));
    });
}
fn no_lint_if_files_are_listed_in_ignore_option() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_LINTER_AND_FILES_IGNORE.as_bytes());

    let file_path_test1 = Path::new("test1.js");
    fs.insert(file_path_test1.into(), FIX_BEFORE.as_bytes());

    let file_path_test2 = Path::new("test2.js");
    fs.insert(file_path_test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path_test1.as_os_str().to_str().unwrap(),
                file_path_test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path_test1)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    let mut buffer = String::new();
    fs.open(file_path_test2)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, CHECK_FORMAT_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_files_are_listed_in_ignore_option",
        fs,
        console,
        result,
    ));
}
fn test_stream_batch_row_limit() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
        (8, Some("name:2"), 4),
    ];

    let product = ProductTable::new();
    let stream_row_limit = 2;
    let (_, endpoint, _) = {
        let engine = TestEngineBuilder::new().build().unwrap();
        let mut cfg = Config::default();
        cfg.end_point_stream_batch_row_limit = stream_row_limit;
        init_data_with_details(Context::default(), engine, &product, &data, true, &cfg)
    };

    let req = DagSelect::from(&product).build();
    assert_eq!(req.get_ranges().len(), 1);

    // only ignore first 7 bytes of the row id
    let ignored_suffix_len = tidb_query_datatype::codec::table::RECORD_ROW_KEY_LEN - 1;

    // `expected_ranges_last_bytes` checks those assertions:
    // 1. We always fetch no more than stream_row_limit rows.
    // 2. The responses' key ranges are disjoint.
    // 3. Each returned key range should cover the returned rows.
    let mut expected_ranges_last_bytes: Vec<(&[u8], &[u8])> = vec![
        (b"\x00", b"\x02\x00"),
        (b"\x02\x00", b"\x05\x00"),
        (b"\x05\x00", b"\xFF"),
    ];
    let check_range = move |resp: &Response| {
        let (start_last_bytes, end_last_bytes) = expected_ranges_last_bytes.remove(0);
        let start = resp.get_range().get_start();
        let end = resp.get_range().get_end();
        assert_eq!(&start[ignored_suffix_len..], start_last_bytes);

        assert_eq!(&end[ignored_suffix_len..], end_last_bytes);
    };

    let resps = handle_streaming_select(&endpoint, req, check_range);
    assert_eq!(resps.len(), 3);
    let expected_output_counts = vec![vec![2_i64], vec![2_i64], vec![1_i64]];
    for (i, resp) in resps.into_iter().enumerate() {
        let mut chunk = Chunk::default();
        chunk.merge_from_bytes(resp.get_data()).unwrap();
        assert_eq!(
            resp.get_output_counts(),
            expected_output_counts[i].as_slice(),
        );

        let chunks = vec![chunk];
        let chunk_data_limit = stream_row_limit * 3; // we have 3 fields.
        check_chunk_datum_count(&chunks, chunk_data_limit);

        let spliter = DagChunkSpliter::new(chunks, 3);
        let j = cmp::min((i + 1) * stream_row_limit, data.len());
        let cur_data = &data[i * stream_row_limit..j];
        for (row, &(id, name, cnt)) in spliter.zip(cur_data) {
            let name_datum = name.map(|s| s.as_bytes()).into();
            let expected_encoded = datum::encode_value(
                &mut EvalContext::default(),
                &[Datum::I64(id), name_datum, cnt.into()],
            )
            .unwrap();
            let result_encoded = datum::encode_value(&mut EvalContext::default(), &row).unwrap();
            assert_eq!(result_encoded, &*expected_encoded);
        }
    }
}
fn test_raftkv_precheck_write_with_ctx() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();

    // make sure leader has been elected.
    assert_eq!(cluster.must_get(b"k1"), None);

    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let follower = region
        .get_peers()
        .iter()
        .find(|p| p.get_id() != leader.get_id())
        .unwrap();

    let leader_storage = cluster.sim.rl().storages[&leader.get_id()].clone();
    let follower_storage = cluster.sim.rl().storages[&follower.get_id()].clone();

    // Assume this is a write request.
    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(region.get_peers()[0].clone());

    // The (write) request can be sent to the leader.
    leader_storage.precheck_write_with_ctx(&ctx).unwrap();
    // The (write) request should not be send to a follower.
    follower_storage.precheck_write_with_ctx(&ctx).unwrap_err();

    // Leader has network partition and it must be not leader any more.
    let filter = Box::new(RegionPacketFilter::new(
        region.get_id(),
        leader.get_store_id(),
    ));
    cluster
        .sim
        .wl()
        .add_recv_filter(leader.get_store_id(), filter.clone());
    cluster
        .sim
        .wl()
        .add_send_filter(leader.get_store_id(), filter);
    sleep_until_election_triggered(&cluster.cfg);
    leader_storage.precheck_write_with_ctx(&ctx).unwrap_err();
}
fn test_cp_backup_numbered() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=numbered")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}.~1~")),
        "How are you?\n"
    );
}
fn capture_names() {
    let re = regex!(r"(.)(?P<a>.)");
    assert_eq!(3, re.captures_len());
    assert_eq!((3, Some(3)), re.capture_names().size_hint());
    assert_eq!(vec![None, None, Some("a")],
               re.capture_names().collect::<Vec<_>>());
}
fn test_split_obs_lines_within_combined_shorts() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let name = "obs-lines-within-shorts";
    RandomFile::new(at, name).add_lines(400);

    scene
        .ucmd()
        .args(&["-x200de", name])
        .succeeds()
        .no_stderr()
        .no_stdout();
    let glob = Glob::new(at, ".", r"x\d\d$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn dashed_name() {
    let f = super::fixture();

    let resolver = Resolver::default();

    let data = [
        (f.clone(), "dash", f.join("node_modules/dash/index.js")),
        (f.clone(), "dash-name", f.join("node_modules/dash-name/index.js")),
        (f.join("node_modules/dash"), "dash", f.join("node_modules/dash/index.js")),
        (f.join("node_modules/dash"), "dash-name", f.join("node_modules/dash-name/index.js")),
        (f.join("node_modules/dash-name"), "dash", f.join("node_modules/dash/index.js")),
        (f.join("node_modules/dash-name"), "dash-name", f.join("node_modules/dash-name/index.js")),
    ];

    for (path, request, expected) in data {
        let resolved_path = resolver.resolve(&path, request).map(|f| f.full_path());
        assert_eq!(resolved_path, Ok(expected), "{path:?} {request}");
    }
}
fn test_macro_fuel() {
    let mut env = Environment::new();
    assert_eq!(env.fuel(), None);
    env.set_fuel(Some(100));
    assert_eq!(env.fuel(), Some(100));
    env.add_template(
        "test",
        "
        {% macro x() %}{% for item in range(5) %}...{% endfor %}{% endmacro %}
        {% for count in range(macros) %}{{ x() }}{% endfor %}
    ",
    )
    .unwrap();
    let t = env.get_template("test").unwrap();

    // this should succeed
    t.render(context!(macros => 3)).unwrap();

    // but running more macros should not
    let err = t.render(context!(macros => 5)).unwrap_err();
    assert_eq!(err.kind(), ErrorKind::OutOfFuel);
}
fn test_trap_return() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module
        (func $hello (import "" "hello"))
        (func (export "run") (call $hello))
        )
    "#;

    let module = Module::new(store.engine(), wat)?;
    let hello_type = FuncType::new(None, None);
    let hello_func = Func::new(&mut store, hello_type, |_, _, _| bail!("test 123"));

    let instance = Instance::new(&mut store, &module, &[hello_func.into()])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();
    assert!(format!("{e:?}").contains("test 123"));

    assert!(
        e.downcast_ref::<WasmBacktrace>().is_some(),
        "error should contain a WasmBacktrace"
    );

    Ok(())
}
fn test_negative_indexing() {
    let positive_lines_index = new_ucmd!().arg("-n").arg("5").arg(FOOBAR_TXT).run();

    let negative_lines_index = new_ucmd!().arg("-n").arg("-5").arg(FOOBAR_TXT).run();

    let positive_bytes_index = new_ucmd!().arg("-c").arg("20").arg(FOOBAR_TXT).run();

    let negative_bytes_index = new_ucmd!().arg("-c").arg("-20").arg(FOOBAR_TXT).run();

    assert_eq!(positive_lines_index.stdout(), negative_lines_index.stdout());
    assert_eq!(positive_bytes_index.stdout(), negative_bytes_index.stdout());
}
fn parse_complete_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::new();
    let string = b"1.2345e10";
    let result = parse::parse_complete::<f64, FORMAT>(string, &options);
    assert_eq!(result, Ok(1.2345e10));

    let string = b"1.2345e";
    let result = parse::parse_complete::<f64, FORMAT>(string, &options);
    assert!(result.is_err());

    let string = b"1.2345 ";
    let result = parse::parse_complete::<f64, FORMAT>(string, &options);
    assert!(result.is_err());
}
fn test_str_utils() {
    let s = "  asd#zcv #hk\t\n  ";
    assert_eq!("asd#zcv", s.purify());

    let s = "con256asd";
    assert!(s.fnmatch("*[2][3-6][5-9]?sd")); // spell-checker:disable-line

    let s = "zxc \t\nqwe jlk    hjl"; // spell-checker:disable-line
    let (k, v) = s.split_two();
    assert_eq!("zxc", k);
    assert_eq!("qwe jlk    hjl", v);
}
fn test_install_backup_numbered_with_numbered() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=numbered")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}.~1~")));
}
fn test_referenced_names_empty_bug() {
    let c = CodeGenerator::new("<unknown>", "");
    let instructions = c.finish().0;
    let rv = instructions.get_referenced_names(0);
    assert!(rv.is_empty());
}
fn typecheck() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "thunk"))
                (func (export "take-string") (param i32 i32))
                (func (export "two-args") (param i32 i32 i32))
                (func (export "ret-one") (result i32) unreachable)

                (memory (export "memory") 1)
                (func (export "realloc") (param i32 i32 i32 i32) (result i32)
                    unreachable)
            )
            (core instance $i (instantiate (module $m)))
            (func (export "thunk")
                (canon lift (core func $i "thunk"))
            )
            (func (export "take-string") (param "a" string)
                (canon lift (core func $i "take-string") (memory $i "memory") (realloc (func $i "realloc")))
            )
            (func (export "take-two-args") (param "a" s32) (param "b" (list u8))
                (canon lift (core func $i "two-args") (memory $i "memory") (realloc (func $i "realloc")))
            )
            (func (export "ret-tuple") (result "a" u8) (result "b" s8)
                (canon lift (core func $i "ret-one") (memory $i "memory") (realloc (func $i "realloc")))
            )
            (func (export "ret-tuple1") (result (tuple u32))
                (canon lift (core func $i "ret-one") (memory $i "memory") (realloc (func $i "realloc")))
            )
            (func (export "ret-string") (result string)
                (canon lift (core func $i "ret-one") (memory $i "memory") (realloc (func $i "realloc")))
            )
            (func (export "ret-list-u8") (result (list u8))
                (canon lift (core func $i "ret-one") (memory $i "memory") (realloc (func $i "realloc")))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let thunk = instance.get_func(&mut store, "thunk").unwrap();
    let take_string = instance.get_func(&mut store, "take-string").unwrap();
    let take_two_args = instance.get_func(&mut store, "take-two-args").unwrap();
    let ret_tuple = instance.get_func(&mut store, "ret-tuple").unwrap();
    let ret_tuple1 = instance.get_func(&mut store, "ret-tuple1").unwrap();
    let ret_string = instance.get_func(&mut store, "ret-string").unwrap();
    let ret_list_u8 = instance.get_func(&mut store, "ret-list-u8").unwrap();
    assert!(thunk.typed::<(), (u32,)>(&store).is_err());
    assert!(thunk.typed::<(u32,), ()>(&store).is_err());
    assert!(thunk.typed::<(), ()>(&store).is_ok());
    assert!(take_string.typed::<(), ()>(&store).is_err());
    assert!(take_string.typed::<(String,), ()>(&store).is_ok());
    assert!(take_string.typed::<(&str,), ()>(&store).is_ok());
    assert!(take_string.typed::<(&[u8],), ()>(&store).is_err());
    assert!(take_two_args.typed::<(), ()>(&store).is_err());
    assert!(take_two_args.typed::<(i32, &[u8]), (u32,)>(&store).is_err());
    assert!(take_two_args.typed::<(u32, &[u8]), ()>(&store).is_err());
    assert!(take_two_args.typed::<(i32, &[u8]), ()>(&store).is_ok());
    assert!(ret_tuple.typed::<(), ()>(&store).is_err());
    assert!(ret_tuple.typed::<(), (u8,)>(&store).is_err());
    assert!(ret_tuple.typed::<(), (u8, i8)>(&store).is_ok());
    assert!(ret_tuple1.typed::<(), ((u32,),)>(&store).is_ok());
    assert!(ret_tuple1.typed::<(), (u32,)>(&store).is_err());
    assert!(ret_string.typed::<(), ()>(&store).is_err());
    assert!(ret_string.typed::<(), (WasmStr,)>(&store).is_ok());
    assert!(ret_list_u8.typed::<(), (WasmList<u16>,)>(&store).is_err());
    assert!(ret_list_u8.typed::<(), (WasmList<i8>,)>(&store).is_err());
    assert!(ret_list_u8.typed::<(), (WasmList<u8>,)>(&store).is_ok());

    Ok(())
}
fn test_cp_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--parents")
        .arg(TEST_COPY_FROM_FOLDER_FILE)
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    assert_eq!(
        at.read(&format!(
            "{TEST_COPY_TO_FOLDER}/{TEST_COPY_FROM_FOLDER_FILE}"
        )),
        "Hello, World!\n"
    );
}
fn test_trap_stack_overflow() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module $rec_mod
            (func $run (export "run") (call $run))
        )
    "#;

    let module = Module::new(store.engine(), wat)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();

    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert!(trace.len() >= 32);
    for i in 0..trace.len() {
        assert_eq!(trace[i].module().name().unwrap(), "rec_mod");
        assert_eq!(trace[i].func_index(), 0);
        assert_eq!(trace[i].func_name(), Some("run"));
    }
    assert_eq!(e.downcast::<Trap>()?, Trap::StackOverflow);

    Ok(())
}
fn test_output_is_random_permutation() {
    let input_seq = vec![1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
    let input = input_seq
        .iter()
        .map(ToString::to_string)
        .collect::<Vec<String>>()
        .join("\n");

    let result = new_ucmd!().pipe_in(input.as_bytes()).succeeds();
    result.no_stderr();

    let mut result_seq: Vec<i32> = result
        .stdout_str()
        .split('\n')
        .filter(|x| !x.is_empty())
        .map(|x| x.parse().unwrap())
        .collect();
    result_seq.sort_unstable();
    assert_ne!(result.stdout_str(), input, "Output is not randomized");
    assert_eq!(result_seq, input_seq, "Output is not a permutation");
}
fn roundtrip_ident_with_dash() {
    let value = MyStructWithDashes {
        my_enum: MyEnumWithDashes::ThisIsMyUnitVariant,
        my_enum2: MyEnumWithDashes::ThisIsMyTupleVariant(false, -3),
        will_be_renamed: 32,
    };

    let serial = ron::ser::to_string(&value).unwrap();

    println!("Serialized: {}", serial);

    let deserial = ron::de::from_str(&serial);

    assert_eq!(Ok(value), deserial);
}
fn test_concurrent_requests_2_conns() {
    let mut options = ResolverOpts::default();

    // there are only 2 conns, so this matches that count
    options.num_concurrent_reqs = 2;

    // we want to make sure that both udp connections are called
    //   this will count down to 0 only if both are called.
    let on_send = OnSendBarrier::new(2);

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));

    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);

    let udp1_nameserver = mock_nameserver_on_send(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        options.clone(),
        on_send.clone(),
    );
    let udp2_nameserver = mock_nameserver_on_send(vec![], options.clone(), on_send);

    let pool = mock_nameserver_pool_on_send(
        vec![udp2_nameserver, udp1_nameserver],
        vec![],
        None,
        options,
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    // there's no actual network traffic happening, 1 sec should be plenty
    //   TODO: for some reason this timeout doesn't work, not clear why...
    // let future = Timeout::new(future, Duration::from_secs(1));

    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], udp_record);
}
fn file_too_large_config_limit() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert(PathBuf::from("biome.json"), CONFIG_FILE_SIZE_LIMIT);

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "file_too_large_config_limit",
        fs,
        console,
        result,
    ));
}
fn reinscribe_with_flag() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let inscribe = CommandBuilder::new("wallet inscribe --file tulip.png --fee-rate 5.0 ")
    .write("tulip.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  assert_eq!(rpc_server.descriptors().len(), 3);

  let txid = rpc_server.mine_blocks(1)[0].txdata[2].txid();

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);
  let request = ord_server.request(format!("/content/{}", inscribe.inscriptions[0].id));

  assert_eq!(request.status(), 200);

  let reinscribe = CommandBuilder::new(format!(
    "wallet inscribe --file orchid.png --fee-rate 1.1 --reinscribe --satpoint {txid}:0:0"
  ))
  .write("orchid.png", [1; 520])
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &["--index-sats"]);
  let request = ord_server.request(format!("/content/{}", reinscribe.inscriptions[0].id));

  assert_eq!(request.status(), 200);
  ord_server.assert_response_regex(
    format!("/sat/{}", 50 * COIN_VALUE),
    format!(
      ".*<dt>inscriptions</dt>.*<a href=/inscription/{}>.*<a href=/inscription/{}>.*",
      inscribe.inscriptions[0].id, reinscribe.inscriptions[0].id
    ),
  );
}
async fn stream_close_by_trailers_frame_releases_capacity() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let window_size = frame::DEFAULT_INITIAL_WINDOW_SIZE as usize;

    let h2 = async move {
        let (mut client, mut h2) = client::handshake(io).await.unwrap();
        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        // Send request
        let (resp1, mut s1) = client.send_request(request, false).unwrap();

        // This effectively reserves the entire connection window
        s1.reserve_capacity(window_size);

        // The capacity should be immediately available as nothing else is
        // happening on the stream.
        assert_eq!(s1.capacity(), window_size);

        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        // Create a second stream
        let (resp2, mut s2) = client.send_request(request, false).unwrap();

        // Request capacity
        s2.reserve_capacity(5);

        // There should be no available capacity (as it is being held up by
        // the previous stream
        assert_eq!(s2.capacity(), 0);

        // Closing the previous stream by sending a trailers frame will
        // release the capacity to s2
        s1.send_trailers(Default::default()).unwrap();

        // The capacity should be available
        assert_eq!(s2.capacity(), 5);

        // Send the frame
        s2.send_data("hello".into(), true).unwrap();

        // Drive both streams to prevent the handles from being dropped
        // (which will send a RST_STREAM) before the connection is closed.
        h2.drive(resp1).await.unwrap();
        h2.drive(resp2).await.unwrap();
    };

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        // Get the first frame
        assert_default_settings!(settings);
        srv.recv_frame(frames::headers(1).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        srv.recv_frame(frames::headers(3).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.send_frame(frames::headers(3).response(200)).await;
        srv.recv_frame(frames::headers(1).eos()).await;
        srv.recv_frame(frames::data(3, &b"hello"[..]).eos()).await;
    };
    join(srv, h2).await;
}
fn does_include_file_with_different_languages_and_files() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "overrides": [
    { "include": ["test.js"], "formatter": { "lineWidth": 120 }, "javascript": { "formatter": { "quoteStyle": "single" } } },
    {
        "include": ["test2.js"],
        "formatter": { "lineWidth": 120, "indentStyle": "space" },
        "javascript": { "formatter": { "semicolons": "asNeeded" } },
        "json": { "formatter": { "indentStyle": "space", "lineWidth": 20, "indentWidth": 4 } }
    },
    {
        "include": ["test3.json"],
        "formatter": { "lineWidth": 120, "indentStyle": "space" },
        "json": { "formatter": { "indentStyle": "space", "lineWidth": 20, "indentWidth": 4 } }
    }
  ]
}

"#
            .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let json_file = Path::new("test3.json");
    fs.insert(json_file.into(), UNFORMATTED_JSON.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
                json_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test, FORMATTED_WITH_SINGLE_QUOTES);
    assert_file_contents(&fs, test2, FORMATTED_WITH_NO_SEMICOLONS);
    assert_file_contents(&fs, json_file, FORMATTED_JSON);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_languages_and_files",
        fs,
        console,
        result,
    ));
}
fn lint_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
extend-select = ["B", "Q"]

[lint.flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .arg("--config")
        .arg(&ruff_toml)
        .arg("-")
        .pass_stdin(r#"a = "abcba".strip("aba")"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:5: Q000 [*] Double quotes found but single quotes preferred
    -:1:5: B005 Using `.strip()` with multi-character strings is misleading
    -:1:19: Q000 [*] Double quotes found but single quotes preferred
    Found 3 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
fn buffered_client_complete_io_for_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    assert!(client.is_handshaking());
    let (rdlen, wrlen) = client
        .complete_io(&mut OtherSession::new_buffered(&mut server))
        .unwrap();
    assert!(rdlen > 0 && wrlen > 0);
    assert!(!client.is_handshaking());
    assert!(!client.wants_write());
}
fn test_sst_recovery_overlap_range_sst_exist() {
    let (mut cluster, pd_client, engine1) = create_tikv_cluster_with_one_node_damaged();

    // create a new sst [1,7] flushed to L0.
    cluster.must_put_cf(CF_DEFAULT, b"1", b"val_1");
    cluster.must_put_cf(CF_DEFAULT, b"3", b"val_1");
    cluster.must_put_cf(CF_DEFAULT, b"4", b"val_1");
    cluster.must_put_cf(CF_DEFAULT, b"5", b"val_1");
    cluster.must_put_cf(CF_DEFAULT, b"7", b"val_1");
    cluster.flush_data();

    let files = engine1.as_inner().get_live_files();
    assert_eq!(files.get_files_count(), 4);

    // Remove peers for safe deletion of files in sst recovery.
    let region = cluster.get_region(b"2");
    let peer = find_peer(&region, 1).unwrap();
    pd_client.must_remove_peer(region.id, peer.clone());
    let region = cluster.get_region(b"4");
    let peer = find_peer(&region, 1).unwrap();
    pd_client.must_remove_peer(region.id, peer.clone());

    // Peer has been removed from store 1 so it won't get this replica.
    cluster.must_put_cf(CF_DEFAULT, b"4", b"val_2");

    std::thread::sleep(CHECK_DURATION);
    must_get_equal(&engine1, b"1", b"val_1");
    must_get_equal(&engine1, b"4", b"val_1");
    must_get_equal(&engine1, b"7", b"val_1");

    // Validate the damaged sst has been deleted.
    compact_files_to_target_level(&engine1, true, 3).unwrap();
    let files = engine1.as_inner().get_live_files();
    assert_eq!(files.get_files_count(), 1);

    must_get_equal(&engine1, b"4", b"val_1");
    assert_eq!(cluster.must_get(b"4").unwrap(), b"val_2");
}
fn downgrade_severity() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_LINTER_DOWNGRADE_DIAGNOSTIC.as_bytes(),
    );

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), NO_DEBUGGER.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    assert_eq!(
        messages
            .iter()
            .filter(|m| m.level == LogLevel::Error)
            .filter(|m| {
                let content = format!("{:#?}", m.content);
                content.contains("suspicious/noDebugger")
            })
            .count(),
        1
    );

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "downgrade_severity",
        fs,
        console,
        result,
    ));
}
fn test_sync_host_func() {
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    atoms::add_to_linker(&mut linker, |cx| cx).unwrap();
    let mut store = store(&engine);
    let shim_mod = shim_module(&engine);
    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();

    let mut results = [Val::I32(0)];
    shim_inst
        .get_func(&mut store, "int_float_args_shim")
        .unwrap()
        .call(&mut store, &[0i32.into(), 123.45f32.into()], &mut results)
        .unwrap();

    assert_eq!(
        results[0].unwrap_i32(),
        types::Errno::Ok as i32,
        "int_float_args errno"
    );
}
fn render_filter_section() {
    let inputs = vec![
        ("{% filter upper %}Hello{% endfilter %}", "HELLO"),
        ("{% filter upper %}Hello{% if true %} world{% endif %}{% endfilter %}", "HELLO WORLD"),
        ("{% filter upper %}Hello {% for i in range(end=3) %}i{% endfor %}{% endfilter %}", "HELLO III"),
        (
            "{% filter upper %}Hello {% for i in range(end=3) %}{% if i == 1 %}{% break %} {% endif %}i{% endfor %}{% endfilter %}",
            "HELLO I",
        ),
        ("{% filter title %}Hello {% if true %}{{ 'world' | upper | safe }}{% endif %}{% endfilter %}", "Hello World"),
        ("{% filter safe %}{% filter upper %}<Hello>{% endfilter %}{% endfilter%}", "<HELLO>")
    ];

    let context = Context::new();
    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_deadline_2() {
    // It should not even take any snapshots when request is outdated from the
    // beginning.
    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    fail::cfg("rockskv_async_snapshot", "panic").unwrap();
    fail::cfg("deadline_check_fail", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_other_error().contains("exceeding the deadline"));
}
fn invoke_error() {
  let tmp = temptree! {
    justfile: JUSTFILE,
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .output()
    .unwrap();

  assert!(!output.status.success());

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--edit")
    .env("VISUAL", "/")
    .output()
    .unwrap();

  assert_eq!(
    String::from_utf8_lossy(&output.stderr),
    if cfg!(windows) {
      "error: Editor `/` invocation failed: program path has no file name\n"
    } else {
      "error: Editor `/` invocation failed: Permission denied (os error 13)\n"
    }
  );
}
fn lint_warning() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), LINT_ERROR.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, LINT_ERROR);

    // The console buffer is expected to contain the following message:
    // 0: "Formatter would have printed the following content"
    // 1: "Compared 1 files"
    assert_eq!(
        console.out_buffer.len(),
        2,
        "console {:#?}",
        console.out_buffer
    );

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "formatter_lint_warning",
        fs,
        console,
        result,
    ));
}
fn zero_rtt_rejection() {
    let _guard = subscribe();
    let mut server_crypto = server_crypto();
    server_crypto.alpn_protocols = vec!["foo".into(), "bar".into()];
    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));
    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);
    let mut client_crypto = client_crypto();
    client_crypto.alpn_protocols = vec!["foo".into()];
    let client_config = ClientConfig::new(Arc::new(client_crypto.clone()));

    // Establish normal connection
    let client_ch = pair.begin_connect(client_config);
    pair.drive();
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Connected)
    );
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    pair.client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .close(pair.time, VarInt(0), [][..].into());
    pair.drive();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::ConnectionLost { .. })
    );
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    pair.client.connections.clear();
    pair.server.connections.clear();

    // Changing protocols invalidates 0-RTT
    client_crypto.alpn_protocols = vec!["bar".into()];
    let client_config = ClientConfig::new(Arc::new(client_crypto));
    info!("resuming session");
    let client_ch = pair.begin_connect(client_config);
    assert!(pair.client_conn_mut(client_ch).has_0rtt());
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    const MSG: &[u8] = b"Hello, 0-RTT!";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive();
    assert!(!pair.client_conn_mut(client_ch).accepted_0rtt());
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Connected)
    );
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    let s2 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    assert_eq!(s, s2);

    let mut recv = pair.server_recv(server_ch, s2);
    let mut chunks = recv.read(false).unwrap();
    assert_eq!(chunks.next(usize::MAX), Err(ReadError::Blocked));
    let _ = chunks.finalize();
    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);
}
fn default_namespace_reset() {
    let mut r = NsReader::from_str(r#"<a xmlns="www1"><b xmlns=""></b></a>"#);
    r.trim_text(true);

    // <a>
    match r.read_resolved_event() {
        Ok((ns, Start(_))) => assert_eq!(ns, Bound(Namespace(b"www1"))),
        e => panic!(
            "expecting outer start element with to resolve to 'www1', got {:?}",
            e
        ),
    }

    // <b>
    match r.read_resolved_event() {
        Ok((ns, Start(_))) => assert_eq!(ns, Unbound),
        e => panic!(
            "expecting inner start element with no namespace, got {:?}",
            e
        ),
    }
    // </b>
    match r.read_resolved_event() {
        Ok((ns, End(_))) => assert_eq!(ns, Unbound),
        e => panic!("expecting inner end element with no namespace, got {:?}", e),
    }

    // </a>
    match r.read_resolved_event() {
        Ok((ns, End(_))) => assert_eq!(ns, Bound(Namespace(b"www1"))),
        e => panic!(
            "expecting outer end element with to resolve to 'www1', got {:?}",
            e
        ),
    }
}
fn test_server_close() {
    do_test(
        3012,
        |mut cli_sock| {
            cli_sock.send(Message::Text("Hello WebSocket".into())).unwrap();

            let message = cli_sock.read().unwrap(); // receive close from server
            assert!(message.is_close());

            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed
            match err {
                Error::ConnectionClosed => {}
                _ => panic!("unexpected error: {:?}", err),
            }
        },
        |mut srv_sock| {
            let message = srv_sock.read().unwrap();
            assert_eq!(message.into_data(), b"Hello WebSocket");

            srv_sock.close(None).unwrap(); // send close to client

            let message = srv_sock.read().unwrap(); // receive acknowledgement
            assert!(message.is_close());

            let err = srv_sock.read().unwrap_err(); // now we should get ConnectionClosed
            match err {
                Error::ConnectionClosed => {}
                _ => panic!("unexpected error: {:?}", err),
            }
        },
    );
}
fn parse_delete_statement_for_multi_tables_with_using() {
    let sql = "DELETE FROM schema1.table1, schema2.table2 USING schema1.table1 JOIN schema2.table2 ON schema2.table2.pk = schema1.table1.col1 WHERE schema2.table2.col2 = 1";
    match verified_stmt(sql) {
        Statement::Delete {
            from,
            using: Some(using),
            ..
        } => {
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("schema1"), Ident::new("table1")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                from[0].relation
            );
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("schema2"), Ident::new("table2")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                from[1].relation
            );
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("schema1"), Ident::new("table1")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                using[0].relation
            );
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("schema2"), Ident::new("table2")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                using[0].joins[0].relation
            );
        }
        _ => unreachable!(),
    }
}
fn test_split_separator_nul_lines() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--lines=2", "-t", "\\0", "separator_nul.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\x002\0");
    assert_eq!(file_read(&at, "xab"), "3\x004\0");
    assert_eq!(file_read(&at, "xac"), "5\0");
    assert!(!at.plus("xad").exists());
}
fn test_mkdir_parent_mode_check_existing_parent() {
    let _guard = TEST_MUTEX.lock();
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir("a");

    let default_umask: mode_t = 0o160;
    let original_umask = unsafe { umask(default_umask) };

    ucmd.arg("-p")
        .arg("a/b/c")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert!(at.dir_exists("a"));
    // parent dirs that already exist do not get their permissions modified
    assert_eq!(
        at.metadata("a").permissions().mode() as mode_t,
        (!original_umask & 0o777) + 0o40000
    );
    assert!(at.dir_exists("a/b"));
    assert_eq!(
        at.metadata("a/b").permissions().mode() as mode_t,
        ((!default_umask & 0o777) | 0o300) + 0o40000
    );
    assert!(at.dir_exists("a/b/c"));
    assert_eq!(
        at.metadata("a/b/c").permissions().mode() as mode_t,
        (!default_umask & 0o777) + 0o40000
    );

    unsafe {
        umask(original_umask);
    }
}
fn test_exceed_max_commit_ts_in_the_middle_of_prewrite() {
    let engine = TestEngineBuilder::new().build().unwrap();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .build()
        .unwrap();
    let cm = storage.get_concurrency_manager();

    let (prewrite_tx, prewrite_rx) = channel();
    // Pause between getting max ts and store the lock in memory
    fail::cfg("before-set-lock-in-memory", "pause").unwrap();

    cm.update_max_ts(40.into());
    let mutations = vec![
        Mutation::make_put(Key::from_raw(b"k1"), b"v".to_vec()),
        Mutation::make_put(Key::from_raw(b"k2"), b"v".to_vec()),
    ];
    storage
        .sched_txn_command(
            commands::Prewrite::new(
                mutations.clone(),
                b"k1".to_vec(),
                10.into(),
                20000,
                false,
                2,
                11.into(),
                50.into(),
                Some(vec![]),
                false,
                AssertionLevel::Off,
                Context::default(),
            ),
            Box::new(move |res| {
                prewrite_tx.send(res).unwrap();
            }),
        )
        .unwrap();
    // sleep a while so the first key gets max ts.
    thread::sleep(Duration::from_millis(200));

    cm.update_max_ts(51.into());
    fail::remove("before-set-lock-in-memory");
    let res = prewrite_rx.recv().unwrap().unwrap();
    assert!(res.min_commit_ts.is_zero());
    assert!(res.one_pc_commit_ts.is_zero());

    let locks = block_on(storage.scan_lock(
        Context::default(),
        20.into(),
        Some(Key::from_raw(b"k1")),
        None,
        2,
    ))
    .unwrap();
    assert_eq!(locks.len(), 2);
    assert_eq!(locks[0].get_key(), b"k1");
    assert!(locks[0].get_use_async_commit());
    assert_eq!(locks[0].get_min_commit_ts(), 41);
    assert_eq!(locks[1].get_key(), b"k2");
    assert!(!locks[1].get_use_async_commit());

    // Send a duplicated request to test the idempotency of prewrite when falling
    // back to 2PC.
    let (prewrite_tx, prewrite_rx) = channel();
    storage
        .sched_txn_command(
            commands::Prewrite::new(
                mutations,
                b"k1".to_vec(),
                10.into(),
                20000,
                false,
                2,
                11.into(),
                50.into(),
                Some(vec![]),
                false,
                AssertionLevel::Off,
                Context::default(),
            ),
            Box::new(move |res| {
                prewrite_tx.send(res).unwrap();
            }),
        )
        .unwrap();
    let res = prewrite_rx.recv().unwrap().unwrap();
    assert!(res.min_commit_ts.is_zero());
    assert!(res.one_pc_commit_ts.is_zero());
}
fn deflate_decoder_empty_read() {
    let original: &[u8] = b"Lorem ipsum dolor sit amet.";
    let mut encoder =
        flate2::write::DeflateEncoder::new(Vec::new(), flate2::Compression::default());
    encoder.write_all(original).unwrap();
    let encoded: Vec<u8> = encoder.finish().unwrap();
    let mut decoder = flate2::read::DeflateDecoder::new(encoded.as_slice());
    assert_eq!(decoder.read(&mut []).unwrap(), 0);
    let mut decoded = Vec::new();
    decoder.read_to_end(&mut decoded).unwrap();
    assert_eq!(decoded.as_slice(), original);
}
fn format_is_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("file.js"), ("--write")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, CUSTOM_FORMAT_BEFORE);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_is_disabled",
        fs,
        console,
        result,
    ));
}
fn parse_variable_tag_lit_math_expression_with_parentheses() {
    let ast = parse("{{ (count + 1) * 2.5 }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Math(MathExpr {
                lhs: Box::new(Expr::new(ExprVal::Math(MathExpr {
                    lhs: Box::new(Expr::new(ExprVal::Ident("count".to_string()))),
                    operator: MathOperator::Add,
                    rhs: Box::new(Expr::new(ExprVal::Int(1))),
                },))),
                operator: MathOperator::Mul,
                rhs: Box::new(Expr::new(ExprVal::Float(2.5))),
            },))
        )
    );
}
fn test_witness_leader() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k1", b"v1");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // can't make leader to witness
    cluster
        .pd_client
        .switch_witnesses(region.get_id(), vec![peer_on_store1.get_id()], vec![true]);

    std::thread::sleep(Duration::from_millis(100));
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap().store_id,
        1
    );
    // leader changes to witness failed, so still can get the value
    must_get_equal(&cluster.get_engine(nodes[0]), b"k1", b"v1");

    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    // can't transfer leader to witness
    cluster.transfer_leader(region.get_id(), peer_on_store3);
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap().store_id,
        nodes[0],
    );
}
fn diff_shows_unsafe_fixes_with_opt_in() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601,UP034",
                "--diff",
                "--unsafe-fixes",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    @@ -1,2 +1,2 @@
    -x = {'a': 1, 'a': 1}
    -print(('foo'))
    +x = {'a': 1}
    +print('foo')


    ----- stderr -----
    Would fix 2 errors.
    "###
    );
}
fn calculate_shl_test() {
    // Binary will always be a 0 shift.
    assert_eq!(binary::calculate_shl(2, 1), 0);
    assert_eq!(binary::calculate_shl(3, 1), 0);
    assert_eq!(binary::calculate_shl(5, 1), 0);
    assert_eq!(binary::calculate_shl(-5, 1), 0);
    assert_eq!(binary::calculate_shl(-3, 1), 0);
    assert_eq!(binary::calculate_shl(-2, 1), 0);

    // Can have a 0 or 1 shift for base 4.
    assert_eq!(binary::calculate_shl(2, 2), 0);
    assert_eq!(binary::calculate_shl(3, 2), 1);
    assert_eq!(binary::calculate_shl(4, 2), 0);
    assert_eq!(binary::calculate_shl(-4, 2), 0);
    assert_eq!(binary::calculate_shl(-3, 2), 1);
    assert_eq!(binary::calculate_shl(-2, 2), 0);

    // Octal can have a `[0, 2]` shift.
    assert_eq!(binary::calculate_shl(2, 3), 2);
    assert_eq!(binary::calculate_shl(3, 3), 0);
    assert_eq!(binary::calculate_shl(4, 3), 1);
    assert_eq!(binary::calculate_shl(-3, 3), 0);
    assert_eq!(binary::calculate_shl(-2, 3), 1);
    assert_eq!(binary::calculate_shl(-1, 3), 2);
}
fn options_test() {
    let mut opts = Options::new();

    unsafe {
        opts.set_max_significant_digits(num::NonZeroUsize::new(10));
        opts.set_min_significant_digits(num::NonZeroUsize::new(5));
        opts.set_positive_exponent_break(num::NonZeroI32::new(9));
        opts.set_negative_exponent_break(num::NonZeroI32::new(-9));
        opts.set_round_mode(options::RoundMode::Truncate);
        opts.set_trim_floats(true);
        opts.set_exponent(b'^');
        opts.set_decimal_point(b',');
        opts.set_nan_string(Some(b"nan"));
        opts.set_inf_string(Some(b"Infinity"));
    }

    assert_eq!(opts.max_significant_digits().unwrap().get(), 10);
    assert_eq!(opts.min_significant_digits().unwrap().get(), 5);
    assert_eq!(opts.positive_exponent_break().unwrap().get(), 9);
    assert_eq!(opts.negative_exponent_break().unwrap().get(), -9);
    assert_eq!(opts.round_mode(), options::RoundMode::Truncate);
    assert_eq!(opts.trim_floats(), true);
    assert_eq!(opts.exponent(), b'^');
    assert_eq!(opts.decimal_point(), b',');
    assert_eq!(opts.nan_string(), Some("nan".as_bytes()));
    assert_eq!(opts.inf_string(), Some("Infinity".as_bytes()));
    assert!(opts.is_valid());

    assert_eq!(Options::builder(), OptionsBuilder::new());
    assert_eq!(opts.rebuild().build(), Ok(opts));
}
fn test_serialize_char() {
    let value = json!(
        ({
            let mut map = BTreeMap::new();
            map.insert('c', ());
            map
        })
    );
    assert_eq!(&Value::Null, value.get("c").unwrap());
}
fn parse_create_table_clone() {
    let sql = "CREATE OR REPLACE TABLE a CLONE a_tmp";
    match verified_stmt(sql) {
        Statement::CreateTable { name, clone, .. } => {
            assert_eq!(ObjectName(vec![Ident::new("a")]), name);
            assert_eq!(Some(ObjectName(vec![(Ident::new("a_tmp"))])), clone)
        }
        _ => unreachable!(),
    }
}
fn owned_get_signatures() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<u32, u32> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        for i in 0..10 {
            table.insert(&i, &(i + 1)).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();

    assert_eq!(2, table.get(&1).unwrap().unwrap().value());

    let mut iter: Range<u32, u32> = table.range::<u32>(..).unwrap();
    for i in 0..10 {
        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);
    }
    assert!(iter.next().is_none());
    let mut iter: Range<u32, u32> = table.range(0..10).unwrap();
    for i in 0..10 {
        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);
    }
    assert!(iter.next().is_none());
    let mut iter = table.range::<&u32>(&0..&10).unwrap();
    for i in 0..10 {
        assert_eq!(iter.next().unwrap().unwrap().1.value(), i + 1);
    }
    assert!(iter.next().is_none());
}
fn test_i32_min() {
    assert_eq!(
        std::i32::MIN,
        from_str(&to_string(&std::i32::MIN).unwrap()).unwrap()
    );
}
fn test_mv_backup_simple() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=simple")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn creates_config_file() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("init")].as_slice()),
    );
    assert!(result.is_ok(), "run_cli returned {result:?}");

    let file_path = Path::new("biome.json");

    let mut file = fs
        .open(file_path)
        .expect("configuration file was not written on disk");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");
    let parsed = parse_json(CONFIG_INIT_DEFAULT, JsonParserOptions::default());
    let formatted =
        biome_json_formatter::format_node(JsonFormatOptions::default(), &parsed.syntax())
            .expect("valid format document")
            .print()
            .expect("valid format document");
    assert_eq!(content, formatted.as_code());

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "creates_config_file",
        fs,
        console,
        result,
    ));
}
fn extends_config_ok_linter_not_formatter() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = Path::new("biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["format.json", "linter.json"] }"#,
    );
    let format = Path::new("format.json");
    fs.insert(format.into(), r#"{ "formatter": { "enabled": true } }"#);
    let lint = Path::new("linter.json");
    fs.insert(
        lint.into(),
        r#"{
  "linter": {
    "rules": {
      "all": false,
      "suspicious": {
        "noDebugger": "warn"
      }
    }
  }
}
        "#,
    );

    let test_file = Path::new("test.js");
    fs.insert(test_file.into(), r#"debugger; console.log("string"); "#);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), test_file.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "extends_config_ok_linter_not_formatter",
        fs,
        console,
        result,
    ));
}
fn test_report_buckets() {
    let region_id = 2;
    let mut cop_cfg = CopConfig::default();
    cop_cfg.enable_region_bucket = Some(true);
    cop_cfg.region_bucket_size = ReadableSize::kb(1);
    let mut config = v2_default_config();
    config.region_split_check_diff = Some(ReadableSize::kb(1));
    let cluster = Cluster::with_cop_cfg(Some(config), cop_cfg);
    let store_id = cluster.node(0).id();
    let router = &cluster.routers[0];

    // When there is only one peer, it should campaign immediately.
    let mut req = RaftCmdRequest::default();
    req.mut_header().set_peer(new_peer(store_id, 3));
    req.mut_status_request()
        .set_cmd_type(StatusCmdType::RegionLeader);
    let res = router.query(region_id, req.clone()).unwrap();
    let status_resp = res.response().unwrap().get_status_response();
    assert_eq!(
        *status_resp.get_region_leader().get_leader(),
        new_peer(store_id, 3)
    );
    router.wait_applied_to_current_term(region_id, Duration::from_secs(3));

    // load data to split bucket.
    let mut suffix = String::from("");
    for _ in 0..200 {
        suffix.push_str("fake ");
    }

    let repeat: u64 = 10;
    let bytes = write_keys(&cluster, region_id, &suffix, repeat.try_into().unwrap());
    // To find the split keys, it should flush memtable manually.
    let mut cached = cluster.node(0).tablet_registry().get(region_id).unwrap();
    cached.latest().unwrap().flush_cf(CF_DEFAULT, true).unwrap();
    // send split region check to split bucket.
    router
        .send(region_id, PeerMsg::Tick(PeerTick::SplitRegionCheck))
        .unwrap();
    std::thread::sleep(std::time::Duration::from_millis(50));
    // report buckets to pd.
    router
        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))
        .unwrap();
    std::thread::sleep(std::time::Duration::from_millis(50));

    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();
    let mut buckets_tmp = vec![];
    let mut bucket_ranges = vec![];
    if let Some(buckets) = resp {
        assert!(buckets.get_keys().len() > 2);
        assert_eq!(buckets.get_region_id(), region_id);
        let write_bytes = buckets.get_stats().get_write_bytes();
        let write_keys = buckets.get_stats().get_write_keys();
        for i in 0..buckets.keys.len() - 1 {
            assert!(write_bytes[i] >= bytes);
            assert!(write_keys[i] >= repeat);
        }
        for i in 0..buckets.keys.len() - 1 {
            buckets_tmp.push(raftstore::store::Bucket::default());
            let bucket_range =
                raftstore::store::BucketRange(buckets.keys[i].clone(), buckets.keys[i + 1].clone());
            bucket_ranges.push(bucket_range);
        }
    }

    // report buckets to pd again, the write bytes and keys should be zero.
    router
        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))
        .unwrap();
    std::thread::sleep(std::time::Duration::from_millis(50));

    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();
    if let Some(buckets) = resp {
        assert_eq!(buckets.get_region_id(), region_id);
        let write_bytes = buckets.get_stats().get_write_bytes();
        let write_keys = buckets.get_stats().get_write_keys();
        for i in 0..buckets.keys.len() - 1 {
            assert!(write_bytes[i] == 0);
            assert!(write_keys[i] == 0);
        }
    }

    // send the same region buckets to refresh which needs to merge the last.
    let resp = block_on(cluster.node(0).pd_client().get_region_by_id(region_id)).unwrap();
    if let Some(region) = resp {
        let region_epoch = region.get_region_epoch().clone();
        for _ in 0..2 {
            let msg = PeerMsg::RefreshRegionBuckets {
                region_epoch: region_epoch.clone(),
                buckets: buckets_tmp.clone(),
                bucket_ranges: Some(bucket_ranges.clone()),
            };
            router.send(region_id, msg).unwrap();
            std::thread::sleep(std::time::Duration::from_millis(50));
        }
    }
    // report buckets to pd again, the write bytes and keys should be zero.
    router
        .send(region_id, PeerMsg::Tick(PeerTick::ReportBuckets))
        .unwrap();
    std::thread::sleep(std::time::Duration::from_millis(50));

    let resp = block_on(cluster.node(0).pd_client().get_buckets_by_id(region_id)).unwrap();
    if let Some(buckets) = resp {
        assert_eq!(buckets.get_region_id(), region_id);
        let write_bytes = buckets.get_stats().get_write_bytes();
        let write_keys = buckets.get_stats().get_write_keys();
        assert_eq!(write_bytes.len(), 1);
        assert_eq!(write_keys.len(), 1);
    }

    fn write_keys(cluster: &Cluster, region_id: u64, suffix: &str, repeat: usize) -> u64 {
        let router = &cluster.routers[0];
        let header = Box::new(router.new_request_for(region_id).take_header());
        for i in 0..repeat {
            let mut put = SimpleWriteEncoder::with_capacity(64);
            let mut key = format!("key-{}", i);
            key.push_str(suffix);
            put.put(CF_DEFAULT, key.as_bytes(), b"value");
            let (msg, sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());
            router.send(region_id, msg).unwrap();
            let _resp = block_on(sub.result()).unwrap();
        }
        ((suffix.as_bytes().len() + 10) * repeat)
            .try_into()
            .unwrap()
    }
}
fn pairs() {
    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);

    check_exact_size_iterator!(p.pairs());
    check_exact_size_iterator!(p.pairs_mut());
    check_exact_size_iterator!(p.into_pairs());

    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);

    assert_eq!(p.pairs().next_back().map(Pair::into_value), Some(&4));
    assert_eq!(
        p.pairs_mut().next_back().map(Pair::into_value),
        Some(&mut 4)
    );
    assert_eq!(p.into_pairs().next_back().map(Pair::into_value), Some(4));
}
fn default_options() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["format", "--isolated", "--stdin-filename", "test.py"])
        .arg("-")
        .pass_stdin(r#"
def foo(arg1, arg2,):
    print('Should\'t change quotes')


if condition:

    print('Hy "Micha"') # Should not change quotes

"#), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    def foo(
        arg1,
        arg2,
    ):
        print("Should't change quotes")


    if condition:
        print('Hy "Micha"')  # Should not change quotes

    ----- stderr -----
    "###);
}
fn map() {
    let mut map = Map::new();
    map.insert(Value::Char('a'), Value::Number(Number::new(1)));
    map.insert(Value::Char('b'), Value::Number(Number::new(2f64)));
    assert_eq!("{ 'a': 1, 'b': 2.0 }".parse(), Ok(Value::Map(map)));
}
fn test_backup_in_flashback() {
    let mut suite = TestSuite::new(3, 144 * 1024 * 1024, ApiVersion::V1);
    suite.must_kv_put(3, 1);
    // Prepare the flashback.
    let region = suite.cluster.get_region(b"key_0");
    suite.cluster.must_send_wait_flashback_msg(
        region.get_id(),
        kvproto::raft_cmdpb::AdminCmdType::PrepareFlashback,
    );
    // Start the backup.
    let tmp = Builder::new().tempdir().unwrap();
    let backup_ts = suite.alloc_ts();
    let storage_path = make_unique_dir(tmp.path());
    let rx = suite.backup(
        vec![],   // start
        vec![],   // end
        0.into(), // begin_ts
        backup_ts,
        &storage_path,
    );
    let resp = block_on(rx.collect::<Vec<_>>());
    assert!(!resp[0].has_error());
    // Finish the flashback.
    suite.cluster.must_send_wait_flashback_msg(
        region.get_id(),
        kvproto::raft_cmdpb::AdminCmdType::FinishFlashback,
    );
}
fn test_unsafe_recovery_early_return_after_exit_joint_state() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Changes the group config to
    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();
    let peer_on_store1 = find_peer(&region, nodes[1]).unwrap();
    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store0.clone());
    cluster.pd_client.must_add_peer(
        region.get_id(),
        new_learner_peer(nodes[0], peer_on_store0.get_id()),
    );
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store2.clone());
    cluster.pd_client.must_add_peer(
        region.get_id(),
        new_learner_peer(nodes[2], peer_on_store2.get_id()),
    );
    // Wait the new learner to be initialized.
    sleep_ms(100);
    pd_client.must_joint_confchange(
        region.get_id(),
        vec![
            (
                ConfChangeType::AddNode,
                new_peer(nodes[0], peer_on_store0.get_id()),
            ),
            (
                ConfChangeType::AddLearnerNode,
                new_learner_peer(nodes[1], peer_on_store1.get_id()),
            ),
        ],
    );
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());

    confirm_quorum_is_lost(&mut cluster, &region);
    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    let to_be_removed: Vec<metapb::Peer> = region
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    let mut demoted = true;
    for _ in 0..10 {
        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

        demoted = region
            .get_peers()
            .iter()
            .filter(|peer| peer.get_store_id() != nodes[0])
            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);
        if demoted {
            break;
        }
        sleep_ms(100);
    }
    assert_eq!(demoted, true);
}
fn intersect() {
    assert_eq!(range(1..2).intersect(range(2..3)), Some(range(2..2)));
    assert_eq!(range(1..5).intersect(range(2..3)), Some(range(2..3)));
    assert_eq!(range(1..2).intersect(range(3..4)), None);
}
fn test_symlink_dangling_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_dangling_file";
    let link = "test_symlink_dangling_file_link";

    ucmd.args(&["-s", file, link]).succeeds().no_stderr();
    assert!(!at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);
}
fn init_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("init"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "init_help",
        fs,
        console,
        result,
    ));
}
fn test_force_leader_twice_on_different_peers() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    // restart to clean lease
    cluster.stop_node(1);
    cluster.run_node(1).unwrap();
    cluster.stop_node(2);
    cluster.run_node(2).unwrap();
    confirm_quorum_is_lost(&mut cluster, &region);

    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // enter force leader on a different peer
    cluster.enter_force_leader(region.get_id(), 2, vec![3, 4, 5]);
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap(),
        *find_peer(&region, 1).unwrap()
    );

    let conf_change = new_change_peer_request(ConfChangeType::RemoveNode, new_peer(3, 3));
    let mut req = new_admin_request(region.get_id(), region.get_region_epoch(), conf_change);
    req.mut_header()
        .set_peer(find_peer(&region, 2).unwrap().clone());
    let resp = cluster
        .call_command(req, Duration::from_millis(10))
        .unwrap();
    let mut not_leader = kvproto::errorpb::NotLeader {
        region_id: region.get_id(),
        ..Default::default()
    };
    not_leader.set_leader(find_peer(&region, 1).unwrap().clone());
    assert_eq!(resp.get_header().get_error().get_not_leader(), &not_leader,);

    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn save_points_and_counts() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.put(b"a", b"").unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.rollback_to_save_point().unwrap();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.put(b"a", b"").unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.pop_save_point().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.clear();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.put(b"a", b"").unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.write().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.rollback_to_save_point().unwrap();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.put(b"a", b"").unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.write().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.pop_save_point().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), 1);

    wb.clear();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.rollback_to_save_point().unwrap();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.pop_save_point().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.clear();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.write().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.rollback_to_save_point().unwrap();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    wb.set_save_point();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);

    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.write().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.pop_save_point().unwrap();

    assert_eq!(wb.is_empty(), false);
    assert_eq!(wb.count(), max_keys);

    wb.clear();

    assert_eq!(wb.is_empty(), true);
    assert_eq!(wb.count(), 0);
}
fn test_fail_change_directory() {
    let scene = TestScenario::new(util_name!());
    let some_non_existing_path = "some_nonexistent_path";
    assert!(!Path::new(some_non_existing_path).is_dir());

    let out = scene
        .ucmd()
        .arg("--chdir")
        .arg(some_non_existing_path)
        .arg("pwd")
        .fails()
        .stderr_move_str();
    assert!(out.contains("env: cannot change directory to "));
}
fn top_level_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-select = ["B", "Q"]

[flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .arg("--config")
        .arg(&ruff_toml)
        .args(["--stdin-filename", "test.py"])
        .arg("-")
        .pass_stdin(r#"a = "abcba".strip("aba")"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    test.py:1:5: Q000 [*] Double quotes found but single quotes preferred
    test.py:1:5: B005 Using `.strip()` with multi-character strings is misleading
    test.py:1:19: Q000 [*] Double quotes found but single quotes preferred
    Found 3 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
fn iadd_small_test() {
    // Overflow check (single)
    // This should set all the internal data values to 0, the top
    // value to (1<<31), and the bottom value to (4>>1).
    // This is because the max_value + 1 leads to all 0s, we set the
    // topmost bit to 1.
    let mut x = Bigint {
        data: from_u32(&[4294967295]),
    };
    x.iadd_small(5);
    assert_eq!(x.data, from_u32(&[4, 1]));

    // No overflow, single value
    let mut x = Bigint {
        data: from_u32(&[5]),
    };
    x.iadd_small(7);
    assert_eq!(x.data, from_u32(&[12]));

    // Single carry, internal overflow
    let mut x = Bigint::from_u64(0x80000000FFFFFFFF);
    x.iadd_small(7);
    assert_eq!(x.data, from_u32(&[6, 0x80000001]));

    // Double carry, overflow
    let mut x = Bigint::from_u64(0xFFFFFFFFFFFFFFFF);
    x.iadd_small(7);
    assert_eq!(x.data, from_u32(&[6, 0, 1]));
}
fn test_hex() {
    assert_eq!(from_str("0x507"), Ok(0x507));
    assert_eq!(from_str("0x1A5"), Ok(0x1A5));
    assert_eq!(from_str("0x53C537"), Ok(0x53C537));

    assert_eq!(
        from_str::<u8>("0x"),
        Err(SpannedError {
            code: Error::ExpectedInteger,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0x_1"),
        Err(SpannedError {
            code: Error::UnderscoreAtBeginning,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0xFFF"),
        Err(SpannedError {
            code: Error::IntegerOutOfBounds,
            position: Position { line: 1, col: 6 },
        })
    );
}
fn test_region_collection_get_regions_in_range() {
    let mut cluster = new_node_cluster(0, 3);

    let (tx, rx) = channel();
    cluster
        .sim
        .wl()
        .post_create_coprocessor_host(Box::new(move |id, host| {
            let p = RegionInfoAccessor::new(host);
            tx.send((id, p)).unwrap()
        }));

    cluster.run();
    let region_info_providers: HashMap<_, _> = rx.try_iter().collect();
    assert_eq!(region_info_providers.len(), 3);
    let regions = prepare_cluster(&mut cluster);

    for node_id in cluster.get_node_ids() {
        let engine = &region_info_providers[&node_id];

        let result = engine.get_regions_in_range(b"", b"").unwrap();
        assert_eq!(result, regions);

        let result = engine.get_regions_in_range(b"k1", b"k3").unwrap();
        assert_eq!(&result, &regions[1..3]);

        let result = engine.get_regions_in_range(b"k3", b"k8").unwrap();
        assert_eq!(&result, &regions[2..5]);

        let result = engine.get_regions_in_range(b"k6", b"k8").unwrap();
        assert_eq!(&result, &regions[3..5]);

        let result = engine.get_regions_in_range(b"k7", b"k99").unwrap();
        assert_eq!(&result, &regions[4..6]);

        let result = engine.get_regions_in_range(b"k99", b"").unwrap();
        assert_eq!(&result, &regions[5..6]);
    }

    for (_, p) in region_info_providers {
        p.stop();
    }
}
fn parse_variable_tag_lit() {
    let ast = parse("{{ 2 }}{{ 3.18 }}{{ \"hey\" }}{{ true }}").unwrap();
    assert_eq!(ast[0], Node::VariableBlock(WS::default(), Expr::new(ExprVal::Int(2))));
    assert_eq!(ast[1], Node::VariableBlock(WS::default(), Expr::new(ExprVal::Float(3.18))));
    assert_eq!(
        ast[2],
        Node::VariableBlock(WS::default(), Expr::new(ExprVal::String("hey".to_string()))),
    );
    assert_eq!(ast[3], Node::VariableBlock(WS::default(), Expr::new(ExprVal::Bool(true))));
}
fn test_status() {
    let cluster = Cluster::default();
    let router = &cluster.routers[0];
    // When there is only one peer, it should campaign immediately.
    let mut req = RaftCmdRequest::default();
    req.mut_header().set_peer(new_peer(1, 3));
    req.mut_status_request()
        .set_cmd_type(StatusCmdType::RegionLeader);
    let res = router.query(2, req.clone()).unwrap();
    let status_resp = res.response().unwrap().get_status_response();
    assert_eq!(
        *status_resp.get_region_leader().get_leader(),
        new_peer(1, 3)
    );

    req.mut_status_request()
        .set_cmd_type(StatusCmdType::RegionDetail);
    let res = router.query(2, req.clone()).unwrap();
    let status_resp = res.response().unwrap().get_status_response();
    let detail = status_resp.get_region_detail();
    assert_eq!(*detail.get_leader(), new_peer(1, 3));
    let region = detail.get_region();
    assert_eq!(region.get_id(), 2);
    assert!(region.get_start_key().is_empty());
    assert!(region.get_end_key().is_empty());
    assert_eq!(*region.get_peers(), vec![new_peer(1, 3)]);
    assert_eq!(region.get_region_epoch().get_version(), 1);
    assert_eq!(region.get_region_epoch().get_conf_ver(), 1);

    // Invalid store id should return error.
    req.mut_header().mut_peer().set_store_id(4);
    let res = router.query(2, req).unwrap();
    let resp = res.response().unwrap();
    assert!(
        resp.get_header().get_error().has_store_not_match(),
        "{:?}",
        resp
    );

    // TODO: add a peer then check for region change and leadership change.
}
fn u64_pow2_test() {
    let values: &[u64] = &[
        0,
        1,
        2,
        3,
        4,
        5,
        7,
        8,
        9,
        15,
        16,
        17,
        31,
        32,
        33,
        63,
        64,
        65,
        127,
        128,
        129,
        255,
        256,
        257,
        511,
        512,
        513,
        1023,
        1024,
        1025,
        2047,
        2048,
        2049,
        4095,
        4096,
        4097,
        8191,
        8192,
        8193,
        16383,
        16384,
        16385,
        32767,
        32768,
        32769,
        65535,
        65536,
        65537,
        131071,
        131072,
        131073,
        262143,
        262144,
        262145,
        524287,
        524288,
        524289,
        1048575,
        1048576,
        1048577,
        2097151,
        2097152,
        2097153,
        4194303,
        4194304,
        4194305,
        8388607,
        8388608,
        8388609,
        16777215,
        16777216,
        16777217,
        33554431,
        33554432,
        33554433,
        67108863,
        67108864,
        67108865,
        134217727,
        134217728,
        134217729,
        268435455,
        268435456,
        268435457,
        536870911,
        536870912,
        536870913,
        1073741823,
        1073741824,
        1073741825,
        2147483647,
        2147483648,
        2147483649,
        4294967295,
        4294967296,
        4294967297,
        8589934591,
        8589934592,
        8589934593,
        17179869183,
        17179869184,
        17179869185,
        34359738367,
        34359738368,
        34359738369,
        68719476735,
        68719476736,
        68719476737,
        137438953471,
        137438953472,
        137438953473,
        274877906943,
        274877906944,
        274877906945,
        549755813887,
        549755813888,
        549755813889,
        1099511627775,
        1099511627776,
        1099511627777,
        2199023255551,
        2199023255552,
        2199023255553,
        4398046511103,
        4398046511104,
        4398046511105,
        8796093022207,
        8796093022208,
        8796093022209,
        17592186044415,
        17592186044416,
        17592186044417,
        35184372088831,
        35184372088832,
        35184372088833,
        70368744177663,
        70368744177664,
        70368744177665,
        140737488355327,
        140737488355328,
        140737488355329,
        281474976710655,
        281474976710656,
        281474976710657,
        562949953421311,
        562949953421312,
        562949953421313,
        1125899906842623,
        1125899906842624,
        1125899906842625,
        2251799813685247,
        2251799813685248,
        2251799813685249,
        4503599627370495,
        4503599627370496,
        4503599627370497,
        9007199254740991,
        9007199254740992,
        9007199254740993,
        18014398509481983,
        18014398509481984,
        18014398509481985,
        36028797018963967,
        36028797018963968,
        36028797018963969,
        72057594037927935,
        72057594037927936,
        72057594037927937,
        144115188075855871,
        144115188075855872,
        144115188075855873,
        288230376151711743,
        288230376151711744,
        288230376151711745,
        576460752303423487,
        576460752303423488,
        576460752303423489,
        1152921504606846975,
        1152921504606846976,
        1152921504606846977,
        2305843009213693951,
        2305843009213693952,
        2305843009213693953,
        4611686018427387903,
        4611686018427387904,
        4611686018427387905,
        9223372036854775807,
        9223372036854775808,
        9223372036854775809,
        18446744073709551615,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn server_respects_buffer_limit_post_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    // this test will vary in behaviour depending on the default suites
    do_handshake(&mut client, &mut server);
    server.set_buffer_limit(Some(48));

    assert_eq!(
        server
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        20
    );
    assert_eq!(
        server
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        6
    );

    transfer(&mut server, &mut client);
    client.process_new_packets().unwrap();

    check_read(&mut client.reader(), b"01234567890123456789012345");
}
fn server_stateless_reset() {
    let _guard = subscribe();
    let mut reset_key = vec![0; 64];
    let mut rng = rand::thread_rng();
    rng.fill_bytes(&mut reset_key);
    let reset_key = hmac::Key::new(hmac::HMAC_SHA256, &reset_key);

    let endpoint_config = Arc::new(EndpointConfig::new(Arc::new(reset_key)));

    let mut pair = Pair::new(endpoint_config.clone(), server_config());
    let (client_ch, _) = pair.connect();
    pair.drive(); // Flush any post-handshake frames
    pair.server.endpoint = Endpoint::new(endpoint_config, Some(Arc::new(server_config())), true);
    // Force the server to generate the smallest possible stateless reset
    pair.client.connections.get_mut(&client_ch).unwrap().ping();
    info!("resetting");
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::Reset
        })
    );
}
async fn recv_invalid_server_stream_id() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        // Write GET /
        .write(&[
            0, 0, 0x10, 1, 5, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,
            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84,
        ])
        .write(SETTINGS_ACK)
        // Read response
        .read(&[0, 0, 1, 1, 5, 0, 0, 0, 2, 137])
        // Write GO_AWAY
        .write(&[0, 0, 8, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1])
        .build();

    let (mut client, h2) = client::handshake(mock).await.unwrap();

    // Send the request
    let request = Request::builder()
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, _) = client.send_request(request, true).unwrap();

    // The connection errors
    assert!(h2.await.is_err());

    // The stream errors
    assert!(response.await.is_err());
}
fn render_macros_with_default_args() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello(val=1) %}{{val}}{% endmacro hello %}"),
        ("hello.html", "{% import \"macros\" as macros %}{{macros::hello()}}"),
    ])
    .unwrap();
    let result = tera.render("hello.html", &Context::new());

    assert_eq!(result.unwrap(), "1".to_string());
}
fn render_set_tag_macro() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}Hello{% endmacro hello %}"),
        (
            "hello.html",
            "{% import \"macros\" as macros %}{% set my_var = macros::hello() %}{{my_var}}",
        ),
    ])
    .unwrap();
    let result = tera.render("hello.html", &Context::new());

    assert_eq!(result.unwrap(), "Hello".to_string());
}
fn fs_error_unknown() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert_error(PathBuf::from("prefix/ci.js"), ErrorEntry::UnknownFileType);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), ("prefix")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_unknown",
        fs,
        console,
        result,
    ));
}
fn TinyVec_reserve_exact() {
  let mut tv: TinyVec<[i32; 4]> = Default::default();
  assert_eq!(tv.capacity(), 4);

  tv.extend_from_slice(&[1, 2]);
  assert_eq!(tv.capacity(), 4);
  tv.reserve_exact(2);
  assert_eq!(tv.capacity(), 4);
  tv.reserve_exact(4);
  assert!(tv.capacity() >= 6);
  tv.extend_from_slice(&[3, 4, 5, 6]);
  tv.reserve_exact(4);
  assert!(tv.capacity() >= 10);
}
fn check_matching_equivalent() {
    let requests = load_requests();

    assert!(requests.len() > 0, "List of parsed request info is empty");

    let engine = get_blocker_engine();

    let requests_len = requests.len() as u32;

    let mut mismatch_expected_match = 0;
    let mut mismatch_expected_exception = 0;
    let mut mismatch_expected_pass = 0;
    let mut false_negative_rules: HashMap<String, (String, String, String)> = HashMap::new();
    let mut false_positive_rules: HashMap<String, (String, String, String)> = HashMap::new();
    let mut false_negative_exceptions: HashMap<String, (String, String, String)> = HashMap::new();
    for req in requests {
        let request = Request::new(&req.url, &req.sourceUrl, &req.r#type).unwrap();
        let checked = engine.check_network_request(&request);
        if req.blocked == 1 && checked.matched != true {
            mismatch_expected_match += 1;
            req.filter.as_ref().map(|f| {
                false_negative_rules.insert(
                    f.clone(),
                    (req.url.clone(), req.sourceUrl.clone(), req.r#type.clone()),
                )
            });
            println!(
                "Expected match, uBo matched {} at {}, type {} ON {:?}",
                req.url, req.sourceUrl, req.r#type, req.filter
            );
        } else if req.blocked == 2 && checked.exception.is_none() {
            mismatch_expected_exception += 1;
            checked.filter.as_ref().map(|f| {
                false_negative_exceptions.insert(
                    f.clone(),
                    (req.url.clone(), req.sourceUrl.clone(), req.r#type.clone()),
                )
            });
            println!(
                "Expected exception to match for {} at {}, type {}, got rule match {:?}",
                req.url, req.sourceUrl, req.r#type, checked.filter
            );
        } else if req.blocked == 0 && checked.matched != false {
            mismatch_expected_pass += 1;
            checked.filter.as_ref().map(|f| {
                false_positive_rules.insert(
                    f.clone(),
                    (req.url.clone(), req.sourceUrl.clone(), req.r#type.clone()),
                )
            });
            println!(
                "Expected pass, matched {} at {}, type {} ON {:?}",
                req.url, req.sourceUrl, req.r#type, checked.filter
            );
        }
    }

    let mismatches = mismatch_expected_match + mismatch_expected_exception + mismatch_expected_pass;
    let ratio = mismatches as f32 / requests_len as f32;
    assert!(ratio < 0.01);
    assert!(
        false_positive_rules.len() < 3,
        "False positive rules higher than expected: {:?}",
        false_positive_rules
    );
    assert!(
        false_negative_rules.len() < 3,
        "False negative rules higher than expected: {:?}",
        false_negative_rules
    );
    assert!(
        false_negative_exceptions.len() < 3,
        "False negative exceptions higher than expected: {:?}",
        false_negative_exceptions
    );
}
fn parse_literal_timestamp_without_time_zone() {
    let sql = "SELECT TIMESTAMP '1999-01-01 01:23:34'";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::Timestamp(None, TimezoneInfo::None),
            value: "1999-01-01 01:23:34".into(),
        },
        expr_from_projection(only(&select.projection)),
    );

    one_statement_parses_to("SELECT TIMESTAMP '1999-01-01 01:23:34'", sql);
}
fn drain_next_back() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    let mut table = write_txn.open_table(U64_TABLE).unwrap();
    let mut iter = table.drain(0..10).unwrap();
    for i in (0..10).rev() {
        let (k, v) = iter.next_back().unwrap().unwrap();
        assert_eq!(i, k.value());
        assert_eq!(i, v.value());
    }
}
fn issue540() {
    #[derive(Serialize)]
    pub enum Enum {
        Variant {},
    }

    #[derive(Serialize)]
    pub struct Struct {
        #[serde(flatten)]
        flatten: Enum,
    }

    assert_eq!(
        to_string_with_root(
            "root",
            &Struct {
                flatten: Enum::Variant {},
            }
        )
        .unwrap(),
        "<root><Variant/></root>"
    );
}
fn applies_custom_jsx_quote_style() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), APPLY_JSX_QUOTE_STYLE_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--jsx-quote-style"),
                ("single"),
                ("--quote-properties"),
                ("preserve"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, APPLY_JSX_QUOTE_STYLE_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_jsx_quote_style",
        fs,
        console,
        result,
    ));
}
fn test_install_ancestors_mode_directories() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ancestor1 = "ancestor1";
    let ancestor2 = "ancestor1/ancestor2";
    let target_dir = "ancestor1/ancestor2/target_dir";
    let directories_arg = "-d";
    let mode_arg = "--mode=200";
    let probe = "probe";

    at.mkdir(probe);
    let default_perms = at.metadata(probe).permissions().mode();

    ucmd.args(&[mode_arg, directories_arg, target_dir])
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(ancestor1));
    assert!(at.dir_exists(ancestor2));
    assert!(at.dir_exists(target_dir));

    assert_eq!(default_perms, at.metadata(ancestor1).permissions().mode());
    assert_eq!(default_perms, at.metadata(ancestor2).permissions().mode());

    // Expected mode only on the target_dir.
    assert_eq!(0o40_200_u32, at.metadata(target_dir).permissions().mode());
}
fn u128_decimal_test() {
    assert_eq!(Ok(0), u128::from_lexical(b"0"));
    assert_eq!(
        Ok(170141183460469231731687303715884105727),
        u128::from_lexical(b"170141183460469231731687303715884105727")
    );
    assert_eq!(
        Ok(170141183460469231731687303715884105728),
        u128::from_lexical(b"170141183460469231731687303715884105728")
    );
    assert_eq!(
        Ok(340282366920938463463374607431768211455),
        u128::from_lexical(b"340282366920938463463374607431768211455")
    );
    assert_eq!(Err(Error::InvalidDigit(0)), u128::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), u128::from_lexical(b"1a"));
}
fn test_symlink_existing_backup() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_existing_backup";
    let link = "test_symlink_existing_backup_link";
    let link_backup = "test_symlink_existing_backup_link.~1~";
    let resulting_backup = "test_symlink_existing_backup_link.~2~";

    // Create symlink and verify
    at.touch(file);
    at.symlink_file(file, link);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    // Create backup symlink and verify
    at.symlink_file(file, link_backup);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link_backup));
    assert_eq!(at.resolve_link(link_backup), file);

    ucmd.args(&["-s", "--backup=nil", file, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file));

    assert!(at.is_symlink(link_backup));
    assert_eq!(at.resolve_link(link_backup), file);

    assert!(at.is_symlink(resulting_backup));
    assert_eq!(at.resolve_link(resulting_backup), file);
}
fn len() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
        table.insert("hello", "world2").unwrap();
        table.insert("hi", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert_eq!(table.len().unwrap(), 3);
}
fn get_invalid() {
    let mut headers = HeaderMap::new();
    headers.insert("foo", "bar".parse().unwrap());
    assert!(headers.get("Evil\r\nKey").is_none());
}
fn test_rmdir_nonempty_directory_no_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir(DIR);
    at.touch(DIR_FILE);

    ucmd.arg(DIR)
        .fails()
        .stderr_is(format!("rmdir: failed to remove 'dir': {NOT_EMPTY}\n"));

    assert!(at.dir_exists(DIR));
}
fn test_new_leader_init_resolver() {
    let (mut cluster, pd_client, mut peer_client1) = prepare_for_stale_read(new_peer(1, 1));
    let mut peer_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));
    peer_client1.ctx.set_stale_read(true);
    peer_client2.ctx.set_stale_read(true);

    // Write `(key1, value1)`
    let commit_ts1 = peer_client1.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );

    // There are no lock in the region, the `safe_ts` should keep updating by the
    // new leader, so we can read `key1` with the newest ts
    cluster.must_transfer_leader(1, new_peer(2, 2));
    peer_client1.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), get_tso(&pd_client));

    // Prewrite on `key2` but not commit yet
    peer_client2.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key2"[..], &b"value1"[..])],
        b"key2".to_vec(),
        get_tso(&pd_client),
    );

    // There are locks in the region, the `safe_ts` can't be updated, so we can't
    // read `key1` with the newest ts
    cluster.must_transfer_leader(1, new_peer(1, 1));
    let resp = peer_client2.kv_read(b"key1".to_vec(), get_tso(&pd_client));
    assert!(resp.get_region_error().has_data_is_not_ready());
    // But we can read `key1` with `commit_ts1`
    peer_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), commit_ts1);
}
fn parse_variable_tag_test_as_expression() {
    let ast = parse("{{ user is defined and user.admin }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Logic(LogicExpr {
                lhs: Box::new(Expr::new(ExprVal::Test(Test {
                    ident: "user".to_string(),
                    negated: false,
                    name: "defined".to_string(),
                    args: vec![],
                },))),
                operator: LogicOperator::And,
                rhs: Box::new(Expr::new(ExprVal::Ident("user.admin".to_string()))),
            },))
        )
    );
}
fn extension_without_fully_specified() {
    let f2 = super::fixture().join("exports-field2");

    let commonjs_resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        condition_names: vec!["webpack".into()],
        ..ResolveOptions::default()
    });

    let resolved_path =
        commonjs_resolver.resolve(&f2, "exports-field/dist/main").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f2.join("node_modules/exports-field/lib/lib2/main.js")));
}
fn parse_update_set_from() {
    let sql = "UPDATE t1 SET name = t2.name FROM (SELECT name, id FROM t1 GROUP BY id) AS t2 WHERE t1.id = t2.id";
    let dialects = TestedDialects {
        dialects: vec![
            Box::new(GenericDialect {}),
            Box::new(DuckDbDialect {}),
            Box::new(PostgreSqlDialect {}),
            Box::new(BigQueryDialect {}),
            Box::new(SnowflakeDialect {}),
            Box::new(RedshiftSqlDialect {}),
            Box::new(MsSqlDialect {}),
        ],
        options: None,
    };
    let stmt = dialects.verified_stmt(sql);
    assert_eq!(
        stmt,
        Statement::Update {
            table: TableWithJoins {
                relation: TableFactor::Table {
                    name: ObjectName(vec![Ident::new("t1")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                joins: vec![],
            },
            assignments: vec![Assignment {
                id: vec![Ident::new("name")],
                value: Expr::CompoundIdentifier(vec![Ident::new("t2"), Ident::new("name")])
            }],
            from: Some(TableWithJoins {
                relation: TableFactor::Derived {
                    lateral: false,
                    subquery: Box::new(Query {
                        with: None,
                        body: Box::new(SetExpr::Select(Box::new(Select {
                            distinct: None,
                            top: None,
                            projection: vec![
                                SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("name"))),
                                SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("id"))),
                            ],
                            into: None,
                            from: vec![TableWithJoins {
                                relation: TableFactor::Table {
                                    name: ObjectName(vec![Ident::new("t1")]),
                                    alias: None,
                                    args: None,
                                    with_hints: vec![],
                                    version: None,
                                    partitions: vec![],
                                },
                                joins: vec![],
                            }],
                            lateral_views: vec![],
                            selection: None,
                            group_by: GroupByExpr::Expressions(vec![Expr::Identifier(Ident::new(
                                "id"
                            ))]),
                            cluster_by: vec![],
                            distribute_by: vec![],
                            sort_by: vec![],
                            having: None,
                            named_window: vec![],
                            qualify: None
                        }))),
                        order_by: vec![],
                        limit: None,
                        limit_by: vec![],
                        offset: None,
                        fetch: None,
                        locks: vec![],
                    }),
                    alias: Some(TableAlias {
                        name: Ident::new("t2"),
                        columns: vec![],
                    })
                },
                joins: vec![],
            }),
            selection: Some(Expr::BinaryOp {
                left: Box::new(Expr::CompoundIdentifier(vec![
                    Ident::new("t1"),
                    Ident::new("id")
                ])),
                op: BinaryOperator::Eq,
                right: Box::new(Expr::CompoundIdentifier(vec![
                    Ident::new("t2"),
                    Ident::new("id")
                ])),
            }),
            returning: None,
        }
    );
}
fn test_read_source_region_after_target_region_merged() {
    let (mut cluster, pd_client, leader_client) =
        prepare_for_stale_read_before_run(new_peer(1, 1), Some(Box::new(configure_for_merge)));

    // Write on source region
    let k1_commit_ts1 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );

    cluster.must_split(&cluster.get_region(&[]), b"key3");
    let source = pd_client.get_region(b"key1").unwrap();
    let target = pd_client.get_region(b"key5").unwrap();
    // Transfer the target region leader to store 1 and the source region leader to
    // store 2
    cluster.must_transfer_leader(target.get_id(), new_peer(1, 1));
    cluster.must_transfer_leader(source.get_id(), find_peer(&source, 2).unwrap().clone());
    // Get the source region follower on store 3
    let mut source_follower_client3 = PeerClient::new(
        &cluster,
        source.get_id(),
        find_peer(&source, 3).unwrap().clone(),
    );
    source_follower_client3.ctx.set_stale_read(true);
    source_follower_client3.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), k1_commit_ts1);

    // Pause on source region `prepare_merge` on store 2 and store 3
    let apply_before_prepare_merge_2_3 = "apply_before_prepare_merge_2_3";
    fail::cfg(apply_before_prepare_merge_2_3, "pause").unwrap();

    // Merge source region into target region
    pd_client.must_merge(source.get_id(), target.get_id());

    // Leave a lock on the original source region key range through the target
    // region leader
    let target_leader = PeerClient::new(&cluster, target.get_id(), new_peer(1, 1));
    let k1_prewrite_ts2 = get_tso(&pd_client);
    target_leader.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value2"[..])],
        b"key1".to_vec(),
        k1_prewrite_ts2,
    );

    // Wait for the source region leader to update `safe_ts` (if it can)
    sleep_ms(50);

    // We still can read `key1` with `k1_commit_ts1` through source region
    source_follower_client3.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), k1_commit_ts1);
    // But can't read `key2` with `k1_prewrite_ts2` because the source leader can't
    // update `safe_ts` after source region is merged into target region even
    // though the source leader didn't know the merge is complement
    let resp = source_follower_client3.kv_read(b"key1".to_vec(), k1_prewrite_ts2);
    assert!(resp.get_region_error().has_data_is_not_ready());

    fail::remove(apply_before_prepare_merge_2_3);
}
fn test_datagram() {
    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let udp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 1));
    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));

    let udp_message = message(query.clone(), vec![udp_record.clone()], vec![], vec![]);
    let tcp_message = message(query.clone(), vec![tcp_record], vec![], vec![]);
    let udp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        Default::default(),
    );
    let tcp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],
        Default::default(),
    );

    let pool = mock_nameserver_pool(
        vec![udp_nameserver],
        vec![tcp_nameserver],
        None,
        Default::default(),
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], udp_record);
}
fn bindgen_test_layout_lol_html_memory_settings_t() {
    const UNINIT: ::std::mem::MaybeUninit<lol_html_memory_settings_t> =
        ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<lol_html_memory_settings_t>(),
        16usize,
        concat!("Size of: ", stringify!(lol_html_memory_settings_t))
    );
    assert_eq!(
        ::std::mem::align_of::<lol_html_memory_settings_t>(),
        8usize,
        concat!("Alignment of ", stringify!(lol_html_memory_settings_t))
    );
    assert_eq!(
        unsafe {
            ::std::ptr::addr_of!((*ptr).preallocated_parsing_buffer_size) as usize - ptr as usize
        },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_memory_settings_t),
            "::",
            stringify!(preallocated_parsing_buffer_size)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).max_allowed_memory_usage) as usize - ptr as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_memory_settings_t),
            "::",
            stringify!(max_allowed_memory_usage)
        )
    );
}
fn client_optional_auth_revocation_works() {
    for kt in ALL_KEY_TYPES.iter() {
        // Create a server configuration that includes a CRL that specifies the client certificate
        // is revoked.
        let crls = vec![kt.client_crl()];
        let server_config = Arc::new(make_server_config_with_optional_client_auth(*kt, crls));

        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions_with_auth(*kt, &[version]);
            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
            // Because the client certificate is revoked, the handshake should fail.
            let err = do_handshake_until_error(&mut client, &mut server);
            assert_eq!(
                err,
                Err(ErrorFromPeer::Server(Error::InvalidCertificate(
                    CertificateError::Revoked
                )))
            );
        }
    }
}
fn test_chown_no_change_to_user() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    for (i, from) in ["42", ":42", "42:42"].iter().enumerate() {
        let file = i.to_string();
        at.touch(&file);
        scene
            .ucmd()
            .arg("-v")
            .arg(format!("--from={from}"))
            .arg("43")
            .arg(&file)
            .succeeds()
            .stdout_only(format!("ownership of '{file}' retained as {user_name}\n"));
    }
}
fn TinyVec_reserve() {
  let mut tv: TinyVec<[i32; 4]> = Default::default();
  assert_eq!(tv.capacity(), 4);
  tv.extend_from_slice(&[1, 2]);
  assert_eq!(tv.capacity(), 4);
  tv.reserve(2);
  assert_eq!(tv.capacity(), 4);
  tv.reserve(4);
  assert!(tv.capacity() >= 6);
  tv.extend_from_slice(&[3, 4, 5, 6]);
  tv.reserve(4);
  assert!(tv.capacity() >= 10);
}
fn test_install_backup_short_no_args_files() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_simple_backup_file_a";
    let file_b = "test_install_simple_backup_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("-b")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn options_tests() {
    let builder = OptionsBuilder::new();
    assert!(builder.is_valid());
    assert!(unsafe { builder.build_unchecked() }.is_valid());
    assert!(OptionsBuilder::default().is_valid());

    let options: Options = Options::new();
    assert!(options.is_valid());
    assert_eq!(options, Options::default());
    assert!(OptionsBuilder::new().build().is_ok());
    assert!(OptionsBuilder::default().build().is_ok());
    assert!(OptionsBuilder::default().is_valid());
    assert_eq!(options.rebuild(), Options::builder());
}
fn power_limit_test() {
    assert_eq!(limits::u32_power_limit(5), 13);
    assert_eq!(limits::u32_power_limit(10), 9);
    assert_eq!(limits::u64_power_limit(5), 27);
    assert_eq!(limits::u64_power_limit(10), 19);
}
fn generic_enum() {
    let msg = GenericMessage { data: Some(100u64) };
    let enumeration = GenericEnum::Data(msg);
    match enumeration {
        GenericEnum::Data(d) => assert_eq!(100, d.data.unwrap()),
        GenericEnum::Number(_) => panic!("Not supposed to reach"),
    }
}
fn client_respects_buffer_limit_pre_handshake_with_vectored_write() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    client.set_buffer_limit(Some(32));

    assert_eq!(
        client
            .writer()
            .write_vectored(&[
                IoSlice::new(b"01234567890123456789"),
                IoSlice::new(b"01234567890123456789")
            ])
            .unwrap(),
        32
    );

    do_handshake(&mut client, &mut server);
    transfer(&mut client, &mut server);
    server.process_new_packets().unwrap();

    check_read(&mut server.reader(), b"01234567890123456789012345678901");
}
fn test_default_issue_4821_t_tmpdir() {
    let scene = TestScenario::new(util_name!());
    let pathname = scene.fixtures.as_string();
    let result = scene
        .ucmd()
        .env(TMPDIR, &pathname)
        .arg("-t")
        .arg("foo.XXXX")
        .succeeds();
    let stdout = result.stdout_str();
    println!("stdout = {stdout}");
    assert!(stdout.contains(&pathname));
}
fn test_exec_details() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);

    let flags = &[0];

    let ctx = Context::default();
    let req = DagSelect::from(&product).build_with(ctx, flags);
    let resp = handle_request(&endpoint, req);
    assert!(resp.has_exec_details());
    let exec_details = resp.get_exec_details();
    assert!(exec_details.has_time_detail());
    assert!(exec_details.has_scan_detail());
    assert!(resp.has_exec_details_v2());
    let exec_details = resp.get_exec_details_v2();
    assert!(exec_details.has_time_detail());
    assert!(exec_details.has_time_detail_v2());
    assert!(exec_details.has_scan_detail_v2());
}
fn test_append() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));
    let record = record;

    // first check the must_exist option
    let result = io_loop
        .block_on(client.append(record.clone(), origin.clone(), true))
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NXRRSet);

    // next append to a non-existent RRset
    let result = io_loop
        .block_on(client.append(record.clone(), origin.clone(), false))
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert_eq!(result.answers()[0], record);

    // will fail if already set and not the same value.
    let mut record2 = record.clone();
    record2.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let record2 = record2;

    let result = io_loop
        .block_on(client.append(record2.clone(), origin.clone(), true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);

    assert!(result.answers().iter().any(|rr| *rr == record));
    assert!(result.answers().iter().any(|rr| *rr == record2));

    // show that appending the same thing again is ok, but doesn't add any records
    let result = io_loop
        .block_on(client.append(record.clone(), origin, true))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);
}
fn option_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<Option<u8>, Option<u32>> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(None, None).unwrap();
        table.insert(None, Some(0)).unwrap();
        table.insert(Some(1), Some(1)).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(table.get(None).unwrap().unwrap().value(), Some(0));
    assert_eq!(table.get(Some(1)).unwrap().unwrap().value(), Some(1));
    let mut iter = table.iter().unwrap();
    assert_eq!(iter.next().unwrap().unwrap().0.value(), None);
    assert_eq!(iter.next().unwrap().unwrap().0.value(), Some(1));
}
fn test_symlink_overwrite_dir_fail() {
    let (at, mut ucmd) = at_and_ucmd!();
    let path_a = "test_symlink_overwrite_dir_a";
    let path_b = "test_symlink_overwrite_dir_b";

    at.touch(path_a);
    at.mkdir(path_b);

    assert!(!ucmd
        .args(&["-s", "-T", path_a, path_b])
        .fails()
        .stderr_str()
        .is_empty());
}
fn test_force_leader_five_nodes() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    // quorum is lost, can't propose command successfully.
    confirm_quorum_is_lost(&mut cluster, &region);

    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    // forbid writes in force leader state
    let put = new_put_cmd(b"k3", b"v3");
    must_get_error_recovery_in_progress(&mut cluster, &region, put);
    // forbid reads in force leader state
    let get = new_get_cmd(b"k1");
    must_get_error_recovery_in_progress(&mut cluster, &region, get);
    // forbid read index in force leader state
    let read_index = new_read_index_cmd();
    must_get_error_recovery_in_progress(&mut cluster, &region, read_index);

    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), None);
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn test_chown_recursive() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    at.mkdir_all("a/b/c");
    at.mkdir("z");
    at.touch(at.plus_as_string("a/a"));
    at.touch(at.plus_as_string("a/b/b"));
    at.touch(at.plus_as_string("a/b/c/c"));
    at.touch(at.plus_as_string("z/y"));

    let result = scene
        .ucmd()
        .arg("-R")
        .arg("--verbose")
        .arg(user_name)
        .arg("a")
        .arg("z")
        .run();
    result.stderr_contains("ownership of 'a/a' retained as");
    result.stderr_contains("ownership of 'z/y' retained as");
}
fn test_cp_arg_update_none_then_all() {
    // take last if multiple update args are supplied,
    // update=all wins in this case
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_none_then_all_file1";
    let new = "test_cp_arg_update_none_then_all_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("--update=none")
        .arg("--update=all")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), "old content\n");
}
fn test() {
    let s = r#" {"Variant":{"x":0,"y":0}} "#;
    assert!(serde_json::from_str::<Enum>(s).is_err());

    let j = json!({"Variant":{"x":0,"y":0}});
    assert!(serde_json::from_value::<Enum>(j).is_err());
}
fn hi32_test() {
    assert_eq!(VecType::from_u16(0xA).hi32(), (0xA0000000, false));
    assert_eq!(VecType::from_u32(0xAB).hi32(), (0xAB000000, false));
    assert_eq!(VecType::from_u64(0xAB00000000).hi32(), (0xAB000000, false));
    assert_eq!(VecType::from_u64(0xA23456789A).hi32(), (0xA2345678, true));
}
fn inscriptions_includes_locked_utxos() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  rpc_server.mine_blocks(1);

  let (inscription, reveal) = inscribe(&rpc_server);

  rpc_server.mine_blocks(1);

  rpc_server.lock(OutPoint {
    txid: reveal,
    vout: 0,
  });

  let output = CommandBuilder::new("wallet inscriptions")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<inscriptions::Output>>();

  assert_eq!(output.len(), 1);
  assert_eq!(output[0].inscription, inscription);
  assert_eq!(output[0].location, format!("{reveal}:0:0").parse().unwrap());
}
fn test_cp_backup_numbered_with_t() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=t")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}.~1~")),
        "How are you?\n"
    );
}
fn test_update_from_toml_file() {
    use std::{error::Error, result::Result};

    use online_config::ConfigManager;

    #[derive(Clone)]
    struct CfgManager(Arc<Mutex<RaftstoreConfig>>);

    impl ConfigManager for CfgManager {
        fn dispatch(&mut self, c: ConfigChange) -> Result<(), Box<dyn Error>> {
            self.0.lock().unwrap().update(c)
        }
    }

    let (cfg, _dir) = TikvConfig::with_tmp().unwrap();
    let cfg_controller = ConfigController::new(cfg);
    let cfg = cfg_controller.get_current();
    let mgr = CfgManager(Arc::new(Mutex::new(cfg.raft_store.clone())));
    cfg_controller.register(Module::Raftstore, Box::new(mgr));

    // update config file
    let c = r#"
[raftstore]
raft-log-gc-threshold = 2000
"#;
    let mut f = File::create(&cfg.cfg_path).unwrap();
    f.write_all(c.as_bytes()).unwrap();
    // before update this configuration item should be the default value
    assert_eq!(
        cfg_controller
            .get_current()
            .raft_store
            .raft_log_gc_threshold,
        50
    );
    // config update from config file
    cfg_controller.update_from_toml_file().unwrap();
    // after update this configration item should be constant with the modified
    // configuration file
    assert_eq!(
        cfg_controller
            .get_current()
            .raft_store
            .raft_log_gc_threshold,
        2000
    );
}
fn test_summary() {
    let cfg = Config {
        report_receiver_interval: ReadableDuration::millis(REPORT_INTERVAL_MS),
        precision: ReadableDuration::millis(PRECISION_MS),
        ..Default::default()
    };

    let (_, collector_reg_handle, resource_tag_factory, mut recorder_worker) =
        init_recorder(cfg.precision.as_millis());
    let (_, data_sink_reg_handle, mut reporter_worker) = init_reporter(cfg, collector_reg_handle);

    let data_sink = MockDataSink::default();

    // At this point we are ready for everything except turning on the switch.

    // expect no data
    {
        let tf = resource_tag_factory.clone();
        let data_sink = data_sink.clone();
        thread::spawn(move || {
            {
                let mut ctx = Context::default();
                ctx.set_resource_group_tag(b"TAG-1".to_vec());
                let tag = tf.new_tag(&ctx);
                let _g = tag.attach();
                resource_metering::record_read_keys(123);
                resource_metering::record_write_keys(456);
            }
            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report
            assert!(data_sink.get(b"TAG-1").is_none());
            data_sink.clear();
        })
        .join()
        .unwrap();
    }

    // turn on
    let reg_guard = data_sink_reg_handle.register(Box::new(data_sink.clone()));

    // expect can get data
    {
        let tf = resource_tag_factory.clone();
        let data_sink = data_sink.clone();
        thread::spawn(move || {
            {
                let mut ctx = Context::default();
                ctx.set_resource_group_tag(b"TAG-1".to_vec());
                let tag = tf.new_tag(&ctx);
                let _g = tag.attach();
                thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply
                resource_metering::record_read_keys(123);
                resource_metering::record_write_keys(456);
            }
            thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report

            let r = data_sink.get(b"TAG-1").unwrap();
            assert_eq!(
                r.get_record()
                    .get_items()
                    .iter()
                    .map(|item| item.read_keys)
                    .sum::<u32>(),
                123
            );
            assert_eq!(
                r.get_record()
                    .get_items()
                    .iter()
                    .map(|item| item.write_keys)
                    .sum::<u32>(),
                456
            );
            data_sink.clear();
        })
        .join()
        .unwrap();
    }

    // turn off
    drop(reg_guard);

    // expect no data
    thread::spawn(move || {
        {
            let mut ctx = Context::default();
            ctx.set_resource_group_tag(b"TAG-1".to_vec());
            let tag = resource_tag_factory.new_tag(&ctx);
            let _g = tag.attach();
            thread::sleep(Duration::from_millis(PRECISION_MS * 2)); // wait config apply
            resource_metering::record_read_keys(123);
            resource_metering::record_write_keys(456);
        }
        thread::sleep(Duration::from_millis(REPORT_INTERVAL_MS + 500)); // wait report
        assert!(data_sink.get(b"TAG-1").is_none());
        data_sink.clear();
    })
    .join()
    .unwrap();

    // stop worker
    recorder_worker.stop();
    reporter_worker.stop();
}
fn test_chown_no_change_to_group() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());
    let result = scene.cmd("id").arg("-ng").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let group_name = String::from(result.stdout_str().trim());
    assert!(!group_name.is_empty());

    for (i, from) in ["42", ":42", "42:42"].iter().enumerate() {
        let file = i.to_string();
        at.touch(&file);
        scene
            .ucmd()
            .arg("-v")
            .arg(format!("--from={from}"))
            .arg(":43")
            .arg(&file)
            .succeeds()
            .stdout_only(format!("ownership of '{file}' retained as {group_name}\n"));
    }
}
fn test_recursive_implicit_some() {
    // Test case provided by d86leader in
    //  https://github.com/ron-rs/ron/issues/367#issue-1147920589

    let x1: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1)");
    let x2: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1, f2: None, f3: None)");
    let x3: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1, f2: 2, f3: 3)");
    let x4: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1, f2: 2, f3: Some(3))");
    let x5: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1, f2: 2, f3: Some(Some(3)))");
    let x6: std::result::Result<MaybeFields, _> =
        ron::from_str("#![enable(implicit_some)]\n(f1: 1, f2: 2, f3: Some(None))");

    assert_eq!(
        x1,
        Ok(MaybeFields {
            f1: 1,
            f2: None,
            f3: None
        })
    );
    assert_eq!(
        x2,
        Ok(MaybeFields {
            f1: 1,
            f2: None,
            f3: None
        })
    );
    assert_eq!(
        x3,
        Ok(MaybeFields {
            f1: 1,
            f2: Some(2),
            f3: Some(Some(3))
        })
    );
    assert_eq!(
        x4,
        Ok(MaybeFields {
            f1: 1,
            f2: Some(2),
            f3: Some(Some(3))
        })
    );
    assert_eq!(
        x5,
        Ok(MaybeFields {
            f1: 1,
            f2: Some(2),
            f3: Some(Some(3))
        })
    );
    assert_eq!(
        x6,
        Ok(MaybeFields {
            f1: 1,
            f2: Some(2),
            f3: Some(None)
        })
    );
}
fn borrowed_str() {
    assert_eq!(
        ron::de::from_str(BORROWED).ok(),
        Some(Borrowed { value: "test" })
    );
}
fn iter() {
    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);

    check_exact_size_iterator!(p.iter());
    check_exact_size_iterator!(p.iter_mut());
    check_exact_size_iterator!(p.into_iter());

    let mut p: Punctuated<_, Token![,]> = punctuated!(2, 3, 4);

    assert_eq!(p.iter().next_back(), Some(&4));
    assert_eq!(p.iter_mut().next_back(), Some(&mut 4));
    assert_eq!(p.into_iter().next_back(), Some(4));
}
fn test_stale_read_while_region_merge() {
    let (mut cluster, pd_client, _) =
        prepare_for_stale_read_before_run(new_peer(1, 1), Some(Box::new(configure_for_merge)));

    cluster.must_split(&cluster.get_region(&[]), b"key3");
    let source = pd_client.get_region(b"key1").unwrap();
    let target = pd_client.get_region(b"key5").unwrap();

    cluster.must_transfer_leader(target.get_id(), new_peer(1, 1));
    let target_leader = PeerClient::new(&cluster, target.get_id(), new_peer(1, 1));
    // Write `(key5, value1)`
    target_leader.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key5"[..], &b"value1"[..])],
        b"key5".to_vec(),
    );

    let source_leader = cluster.leader_of_region(source.get_id()).unwrap();
    let source_leader = PeerClient::new(&cluster, source.get_id(), source_leader);
    // Prewrite on `key1` but not commit yet
    let k1_prewrite_ts = get_tso(&pd_client);
    source_leader.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
        k1_prewrite_ts,
    );

    // Write `(key5, value2)`
    let k5_commit_ts = target_leader.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key5"[..], &b"value2"[..])],
        b"key5".to_vec(),
    );

    // Merge source region into target region, the lock on source region should also
    // merge into the target region and cause the target region's `safe_ts`
    // decrease
    pd_client.must_merge(source.get_id(), target.get_id());

    let mut follower_client2 = PeerClient::new(&cluster, target.get_id(), new_peer(2, 2));
    follower_client2.ctx.set_stale_read(true);
    // We can read `(key5, value1)` with `k1_prewrite_ts`
    follower_client2.must_kv_read_equal(b"key5".to_vec(), b"value1".to_vec(), k1_prewrite_ts);
    // Can't read `key5` with `k5_commit_ts` because `k1_prewrite_ts` is smaller
    // than `k5_commit_ts`
    let resp = follower_client2.kv_read(b"key5".to_vec(), k5_commit_ts);
    assert!(resp.get_region_error().has_data_is_not_ready());

    let target_leader = PeerClient::new(&cluster, target.get_id(), new_peer(1, 1));
    // Commit on `key1`
    target_leader.must_kv_commit(vec![b"key1".to_vec()], k1_prewrite_ts, get_tso(&pd_client));
    // We can read `(key5, value2)` now
    follower_client2.must_kv_read_equal(b"key5".to_vec(), b"value2".to_vec(), get_tso(&pd_client));
}
fn test_split_multiple_obs_lines_within_combined() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let name = "multiple-obs-lines";
    RandomFile::new(at, name).add_lines(400);

    scene
        .ucmd()
        .args(&["-d5000x", "-e200d", name])
        .succeeds()
        .no_stderr()
        .no_stdout();
    let glob = Glob::new(at, ".", r"x\d\d$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn get_set_funcref_globals_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let f = Func::wrap(&mut store, || {});

    // Initialize with a null funcref.

    let global = Global::new(
        &mut store,
        GlobalType::new(ValType::FuncRef, Mutability::Var),
        Val::FuncRef(None),
    )?;
    assert!(global.get(&mut store).unwrap_funcref().is_none());

    global.set(&mut store, Val::FuncRef(Some(f.clone())))?;
    let f2 = global.get(&mut store).unwrap_funcref().cloned().unwrap();
    assert_eq!(f.ty(&store), f2.ty(&store));

    // Initialize with a non-null funcref.

    let global = Global::new(
        &mut store,
        GlobalType::new(ValType::FuncRef, Mutability::Var),
        Val::FuncRef(Some(f.clone())),
    )?;
    let f2 = global.get(&mut store).unwrap_funcref().cloned().unwrap();
    assert_eq!(f.ty(&store), f2.ty(&store));

    Ok(())
}
fn write() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED);

    assert_eq!(console.out_buffer.len(), 1);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "formatter_write",
        fs,
        console,
        result,
    ));
}
fn case_insensitive_starts_with_test() {
    assert_eq!(shared::case_insensitive_starts_with(b"NaN".iter(), b"nAN".iter()), true);
    assert_eq!(shared::case_insensitive_starts_with(b"nAN".iter(), b"nAN".iter()), true);
    assert_eq!(shared::case_insensitive_starts_with(b"nAN1".iter(), b"nAN".iter()), true);
    assert_eq!(shared::case_insensitive_starts_with(b"nAN1".iter(), b"nAN12".iter()), false);
}
fn save_point_rollback_partial() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    wb.put(b"b", b"").unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();
    let a = db.engine.get_value(b"a").unwrap();
    assert!(a.is_some());
    let b = db.engine.get_value(b"b").unwrap();
    assert!(b.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    for i in 0..max_keys {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    wb.put(b"b", b"").unwrap();
    for i in max_keys..2 * max_keys {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();
    let a = db.engine.get_value(b"a").unwrap();
    assert!(a.is_some());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }
    let b = db.engine.get_value(b"b").unwrap();
    assert!(b.is_none());
    for i in max_keys..2 * max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn lint_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), LINT_ERROR.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "lint_error",
        fs,
        console,
        result,
    ));
}
fn invalid_nan_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.nan_string(Some(b"naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaan"));
    assert!(!builder.is_valid());
    builder = builder.nan_string(Some(b"inf"));
    assert!(!builder.is_valid());
    builder = builder.nan_string(Some(b"na00n"));
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.nan_string(Some(b"nan"));
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
    builder = builder.nan_string(None);
    assert!(builder.is_valid());
}
fn test_ingest_multiple_sst() {
    let (_cluster, ctx, tikv, import) = new_cluster_and_tikv_import_client();

    let temp_dir = Builder::new()
        .prefix("test_ingest_multiple_sst")
        .tempdir()
        .unwrap();

    let sst_path = temp_dir.path().join("test.sst");
    let sst_range1 = (0, 100);
    let (mut meta1, data1) = gen_sst_file(sst_path, sst_range1);
    meta1.set_region_id(ctx.get_region_id());
    meta1.set_region_epoch(ctx.get_region_epoch().clone());

    let sst_path2 = temp_dir.path().join("write-test.sst");
    let sst_range2 = (100, 200);
    let (mut meta2, data2) = gen_sst_file(sst_path2, sst_range2);
    meta2.set_region_id(ctx.get_region_id());
    meta2.set_region_epoch(ctx.get_region_epoch().clone());
    meta2.set_cf_name("write".to_owned());

    send_upload_sst(&import, &meta1, &data1).unwrap();
    send_upload_sst(&import, &meta2, &data2).unwrap();

    let mut ingest = MultiIngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.mut_ssts().push(meta1);
    ingest.mut_ssts().push(meta2);
    let resp = import.multi_ingest(&ingest).unwrap();
    assert!(!resp.has_error(), "{:?}", resp.get_error());

    // Check ingested kvs
    check_ingested_kvs(&tikv, &ctx, sst_range1);
    check_ingested_kvs_cf(&tikv, &ctx, "write", sst_range2);
}
fn test_shell_syntax() {
    use std::env;
    let last = env::var("SHELL");
    env::set_var("SHELL", "/path/csh");
    assert_eq!(OutputFmt::CShell, guess_syntax());
    env::set_var("SHELL", "csh");
    assert_eq!(OutputFmt::CShell, guess_syntax());
    env::set_var("SHELL", "/path/bash");
    assert_eq!(OutputFmt::Shell, guess_syntax());
    env::set_var("SHELL", "bash");
    assert_eq!(OutputFmt::Shell, guess_syntax());
    env::set_var("SHELL", "/asd/bar");
    assert_eq!(OutputFmt::Shell, guess_syntax());
    env::set_var("SHELL", "foo");
    assert_eq!(OutputFmt::Shell, guess_syntax());
    env::set_var("SHELL", "");
    assert_eq!(OutputFmt::Unknown, guess_syntax());
    env::remove_var("SHELL");
    assert_eq!(OutputFmt::Unknown, guess_syntax());

    if let Ok(s) = last {
        env::set_var("SHELL", s);
    }
}
fn test_delete_lock_proposed_before_proposing_locks() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_heartbeat_ticks = 20;
    cluster.run();

    let region_id = 1;
    cluster.must_transfer_leader(1, new_peer(1, 1));
    let leader = cluster.leader_of_region(region_id).unwrap();

    let snapshot = cluster.must_get_snapshot_of_region(region_id);
    let txn_ext = snapshot.txn_ext.unwrap();
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(
            Key::from_raw(b"key"),
            PessimisticLock {
                primary: b"key".to_vec().into_boxed_slice(),
                start_ts: 10.into(),
                ttl: 1000,
                for_update_ts: 10.into(),
                min_commit_ts: 20.into(),
                last_change_ts: 5.into(),
                versions_to_last_change: 3,
            },
        )])
        .unwrap();

    let addr = cluster.sim.rl().get_addr(1);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env).connect(&addr);
    let client = TikvClient::new(channel);

    let mut req = CleanupRequest::default();
    let mut ctx = Context::default();
    ctx.set_region_id(region_id);
    ctx.set_region_epoch(cluster.get_region_epoch(region_id));
    ctx.set_peer(leader);
    req.set_context(ctx);
    req.set_key(b"key".to_vec());
    req.set_start_version(10);
    req.set_current_ts(u64::MAX);

    // Pause the command before it actually removes locks.
    fail::cfg("scheduler_async_write_finish", "pause").unwrap();
    let (tx, resp_rx) = mpsc::channel();
    thread::spawn(move || tx.send(client.kv_cleanup(&req).unwrap()).unwrap());

    thread::sleep(Duration::from_millis(200));
    resp_rx.try_recv().unwrap_err();

    cluster.transfer_leader(1, new_peer(2, 2));
    thread::sleep(Duration::from_millis(200));

    // Transfer leader will not make the command fail.
    fail::remove("scheduler_async_write_finish");
    let resp = resp_rx.recv().unwrap();
    assert!(!resp.has_region_error());

    for _ in 0..10 {
        thread::sleep(Duration::from_millis(100));
        cluster.reset_leader_of_region(region_id);
        if cluster.leader_of_region(region_id).unwrap().id == 2 {
            let snapshot = cluster.must_get_snapshot_of_region(1);
            assert!(
                snapshot
                    .get_cf(CF_LOCK, &Key::from_raw(b"key"))
                    .unwrap()
                    .is_none()
            );
            return;
        }
    }
    panic!("region should succeed to transfer leader to peer 2");
}
fn is_client_error() {
    assert!(status_code(400).is_client_error());
    assert!(status_code(499).is_client_error());

    assert!(!status_code(399).is_client_error());
    assert!(!status_code(500).is_client_error());
}
async fn send_headers_recv_data_single_frame() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        // Write GET /
        .write(&[
            0, 0, 16, 1, 5, 0, 0, 0, 1, 130, 135, 65, 139, 157, 41, 172, 75, 143, 168, 233, 25,
            151, 33, 233, 132,
        ])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[
            0, 0, 1, 1, 4, 0, 0, 0, 1, 136, 0, 0, 5, 0, 0, 0, 0, 0, 1, 104, 101, 108, 108, 111, 0,
            0, 5, 0, 1, 0, 0, 0, 1, 119, 111, 114, 108, 100,
        ])
        .build();

    let (mut client, mut h2) = client::handshake(mock).await.unwrap();

    // Send the request
    let request = Request::builder()
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, _) = client.send_request(request, true).unwrap();

    let resp = h2.run(response).await.unwrap();
    assert_eq!(resp.status(), StatusCode::OK);

    // Take the body
    let (_, body) = resp.into_parts();

    // Wait for all the data frames to be received
    let bytes: Vec<_> = h2.run(body.try_collect()).await.unwrap();

    // Two data frames
    assert_eq!(2, bytes.len());

    assert_eq!(bytes[0], &b"hello"[..]);
    assert_eq!(bytes[1], &b"world"[..]);

    // The H2 connection is closed
    h2.await.unwrap();
}
fn lower_n_mask_test() {
    assert_eq!(mask::lower_n_mask(2), 0b11);
}
fn does_include_file_with_different_formatting_and_all_of_them() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "overrides": [
    { "include": ["special/**"], "formatter": { "lineWidth": 130 } },
    { "include": ["special/**"], "formatter": { "lineWidth": 20 } }
   ]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FORMATTED_LINE_WIDTH_OVERRIDDEN);
    assert_file_contents(&fs, test, FORMATTED_LINE_WIDTH);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_formatting_and_all_of_them",
        fs,
        console,
        result,
    ));
}
fn unreadable_dir() -> Result<()> {
    // Create a directory with 000 (not iterable/readable) permissions
    let tempdir = TempDir::new()?;
    let unreadable_dir = tempdir.path().join("unreadable_dir");
    fs::create_dir(&unreadable_dir)?;
    fs::set_permissions(&unreadable_dir, Permissions::from_mode(0o000))?;

    // We (currently?) have to use a subcommand to check exit status (currently wrong) and logging
    // output
    // TODO(konstin): This should be a failure, but we currently can't track that
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["--no-cache", "--isolated"])
        .arg(&unreadable_dir), @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    warning: Encountered error: Permission denied (os error 13)
    "###);
    Ok(())
}
fn fabsf_spec_test() {
    assert!(libm::fabsf(f32::NAN).is_nan());
    for f in [0.0, -0.0].iter().copied() {
        assert_eq!(libm::fabsf(f), 0.0);
    }
    for f in [f32::INFINITY, f32::NEG_INFINITY].iter().copied() {
        assert_eq!(libm::fabsf(f), f32::INFINITY);
    }
}
fn generic_signature_lifetimes() {
    fn write_key_generic<K: RedbKey>(
        table: TableDefinition<K, &[u8]>,
        key: K::SelfType<'_>,
        db: &Database,
    ) {
        let buf = [1, 2, 3];
        let write_txn = db.begin_write().unwrap();
        {
            let mut table = write_txn.open_table(table).unwrap();
            table.insert(key, buf.as_slice()).unwrap();
        }
        write_txn.commit().unwrap();
    }

    fn read_key_generic<K: RedbKey>(
        table: TableDefinition<K, &[u8]>,
        key: K::SelfType<'_>,
        db: &Database,
    ) {
        let buf = [1, 2, 3];
        let read_txn = db.begin_read().unwrap();
        let table = read_txn.open_table(table).unwrap();
        assert_eq!(table.get(key).unwrap().unwrap().value(), buf);
    }

    let tmpfile = create_tempfile();
    let db = &Database::create(tmpfile.path()).unwrap();
    {
        let (table, key) = (TableDefinition::<&str, _>::new("&str"), "key");
        write_key_generic(table, key, db);
        read_key_generic(table, key, db);
    }
    {
        let (table, key) = (TableDefinition::<(), _>::new("()"), ());
        write_key_generic(table, key, db);
        read_key_generic(table, key, db);
    }
}
fn trap_with_native_to_wasm_stack_args() -> Result<()> {
    let engine = Engine::default();
    let mut store = Store::new(&engine, ());
    let module = Module::new(
        &engine,
        r#"
            (module
                (func $trap
                    unreachable)
                (func $run (param i64 i64 i64 i64 i64 i64 i64 i64 i64 i64 i64 i64 i64 i64 i64)
                    call $trap)
                (export "run" (func $run))
            )
        "#,
    )?;

    let instance = Instance::new(&mut store, &module, &[])?;
    let run = instance.get_func(&mut store, "run").unwrap();

    let err = run
        .typed::<(
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
            i64,
        ), ()>(&mut store)?
        .call(&mut store, (0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0))
        .unwrap_err();
    assert!(err.is::<Trap>());

    let trace = err.downcast_ref::<WasmBacktrace>().unwrap();
    assert_eq!(trace.frames().len(), 2);
    assert_eq!(trace.frames()[0].func_name(), Some("trap"));
    assert_eq!(trace.frames()[1].func_name(), Some("run"));

    Ok(())
}
fn diff_only_unsafe_fixes_available() {
    assert_cmd_snapshot!(
    Command::new(get_cargo_bin(BIN_NAME))
        .args([
            "-",
            "--output-format",
            "text",
            "--isolated",
            "--no-cache",
            "--select",
            "F601",
            "--diff",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
        @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    No errors would be fixed (1 fix available with `--unsafe-fixes`).
    "###
    );
}
fn rust_catch_panic_import() -> Result<()> {
    let mut store = Store::<()>::default();

    let binary = wat::parse_str(
        r#"
            (module $a
                (import "" "panic" (func $panic))
                (import "" "catch panic" (func $catch_panic))
                (func (export "panic") call $panic)
                (func (export "run")
                  call $catch_panic
                  call $catch_panic
                  unreachable
                )
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let num_panics = std::sync::Arc::new(std::sync::atomic::AtomicU32::new(0));
    let sig = FuncType::new(None, None);
    let panic = Func::new(&mut store, sig, {
        let num_panics = num_panics.clone();
        move |_, _, _| {
            num_panics.fetch_add(1, std::sync::atomic::Ordering::SeqCst);
            panic!("this is a panic");
        }
    });
    let catch_panic = Func::wrap(&mut store, |mut caller: Caller<'_, _>| {
        panic::catch_unwind(AssertUnwindSafe(|| {
            drop(
                caller
                    .get_export("panic")
                    .unwrap()
                    .into_func()
                    .unwrap()
                    .call(&mut caller, &[], &mut []),
            );
        }))
        .unwrap_err();
    });

    let instance = Instance::new(&mut store, &module, &[panic.into(), catch_panic.into()])?;
    let run = instance.get_typed_func::<(), ()>(&mut store, "run")?;
    let trap = run.call(&mut store, ()).unwrap_err();
    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 1);
    assert_eq!(trace[0].func_index(), 3);
    assert_eq!(num_panics.load(std::sync::atomic::Ordering::SeqCst), 2);
    Ok(())
}
fn char() {
    assert_eq!("'a'".parse(), Ok(Value::Char('a')));
}
async fn too_big_headers_sends_reset_after_431_if_not_eos() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;
        assert_frame_eq(settings, frames::settings().max_header_list_size(10));
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .field("some-header", "some-value"),
            )
            .await;
        client
            .recv_frame(frames::headers(1).response(431).eos())
            .await;
        client.recv_frame(frames::reset(1).refused()).await;
    };

    let srv = async move {
        let mut srv = server::Builder::new()
            .max_header_list_size(10)
            .handshake::<_, Bytes>(io)
            .await
            .expect("handshake");

        let req = srv.next().await;
        assert!(req.is_none(), "req is {:?}", req);
    };

    join(client, srv).await;
}
fn try_reinscribe_without_flag() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let reveal_txid = CommandBuilder::new("wallet inscribe --file tulip.png --fee-rate 5.0 ")
    .write("tulip.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>()
    .reveal;

  assert_eq!(rpc_server.descriptors().len(), 3);

  rpc_server.mine_blocks(1);

  CommandBuilder::new(format!(
    "wallet inscribe --file orchid.png --fee-rate 1.1 --satpoint {reveal_txid}:0:0"
  ))
  .write("orchid.png", [1; 520])
  .rpc_server(&rpc_server)
  .expected_exit_code(1)
  .stderr_regex(format!(
    "error: sat at {reveal_txid}:0:0 already inscribed.*"
  ))
  .run_and_extract_stdout();
}
fn maximum_diagnostics() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), ERRORS.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    assert_eq!(
        messages
            .iter()
            .filter(|m| m.level == LogLevel::Error)
            .count(),
        20_usize
    );

    assert!(messages
        .iter()
        .filter(|m| m.level == LogLevel::Log)
        .any(|m| {
            let content = format!("{:?}", m.content);
            content.contains("The number of diagnostics exceeds the number allowed by Biome")
                && content.contains("Diagnostics not shown")
                && content.contains("77")
        }));

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "maximum_diagnostics",
        fs,
        console,
        result,
    ));
}
fn test_store_heartbeat() {
    let region_id = 2;
    let cluster = Cluster::with_node_count(1, None);
    let store_id = cluster.node(0).id();
    let router = &cluster.routers[0];
    // load data to split bucket.
    let header = Box::new(router.new_request_for(region_id).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");
    let data = put.encode();
    let write_bytes = data.data_size();
    let (msg, sub) = PeerMsg::simple_write(header, data);
    router.send(region_id, msg).unwrap();
    let _resp = block_on(sub.result()).unwrap();

    // report store heartbeat to pd.
    std::thread::sleep(std::time::Duration::from_millis(50));
    router
        .store_router()
        .send_control(StoreMsg::Tick(StoreTick::PdStoreHeartbeat))
        .unwrap();
    std::thread::sleep(std::time::Duration::from_millis(50));

    let stats = block_on(cluster.node(0).pd_client().get_store_stats_async(store_id)).unwrap();
    if stats.get_start_time() > 0 {
        assert_ne!(stats.get_capacity(), 0);
        assert_ne!(stats.get_used_size(), 0);
        assert_eq!(stats.get_keys_written(), 1);
        assert!(stats.get_bytes_written() > write_bytes.try_into().unwrap());
    }
}
fn invalid_nan_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.nan_string(Some(b"naaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaan"));
    assert!(!builder.is_valid());
    builder = builder.nan_string(Some(b"inf"));
    assert!(!builder.is_valid());
    builder = builder.nan_string(Some(b"na00n"));
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.nan_string(Some(b"nan"));
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
    builder = builder.nan_string(None);
    assert!(builder.is_valid());
}
fn does_handle_included_file_and_disable_organize_imports() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "include": ["test.js", "special/**"]
  },
  "overrides": [{ "include": ["special/**"], "organizeImports": { "enabled": false } }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNORGANIZED.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNORGANIZED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                "--formatter-enabled=false",
                "--linter-enabled=false",
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, UNORGANIZED);
    assert_file_contents(&fs, test, ORGANIZED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_included_file_and_disable_organize_imports",
        fs,
        console,
        result,
    ));
}
fn write_only_files_in_correct_base() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_to_format = Path::new("src/format.js");
    fs.insert(
        file_to_format.into(),
        <&str>::clone(&UNFORMATTED).as_bytes(),
    );

    let file_to_not_format = Path::new("scripts/format.js");
    fs.insert(file_to_not_format.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--write"), ("./src")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_to_format)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED, "we test the file is formatted");
    drop(file);
    let mut file = fs
        .open(file_to_not_format)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED, "we test the file is not formatted");
    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "write_only_files_in_correct_base",
        fs,
        console,
        result,
    ));
}
fn does_lint_included_files() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": { "ignore": ["test.js"] }, "linter": { "include": ["test.js"] }
}
"#,
    );

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_lint_included_files",
        fs,
        console,
        result,
    ));
}
fn test_kill_list_final_new_line() {
    let re = Regex::new("\\n$").unwrap();
    assert!(re.is_match(new_ucmd!().arg("-l").succeeds().stdout_str()));
}
fn test_kill_with_signal_number_new_form() {
    let mut target = Target::new();
    new_ucmd!()
        .arg("-s")
        .arg("9")
        .arg(format!("{}", target.pid()))
        .succeeds();
    assert_eq!(target.wait_for_signal(), Some(9));
}
fn parse_cte_renamed_columns() {
    let sql = "WITH cte (col1, col2) AS (SELECT foo, bar FROM baz) SELECT * FROM cte";
    let query = all_dialects().verified_query(sql);
    assert_eq!(
        vec![Ident::new("col1"), Ident::new("col2")],
        query
            .with
            .unwrap()
            .cte_tables
            .first()
            .unwrap()
            .alias
            .columns
    );
}
fn migrate_config_up_to_date() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let configuration = r#"{ "linter": { "enabled": true } }"#;

    let configuration_path = Path::new("biome.json");
    fs.insert(configuration_path.into(), configuration.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("migrate")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs.open(configuration_path).expect("file to open");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, configuration);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "migrate_config_up_to_date",
        fs,
        console,
        result,
    ));
}
fn test_kill_with_default_signal() {
    let mut target = Target::new();
    new_ucmd!().arg(format!("{}", target.pid())).succeeds();
    assert_eq!(target.wait_for_signal(), Some(libc::SIGTERM));
}
fn bad_globals() {
    let mut store = Store::<()>::default();
    let ty = GlobalType::new(ValType::I32, Mutability::Var);
    assert!(Global::new(&mut store, ty.clone(), Val::I64(0)).is_err());
    assert!(Global::new(&mut store, ty.clone(), Val::F32(0)).is_err());
    assert!(Global::new(&mut store, ty.clone(), Val::F64(0)).is_err());

    let ty = GlobalType::new(ValType::I32, Mutability::Const);
    let g = Global::new(&mut store, ty.clone(), Val::I32(0)).unwrap();
    assert!(g.set(&mut store, Val::I32(1)).is_err());

    let ty = GlobalType::new(ValType::I32, Mutability::Var);
    let g = Global::new(&mut store, ty.clone(), Val::I32(0)).unwrap();
    assert!(g.set(&mut store, Val::I64(0)).is_err());
}
fn test_request_snapshot_after_term_change() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(20);
    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    cluster.must_put(b"k1", b"v1");

    std::thread::sleep(Duration::from_millis(100));
    must_get_none(&cluster.get_engine(3), b"k1");

    // witness -> nonwitness
    let fp1 = "ignore generate snapshot";
    fail::cfg(fp1, "return").unwrap();
    cluster
        .pd_client
        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);
    std::thread::sleep(Duration::from_millis(500));
    // as we ignore generate snapshot, so snapshot should still not applied yet
    assert_eq!(cluster.pd_client.get_pending_peers().len(), 1);
    must_get_none(&cluster.get_engine(3), b"k1");

    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    // After leader changes, the `term` and `last term` no longer match, so
    // continue to receive `MsgAppend` until the two get equal, then retry to
    // request snapshot and complete the application.
    std::thread::sleep(Duration::from_millis(500));
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    assert_eq!(cluster.pd_client.get_pending_peers().len(), 0);
    fail::remove(fp1);
}
fn check_extend_unsafe_fixes_conflict_with_extend_safe_fixes() -> Result<()> {
    // Adding a rule to both options should result in it being treated as unsafe
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
extend-unsafe-fixes = ["UP034"]
extend-safe-fixes = ["UP034"]
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["check", "--config"])
        .arg(&ruff_toml)
        .arg("-")
        .args([
            "--output-format",
            "text",
            "--no-cache",
            "--select",
            "F601,UP034",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    -:2:7: UP034 Avoid extraneous parentheses
    Found 2 errors.
    No fixes available (2 hidden fixes can be enabled with the `--unsafe-fixes` option).

    ----- stderr -----
    "###);

    Ok(())
}
fn seq() {
    let seq = vec![
        Value::Number(Number::new(1)),
        Value::Number(Number::new(2f64)),
    ];
    assert_eq!("[1, 2.0]".parse(), Ok(Value::Seq(seq)));

    let err = Value::Seq(vec![Value::Number(Number::new(1))])
        .into_rust::<[i32; 2]>()
        .unwrap_err();

    assert_eq!(
        err,
        Error::ExpectedDifferentLength {
            expected: String::from("an array of length 2"),
            found: 1,
        }
    );

    let err = Value::Seq(vec![
        Value::Number(Number::new(1)),
        Value::Number(Number::new(2)),
        Value::Number(Number::new(3)),
    ])
    .into_rust::<[i32; 2]>()
    .unwrap_err();

    assert_eq!(
        err,
        Error::ExpectedDifferentLength {
            expected: String::from("a sequence of length 2"),
            found: 3,
        }
    );
}
fn test_mv_interactive_dir_to_file_not_affirmative() {
    let (at, mut ucmd) = at_and_ucmd!();

    let dir = "test_mv_interactive_dir_to_file_not_affirmative_dir";
    let file = "test_mv_interactive_dir_to_file_not_affirmative_file";

    at.mkdir(dir);
    at.touch(file);

    ucmd.arg(dir)
        .arg(file)
        .arg("-i")
        .pipe_in("n")
        .fails()
        .no_stdout();

    assert!(at.dir_exists(dir));
}
fn test_cp_sparse_always_empty() {
    let (at, mut ucmd) = at_and_ucmd!();

    const BUFFER_SIZE: usize = 4096 * 4;
    let buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];

    at.make_file("src_file1");
    at.write_bytes("src_file1", &buf);

    ucmd.args(&["--sparse=always", "src_file1", "dst_file_sparse"])
        .succeeds();

    assert_eq!(at.read_bytes("dst_file_sparse"), buf);
    assert_eq!(at.metadata("dst_file_sparse").blocks(), 0);
}
fn parse_literal_string() {
    let sql = r#"SELECT 'single', "double""#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Value(Value::SingleQuotedString("single".to_string())),
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Value(Value::DoubleQuotedString("double".to_string())),
        expr_from_projection(&select.projection[1])
    );
}
fn test_read_on_replica() {
    let count = 3;
    let mut cluster = new_server_cluster(0, count);
    cluster.cfg.raft_store.hibernate_regions = false;
    cluster.run();

    let k1 = b"k1";
    let (k2, v2) = (b"k2", b"v2");
    let (k3, v3) = (b"k3", b"v3");
    let (k4, v4) = (b"k4", b"v4");

    // make sure leader has been elected.
    assert_eq!(cluster.must_get(k1), None);

    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let mut leader_storage = cluster.sim.rl().storages[&leader.get_id()].clone();

    let mut leader_ctx = Context::default();
    leader_ctx.set_region_id(region.get_id());
    leader_ctx.set_region_epoch(region.get_region_epoch().clone());
    leader_ctx.set_peer(leader.clone());
    let leader_snap_ctx = SnapContext {
        pb_ctx: &leader_ctx,
        ..Default::default()
    };

    // write some data
    let peers = region.get_peers();
    assert_none(leader_snap_ctx, &mut leader_storage, k2);
    must_put(&leader_ctx, &leader_storage, k2, v2);

    // read on follower
    let mut follower_peer = None;
    let mut follower_id = 0;
    for p in peers {
        if p.get_id() != leader.get_id() {
            follower_id = p.get_id();
            follower_peer = Some(p.clone());
            break;
        }
    }

    assert!(follower_peer.is_some());
    let mut follower_ctx = Context::default();
    follower_ctx.set_region_id(region.get_id());
    follower_ctx.set_region_epoch(region.get_region_epoch().clone());
    follower_ctx.set_peer(follower_peer.as_ref().unwrap().clone());
    follower_ctx.set_replica_read(true);
    let follower_snap_ctx = SnapContext {
        pb_ctx: &follower_ctx,
        ..Default::default()
    };
    let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();
    assert_has(follower_snap_ctx.clone(), &mut follower_storage, k2, v2);

    must_put(&leader_ctx, &leader_storage, k3, v3);
    assert_has(follower_snap_ctx.clone(), &mut follower_storage, k3, v3);

    cluster.stop_node(follower_id);
    must_put(&leader_ctx, &leader_storage, k4, v4);
    cluster.run_node(follower_id).unwrap();
    let mut follower_storage = cluster.sim.rl().storages[&follower_id].clone();
    // sleep to ensure the follower has received a heartbeat from the leader
    thread::sleep(time::Duration::from_millis(300));
    assert_has(follower_snap_ctx, &mut follower_storage, k4, v4);
}
fn conflicting_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
indent-width = 2

[lint]
select = ["ALL"]
ignore = ["D203", "D212"]

[lint.isort]
lines-after-imports = 3
lines-between-types = 2
force-wrap-aliases = true
combine-as-imports = true
split-on-trailing-comma = true

[lint.flake8-quotes]
inline-quotes = "single"
docstring-quotes = "single"
multiline-quotes = "single"

[format]
skip-magic-trailing-comma = true
indent-style = "tab"
"#,
    )?;

    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["format", "--no-cache", "--config"])
        .arg(&ruff_toml)
        .arg(test_path), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    1 file reformatted

    ----- stderr -----
    warning: The following rules may cause conflicts when used with the formatter: `COM812`, `ISC001`. To avoid unexpected behavior, we recommend disabling these rules, either by removing them from the `select` or `extend-select` configuration, or adding them to the `ignore` configuration.
    warning: The `format.indent-style="tab"` option is incompatible with `W191`, which lints against all uses of tabs. We recommend disabling these rules when using the formatter, which enforces a consistent indentation style. Alternatively, set the `format.indent-style` option to `"space"`.
    warning: The `format.indent-style="tab"` option is incompatible with `D206`, with requires space-based indentation. We recommend disabling these rules when using the formatter, which enforces a consistent indentation style. Alternatively, set the `format.indent-style` option to `"space"`.
    warning: The `flake8-quotes.inline-quotes="single"` option is incompatible with the formatter's `format.quote-style="double"`. We recommend disabling `Q000` and `Q003` when using the formatter, which enforces a consistent quote style. Alternatively, set both options to either `"single"` or `"double"`.
    warning: The `flake8-quotes.multiline-quotes="single"` option is incompatible with the formatter. We recommend disabling `Q001` when using the formatter, which enforces double quotes for multiline strings. Alternatively, set the `flake8-quotes.multiline-quotes` option to `"double"`.`
    warning: The `flake8-quotes.multiline-quotes="single"` option is incompatible with the formatter. We recommend disabling `Q002` when using the formatter, which enforces double quotes for docstrings. Alternatively, set the `flake8-quotes.docstring-quotes` option to `"double"`.`
    warning: The isort option `isort.lines-after-imports` with a value other than `-1`, `1` or `2` is incompatible with the formatter. To avoid unexpected behavior, we recommend setting the option to one of: `2`, `1`, or `-1` (default).
    warning: The isort option `isort.lines-between-types` with a value greater than 1 is incompatible with the formatter. To avoid unexpected behavior, we recommend setting the option to one of: `1` or `0` (default).
    warning: The isort option `isort.force-wrap-aliases` is incompatible with the formatter `format.skip-magic-trailing-comma=true` option. To avoid unexpected behavior, we recommend either setting `isort.force-wrap-aliases=false` or `format.skip-magic-trailing-comma=false`.
    warning: The isort option `isort.split-on-trailing-comma` is incompatible with the formatter `format.skip-magic-trailing-comma=true` option. To avoid unexpected behavior, we recommend either setting `isort.split-on-trailing-comma=false` or `format.skip-magic-trailing-comma=false`.
    "###);
    Ok(())
}
fn test_nonexistent_tmpdir_env_var() {
    #[cfg(not(windows))]
    new_ucmd!().env(TMPDIR, "no/such/dir").fails().stderr_only("mktemp: failed to create file via template 'no/such/dir/tmp.XXXXXXXXXX': No such file or directory\n");
    #[cfg(windows)]
    {
        let result = new_ucmd!().env(TMPDIR, r"no\such\dir").fails();
        result.no_stdout();
        let stderr = result.stderr_str();
        assert!(
            stderr.starts_with("mktemp: failed to create file via template"),
            "{}",
            stderr
        );
        assert!(
            stderr.ends_with("no\\such\\dir\\tmp.XXXXXXXXXX': No such file or directory\n"),
            "{}",
            stderr
        );
    }

    #[cfg(not(windows))]
    new_ucmd!().env(TMPDIR, "no/such/dir").arg("-d").fails().stderr_only("mktemp: failed to create directory via template 'no/such/dir/tmp.XXXXXXXXXX': No such file or directory\n");
    #[cfg(windows)]
    {
        let result = new_ucmd!().env(TMPDIR, r"no\such\dir").arg("-d").fails();
        result.no_stdout();
        let stderr = result.stderr_str();
        assert!(
            stderr.starts_with("mktemp: failed to create directory via template"),
            "{}",
            stderr
        );
        assert!(
            stderr.ends_with("no\\such\\dir\\tmp.XXXXXXXXXX': No such file or directory\n"),
            "{}",
            stderr
        );
    }
}
fn test_install_creating_leading_dirs_verbose() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let source = "create_leading_test_file";
    let target = "dir1/no-dir2/no-dir3/test_file";

    at.touch(source);
    at.mkdir("dir1");

    let creating_dir1 = regex::Regex::new("(?m)^install: creating directory.*dir1'$").unwrap();
    let creating_nodir23 =
        regex::Regex::new(r"(?m)^install: creating directory.*no-dir[23]'$").unwrap();

    scene
        .ucmd()
        .arg("-Dv")
        .arg(source)
        .arg(at.plus(target))
        .succeeds()
        .stdout_matches(&creating_nodir23)
        .stdout_does_not_match(&creating_dir1)
        .no_stderr();

    assert!(at.file_exists(target));
}
fn factor_test() {
  assert_eq!(factor("3"), Ok(("", 3)));
  assert_eq!(factor(" 12"), Ok(("", 12)));
  assert_eq!(factor("537  "), Ok(("", 537)));
  assert_eq!(factor("  24   "), Ok(("", 24)));
}
fn i8_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0i8.to_lexical(&mut buffer));
    assert_eq!(b"1", 1i8.to_lexical(&mut buffer));
    assert_eq!(b"5", 5i8.to_lexical(&mut buffer));
    assert_eq!(b"127", 127i8.to_lexical(&mut buffer));
    assert_eq!(b"-128", (128u8 as i8).to_lexical(&mut buffer));
    assert_eq!(b"-1", (255u8 as i8).to_lexical(&mut buffer));
    assert_eq!(b"-1", (-1i8).to_lexical(&mut buffer));
}
fn test_chainable_undefined() {
    let mut env = Environment::new();
    env.set_undefined_behavior(UndefinedBehavior::Chainable);
    env.add_filter("test", |state: &State, value: String| -> String {
        assert_eq!(state.undefined_behavior(), UndefinedBehavior::Chainable);
        assert_eq!(value, "");
        value
    });

    assert_eq!(render!(in env, "<{{ true.missing_attribute }}>"), "<>");
    assert_eq!(render!(in env, "<{{ undefined.missing_attribute }}>"), "<>");
    assert_eq!(
        render!(in env, "<{% for x in undefined %}...{% endfor %}>"),
        "<>"
    );
    assert_eq!(render!(in env, "<{{ undefined }}>"), "<>");
    assert_eq!(render!(in env, "{{ undefined is undefined }}"), "true");
    assert_eq!(render!(in env, "{{ undefined|list }}"), "[]");
    assert_eq!(render!(in env, "<{{ undefined|test }}>"), "<>");
    assert_eq!(render!(in env, "{{ 42 in undefined }}"), "false");
}
fn simple() {
    assert_eq!(
        parse_and_match("{int $a = _+foo+$a;}", "void foo() {int bar=10+foo+bar;}"),
        1
    );
}
fn test_read_write_roundtrip_escape_text() -> Result<()> {
    let input = r#"
        <?xml version="1.0" encoding="UTF-8"?>
        <section ns:label="header">
            <section ns:label="empty element section" />
            <section ns:label="start/end section"></section>
            <section ns:label="with text">data &lt;escaped&gt;</section>
            </section>
    "#;

    let mut reader = Reader::from_str(input);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        match reader.read_event()? {
            Eof => break,
            Text(e) => {
                let t = e.unescape().unwrap();
                assert!(writer.write_event(Text(BytesText::new(&t))).is_ok());
            }
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(String::from_utf8(result).unwrap(), input);
    Ok(())
}
fn auto() {
    let f = super::fixture_root().join("tsconfig_project_references");

    let resolver = Resolver::new(ResolveOptions {
        tsconfig: Some(TsconfigOptions {
            config_file: f.join("app"),
            references: TsconfigReferences::Auto,
        }),
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        // Test normal paths alias
        (f.join("app"), "@/index.ts", f.join("app/aliased/index.ts")),
        (f.join("app"), "@/../index.ts", f.join("app/index.ts")),
        // Test project reference
        (f.join("project_a"), "@/index.ts", f.join("project_a/aliased/index.ts")),
        (f.join("project_b/src"), "@/index.ts", f.join("project_b/src/aliased/index.ts")),
        // Does not have paths alias
        (f.join("project_a"), "./index.ts", f.join("project_a/index.ts")),
        (f.join("project_c"), "./index.ts", f.join("project_c/index.ts")),
    ];

    for (path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|f| f.full_path());
        assert_eq!(resolved_path, Ok(expected), "{request} {path:?}");
    }
}
fn test_install_backup_existing() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=existing")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn function_interrupt_from_afar() -> anyhow::Result<()> {
    // Create an instance which calls an imported function on each iteration of
    // the loop so we can count the number of loop iterations we've executed so
    // far.
    static HITS: AtomicUsize = AtomicUsize::new(0);
    static STOP: AtomicBool = AtomicBool::new(false);

    let mut store = interruptable_store();
    let module = hugely_recursive_module(store.engine())?;
    let func = Func::wrap(&mut store, || {
        HITS.fetch_add(1, SeqCst);
    });
    let instance = Instance::new(&mut store, &module, &[func.into()])?;

    // Use the instance's interrupt handle to wait for it to enter the loop long
    // enough and then we signal an interrupt happens.
    let engine = store.engine().clone();
    let thread = std::thread::spawn(move || {
        while HITS.load(SeqCst) <= NUM_HITS && !STOP.load(SeqCst) {
            // continue ...
        }
        engine.increment_epoch();
    });

    // Enter the infinitely looping function and assert that our interrupt
    // handle does indeed actually interrupt the function.
    let iloop = instance.get_typed_func::<(), ()>(&mut store, "loop")?;
    let trap = iloop.call(&mut store, ()).unwrap_err().downcast::<Trap>()?;
    STOP.store(true, SeqCst);
    thread.join().unwrap();
    assert!(HITS.load(SeqCst) > NUM_HITS);
    assert_eq!(trap, Trap::Interrupt);
    Ok(())
}
fn invalid_justfile() {
  let tmp = temptree! {
    justfile: JUSTFILE,
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .output()
    .unwrap();

  assert!(!output.status.success());

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--edit")
    .env("VISUAL", "cat")
    .output()
    .unwrap();

  assert_stdout(&output, JUSTFILE);
}
fn nursery_prefix() {
    // `--select E` should detect E741, but not E225, which is in the nursery.
    let args = ["--select", "E"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    Found 1 error.

    ----- stderr -----
    "###);
}
fn test_second_document_syntax_error() {
    let yaml = indoc! {"
        ---
        0
        ---
        ]
    "};

    let mut de = Deserializer::from_str(yaml);
    let first_doc = de.next().unwrap();
    let result = <usize as serde::Deserialize>::deserialize(first_doc);
    assert_eq!(0, result.unwrap());

    let second_doc = de.next().unwrap();
    let result = <usize as serde::Deserialize>::deserialize(second_doc);
    let expected =
        "did not find expected node content at line 4 column 1, while parsing a block node";
    assert_eq!(expected, result.unwrap_err().to_string());
}
fn config_builder_for_server_rejects_incompatible_cipher_suites() {
    assert_eq!(
        ServerConfig::builder()
            .with_cipher_suites(&[rustls::cipher_suite::TLS13_AES_256_GCM_SHA384])
            .with_safe_default_kx_groups()
            .with_protocol_versions(&[&rustls::version::TLS12])
            .err(),
        Some(Error::General("no usable cipher suites configured".into()))
    );
}
fn test_link_no_circular() {
    let (at, mut ucmd) = at_and_ucmd!();
    let link = "test_link_no_circular";

    ucmd.args(&[link, link])
        .fails()
        .stderr_is("link: cannot create link 'test_link_no_circular' to 'test_link_no_circular': No such file or directory\n");
    assert!(!at.file_exists(link));
}
fn unreadable_pyproject_toml() -> Result<()> {
    let tempdir = TempDir::new()?;
    let pyproject_toml = tempdir.path().join("pyproject.toml");
    // Create an empty file with 000 permissions
    fs::OpenOptions::new()
        .create(true)
        .write(true)
        .mode(0o000)
        .open(pyproject_toml)?;

    // Don't `--isolated` since the configuration discovery is where the error happens
    let args = Args::parse_from(["", "check", "--no-cache", tempdir.path().to_str().unwrap()]);
    let err = run(args).err().context("Unexpected success")?;
    assert_eq!(
        err.chain()
            .map(std::string::ToString::to_string)
            .collect::<Vec<_>>(),
        vec!["Permission denied (os error 13)".to_string()],
    );
    Ok(())
}
fn test_lease_read_callback_destroy() {
    // Only server cluster can fake sending message successfully in raftstore layer.
    let mut cluster = new_server_cluster(0, 3);
    // Increase the Raft tick interval to make this test case running reliably.
    let election_timeout = configure_for_lease_read(&mut cluster.cfg, Some(50), None);
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    // Isolate the target peer to make transfer leader fail.
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    cluster.transfer_leader(1, new_peer(3, 3));
    thread::sleep(election_timeout * 2);
    // Trigger ReadIndex on the leader.
    assert_eq!(cluster.must_get(b"k1"), Some(b"v1".to_vec()));
    cluster.must_put(b"k2", b"v2");
}
fn test_public_assigned() {
    // Misc assigned.
    assert!(is_public_assigned('\0'));
    assert!(is_public_assigned('a'));
    assert!(is_public_assigned('\u{7f}'));
    assert!(is_public_assigned('\u{80}'));
    assert!(!is_public_assigned('\u{9e4}'));

    // Around the first unassigned non-private-use.
    assert!(is_public_assigned('\u{377}'));
    assert!(!is_public_assigned('\u{378}'));
    assert!(!is_public_assigned('\u{379}'));
    assert!(is_public_assigned('\u{37a}'));
    assert!(is_public_assigned('\u{37f}'));

    // Around the last assigned non-private-use.
    assert!(!is_public_assigned('\u{e00ff}'));
    assert!(is_public_assigned('\u{e0100}'));
    assert!(is_public_assigned('\u{e01ef}'));
    assert!(!is_public_assigned('\u{e01f0}'));

    // Private-Use areas
    assert!(!is_public_assigned('\u{e000}'));
    assert!(!is_public_assigned('\u{f8ff}'));
    assert!(!is_public_assigned('\u{f0000}'));
    assert!(!is_public_assigned('\u{ffffd}'));
    assert!(!is_public_assigned('\u{100000}'));
    assert!(!is_public_assigned('\u{10fffd}'));

    // Noncharacters are considered unassigned.
    assert!(!is_public_assigned('\u{fdd0}'));
    assert!(!is_public_assigned('\u{fdef}'));
    assert!(!is_public_assigned('\u{fffe}'));
    assert!(!is_public_assigned('\u{ffff}'));
    assert!(!is_public_assigned('\u{1fffe}'));
    assert!(!is_public_assigned('\u{1ffff}'));
    assert!(!is_public_assigned('\u{2fffe}'));
    assert!(!is_public_assigned('\u{2ffff}'));
    assert!(!is_public_assigned('\u{3fffe}'));
    assert!(!is_public_assigned('\u{3ffff}'));
    assert!(!is_public_assigned('\u{4fffe}'));
    assert!(!is_public_assigned('\u{4ffff}'));
    assert!(!is_public_assigned('\u{5fffe}'));
    assert!(!is_public_assigned('\u{5ffff}'));
    assert!(!is_public_assigned('\u{6fffe}'));
    assert!(!is_public_assigned('\u{6ffff}'));
    assert!(!is_public_assigned('\u{7fffe}'));
    assert!(!is_public_assigned('\u{7ffff}'));
    assert!(!is_public_assigned('\u{8fffe}'));
    assert!(!is_public_assigned('\u{8ffff}'));
    assert!(!is_public_assigned('\u{9fffe}'));
    assert!(!is_public_assigned('\u{9ffff}'));
    assert!(!is_public_assigned('\u{afffe}'));
    assert!(!is_public_assigned('\u{affff}'));
    assert!(!is_public_assigned('\u{bfffe}'));
    assert!(!is_public_assigned('\u{bffff}'));
    assert!(!is_public_assigned('\u{cfffe}'));
    assert!(!is_public_assigned('\u{cffff}'));
    assert!(!is_public_assigned('\u{dfffe}'));
    assert!(!is_public_assigned('\u{dffff}'));
    assert!(!is_public_assigned('\u{efffe}'));
    assert!(!is_public_assigned('\u{effff}'));
    assert!(!is_public_assigned('\u{ffffe}'));
    assert!(!is_public_assigned('\u{fffff}'));
    assert!(!is_public_assigned('\u{10fffe}'));
    assert!(!is_public_assigned('\u{10ffff}'));

    // Several ranges are defined by "<..., First>" and "<..., Last>" pairs in
    // UnicodeData.txt:

    // CJK Ideograph Extension A
    assert!(is_public_assigned('\u{3400}'));
    assert!(is_public_assigned('\u{4dbf}'));

    // CJK Ideograph
    assert!(is_public_assigned('\u{4e00}'));
    assert!(is_public_assigned('\u{9ffc}'));

    // Hangul Syllable
    assert!(is_public_assigned('\u{ac00}'));
    assert!(is_public_assigned('\u{d7a3}'));

    // Tangut Ideograph
    assert!(is_public_assigned('\u{17000}'));
    assert!(is_public_assigned('\u{187f7}'));

    // Tangut Ideograph Supplement
    assert!(is_public_assigned('\u{18d00}'));
    assert!(is_public_assigned('\u{18d08}'));

    // CJK Ideograph Extension B
    assert!(is_public_assigned('\u{20000}'));
    assert!(is_public_assigned('\u{2a6dd}'));

    // CJK Ideograph Extension C
    assert!(is_public_assigned('\u{2a700}'));
    assert!(is_public_assigned('\u{2b734}'));

    // CJK Ideograph Extension D
    assert!(is_public_assigned('\u{2b740}'));
    assert!(is_public_assigned('\u{2b81d}'));

    // CJK Ideograph Extension E
    assert!(is_public_assigned('\u{2b820}'));
    assert!(is_public_assigned('\u{2cea1}'));

    // CJK Ideograph Extension F
    assert!(is_public_assigned('\u{2ceb0}'));
    assert!(is_public_assigned('\u{2ebe0}'));

    // CJK Ideograph Extension G
    assert!(is_public_assigned('\u{30000}'));
    assert!(is_public_assigned('\u{3134a}'));
}
fn get_host_function() -> Result<()> {
    let engine = Engine::default();
    let module = Module::new(&engine, r#"(module (import "mod" "f1" (func)))"#)?;

    let mut linker = Linker::new(&engine);
    linker.func_wrap("mod", "f1", || {})?;
    let mut store = Store::new(&engine, ());
    assert!(linker
        .get_by_import(&mut store, &module.imports().nth(0).unwrap())
        .is_some());

    Ok(())
}
fn test_chown_file_notexisting() {
    // test chown username not_existing

    let scene = TestScenario::new(util_name!());

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    scene
        .ucmd()
        .arg(&user_name)
        .arg("--verbose")
        .arg("not_existing")
        .fails()
        .stdout_contains(format!(
            "failed to change ownership of 'not_existing' to {user_name}"
        ));
    // TODO: uncomment once message changed from "cannot dereference" to "cannot access"
    // result.stderr_contains("cannot access 'not_existing': No such file or directory");
}
fn render_multiple_inheritance() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("top", "{% block pre %}{% endblock pre %}{% block main %}{% endblock main %}"),
        ("mid", "{% extends \"top\" %}{% block pre %}PRE{% endblock pre %}"),
        ("bottom", "{% extends \"mid\" %}{% block main %}MAIN{% endblock main %}"),
    ])
    .unwrap();
    let result = tera.render("bottom", &Context::new());

    assert_eq!(result.unwrap(), "PREMAIN".to_string());
}
fn server_allow_any_anonymous_or_authenticated_client() {
    let kt = KeyType::Rsa;
    for client_cert_chain in [None, Some(kt.get_client_chain())].iter() {
        let client_auth_roots = get_client_root_store(kt);
        let client_auth = AllowAnyAnonymousOrAuthenticatedClient::new(client_auth_roots);

        let server_config = ServerConfig::builder()
            .with_safe_defaults()
            .with_client_cert_verifier(Arc::new(client_auth))
            .with_single_cert(kt.get_chain(), kt.get_key())
            .unwrap();
        let server_config = Arc::new(server_config);

        for version in rustls::ALL_VERSIONS {
            let client_config = if client_cert_chain.is_some() {
                make_client_config_with_versions_with_auth(kt, &[version])
            } else {
                make_client_config_with_versions(kt, &[version])
            };
            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
            do_handshake(&mut client, &mut server);

            let certs = server.peer_certificates();
            assert_eq!(certs, client_cert_chain.as_deref());
        }
    }
}
fn cannot_reenter_during_import() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "f" (func $f))

                (core func $f (canon lower (func $f)))

                (core module $m
                    (import "" "f" (func $f))
                    (func (export "call") call $f)
                    (func (export "dtor") (param i32) unreachable)
                )

                (core instance $i (instantiate $m
                    (with "" (instance
                        (export "f" (func $f))
                    ))
                ))

                (type $t2' (resource (rep i32) (dtor (func $i "dtor"))))
                (export $t2 "t" (type $t2'))
                (core func $ctor (canon resource.new $t2))
                (func (export "ctor") (param "x" u32) (result (own $t2))
                    (canon lift (core func $ctor)))

                (func (export "call") (canon lift (core func $i "call")))
            )
        "#,
    )?;

    let mut store = Store::new(&engine, None);
    let mut linker = Linker::new(&engine);
    linker.root().func_wrap("f", |mut cx, ()| {
        let data: &mut Option<ResourceAny> = cx.data_mut();
        let err = data.take().unwrap().resource_drop(cx).unwrap_err();
        assert_eq!(
            err.downcast_ref(),
            Some(&Trap::CannotEnterComponent),
            "bad error: {err:?}"
        );
        Ok(())
    })?;
    let i = linker.instantiate(&mut store, &c)?;

    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, "ctor")?;
    let call = i.get_typed_func::<(), ()>(&mut store, "call")?;

    let (resource,) = ctor.call(&mut store, (100,))?;
    ctor.post_return(&mut store)?;
    *store.data_mut() = Some(resource);
    call.call(&mut store, ())?;

    Ok(())
}
fn iter_last_nth() {
  let mut av: ArrayVec<[i32; 10]> = Default::default();
  av.push(1);
  av.push(2);
  av.push(3);
  av.push(4);
  assert_eq!(av.len(), 4);
  let mut iter = av.into_iter();
  assert_eq!(iter.next(), Some(1));
  assert_eq!(iter.next(), Some(2));
  assert_eq!(iter.next(), Some(3));
  assert_eq!(iter.next(), Some(4));
  assert_eq!(iter.next(), None);
  assert_eq!(iter.last(), None);

  let mut av: ArrayVec<[i32; 10]> = Default::default();
  av.push(1);
  av.push(2);
  av.push(3);

  assert_eq!(av.into_iter().nth(0), Some(1));
}
fn sum() {
    let xs: Vec<TextSize> = vec![size(0), size(1), size(2)];
    assert_eq!(xs.iter().sum::<TextSize>(), size(3));
    assert_eq!(xs.into_iter().sum::<TextSize>(), size(3));
}
fn encrypted_file() {
    let zip_file_bytes = &mut Cursor::new(vec![
        0x50, 0x4b, 0x03, 0x04, 0x14, 0x00, 0x01, 0x00, 0x00, 0x00, 0x54, 0xbd, 0xb5, 0x50, 0x2f,
        0x20, 0x79, 0x55, 0x2f, 0x00, 0x00, 0x00, 0x23, 0x00, 0x00, 0x00, 0x08, 0x00, 0x00, 0x00,
        0x74, 0x65, 0x73, 0x74, 0x2e, 0x74, 0x78, 0x74, 0xca, 0x2d, 0x1d, 0x27, 0x19, 0x19, 0x63,
        0x43, 0x77, 0x9a, 0x71, 0x76, 0xc9, 0xec, 0xd1, 0x6f, 0xd9, 0xf5, 0x22, 0x67, 0xb3, 0x8f,
        0x52, 0xb5, 0x41, 0xbc, 0x5c, 0x36, 0xf2, 0x1d, 0x84, 0xc3, 0xc0, 0x28, 0x3b, 0xfd, 0xe1,
        0x70, 0xc2, 0xcc, 0x0c, 0x11, 0x0c, 0xc5, 0x95, 0x2f, 0xa4, 0x50, 0x4b, 0x01, 0x02, 0x3f,
        0x00, 0x14, 0x00, 0x01, 0x00, 0x00, 0x00, 0x54, 0xbd, 0xb5, 0x50, 0x2f, 0x20, 0x79, 0x55,
        0x2f, 0x00, 0x00, 0x00, 0x23, 0x00, 0x00, 0x00, 0x08, 0x00, 0x24, 0x00, 0x00, 0x00, 0x00,
        0x00, 0x00, 0x00, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x74, 0x65, 0x73, 0x74,
        0x2e, 0x74, 0x78, 0x74, 0x0a, 0x00, 0x20, 0x00, 0x00, 0x00, 0x00, 0x00, 0x01, 0x00, 0x18,
        0x00, 0x31, 0xb2, 0x3b, 0xbf, 0xb8, 0x2f, 0xd6, 0x01, 0x31, 0xb2, 0x3b, 0xbf, 0xb8, 0x2f,
        0xd6, 0x01, 0xa8, 0xc4, 0x45, 0xbd, 0xb8, 0x2f, 0xd6, 0x01, 0x50, 0x4b, 0x05, 0x06, 0x00,
        0x00, 0x00, 0x00, 0x01, 0x00, 0x01, 0x00, 0x5a, 0x00, 0x00, 0x00, 0x55, 0x00, 0x00, 0x00,
        0x00, 0x00,
    ]);

    let mut archive = zip::ZipArchive::new(zip_file_bytes).unwrap();

    assert_eq!(archive.len(), 1); //Only one file inside archive: `test.txt`

    {
        // No password
        let file = archive.by_index(0);
        match file {
            Err(zip::result::ZipError::UnsupportedArchive(
                zip::result::ZipError::PASSWORD_REQUIRED,
            )) => (),
            Err(_) => panic!(
                "Expected PasswordRequired error when opening encrypted file without password"
            ),
            Ok(_) => panic!("Error: Successfully opened encrypted file without password?!"),
        }
    }

    {
        // Wrong password
        let file = archive.by_index_decrypt(0, b"wrong password");
        match file {
            Ok(Err(zip::result::InvalidPassword)) => (),
            Err(_) => panic!(
                "Expected InvalidPassword error when opening encrypted file with wrong password"
            ),
            Ok(Ok(_)) => panic!("Error: Successfully opened encrypted file with wrong password?!"),
        }
    }

    {
        // Correct password, read contents
        let mut file = archive
            .by_index_decrypt(0, "test".as_bytes())
            .unwrap()
            .unwrap();
        let file_name = file.enclosed_name().unwrap();
        assert_eq!(file_name, std::path::PathBuf::from("test.txt"));

        let mut data = Vec::new();
        file.read_to_end(&mut data).unwrap();
        assert_eq!(data, "abcdefghijklmnopqrstuvwxyz123456789".as_bytes());
    }
}
fn expr_test() {
  assert_eq!(expr(" 1 +  2 "), Ok(("", 3)));
  assert_eq!(expr(" 12 + 6 - 4+  3"), Ok(("", 17)));
  assert_eq!(expr(" 1 + 2*3 + 4"), Ok(("", 11)));
}
fn test_request_in_joint_state() {
    let mut cluster = new_node_cluster(0, 3);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region_id = cluster.run_conf_change();

    cluster.must_put(b"k1", b"v1");
    pd_client.must_add_peer(region_id, new_peer(2, 2));
    pd_client.must_add_peer(region_id, new_learner_peer(3, 3));
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");

    // Enter joint, now we have C_old(1, 2) and C_new(1, 3)
    pd_client.must_joint_confchange(
        region_id,
        vec![
            (ConfChangeType::AddLearnerNode, new_learner_peer(2, 2)),
            (ConfChangeType::AddNode, new_peer(3, 3)),
        ],
    );

    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    // Both new and old configuation have the newest log
    must_get_equal(&cluster.get_engine(2), b"k2", b"v2");
    must_get_equal(&cluster.get_engine(3), b"k2", b"v2");

    let region = cluster.get_region(b"k1");

    // Isolated peer 2, so the old configuation can't reach quorum
    cluster.add_send_filter(IsolationFilterFactory::new(2));
    let mut rx = cluster
        .async_request(put_request(&region, 1, b"k3", b"v3"))
        .unwrap();
    assert_eq!(
        rx.recv_timeout(Duration::from_millis(100)),
        Err(future::RecvTimeoutError::Timeout)
    );
    cluster.clear_send_filters();

    // Isolated peer 3, so the new configuation can't reach quorum
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    let mut rx = cluster
        .async_request(put_request(&region, 1, b"k4", b"v4"))
        .unwrap();
    assert_eq!(
        rx.recv_timeout(Duration::from_millis(100)),
        Err(future::RecvTimeoutError::Timeout)
    );
    cluster.clear_send_filters();

    // Leave joint
    pd_client.must_leave_joint(region_id);

    // Isolated peer 2, but it is not in quorum any more
    cluster.add_send_filter(IsolationFilterFactory::new(2));
    cluster.must_put(b"k5", b"v5");
    must_get_equal(&cluster.get_engine(3), b"k5", b"v5");
}
fn test_query_edns(client: &mut AsyncClient) -> impl Future<Output = ()> {
    let name = Name::from_ascii("WWW.example.com").unwrap();
    let mut edns = Edns::new();
    // garbage subnet value, but lets check
    edns.options_mut()
        .insert(EdnsOption::Subnet("1.2.0.0/16".parse().unwrap()));

    // TODO: write builder
    let mut msg = Message::new();
    msg.add_query({
        let mut query = Query::query(name.clone(), RecordType::A);
        query.set_query_class(DNSClass::IN);
        query
    })
    .set_id(rand::random::<u16>())
    .set_message_type(MessageType::Query)
    .set_op_code(OpCode::Query)
    .set_recursion_desired(true)
    .set_edns(edns)
    .extensions_mut()
    .as_mut()
    .map(|edns| edns.set_max_payload(1232).set_version(0));

    client
        .send(msg)
        .first_answer()
        .map_ok(move |response| {
            println!("response records: {response:?}");
            assert!(response
                .queries()
                .first()
                .expect("expected query")
                .name()
                .eq_case(&name));

            let record = &response.answers()[0];
            assert_eq!(record.name(), &name);
            assert_eq!(record.record_type(), RecordType::A);
            assert_eq!(record.dns_class(), DNSClass::IN);
            assert!(response.extensions().is_some());
            assert_eq!(
                response
                    .extensions()
                    .as_ref()
                    .unwrap()
                    .option(EdnsCode::Subnet)
                    .unwrap(),
                &EdnsOption::Subnet("1.2.0.0/16".parse().unwrap())
            );
            if let RData::A(ref address) = *record.data().unwrap() {
                assert_eq!(address, &A::new(93, 184, 216, 34))
            } else {
                panic!();
            }
        })
        .map(|r: Result<_, _>| r.expect("query failed"))
}
fn parse_create_table_as() {
    let sql = "CREATE TABLE t AS SELECT * FROM a";

    match verified_stmt(sql) {
        Statement::CreateTable { name, query, .. } => {
            assert_eq!(name.to_string(), "t".to_string());
            assert_eq!(query, Some(Box::new(verified_query("SELECT * FROM a"))));
        }
        _ => unreachable!(),
    }

    // BigQuery allows specifying table schema in CTAS
    // ANSI SQL and PostgreSQL let you only specify the list of columns
    // (without data types) in a CTAS, but we have yet to support that.
    let sql = "CREATE TABLE t (a INT, b INT) AS SELECT 1 AS b, 2 AS a";
    match verified_stmt(sql) {
        Statement::CreateTable { columns, query, .. } => {
            assert_eq!(columns.len(), 2);
            assert_eq!(columns[0].to_string(), "a INT".to_string());
            assert_eq!(columns[1].to_string(), "b INT".to_string());
            assert_eq!(
                query,
                Some(Box::new(verified_query("SELECT 1 AS b, 2 AS a")))
            );
        }
        _ => unreachable!(),
    }
}
fn server_close_notify() {
    let kt = KeyType::Rsa;
    let server_config = Arc::new(make_server_config_with_mandatory_client_auth(kt));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions_with_auth(kt, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        do_handshake(&mut client, &mut server);

        // check that alerts don't overtake appdata
        assert_eq!(
            12,
            server
                .writer()
                .write(b"from-server!")
                .unwrap()
        );
        assert_eq!(
            12,
            client
                .writer()
                .write(b"from-client!")
                .unwrap()
        );
        server.send_close_notify();

        transfer(&mut server, &mut client);
        let io_state = client.process_new_packets().unwrap();
        assert!(io_state.peer_has_closed());
        check_read_and_close(&mut client.reader(), b"from-server!");

        transfer(&mut client, &mut server);
        server.process_new_packets().unwrap();
        check_read(&mut server.reader(), b"from-client!");
    }
}
fn render_include_array_tag() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("world", "world"),
        ("hello", "<h1>Hello {% include [\"custom/world\", \"world\"] %}</h1>"),
    ])
    .unwrap();
    let result = tera.render("hello", &Context::new()).unwrap();
    assert_eq!(result, "<h1>Hello world</h1>".to_owned());

    tera.add_raw_template("custom/world", "custom world").unwrap();
    let result = tera.render("hello", &Context::new()).unwrap();
    assert_eq!(result, "<h1>Hello custom world</h1>".to_owned());
}
fn file_too_large_cli_limit() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--files-max-size=16"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "file_too_large_cli_limit",
        fs,
        console,
        result,
    ));
}
fn write_error() {
  let tempdir = temptree! {
    justfile: "x    :=    'hello'   ",
  };

  let test = Test::with_tempdir(tempdir)
    .no_justfile()
    .args(["--fmt", "--unstable"])
    .status(EXIT_FAILURE)
    .stderr_regex(if cfg!(windows) {
      r"error: Failed to write justfile to `.*`: Access is denied. \(os error 5\)\n"
    } else {
      r"error: Failed to write justfile to `.*`: Permission denied \(os error 13\)\n"
    });

  let justfile_path = test.justfile_path();

  ("chmod", "400", &justfile_path).run();

  let _tempdir = test.run();

  assert_eq!(
    fs::read_to_string(&justfile_path).unwrap(),
    "x    :=    'hello'   "
  );
}
fn test_hex_suffix_alias() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n", "4", "--hex=9", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x0a"), "b");
    assert_eq!(at.read("x0b"), "c");
    assert_eq!(at.read("x0c"), "");
}
fn test_split_default_with_io_blksize() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_default_with_io_blksize";
    RandomFile::new(&at, name).add_lines(2000);
    ucmd.args(&[name, "---io-blksize", "2M"]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_writer_borrow() -> Result<()> {
    let txt = include_str!("../tests/documents/test_writer.xml").trim();
    let mut reader = Reader::from_str(txt);
    reader.trim_text(true);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(&e).is_ok()), // either `e` or `&e`
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(result, txt.as_bytes());
    Ok(())
}
fn bh_test() {
    assert_eq!(bh(1e-45_f32), (3, -150));
    assert_eq!(bh(5e-324_f64), (3, -1075));
    assert_eq!(bh(1_f32), (16777217, -24));
    assert_eq!(bh(1_f64), (9007199254740993, -53));
    assert_eq!(bh(1e38_f32), (19721523, 102));
    assert_eq!(bh(1e308_f64), (10020841800044865, 970));
}
fn test_download_sst() {
    let (_cluster, ctx, tikv, import) = new_cluster_and_tikv_import_client();
    let temp_dir = Builder::new()
        .prefix("test_download_sst")
        .tempdir()
        .unwrap();

    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, _) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());

    // Checks that downloading a non-existing storage returns error.
    let mut download = DownloadRequest::default();
    download.set_sst(meta.clone());
    download.set_storage_backend(external_storage_export::make_local_backend(temp_dir.path()));
    download.set_name("missing.sst".to_owned());

    let result = import.download(&download).unwrap();
    assert!(
        result.has_error(),
        "unexpected download reply: {:?}",
        result
    );

    // Checks that downloading an empty SST returns OK (but cannot be ingested)
    download.set_name("test.sst".to_owned());
    download.mut_sst().mut_range().set_start(vec![sst_range.1]);
    download
        .mut_sst()
        .mut_range()
        .set_end(vec![sst_range.1 + 1]);
    let result = import.download(&download).unwrap();
    assert!(result.get_is_empty());

    // Now perform a proper download.
    download.mut_sst().mut_range().set_start(Vec::new());
    download.mut_sst().mut_range().set_end(Vec::new());
    let result = import.download(&download).unwrap();
    assert!(!result.get_is_empty());
    assert_eq!(result.get_range().get_start(), &[sst_range.0]);
    assert_eq!(result.get_range().get_end(), &[sst_range.1 - 1]);

    // Do an ingest and verify the result is correct.

    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error());

    check_ingested_kvs(&tikv, &ctx, sst_range);
}
fn template_cant_access_macros_context() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("parent", r#"{% import "macros" as macros %}{{ macros::empty() }}{{ quote | default(value="I'd rather have roses on my table than diamonds on my neck.") }}"#),
        ("macros", r#"{% macro empty() %}{% set_global quote = "This should not reachable from the calling template!" %}{% endmacro empty %}"#)
    ]).unwrap();

    let result = tera.render("parent", &Context::new());
    assert_eq!(result.unwrap(), "I'd rather have roses on my table than diamonds on my neck.");
}
fn atomic_wait_timeout_length() -> Result<()> {
    let sleep_nanoseconds = 500000000;
    let wat = format!(
        r#"(module
        (import "env" "memory" (memory 1 1 shared))

        (func (export "func1") (result i32)
            (memory.atomic.wait32 (i32.const 0) (i32.const 0) (i64.const {sleep_nanoseconds}))
        )

        (data (i32.const 0) "\00\00\00\00")
    )"#
    );
    let mut config = Config::new();
    config.wasm_threads(true);
    let engine = Engine::new(&config)?;
    let module = Module::new(&engine, wat)?;
    let mut store = Store::new(&engine, ());
    let shared_memory = SharedMemory::new(&engine, MemoryType::shared(1, 1))?;
    let instance = Instance::new(&mut store, &module, &[shared_memory.clone().into()])?;
    let now = Instant::now();
    let func_ret = instance
        .get_typed_func::<(), i32>(&mut store, "func1")
        .unwrap()
        .call(&mut store, ())
        .unwrap();
    let duration = now.elapsed();
    assert!(
        duration.as_nanos() >= sleep_nanoseconds,
        "duration: {duration:?} < {sleep_nanoseconds:?}"
    );
    assert_eq!(func_ret, 2);
    Ok(())
}
fn can_remove_whitespace_macros() {
    let mut context = Context::new();
    context.insert("numbers", &vec![1, 2, 3]);

    let inputs = vec![
        (r#" {%- import "macros" as macros -%} {{macros::hey()}}"#, "Hey!"),
        (r#" {% import "macros" as macros %} {{macros::hey()}}"#, "Hey!"),
        (r#" {%- import "macros" as macros %} {%- set hey = macros::hey() -%} {{hey}}"#, "Hey!"),
    ];

    for (input, expected) in inputs {
        let mut tera = Tera::default();
        tera.add_raw_templates(vec![
            ("macros", "{% macro hey() -%} Hey! {%- endmacro %}"),
            ("tpl", input),
        ])
        .unwrap();
        assert_eq!(tera.render("tpl", &context).unwrap(), expected);
    }
}
fn test_datetimeformat_iso_negative() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "America/Chicago");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("1687624642.5|datetimeformat(format='iso')")
        .unwrap();
    assert_eq!(
        expr.eval(()).unwrap().to_string(),
        "2023-06-24T11:37:22-05:00"
    )
}
fn remove_multiple_a() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());
    headers.insert(VARY, "*".parse().unwrap());

    assert_eq!(headers.len(), 6);

    let cookie = headers.remove(SET_COOKIE);
    assert_eq!(cookie, Some("cookie_1=value 1".parse().unwrap()));
    assert_eq!(headers.len(), 3);

    let via = headers.remove(VIA);
    assert_eq!(via, Some("1.1 example.com".parse().unwrap()));
    assert_eq!(headers.len(), 1);

    let vary = headers.remove(VARY);
    assert_eq!(vary, Some("*".parse().unwrap()));
    assert_eq!(headers.len(), 0);
}
fn test_rm_empty_directory() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_rm_empty_directory";

    at.mkdir(dir);

    ucmd.arg("-d").arg(dir).succeeds().no_stderr();

    assert!(!at.dir_exists(dir));
}
fn remove_entry_3_others_a() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());
    headers.insert(VARY, "*".parse().unwrap());

    assert_eq!(headers.len(), 6);

    let cookie = remove_values(&mut headers, SET_COOKIE);
    assert_eq!(cookie, Some("cookie_1=value 1".parse().unwrap()));
    assert_eq!(headers.len(), 3);

    let via = remove_values(&mut headers, VIA);
    assert_eq!(via, Some("1.1 example.com".parse().unwrap()));
    assert_eq!(headers.len(), 1);

    let vary = remove_values(&mut headers, VARY);
    assert_eq!(vary, Some("*".parse().unwrap()));
    assert_eq!(headers.len(), 0);
}
fn dynamic_val() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t1" (type $t1 (sub resource)))
                (type $t2' (resource (rep i32)))
                (export $t2 "t2" (type $t2'))
                (core func $f (canon resource.new $t2))

                (core module $m
                    (func (export "pass") (param i32) (result i32)
                        (local.get 0)))
                (core instance $i (instantiate $m))

                (func (export "a") (param "x" (own $t1)) (result (own $t1))
                    (canon lift (core func $i "pass")))
                (func (export "b") (param "x" u32) (result (own $t2))
                    (canon lift (core func $f)))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t1", |_, _| Ok(()))?;
    let i = linker.instantiate(&mut store, &c)?;

    let a = i.get_func(&mut store, "a").unwrap();
    let a_typed = i.get_typed_func::<(Resource<MyType>,), (ResourceAny,)>(&mut store, "a")?;
    let b = i.get_func(&mut store, "b").unwrap();
    let t2 = i.get_resource(&mut store, "t2").unwrap();

    let t1 = Resource::new_own(100);
    let (t1,) = a_typed.call(&mut store, (t1,))?;
    a_typed.post_return(&mut store)?;
    assert_eq!(t1.ty(), ResourceType::host::<MyType>());

    let mut results = [Val::Bool(false)];
    a.call(&mut store, &[Val::Resource(t1)], &mut results)?;
    a.post_return(&mut store)?;
    match &results[0] {
        Val::Resource(resource) => {
            assert_eq!(resource.ty(), ResourceType::host::<MyType>());
        }
        _ => unreachable!(),
    }

    b.call(&mut store, &[Val::U32(200)], &mut results)?;
    match &results[0] {
        Val::Resource(resource) => {
            assert_eq!(resource.ty(), t2);
        }
        _ => unreachable!(),
    }

    Ok(())
}
fn is_right_endpoint_test() {
    assert_eq!(algorithm::is_right_endpoint::<f64>(1), true);
    assert_eq!(algorithm::is_right_endpoint::<f64>(2), true);
    assert_eq!(algorithm::is_right_endpoint::<f64>(3), true);
    assert_eq!(algorithm::is_right_endpoint::<f64>(4), false);
}
fn test_basic() {
    check!(0.0);
    check!(-0.0);
    check!(1.0);
    check!(-1.0);
    assert_eq!(pretty(f32::NAN), "NaN");
    assert_eq!(pretty(f32::INFINITY), "inf");
    assert_eq!(pretty(f32::NEG_INFINITY), "-inf");
}
fn test_datetimeformat_chrono() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATETIME_FORMAT", "[hour]:[minute]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("d|datetimeformat(format=format)")
        .unwrap();

    let d = chrono::DateTime::parse_from_rfc3339("2023-06-24T16:37:00Z").unwrap();
    assert_eq!(
        expr.eval(context!(d, format => "short"))
            .unwrap()
            .to_string(),
        "2023-06-24 18:37"
    );
}
fn indent_size_parse_errors_overflow() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--indent-size=257"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "indent_size_parse_errors_overflow",
        fs,
        console,
        result,
    ));
}
fn write_batch_write_twice_1() {
    let db = default_engine();

    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"aa").unwrap();

    wb.write().unwrap();
    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");

    let db = multi_batch_write_engine();

    let mut wb = db.engine.write_batch_with_cap(1024);

    for i in 0..123_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"aa").unwrap();

    wb.write().unwrap();
    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");
    for i in 0..123_usize {
        let x = i.to_be_bytes();
        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);
    }
}
fn test_expr_size() {
    assert_eq!(mem::size_of::<Expr>(), 176);
}
fn math() {
    assert_eq!(size(10) + size(5), size(15));
    assert_eq!(size(10) - size(5), size(5));
}
fn test_symlink_to_dir_2args() {
    let (at, mut ucmd) = at_and_ucmd!();
    let filename = "test_symlink_to_dir_2args_file";
    let from_file = &format!("{}/{}", at.as_string(), filename);
    let to_dir = "test_symlink_to_dir_2args_to_dir";
    let to_file = &format!("{to_dir}/{filename}");

    at.mkdir(to_dir);
    at.touch(from_file);

    ucmd.args(&["-s", from_file, to_dir]).succeeds().no_stderr();

    assert!(at.file_exists(to_file));
    assert!(at.is_symlink(to_file));
    assert_eq!(at.resolve_link(to_file), filename);
}
fn is_fast_path_test() {
    let mut number = Number {
        exponent: -4,
        mantissa: 12345,
        is_negative: false,
        many_digits: false,
        integer: &[],
        fraction: None,
    };
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), true);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.exponent = -15;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.exponent = -25;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), false);

    number.exponent = 25;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.exponent = 36;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.exponent = 38;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), false);

    number.mantissa = 1 << 25;
    number.exponent = 0;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.mantissa = 1 << 54;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), false);

    number.mantissa = 1 << 52;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), true);

    number.many_digits = true;
    assert_eq!(number.is_fast_path::<f32, { STANDARD }>(), false);
    assert_eq!(number.is_fast_path::<f64, { STANDARD }>(), false);
}
fn congested_tail_loss() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, _) = pair.connect();

    const TARGET: u64 = 2048;
    assert!(pair.client_conn_mut(client_ch).congestion_window() > TARGET);
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    // Send data without receiving ACKs until the congestion state falls below target
    while pair.client_conn_mut(client_ch).congestion_window() > TARGET {
        let n = pair.client_send(client_ch, s).write(&[42; 1024]).unwrap();
        assert_eq!(n, 1024);
        pair.drive_client();
    }
    assert!(!pair.server.inbound.is_empty());
    pair.server.inbound.clear();
    // Ensure that the congestion state recovers after retransmits occur and are ACKed
    info!("recovering");
    pair.drive();
    assert!(pair.client_conn_mut(client_ch).congestion_window() > TARGET);
    pair.client_send(client_ch, s).write(&[42; 1024]).unwrap();
}
fn scalar_mul_test() {
    assert_eq!(bigint::scalar_mul(5, 5, 0), (25, 0));
    assert_eq!(bigint::scalar_mul(5, 5, 1), (26, 0));
    assert_eq!(bigint::scalar_mul(Limb::MAX, 2, 0), (Limb::MAX - 1, 1));
}
fn test_something() {
    let data = [];
    let mut testcase = testcase;
    let fuel: u8 = std::env::args()
        .find_map(|arg| arg.strip_prefix("--fuel=").map(|s| s.to_owned()))
        .map(|fuel| fuel.parse().expect("fuel should be a valid integer"))
        .unwrap_or_default();
    for i in 0..testcase.ctrl_planes.len() {
        testcase.ctrl_planes[i].set_fuel(fuel)
    }
    let testcase = testcase;
    assert!(testcase.isa.flags().enable_verifier());
    let valid_inputs = STATISTICS.valid_inputs.fetch_add(1, Ordering::SeqCst);
    if valid_inputs != 0 && valid_inputs % 10000 == 0 {
        STATISTICS.print(valid_inputs);
    }
    if !testcase.compare_against_host {
        let opt_testcase = testcase.to_optimized();
        run_test_inputs(&testcase, |args| {
            let mut interpreter = build_interpreter(&opt_testcase);
            run_in_interpreter(&mut interpreter, args)
        });
    } else {
        let mut compiler = TestFileCompiler::new(testcase.isa.clone());
        compiler
            .add_functions(&testcase.functions[..], testcase.ctrl_planes.clone())
            .unwrap();
        let compiled = compiler.compile().unwrap();
        let trampoline = compiled.get_trampoline(testcase.main()).unwrap();
        run_test_inputs(&testcase, |args| run_in_host(&trampoline, args));
    }
}
fn fix_only_unsafe_fixes_available() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601",
                "--fix",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    x = {'a': 1, 'a': 1}
    print(('foo'))

    ----- stderr -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    Found 1 error.
    No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).
    "###);
}
fn test_limits_table_only() -> Result<()> {
    let engine = Engine::default();
    let module = Module::new(
        &engine,
        r#"(module (memory (export "m") 0) (table (export "t") 0 anyfunc))"#,
    )?;

    let mut store = Store::new(&engine, StoreLimitsBuilder::new().table_elements(5).build());
    store.limiter(|s| s as &mut dyn ResourceLimiter);

    let instance = Instance::new(&mut store, &module, &[])?;

    // Test instance exports and host objects *not* hitting the limit
    for memory in IntoIterator::into_iter([
        instance.get_memory(&mut store, "m").unwrap(),
        Memory::new(&mut store, MemoryType::new(0, None))?,
    ]) {
        memory.grow(&mut store, 3)?;
        memory.grow(&mut store, 5)?;
        memory.grow(&mut store, 2)?;
        memory.grow(&mut store, 1)?;
    }

    // Test instance exports and host objects hitting the limit
    for table in IntoIterator::into_iter([
        instance.get_table(&mut store, "t").unwrap(),
        Table::new(
            &mut store,
            TableType::new(ValType::FuncRef, 0, None),
            Val::FuncRef(None),
        )?,
    ]) {
        table.grow(&mut store, 2, Val::FuncRef(None))?;
        table.grow(&mut store, 1, Val::FuncRef(None))?;
        table.grow(&mut store, 2, Val::FuncRef(None))?;

        assert_eq!(
            table
                .grow(&mut store, 1, Val::FuncRef(None))
                .map_err(|e| e.to_string())
                .unwrap_err(),
            "failed to grow table by `1`"
        );
    }

    Ok(())
}
fn check_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "check_help",
        fs,
        console,
        result,
    ));
}
fn test_update_max_ts_before_scan_memory_locks() {
    let engine = TestEngineBuilder::new().build().unwrap();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .build()
        .unwrap();

    fail::cfg("before-storage-check-memory-locks", "sleep(500)").unwrap();
    let get_fut = storage.get(Context::default(), Key::from_raw(b"k"), 100.into());

    thread::sleep(Duration::from_millis(200));

    let (prewrite_tx, prewrite_rx) = channel();
    storage
        .sched_txn_command(
            commands::Prewrite::new(
                vec![Mutation::make_put(Key::from_raw(b"k"), b"v".to_vec())],
                b"k".to_vec(),
                10.into(),
                20000,
                false,
                1,
                TimeStamp::default(),
                TimeStamp::default(),
                Some(vec![]),
                false,
                AssertionLevel::Off,
                Context::default(),
            ),
            Box::new(move |res| {
                prewrite_tx.send(res).unwrap();
            }),
        )
        .unwrap();

    // The prewritten lock is not seen by the reader
    assert_eq!(block_on(get_fut).unwrap().0, None);
    // But we make sure in this case min_commit_ts is greater than start_ts.
    let res = prewrite_rx.recv().unwrap().unwrap();
    assert_eq!(res.min_commit_ts, 101.into());
}
fn filter_args_are_not_escaped() {
    let mut context = Context::new();
    context.insert("my_var", &"hey");
    context.insert("to", &"&");
    let input = r#"{{ my_var | replace(from="h", to=to) }}"#;

    assert_eq!(render_template(input, &context).unwrap(), "&amp;ey");
}
fn encode_engine_slice_error_when_buffer_too_small() {
    for num_triples in 1..100 {
        let input = "AAA".repeat(num_triples);
        let mut vec = vec![0; (num_triples - 1) * 4];
        assert_eq!(
            EncodeSliceError::OutputSliceTooSmall,
            STANDARD.encode_slice(&input, &mut vec).unwrap_err()
        );
        vec.push(0);
        assert_eq!(
            EncodeSliceError::OutputSliceTooSmall,
            STANDARD.encode_slice(&input, &mut vec).unwrap_err()
        );
        vec.push(0);
        assert_eq!(
            EncodeSliceError::OutputSliceTooSmall,
            STANDARD.encode_slice(&input, &mut vec).unwrap_err()
        );
        vec.push(0);
        assert_eq!(
            EncodeSliceError::OutputSliceTooSmall,
            STANDARD.encode_slice(&input, &mut vec).unwrap_err()
        );
        vec.push(0);
        assert_eq!(
            num_triples * 4,
            STANDARD.encode_slice(&input, &mut vec).unwrap()
        );
    }
}
fn cf_names() {
    let db = engine_cfs(ALL_CFS);
    let names = db.engine.cf_names();
    assert_eq!(names.len(), ALL_CFS.len());
    for cf in ALL_CFS {
        assert!(names.contains(cf));
    }
}
fn test_install_backup_long_no_args_files() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_simple_backup_file_a";
    let file_b = "test_install_simple_backup_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_mv_move_multiple_files_into_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "test_mv_move_multiple_files_into_file1";
    let file2 = "test_mv_move_multiple_files_into_file2";
    let file3 = "test_mv_move_multiple_files_into_file3";

    at.touch(file1);
    at.touch(file2);
    at.touch(file3);

    ucmd.arg(file1)
        .arg(file2)
        .arg(file3)
        .fails()
        .stderr_is(format!("mv: target '{file3}': Not a directory\n"));

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
}
fn test_chown_only_user_id() {
    // test chown 1111 file.txt

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("id").arg("-u").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let user_id = String::from(result.stdout_str().trim());
    assert!(!user_id.is_empty());

    let file1 = "test_chown_file1";
    at.touch(file1);

    let result = scene.ucmd().arg(user_id).arg("--verbose").arg(file1).run();
    if skipping_test_is_okay(&result, "invalid user") {
        // From the Logs: "Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)"
        // stderr: "chown: invalid user: '1001'
        return;
    }
    result.stderr_contains("retained as");

    scene
        .ucmd()
        .arg("0")
        .arg("--verbose")
        .arg(file1)
        .fails()
        .stderr_contains("failed to change");
}
fn test_abs_overflow() {
    let ok = abs(Value::from(i64::MIN)).unwrap();
    assert_eq!(ok, Value::from(-(i64::MIN as i128)));
    let err = abs(Value::from(i128::MIN)).unwrap_err();
    assert_eq!(err.to_string(), "invalid operation: overflow on abs");
}
fn test_restart_resume() {
    let mut cluster = Cluster::default();
    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();
    let router = &mut cluster.routers[0];

    let region_id = 2;
    let region = router.region_detail(region_id);
    let peer = region.get_peers()[0].clone();
    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    let fp = "async_write_before_cb";
    fail::cfg(fp, "return").unwrap();

    let split_region_id = 1000;
    let mut new_peer = peer.clone();
    new_peer.set_id(1001);
    split_region(
        router,
        region,
        peer,
        split_region_id,
        new_peer,
        None,
        None,
        b"k11",
        b"k11",
        true,
    );

    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"k22", b"value");
    let header = Box::new(router.new_request_for(region_id).take_header());
    let (msg, mut sub) = PeerMsg::simple_write(header, put.encode());
    router.send(region_id, msg).unwrap();
    // Send a command to ensure split init is triggered.
    block_on(sub.wait_proposed());

    let region_state = raft_engine
        .get_region_state(split_region_id, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
    let path = cluster
        .node(0)
        .tablet_registry()
        .tablet_path(split_region_id, RAFT_INIT_LOG_INDEX);
    assert!(!path.exists(), "{} should not exist", path.display());
    drop(raft_engine);

    cluster.restart(0);
    // If split is resumed, the tablet should be installed.
    assert!(
        path.exists(),
        "{} should exist after restart",
        path.display()
    );

    // Both region should be recovered correctly.
    let cases = vec![
        (split_region_id, b"k01", b"v01"),
        (region_id, b"k21", b"v21"),
    ];
    let router = &mut cluster.routers[0];
    let new_epoch = router
        .new_request_for(split_region_id)
        .take_header()
        .take_region_epoch();
    // Split will be resumed for region 2, not removing the fp will make write block
    // forever.
    fail::remove(fp);
    let timer = Instant::now();
    for (region_id, key, val) in cases {
        let mut put = SimpleWriteEncoder::with_capacity(64);
        put.put(CF_DEFAULT, key, val);
        let mut header = Box::new(router.new_request_for(region_id).take_header());
        while timer.elapsed() < Duration::from_secs(3) {
            // We need to wait till source peer replay split.
            if *header.get_region_epoch() != new_epoch {
                thread::sleep(Duration::from_millis(100));
                header = Box::new(router.new_request_for(region_id).take_header());
                continue;
            }
            break;
        }
        assert_eq!(*header.get_region_epoch(), new_epoch, "{:?}", header);
        let (msg, sub) = PeerMsg::simple_write(header, put.encode());
        router.send(region_id, msg).unwrap();
        // Send a command to ensure split init is triggered.
        let resp = block_on(sub.result()).unwrap();
        assert!(!resp.get_header().has_error(), "{:?}", resp);
    }
}
fn memory_zeroed() -> Result<()> {
    if skip_pooling_allocator_tests() {
        return Ok(());
    }

    let mut pool = crate::small_pool_config();
    pool.memory_pages(1).table_elements(0);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    config.dynamic_memory_guard_size(0);
    config.static_memory_guard_size(0);
    config.static_memory_maximum_size(65536);

    let engine = Engine::new(&config)?;

    let module = Module::new(&engine, r#"(module (memory (export "m") 1))"#)?;

    // Instantiate the module repeatedly after writing data to the entire memory
    for _ in 0..10 {
        let mut store = Store::new(&engine, ());
        let instance = Instance::new(&mut store, &module, &[])?;
        let memory = instance.get_memory(&mut store, "m").unwrap();

        assert_eq!(memory.size(&store,), 1);
        assert_eq!(memory.data_size(&store), 65536);

        let ptr = memory.data_mut(&mut store).as_mut_ptr();

        unsafe {
            for i in 0..8192 {
                assert_eq!(*ptr.cast::<u64>().offset(i), 0);
            }
            std::ptr::write_bytes(ptr, 0xFE, memory.data_size(&store));
        }
    }

    Ok(())
}
fn test_touch_set_date5() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_date";

    ucmd.args(&["-d", "1970-01-01 18:43:33.023456789", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    // Slightly different result on Windows for nano seconds
    // TODO: investigate
    #[cfg(windows)]
    let expected = FileTime::from_unix_time(67413, 23_456_700);
    #[cfg(not(windows))]
    let expected = FileTime::from_unix_time(67413, 23_456_789);

    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime, expected);
    assert_eq!(mtime, expected);
}
fn test_dircolors_for_dir_as_file() {
    let result = new_ucmd!().args(&["-c", "/"]).fails();
    result.no_stdout();
    assert_eq!(
        result.stderr_str().trim(),
        "dircolors: expected file, got directory '/'",
    );
}
fn test_new_xml_decl_standalone() {
    let mut writer = Writer::new(Vec::new());
    writer
        .write_event(Decl(BytesDecl::new("1.2", None, Some("yo"))))
        .expect("writing xml decl should succeed");

    let result = writer.into_inner();
    assert_eq!(
        String::from_utf8(result).expect("utf-8 output"),
        "<?xml version=\"1.2\" standalone=\"yo\"?>",
        "writer output (LHS)"
    );
}
fn test_touch_set_cymdhms_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_cymdhms_time";

    ucmd.args(&["-t", "201501011234.56", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M.%S", "201501010000.00");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);
}
fn does_organize_imports_of_included_files() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "formatter": { "enabled": false },
  "linter": { "enabled": false },
   "files": { "ignore": ["test2.js", "test.js"] }, "organizeImports": { "include": ["test.js"] }
}
"#,
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNORGANIZED.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNORGANIZED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNORGANIZED);

    drop(file);

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, ORGANIZED);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_organize_imports_of_included_files",
        fs,
        console,
        result,
    ));
}
fn lex_extends_tag() {
    assert!(TeraParser::parse(Rule::extends_tag, "{% extends \"index.html\" %}").is_ok());
}
fn test_template_removal() {
    let mut env = Environment::new();
    env.add_template("test", "{{ a }}").unwrap();
    env.remove_template("test");
    assert!(env.get_template("test").is_err());
}
fn multi_memory_with_imported_memories() -> Result<()> {
    // This test checks that the base address for the defined memory is correct for the instance
    // despite the presence of an imported memory.

    let mut pool = crate::small_pool_config();
    pool.total_memories(2).max_memories_per_module(2);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    config.wasm_multi_memory(true);

    let engine = Engine::new(&config)?;
    let module = Module::new(
        &engine,
        r#"(module (import "" "m1" (memory 0)) (memory (export "m2") 1))"#,
    )?;

    let mut store = Store::new(&engine, ());

    let m1 = Memory::new(&mut store, MemoryType::new(0, None))?;
    let instance = Instance::new(&mut store, &module, &[m1.into()])?;

    let m2 = instance.get_memory(&mut store, "m2").unwrap();

    m2.data_mut(&mut store)[0] = 0x42;
    assert_eq!(m2.data(&store)[0], 0x42);

    Ok(())
}
fn test_integer128_key() {
    let map = treemap! {
        100000000000000000000000000000000000000u128 => (),
    };
    let j = r#"{"100000000000000000000000000000000000000":null}"#;
    assert_eq!(to_string(&map).unwrap(), j);
    assert_eq!(from_str::<BTreeMap<u128, ()>>(j).unwrap(), map);
}
fn lit() {
    let stream = "/// doc".parse::<TokenStream>().unwrap();
    let lit = lit_of_outer_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\" doc\"");

    let stream = "//! doc".parse::<TokenStream>().unwrap();
    let lit = lit_of_inner_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\" doc\"");

    let stream = "/** doc */".parse::<TokenStream>().unwrap();
    let lit = lit_of_outer_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\" doc \"");

    let stream = "/*! doc */".parse::<TokenStream>().unwrap();
    let lit = lit_of_inner_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\" doc \"");
}
fn f64_roundtrip_test() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let options = Options::builder().build().unwrap();
    for &float in F64_DATA.iter() {
        let count = unsafe { compact::write_float::<_, DECIMAL>(float, &mut buffer, &options) };
        let actual = unsafe { std::str::from_utf8_unchecked(&buffer[..count]) };
        let roundtrip = actual.parse::<f64>();
        assert_eq!(roundtrip, Ok(float));
    }
}
fn test_sequence_ex2() {
    let file = include_str!("preserve_sequence_ex2.ron");
    assert_eq!(read_original(file), make_roundtrip(file));
}
fn fast_log10_test() {
    // Check the first, even if illogical case works.
    assert_eq!(decimal::fast_log10(0u32), 0);
    assert_eq!(decimal::fast_log10(10u32), 0);
    assert_eq!(decimal::fast_log10(15u32), 0);
    assert_eq!(decimal::fast_log10(20u32), 1);
    assert_eq!(decimal::fast_log10(100u32), 1);
    assert_eq!(decimal::fast_log10(200u32), 2);
}
fn ci_parse_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), PARSE_ERROR.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_parse_error",
        fs,
        console,
        result,
    ));
}
fn string() {
    let normal = "\"String\"";
    assert_eq!(normal.parse(), Ok(Value::String("String".into())));

    let raw = "r\"Raw String\"";
    assert_eq!(raw.parse(), Ok(Value::String("Raw String".into())));

    let raw_hashes = "r#\"Raw String\"#";
    assert_eq!(raw_hashes.parse(), Ok(Value::String("Raw String".into())));

    let raw_escaped = "r##\"Contains \"#\"##";
    assert_eq!(
        raw_escaped.parse(),
        Ok(Value::String("Contains \"#".into()))
    );

    let raw_multi_line = "r\"Multi\nLine\"";
    assert_eq!(
        raw_multi_line.parse(),
        Ok(Value::String("Multi\nLine".into()))
    );
}
fn parse_insert_values() {
    let row = vec![
        Expr::Value(number("1")),
        Expr::Value(number("2")),
        Expr::Value(number("3")),
    ];
    let rows1 = vec![row.clone()];
    let rows2 = vec![row.clone(), row];

    let sql = "INSERT customer VALUES (1, 2, 3)";
    check_one(sql, "customer", &[], &rows1);

    let sql = "INSERT INTO customer VALUES (1, 2, 3)";
    check_one(sql, "customer", &[], &rows1);

    let sql = "INSERT INTO customer VALUES (1, 2, 3), (1, 2, 3)";
    check_one(sql, "customer", &[], &rows2);

    let sql = "INSERT INTO public.customer VALUES (1, 2, 3)";
    check_one(sql, "public.customer", &[], &rows1);

    let sql = "INSERT INTO db.public.customer VALUES (1, 2, 3)";
    check_one(sql, "db.public.customer", &[], &rows1);

    let sql = "INSERT INTO public.customer (id, name, active) VALUES (1, 2, 3)";
    check_one(
        sql,
        "public.customer",
        &["id".to_string(), "name".to_string(), "active".to_string()],
        &rows1,
    );

    fn check_one(
        sql: &str,
        expected_table_name: &str,
        expected_columns: &[String],
        expected_rows: &[Vec<Expr>],
    ) {
        match verified_stmt(sql) {
            Statement::Insert {
                table_name,
                columns,
                source,
                ..
            } => {
                assert_eq!(table_name.to_string(), expected_table_name);
                assert_eq!(columns.len(), expected_columns.len());
                for (index, column) in columns.iter().enumerate() {
                    assert_eq!(column, &Ident::new(expected_columns[index].clone()));
                }
                match &*source.body {
                    SetExpr::Values(Values { rows, .. }) => {
                        assert_eq!(rows.as_slice(), expected_rows)
                    }
                    _ => unreachable!(),
                }
            }
            _ => unreachable!(),
        }
    }

    verified_stmt("INSERT INTO customer WITH foo AS (SELECT 1) SELECT * FROM foo UNION VALUES (1)");
}
fn preserve_data_segments() -> Result<()> {
    let mut pool = crate::small_pool_config();
    pool.total_memories(2);
    let mut config = Config::new();
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));
    let engine = Engine::new(&config)?;
    let m = Module::new(
        &engine,
        r#"
            (module
                (memory (export "mem") 1 1)
                (data (i32.const 0) "foo"))
        "#,
    )?;
    let mut store = Store::new(&engine, ());
    let i = Instance::new(&mut store, &m, &[])?;

    // Drop the module. This should *not* drop the actual data referenced by the
    // module.
    drop(m);

    // Spray some stuff on the heap. If wasm data lived on the heap this should
    // paper over things and help us catch use-after-free here if it would
    // otherwise happen.
    if !cfg!(miri) {
        let mut strings = Vec::new();
        for _ in 0..1000 {
            let mut string = String::new();
            for _ in 0..1000 {
                string.push('g');
            }
            strings.push(string);
        }
        drop(strings);
    }

    let mem = i.get_memory(&mut store, "mem").unwrap();

    // Hopefully it's still `foo`!
    assert!(mem.data(&store).starts_with(b"foo"));

    Ok(())
}
fn parse_create_table_auto_increment() {
    let sql = "CREATE TABLE foo (bar INT PRIMARY KEY AUTOINCREMENT)";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::CreateTable { name, columns, .. } => {
            assert_eq!(name.to_string(), "foo");
            assert_eq!(
                vec![ColumnDef {
                    name: "bar".into(),
                    data_type: DataType::Int(None),
                    collation: None,
                    options: vec![
                        ColumnOptionDef {
                            name: None,
                            option: ColumnOption::Unique { is_primary: true },
                        },
                        ColumnOptionDef {
                            name: None,
                            option: ColumnOption::DialectSpecific(vec![Token::make_keyword(
                                "AUTOINCREMENT"
                            )]),
                        },
                    ],
                }],
                columns
            );
        }
        _ => unreachable!(),
    }
}
fn test_new_xml_decl_version() {
    let mut writer = Writer::new(Vec::new());
    writer
        .write_event(Decl(BytesDecl::new("1.2", None, None)))
        .expect("writing xml decl should succeed");

    let result = writer.into_inner();
    assert_eq!(
        String::from_utf8(result).expect("utf-8 output"),
        "<?xml version=\"1.2\"?>",
        "writer output (LHS)"
    );
}
fn absolute_path() {
    let f = super::fixture();
    let resolver = Resolver::new(ResolveOptions {
        alias: vec![(f.join("foo").to_str().unwrap().to_string(), vec![AliasValue::Ignore])],
        modules: vec![f.clone().to_str().unwrap().to_string()],
        ..ResolveOptions::default()
    });
    let resolution = resolver.resolve(&f, "foo/index");
    assert_eq!(resolution, Err(ResolveError::Ignored(f.join("foo"))));
}
fn test_split_str_prefixed_chunks_by_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_str_prefixed_chunks_by_bytes";
    RandomFile::new(&at, name).add_bytes(10000);
    // Important that this is less than 1024 since that's our internal buffer
    // size. Good to test that we don't overshoot.
    ucmd.args(&["-b", "1000", name, "b"]).succeeds();

    let glob = Glob::new(&at, ".", r"b[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 10);
    for filename in glob.collect() {
        assert_eq!(glob.directory.metadata(&filename).len(), 1000);
    }
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn issue_22() {
    let mut x = Router::new();
    x.insert("/foo_bar", "Welcome!").unwrap();
    x.insert("/foo/bar", "Welcome!").unwrap();
    assert_eq!(x.at("/foo/").unwrap_err(), MatchError::NotFound);

    let mut x = Router::new();
    x.insert("/foo", "Welcome!").unwrap();
    x.insert("/foo/bar", "Welcome!").unwrap();
    assert_eq!(x.at("/foo/").unwrap_err(), MatchError::ExtraTrailingSlash);
}
fn test_symlink_circular() {
    let (at, mut ucmd) = at_and_ucmd!();
    let link = "test_symlink_circular";

    ucmd.args(&["-s", link]).succeeds().no_stderr();
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), link);
}
fn parse_variable_tag_array_lit_with_filter() {
    let ast = parse("{{ [1, 2, 3] | length }}").unwrap();
    let mut join_args = HashMap::new();
    join_args.insert("n".to_string(), Expr::new(ExprVal::Int(2)));

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::with_filters(
                ExprVal::Array(vec![
                    Expr::new(ExprVal::Int(1)),
                    Expr::new(ExprVal::Int(2)),
                    Expr::new(ExprVal::Int(3))
                ]),
                vec![FunctionCall { name: "length".to_string(), args: HashMap::new() },],
            )
        )
    );
}
fn rage_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("rage"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "rage_help",
        fs,
        console,
        result,
    ));
}
fn database_lock() {
    let tmpfile = create_tempfile();
    let result = Database::create(tmpfile.path());
    assert!(result.is_ok());
    let result2 = Database::open(tmpfile.path());
    assert!(
        matches!(result2, Err(DatabaseError::DatabaseAlreadyOpen)),
        "{result2:?}",
    );
    drop(result);
    let result = Database::open(tmpfile.path());
    assert!(result.is_ok());
}
async fn recv_trailers_only() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        // Write GET /
        .write(&[
            0, 0, 0x10, 1, 5, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,
            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84,
        ])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[
            0, 0, 1, 1, 4, 0, 0, 0, 1, 0x88, 0, 0, 9, 1, 5, 0, 0, 0, 1, 0x40, 0x84, 0x42, 0x46,
            0x9B, 0x51, 0x82, 0x3F, 0x5F,
        ])
        .build();

    let (mut client, mut h2) = client::handshake(mock).await.unwrap();

    // Send the request
    let request = Request::builder()
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, _) = client.send_request(request, true).unwrap();

    let response = h2.run(response).await.unwrap();
    assert_eq!(response.status(), StatusCode::OK);

    let (_, mut body) = response.into_parts();

    // Make sure there is no body
    let chunk = h2.run(Box::pin(body.next())).await;
    assert!(chunk.is_none());

    let trailers = h2
        .run(poll_fn(|cx| body.poll_trailers(cx)))
        .await
        .unwrap()
        .unwrap();
    assert_eq!(1, trailers.len());
    assert_eq!(trailers["status"], "ok");

    h2.await.unwrap();
}
fn test_pooling_allocator_initial_limits_exceeded() -> Result<()> {
    let mut pool = crate::small_pool_config();
    pool.total_memories(2)
        .max_memories_per_module(2)
        .memory_pages(5);
    let mut config = Config::new();
    config.wasm_multi_memory(true);
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));

    let engine = Engine::new(&config)?;
    let module = Module::new(
        &engine,
        r#"(module (memory (export "m1") 2) (memory (export "m2") 5))"#,
    )?;

    let mut store = Store::new(
        &engine,
        StoreLimitsBuilder::new()
            .memory_size(3 * WASM_PAGE_SIZE)
            .build(),
    );
    store.limiter(|s| s as &mut dyn ResourceLimiter);

    match Instance::new(&mut store, &module, &[]) {
        Ok(_) => unreachable!(),
        Err(e) => assert_eq!(
            e.to_string(),
            "memory minimum size of 5 pages exceeds memory limits"
        ),
    }

    // An instance should still be able to be created after the failure above
    let module = Module::new(&engine, r#"(module (memory (export "m") 2))"#)?;

    Instance::new(&mut store, &module, &[])?;

    Ok(())
}
fn test_writer() -> Result<()> {
    let txt = include_str!("../tests/documents/test_writer.xml").trim();
    let mut reader = Reader::from_str(txt);
    reader.trim_text(true);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(result, txt.as_bytes());
    Ok(())
}
fn should_not_format_json_files_if_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let biome_json = Path::new("biome.json");
    fs.insert(
        biome_json.into(),
        r#"{
        "formatter": {
            "indentStyle": "space"
        },
        "javascript": {
            "formatter": {
                "lineWidth": 80,
                "indentSize": 4
            }
        },
        "json": {
            "formatter": {
                "enabled": false
            }
        }
    }"#,
    );

    let json_file_content = r#"
{
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let json_file = Path::new("input.json");
    fs.insert(json_file.into(), json_file_content.as_bytes());

    let js_file_content = r#"
const a = {
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let js_file = Path::new("input.js");
    fs.insert(js_file.into(), js_file_content.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                "--write",
                json_file.as_os_str().to_str().unwrap(),
                js_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(json_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, json_file_content);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_not_format_json_files_if_disabled",
        fs,
        console,
        result,
    ));
}
fn format_with_configuration() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_FORMAT.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), CUSTOM_FORMAT_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("file.js"), ("--write")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, CUSTOM_FORMAT_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_with_configuration",
        fs,
        console,
        result,
    ));
}
fn format_stdin_successfully() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    console
        .in_buffer
        .push("function f() {return{}}".to_string());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--stdin-file-path"), ("mock.js")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let message = console
        .out_buffer
        .get(0)
        .expect("Console should have written a message");

    let content = markup_to_string(markup! {
        {message.content}
    });

    assert_eq!(content, "function f() {\n\treturn {};\n}\n");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_stdin_successfully",
        fs,
        console,
        result,
    ));
}
async fn call_wrapped_async_func() -> Result<(), Error> {
    let mut config = Config::new();
    config.async_support(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, State::default());
    store.call_hook(State::call_hook);
    let f = Func::wrap4_async(
        &mut store,
        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {
            Box::new(async move {
                // Calling this func will switch context into wasm, then back to host:
                assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);

                assert_eq!(
                    caller.data().calls_into_host,
                    caller.data().returns_from_host + 1
                );
                assert_eq!(
                    caller.data().calls_into_wasm,
                    caller.data().returns_from_wasm + 1
                );

                assert_eq!(a, 1);
                assert_eq!(b, 2);
                assert_eq!(c, 3.0);
                assert_eq!(d, 4.0);
            })
        },
    );

    f.call_async(
        &mut store,
        &[Val::I32(1), Val::I64(2), 3.0f32.into(), 4.0f64.into()],
        &mut [],
    )
    .await?;

    // One switch from vm to host to call f, another in return from f.
    assert_eq!(store.data().calls_into_host, 1);
    assert_eq!(store.data().returns_from_host, 1);
    assert_eq!(store.data().calls_into_wasm, 1);
    assert_eq!(store.data().returns_from_wasm, 1);

    f.typed::<(i32, i64, f32, f64), ()>(&store)?
        .call_async(&mut store, (1, 2, 3.0, 4.0))
        .await?;

    assert_eq!(store.data().calls_into_host, 2);
    assert_eq!(store.data().returns_from_host, 2);
    assert_eq!(store.data().calls_into_wasm, 2);
    assert_eq!(store.data().returns_from_wasm, 2);

    Ok(())
}
fn right_variable_name_is_needed_in_for_loop() {
    let mut data = HashMap::new();
    data.insert("content", "hello");
    let mut context = Context::new();
    context.insert("comments", &vec![data]);
    let mut tera = Tera::default();
    tera.add_raw_template(
        "tpl",
        r#"
{%- for comment in comments -%}
<p>{{ comment.content }}</p>
<p>{{ whocares.content }}</p>
<p>{{ doesntmatter.content }}</p>
{% endfor -%}"#,
    )
    .unwrap();
    let result = tera.render("tpl", &context);

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Variable `whocares.content` not found in context while rendering \'tpl\'"
    );
}
fn test_trailing_zeros() {
    assert_eq!(26843550.0, s2f(b"26843549.5").unwrap());
    assert_eq!(50000004.0, s2f(b"50000002.5").unwrap());
    assert_eq!(99999992.0, s2f(b"99999989.5").unwrap());
}
fn buffered_client_data_sent() {
    let server_config = Arc::new(make_server_config(KeyType::Rsa));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);

        assert_eq!(5, client.writer().write(b"hello").unwrap());

        do_handshake(&mut client, &mut server);
        transfer(&mut client, &mut server);
        server.process_new_packets().unwrap();

        check_read(&mut server.reader(), b"hello");
    }
}
fn doesnt_error_if_no_files_were_processed() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), "--no-errors-on-unmatched", ("file.js")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "doesnt_error_if_no_files_were_processed",
        fs,
        console,
        result,
    ));
}
fn test_witness_replica_read() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // make sure the peer_on_store3 has completed applied to witness
    std::thread::sleep(Duration::from_millis(200));

    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cmd(b"k0")],
        false,
    );
    request.mut_header().set_peer(peer_on_store3);
    request.mut_header().set_replica_read(true);

    let resp = cluster
        .read(None, request, Duration::from_millis(100))
        .unwrap();
    assert_eq!(
        resp.get_header().get_error().get_is_witness(),
        &kvproto::errorpb::IsWitness {
            region_id: region.get_id(),
            ..Default::default()
        }
    );
}
fn diff_does_not_show_display_only_fixes_with_unsafe_fixes_enabled() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "B006",
                "--diff",
                "--unsafe-fixes",
            ])
            .pass_stdin("def add_to_list(item, some_list=[]): ..."),
            @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    "###);
}
fn test_double_to_bits() {
    assert_eq!(0, 0.0_f64.to_bits());
    assert_eq!(
        0x400921FB54442D18,
        3.1415926535897932384626433_f64.to_bits(),
    );
}
fn test_json_pointer_mut() {
    // Test case taken from https://tools.ietf.org/html/rfc6901#page-5
    let mut data: Value = from_str(
        r#"{
        "foo": ["bar", "baz"],
        "": 0,
        "a/b": 1,
        "c%d": 2,
        "e^f": 3,
        "g|h": 4,
        "i\\j": 5,
        "k\"l": 6,
        " ": 7,
        "m~n": 8
    }"#,
    )
    .unwrap();

    // Basic pointer checks
    assert_eq!(data.pointer_mut("/foo").unwrap(), &json!(["bar", "baz"]));
    assert_eq!(data.pointer_mut("/foo/0").unwrap(), &json!("bar"));
    assert_eq!(data.pointer_mut("/").unwrap(), 0);
    assert_eq!(data.pointer_mut("/a~1b").unwrap(), 1);
    assert_eq!(data.pointer_mut("/c%d").unwrap(), 2);
    assert_eq!(data.pointer_mut("/e^f").unwrap(), 3);
    assert_eq!(data.pointer_mut("/g|h").unwrap(), 4);
    assert_eq!(data.pointer_mut("/i\\j").unwrap(), 5);
    assert_eq!(data.pointer_mut("/k\"l").unwrap(), 6);
    assert_eq!(data.pointer_mut("/ ").unwrap(), 7);
    assert_eq!(data.pointer_mut("/m~0n").unwrap(), 8);

    // Invalid pointers
    assert!(data.pointer_mut("/unknown").is_none());
    assert!(data.pointer_mut("/e^f/ertz").is_none());
    assert!(data.pointer_mut("/foo/00").is_none());
    assert!(data.pointer_mut("/foo/01").is_none());

    // Mutable pointer checks
    *data.pointer_mut("/").unwrap() = 100.into();
    assert_eq!(data.pointer("/").unwrap(), 100);
    *data.pointer_mut("/foo/0").unwrap() = json!("buzz");
    assert_eq!(data.pointer("/foo/0").unwrap(), &json!("buzz"));

    // Example of ownership stealing
    assert_eq!(
        data.pointer_mut("/a~1b")
            .map(|m| mem::replace(m, json!(null)))
            .unwrap(),
        1
    );
    assert_eq!(data.pointer("/a~1b").unwrap(), &json!(null));

    // Need to compare against a clone so we don't anger the borrow checker
    // by taking out two references to a mutable value
    let mut d2 = data.clone();
    assert_eq!(data.pointer_mut("").unwrap(), &mut d2);
}
fn test_turnoff_titan() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.rocksdb.defaultcf.disable_auto_compactions = true;
    cluster.cfg.rocksdb.defaultcf.num_levels = 1;
    configure_for_enable_titan(&mut cluster, ReadableSize::kb(0));
    cluster.run();
    assert_eq!(cluster.must_get(b"k1"), None);

    let size = 5;
    for i in 0..size {
        cluster
            .put(
                format!("k{:02}0", i).as_bytes(),
                format!("v{}", i).as_bytes(),
            )
            .unwrap();
    }
    cluster.must_flush_cf(CF_DEFAULT, true);
    for i in 0..size {
        cluster
            .put(
                format!("k{:02}1", i).as_bytes(),
                format!("v{}", i).as_bytes(),
            )
            .unwrap();
    }
    cluster.must_flush_cf(CF_DEFAULT, true);
    for i in cluster.get_node_ids().into_iter() {
        let engine = cluster.get_engine(i);
        let db = engine.as_inner();
        assert_eq!(
            db.get_property_int("rocksdb.num-files-at-level0").unwrap(),
            2
        );
        assert_eq!(
            db.get_property_int("rocksdb.num-files-at-level1").unwrap(),
            0
        );
        assert_eq!(
            db.get_property_int("rocksdb.titandb.num-live-blob-file")
                .unwrap(),
            2
        );
        assert_eq!(
            db.get_property_int("rocksdb.titandb.num-obsolete-blob-file")
                .unwrap(),
            0
        );
    }
    cluster.shutdown();

    // try reopen db when titan isn't properly turned off.
    configure_for_disable_titan(&mut cluster);
    cluster.pre_start_check().unwrap_err();

    configure_for_enable_titan(&mut cluster, ReadableSize::kb(0));
    cluster.pre_start_check().unwrap();
    cluster.start().unwrap();
    assert_eq!(cluster.must_get(b"k1"), None);
    for i in cluster.get_node_ids().into_iter() {
        let db = cluster.get_engine(i);
        let opt = vec![("blob_run_mode", "kFallback")];
        db.set_options_cf(CF_DEFAULT, &opt).unwrap();
    }
    cluster.compact_data();
    let mut all_check_pass = true;
    for _ in 0..10 {
        // wait for gc completes.
        sleep_ms(10);
        all_check_pass = true;
        for i in cluster.get_node_ids().into_iter() {
            let engine = cluster.get_engine(i);
            let db = engine.as_inner();
            if db.get_property_int("rocksdb.num-files-at-level0").unwrap() != 0 {
                all_check_pass = false;
                break;
            }
            if db.get_property_int("rocksdb.num-files-at-level1").unwrap() != 1 {
                all_check_pass = false;
                break;
            }
            if db
                .get_property_int("rocksdb.titandb.num-live-blob-file")
                .unwrap()
                != 0
            {
                all_check_pass = false;
                break;
            }
        }
        if all_check_pass {
            break;
        }
    }
    if !all_check_pass {
        panic!("unexpected titan gc results");
    }
    cluster.shutdown();

    configure_for_disable_titan(&mut cluster);
    // wait till files are purged, timeout set to purge_obsolete_files_period.
    for _ in 1..100 {
        sleep_ms(10);
        if cluster.pre_start_check().is_ok() {
            return;
        }
    }
    cluster.pre_start_check().unwrap();
}
fn test_witness_raftlog_gc_after_reboot() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(50);
    cluster
        .cfg
        .raft_store
        .request_voter_replicated_index_interval = ReadableDuration::millis(100);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(200));
    let mut before_states = HashMap::default();
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        before_states.insert(id, state.take_truncated_state());
    }

    // one follower is down
    cluster.stop_node(nodes[1]);

    // write some data to make log gap exceeds the gc limit
    for i in 1..1000 {
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
    }

    // the witness truncated index is not advanced
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        if id == 2 {
            assert_eq!(
                state.get_truncated_state().get_index() - before_states[&id].get_index(),
                0
            );
        } else {
            assert_ne!(
                900,
                state.get_truncated_state().get_index() - before_states[&id].get_index()
            );
        }
    }

    fail::cfg("on_raft_gc_log_tick", "return").unwrap();

    // the follower is back online
    cluster.run_node(nodes[1]).unwrap();
    cluster.must_put(b"k00", b"v00");
    must_get_equal(&cluster.get_engine(nodes[1]), b"k00", b"v00");

    // the witness is down
    cluster.stop_node(nodes[2]);
    std::thread::sleep(Duration::from_millis(100));
    // the witness is back online
    cluster.run_node(nodes[2]).unwrap();

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(300));

    // the truncated index is advanced now, as all the peers has replicated
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        assert_ne!(
            900,
            state.get_truncated_state().get_index() - before_states[&id].get_index()
        );
    }
    fail::remove("on_raft_gc_log_tick");
}
fn test_batch() {
    let (control_tx, control_fsm) = Runner::new(10);
    let (router, mut system) =
        batch_system::create_system(&Config::default(), control_tx, control_fsm, None);
    let builder = Builder::new();
    let metrics = builder.metrics.clone();
    system.spawn("test".to_owned(), builder);
    let mut expected_metrics = HandleMetrics::default();
    assert_eq!(*metrics.lock().unwrap(), expected_metrics);
    let (tx, rx) = mpsc::unbounded();
    let tx_ = tx.clone();
    let r = router.clone();
    router
        .send_control(Message::Callback(Box::new(
            move |_: &Handler, _: &mut Runner| {
                let (tx, runner) = Runner::new(10);
                let mailbox = BasicMailbox::new(tx, runner, Arc::default());
                r.register(1, mailbox);
                tx_.send(1).unwrap();
            },
        )))
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(1));
    // sleep to wait Batch-System to finish calling end().
    sleep(Duration::from_millis(20));
    router
        .send(
            1,
            Message::Callback(Box::new(move |_: &Handler, _: &mut Runner| {
                tx.send(2).unwrap();
            })),
        )
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(2));
    system.shutdown();
    expected_metrics.control = 1;
    expected_metrics.normal = 1;
    expected_metrics.begin = 2;
    assert_eq!(*metrics.lock().unwrap(), expected_metrics);
}
fn test_log10_pow2() {
    assert_eq!(0, log10_pow2(0));
    assert_eq!(0, log10_pow2(1));
    assert_eq!(0, log10_pow2(2));
    assert_eq!(0, log10_pow2(3));
    assert_eq!(1, log10_pow2(4));
    assert_eq!(496, log10_pow2(1650));
}
fn parse_select_with_date_column_name() {
    let sql = "SELECT date";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Identifier(Ident {
            value: "date".into(),
            quote_style: None,
        }),
        expr_from_projection(only(&select.projection)),
    );
}
fn errors_with_inheritance_in_included_template() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("base", "Base - {% include \"child\" %}"),
        ("parent", "{% block title %}Parent{% endblock %}"),
        ("child", "{% extends \"parent\" %}{% block title %}{{ super() }} - Child{% endblock %}"),
    ])
    .unwrap();

    let result = tera.render("base", &Context::new());

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Inheritance in included templates is currently not supported: extended `parent`"
    );
}
fn test_something() {
    let data = [];
    let config = general_purpose::GeneralPurposeConfig::new()
        .with_encode_padding(false)
        .with_decode_padding_mode(engine::DecodePaddingMode::RequireNone);
    let engine = general_purpose::GeneralPurpose::new(&base64::alphabet::STANDARD, config);
    let encoded = engine.encode(data);
    let decoded = engine.decode(&encoded).unwrap();
    assert_eq!(data, decoded.as_slice());
}
fn fix_applies_unsafe_fixes_with_opt_in() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601,UP034",
                "--fix",
                "--unsafe-fixes",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    x = {'a': 1}
    print('foo')

    ----- stderr -----
    Found 2 errors (2 fixed, 0 remaining).
    "###);
}
fn parse_collate() {
    let sql = "SELECT name COLLATE \"de_DE\" FROM customer";
    assert_matches!(
        only(&all_dialects().verified_only_select(sql).projection),
        SelectItem::UnnamedExpr(Expr::Collate { .. })
    );
}
fn test_periodical_update() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(LeaderChange::new()));
    let eps = server.bind_addrs();

    let counter = Arc::new(AtomicUsize::new(0));
    let client = new_client_with_update_interval(eps, None, ReadableDuration::secs(3));
    let counter1 = Arc::clone(&counter);
    client.handle_reconnect(move || {
        counter1.fetch_add(1, Ordering::SeqCst);
    });
    let leader = client.get_leader();

    for _ in 0..5 {
        let new = client.get_leader();
        if new != leader {
            assert!(counter.load(Ordering::SeqCst) >= 1);
            return;
        }
        thread::sleep(LeaderChange::get_leader_interval());
    }

    panic!("failed, leader should changed");
}
fn trailing_comma_parse_errors() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--trailing-comma"), ("NONE"), ("file.js")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "trailing_comma_parse_errors",
        fs,
        console,
        result,
    ));
}
fn test_write_to_self() {
    let s = TestScenario::new(util_name!());
    let file_path = s.fixtures.plus("first_file");
    s.fixtures.write("second_file", "second_file_content.");

    let file = OpenOptions::new()
        .create_new(true)
        .write(true)
        .append(true)
        .open(file_path)
        .unwrap();

    s.fixtures.append("first_file", "first_file_content.");

    s.ucmd()
        .set_stdout(file)
        .arg("first_file")
        .arg("first_file")
        .arg("second_file")
        .fails()
        .code_is(2)
        .stderr_only("cat: first_file: input file is output file\ncat: first_file: input file is output file\n");

    assert_eq!(
        s.fixtures.read("first_file"),
        "first_file_content.second_file_content."
    );
}
fn test_read_index_stale_in_suspect_lease() {
    let mut cluster = new_node_cluster(0, 3);

    // Increase the election tick to make this test case running reliably.
    configure_for_lease_read(&mut cluster.cfg, Some(50), Some(10_000));
    let max_lease = Duration::from_secs(2);
    // Stop log compaction to transfer leader with filter easier.
    configure_for_request_snapshot(&mut cluster);
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration(max_lease);

    cluster.pd_client.disable_default_operator();
    let r1 = cluster.run_conf_change();
    cluster.pd_client.must_add_peer(r1, new_peer(2, 2));
    cluster.pd_client.must_add_peer(r1, new_peer(3, 3));

    let r1 = cluster.get_region(b"k1");
    // Put and test again to ensure that peer 3 get the latest writes by message
    // append instead of snapshot, so that transfer leader to peer 3 can 100%
    // success.
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(3), b"k2", b"v2");
    // Ensure peer 3 is ready to become leader.
    let resp_ch = async_read_on_peer(&mut cluster, new_peer(3, 3), r1.clone(), b"k2", true, true);
    let resp = block_on_timeout(resp_ch, Duration::from_secs(3)).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    assert_eq!(
        resp.get_responses()[0].get_get().get_value(),
        b"v2",
        "{:?}",
        resp
    );
    let old_leader = cluster.leader_of_region(r1.get_id()).unwrap();

    // Use a macro instead of a closure to avoid any capture of local variables.
    macro_rules! read_on_old_leader {
        () => {{
            let (tx, rx) = mpsc::sync_channel(1);
            let mut read_request = new_request(
                r1.get_id(),
                r1.get_region_epoch().clone(),
                vec![new_get_cmd(b"k1")],
                true, // read quorum
            );
            read_request.mut_header().set_peer(new_peer(1, 1));
            let sim = cluster.sim.wl();
            sim.async_command_on_node(
                old_leader.get_id(),
                read_request,
                Callback::read(Box::new(move |resp| tx.send(resp.response).unwrap())),
            )
            .unwrap();
            rx
        }};
    }

    // Delay all raft messages to peer 1.
    let dropped_msgs = Arc::new(Mutex::new(Vec::new()));
    let filter = Box::new(
        RegionPacketFilter::new(r1.id, old_leader.store_id)
            .direction(Direction::Recv)
            .skip(MessageType::MsgTransferLeader)
            .reserve_dropped(Arc::clone(&dropped_msgs)),
    );
    cluster
        .sim
        .wl()
        .add_recv_filter(old_leader.get_id(), filter);

    let resp1 = read_on_old_leader!();

    cluster.must_transfer_leader(r1.get_id(), new_peer(3, 3));

    let resp2 = read_on_old_leader!();

    // Unpark all pending messages and clear all filters.
    let router = cluster.sim.wl().get_router(old_leader.get_id()).unwrap();
    'LOOP: loop {
        for raft_msg in mem::take::<Vec<_>>(dropped_msgs.lock().unwrap().as_mut()) {
            let msg_type = raft_msg.get_message().get_msg_type();
            if msg_type == MessageType::MsgHeartbeatResponse {
                router.send_raft_message(raft_msg).unwrap();
                continue;
            }
            cluster.sim.wl().clear_recv_filters(old_leader.get_id());
            break 'LOOP;
        }
    }

    let resp1 = resp1.recv().unwrap();
    assert!(
        resp1.get_header().get_error().has_stale_command()
            || resp1.get_responses()[0].get_get().get_value() == b"v1"
    );

    // Response 2 should contains an error.
    let resp2 = resp2.recv().unwrap();
    assert!(resp2.get_header().get_error().has_stale_command());
    drop(cluster);
}
fn test_scheduler_pool_auto_switch_for_resource_ctl() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();

    let engine = cluster
        .sim
        .read()
        .unwrap()
        .storages
        .get(&1)
        .unwrap()
        .clone();
    let resource_manager = ResourceGroupManager::default();
    let resource_ctl = resource_manager.derive_controller("test".to_string(), true);

    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .config(cluster.cfg.tikv.storage.clone())
        .build_for_resource_controller(resource_ctl)
        .unwrap();

    let region = cluster.get_region(b"k1");
    let mut ctx = Context::default();
    ctx.set_region_id(region.id);
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(cluster.leader_of_region(region.id).unwrap());

    let do_prewrite = |key: &[u8], val: &[u8]| {
        // prewrite
        let (prewrite_tx, prewrite_rx) = channel();
        storage
            .sched_txn_command(
                commands::Prewrite::new(
                    vec![Mutation::make_put(Key::from_raw(key), val.to_vec())],
                    key.to_vec(),
                    10.into(),
                    100,
                    false,
                    2,
                    TimeStamp::default(),
                    TimeStamp::default(),
                    None,
                    false,
                    AssertionLevel::Off,
                    ctx.clone(),
                ),
                Box::new(move |res: storage::Result<_>| {
                    let _ = prewrite_tx.send(res);
                }),
            )
            .unwrap();
        prewrite_rx.recv_timeout(Duration::from_secs(2))
    };

    let (sender, receiver) = channel();
    let priority_queue_sender = Mutex::new(sender.clone());
    let single_queue_sender = Mutex::new(sender);
    fail::cfg_callback("priority_pool_task", move || {
        let sender = priority_queue_sender.lock().unwrap();
        sender.send("priority_queue").unwrap();
    })
    .unwrap();
    fail::cfg_callback("single_queue_pool_task", move || {
        let sender = single_queue_sender.lock().unwrap();
        sender.send("single_queue").unwrap();
    })
    .unwrap();

    // Default is use single queue
    assert_eq!(do_prewrite(b"k1", b"v1").is_ok(), true);
    assert_eq!(
        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),
        "single_queue"
    );

    // Add group use priority queue
    use kvproto::resource_manager::{GroupMode, GroupRequestUnitSettings, ResourceGroup};
    let mut group = ResourceGroup::new();
    group.set_name("rg1".to_string());
    group.set_mode(GroupMode::RuMode);
    let mut ru_setting = GroupRequestUnitSettings::new();
    ru_setting.mut_r_u().mut_settings().set_fill_rate(100000);
    group.set_r_u_settings(ru_setting);
    resource_manager.add_resource_group(group);
    thread::sleep(Duration::from_millis(200));
    assert_eq!(do_prewrite(b"k2", b"v2").is_ok(), true);
    assert_eq!(
        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),
        "priority_queue"
    );

    // Delete group use single queue
    resource_manager.remove_resource_group("rg1");
    thread::sleep(Duration::from_millis(200));
    assert_eq!(do_prewrite(b"k3", b"v3").is_ok(), true);
    assert_eq!(
        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),
        "single_queue"
    );

    // Scale pool size
    let scheduler = storage.get_scheduler();
    let pool = scheduler.get_sched_pool();
    assert_eq!(pool.get_pool_size(CommandPri::Normal), 1);
    pool.scale_pool_size(2);
    assert_eq!(pool.get_pool_size(CommandPri::Normal), 2);
}
fn test_unsafe_recovery_already_in_joint_state() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();
    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store2.clone());
    cluster.pd_client.must_add_peer(
        region.get_id(),
        new_learner_peer(nodes[2], peer_on_store2.get_id()),
    );
    // Wait the new learner to be initialized.
    sleep_ms(100);
    pd_client.must_joint_confchange(
        region.get_id(),
        vec![
            (
                ConfChangeType::AddLearnerNode,
                new_learner_peer(nodes[0], peer_on_store0.get_id()),
            ),
            (
                ConfChangeType::AddNode,
                new_peer(nodes[2], peer_on_store2.get_id()),
            ),
        ],
    );
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());

    confirm_quorum_is_lost(&mut cluster, &region);
    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    let to_be_removed: Vec<metapb::Peer> = region
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    let mut demoted = true;
    let mut promoted = false;
    for _ in 0..10 {
        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

        promoted = region
            .get_peers()
            .iter()
            .find(|peer| peer.get_store_id() == nodes[0])
            .unwrap()
            .get_role()
            == metapb::PeerRole::Voter;

        demoted = region
            .get_peers()
            .iter()
            .filter(|peer| peer.get_store_id() != nodes[0])
            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);
        if demoted && promoted {
            break;
        }
        sleep_ms(100);
    }
    assert!(demoted);
    assert!(promoted);
}
fn test_u128_min() {
    assert_eq!(
        std::u128::MIN,
        from_str(&to_string(&std::u128::MIN).unwrap()).unwrap()
    );
}
fn test_skip_gc_by_check() {
    GC_COMPACTION_FILTER_PERFORM.reset();
    GC_COMPACTION_FILTER_SKIP.reset();

    let mut cfg = DbConfig::default();
    cfg.defaultcf.disable_auto_compactions = true;
    cfg.defaultcf.dynamic_level_bytes = false;
    cfg.defaultcf.num_levels = 7;
    let dir = tempfile::TempDir::new().unwrap();
    let builder = TestEngineBuilder::new().path(dir.path());
    let engine = builder
        .api_version(ApiVersion::V2)
        .build_with_cfg(&cfg)
        .unwrap();
    let raw_engine = engine.get_rocksdb();
    let mut gc_runner = TestGcRunner::new(0);

    do_write(&engine, false, 5);
    engine.get_rocksdb().flush_cfs(&[], true).unwrap();

    // The min_mvcc_ts ts > gc safepoint, check_need_gc return false, don't call
    // dofilter
    gc_runner
        .safe_point(TimeStamp::new(1).into_inner())
        .gc_raw(&raw_engine);
    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );

    // TEST 2:When is_bottommost_level = false,
    // write data to level2
    do_write(&engine, false, 5);
    engine.get_rocksdb().flush_cfs(&[], true).unwrap();

    do_gc(&raw_engine, 2, &mut gc_runner, &dir);

    do_write(&engine, false, 5);
    engine.get_rocksdb().flush_cfs(&[], true).unwrap();

    // Set ratio_threshold, let (props.num_versions as f64 > props.num_rows as
    // f64 * ratio_threshold) return false
    gc_runner.ratio_threshold = Option::Some(f64::MAX);

    // is_bottommost_level = false
    do_gc(&raw_engine, 1, &mut gc_runner, &dir);

    assert_eq!(
        GC_COMPACTION_FILTER_PERFORM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        3
    );

    // The check_need_gc return false, GC_COMPACTION_FILTER_SKIP will add 1.
    assert_eq!(
        GC_COMPACTION_FILTER_SKIP
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        2
    );
}
fn correctly_handle_zip_with_garbage_after_comment() {
    let mut v = Vec::new();
    v.extend_from_slice(include_bytes!("../tests/data/comment_garbage.zip"));
    let archive = ZipArchive::new(io::Cursor::new(v)).expect("couldn't open test zip file");

    assert_eq!(archive.comment(), "short.".as_bytes());
}
fn test_trailing_comma_enum_struct_variant() {
    assert!(from_str::<Enum>("Struct(a:1,b:2)").is_ok());
    assert!(from_str::<Enum>("Struct(a:1,b:2,)").is_ok());
    assert!(from_str::<Enum>("Struct(a:1,b:2,,)").is_err());
}
fn test_destroy_source_peer_while_merging() {
    let mut cluster = new_node_cluster(0, 5);
    configure_for_merge(&mut cluster.cfg);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");
    for i in 1..=5 {
        must_get_equal(&cluster.get_engine(i), b"k1", b"v1");
        must_get_equal(&cluster.get_engine(i), b"k3", b"v3");
    }

    cluster.must_split(&pd_client.get_region(b"k1").unwrap(), b"k2");
    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k3").unwrap();
    cluster.must_transfer_leader(right.get_id(), new_peer(1, 1));

    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    // Start merge and wait until peer 5 apply prepare merge
    cluster.must_try_merge(right.get_id(), left.get_id());
    cluster.must_peer_state(right.get_id(), 5, PeerState::Merging);

    // filter heartbeat and append message for peer 5
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(right.get_id(), 5)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgHeartbeat)
            .msg_type(MessageType::MsgAppend),
    ));

    // remove peer from target region to trigger merge rollback.
    pd_client.must_remove_peer(left.get_id(), find_peer(&left, 2).unwrap().clone());
    must_get_none(&cluster.get_engine(2), b"k1");

    // Merge must rollbacked if we can put more data to the source region
    fail::remove(schedule_merge_fp);
    cluster.must_put(b"k4", b"v4");
    for i in 1..=4 {
        must_get_equal(&cluster.get_engine(i), b"k4", b"v4");
    }

    // remove peer 5 from peer list so it will destroy itself by tombstone message
    // and should not persist the `merge_state`
    pd_client.must_remove_peer(right.get_id(), new_peer(5, 5));
    must_get_none(&cluster.get_engine(5), b"k3");

    // so that other peers will send message to store 5
    pd_client.must_add_peer(right.get_id(), new_peer(5, 6));
    // but it is still in tombstone state due to the message filter
    let state = cluster.region_local_state(right.get_id(), 5);
    assert_eq!(state.get_state(), PeerState::Tombstone);

    // let the peer on store 4 have a larger peer id
    pd_client.must_remove_peer(right.get_id(), new_peer(4, 4));
    pd_client.must_add_peer(right.get_id(), new_peer(4, 7));
    must_get_equal(&cluster.get_engine(4), b"k4", b"v4");

    // if store 5 have persist the merge state, peer 2 and peer 3 will be destroyed
    // because store 5 will response their request vote message with a gc
    // message, and peer 7 will cause store 5 panic because peer 7 have larger
    // peer id than the peer in the merge state
    cluster.clear_send_filters();
    cluster.add_send_filter(IsolationFilterFactory::new(1));

    cluster.must_put(b"k5", b"v5");
    assert!(!state.has_merge_state(), "{:?}", state);
    for i in 2..=5 {
        must_get_equal(&cluster.get_engine(i), b"k5", b"v5");
    }
}
fn use_after_drop() -> anyhow::Result<()> {
    let mut store = Store::<()>::default();
    let module = Module::new(
        store.engine(),
        r#"
            (module
                (global (export "foo") (mut i32) (i32.const 100)))
        "#,
    )?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let g = instance.get_global(&mut store, "foo").unwrap();
    assert_eq!(g.get(&mut store).i32(), Some(100));
    g.set(&mut store, 101.into())?;
    assert_eq!(g.get(&mut store).i32(), Some(101));
    Instance::new(&mut store, &module, &[])?;
    assert_eq!(g.get(&mut store).i32(), Some(101));
    drop(module);
    assert_eq!(g.get(&mut store).i32(), Some(101));

    // spray some heap values
    let mut x = Vec::new();
    for _ in 0..100 {
        x.push("xy".to_string());
    }
    drop(x);
    assert_eq!(g.get(&mut store).i32(), Some(101));
    Ok(())
}
fn test_skip_iter_tc() {
    // Test iterators that skip multiple, trailing digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_trailing_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"_45_5");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"__45__5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".45_5");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".45__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"4_5.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4__5.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"_45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"__45.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"_4_5");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"__4__5");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"_4_5.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"__4__5.56");
}
fn treat_known_json_files_as_jsonc_files() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let code = r#"
/*test*/ [

/* some other comment*/1, 2, 3]
    "#;
    let ts = Path::new("files/typescript.json");
    fs.insert(ts.into(), code.as_bytes());
    let eslint = Path::new("files/.eslintrc.json");
    fs.insert(eslint.into(), code.as_bytes());
    let jshint = Path::new("files/.jshintrc");
    fs.insert(jshint.into(), code.as_bytes());
    let babel = Path::new("files/.babelrc");
    fs.insert(babel.into(), code.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ts.as_os_str().to_str().unwrap(),
                eslint.as_os_str().to_str().unwrap(),
                jshint.as_os_str().to_str().unwrap(),
                babel.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "treat_known_json_files_as_jsonc_files",
        fs,
        console,
        result,
    ));
}
fn with_malformed_configuration() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    fs.insert(
        Path::new("biome.json").to_path_buf(),
        r#"{
  "formatter": {
    "enabled":
  }
}"#,
    );

    let result = run_rage(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("rage")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_rage_snapshot(SnapshotPayload::new(
        module_path!(),
        "with_malformed_configuration",
        fs,
        console,
        result,
    ));
}
fn test_bad_input() {
    assert_eq!(Error::MalformedInput, s2d(b"x").unwrap_err());
    assert_eq!(Error::MalformedInput, s2d(b"1..1").unwrap_err());
    assert_eq!(Error::MalformedInput, s2d(b"..").unwrap_err());
    assert_eq!(Error::MalformedInput, s2d(b"1..1").unwrap_err());
    assert_eq!(Error::MalformedInput, s2d(b"1ee1").unwrap_err());
    assert_eq!(Error::MalformedInput, s2d(b"1e.1").unwrap_err());
    assert_eq!(Error::InputTooShort, s2d(b"").unwrap_err());
    assert_eq!(Error::InputTooLong, s2d(b"123456789012345678").unwrap_err());
    assert_eq!(Error::InputTooLong, s2d(b"1e12345").unwrap_err());
}
fn read_isolation2() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    {
        let mut write_table = write_txn.open_table(STR_TABLE).unwrap();
        write_table.remove("hello").unwrap();
        write_table.insert("hello2", "world2").unwrap();
        write_table.insert("hello3", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn2 = db.begin_read().unwrap();
    let table2 = read_txn2.open_table(STR_TABLE).unwrap();
    assert!(table2.get("hello").unwrap().is_none());
    assert_eq!("world2", table2.get("hello2").unwrap().unwrap().value());
    assert_eq!("world3", table2.get("hello3").unwrap().unwrap().value());
    assert_eq!(table2.len().unwrap(), 2);

    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    assert!(table.get("hello2").unwrap().is_none());
    assert!(table.get("hello3").unwrap().is_none());
    assert_eq!(table.len().unwrap(), 1);
}
fn test_unknown_enum_variant() {
    assert_eq!(
        ron::from_str::<TestEnum>("NotAVariant"),
        Err(SpannedError {
            code: Error::NoSuchEnumVariant {
                expected: &["StructVariant", "NewtypeVariant"],
                found: String::from("NotAVariant"),
                outer: Some(String::from("TestEnum")),
            },
            position: Position { line: 1, col: 12 },
        })
    );
}
fn test_parse_4digits() {
    assert_eq!(algorithm::parse_4digits::<{ STANDARD }>(0x31_32_33_34), 4321);
    #[cfg(feature = "radix")]
    assert_eq!(algorithm::parse_4digits::<{ from_radix(5) }>(0x31_32_33_34), 586);
    assert_eq!(algorithm::parse_4digits::<{ STANDARD }>(0x36_37_38_39), 9876);
}
fn f32_decimal_test() {
    // integer test
    assert_eq!(0.0, f32::from_lexical(b"0").unwrap());
    assert_eq!(1.0, f32::from_lexical(b"1").unwrap());
    assert_eq!(12.0, f32::from_lexical(b"12").unwrap());
    assert_eq!(123.0, f32::from_lexical(b"123").unwrap());
    assert_eq!(1234.0, f32::from_lexical(b"1234").unwrap());
    assert_eq!(12345.0, f32::from_lexical(b"12345").unwrap());
    assert_eq!(123456.0, f32::from_lexical(b"123456").unwrap());
    assert_eq!(1234567.0, f32::from_lexical(b"1234567").unwrap());
    assert_eq!(12345678.0, f32::from_lexical(b"12345678").unwrap());

    // No fraction after decimal point test
    assert_eq!(1.0, f32::from_lexical(b"1.").unwrap());
    assert_eq!(12.0, f32::from_lexical(b"12.").unwrap());
    assert_eq!(1234567.0, f32::from_lexical(b"1234567.").unwrap());

    // No integer before decimal point test
    assert_eq!(0.1, f32::from_lexical(b".1").unwrap());
    assert_eq!(0.12, f32::from_lexical(b".12").unwrap());
    assert_eq!(0.1234567, f32::from_lexical(b".1234567").unwrap());

    // decimal test
    assert_eq!(123.1, f32::from_lexical(b"123.1").unwrap());
    assert_eq!(123.12, f32::from_lexical(b"123.12").unwrap());
    assert_eq!(123.123, f32::from_lexical(b"123.123").unwrap());
    assert_eq!(123.1234, f32::from_lexical(b"123.1234").unwrap());
    assert_eq!(123.12345, f32::from_lexical(b"123.12345").unwrap());

    // rounding test
    assert_eq!(123456790.0, f32::from_lexical(b"123456789").unwrap());
    assert_eq!(123456790.0, f32::from_lexical(b"123456789.1").unwrap());
    assert_eq!(123456790.0, f32::from_lexical(b"123456789.12").unwrap());
    assert_eq!(123456790.0, f32::from_lexical(b"123456789.123").unwrap());
    assert_eq!(123456790.0, f32::from_lexical(b"123456789.1234").unwrap());
    assert_eq!(123456790.0, f32::from_lexical(b"123456789.12345").unwrap());

    // exponent test
    assert_eq!(123456789.12345, f32::from_lexical(b"1.2345678912345e8").unwrap());
    assert_eq!(123450000.0, f32::from_lexical(b"1.2345e+8").unwrap());
    assert_eq!(1.2345e+11, f32::from_lexical(b"1.2345e+11").unwrap());
    assert_eq!(1.2345e+11, f32::from_lexical(b"123450000000").unwrap());
    assert_eq!(1.2345e+38, f32::from_lexical(b"1.2345e+38").unwrap());
    assert_eq!(1.2345e+38, f32::from_lexical(b"123450000000000000000000000000000000000").unwrap());
    assert_eq!(1.2345e-8, f32::from_lexical(b"1.2345e-8").unwrap());
    assert_eq!(1.2345e-8, f32::from_lexical(b"0.000000012345").unwrap());
    assert_eq!(1.2345e-38, f32::from_lexical(b"1.2345e-38").unwrap());
    assert_eq!(
        1.2345e-38,
        f32::from_lexical(b"0.000000000000000000000000000000000000012345").unwrap()
    );

    assert!(f32::from_lexical(b"NaN").unwrap().is_nan());
    assert!(f32::from_lexical(b"nan").unwrap().is_nan());
    assert!(f32::from_lexical(b"NAN").unwrap().is_nan());
    assert!(f32::from_lexical(b"inf").unwrap().is_infinite());
    assert!(f32::from_lexical(b"INF").unwrap().is_infinite());
    assert!(f32::from_lexical(b"+inf").unwrap().is_infinite());
    assert!(f32::from_lexical(b"-inf").unwrap().is_infinite());

    // Check various expected failures.
    assert_eq!(Err(Error::Empty(0)), f32::from_lexical(b""));
    assert_eq!(Err(Error::EmptyMantissa(0)), f32::from_lexical(b"e"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f32::from_lexical(b"E"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f32::from_lexical(b".e1"));
    assert_eq!(Err(Error::EmptyMantissa(1)), f32::from_lexical(b".e-1"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f32::from_lexical(b"e1"));
    assert_eq!(Err(Error::EmptyMantissa(0)), f32::from_lexical(b"e-1"));
    assert_eq!(Err(Error::Empty(1)), f32::from_lexical(b"+"));
    assert_eq!(Err(Error::Empty(1)), f32::from_lexical(b"-"));

    // Bug fix for Issue #8
    assert_eq!(Ok(5.002868148396374), f32::from_lexical(b"5.002868148396374"));

    // Other bug fixes
    assert_eq!(Ok(7.2625224e+37), f32::from_lexical(b"72625224000000000000000000000000000000"));
    assert_eq!(Ok(7.2625224e+37), f32::from_lexical(b"72625224000000000000000000000000000000.0"));
    assert_eq!(Ok(-7.2625224e+37), f32::from_lexical(b"-72625224000000000000000000000000000000"));
    assert_eq!(Ok(-7.2625224e+37), f32::from_lexical(b"-72625224000000000000000000000000000000.0"));
}
fn test_leader_transfer() {
    let mut suite = TestSuite::new(3, ApiVersion::V2);
    let key1 = b"rk1";
    let region = suite.cluster.get_region(key1);

    // Transfer leader and write to store 1.
    {
        suite.must_transfer_leader(&region, 1);
        let leader1 = suite.must_leader_on_store(key1, 1);

        suite.must_raw_put(key1, b"v1");
        suite.must_raw_put(key1, b"v2");
        suite.must_raw_put(key1, b"v3");
        suite.flush_timestamp(leader1.get_store_id()); // Flush to make ts bigger than other stores.
        suite.must_raw_put(key1, b"v4");
        assert_eq!(suite.must_raw_get(key1), Some(b"v4".to_vec()));
    }

    // Make causal_ts_provider.async_flush() & handle_update_max_timestamp fail.
    fail::cfg(FP_GET_TSO, "return(50)").unwrap();

    // Transfer leader and write to store 2.
    {
        suite.must_transfer_leader(&region, 2);
        suite.must_leader_on_store(key1, 2);

        // Store 2 has a TSO batch smaller than store 1.
        suite.raw_put_err_by_timestamp_not_synced(key1, b"v5");
        assert_eq!(suite.must_raw_get(key1), Some(b"v4".to_vec()));
        suite.raw_put_err_by_timestamp_not_synced(key1, b"v6");
        assert_eq!(suite.must_raw_get(key1), Some(b"v4".to_vec()));
    }

    // Transfer leader back.
    suite.must_transfer_leader(&region, 1);
    suite.must_leader_on_store(key1, 1);
    // Make handle_update_max_timestamp succeed.
    fail::cfg(FP_GET_TSO, "off").unwrap();
    // Transfer leader and write to store 2 again.
    {
        suite.must_transfer_leader(&region, 2);
        suite.must_leader_on_store(key1, 2);

        suite.must_raw_put(key1, b"v7");
        assert_eq!(suite.must_raw_get(key1), Some(b"v7".to_vec()));
        suite.must_raw_put(key1, b"v8");
        assert_eq!(suite.must_raw_get(key1), Some(b"v8".to_vec()));
    }

    fail::remove(FP_GET_TSO);
    suite.stop();
}
fn test_batch_raft_fallback() {
    let msg_count = Arc::new(AtomicUsize::new(0));
    let batch_msg_count = Arc::new(AtomicUsize::new(0));
    let service = MockKvForRaft::new(Arc::clone(&msg_count), Arc::clone(&batch_msg_count), false);
    let (mock_server, port) = create_mock_server(service, 60000, 60100).unwrap();

    let mut raft_client = get_raft_client_by_port(port);
    (0..100).for_each(|_| {
        raft_client.send(RaftMessage::default()).unwrap();
        thread::sleep(time::Duration::from_millis(10));
        raft_client.flush();
    });

    assert!(msg_count.load(Ordering::SeqCst) > 0);
    assert_eq!(batch_msg_count.load(Ordering::SeqCst), 0);
    drop(mock_server)
}
fn stdin_fix_py() {
    let args = ["--fix"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("import os\nimport sys\n\nprint(sys.version)\n"), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    import sys

    print(sys.version)

    ----- stderr -----
    Found 1 error (1 fixed, 0 remaining).
    "###);
}
fn can_load_macro_in_child() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 }}{% endmacro hello %}"),
        ("parent", "{% block bob %}{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% import \"macros\" as macros %}{% block bob %}{{ macros::hello() }}{% endblock bob %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "1".to_string());
}
fn test_item_size() {
    assert_eq!(mem::size_of::<Item>(), 360);
}
fn test_analyze_single_primary_column() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, None, 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);

    let req = new_analyze_column_req(&product, 1, 3, 3, 3, 4, 32);
    let resp = handle_request(&endpoint, req);
    assert!(!resp.get_data().is_empty());
    let mut analyze_resp = AnalyzeColumnsResp::default();
    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();
    let hist = analyze_resp.get_pk_hist();
    assert_eq!(hist.get_buckets().len(), 2);
    assert_eq!(hist.get_ndv(), 4);
    let collectors = analyze_resp.get_collectors().to_vec();
    assert_eq!(collectors.len(), 0);
}
fn test_pessimistic_lock_check_epoch() {
    let mut cluster = new_server_cluster(0, 2);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));

    let region = cluster.get_region(b"");
    let leader = region.get_peers()[0].clone();

    let epoch = cluster.get_region_epoch(region.id);
    let mut ctx = Context::default();
    ctx.set_region_id(region.id);
    ctx.set_peer(leader.clone());
    ctx.set_region_epoch(epoch);

    let (fp_tx, fp_rx) = sync_channel(0);
    fail::cfg_callback("acquire_pessimistic_lock", move || {
        fp_tx.send(()).unwrap();
    })
    .unwrap();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let mut mutation = pb::Mutation::default();
    mutation.set_op(Op::PessimisticLock);
    mutation.key = b"key".to_vec();
    let mut req = PessimisticLockRequest::default();
    req.set_context(ctx.clone());
    req.set_mutations(vec![mutation].into());
    req.set_start_version(10);
    req.set_for_update_ts(10);
    req.set_primary_lock(b"key".to_vec());

    let lock_resp = thread::spawn(move || client.kv_pessimistic_lock(&req).unwrap());
    thread::sleep(Duration::from_millis(300));

    // Transfer leader out and back, so the term should have changed.
    cluster.must_transfer_leader(1, new_peer(2, 2));
    cluster.must_transfer_leader(1, new_peer(1, 1));
    fp_rx.recv().unwrap();

    let resp = lock_resp.join().unwrap();
    // Region leader changes, so we should get a StaleCommand error.
    assert!(resp.get_region_error().has_stale_command());
}
fn parse_string_concat() {
    let ast = parse("{{ `hello` ~ ident }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::StringConcat(StringConcat {
                values: vec![
                    ExprVal::String("hello".to_string()),
                    ExprVal::Ident("ident".to_string()),
                ]
            }))
        ),
    );
}
fn server_closes_uncleanly() {
    let kt = KeyType::Rsa;
    let server_config = Arc::new(make_server_config(kt));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(kt, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        do_handshake(&mut client, &mut server);

        // check that unclean EOF reporting does not overtake appdata
        assert_eq!(
            12,
            server
                .writer()
                .write(b"from-server!")
                .unwrap()
        );
        assert_eq!(
            12,
            client
                .writer()
                .write(b"from-client!")
                .unwrap()
        );

        transfer(&mut server, &mut client);
        transfer_eof(&mut client);
        let io_state = client.process_new_packets().unwrap();
        assert!(!io_state.peer_has_closed());
        check_read(&mut client.reader(), b"from-server!");

        check_read_err(
            &mut client.reader() as &mut dyn io::Read,
            io::ErrorKind::UnexpectedEof,
        );

        // may still transmit pending frames
        transfer(&mut client, &mut server);
        server.process_new_packets().unwrap();
        check_read(&mut server.reader(), b"from-client!");
    }
}
fn issue115() {
    let mut r = Reader::from_str("<tag1 attr1='line 1\nline 2'></tag1>");
    match r.read_event() {
        Ok(Event::Start(e)) if e.name() == QName(b"tag1") => {
            let v = e.attributes().map(|a| a.unwrap().value).collect::<Vec<_>>();
            assert_eq!(v[0].clone().into_owned(), b"line 1\nline 2");
        }
        _ => (),
    }
}
fn count_factors_test() {
    assert_eq!(algorithm::count_factors(5, 25), 2);
    assert_eq!(algorithm::count_factors(5, 30), 1);
    assert_eq!(algorithm::count_factors(5, 125), 3);
    assert_eq!(algorithm::count_factors(5, 126), 0);
}
fn test_lookup() {
    let runtime = Runtime::new().expect("failed to create Tokio Runtime");
    let forwarder = ForwardAuthority::new(TokioConnectionProvider::default())
        .expect("failed to create forwarder");

    let lookup = runtime
        .block_on(forwarder.lookup(
            &Name::from_str("www.example.com.").unwrap().into(),
            RecordType::A,
            Default::default(),
        ))
        .unwrap();

    let address = lookup.iter().next().expect("no addresses returned!");
    let address = address
        .data()
        .and_then(RData::as_a)
        .expect("not an A record");
    assert_eq!(*address, Ipv4Addr::new(93, 184, 216, 34).into());
}
fn test_create_multi() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // create a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));
    let record = record;

    let mut record2 = record.clone();
    record2.set_data(Some(RData::A(A::new(100, 10, 100, 11))));
    let record2 = record2;

    let mut rrset = RecordSet::from(record.clone());
    rrset.insert(record2.clone(), 0);
    let rrset = rrset;

    let result = io_loop
        .block_on(client.create(rrset.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    let result = io_loop
        .block_on(client.query(
            record.name().clone(),
            record.dns_class(),
            record.record_type(),
        ))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);

    assert!(result.answers().iter().any(|rr| *rr == record));
    assert!(result.answers().iter().any(|rr| *rr == record2));

    // trying to create again should error
    // TODO: it would be cool to make this
    let result = io_loop
        .block_on(client.create(rrset, origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);

    // will fail if already set and not the same value.
    let mut record = record;
    record.set_data(Some(RData::A(A::new(101, 11, 101, 12))));

    let result = io_loop
        .block_on(client.create(record, origin))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);
}
fn test_install_mode_directories() {
    let (at, mut ucmd) = at_and_ucmd!();
    let component = "component";
    let directories_arg = "-d";
    let mode_arg = "--mode=333";

    ucmd.arg(directories_arg)
        .arg(component)
        .arg(mode_arg)
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(component));
    let permissions = at.metadata(component).permissions();
    assert_eq!(0o040_333_u32, PermissionsExt::mode(&permissions));
}
fn remove_entry_multi_3() {
    let mut headers = HeaderMap::new();
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());

    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 3);
    assert_eq!(headers.len(), 0);
}
fn parse_f64_lossy_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::builder().lossy(true).build().unwrap();
    let parse = move |x| f64::from_lexical_partial_with_options::<FORMAT>(x, &options);

    assert_eq!(Ok((1.2345, 6)), parse(b"1.2345"));
    assert_eq!(Ok((12.345, 6)), parse(b"12.345"));
    assert_eq!(Ok((12345.6789, 10)), parse(b"12345.6789"));
    assert_eq!(Ok((1.2345e10, 9)), parse(b"1.2345e10"));
}
fn test_chown_owner_group_id() {
    // test chown 1111:1111 file.txt

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("id").arg("-u").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let user_id = String::from(result.stdout_str().trim());
    assert!(!user_id.is_empty());

    let result = scene.cmd("id").arg("-g").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let group_id = String::from(result.stdout_str().trim());
    assert!(!group_id.is_empty());

    let file1 = "test_chown_file1";
    at.touch(file1);

    let result = scene
        .ucmd()
        .arg(format!("{user_id}:{group_id}"))
        .arg("--verbose")
        .arg(file1)
        .run();
    if skipping_test_is_okay(&result, "invalid user") {
        // From the Logs: "Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)"
        // stderr: "chown: invalid user: '1001:116'
        return;
    }
    result.stderr_contains("retained as");

    let result = scene
        .ucmd()
        .arg(format!("{user_id}.{group_id}"))
        .arg("--verbose")
        .arg(file1)
        .run();
    if skipping_test_is_okay(&result, "invalid user") {
        // From the Logs: "Build (ubuntu-18.04, x86_64-unknown-linux-gnu, feat_os_unix, use-cross)"
        // stderr: "chown: invalid user: '1001.116'
        return;
    }
    result.stderr_contains("retained as");

    scene
        .ucmd()
        .arg("0:0")
        .arg("--verbose")
        .arg(file1)
        .fails()
        .stderr_contains("failed to change");
}
fn parse_substring_in_select() {
    let sql = "SELECT DISTINCT SUBSTRING(description, 0, 1) FROM test";
    match ms().one_statement_parses_to(
        sql,
        "SELECT DISTINCT SUBSTRING(description, 0, 1) FROM test",
    ) {
        Statement::Query(query) => {
            assert_eq!(
                Box::new(Query {
                    with: None,

                    body: Box::new(SetExpr::Select(Box::new(Select {
                        distinct: Some(Distinct::Distinct),
                        top: None,
                        projection: vec![SelectItem::UnnamedExpr(Expr::Substring {
                            expr: Box::new(Expr::Identifier(Ident {
                                value: "description".to_string(),
                                quote_style: None
                            })),
                            substring_from: Some(Box::new(Expr::Value(number("0")))),
                            substring_for: Some(Box::new(Expr::Value(number("1")))),
                            special: true,
                        })],
                        into: None,
                        from: vec![TableWithJoins {
                            relation: TableFactor::Table {
                                name: ObjectName(vec![Ident {
                                    value: "test".to_string(),
                                    quote_style: None
                                }]),
                                alias: None,
                                args: None,
                                with_hints: vec![],
                                version: None,
                                partitions: vec![],
                            },
                            joins: vec![]
                        }],
                        lateral_views: vec![],
                        selection: None,
                        group_by: GroupByExpr::Expressions(vec![]),
                        cluster_by: vec![],
                        distribute_by: vec![],
                        sort_by: vec![],
                        having: None,
                        named_window: vec![],
                        qualify: None
                    }))),
                    order_by: vec![],
                    limit: None,
                    limit_by: vec![],
                    offset: None,
                    fetch: None,
                    locks: vec![],
                }),
                query
            );
        }
        _ => unreachable!(),
    }
}
fn test_increase_async_ios() {
    let mut cluster = new_node_cluster(0, 1);
    cluster.cfg.raft_store.store_io_pool_size = 1;
    cluster.pd_client.disable_default_operator();
    cluster.run();

    // Save current async-io tids before shrinking
    let org_writers_tids = get_async_writers_tids();
    assert_eq!(1, org_writers_tids.len());
    // Request can be handled as usual
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");

    // Update config, expand from 1 to 2
    {
        let sim = cluster.sim.rl();
        let cfg_controller = sim.get_cfg_controller().unwrap();

        let change = {
            let mut change = HashMap::new();
            change.insert("raftstore.store-io-pool-size".to_owned(), "2".to_owned());
            change
        };

        cfg_controller.update(change).unwrap();
        assert_eq!(
            cfg_controller.get_current().raft_store.store_io_pool_size,
            2
        );
        // Wait for the completion of increasing async-ios
        std::thread::sleep(std::time::Duration::from_secs(1));
    }
    // Save current async-io tids after scaling up, and compared with the
    // orginial one before scaling up, the thread num should be added up to TWO.
    let cur_writers_tids = get_async_writers_tids();
    assert_eq!(cur_writers_tids.len() - 1, org_writers_tids.len());

    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
}
fn u32_digit_count_test() {
    assert_eq!(u32::digit_count(0), 1);
    assert_eq!(u32::digit_count(1), 1);
    assert_eq!(u32::digit_count(9), 1);
    assert_eq!(u32::digit_count(10), 2);
    assert_eq!(u32::digit_count(11), 2);

    assert_eq!(u32::digit_count((1 << 16) - 1), 5);
    assert_eq!(u32::digit_count(1 << 16), 5);
    assert_eq!(u32::digit_count((1 << 16) + 1), 5);

    assert_eq!(u32::digit_count(u32::MAX), 10);
}
fn write_batch_count() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    assert_eq!(wb.count(), 0);
    wb.put(b"a", b"").unwrap();
    assert_eq!(wb.count(), 1);
    wb.write().unwrap();
    assert_eq!(wb.count(), 1);

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    assert_eq!(wb.count(), 0);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    assert_eq!(wb.count(), 256);
    wb.write().unwrap();
    assert_eq!(wb.count(), 256);
}
fn is_informational() {
    assert!(status_code(100).is_informational());
    assert!(status_code(199).is_informational());

    assert!(!status_code(200).is_informational());
}
fn u128_test() {
    let mut buffer = [b'\x00'; 48];
    assert_eq!(b"0", 0u128.to_lexical(&mut buffer));
    assert_eq!(b"1", 1u128.to_lexical(&mut buffer));
    assert_eq!(b"5", 5u128.to_lexical(&mut buffer));
    assert_eq!(
        &b"170141183460469231731687303715884105727"[..],
        170141183460469231731687303715884105727u128.to_lexical(&mut buffer)
    );
    assert_eq!(
        &b"170141183460469231731687303715884105728"[..],
        170141183460469231731687303715884105728u128.to_lexical(&mut buffer)
    );
    assert_eq!(
        &b"340282366920938463463374607431768211455"[..],
        340282366920938463463374607431768211455u128.to_lexical(&mut buffer)
    );
    assert_eq!(
        &b"340282366920938463463374607431768211455"[..],
        (-1i128 as u128).to_lexical(&mut buffer)
    );
}
fn can_inherit_macro_import_from_parent() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}HELLO{% endmacro hello %}"),
        ("parent", "{% import \"macros\" as macros %}{% block bob %}parent{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{macros::hello()}}{% endblock bob %}"),
    ])
    .unwrap();

    let result = tera.render("child", &Context::default());
    assert_eq!(result.unwrap(), "HELLO".to_string());
}
fn file_too_large_config_limit() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert(PathBuf::from("biome.json"), CONFIG_FILE_SIZE_LIMIT);

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "file_too_large_config_limit",
        fs,
        console,
        result,
    ));
}
fn applies_custom_quote_style() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), APPLY_QUOTE_STYLE_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--quote-style"),
                ("single"),
                ("--quote-properties"),
                ("preserve"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, APPLY_QUOTE_STYLE_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_quote_style",
        fs,
        console,
        result,
    ));
}
fn parse_simple_macro_definition() {
    let ast = parse("{% macro hello(a=1, b='hello', c) %}A: {{a}}{% endmacro %}").unwrap();
    let mut args = HashMap::new();
    args.insert("a".to_string(), Some(Expr::new(ExprVal::Int(1))));
    args.insert("b".to_string(), Some(Expr::new(ExprVal::String("hello".to_string()))));
    args.insert("c".to_string(), None);

    assert_eq!(
        ast[0],
        Node::MacroDefinition(
            WS::default(),
            MacroDefinition {
                name: "hello".to_string(),
                args,
                body: vec![
                    Node::Text("A: ".to_string()),
                    Node::VariableBlock(WS::default(), Expr::new(ExprVal::Ident("a".to_string()))),
                ],
            },
            WS::default(),
        )
    );
}
fn should_write_to_engine() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();
    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;

    let mut key = vec![];
    loop {
        key.push(b'a');
        wb.put(&key, b"").unwrap();
        if key.len() <= max_keys {
            assert!(!wb.should_write_to_engine());
        }
        if key.len() == max_keys + 1 {
            assert!(wb.should_write_to_engine());
            wb.write().unwrap();
            break;
        }
    }

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = KvTestEngine::WRITE_BATCH_MAX_KEYS;

    let mut key = vec![];
    loop {
        key.push(b'a');
        wb.put(&key, b"").unwrap();
        if key.len() <= max_keys {
            assert!(!wb.should_write_to_engine());
        }
        if key.len() == max_keys + 1 {
            assert!(wb.should_write_to_engine());
            wb.write().unwrap();
            break;
        }
    }
}
fn parse_category_then_multiple_keys_and_values_test() {
  //FIXME: there can be an empty line or a comment line after a category
  let ini_file = "[abcd]
parameter=value;abc

key = value2

[category]";

  let ini_after_parser = "[category]";

  let res = category_and_keys(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, ref o)) => println!("i: {} | o: {:?}", i, o),
    _ => println!("error"),
  }

  let mut expected_h: HashMap<&str, &str> = HashMap::new();
  expected_h.insert("parameter", "value");
  expected_h.insert("key", "value2");
  assert_eq!(res, Ok((ini_after_parser, ("abcd", expected_h))));
}
fn does_handle_only_included_files() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": { "include": ["test.js"] }
}
"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_only_included_files",
        fs,
        console,
        result,
    ));
}
fn render_nested_block_multiple_inheritance_no_super() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("index", "{% block content%}INDEX{% endblock content %}"),
        (
            "docs",
            "{% extends \"index\" %}{% block content%}DOCS{% block more %}MORE{% endblock more %}{% endblock content %}",
        ),
        ("page", "{% extends \"docs\" %}{% block more %}PAGE{% endblock more %}"),
    ]).unwrap();

    let result = tera.render("page", &Context::new());

    assert_eq!(result.unwrap(), "DOCSPAGE".to_string());
}
fn strip_end_newline() {
    assert_eq!("test", normalize_html("test\n"));
}
fn tuple_type_lifetime() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<(&str, u8), (u16, u32)> = TableDefinition::new("table");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(table_def).unwrap();
        table
            .insert(&(String::from("hello").as_str(), 5), &(0, 123))
            .unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(table_def).unwrap();
    assert_eq!(table.get(&("hello", 5)).unwrap().unwrap().value(), (0, 123));
}
fn parse_category_test() {
  let ini_file = "[category]

parameter=value
key = value2";

  let ini_without_category = "parameter=value
key = value2";

  let res = category(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, o)) => println!("i: {} | o: {:?}", i, o),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_category, "category")));
}
fn recursion() -> Result<(), Error> {
    // Make sure call hook behaves reasonably when called recursively

    let engine = Engine::default();
    let mut store = Store::new(&engine, State::default());
    store.call_hook(State::call_hook);
    let mut linker = Linker::new(&engine);

    linker.func_wrap("host", "f", |mut caller: Caller<State>, n: i32| {
        assert_eq!(caller.data().context.last(), Some(&Context::Host));

        assert_eq!(caller.data().calls_into_host, caller.data().calls_into_wasm);

        // Recurse
        if n > 0 {
            caller
                .get_export("export")
                .expect("caller exports \"export\"")
                .into_func()
                .expect("export is a func")
                .typed::<i32, ()>(&caller)
                .expect("export typing")
                .call(&mut caller, n - 1)
                .unwrap()
        }
    })?;

    let wat = r#"
        (module
            (import "host" "f"
                (func $f (param i32)))
            (func (export "export") (param i32)
                (call $f (local.get 0)))
        )
    "#;
    let module = Module::new(&engine, wat)?;

    let inst = linker.instantiate(&mut store, &module)?;
    let export = inst
        .get_export(&mut store, "export")
        .expect("get export")
        .into_func()
        .expect("export is func");

    // Recursion depth:
    let n: usize = 10;

    export.call(&mut store, &[Val::I32(n as i32)], &mut [])?;

    // Recurse down to 0: n+1 calls
    assert_eq!(store.data().calls_into_host, n + 1);
    assert_eq!(store.data().returns_from_host, n + 1);
    assert_eq!(store.data().calls_into_wasm, n + 1);
    assert_eq!(store.data().returns_from_wasm, n + 1);

    export
        .typed::<i32, ()>(&store)?
        .call(&mut store, n as i32)?;

    assert_eq!(store.data().calls_into_host, 2 * (n + 1));
    assert_eq!(store.data().returns_from_host, 2 * (n + 1));
    assert_eq!(store.data().calls_into_wasm, 2 * (n + 1));
    assert_eq!(store.data().returns_from_wasm, 2 * (n + 1));

    Ok(())
}
fn sqrtf_sanity_test() {
    assert_eq!(libm::sqrtf(100.0), 10.0);
    assert_eq!(libm::sqrtf(4.0), 2.0);
}
fn test_v1_receive_snap_from_v2() {
    let test_receive_snap = |key_num| {
        let mut cluster_v1 = test_raftstore::new_server_cluster(1, 1);
        let mut cluster_v2 = test_raftstore_v2::new_server_cluster(1, 1);
        let mut cluster_v1_tikv = test_raftstore::new_server_cluster(1, 1);

        cluster_v1.cfg.raft_store.enable_v2_compatible_learner = true;

        cluster_v1.run();
        cluster_v2.run();
        cluster_v1_tikv.run();

        let s1_addr = cluster_v1.get_addr(1);
        let s2_addr = cluster_v1_tikv.get_addr(1);
        let region = cluster_v2.get_region(b"");
        let region_id = region.get_id();
        let engine = cluster_v2.get_engine(1);
        let tablet = engine.get_tablet_by_id(region_id).unwrap();

        for i in 0..key_num {
            let k = format!("zk{:04}", i);
            tablet.put(k.as_bytes(), &random_long_vec(1024)).unwrap();
        }

        let snap_mgr = cluster_v2.get_snap_mgr(1);
        let security_mgr = cluster_v2.get_security_mgr();
        let (msg, snap_key) = generate_snap(&engine, region_id, &snap_mgr);
        let cfg = tikv::server::Config::default();
        let limit = Limiter::new(f64::INFINITY);
        let env = Arc::new(Environment::new(1));
        let _ = block_on(async {
            send_snap_v2(
                env.clone(),
                snap_mgr.clone(),
                security_mgr.clone(),
                &cfg,
                &s1_addr,
                msg.clone(),
                limit.clone(),
            )
            .unwrap()
            .await
        });
        let send_result = block_on(async {
            send_snap_v2(env, snap_mgr, security_mgr, &cfg, &s2_addr, msg, limit)
                .unwrap()
                .await
        });
        // snapshot should be rejected by cluster v1 tikv, and the snapshot should be
        // deleted.
        assert!(send_result.is_err());
        let dir = cluster_v2.get_snap_dir(1);
        let read_dir = std::fs::read_dir(dir).unwrap();
        assert_eq!(0, read_dir.count());

        // The snapshot has been received by cluster v1, so check it's completeness
        let snap_mgr = cluster_v1.get_snap_mgr(1);
        let path = snap_mgr
            .tablet_snap_manager()
            .unwrap()
            .final_recv_path(&snap_key);
        let rocksdb = engine_rocks::util::new_engine_opt(
            path.as_path().to_str().unwrap(),
            RocksDbOptions::default(),
            LARGE_CFS
                .iter()
                .map(|&cf| (cf, RocksCfOptions::default()))
                .collect(),
        )
        .unwrap();

        for i in 0..key_num {
            let k = format!("zk{:04}", i);
            assert!(
                rocksdb
                    .get_value_cf("default", k.as_bytes())
                    .unwrap()
                    .is_some()
            );
        }
    };

    // test small snapshot
    test_receive_snap(20);

    // test large snapshot
    test_receive_snap(5000);
}
fn test_stale_learner_with_read_index() {
    let mut cluster = new_server_cluster(0, 4);
    // Do not rely on pd to remove stale peer
    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::hours(2);
    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::minutes(20);
    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::minutes(10);
    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check
    pd_client.disable_default_operator();

    let r1 = cluster.run_conf_change();
    pd_client.must_add_peer(r1, new_peer(2, 2));
    pd_client.must_add_peer(r1, new_learner_peer(3, 3));
    cluster.must_put(b"k1", b"v1");
    let engine3 = cluster.get_engine(3);
    must_get_equal(&engine3, b"k1", b"v1");

    // And then isolate peer on store 3 from leader
    cluster.add_send_filter(IsolationFilterFactory::new(3));

    // Delete the learner
    pd_client.must_remove_peer(r1, new_learner_peer(3, 3));

    cluster.clear_send_filters();

    // Stale learner should exist
    must_get_equal(&engine3, b"k1", b"v1");

    let region = cluster.get_region(b"k1");

    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cf_cmd("default", b"k1")],
        false,
    );
    request.mut_header().set_peer(new_peer(3, 3));
    request.mut_header().set_replica_read(true);
    let (cb, _) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(3, request, cb)
        .unwrap();

    // Stale learner should be destroyed due to interaction between leader
    must_get_none(&engine3, b"k1");
    let state_key = keys::region_state_key(r1);
    let state: RegionLocalState = engine3.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();
    assert_eq!(state.get_state(), PeerState::Tombstone);
}
fn test_is_4digits() {
    let value: u32 = 0x31_32_33_34;
    #[cfg(feature = "power-of-two")]
    assert!(!algorithm::is_4digits::<{ from_radix(4) }>(value));
    #[cfg(feature = "radix")]
    assert!(algorithm::is_4digits::<{ from_radix(5) }>(value));
    assert!(algorithm::is_4digits::<{ STANDARD }>(value));

    let value: u32 = 0x29_30_39_38;
    assert!(!algorithm::is_4digits::<{ STANDARD }>(value));

    let value: u32 = 0x31_32_33_40;
    assert!(!algorithm::is_4digits::<{ STANDARD }>(value));

    let value: u32 = 0x31_32_33_39;
    #[cfg(feature = "radix")]
    assert!(!algorithm::is_4digits::<{ from_radix(9) }>(value));
    assert!(algorithm::is_4digits::<{ STANDARD }>(value));
}
fn post_return_all_types() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "i32") (result i32)
                    i32.const 1)
                (func (export "i64") (result i64)
                    i64.const 2)
                (func (export "f32") (result f32)
                    f32.const 3)
                (func (export "f64") (result f64)
                    f64.const 4)

                (func (export "post-i32") (param i32)
                    local.get 0
                    i32.const 1
                    i32.ne
                    if unreachable end)
                (func (export "post-i64") (param i64)
                    local.get 0
                    i64.const 2
                    i64.ne
                    if unreachable end)
                (func (export "post-f32") (param f32)
                    local.get 0
                    f32.const 3
                    f32.ne
                    if unreachable end)
                (func (export "post-f64") (param f64)
                    local.get 0
                    f64.const 4
                    f64.ne
                    if unreachable end)
            )
            (core instance $i (instantiate $m))
            (func (export "i32") (result u32)
                (canon lift (core func $i "i32") (post-return (func $i "post-i32")))
            )
            (func (export "i64") (result u64)
                (canon lift (core func $i "i64") (post-return (func $i "post-i64")))
            )
            (func (export "f32") (result float32)
                (canon lift (core func $i "f32") (post-return (func $i "post-f32")))
            )
            (func (export "f64") (result float64)
                (canon lift (core func $i "f64") (post-return (func $i "post-f64")))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, false);
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let i32 = instance.get_typed_func::<(), (u32,)>(&mut store, "i32")?;
    let i64 = instance.get_typed_func::<(), (u64,)>(&mut store, "i64")?;
    let f32 = instance.get_typed_func::<(), (f32,)>(&mut store, "f32")?;
    let f64 = instance.get_typed_func::<(), (f64,)>(&mut store, "f64")?;

    assert_eq!(i32.call(&mut store, ())?, (1,));
    i32.post_return(&mut store)?;

    assert_eq!(i64.call(&mut store, ())?, (2,));
    i64.post_return(&mut store)?;

    assert_eq!(f32.call(&mut store, ())?, (3.,));
    f32.post_return(&mut store)?;

    assert_eq!(f64.call(&mut store, ())?, (4.,));
    f64.post_return(&mut store)?;

    Ok(())
}
fn precedence() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
extend-select = ["B", "Q"]

[flake8-quotes]
inline-quotes = "double"

[lint.flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .arg("--config")
        .arg(&ruff_toml)
        .arg("-")
        .pass_stdin(r#"a = "abcba".strip("aba")"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:5: Q000 [*] Double quotes found but single quotes preferred
    -:1:5: B005 Using `.strip()` with multi-character strings is misleading
    -:1:19: Q000 [*] Double quotes found but single quotes preferred
    Found 3 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
fn test_timeout() {
    let core = Runtime::new().expect("could not get core");
    let timeout_stream = TimeoutStream::new(NeverStream {}, Duration::from_millis(1));

    assert!(core
        .block_on(timeout_stream.into_future())
        .0
        .expect("nothing in stream")
        .is_err());
}
fn server_can_send_3_inital_packets() {
    let _guard = subscribe();

    let (cert, key) = big_cert_and_key();
    let server = server_config_with_cert(cert.clone(), key);
    let client = client_config_with_certs(vec![cert]);
    let mut pair = Pair::new(Default::default(), server);

    let client_ch = pair.begin_connect(client);
    // Client sends initial
    pair.drive_client();
    // Server sends first flight, gets blocked on anti-amplification
    pair.drive_server();
    // Server should have queued 3 packets at this time
    assert_eq!(pair.client.inbound.len(), 3);

    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected { .. })
    );
}
fn receive() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet receive")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Output>();

  assert!(output.address.is_valid_for_network(Network::Bitcoin));
}
fn array_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<&[u8; 5], &[u8; 9]> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(b"hello", b"world_123").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    let hello = b"hello";
    assert_eq!(b"world_123", table.get(hello).unwrap().unwrap().value());

    let mut iter: Range<&[u8; 5], &[u8; 9]> = table.range::<&[u8; 5]>(..).unwrap();
    assert_eq!(iter.next().unwrap().unwrap().1.value(), b"world_123");
    assert!(iter.next().is_none());
}
fn test_value_by_index() {
    let val = Value::from(vec![1u32, 2, 3]);
    assert_eq!(val.get_item_by_index(0).unwrap(), Value::from(1));
    assert!(val.get_item_by_index(4).unwrap().is_undefined());
}
fn congestion() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, _) = pair.connect();

    const TARGET: u64 = 2048;
    assert!(pair.client_conn_mut(client_ch).congestion_window() > TARGET);
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    // Send data without receiving ACKs until the congestion state falls below target
    while pair.client_conn_mut(client_ch).congestion_window() > TARGET {
        let n = pair.client_send(client_ch, s).write(&[42; 1024]).unwrap();
        assert_eq!(n, 1024);
        pair.drive_client();
    }
    // Ensure that the congestion state recovers after receiving the ACKs
    pair.drive();
    assert!(pair.client_conn_mut(client_ch).congestion_window() >= TARGET);
    pair.client_send(client_ch, s).write(&[42; 1024]).unwrap();
}
fn test_get_tombstone_store() {
    let eps_count = 1;
    let server = MockServer::new(eps_count);
    let eps = server.bind_addrs();
    let client = new_client(eps, None);

    let mut all_stores = vec![];
    let store_id = client.alloc_id().unwrap();
    let mut store = metapb::Store::default();
    store.set_id(store_id);
    let region_id = client.alloc_id().unwrap();
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    client.bootstrap_cluster(store.clone(), region).unwrap();

    all_stores.push(store);
    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);
    let s = client.get_all_stores(false).unwrap();
    assert_eq!(s, all_stores);

    // Add tombstone store.
    let mut store99 = metapb::Store::default();
    store99.set_id(99);
    store99.set_state(metapb::StoreState::Tombstone);
    server.default_handler().add_store(store99.clone());

    let r = block_on(client.get_store_async(99));
    assert_eq!(r.unwrap_err().error_code(), error_code::pd::STORE_TOMBSTONE);
}
fn incorrect_description_file_2() {
    let f = super::fixture().join("incorrect-package");
    let resolution = Resolver::default().resolve(f.join("pack2"), ".");
    let error = ResolveError::JSON(JSONError {
        path: f.join("pack2/package.json"),
        message: String::from("EOF while parsing a value at line 1 column 0"),
        line: 1,
        column: 0,
    });
    assert_eq!(resolution, Err(error));
}
fn parse_create_table_as_table() {
    let sql1 = "CREATE TABLE new_table AS TABLE old_table";

    let expected_query1 = Box::new(Query {
        with: None,
        body: Box::new(SetExpr::Table(Box::new(Table {
            table_name: Some("old_table".to_string()),
            schema_name: None,
        }))),
        order_by: vec![],
        limit: None,
        limit_by: vec![],
        offset: None,
        fetch: None,
        locks: vec![],
    });

    match verified_stmt(sql1) {
        Statement::CreateTable { query, name, .. } => {
            assert_eq!(name, ObjectName(vec![Ident::new("new_table")]));
            assert_eq!(query.unwrap(), expected_query1);
        }
        _ => unreachable!(),
    }

    let sql2 = "CREATE TABLE new_table AS TABLE schema_name.old_table";

    let expected_query2 = Box::new(Query {
        with: None,
        body: Box::new(SetExpr::Table(Box::new(Table {
            table_name: Some("old_table".to_string()),
            schema_name: Some("schema_name".to_string()),
        }))),
        order_by: vec![],
        limit: None,
        limit_by: vec![],
        offset: None,
        fetch: None,
        locks: vec![],
    });

    match verified_stmt(sql2) {
        Statement::CreateTable { query, name, .. } => {
            assert_eq!(name, ObjectName(vec![Ident::new("new_table")]));
            assert_eq!(query.unwrap(), expected_query2);
        }
        _ => unreachable!(),
    }
}
fn parse_set_tag_lit() {
    let ast = parse("{% set hello = \"hi\" %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Set(
            WS::default(),
            Set {
                key: "hello".to_string(),
                value: Expr::new(ExprVal::String("hi".to_string())),
                global: false,
            },
        )
    );
}
fn test_chmod_file_after_non_existing_file() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    at.touch(TEST_FILE);
    at.touch("file2");
    set_permissions(at.plus(TEST_FILE), Permissions::from_mode(0o664)).unwrap();
    set_permissions(at.plus("file2"), Permissions::from_mode(0o664)).unwrap();
    scene
        .ucmd()
        .arg("u+x")
        .arg("does-not-exist")
        .arg(TEST_FILE)
        .fails()
        .stderr_contains("chmod: cannot access 'does-not-exist': No such file or directory")
        .code_is(1);

    assert_eq!(at.metadata(TEST_FILE).permissions().mode(), 0o100_764);

    scene
        .ucmd()
        .arg("u+x")
        .arg("--q")
        .arg("does-not-exist")
        .arg("file2")
        .fails()
        .no_stderr()
        .code_is(1);
    assert_eq!(at.metadata("file2").permissions().mode(), 0o100_764);
}
fn test_symlink_implicit_target_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_symlink_implicit_target_dir";
    // On windows, slashes aren't allowed in symlink targets, so use
    // PathBuf to construct `file` instead of simple "dir/file".
    let filename = "test_symlink_implicit_target_file";
    let path = PathBuf::from(dir).join(filename);
    let file = &path.to_string_lossy();

    at.mkdir(dir);
    at.touch(&path);

    ucmd.args(&["-s", file]).succeeds().no_stderr();

    assert!(at.file_exists(filename));
    assert!(at.is_symlink(filename));
    assert_eq!(at.resolve_link(filename), *file);
}
fn double_fast_path_test() {
    // valid
    let mantissa = (1 << f64::MANTISSA_SIZE) - 1;
    let (min_exp, max_exp) = f64::exponent_limit();
    for exp in min_exp..=max_exp {
        let f = fast_path::<f64>(mantissa, exp);
        assert!(f.is_some(), "should be valid {:?}.", (mantissa, exp));
    }

    // invalid exponents
    let (min_exp, max_exp) = f64::exponent_limit();
    let f = fast_path::<f64>(mantissa, min_exp - 1);
    assert!(f.is_none(), "exponent under min_exp");

    let f = fast_path::<f64>(mantissa, max_exp + 1);
    assert!(f.is_none(), "exponent above max_exp");

    assert_eq!(
        Some(0.04628372940652459),
        fast_path::<f64>(4628372940652459, -17)
    );
    assert_eq!(None, fast_path::<f64>(26383446160308229, -272));
}
fn test_unsupported_format() {
    let result = new_ucmd!().arg("+%#z").fails();
    result.no_stdout();
    assert!(result.stderr_str().starts_with("date: invalid format %#z"));
}
fn exponent_fast_path_test() {
    assert_eq!(f32::min_exponent_fast_path(10), -10);
    assert_eq!(f32::max_exponent_fast_path(10), 10);
    assert_eq!(f32::max_exponent_disguised_fast_path(10), 17);

    assert_eq!(f64::min_exponent_fast_path(10), -22);
    assert_eq!(f64::max_exponent_fast_path(10), 22);
    assert_eq!(f64::max_exponent_disguised_fast_path(10), 37);
}
fn serialize_not_overly_massive() -> Result<()> {
    let mut config = Config::new();
    config.memory_guaranteed_dense_image_size(1 << 20);
    let engine = Engine::new(&config)?;

    let assert_smaller_than_1mb = |module: &str| -> Result<()> {
        println!("{}", module);
        let bytes = Module::new(&engine, module)?.serialize()?;
        assert!(bytes.len() < (1 << 20));
        Ok(())
    };

    // Tons of space between data segments should use sparse initialization,
    // along with various permutations of empty and nonempty segments.
    assert_smaller_than_1mb(
        r#"(module
            (memory 20000)
            (data (i32.const 0) "a")
            (data (i32.const 0x200000) "b")
        )"#,
    )?;
    assert_smaller_than_1mb(
        r#"(module
            (memory 20000)
            (data (i32.const 0) "a")
            (data (i32.const 0x200000) "")
        )"#,
    )?;
    assert_smaller_than_1mb(
        r#"(module
            (memory 20000)
            (data (i32.const 0) "")
            (data (i32.const 0x200000) "b")
        )"#,
    )?;
    assert_smaller_than_1mb(
        r#"(module
            (memory 20000)
            (data (i32.const 0) "")
            (data (i32.const 0x200000) "")
        )"#,
    )?;

    // lone data segment
    assert_smaller_than_1mb(
        r#"(module
            (memory 20000)
            (data (i32.const 0x200000) "b")
        )"#,
    )?;

    Ok(())
}
fn test_log10_pow5() {
    assert_eq!(0, log10_pow5(0));
    assert_eq!(0, log10_pow5(1));
    assert_eq!(1, log10_pow5(2));
    assert_eq!(2, log10_pow5(3));
    assert_eq!(2, log10_pow5(4));
    assert_eq!(1831, log10_pow5(2620));
}
fn test_hex_suffix_no_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-l", "9", "--hex-suffixes", "onehundredlines.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x00"), "00\n01\n02\n03\n04\n05\n06\n07\n08\n");
    assert_eq!(at.read("x01"), "09\n10\n11\n12\n13\n14\n15\n16\n17\n");
    assert_eq!(at.read("x02"), "18\n19\n20\n21\n22\n23\n24\n25\n26\n");
    assert_eq!(at.read("x03"), "27\n28\n29\n30\n31\n32\n33\n34\n35\n");
    assert_eq!(at.read("x04"), "36\n37\n38\n39\n40\n41\n42\n43\n44\n");
    assert_eq!(at.read("x05"), "45\n46\n47\n48\n49\n50\n51\n52\n53\n");
    assert_eq!(at.read("x06"), "54\n55\n56\n57\n58\n59\n60\n61\n62\n");
    assert_eq!(at.read("x07"), "63\n64\n65\n66\n67\n68\n69\n70\n71\n");
    assert_eq!(at.read("x08"), "72\n73\n74\n75\n76\n77\n78\n79\n80\n");
    assert_eq!(at.read("x09"), "81\n82\n83\n84\n85\n86\n87\n88\n89\n");
    assert_eq!(at.read("x0a"), "90\n91\n92\n93\n94\n95\n96\n97\n98\n");
    assert_eq!(at.read("x0b"), "99\n");
}
fn valid_context_directory() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.mkdir("a");
    dir.symlink_dir("a", "la");

    let b_path = Path::new("a").join("b.txt");
    dir.touch(b_path.to_str().unwrap());

    let la_context = get_file_context(dir.plus("la")).unwrap();
    let b_context = get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap();

    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    cmd.args(&["--verbose", new_la_context])
        .arg(dir.plus("la"))
        .succeeds();
    assert_eq!(get_file_context(dir.plus("la")).unwrap(), la_context);
    assert_eq!(
        get_file_context(dir.plus("a")).unwrap().as_deref(),
        Some(new_la_context)
    );
    assert_eq!(
        get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap(),
        b_context
    );
}
fn parse_set_array() {
    let ast = parse("{% set hello = [1, true, 'hello'] %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Set(
            WS::default(),
            Set {
                key: "hello".to_string(),
                value: Expr::new(ExprVal::Array(vec![
                    Expr::new(ExprVal::Int(1)),
                    Expr::new(ExprVal::Bool(true)),
                    Expr::new(ExprVal::String("hello".to_string())),
                ])),
                global: false,
            },
        )
    );
}
fn format_properties_test() {
    let format = NumberFormat::<{ STANDARD }> {};
    assert_eq!(format.flags(), STANDARD & format::FLAG_MASK);
    assert_eq!(format.interface_flags(), STANDARD & format::INTERFACE_FLAG_MASK);
    assert_eq!(format.digit_separator(), b'\x00');
    assert_eq!(format.base_prefix(), b'\x00');
    assert_eq!(format.base_suffix(), b'\x00');
    assert_eq!(format.mantissa_radix(), 10);
    assert_eq!(format.radix(), 10);
    assert_eq!(format.exponent_base(), 10);
    assert_eq!(format.exponent_radix(), 10);
    assert_eq!(format.required_integer_digits(), false);
    assert_eq!(format.required_fraction_digits(), false);
    assert_eq!(format.required_exponent_digits(), true);
    assert_eq!(format.required_mantissa_digits(), true);
    assert_eq!(format.required_digits(), true);
    assert_eq!(format.no_positive_mantissa_sign(), false);
    assert_eq!(format.required_mantissa_sign(), false);
    assert_eq!(format.no_exponent_notation(), false);
    assert_eq!(format.no_positive_exponent_sign(), false);
    assert_eq!(format.required_exponent_sign(), false);
    assert_eq!(format.no_exponent_without_fraction(), false);
    assert_eq!(format.no_special(), false);
    assert_eq!(format.case_sensitive_special(), false);
    assert_eq!(format.no_integer_leading_zeros(), false);
    assert_eq!(format.no_float_leading_zeros(), false);
    assert_eq!(format.required_exponent_notation(), false);
    assert_eq!(format.case_sensitive_exponent(), false);
    assert_eq!(format.case_sensitive_base_prefix(), false);
    assert_eq!(format.case_sensitive_base_suffix(), false);
    assert_eq!(format.integer_internal_digit_separator(), false);
    assert_eq!(format.fraction_internal_digit_separator(), false);
    assert_eq!(format.exponent_internal_digit_separator(), false);
    assert_eq!(format.internal_digit_separator(), false);
    assert_eq!(format.integer_leading_digit_separator(), false);
    assert_eq!(format.fraction_leading_digit_separator(), false);
    assert_eq!(format.exponent_leading_digit_separator(), false);
    assert_eq!(format.leading_digit_separator(), false);
    assert_eq!(format.integer_trailing_digit_separator(), false);
    assert_eq!(format.fraction_trailing_digit_separator(), false);
    assert_eq!(format.exponent_trailing_digit_separator(), false);
    assert_eq!(format.trailing_digit_separator(), false);
    assert_eq!(format.integer_consecutive_digit_separator(), false);
    assert_eq!(format.fraction_consecutive_digit_separator(), false);
    assert_eq!(format.exponent_consecutive_digit_separator(), false);
    assert_eq!(format.consecutive_digit_separator(), false);
    assert_eq!(format.special_digit_separator(), false);
}
fn decode_error_size() {
    assert_eq!(std::mem::size_of::<bincode::error::DecodeError>(), 32);
}
fn to_decimal_test() {
    assert_eq!(to_decimal_f32(0.0), (0, 0));
    assert_eq!(to_decimal_f32(0.5), (5, -1));
    assert_eq!(to_decimal_f32(1.0), (1, 0));
    assert_eq!(to_decimal_f32(1.5), (15, -1));
    assert_eq!(to_decimal_f32(1.23456), (123456, -5));
    assert_eq!(to_decimal_f32(2.3786281e+38), (23786281, 31));
    assert_eq!(to_decimal_f32(2147481600.0), (21474816, 2));
    assert_eq!(to_decimal_f32(2147483600.0), (21474836, 2));
    assert_eq!(to_decimal_f32(2762159900.0), (27621599, 2));
    assert_eq!(to_decimal_f32(77371252000000000000000000.0), (77371252, 18));

    assert_eq!(to_decimal_f64(0.0), (0, 0));
    assert_eq!(to_decimal_f64(0.5), (5, -1));
    assert_eq!(to_decimal_f64(1.0), (1, 0));
    assert_eq!(to_decimal_f64(1.5), (15, -1));
    assert_eq!(to_decimal_f64(1.23456), (123456, -5));
    assert_eq!(to_decimal_f64(2.2250738585072014e-308), (22250738585072014, -324));
    assert_eq!(to_decimal_f64(1.7976931348623157e+308), (17976931348623157, 292));
}
fn test_trailing_comma_map() {
    assert!(from_str::<HashMap<i32, bool>>("{1:false,2:true}").is_ok());
    assert!(from_str::<HashMap<i32, bool>>("{1:false,2:true,}").is_ok());
    assert!(from_str::<HashMap<i32, bool>>("{1:false,2:true,,}").is_err());
}
fn parse_create_or_replace_table() {
    let sql = "CREATE OR REPLACE TABLE t (a INT)";

    match verified_stmt(sql) {
        Statement::CreateTable {
            name, or_replace, ..
        } => {
            assert_eq!(name.to_string(), "t".to_string());
            assert!(or_replace);
        }
        _ => unreachable!(),
    }

    let sql = "CREATE TABLE t (a INT, b INT) AS SELECT 1 AS b, 2 AS a";
    match verified_stmt(sql) {
        Statement::CreateTable { columns, query, .. } => {
            assert_eq!(columns.len(), 2);
            assert_eq!(columns[0].to_string(), "a INT".to_string());
            assert_eq!(columns[1].to_string(), "b INT".to_string());
            assert_eq!(
                query,
                Some(Box::new(verified_query("SELECT 1 AS b, 2 AS a")))
            );
        }
        _ => unreachable!(),
    }
}
fn parse_variable_tag_global_function() {
    let ast = parse("{{ get_time(some=1) }}").unwrap();
    let mut args = HashMap::new();
    args.insert("some".to_string(), Expr::new(ExprVal::Int(1)));

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::FunctionCall(FunctionCall { name: "get_time".to_string(), args },))
        )
    );
}
fn test_symlink_overwrite_force() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_symlink_overwrite_force_a";
    let file_b = "test_symlink_overwrite_force_b";
    let link = "test_symlink_overwrite_force_link";

    // Create symlink
    at.symlink_file(file_a, link);
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file_a);

    // Force overwrite of existing symlink
    ucmd.args(&["--force", "-s", file_b, link]).succeeds();
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file_b);
}
fn test_pd_client_heartbeat_send_failed() {
    let pd_client_send_fail_fp = "region_heartbeat_send_failed";
    fail::cfg(pd_client_send_fail_fp, "return()").unwrap();
    let server = MockServer::with_case(1, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();

    let client = new_client(eps, None);
    let poller = Builder::new_multi_thread()
        .thread_name(thd_name!("poller"))
        .worker_threads(1)
        .build()
        .unwrap();
    let (tx, rx) = mpsc::channel();
    let f =
        client.handle_region_heartbeat_response(1, move |resp| tx.send(resp).unwrap_or_default());
    poller.spawn(f);

    let heartbeat_send_fail = |ok| {
        let mut region = metapb::Region::default();
        region.set_id(1);
        poller.spawn(client.region_heartbeat(
            store::RAFT_INIT_LOG_TERM,
            region,
            metapb::Peer::default(),
            RegionStat::default(),
            None,
        ));
        let rsp = rx.recv_timeout(Duration::from_millis(100));
        if ok {
            assert!(rsp.is_ok());
            assert_eq!(rsp.unwrap().get_region_id(), 1);
        } else {
            rsp.unwrap_err();
        }

        let region = block_on(client.get_region_by_id(1));
        if ok {
            assert!(region.is_ok());
            let r = region.unwrap();
            assert!(r.is_some());
            assert_eq!(1, r.unwrap().get_id());
        } else {
            region.unwrap_err();
        }
    };
    // send fail if network is block.
    heartbeat_send_fail(false);
    fail::remove(pd_client_send_fail_fp);
    // send success after network recovered.
    heartbeat_send_fail(true);
}
fn vba() {
    setup();

    let path = format!("{}/tests/vba.xlsm", env!("CARGO_MANIFEST_DIR"));
    let mut excel: Xlsx<_> = open_workbook(&path).unwrap();

    let mut vba = excel.vba_project().unwrap().unwrap();
    assert_eq!(
        vba.to_mut().get_module("testVBA").unwrap(),
        "Attribute VB_Name = \"testVBA\"\r\nPublic Sub test()\r\n    MsgBox \"Hello from \
         vba!\"\r\nEnd Sub\r\n"
    );
}
fn hi_test() {
    assert_eq!(unsafe { bigint::nonzero(&[0, 0, 0], 0) }, false);
    assert_eq!(unsafe { bigint::nonzero(&[1, 0, 0], 0) }, true);

    assert_eq!(bigint::u32_to_hi16_1(1), (0x8000, false));
    assert_eq!(bigint::u32_to_hi16_2(1, 4), (0x8000, true));
    assert_eq!(bigint::u32_to_hi32_1(1), (0x80000000, false));
    assert_eq!(bigint::u32_to_hi32_2(1, 4), (0x80000002, false));
    assert_eq!(bigint::u32_to_hi64_1(1), (0x8000000000000000, false));
    assert_eq!(bigint::u32_to_hi64_2(1, 4), (0x8000000200000000, false));
    assert_eq!(bigint::u32_to_hi64_2(1, 5), (0x8000000280000000, false));
    assert_eq!(bigint::u32_to_hi64_3(1, 5, 4), (0x8000000280000002, false));
    assert_eq!(bigint::u32_to_hi64_3(1, 5, 5), (0x8000000280000002, true));

    assert_eq!(bigint::u64_to_hi16_1(1), (0x8000, false));
    assert_eq!(bigint::u64_to_hi16_2(1, 4), (0x8000, true));
    assert_eq!(bigint::u64_to_hi32_1(1), (0x80000000, false));
    assert_eq!(bigint::u64_to_hi32_2(1, 4), (0x80000000, true));
    assert_eq!(bigint::u64_to_hi64_1(1), (0x8000000000000000, false));
    assert_eq!(bigint::u64_to_hi64_2(1, 4), (0x8000000000000002, false));
    assert_eq!(bigint::u64_to_hi64_2(1, 5), (0x8000000000000002, true));
}
fn take_till_issue() {
  use nom::bytes::streaming::take_till;

  fn nothing(i: &[u8]) -> IResult<&[u8], &[u8]> {
    take_till(|_| true)(i)
  }

  assert_eq!(nothing(b""), Err(Err::Incomplete(Needed::new(1))));
  assert_eq!(nothing(b"abc"), Ok((&b"abc"[..], &b""[..])));
}
fn parse_empty_template() {
    let ast = parse("").unwrap();
    assert_eq!(ast.len(), 0);
}
fn test_split_bytes_prime_part_size() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "test_split_bytes_prime_part_size";
    RandomFile::new(&at, name).add_bytes(10000);
    // 1753 is prime and greater than the buffer size, 1024.
    ucmd.args(&["-b", "1753", name, "b"]).succeeds();

    let glob = Glob::new(&at, ".", r"b[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 6);
    let mut fns = glob.collect();
    // glob.collect() is not guaranteed to return in sorted order, so we sort.
    fns.sort();
    #[allow(clippy::needless_range_loop)]
    for i in 0..5 {
        assert_eq!(glob.directory.metadata(&fns[i]).len(), 1753);
    }
    assert_eq!(glob.directory.metadata(&fns[5]).len(), 1235);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_chmod_keep_setgid() {
    for (from, arg, to) in [
        (0o7777, "777", 0o46777),
        (0o7777, "=777", 0o40777),
        (0o7777, "0777", 0o46777),
        (0o7777, "=0777", 0o40777),
        (0o7777, "00777", 0o40777),
        (0o2444, "a+wx", 0o42777),
        (0o2444, "a=wx", 0o42333),
        (0o1444, "g+s", 0o43444),
        (0o4444, "u-s", 0o40444),
        (0o7444, "a-s", 0o41444),
    ] {
        let (at, mut ucmd) = at_and_ucmd!();
        at.mkdir("dir");
        set_permissions(at.plus("dir"), Permissions::from_mode(from)).unwrap();
        let r = ucmd.arg(arg).arg("dir").succeeds();
        println!("{}", r.stderr_str());
        assert_eq!(at.metadata("dir").permissions().mode(), to);
    }
}
fn cid_retirement() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    // Server retires current active remote CIDs
    pair.server_conn_mut(server_ch)
        .rotate_local_cid(1, Instant::now());
    pair.drive();
    // Any unexpected behavior may trigger TransportError::CONNECTION_ID_LIMIT_ERROR
    assert!(!pair.client_conn_mut(client_ch).is_closed());
    assert!(!pair.server_conn_mut(server_ch).is_closed());
    assert_matches!(pair.client_conn_mut(client_ch).active_rem_cid_seq(), 1);

    use crate::cid_queue::CidQueue;
    use crate::LOC_CID_COUNT;
    let mut active_cid_num = CidQueue::LEN as u64;
    active_cid_num = active_cid_num.min(LOC_CID_COUNT);

    let next_retire_prior_to = active_cid_num + 1;
    pair.client_conn_mut(client_ch).ping();
    // Server retires all valid remote CIDs
    pair.server_conn_mut(server_ch)
        .rotate_local_cid(next_retire_prior_to, Instant::now());
    pair.drive();
    assert!(!pair.client_conn_mut(client_ch).is_closed());
    assert!(!pair.server_conn_mut(server_ch).is_closed());
    assert_matches!(
        pair.client_conn_mut(client_ch).active_rem_cid_seq(),
        _next_retire_prior_to
    );
}
fn lex_test() {
    let inputs =
        vec!["a is defined", "a is defined()", "a is divisibleby(2)", "a is in([1, 2, something])"];
    for i in inputs {
        // The () are not counted as tokens for some reasons so can't use the macro
        assert!(TeraParser::parse(Rule::test, i).is_ok());
    }
}
fn test_pessimistic_lock_check_valid() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));
    let txn_ext = cluster
        .must_get_snapshot_of_region(1)
        .ext()
        .get_txn_ext()
        .unwrap()
        .clone();

    let region = cluster.get_region(b"");
    let leader = region.get_peers()[0].clone();
    fail::cfg("acquire_pessimistic_lock", "pause").unwrap();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let mut mutation = pb::Mutation::default();
    mutation.set_op(Op::PessimisticLock);
    mutation.key = b"key".to_vec();
    let mut req = PessimisticLockRequest::default();
    req.set_context(ctx.clone());
    req.set_mutations(vec![mutation].into());
    req.set_start_version(10);
    req.set_for_update_ts(10);
    req.set_primary_lock(b"key".to_vec());

    let lock_resp = thread::spawn(move || client.kv_pessimistic_lock(&req).unwrap());
    thread::sleep(Duration::from_millis(300));
    // Set `status` to `TransferringLeader` to make the locks table not writable,
    // but the region remains available to serve.
    txn_ext.pessimistic_locks.write().status = LocksStatus::TransferringLeader;
    fail::remove("acquire_pessimistic_lock");

    let resp = lock_resp.join().unwrap();
    // There should be no region error.
    assert!(!resp.has_region_error());
    // The lock should not be written to the in-memory pessimistic lock table.
    assert!(txn_ext.pessimistic_locks.read().is_empty());
}
fn range_query() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(SLICE_U64_TABLE).unwrap();
        for i in 0..5 {
            table.insert(b"0".as_slice(), &i).unwrap();
        }
        for i in 5..10 {
            table.insert(b"1".as_slice(), &i).unwrap();
        }
        for i in 10..15 {
            table.insert(b"2".as_slice(), &i).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(SLICE_U64_TABLE).unwrap();
    let start = b"0".as_ref();
    let end = b"1".as_ref();
    let mut iter = table.range(start..=end).unwrap();

    {
        let (key, mut values) = iter.next().unwrap().unwrap();
        for i in 0..5 {
            assert_eq!(b"0", key.value());
            let value = values.next().unwrap().unwrap();
            assert_eq!(i, value.value());
        }
    }
    {
        let (key, mut values) = iter.next().unwrap().unwrap();
        for i in 5..10 {
            assert_eq!(b"1", key.value());
            let value = values.next().unwrap().unwrap();
            assert_eq!(i, value.value());
        }
    }
    assert!(iter.next().is_none());

    let mut total: u64 = 0;
    for item in table.range(start..=end).unwrap() {
        let (_, values) = item.unwrap();
        total += values.map(|x| x.unwrap().value()).sum::<u64>();
    }
    assert_eq!(total, 45);
}
fn test_not_invoke_committed_cb_when_fail_to_commit() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.pd_client.disable_default_operator();
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k", b"v");

    // Partition the leader and followers to let the leader fails to commit the
    // proposal.
    cluster.partition(vec![1], vec![2, 3]);
    let write_req = make_write_req(&mut cluster, b"k1");
    let (cb, mut cb_receivers) = make_cb(&write_req);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, write_req, cb)
        .unwrap();
    // Check the request is proposed but not committed.
    cb_receivers
        .committed
        .recv_timeout(Duration::from_millis(200))
        .unwrap_err();
    cb_receivers.proposed.try_recv().unwrap();

    // The election timeout is 250ms by default.
    let election_timeout = cluster.cfg.raft_store.raft_base_tick_interval.0
        * cluster.cfg.raft_store.raft_election_timeout_ticks as u32;
    std::thread::sleep(2 * election_timeout);

    // Make sure a new leader is elected and will discard the previous proposal when
    // partition is recovered.
    cluster.must_put(b"k2", b"v");
    cluster.clear_send_filters();

    let resp = cb_receivers
        .applied
        .recv_timeout(Duration::from_secs(1))
        .unwrap();
    assert!(resp.get_header().has_error(), "{:?}", resp);
    // The committed callback shouldn't be invoked.
    cb_receivers.committed.try_recv().unwrap_err();
}
fn static_duplicate_works() {
    let (mut store, duplicate, duplicate_dyn) = setup_duplicate();
    let duplicate = duplicate.typed::<i32, (i32, i32)>(&mut store).unwrap();
    let duplicate_dyn = duplicate_dyn.typed::<i32, (i32, i32)>(&mut store).unwrap();
    for input in 0..10 {
        assert_eq!(duplicate.call(&mut store, input).unwrap(), (input, input));
        assert_eq!(
            duplicate_dyn.call(&mut store, input).unwrap(),
            (input, input)
        );
    }
}
fn ci_does_not_run_formatter_via_cli() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let input_file = Path::new("file.js");
    fs.insert(input_file.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                ("--formatter-enabled=false"),
                input_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(input_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_does_not_run_formatter_via_cli",
        fs,
        console,
        result,
    ));
}
async fn sync_then_async_trap() -> Result<()> {
    // Test the trapping and capturing the stack with the following sequence of
    // calls:
    //
    // a[sync] ---> b[host] ---> c[async]

    drop(env_logger::try_init());

    let wat = r#"
        (module
            (import "" "b" (func $b))
            (func $a (export "a")
                call $b
            )
            (func $c (export "c")
                unreachable
            )
        )
    "#;

    let mut async_store = Store::new(&Engine::new(Config::new().async_support(true)).unwrap(), ());

    let async_module = Module::new(async_store.engine(), wat)?;

    let mut async_linker = Linker::new(async_store.engine());
    async_linker.func_wrap("", "b", |_caller: Caller<_>| unreachable!())?;

    let async_instance = async_linker
        .instantiate_async(&mut async_store, &async_module)
        .await?;

    struct SyncCtx {
        async_instance: Instance,
        async_store: Store<()>,
    }

    let mut sync_store = Store::new(
        &Engine::default(),
        SyncCtx {
            async_instance,
            async_store,
        },
    );

    let sync_module = Module::new(sync_store.engine(), wat)?;

    let mut sync_linker = Linker::new(sync_store.engine());
    sync_linker.func_wrap("", "b", move |mut caller: Caller<SyncCtx>| -> Result<()> {
        log::info!("Called `b`...");
        let async_instance = caller.data().async_instance;
        let async_store = &mut caller.data_mut().async_store;

        log::info!("Calling `c`...");
        let c = async_instance
            .get_typed_func::<(), ()>(&mut *async_store, "c")
            .unwrap();
        tokio::task::block_in_place(|| {
            tokio::runtime::Handle::current()
                .block_on(async move { c.call_async(async_store, ()).await })
        })?;
        Ok(())
    })?;

    let sync_instance = sync_linker.instantiate(&mut sync_store, &sync_module)?;

    log::info!("Calling `a`...");
    let a = sync_instance
        .get_typed_func::<(), ()>(&mut sync_store, "a")
        .unwrap();
    let trap = a.call(&mut sync_store, ()).unwrap_err();

    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();
    // We don't support cross-store or cross-engine symbolication currently, so
    // the other frames are ignored.
    assert_eq!(trace.len(), 1);
    assert_eq!(trace[0].func_name(), Some("c"));

    Ok(())
}
fn test_install_backup_custom_suffix_via_env() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_custom_suffix_file_a";
    let file_b = "test_install_backup_custom_suffix_file_b";
    let suffix = "super-suffix-of-the-century";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("-b")
        .env("SIMPLE_BACKUP_SUFFIX", suffix)
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn capture_index_lifetime() {
    // This is a test of whether the types on `caps["..."]` are general
    // enough. If not, this will fail to typecheck.
    fn inner(s: &str) -> usize {
        let re = regex!(r"(?P<number>\d+)");
        let caps = re.captures(t!(s)).unwrap();
        caps["number"].len()
    }
    assert_eq!(3, inner("123"));
}
fn does_render_owned_for_loop_with_objects() {
    let mut context = Context::new();
    let data = json!([
        {"id": 1, "year": 2015},
        {"id": 2, "year": 2015},
        {"id": 3, "year": 2016},
        {"id": 4, "year": 2017},
        {"id": 5, "year": 2017},
        {"id": 6, "year": 2017},
        {"id": 7, "year": 2018},
        {"id": 8},
        {"id": 9, "year": null},
    ]);
    context.insert("something", &data);

    let tpl =
        r#"{% for year, things in something | group_by(attribute="year") %}{{year}},{% endfor %}"#;
    let expected = "2015,2016,2017,2018,";
    assert_eq!(render_template(tpl, &context).unwrap(), expected);
}
fn test_u128_max() {
    assert_eq!(
        std::u128::MAX,
        from_str(&to_string(&std::u128::MAX).unwrap()).unwrap()
    );
}
fn resolve() {
    let f = super::fixture();

    let resolver = Resolver::default();

    let main1_js_path = f.join("main1.js").to_string_lossy().to_string();

    #[rustfmt::skip]
    let pass = [
        ("absolute path", f.clone(), main1_js_path.as_str(), f.join("main1.js")),
        ("file with .js", f.clone(), "./main1.js", f.join("main1.js")),
        ("file without extension", f.clone(), "./main1", f.join("main1.js")),
        ("another file with .js", f.clone(), "./a.js", f.join("a.js")),
        ("another file without extension", f.clone(), "./a", f.join("a.js")),
        ("file in module with .js", f.clone(), "m1/a.js", f.join("node_modules/m1/a.js")),
        ("file in module without extension", f.clone(), "m1/a", f.join("node_modules/m1/a.js")),
        ("another file in module without extension", f.clone(), "complexm/step1", f.join("node_modules/complexm/step1.js")),
        ("from submodule to file in sibling module", f.join("node_modules/complexm"), "m2/b.js", f.join("node_modules/m2/b.js")),
        ("from nested directory to overwritten file in module", f.join("multiple_modules"), "m1/a.js", f.join("multiple_modules/node_modules/m1/a.js")),
        ("from nested directory to not overwritten file in module", f.join("multiple_modules"), "m1/b.js", f.join("node_modules/m1/b.js")),
        ("file with query", f.clone(), "./main1.js?query", f.join("main1.js?query")),
        ("file with fragment", f.clone(), "./main1.js#fragment", f.join("main1.js#fragment")),
        ("file with fragment and query", f.clone(), "./main1.js#fragment?query", f.join("main1.js#fragment?query")),
        ("file with query and fragment", f.clone(), "./main1.js?#fragment", f.join("main1.js?#fragment")),
        ("file in module with query", f.clone(), "m1/a?query", f.join("node_modules/m1/a.js?query")),
        ("file in module with fragment", f.clone(), "m1/a#fragment", f.join("node_modules/m1/a.js#fragment")),
        ("file in module with fragment and query", f.clone(), "m1/a#fragment?query", f.join("node_modules/m1/a.js#fragment?query")),
        ("file in module with query and fragment", f.clone(), "m1/a?#fragment", f.join("node_modules/m1/a.js?#fragment")),
        ("file in module with query and fragment", f.clone(), "m1/a?#fragment", f.join("node_modules/m1/a.js?#fragment")),
        ("differ between directory and file, resolve file", f.clone(), "./dirOrFile", f.join("dirOrFile.js")),
        ("differ between directory and file, resolve directory", f.clone(), "./dirOrFile/", f.join("dirOrFile/index.js")),
        ("find node_modules outside of node_modules", f.join("browser-module/node_modules"), "m1/a", f.join("node_modules/m1/a.js")),
        ("don't crash on main field pointing to self", f.clone(), "./main-field-self", f.join("./main-field-self/index.js")),
        ("don't crash on main field pointing to self (2)", f.clone(), "./main-field-self2", f.join("./main-field-self2/index.js")),
        // enhanced-resolve has `#` prepended with a `\0`, they are removed from the
        // following 3 expected test results.
        // See https://github.com/webpack/enhanced-resolve#escaping
        ("handle fragment edge case (no fragment)", f.clone(), "./no#fragment/#/#", f.join("no#fragment/#/#.js")),
        ("handle fragment edge case (fragment)", f.clone(), "./no#fragment/#/", f.join("no.js#fragment/#/")),
        ("handle fragment escaping", f.clone(), "./no\0#fragment/\0#/\0##fragment", f.join("no#fragment/#/#.js#fragment")),
    ];

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn compute_nearest_normal_test() {
    assert_eq!(compute_nearest_normal(1.23456), (123456, -5));
    assert_eq!(compute_nearest_normal(13.9999999999999982236431606), (13999999999999998, -15));
}
fn ci_lint_error() {
    let mut fs = MemoryFileSystem::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), LINT_ERROR.as_bytes());

    let mut console = BufferConsole::default();
    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_lint_error",
        fs,
        console,
        result,
    ));
}
fn is_left_endpoint_test() {
    assert_eq!(algorithm::is_left_endpoint::<f64>(1), false);
    assert_eq!(algorithm::is_left_endpoint::<f64>(2), true);
    assert_eq!(algorithm::is_left_endpoint::<f64>(3), true);
    assert_eq!(algorithm::is_left_endpoint::<f64>(4), false);
}
fn render_images_identity() {
    process_images("results_identity.txt", &TEST_SUITES, |path| {
        let decoder = png::Decoder::new(File::open(&path)?);
        let mut reader = decoder.read_info()?;
        let mut img_data = vec![0; reader.output_buffer_size()];
        let info = reader.next_frame(&mut img_data)?;
        let bits =
            ((info.width as usize * info.color_type.samples() * info.bit_depth as usize + 7) & !7)
                * info.height as usize;
        // First sanity check:
        assert_eq!(
            img_data.len() * 8,
            bits,
            "path: {} info: {:?} bits: {}",
            path.display(),
            info,
            bits
        );
        let mut crc = Crc32::new();
        crc.update(&img_data);
        Ok(crc.finalize())
    });
}
fn parse_floor_datetime() {
    let sql = "SELECT FLOOR(d TO DAY)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Floor {
            expr: Box::new(Expr::Identifier(Ident::new("d"))),
            field: DateTimeField::Day,
        },
        expr_from_projection(only(&select.projection)),
    );

    one_statement_parses_to("SELECT FLOOR(d to day)", "SELECT FLOOR(d TO DAY)");

    verified_stmt("SELECT FLOOR(d TO HOUR) FROM df");
    verified_stmt("SELECT FLOOR(d TO MINUTE) FROM df");
    verified_stmt("SELECT FLOOR(d TO SECOND) FROM df");
    verified_stmt("SELECT FLOOR(d TO MILLISECOND) FROM df");

    let res = parse_sql_statements("SELECT FLOOR(d TO JIFFY) FROM df");
    assert_eq!(
        ParserError::ParserError("Expected date/time field, found: JIFFY".to_string()),
        res.unwrap_err()
    );
}
fn fs_error_infinite_symlink_expansion_to_files() {
    let mut console = BufferConsole::default();

    let root_path = temp_dir().join("check_rome_test_infinite_symlink_expansion_to_files");
    let subdir1_path = root_path.join("prefix");
    let subdir2_path = root_path.join("foo").join("bar");

    let _ = remove_dir_all(&root_path);
    create_dir_all(&subdir1_path).unwrap();
    create_dir_all(&subdir2_path).unwrap();

    let symlink1_path = subdir1_path.join("symlink1");
    let symlink2_path = subdir2_path.join("symlink2");

    #[cfg(target_family = "unix")]
    {
        symlink(&symlink2_path, &symlink1_path).unwrap();
        symlink(&symlink1_path, &symlink2_path).unwrap();
    }

    #[cfg(target_os = "windows")]
    {
        check_windows_symlink!(symlink_dir(&symlink2_path, &symlink1_path));
        check_windows_symlink!(symlink_dir(&symlink1_path, &symlink2_path));
    }

    let result = run_cli(
        DynRef::Owned(Box::new(OsFileSystem)),
        &mut console,
        Args::from([("check"), (root_path.display().to_string().as_str())].as_slice()),
    );

    remove_dir_all(root_path).unwrap();

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Don't use a snapshot here, since the diagnostics can be reported in
    // arbitrary order:
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains("Deeply nested symlink expansion")));
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains(&symlink1_path.display().to_string())));
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains(&symlink2_path.display().to_string())));
}
fn parse_alter_table_constraints() {
    check_one("CONSTRAINT address_pkey PRIMARY KEY (address_id)");
    check_one("CONSTRAINT uk_task UNIQUE (report_date, task_id)");
    check_one(
        "CONSTRAINT customer_address_id_fkey FOREIGN KEY (address_id) \
         REFERENCES public.address(address_id)",
    );
    check_one("CONSTRAINT ck CHECK (rtrim(ltrim(REF_CODE)) <> '')");

    check_one("PRIMARY KEY (foo, bar)");
    check_one("UNIQUE (id)");
    check_one("FOREIGN KEY (foo, bar) REFERENCES AnotherTable(foo, bar)");
    check_one("CHECK (end_date > start_date OR end_date IS NULL)");

    fn check_one(constraint_text: &str) {
        match alter_table_op(verified_stmt(&format!(
            "ALTER TABLE tab ADD {constraint_text}"
        ))) {
            AlterTableOperation::AddConstraint(constraint) => {
                assert_eq!(constraint_text, constraint.to_string());
            }
            _ => unreachable!(),
        }
        verified_stmt(&format!("CREATE TABLE foo (id INT, {constraint_text})"));
    }
}
fn to_f64_test() {
    // underflow
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -1138,
    };
    assert_eq!(x.into_float::<f64>(), 0.0);

    // min value
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -1137,
    };
    assert_eq!(x.into_float::<f64>(), 5e-324);

    // 1.0e-250
    let x = ExtendedFloat {
        mant: 13207363278391631872,
        exp: -894,
    };
    assert_eq!(x.into_float::<f64>(), 1e-250);

    // 1.0e-150
    let x = ExtendedFloat {
        mant: 15095849699286165504,
        exp: -562,
    };
    assert_eq!(x.into_float::<f64>(), 1e-150);

    // 1.0e-45
    let x = ExtendedFloat {
        mant: 13164036458569648128,
        exp: -213,
    };
    assert_eq!(x.into_float::<f64>(), 1e-45);

    // 1.0e-40
    let x = ExtendedFloat {
        mant: 10043362776618688512,
        exp: -196,
    };
    assert_eq!(x.into_float::<f64>(), 1e-40);

    // 1.0e-20
    let x = ExtendedFloat {
        mant: 13611294676837537792,
        exp: -130,
    };
    assert_eq!(x.into_float::<f64>(), 1e-20);

    // 1.0
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -63,
    };
    assert_eq!(x.into_float::<f64>(), 1.0);

    // 1e20
    let x = ExtendedFloat {
        mant: 12500000000000000000,
        exp: 3,
    };
    assert_eq!(x.into_float::<f64>(), 1e20);

    // 1e40
    let x = ExtendedFloat {
        mant: 16940658945086007296,
        exp: 69,
    };
    assert_eq!(x.into_float::<f64>(), 1e40);

    // 1e150
    let x = ExtendedFloat {
        mant: 11270725851789228032,
        exp: 435,
    };
    assert_eq!(x.into_float::<f64>(), 1e150);

    // 1e250
    let x = ExtendedFloat {
        mant: 12882297539194265600,
        exp: 767,
    };
    assert_eq!(x.into_float::<f64>(), 1e250);

    // max value
    let x = ExtendedFloat {
        mant: 9007199254740991,
        exp: 971,
    };
    assert_eq!(x.into_float::<f64>(), 1.7976931348623157e308);

    // max value
    let x = ExtendedFloat {
        mant: 18446744073709549568,
        exp: 960,
    };
    assert_eq!(x.into_float::<f64>(), 1.7976931348623157e308);

    // overflow
    let x = ExtendedFloat {
        mant: 9007199254740992,
        exp: 971,
    };
    assert_eq!(x.into_float::<f64>(), f64::INFINITY);

    // overflow
    let x = ExtendedFloat {
        mant: 18446744073709549568,
        exp: 961,
    };
    assert_eq!(x.into_float::<f64>(), f64::INFINITY);

    // Underflow
    // Adapted from failures in strtod.
    let x = ExtendedFloat {
        exp: -1139,
        mant: 18446744073709550712,
    };
    assert_eq!(x.into_float::<f64>(), 0.0);

    let x = ExtendedFloat {
        exp: -1139,
        mant: 18446744073709551460,
    };
    assert_eq!(x.into_float::<f64>(), 0.0);

    let x = ExtendedFloat {
        exp: -1138,
        mant: 9223372036854776103,
    };
    assert_eq!(x.into_float::<f64>(), 5e-324);

    // Integers.
    for int in &INTEGERS {
        let fp = ExtendedFloat { mant: *int, exp: 0 };
        assert_eq!(fp.into_float::<f64>(), *int as f64, "{:?} as f64", *int);
    }
}
fn deflate_encoder_empty_read() {
    let original: &[u8] = b"Lorem ipsum dolor sit amet.";
    let mut encoder = flate2::read::DeflateEncoder::new(original, flate2::Compression::default());
    assert_eq!(encoder.read(&mut []).unwrap(), 0);
    let mut encoded = Vec::new();
    encoder.read_to_end(&mut encoded).unwrap();
    let mut decoder = flate2::read::DeflateDecoder::new(encoded.as_slice());
    let mut decoded = Vec::new();
    decoder.read_to_end(&mut decoded).unwrap();
    assert_eq!(decoded.as_slice(), original);
}
fn floor_log2_test() {
    assert_eq!(algorithm::floor_log2(25), 4);
    assert_eq!(algorithm::floor_log2(30), 4);
    assert_eq!(algorithm::floor_log2(125), 6);
    assert_eq!(algorithm::floor_log2(126), 6);
    assert_eq!(algorithm::floor_log2(128), 7);
}
fn parse_array_fn() {
    let sql = "SELECT array(x1, x2) FROM foo";
    let select = clickhouse().verified_only_select(sql);
    assert_eq!(
        &Expr::Function(Function {
            name: ObjectName(vec![Ident::new("array")]),
            args: vec![
                FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::Identifier(Ident::new("x1")))),
                FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::Identifier(Ident::new("x2")))),
            ],
            null_treatment: None,
            filter: None,
            over: None,
            distinct: false,
            special: false,
            order_by: vec![],
        }),
        expr_from_projection(only(&select.projection))
    );
}
fn test_cp_arg_backup_arg_first() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
fn test_touch_set_only_mtime() {
    let mtime_args = ["-m", "--time=modify", "--time=mtime"];
    let file = "test_touch_set_only_mtime";

    for mtime_arg in mtime_args {
        let (at, mut ucmd) = at_and_ucmd!();

        ucmd.args(&["-t", "201501011234", mtime_arg, file])
            .succeeds()
            .no_stderr();

        assert!(at.file_exists(file));

        let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");
        let (atime, mtime) = get_file_times(&at, file);
        assert!(atime != mtime);
        assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);
    }
}
fn invalid_exponent_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.exponent(b'\x00');
    assert!(!builder.is_valid());
    builder = builder.exponent(b'\x7f');
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.exponent(b'^');
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
}
fn vec_vec_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<u8, Vec<Vec<&str>>> = TableDefinition::new("x");

    let value = vec![vec!["hello", "world"], vec!["this", "is", "a", "test"]];
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(0, &value).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(value, table.get(0).unwrap().unwrap().value());
}
fn test_oct() {
    assert_eq!(from_str("0o1461"), Ok(0o1461));
    assert_eq!(from_str("0o051"), Ok(0o051));
    assert_eq!(from_str("0o150700"), Ok(0o150700));

    assert_eq!(
        from_str::<u8>("0o"),
        Err(SpannedError {
            code: Error::ExpectedInteger,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0o_1"),
        Err(SpannedError {
            code: Error::UnderscoreAtBeginning,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0o77777"),
        Err(SpannedError {
            code: Error::IntegerOutOfBounds,
            position: Position { line: 1, col: 8 },
        })
    );
}
fn applies_custom_trailing_comma() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), APPLY_TRAILING_COMMA_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--trailing-comma"),
                ("none"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, APPLY_TRAILING_COMMA_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_trailing_comma",
        fs,
        console,
        result,
    ));
}
fn test_adjacently_tagged_enum() {
    // Note: TestEnumAdjacent makes sense here since we are now treating
    //        the enum as a struct

    assert_eq!(
        ron::from_str::<TestEnumAdjacent>("(type: StructVariant, content: (d: 4))"),
        Err(SpannedError {
            code: Error::MissingStructField {
                field: "a",
                outer: Some(String::from("TestEnumAdjacent")),
            },
            position: Position { line: 1, col: 37 },
        })
    );
}
fn apply_ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_ok",
        fs,
        console,
        result,
    ));
}
fn render_multiple_inheritance_with_super() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        (
            "grandparent",
            "{% block hey %}hello{% endblock hey %} {% block ending %}sincerely{% endblock ending %}",
        ),
        (
            "parent",
            "{% extends \"grandparent\" %}{% block hey %}hi and grandma says {{ super() }}{% endblock hey %}",
        ),
        (
            "child",
            "{% extends \"parent\" %}{% block hey %}dad says {{ super() }}{% endblock hey %}{% block ending %}{{ super() }} with love{% endblock ending %}",
        ),
    ]).unwrap();
    let result = tera.render("child", &Context::new());

    assert_eq!(
        result.unwrap(),
        "dad says hi and grandma says hello sincerely with love".to_string()
    );
}
fn test_copy_into_with_stage_params() {
    let sql = concat!(
        "COPY INTO my_company.emp_basic ",
        "FROM 's3://load/files/' ",
        "STORAGE_INTEGRATION=myint ",
        "ENDPOINT='<s3_api_compatible_endpoint>' ",
        "CREDENTIALS=(AWS_KEY_ID='1a2b3c' AWS_SECRET_KEY='4x5y6z') ",
        "ENCRYPTION=(MASTER_KEY='key' TYPE='AWS_SSE_KMS')"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake {
            from_stage,
            stage_params,
            ..
        } => {
            //assert_eq!("s3://load/files/", stage_params.url.unwrap());
            assert_eq!(
                from_stage,
                ObjectName(vec![Ident::with_quote('\'', "s3://load/files/")])
            );
            assert_eq!("myint", stage_params.storage_integration.unwrap());
            assert_eq!(
                "<s3_api_compatible_endpoint>",
                stage_params.endpoint.unwrap()
            );
            assert!(stage_params
                .credentials
                .options
                .contains(&DataLoadingOption {
                    option_name: "AWS_KEY_ID".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "1a2b3c".to_string()
                }));
            assert!(stage_params
                .credentials
                .options
                .contains(&DataLoadingOption {
                    option_name: "AWS_SECRET_KEY".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "4x5y6z".to_string()
                }));
            assert!(stage_params
                .encryption
                .options
                .contains(&DataLoadingOption {
                    option_name: "MASTER_KEY".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "key".to_string()
                }));
            assert!(stage_params
                .encryption
                .options
                .contains(&DataLoadingOption {
                    option_name: "TYPE".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "AWS_SSE_KMS".to_string()
                }));
        }
        _ => unreachable!(),
    };

    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);

    // stage params within copy into with transformations
    let sql = concat!(
        "COPY INTO my_company.emp_basic FROM ",
        "(SELECT t1.$1 FROM 's3://load/files/' STORAGE_INTEGRATION=myint)",
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake {
            from_stage,
            stage_params,
            ..
        } => {
            assert_eq!(
                from_stage,
                ObjectName(vec![Ident::with_quote('\'', "s3://load/files/")])
            );
            assert_eq!("myint", stage_params.storage_integration.unwrap());
        }
        _ => unreachable!(),
    }
}
fn extension_alias() {
    let f = super::fixture().join("extension-alias");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        main_files: vec!["index.js".into()],
        extension_alias: vec![
            (".js".into(), vec![".ts".into(), ".js".into()]),
            (".mjs".into(), vec![".mts".into()]),
        ],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("should alias fully specified file", f.clone(), "./index.js", f.join("index.ts")),
        ("should alias fully specified file when there are two alternatives", f.clone(), "./dir/index.js", f.join("dir/index.ts")),
        ("should also allow the second alternative", f.clone(), "./dir2/index.js", f.join("dir2/index.js")),
        ("should support alias option without an array", f.clone(), "./dir2/index.mjs", f.join("dir2/index.mts")),
    ];

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }

    #[rustfmt::skip]
    let fail = [
        ("should not allow to fallback to the original extension or add extensions", f, "./index.mjs"),
    ];

    for (comment, path, request) in fail {
        let resolution = resolver.resolve(&path, request);
        assert_eq!(resolution, Err(ResolveError::ExtensionAlias), "{comment} {path:?} {request}");
    }
}
fn parse_create_materialized_view_with_cluster_by() {
    let sql = "CREATE MATERIALIZED VIEW myschema.myview CLUSTER BY (foo) AS SELECT foo FROM bar";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            or_replace,
            columns,
            query,
            materialized,
            with_options,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("myschema.myview", name.to_string());
            assert_eq!(Vec::<Ident>::new(), columns);
            assert_eq!("SELECT foo FROM bar", query.to_string());
            assert!(materialized);
            assert_eq!(with_options, vec![]);
            assert!(!or_replace);
            assert_eq!(cluster_by, vec![Ident::new("foo")]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(!temporary);
        }
        _ => unreachable!(),
    }
}
fn static_type_check_works() {
    let mut store = test_setup();
    let identity = Func::wrap(&mut store, |value: i32| value);
    // Case: Too few inputs given to function.
    assert_matches!(
        identity.typed::<(), i32>(&mut store),
        Err(Error::Func(FuncError::MismatchingParameterLen))
    );
    // Case: Too many inputs given to function.
    assert_matches!(
        identity.typed::<(i32, i32), i32>(&mut store),
        Err(Error::Func(FuncError::MismatchingParameterLen))
    );
    // Case: Too few results given to function.
    assert_matches!(
        identity.typed::<i32, ()>(&mut store),
        Err(Error::Func(FuncError::MismatchingResultLen))
    );
    // Case: Too many results given to function.
    assert_matches!(
        identity.typed::<i32, (i32, i32)>(&mut store),
        Err(Error::Func(FuncError::MismatchingResultLen))
    );
    // Case: Mismatching type given as input to function.
    assert_matches!(
        identity.typed::<i64, i32>(&mut store),
        Err(Error::Func(FuncError::MismatchingParameterType))
    );
    // Case: Mismatching type given as output of function.
    assert_matches!(
        identity.typed::<i32, i64>(&mut store),
        Err(Error::Func(FuncError::MismatchingResultType))
    );
}
pub fn test_multiple_subscribers() {
    let mut test_suite = TestSuite::new(resource_metering::Config {
        report_receiver_interval: ReadableDuration::secs(3),
        precision: ReadableDuration::secs(1),
        ..Default::default()
    });

    // Workload
    // [req-1, req-2]
    test_suite.setup_workload(vec!["req-1", "req-2"]);
    let jhs: Vec<_> = (0..3)
        .map(|_| {
            let (client, stream) = test_suite.subscribe();
            test_suite.rt.spawn(async move {
                let _client = client;
                let tags = stream.take(4).map(|record| {
                    String::from_utf8_lossy(record.unwrap().get_record().get_resource_group_tag())
                        .into_owned()
                });
                tags.collect::<HashSet<_>>().await
            })
        })
        .collect();

    for jh in jhs {
        let res = test_suite.rt.block_on(jh).unwrap();
        assert!(res.contains("req-1"));
        assert!(res.contains("req-2"));
    }
}
fn literal_byte_string() {
    assert_eq!(Literal::byte_string(b"").to_string(), "b\"\"");
    assert_eq!(
        Literal::byte_string(b"\0\t\n\r\"\\2\x10").to_string(),
        "b\"\\0\\t\\n\\r\\\"\\\\2\\x10\"",
    );
    assert_eq!(
        Literal::byte_string(b"a\00b\07c\08d\0e\0").to_string(),
        "b\"a\\x000b\\x007c\\08d\\0e\\0\"",
    );

    "b\"\\\r\n    x\"".parse::<TokenStream>().unwrap();
    "b\"\\\r\n  \rx\"".parse::<TokenStream>().unwrap_err();
    "b\"\\\r\n  \u{a0}x\"".parse::<TokenStream>().unwrap_err();
    "br\"\u{a0}\"".parse::<TokenStream>().unwrap_err();
}
fn compute_left_closed_directed_test() {
    assert_eq!(compute_left_closed_directed(1.23456), (12345600000000002, -16));
    assert_eq!(
        compute_left_closed_directed(13.9999999999999982236431606),
        (13999999999999999, -15)
    );
}
fn sanity_test_artifact_deserialize() {
    let engine = Engine::headless();
    let result = unsafe { Module::deserialize(&engine, &[]) };
    assert!(result.is_err());
}
fn test_touch_set_date6() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_date";

    ucmd.args(&["-d", "2000-01-01 00:00", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let expected = FileTime::from_unix_time(946_684_800, 0);

    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime, expected);
    assert_eq!(mtime, expected);
}
fn test_simple_print() {
    let mut cmd = get_cmd();
    let assert = cmd.arg(get_bin_path("simple_print")).assert();
    let output = assert.get_output();
    let stdout = &output.stdout;
    assert!(contains_slice(stdout, b"Hello World"));
    if !(contains_slice(stdout, b"Hello World\n")) {
        eprint!("UNEQUAL: {}", std::str::from_utf8(stdout).unwrap());
    }
}
fn ArrayVec_swap_remove() {
  let mut av: ArrayVec<[i32; 10]> = Default::default();
  av.push(1);
  av.push(2);
  av.push(3);
  av.push(4);
  assert_eq!(av.swap_remove(3), 4);
  assert_eq!(&av[..], &[1, 2, 3][..]);
  assert_eq!(av.swap_remove(0), 1);
  assert_eq!(&av[..], &[3, 2][..]);
  assert_eq!(av.swap_remove(0), 3);
  assert_eq!(&av[..], &[2][..]);
  assert_eq!(av.swap_remove(0), 2);
  assert_eq!(&av[..], &[][..]);
}
fn parse_trim() {
    one_statement_parses_to(
        "SELECT TRIM(BOTH 'xyz' FROM 'xyzfooxyz')",
        "SELECT TRIM(BOTH 'xyz' FROM 'xyzfooxyz')",
    );

    one_statement_parses_to(
        "SELECT TRIM(LEADING 'xyz' FROM 'xyzfooxyz')",
        "SELECT TRIM(LEADING 'xyz' FROM 'xyzfooxyz')",
    );

    one_statement_parses_to(
        "SELECT TRIM(TRAILING 'xyz' FROM 'xyzfooxyz')",
        "SELECT TRIM(TRAILING 'xyz' FROM 'xyzfooxyz')",
    );

    one_statement_parses_to(
        "SELECT TRIM('xyz' FROM 'xyzfooxyz')",
        "SELECT TRIM('xyz' FROM 'xyzfooxyz')",
    );
    one_statement_parses_to("SELECT TRIM('   foo   ')", "SELECT TRIM('   foo   ')");
    one_statement_parses_to(
        "SELECT TRIM(LEADING '   foo   ')",
        "SELECT TRIM(LEADING '   foo   ')",
    );

    assert_eq!(
        ParserError::ParserError("Expected ), found: 'xyz'".to_owned()),
        parse_sql_statements("SELECT TRIM(FOO 'xyz' FROM 'xyzfooxyz')").unwrap_err()
    );

    //keep Snowflake/BigQuery TRIM syntax failing
    let all_expected_snowflake = TestedDialects {
        dialects: vec![
            //Box::new(GenericDialect {}),
            Box::new(PostgreSqlDialect {}),
            Box::new(MsSqlDialect {}),
            Box::new(AnsiDialect {}),
            //Box::new(SnowflakeDialect {}),
            Box::new(HiveDialect {}),
            Box::new(RedshiftSqlDialect {}),
            Box::new(MySqlDialect {}),
            //Box::new(BigQueryDialect {}),
            Box::new(SQLiteDialect {}),
            Box::new(DuckDbDialect {}),
        ],
        options: None,
    };
    assert_eq!(
        ParserError::ParserError("Expected ), found: 'a'".to_owned()),
        all_expected_snowflake
            .parse_sql_statements("SELECT TRIM('xyz', 'a')")
            .unwrap_err()
    );
}
fn test_pub() {
    assert_vis_parse!("pub", Ok(Visibility::Public(_)));
}
fn key_update_simple() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    let s = pair
        .client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .streams()
        .open(Dir::Bi)
        .expect("couldn't open first stream");

    const MSG1: &[u8] = b"hello1";
    pair.client_send(client_ch, s).write(MSG1).unwrap();
    pair.drive();

    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG1
    );
    let _ = chunks.finalize();

    info!("initiating key update");
    pair.client_conn_mut(client_ch).initiate_key_update();

    const MSG2: &[u8] = b"hello2";
    pair.client_send(client_ch, s).write(MSG2).unwrap();
    pair.drive();

    assert_matches!(pair.server_conn_mut(server_ch).poll(), Some(Event::Stream(StreamEvent::Readable { id })) if id == s);
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 6 && chunk.bytes == MSG2
    );
    let _ = chunks.finalize();

    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);
    assert_eq!(pair.server_conn_mut(server_ch).lost_packets(), 0);
}
fn test_rm_force_multiple() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_rm_force_a";
    let file_b = "test_rm_force_b";

    at.touch(file_a);
    at.touch(file_b);
    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    ucmd.arg("-f")
        .arg("-f")
        .arg("-f")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
}
fn drain_filter_all_elements_next_back() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    let mut table = write_txn.open_table(U64_TABLE).unwrap();
    let mut iter = table.drain_filter(0..10, |_, _| true).unwrap();
    for i in (0..10).rev() {
        let (k, v) = iter.next_back().unwrap().unwrap();
        assert_eq!(i, k.value());
        assert_eq!(i, v.value());
    }
}
fn test_new_xml_decl_empty() {
    let mut writer = Writer::new(Vec::new());
    // An empty version should arguably be an error, but we don't expect anyone to actually supply
    // an empty version.
    writer
        .write_event(Decl(BytesDecl::new("", Some(""), Some(""))))
        .expect("writing xml decl should succeed");

    let result = writer.into_inner();
    assert_eq!(
        String::from_utf8(result).expect("utf-8 output"),
        "<?xml version=\"\" encoding=\"\" standalone=\"\"?>",
        "writer output (LHS)"
    );
}
fn should_apply_different_indent_style() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let biome_json = Path::new("biome.json");
    fs.insert(
        biome_json.into(),
        r#"{
        "formatter": {
            "indentStyle": "space"
        },
        "javascript": {
            "formatter": {
                "lineWidth": 320,
                "indentSize": 8,
                "indentStyle": "tab"
            }
        },
        "json": {
            "formatter": {
                "lineWidth": 80,
                "indentSize": 2,
                "indentStyle": "tab"
            }
        }
    }"#,
    );

    let json_file_content = r#"
{
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let json_file = Path::new("input.json");
    fs.insert(json_file.into(), json_file_content.as_bytes());

    let js_file_content = r#"
const a = {
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let js_file = Path::new("input.js");
    fs.insert(js_file.into(), js_file_content.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                "--write",
                json_file.as_os_str().to_str().unwrap(),
                js_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(js_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert!(content.contains('\t'), "should not contain tabs");

    drop(file);

    let mut file = fs
        .open(json_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert!(content.contains('\t'), "should not contain tabs");

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_apply_different_indent_style",
        fs,
        console,
        result,
    ));
}
fn dynamic_many_params_many_results_works() {
    let (mut store, func) = setup_many_params_many_results();
    let mut results = [0; 16].map(Value::I32);
    let inputs = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15].map(Value::I32);
    func.call(&mut store, &inputs, &mut results).unwrap();
    assert_eq!(
        results.map(|result| result.i32().unwrap()),
        inputs.map(|input| input.i32().unwrap()),
    )
}
fn current_dir() {
  let tmp = tempdir();

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--init")
    .output()
    .unwrap();

  assert!(output.status.success());

  assert_eq!(
    fs::read_to_string(tmp.path().join("justfile")).unwrap(),
    EXPECTED
  );
}
fn test_router_trace() {
    let (control_tx, control_fsm) = Runner::new(10);
    let (router, mut system) =
        batch_system::create_system(&Config::default(), control_tx, control_fsm, None);
    let builder = Builder::new();
    system.spawn("test".to_owned(), builder);

    let register_runner = |addr| {
        let (sender, runner) = Runner::new(10);
        let mailbox = BasicMailbox::new(sender, runner, router.state_cnt().clone());
        router.register(addr, mailbox);
    };
    let close_runner = |addr| {
        router.close(addr);
    };

    let mut mailboxes = vec![];
    for i in 0..10 {
        register_runner(i);
        mailboxes.push(router.mailbox(i).unwrap());
    }
    assert_eq!(router.alive_cnt(), 10);
    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 11);
    for i in 0..10 {
        close_runner(i);
    }
    assert_eq!(router.alive_cnt(), 0);
    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 11);
    drop(mailboxes);
    assert_eq!(router.alive_cnt(), 0);
    assert_eq!(router.state_cnt().load(Ordering::Relaxed), 1);
}
fn ci_runs_linter_not_formatter_issue_3495() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), INCORRECT_CODE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("ci target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_runs_linter_not_formatter_issue_3495",
        fs,
        console,
        result,
    ));
}
fn test_memory_count_limit() {
    let limits = StoreLimitsBuilder::new().memories(0).build();
    assert!(Test::new(0x30, 100, limits).is_err());
}
fn fast_path_partial_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::new();
    let string = b"1.2345e10";
    let result = parse::fast_path_partial::<f64, FORMAT>(string, &options);
    assert_eq!(result, Ok((1.2345e10, 9)));

    let string = b"1.2345e";
    let result = parse::fast_path_partial::<f64, FORMAT>(string, &options);
    assert!(result.is_err());

    let string = b"1.2345 ";
    let result = parse::fast_path_partial::<f64, FORMAT>(string, &options);
    assert_eq!(result, Ok((1.2345, 6)));
}
fn leaves_necessary_whitespace_alone() {
    assert_eq!("<u>a</u> b <u>c</u>", normalize_html("<u>a</u> b <u>c</u>"))
}
fn aes256_encrypted_uncompressed_file() {
    let mut v = Vec::new();
    v.extend_from_slice(include_bytes!("data/aes_archive.zip"));
    let mut archive = ZipArchive::new(io::Cursor::new(v)).expect("couldn't open test zip file");

    let mut file = archive
        .by_name_decrypt("secret_data_256_uncompressed", PASSWORD)
        .expect("couldn't find file in archive")
        .expect("invalid password");
    assert_eq!("secret_data_256_uncompressed", file.name());

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("couldn't read encrypted file");
    assert_eq!(SECRET_CONTENT, content);
}
fn stop_before_finish() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive();

    info!("stopping stream");
    const ERROR: VarInt = VarInt(42);
    pair.server_recv(server_ch, s).stop(ERROR).unwrap();
    pair.drive();

    assert_matches!(
        pair.client_send(client_ch, s).finish(),
        Err(FinishError::Stopped(ERROR))
    );
}
fn pop() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();

        assert!(table.pop_first().unwrap().is_none());
        assert!(table.pop_last().unwrap().is_none());

        table.insert("a", "world").unwrap();
        table.insert("b", "world2").unwrap();
        table.insert("c", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        {
            let (key, value) = table.pop_first().unwrap().unwrap();
            assert_eq!(key.value(), "a");
            assert_eq!(value.value(), "world");
        }
        {
            let (key, value) = table.pop_last().unwrap().unwrap();
            assert_eq!(key.value(), "c");
            assert_eq!(value.value(), "world3");
        }
        {
            let (key, value) = table.pop_last().unwrap().unwrap();
            assert_eq!(key.value(), "b");
            assert_eq!(value.value(), "world2");
        }

        assert!(table.pop_first().unwrap().is_none());
        assert!(table.pop_last().unwrap().is_none());
    }
    write_txn.commit().unwrap();
}
fn parse_number() {
    let expr = verified_expr("1.0");

    #[cfg(feature = "bigdecimal")]
    assert_eq!(
        expr,
        Expr::Value(Value::Number(bigdecimal::BigDecimal::from(1), false))
    );

    #[cfg(not(feature = "bigdecimal"))]
    assert_eq!(expr, Expr::Value(Value::Number("1.0".into(), false)));
}
fn bad_import_alignment() -> Result<()> {
    let component = format!(
        r#"
(component
  (import "unaligned-retptr" (func $unaligned_retptr (result string)))
  (type $many_arg (tuple
    string string string string
    string string string string
    string
  ))
  (import "unaligned-argptr" (func $unaligned_argptr (param "a" $many_arg)))
  (core module $libc_panic
    (memory (export "memory") 1)
    (func (export "realloc") (param i32 i32 i32 i32) (result i32)
      unreachable)
  )
  (core instance $libc_panic (instantiate $libc_panic))

  (core func $unaligned_retptr_lower
    (canon lower (func $unaligned_retptr) (memory $libc_panic "memory") (realloc (func $libc_panic "realloc")))
  )
  (core func $unaligned_argptr_lower
    (canon lower (func $unaligned_argptr) (memory $libc_panic "memory") (realloc (func $libc_panic "realloc")))
  )

  (core module $m
    (import "host" "unaligned-retptr" (func $unaligned_retptr (param i32)))
    (import "host" "unaligned-argptr" (func $unaligned_argptr (param i32)))

    (func (export "unaligned-retptr")
     (call $unaligned_retptr (i32.const 1)))
    (func (export "unaligned-argptr")
     (call $unaligned_argptr (i32.const 1)))
  )
  (core instance $m (instantiate $m
    (with "host" (instance
      (export "unaligned-retptr" (func $unaligned_retptr_lower))
      (export "unaligned-argptr" (func $unaligned_argptr_lower))
    ))
  ))

  (func (export "unaligned-retptr2")
    (canon lift (core func $m "unaligned-retptr"))
  )
  (func (export "unaligned-argptr2")
    (canon lift (core func $m "unaligned-argptr"))
  )
)
        "#
    );

    let engine = super::engine();
    let mut linker = Linker::new(&engine);
    linker
        .root()
        .func_wrap("unaligned-retptr", |_, _: ()| -> Result<(String,)> {
            Ok((String::new(),))
        })?;
    linker.root().func_wrap(
        "unaligned-argptr",
        |_,
         _: ((
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
            WasmStr,
        ),)|
         -> Result<()> { unreachable!() },
    )?;
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());

    let trap = linker
        .instantiate(&mut store, &component)?
        .get_typed_func::<(), ()>(&mut store, "unaligned-retptr2")?
        .call(&mut store, ())
        .unwrap_err();
    assert!(
        format!("{:?}", trap).contains("pointer not aligned"),
        "{}",
        trap
    );
    let trap = linker
        .instantiate(&mut store, &component)?
        .get_typed_func::<(), ()>(&mut store, "unaligned-argptr2")?
        .call(&mut store, ())
        .unwrap_err();
    assert!(
        format!("{:?}", trap).contains("pointer not aligned"),
        "{}",
        trap
    );

    Ok(())
}
fn test_snowflake_trim() {
    let real_sql = r#"SELECT customer_id, TRIM(sub_items.value:item_price_id, '"', "a") AS item_price_id FROM models_staging.subscriptions"#;
    assert_eq!(snowflake().verified_stmt(real_sql).to_string(), real_sql);

    let sql_only_select = "SELECT TRIM('xyz', 'a')";
    let select = snowflake().verified_only_select(sql_only_select);
    assert_eq!(
        &Expr::Trim {
            expr: Box::new(Expr::Value(Value::SingleQuotedString("xyz".to_owned()))),
            trim_where: None,
            trim_what: None,
            trim_characters: Some(vec![Expr::Value(Value::SingleQuotedString("a".to_owned()))]),
        },
        expr_from_projection(only(&select.projection))
    );

    // missing comma separation
    let error_sql = "SELECT TRIM('xyz' 'a')";
    assert_eq!(
        ParserError::ParserError("Expected ), found: 'a'".to_owned()),
        snowflake().parse_sql_statements(error_sql).unwrap_err()
    );
}
fn test_value_as_f64() {
    let v = serde_json::from_str::<Value>("1e1000");

    #[cfg(not(feature = "arbitrary_precision"))]
    assert!(v.is_err());

    #[cfg(feature = "arbitrary_precision")]
    assert_eq!(v.unwrap().as_f64(), None);
}
fn leading_zeros_test() {
    assert_eq!(Bigfloat::new().leading_zeros(), 0);

    assert_eq!(Bigfloat::from_u32(0xFF).leading_zeros(), LIMB_BITS as u32 - 8);
    assert_eq!(Bigfloat::from_u64(0xFF00000000).leading_zeros(), 24);

    assert_eq!(Bigfloat::from_u32(0xF).leading_zeros(), LIMB_BITS as u32 - 4);
    assert_eq!(Bigfloat::from_u64(0xF00000000).leading_zeros(), 28);

    assert_eq!(Bigfloat::from_u32(0xF0).leading_zeros(), LIMB_BITS as u32 - 8);
    assert_eq!(Bigfloat::from_u64(0xF000000000).leading_zeros(), 24);
}
fn test_install_backup_numbered_with_t() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=t")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}.~1~")));
}
fn test_validate_endpoints_retry() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(Split::new()));
    let env = Arc::new(
        EnvBuilder::new()
            .cq_count(1)
            .name_prefix(thd_name!("test-pd"))
            .build(),
    );
    let mut eps = server.bind_addrs();
    let mock_port = 65535;
    eps.insert(0, ("127.0.0.1".to_string(), mock_port));
    eps.pop();
    let mgr = Arc::new(SecurityManager::new(&SecurityConfig::default()).unwrap());
    let connector = PdConnector::new(env, mgr);
    assert!(block_on(connector.validate_endpoints(&new_config(eps), false)).is_err());
}
fn test_compare_and_swap_multi() {
    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // create a record
    let mut current = RecordSet::with_ttl(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );

    let current1 = current
        .new_record(&RData::A(A::new(100, 10, 100, 10)))
        .clone();
    let current2 = current
        .new_record(&RData::A(A::new(100, 10, 100, 11)))
        .clone();
    let current = current;

    let result = io_loop
        .block_on(client.create(current.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let mut new = RecordSet::with_ttl(current.name().clone(), current.record_type(), current.ttl());
    let new1 = new.new_record(&RData::A(A::new(100, 10, 101, 10))).clone();
    let new2 = new.new_record(&RData::A(A::new(100, 10, 101, 11))).clone();
    let new = new;

    let result = io_loop
        .block_on(client.compare_and_swap(current.clone(), new.clone(), origin.clone()))
        .expect("compare_and_swap failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(new.name().clone(), new.dns_class(), new.record_type()))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);
    assert!(result.answers().iter().any(|rr| *rr == new1));
    assert!(result.answers().iter().any(|rr| *rr == new2));
    assert!(!result.answers().iter().any(|rr| *rr == current1));
    assert!(!result.answers().iter().any(|rr| *rr == current2));

    // check the it fails if tried again.
    let mut not = new1.clone();
    not.set_data(Some(RData::A(A::new(102, 12, 102, 12))));
    let not = not;

    let result = io_loop
        .block_on(client.compare_and_swap(current, not.clone(), origin))
        .expect("compare_and_swap failed");
    assert_eq!(result.response_code(), ResponseCode::NXRRSet);

    let result = io_loop
        .block_on(client.query(new.name().clone(), new.dns_class(), new.record_type()))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);
    assert!(result.answers().iter().any(|rr| *rr == new1));
    assert!(!result.answers().iter().any(|rr| *rr == not));
}
fn test_output_counts() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);

    let req = DagSelect::from(&product).build();
    let resp = handle_select(&endpoint, req);
    assert_eq!(resp.get_output_counts(), &[data.len() as i64]);
}
fn simple_test() {
    // Test the simple properties of the stack vector.
    let mut x = VecType::from_u32(1);
    assert_eq!(x.len(), 1);
    assert_eq!(x.is_empty(), false);
    assert_eq!(x.capacity(), SIZE);
    x.try_push(5).unwrap();
    assert_eq!(x.len(), 2);
    assert_eq!(x.pop(), Some(5));
    assert_eq!(x.len(), 1);
    assert_eq!(&*x, &[1]);
    x.try_extend(&[2, 3, 4]).unwrap();
    assert_eq!(x.len(), 4);
    assert_eq!(&*x, &[1, 2, 3, 4]);
    x.try_resize(6, 0).unwrap();
    assert_eq!(x.len(), 6);
    assert_eq!(&*x, &[1, 2, 3, 4, 0, 0]);
    x.try_resize(0, 0).unwrap();
    assert_eq!(x.len(), 0);
    assert_eq!(x.is_empty(), true);

    let x = VecType::try_from(&[5, 1]).unwrap();
    assert_eq!(x.len(), 2);
    assert_eq!(x.is_empty(), false);
    assert_eq!(x.hi16(), (0x8000, true));
    if LIMB_BITS == 32 {
        assert_eq!(x.hi32(), (0x80000002, true));
        assert_eq!(x.hi64(), (0x8000000280000000, false));
    } else {
        assert_eq!(x.hi32(), (0x80000000, true));
        assert_eq!(x.hi64(), (0x8000000000000002, true));
    }
    let rview = x.rview();
    assert_eq!(x[0], 5);
    assert_eq!(x[1], 1);
    assert_eq!(rview[0], 1);
    assert_eq!(rview[1], 5);
    assert_eq!(rview.get(1), Some(&5));
    assert_eq!(rview.get(2), None);

    assert_eq!(VecType::from_u16(u16::MAX).hi16(), (u16::MAX, false));
    assert_eq!(VecType::from_u32(u32::MAX).hi32(), (u32::MAX, false));
    assert_eq!(VecType::from_u64(u64::MAX).hi64(), (u64::MAX, false));
}
fn resolve_to_context() {
    let f = super::fixture();
    let resolver =
        Resolver::new(ResolveOptions { resolve_to_context: true, ..ResolveOptions::default() });

    #[rustfmt::skip]
    let data = [
        ("context for fixtures", f.clone(), "./", f.clone()),
        ("context for fixtures/lib", f.clone(), "./lib", f.join("lib")),
        ("context for fixtures with ..", f.clone(), "./lib/../../fixtures/./lib/..", f.clone()),
        ("context for fixtures with query", f.clone(), "./?query", f.clone().with_file_name("fixtures?query")),
    ];

    for (comment, path, request, expected) in data {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn parse_escaped_single_quote_string_predicate_with_escape() {
    use self::BinaryOperator::*;
    let sql = "SELECT id, fname, lname FROM customer \
               WHERE salary <> 'Jim''s salary'";

    let ast = verified_only_select(sql);

    assert_eq!(
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Identifier(Ident::new("salary"))),
            op: NotEq,
            right: Box::new(Expr::Value(Value::SingleQuotedString(
                "Jim's salary".to_string()
            ))),
        }),
        ast.selection,
    );
}
fn test_numeric_suffix_no_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-l", "9", "--numeric-suffixes", "onehundredlines.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x00"), "00\n01\n02\n03\n04\n05\n06\n07\n08\n");
    assert_eq!(at.read("x01"), "09\n10\n11\n12\n13\n14\n15\n16\n17\n");
    assert_eq!(at.read("x02"), "18\n19\n20\n21\n22\n23\n24\n25\n26\n");
    assert_eq!(at.read("x03"), "27\n28\n29\n30\n31\n32\n33\n34\n35\n");
    assert_eq!(at.read("x04"), "36\n37\n38\n39\n40\n41\n42\n43\n44\n");
    assert_eq!(at.read("x05"), "45\n46\n47\n48\n49\n50\n51\n52\n53\n");
    assert_eq!(at.read("x06"), "54\n55\n56\n57\n58\n59\n60\n61\n62\n");
    assert_eq!(at.read("x07"), "63\n64\n65\n66\n67\n68\n69\n70\n71\n");
    assert_eq!(at.read("x08"), "72\n73\n74\n75\n76\n77\n78\n79\n80\n");
    assert_eq!(at.read("x09"), "81\n82\n83\n84\n85\n86\n87\n88\n89\n");
    assert_eq!(at.read("x10"), "90\n91\n92\n93\n94\n95\n96\n97\n98\n");
    assert_eq!(at.read("x11"), "99\n");
}
fn write_batch_put() {
    let db = default_engine();

    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"aa").unwrap();

    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");

    let db = multi_batch_write_engine();

    let mut wb = db.engine.write_batch_with_cap(1024);

    for i in 0..128_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"aa").unwrap();
    for i in 128..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }

    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);
    }
}
fn dont_retry_on_negative_response() {
    let mut response = Message::new();
    response
        .set_message_type(MessageType::Response)
        .set_op_code(OpCode::Update)
        .set_response_code(ResponseCode::NoError);
    let error = ResolveError::from_response(DnsResponse::from_message(response).unwrap(), false)
        .expect_err("NODATA should be an error");
    let client = RetryDnsHandle::new(
        TestClient {
            retries: 1,
            error_response: error,
            attempts: Arc::new(AtomicU16::new(0)),
        },
        2,
    );
    let test1 = Message::new();
    assert!(block_on(client.send(test1).first_answer()).is_err());
}
fn attempt_to_leave_during_malloc() -> Result<()> {
    let component = r#"
(component
  (import "thunk" (func $thunk))
  (import "ret-string" (func $ret_string (result string)))

  (core module $host_shim
    (table (export "table") 2 funcref)
    (func $shim_thunk (export "thunk")
      i32.const 0
      call_indirect)
    (func $shim_ret_string (export "ret-string") (param i32)
      local.get 0
      i32.const 1
      call_indirect (param i32))
  )
  (core instance $host_shim (instantiate $host_shim))

  (core module $m
    (import "host" "thunk" (func $thunk))
    (import "host" "ret-string" (func $ret_string (param i32)))

    (memory (export "memory") 1)

    (func $realloc (export "realloc") (param i32 i32 i32 i32) (result i32)
      call $thunk
      unreachable)

    (func $run (export "run")
      i32.const 8
      call $ret_string)

    (func (export "take-string") (param i32 i32)
        unreachable)
  )
  (core instance $m (instantiate $m (with "host" (instance $host_shim))))

  (core module $host_shim_filler_inner
    (import "shim" "table" (table 2 funcref))
    (import "host" "thunk" (func $thunk))
    (import "host" "ret-string" (func $ret_string (param i32)))
    (elem (i32.const 0) $thunk $ret_string)
  )

  (core func $thunk_lower
    (canon lower (func $thunk) (memory $m "memory") (realloc (func $m "realloc")))
  )

  (core func $ret_string_lower
    (canon lower (func $ret_string) (memory $m "memory") (realloc (func $m "realloc")))
  )

  (core instance (instantiate $host_shim_filler_inner
    (with "shim" (instance $host_shim))
    (with "host" (instance
      (export "thunk" (func $thunk_lower))
      (export "ret-string" (func $ret_string_lower))
    ))
  ))

  (func (export "run")
    (canon lift (core func $m "run"))
  )
  (func (export "take-string") (param "a" string)
    (canon lift (core func $m "take-string") (memory $m "memory") (realloc (func $m "realloc")))
  )
)
    "#;

    let engine = super::engine();
    let mut linker = Linker::new(&engine);
    linker.root().func_wrap("thunk", |_, _: ()| -> Result<()> {
        panic!("should not get here")
    })?;
    linker
        .root()
        .func_wrap("ret-string", |_, _: ()| -> Result<_> {
            Ok(("hello".to_string(),))
        })?;
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());

    // Assert that during a host import if we return values to wasm that a trap
    // happens if we try to leave the instance.
    let trap = linker
        .instantiate(&mut store, &component)?
        .get_typed_func::<(), ()>(&mut store, "run")?
        .call(&mut store, ())
        .unwrap_err();
    assert!(
        format!("{trap:?}").contains("cannot leave component instance"),
        "bad trap: {trap:?}",
    );

    let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 4);

    // This was our entry point...
    assert_eq!(trace[3].module().name(), Some("m"));
    assert_eq!(trace[3].func_name(), Some("run"));

    // ... which called an imported function which ends up being originally
    // defined by the shim instance. The shim instance then does an indirect
    // call through a table which goes to the `canon.lower`'d host function
    assert_eq!(trace[2].module().name(), Some("host_shim"));
    assert_eq!(trace[2].func_name(), Some("shim_ret_string"));

    // ... and the lowered host function will call realloc to allocate space for
    // the result
    assert_eq!(trace[1].module().name(), Some("m"));
    assert_eq!(trace[1].func_name(), Some("realloc"));

    // ... but realloc calls the shim instance and tries to exit the
    // component, triggering a dynamic trap
    assert_eq!(trace[0].module().name(), Some("host_shim"));
    assert_eq!(trace[0].func_name(), Some("shim_thunk"));

    // In addition to the above trap also ensure that when we enter a wasm
    // component if we try to leave while lowering then that's also a dynamic
    // trap.
    let trap = linker
        .instantiate(&mut store, &component)?
        .get_typed_func::<(&str,), ()>(&mut store, "take-string")?
        .call(&mut store, ("x",))
        .unwrap_err();
    assert!(
        format!("{trap:?}").contains("cannot leave component instance"),
        "bad trap: {trap:?}",
    );
    Ok(())
}
async fn push_request_against_concurrency() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        client
            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(1))
            .await;
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .eos(),
            )
            .await;
        client
            .recv_frame(
                frames::push_promise(1, 2).request("GET", "https://http2.akamai.com/style.css"),
            )
            .await;
        client.recv_frame(frames::headers(2).response(200)).await;
        client
            .recv_frame(
                frames::push_promise(1, 4).request("GET", "https://http2.akamai.com/style2.css"),
            )
            .await;
        client.recv_frame(frames::data(2, &b""[..]).eos()).await;
        client
            .recv_frame(frames::headers(4).response(200).eos())
            .await;
        client
            .recv_frame(frames::headers(1).response(200).eos())
            .await;
    };

    let srv = async move {
        let mut srv = server::handshake(io).await.expect("handshake");
        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(req.method(), &http::Method::GET);

        // Promise stream 2 and start response (concurrency limit reached)
        let mut s2_tx = {
            let req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style.css")
                .body(())
                .unwrap();
            let mut pushed_stream = stream.push_request(req).unwrap();
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            pushed_stream.send_response(rsp, false).unwrap()
        };

        // Promise stream 4 and push response
        {
            let pushed_req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style2.css")
                .body(())
                .unwrap();
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            stream
                .push_request(pushed_req)
                .unwrap()
                .send_response(rsp, true)
                .unwrap();
        }

        // Send and finish response for stream 1
        {
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            stream.send_response(rsp, true).unwrap();
        }

        // Finish response for stream 2 (at which point stream 4 will be sent)
        s2_tx.send_data(vec![0; 0].into(), true).unwrap();

        assert!(srv.next().await.is_none());
    };

    join(client, srv).await;
}
fn test_closing_bracket_in_single_quote_attr() {
    let mut r = Reader::from_str("<a attr='>' check='2'></a>");
    r.trim_text(true);
    match r.read_event() {
        Ok(Start(e)) => {
            let mut attrs = e.attributes();
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"attr"),
                    value: Cow::Borrowed(b">"),
                }))
            );
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"check"),
                    value: Cow::Borrowed(b"2"),
                }))
            );
            assert_eq!(attrs.next(), None);
        }
        x => panic!("expected <a attr='>'>, got {:?}", x),
    }
    next_eq!(r, End, b"a");
}
fn u16_decimal_test() {
    assert_eq!(Ok(0), u16::from_lexical(b"0"));
    assert_eq!(Ok(32767), u16::from_lexical(b"32767"));
    assert_eq!(Ok(32768), u16::from_lexical(b"32768"));
    assert_eq!(Ok(65535), u16::from_lexical(b"65535"));
    assert_eq!(Err(Error::InvalidDigit(0)), u16::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), u16::from_lexical(b"1a"));
}
fn test_symlink_do_not_overwrite() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_do_not_overwrite";
    let link = "test_symlink_do_not_overwrite_link";

    at.touch(file);
    at.touch(link);

    ucmd.args(&["-s", file, link]).fails();
    assert!(at.file_exists(file));
    assert!(at.file_exists(link));
    assert!(!at.is_symlink(link));
}
fn test_deserialise_tuple_newtypes() {
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeUnit(Unit)"#)
            .unwrap_err()
            .code,
        Error::ExpectedStructLikeEnd,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeUnit(())"#)
            .unwrap_err()
            .code,
        Error::ExpectedStructLikeEnd,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeUnit()"#).unwrap(),
        TestEnum::TupleNewtypeUnit(Unit),
    );

    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeNewtype(Newtype(4))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedInteger,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeNewtype((4))"#)
            .unwrap_err()
            .code,
        Error::ExpectedInteger,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeNewtype(4)"#)
            .unwrap(),
        TestEnum::TupleNewtypeNewtype(Newtype(4)),
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_newtypes)] TupleNewtypeNewtype(4)"#).unwrap(),
        TestEnum::TupleNewtypeNewtype(Newtype(4)),
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_newtypes)] #![enable(unwrap_variant_newtypes)] TupleNewtypeNewtype(4)"#).unwrap(),
        TestEnum::TupleNewtypeNewtype(Newtype(4)),
    );

    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeTuple((4, false))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedInteger,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeTuple(4, false)"#)
            .unwrap(),
        TestEnum::TupleNewtypeTuple((4, false)),
    );

    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeTupleStruct(TupleStruct(4, false))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedInteger,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeTupleStruct((4, false))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedInteger,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeTupleStruct(4, false)"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeTupleStruct(TupleStruct(4, false)),
    );

    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeStruct(Struct(a: 4, b: false))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedMapColon,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeStruct((a: 4, b: false))"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedIdentifier,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeStruct(a: 4, b: false)"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeStruct(Struct { a: 4, b: false }),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(A)"#).unwrap(),
        TestEnum::TupleNewtypeEnum(Enum::A),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(B(a: 4, b: false))"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeEnum(Enum::B(Struct { a: 4, b: false })),
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(C 4, false)"#)
            .unwrap_err()
            .code,
        Error::ExpectedStructLike,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(C(4, false))"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeEnum(Enum::C(4, false)),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(D a: 4, b: false)"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedStructLike,
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeEnum(D(a: 4, b: false))"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeEnum(Enum::D { a: 4, b: false }),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeOption(None)"#)
            .unwrap(),
        TestEnum::TupleNewtypeOption(None),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeOption(Some(a: 4, b: false))"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeOption(Some(Struct { a: 4, b: false })),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeOption(a: 4, b: false)"#
        )
        .unwrap_err()
        .code,
        Error::ExpectedOption,
    );
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes, implicit_some)] TupleNewtypeOption(a: 4, b: false)"#).unwrap(),
        TestEnum::TupleNewtypeOption(Some(Struct { a: 4, b: false })),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeSeq([])"#).unwrap(),
        TestEnum::TupleNewtypeSeq(vec![]),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeSeq([(a: 4, b: false)])"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeSeq(vec![Struct { a: 4, b: false }]),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeSeq([Struct(a: 4, b: false)])"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeSeq(vec![Struct { a: 4, b: false }]),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeMap({})"#).unwrap(),
        TestEnum::TupleNewtypeMap(vec![].into_iter().collect()),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeMap({2: (a: 4, b: false)})"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeMap(vec![(2, Struct { a: 4, b: false })].into_iter().collect()),
    );
    assert_eq!(
        from_str::<TestEnum>(
            r#"#![enable(unwrap_variant_newtypes)] TupleNewtypeMap({8: Struct(a: 4, b: false)})"#
        )
        .unwrap(),
        TestEnum::TupleNewtypeMap(vec![(8, Struct { a: 4, b: false })].into_iter().collect()),
    );
}
fn fabsd_sanity_test() {
    assert_eq!(libm::fabsd(-1.0), 1.0);
    assert_eq!(libm::fabsd(2.8), 2.8);
}
fn render_super_in_top_block_errors() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("index", "{% block content%}{{super()}}{% endblock content %}")])
        .unwrap();

    let result = tera.render("index", &Context::new());
    assert!(result.is_err());
}
fn test_precedence_of_human_readable_header_over_output_header() {
    let output = new_ucmd!()
        .args(&["-H", "--output=size"])
        .succeeds()
        .stdout_move_str();
    let header = output.lines().next().unwrap().to_string();
    assert_eq!(header.trim(), "Size");
}
fn test_le() {
    assert!(version("0.0.0") <= version("1.2.3-alpha2"));
    assert!(version("1.0.0") <= version("1.2.3-alpha2"));
    assert!(version("1.2.0") <= version("1.2.3-alpha2"));
    assert!(version("1.2.3-alpha1") <= version("1.2.3-alpha2"));
    assert!(version("1.2.3-alpha2") <= version("1.2.3-alpha2"));
    assert!(version("1.2.3+23") <= version("1.2.3+42"));
}
fn parse_create_or_replace_materialized_view() {
    // Supported in BigQuery (Beta)
    // https://cloud.google.com/bigquery/docs/materialized-views-intro
    // and Snowflake:
    // https://docs.snowflake.com/en/sql-reference/sql/create-materialized-view.html
    let sql = "CREATE OR REPLACE MATERIALIZED VIEW v AS SELECT 1";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            columns,
            or_replace,
            with_options,
            query,
            materialized,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("v", name.to_string());
            assert_eq!(columns, vec![]);
            assert_eq!(with_options, vec![]);
            assert_eq!("SELECT 1", query.to_string());
            assert!(materialized);
            assert!(or_replace);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(!temporary);
        }
        _ => unreachable!(),
    }
}
fn parse_literal_datetime() {
    let sql = "SELECT DATETIME '1999-01-01 01:23:34.45'";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::Datetime(None),
            value: "1999-01-01 01:23:34.45".into(),
        },
        expr_from_projection(only(&select.projection)),
    );
}
fn TinyVec_splice() {
  let mut tv: TinyVec<[i32; 10]> = Default::default();
  tv.push(1);
  tv.push(2);
  tv.push(3);

  // splice returns the same things as drain
  assert_eq!(Vec::from_iter(tv.clone().splice(.., None)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().splice(..2, None)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(..3, None)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().splice(..=1, None)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(..=2, None)), vec![1, 2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().splice(0.., None)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().splice(1.., None)), vec![2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().splice(0..2, None)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(0..3, None)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().splice(1..2, None)), vec![2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(1..3, None)), vec![2, 3]);

  assert_eq!(Vec::from_iter(tv.clone().splice(0..=1, None)), vec![1, 2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(0..=2, None)), vec![1, 2, 3]);
  assert_eq!(Vec::from_iter(tv.clone().splice(1..=1, None)), vec![2]);
  assert_eq!(Vec::from_iter(tv.clone().splice(1..=2, None)), vec![2, 3]);

  // splice removes the same things as drain
  let mut tv2 = tv.clone();
  tv2.splice(.., None);
  assert_eq!(tv2, tiny_vec![]);

  let mut tv2 = tv.clone();
  tv2.splice(..2, None);
  assert_eq!(tv2, tiny_vec![3]);

  let mut tv2 = tv.clone();
  tv2.splice(..3, None);
  assert_eq!(tv2, tiny_vec![]);

  let mut tv2 = tv.clone();
  tv2.splice(..=1, None);
  assert_eq!(tv2, tiny_vec![3]);
  let mut tv2 = tv.clone();
  tv2.splice(..=2, None);
  assert_eq!(tv2, tiny_vec![]);

  let mut tv2 = tv.clone();
  tv2.splice(0.., None);
  assert_eq!(tv2, tiny_vec![]);
  let mut tv2 = tv.clone();
  tv2.splice(1.., None);
  assert_eq!(tv2, tiny_vec![1]);

  let mut tv2 = tv.clone();
  tv2.splice(0..2, None);
  assert_eq!(tv2, tiny_vec![3]);

  let mut tv2 = tv.clone();
  tv2.splice(0..3, None);
  assert_eq!(tv2, tiny_vec![]);
  let mut tv2 = tv.clone();
  tv2.splice(1..2, None);
  assert_eq!(tv2, tiny_vec![1, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(1..3, None);
  assert_eq!(tv2, tiny_vec![1]);

  let mut tv2 = tv.clone();
  tv2.splice(0..=1, None);
  assert_eq!(tv2, tiny_vec![3]);

  let mut tv2 = tv.clone();
  tv2.splice(0..=2, None);
  assert_eq!(tv2, tiny_vec![]);

  let mut tv2 = tv.clone();
  tv2.splice(1..=1, None);
  assert_eq!(tv2, tiny_vec![1, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(1..=2, None);
  assert_eq!(tv2, tiny_vec![1]);

  // splice adds the elements correctly
  let mut tv2 = tv.clone();
  tv2.splice(.., 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(..2, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(..3, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(..=1, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(..=2, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(0.., 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(1.., 4..=6);
  assert_eq!(tv2, tiny_vec![1, 4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(0..2, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(0..3, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(1..2, 4..=6);
  assert_eq!(tv2, tiny_vec![1, 4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(1..3, 4..=6);
  assert_eq!(tv2, tiny_vec![1, 4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(0..=1, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(0..=2, 4..=6);
  assert_eq!(tv2, tiny_vec![4, 5, 6]);

  let mut tv2 = tv.clone();
  tv2.splice(1..=1, 4..=6);
  assert_eq!(tv2, tiny_vec![1, 4, 5, 6, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(1..=2, 4..=6);
  assert_eq!(tv2, tiny_vec![1, 4, 5, 6]);

  // splice adds the elements correctly when the replacement is smaller
  let mut tv2 = tv.clone();
  tv2.splice(.., Some(4));
  assert_eq!(tv2, tiny_vec![4]);

  let mut tv2 = tv.clone();
  tv2.splice(..2, Some(4));
  assert_eq!(tv2, tiny_vec![4, 3]);

  let mut tv2 = tv.clone();
  tv2.splice(1.., Some(4));
  assert_eq!(tv2, tiny_vec![1, 4]);

  let mut tv2 = tv.clone();
  tv2.splice(1..=1, Some(4));
  assert_eq!(tv2, tiny_vec![1, 4, 3]);
}
fn test_dateformat_time_rs() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATE_FORMAT", "[year]-[month]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("d|dateformat(format=format)")
        .unwrap();

    let d = time::Date::from_ordinal_date(2023, 42).unwrap();
    assert_eq!(
        expr.eval(context!(d, format => "short"))
            .unwrap()
            .to_string(),
        "2023-02-11"
    );
}
fn parse_alter_table_drop_constraint() {
    let alter_stmt = "ALTER TABLE tab";
    match alter_table_op(verified_stmt(
        "ALTER TABLE tab DROP CONSTRAINT constraint_name CASCADE",
    )) {
        AlterTableOperation::DropConstraint {
            name: constr_name,
            if_exists,
            cascade,
        } => {
            assert_eq!("constraint_name", constr_name.to_string());
            assert!(!if_exists);
            assert!(cascade);
        }
        _ => unreachable!(),
    }
    match alter_table_op(verified_stmt(
        "ALTER TABLE tab DROP CONSTRAINT IF EXISTS constraint_name",
    )) {
        AlterTableOperation::DropConstraint {
            name: constr_name,
            if_exists,
            cascade,
        } => {
            assert_eq!("constraint_name", constr_name.to_string());
            assert!(if_exists);
            assert!(!cascade);
        }
        _ => unreachable!(),
    }

    let res = parse_sql_statements(&format!("{alter_stmt} DROP CONSTRAINT is_active TEXT"));
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: TEXT".to_string()),
        res.unwrap_err()
    );
}
fn parse_json_ops_without_colon() {
    use self::JsonOperator;
    let binary_ops = &[
        ("->", JsonOperator::Arrow, all_dialects()),
        ("->>", JsonOperator::LongArrow, all_dialects()),
        ("#>", JsonOperator::HashArrow, pg_and_generic()),
        ("#>>", JsonOperator::HashLongArrow, pg_and_generic()),
        ("@>", JsonOperator::AtArrow, all_dialects()),
        ("<@", JsonOperator::ArrowAt, all_dialects()),
        ("#-", JsonOperator::HashMinus, pg_and_generic()),
        ("@?", JsonOperator::AtQuestion, all_dialects()),
        ("@@", JsonOperator::AtAt, all_dialects()),
    ];

    for (str_op, op, dialects) in binary_ops {
        let select = dialects.verified_only_select(&format!("SELECT a {} b", &str_op));
        assert_eq!(
            SelectItem::UnnamedExpr(Expr::JsonAccess {
                left: Box::new(Expr::Identifier(Ident::new("a"))),
                operator: *op,
                right: Box::new(Expr::Identifier(Ident::new("b"))),
            }),
            select.projection[0]
        );
    }
}
fn test_du_dereference() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    at.symlink_dir(SUB_DEEPER_DIR, SUB_DIR_LINKS_DEEPER_SYM_DIR);

    let result = ts.ucmd().arg("-L").arg(SUB_DIR_LINKS).succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &["-L", SUB_DIR_LINKS]));

        if result_reference.succeeded() {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }

    _du_dereference(result.stdout_str());
}
fn scale_sci_exp_test() {
    // Binary is always the same.
    assert_eq!(binary::scale_sci_exp(2, 1), 2);
    assert_eq!(binary::scale_sci_exp(1, 1), 1);
    assert_eq!(binary::scale_sci_exp(0, 1), 0);
    assert_eq!(binary::scale_sci_exp(-1, 1), -1);
    assert_eq!(binary::scale_sci_exp(-2, 1), -2);

    // Base 4 will always be the round-to-negative-infinity div.
    assert_eq!(binary::scale_sci_exp(2, 2), 1);
    assert_eq!(binary::scale_sci_exp(1, 2), 0);
    assert_eq!(binary::scale_sci_exp(0, 2), 0);
    assert_eq!(binary::scale_sci_exp(-1, 2), -1);
    assert_eq!(binary::scale_sci_exp(-2, 2), -1);
    assert_eq!(binary::scale_sci_exp(-3, 2), -2);
}
fn test_mv_arg_update_all() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file1 = "test_mv_arg_update_none_file1";
    let file2 = "test_mv_arg_update_none_file2";
    let file1_content = "file1 content\n";
    let file2_content = "file2 content\n";

    at.write(file1, file1_content);
    at.write(file2, file2_content);

    ucmd.arg(file1)
        .arg(file2)
        .arg("--update=all")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(file2), file1_content);
}
fn parse_key_value_with_space_test() {
  let ini_file = &b"parameter = value
key = value2"[..];

  let ini_without_key_value = &b"\nkey = value2"[..];

  let res = key_value(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, (o1, o2))) => println!("i: {:?} | o: ({:?},{:?})", str::from_utf8(i), o1, o2),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_key_value, ("parameter", "value"))));
}
fn parse_string_concat_multiple() {
    let ast = parse("{{ `hello` ~ ident ~ 'ho' }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::StringConcat(StringConcat {
                values: vec![
                    ExprVal::String("hello".to_string()),
                    ExprVal::Ident("ident".to_string()),
                    ExprVal::String("ho".to_string()),
                ]
            }))
        ),
    );
}
fn test_closing_bracket_in_double_quote_mixed() {
    let mut r = Reader::from_str(r#"<a attr="'>'" check="'2'"></a>"#);
    r.trim_text(true);
    match r.read_event() {
        Ok(Start(e)) => {
            let mut attrs = e.attributes();
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"attr"),
                    value: Cow::Borrowed(b"'>'"),
                }))
            );
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"check"),
                    value: Cow::Borrowed(b"'2'"),
                }))
            );
            assert_eq!(attrs.next(), None);
        }
        x => panic!("expected <a attr='>'>, got {:?}", x),
    }
    next_eq!(r, End, b"a");
}
fn fabsf_spec_test() {
    assert!(libm::fabsf(f32::NAN).is_nan());
    for f in [0.0, -0.0].iter().copied() {
        assert_eq!(libm::fabsf(f), 0.0);
    }
    for f in [f32::INFINITY, f32::NEG_INFINITY].iter().copied() {
        assert_eq!(libm::fabsf(f), f32::INFINITY);
    }
}
fn test_rmdir_ignore_nonempty_directory_with_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir_all(NESTED_DIR);
    at.touch(NESTED_DIR_FILE);

    ucmd.arg("--ignore-fail-on-non-empty")
        .arg("-p")
        .arg(NESTED_DIR)
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(NESTED_DIR));
}
fn no_actual_wasm_code() -> Result<()> {
    let component = r#"
        (component
            (import "f" (func $f))

            (core func $f_lower
                (canon lower (func $f))
            )
            (core module $m
                (import "" "" (func $f))
                (export "f" (func $f))
            )
            (core instance $i (instantiate $m
                (with "" (instance
                    (export "" (func $f_lower))
                ))
            ))
            (func (export "thunk")
                (canon lift
                    (core func $i "f")
                )
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, 0);

    // First, test the static API

    let mut linker = Linker::new(&engine);
    linker.root().func_wrap(
        "f",
        |mut store: StoreContextMut<'_, u32>, _: ()| -> Result<()> {
            *store.data_mut() += 1;
            Ok(())
        },
    )?;

    let instance = linker.instantiate(&mut store, &component)?;
    let thunk = instance.get_typed_func::<(), ()>(&mut store, "thunk")?;

    assert_eq!(*store.data(), 0);
    thunk.call(&mut store, ())?;
    assert_eq!(*store.data(), 1);

    // Next, test the dynamic API

    *store.data_mut() = 0;
    let mut linker = Linker::new(&engine);
    linker.root().func_new(
        &component,
        "f",
        |mut store: StoreContextMut<'_, u32>, _, _| {
            *store.data_mut() += 1;
            Ok(())
        },
    )?;

    let instance = linker.instantiate(&mut store, &component)?;
    let thunk = instance.get_func(&mut store, "thunk").unwrap();

    assert_eq!(*store.data(), 0);
    thunk.call(&mut store, &[], &mut [])?;
    assert_eq!(*store.data(), 1);

    Ok(())
}
fn u128_pow2_test() {
    let values: &[u128] = &[
        0,
        1,
        2,
        3,
        4,
        5,
        7,
        8,
        9,
        15,
        16,
        17,
        31,
        32,
        33,
        63,
        64,
        65,
        127,
        128,
        129,
        255,
        256,
        257,
        511,
        512,
        513,
        1023,
        1024,
        1025,
        2047,
        2048,
        2049,
        4095,
        4096,
        4097,
        8191,
        8192,
        8193,
        16383,
        16384,
        16385,
        32767,
        32768,
        32769,
        65535,
        65536,
        65537,
        131071,
        131072,
        131073,
        262143,
        262144,
        262145,
        524287,
        524288,
        524289,
        1048575,
        1048576,
        1048577,
        2097151,
        2097152,
        2097153,
        4194303,
        4194304,
        4194305,
        8388607,
        8388608,
        8388609,
        16777215,
        16777216,
        16777217,
        33554431,
        33554432,
        33554433,
        67108863,
        67108864,
        67108865,
        134217727,
        134217728,
        134217729,
        268435455,
        268435456,
        268435457,
        536870911,
        536870912,
        536870913,
        1073741823,
        1073741824,
        1073741825,
        2147483647,
        2147483648,
        2147483649,
        4294967295,
        4294967296,
        4294967297,
        8589934591,
        8589934592,
        8589934593,
        17179869183,
        17179869184,
        17179869185,
        34359738367,
        34359738368,
        34359738369,
        68719476735,
        68719476736,
        68719476737,
        137438953471,
        137438953472,
        137438953473,
        274877906943,
        274877906944,
        274877906945,
        549755813887,
        549755813888,
        549755813889,
        1099511627775,
        1099511627776,
        1099511627777,
        2199023255551,
        2199023255552,
        2199023255553,
        4398046511103,
        4398046511104,
        4398046511105,
        8796093022207,
        8796093022208,
        8796093022209,
        17592186044415,
        17592186044416,
        17592186044417,
        35184372088831,
        35184372088832,
        35184372088833,
        70368744177663,
        70368744177664,
        70368744177665,
        140737488355327,
        140737488355328,
        140737488355329,
        281474976710655,
        281474976710656,
        281474976710657,
        562949953421311,
        562949953421312,
        562949953421313,
        1125899906842623,
        1125899906842624,
        1125899906842625,
        2251799813685247,
        2251799813685248,
        2251799813685249,
        4503599627370495,
        4503599627370496,
        4503599627370497,
        9007199254740991,
        9007199254740992,
        9007199254740993,
        18014398509481983,
        18014398509481984,
        18014398509481985,
        36028797018963967,
        36028797018963968,
        36028797018963969,
        72057594037927935,
        72057594037927936,
        72057594037927937,
        144115188075855871,
        144115188075855872,
        144115188075855873,
        288230376151711743,
        288230376151711744,
        288230376151711745,
        576460752303423487,
        576460752303423488,
        576460752303423489,
        1152921504606846975,
        1152921504606846976,
        1152921504606846977,
        2305843009213693951,
        2305843009213693952,
        2305843009213693953,
        4611686018427387903,
        4611686018427387904,
        4611686018427387905,
        9223372036854775807,
        9223372036854775808,
        9223372036854775809,
        18446744073709551615,
        18446744073709551616,
        18446744073709551617,
        36893488147419103231,
        36893488147419103232,
        36893488147419103233,
        73786976294838206463,
        73786976294838206464,
        73786976294838206465,
        147573952589676412927,
        147573952589676412928,
        147573952589676412929,
        295147905179352825855,
        295147905179352825856,
        295147905179352825857,
        590295810358705651711,
        590295810358705651712,
        590295810358705651713,
        1180591620717411303423,
        1180591620717411303424,
        1180591620717411303425,
        2361183241434822606847,
        2361183241434822606848,
        2361183241434822606849,
        4722366482869645213695,
        4722366482869645213696,
        4722366482869645213697,
        9444732965739290427391,
        9444732965739290427392,
        9444732965739290427393,
        18889465931478580854783,
        18889465931478580854784,
        18889465931478580854785,
        37778931862957161709567,
        37778931862957161709568,
        37778931862957161709569,
        75557863725914323419135,
        75557863725914323419136,
        75557863725914323419137,
        151115727451828646838271,
        151115727451828646838272,
        151115727451828646838273,
        302231454903657293676543,
        302231454903657293676544,
        302231454903657293676545,
        604462909807314587353087,
        604462909807314587353088,
        604462909807314587353089,
        1208925819614629174706175,
        1208925819614629174706176,
        1208925819614629174706177,
        2417851639229258349412351,
        2417851639229258349412352,
        2417851639229258349412353,
        4835703278458516698824703,
        4835703278458516698824704,
        4835703278458516698824705,
        9671406556917033397649407,
        9671406556917033397649408,
        9671406556917033397649409,
        19342813113834066795298815,
        19342813113834066795298816,
        19342813113834066795298817,
        38685626227668133590597631,
        38685626227668133590597632,
        38685626227668133590597633,
        77371252455336267181195263,
        77371252455336267181195264,
        77371252455336267181195265,
        154742504910672534362390527,
        154742504910672534362390528,
        154742504910672534362390529,
        309485009821345068724781055,
        309485009821345068724781056,
        309485009821345068724781057,
        618970019642690137449562111,
        618970019642690137449562112,
        618970019642690137449562113,
        1237940039285380274899124223,
        1237940039285380274899124224,
        1237940039285380274899124225,
        2475880078570760549798248447,
        2475880078570760549798248448,
        2475880078570760549798248449,
        4951760157141521099596496895,
        4951760157141521099596496896,
        4951760157141521099596496897,
        9903520314283042199192993791,
        9903520314283042199192993792,
        9903520314283042199192993793,
        19807040628566084398385987583,
        19807040628566084398385987584,
        19807040628566084398385987585,
        39614081257132168796771975167,
        39614081257132168796771975168,
        39614081257132168796771975169,
        79228162514264337593543950335,
        79228162514264337593543950336,
        79228162514264337593543950337,
        158456325028528675187087900671,
        158456325028528675187087900672,
        158456325028528675187087900673,
        316912650057057350374175801343,
        316912650057057350374175801344,
        316912650057057350374175801345,
        633825300114114700748351602687,
        633825300114114700748351602688,
        633825300114114700748351602689,
        1267650600228229401496703205375,
        1267650600228229401496703205376,
        1267650600228229401496703205377,
        2535301200456458802993406410751,
        2535301200456458802993406410752,
        2535301200456458802993406410753,
        5070602400912917605986812821503,
        5070602400912917605986812821504,
        5070602400912917605986812821505,
        10141204801825835211973625643007,
        10141204801825835211973625643008,
        10141204801825835211973625643009,
        20282409603651670423947251286015,
        20282409603651670423947251286016,
        20282409603651670423947251286017,
        40564819207303340847894502572031,
        40564819207303340847894502572032,
        40564819207303340847894502572033,
        81129638414606681695789005144063,
        81129638414606681695789005144064,
        81129638414606681695789005144065,
        162259276829213363391578010288127,
        162259276829213363391578010288128,
        162259276829213363391578010288129,
        324518553658426726783156020576255,
        324518553658426726783156020576256,
        324518553658426726783156020576257,
        649037107316853453566312041152511,
        649037107316853453566312041152512,
        649037107316853453566312041152513,
        1298074214633706907132624082305023,
        1298074214633706907132624082305024,
        1298074214633706907132624082305025,
        2596148429267413814265248164610047,
        2596148429267413814265248164610048,
        2596148429267413814265248164610049,
        5192296858534827628530496329220095,
        5192296858534827628530496329220096,
        5192296858534827628530496329220097,
        10384593717069655257060992658440191,
        10384593717069655257060992658440192,
        10384593717069655257060992658440193,
        20769187434139310514121985316880383,
        20769187434139310514121985316880384,
        20769187434139310514121985316880385,
        41538374868278621028243970633760767,
        41538374868278621028243970633760768,
        41538374868278621028243970633760769,
        83076749736557242056487941267521535,
        83076749736557242056487941267521536,
        83076749736557242056487941267521537,
        166153499473114484112975882535043071,
        166153499473114484112975882535043072,
        166153499473114484112975882535043073,
        332306998946228968225951765070086143,
        332306998946228968225951765070086144,
        332306998946228968225951765070086145,
        664613997892457936451903530140172287,
        664613997892457936451903530140172288,
        664613997892457936451903530140172289,
        1329227995784915872903807060280344575,
        1329227995784915872903807060280344576,
        1329227995784915872903807060280344577,
        2658455991569831745807614120560689151,
        2658455991569831745807614120560689152,
        2658455991569831745807614120560689153,
        5316911983139663491615228241121378303,
        5316911983139663491615228241121378304,
        5316911983139663491615228241121378305,
        10633823966279326983230456482242756607,
        10633823966279326983230456482242756608,
        10633823966279326983230456482242756609,
        21267647932558653966460912964485513215,
        21267647932558653966460912964485513216,
        21267647932558653966460912964485513217,
        42535295865117307932921825928971026431,
        42535295865117307932921825928971026432,
        42535295865117307932921825928971026433,
        85070591730234615865843651857942052863,
        85070591730234615865843651857942052864,
        85070591730234615865843651857942052865,
        170141183460469231731687303715884105727,
        170141183460469231731687303715884105728,
        170141183460469231731687303715884105729,
        340282366920938463463374607431768211455,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn link_twice_bad() -> Result<()> {
    let mut store = Store::<()>::default();
    let mut linker = Linker::<()>::new(store.engine());

    // functions
    linker.func_wrap("f", "", || {})?;
    assert!(linker.func_wrap("f", "", || {}).is_err());
    assert!(linker
        .func_wrap("f", "", || -> Result<()> { loop {} })
        .is_err());

    // globals
    let ty = GlobalType::new(ValType::I32, Mutability::Const);
    let global = Global::new(&mut store, ty, Val::I32(0))?;
    linker.define(&mut store, "g", "1", global.clone())?;
    assert!(linker.define(&mut store, "g", "1", global.clone()).is_err());

    let ty = GlobalType::new(ValType::I32, Mutability::Var);
    let global = Global::new(&mut store, ty, Val::I32(0))?;
    linker.define(&mut store, "g", "2", global.clone())?;
    assert!(linker.define(&mut store, "g", "2", global.clone()).is_err());

    let ty = GlobalType::new(ValType::I64, Mutability::Const);
    let global = Global::new(&mut store, ty, Val::I64(0))?;
    linker.define(&mut store, "g", "3", global.clone())?;
    assert!(linker.define(&mut store, "g", "3", global.clone()).is_err());

    // memories
    let ty = MemoryType::new(1, None);
    let memory = Memory::new(&mut store, ty)?;
    linker.define(&mut store, "m", "", memory.clone())?;
    assert!(linker.define(&mut store, "m", "", memory.clone()).is_err());
    let ty = MemoryType::new(2, None);
    let memory = Memory::new(&mut store, ty)?;
    assert!(linker.define(&mut store, "m", "", memory.clone()).is_err());

    // tables
    let ty = TableType::new(ValType::FuncRef, 1, None);
    let table = Table::new(&mut store, ty, Val::FuncRef(None))?;
    linker.define(&mut store, "t", "", table.clone())?;
    assert!(linker.define(&mut store, "t", "", table.clone()).is_err());
    let ty = TableType::new(ValType::FuncRef, 2, None);
    let table = Table::new(&mut store, ty, Val::FuncRef(None))?;
    assert!(linker.define(&mut store, "t", "", table.clone()).is_err());
    Ok(())
}
async fn stream_close_by_data_frame_releases_capacity() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let window_size = frame::DEFAULT_INITIAL_WINDOW_SIZE as usize;

    let h2 = async move {
        let (mut client, mut h2) = client::handshake(io).await.unwrap();
        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        // Send request
        let (resp1, mut s1) = client.send_request(request, false).unwrap();

        // This effectively reserves the entire connection window
        s1.reserve_capacity(window_size);

        // The capacity should be immediately available as nothing else is
        // happening on the stream.
        assert_eq!(s1.capacity(), window_size);

        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        // Create a second stream
        let (resp2, mut s2) = client.send_request(request, false).unwrap();

        // Request capacity
        s2.reserve_capacity(5);

        // There should be no available capacity (as it is being held up by
        // the previous stream
        assert_eq!(s2.capacity(), 0);

        // Closing the previous stream by sending an empty data frame will
        // release the capacity to s2
        s1.send_data("".into(), true).unwrap();

        // The capacity should be available
        assert_eq!(s2.capacity(), 5);

        // Send the frame
        s2.send_data("hello".into(), true).unwrap();

        // Drive both streams to prevent the handles from being dropped
        // (which will send a RST_STREAM) before the connection is closed.
        h2.drive(resp1).await.unwrap();
        h2.drive(resp2).await.unwrap();
    };

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_default_settings!(settings);
        srv.recv_frame(frames::headers(1).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        srv.recv_frame(frames::headers(3).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.send_frame(frames::headers(3).response(200)).await;
        srv.recv_frame(frames::data(1, &b""[..]).eos()).await;
        srv.recv_frame(frames::data(3, &b"hello"[..]).eos()).await;
    };
    join(srv, h2).await;
}
fn parse_literal_string() {
    let sql = "SELECT 'one', N'national string', X'deadBEEF'";
    let select = verified_only_select(sql);
    assert_eq!(3, select.projection.len());
    assert_eq!(
        &Expr::Value(Value::SingleQuotedString("one".to_string())),
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Value(Value::NationalStringLiteral("national string".to_string())),
        expr_from_projection(&select.projection[1])
    );
    assert_eq!(
        &Expr::Value(Value::HexStringLiteral("deadBEEF".to_string())),
        expr_from_projection(&select.projection[2])
    );

    one_statement_parses_to("SELECT x'deadBEEF'", "SELECT X'deadBEEF'");
    one_statement_parses_to("SELECT n'national string'", "SELECT N'national string'");
}
fn test_evil_server_close() {
    do_test(
        3013,
        |mut cli_sock| {
            cli_sock.send(Message::Text("Hello WebSocket".into())).unwrap();

            sleep(Duration::from_secs(1));

            let message = cli_sock.read().unwrap(); // receive close from server
            assert!(message.is_close());

            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed
            match err {
                Error::ConnectionClosed => {}
                _ => panic!("unexpected error: {:?}", err),
            }
        },
        |mut srv_sock| {
            let message = srv_sock.read().unwrap();
            assert_eq!(message.into_data(), b"Hello WebSocket");

            srv_sock.close(None).unwrap(); // send close to client

            let message = srv_sock.read().unwrap(); // receive acknowledgement
            assert!(message.is_close());
            // and now just drop the connection without waiting for `ConnectionClosed`
            srv_sock.get_mut().set_linger(Some(Duration::from_secs(0))).unwrap();
            drop(srv_sock);
        },
    );
}
async fn reserved_capacity_assigned_in_multi_window_updates() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let h2 = async move {
        let (mut client, mut h2) = client::handshake(io).await.unwrap();
        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let (response, mut stream) = client.send_request(request, false).unwrap();

        // Consume the capacity
        let payload = vec![0; frame::DEFAULT_INITIAL_WINDOW_SIZE as usize];
        stream.send_data(payload.into(), false).unwrap();

        // Reserve more data than we want
        stream.reserve_capacity(10);

        let mut stream = h2.drive(util::wait_for_capacity(stream, 5)).await;
        stream.send_data("hello".into(), false).unwrap();
        stream.send_data("world".into(), true).unwrap();

        let response = h2.drive(response).await.unwrap();
        assert_eq!(response.status(), StatusCode::NO_CONTENT);

        // Wait for the connection to close
        h2.await.unwrap();
    };

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_default_settings!(settings);
        srv.recv_frame(frames::headers(1).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;
        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;
        srv.recv_frame(frames::data(1, vec![0u8; 16_384])).await;
        srv.recv_frame(frames::data(1, vec![0u8; 16_383])).await;
        idle_ms(100).await;
        // Increase the connection window
        srv.send_frame(frames::window_update(0, 10)).await;
        // Incrementally increase the stream window
        srv.send_frame(frames::window_update(1, 4)).await;
        idle_ms(50).await;
        srv.send_frame(frames::window_update(1, 1)).await;
        // Receive first chunk
        srv.recv_frame(frames::data(1, "hello")).await;
        srv.send_frame(frames::window_update(1, 5)).await;
        // Receive second chunk
        srv.recv_frame(frames::data(1, "world").eos()).await;
        srv.send_frame(frames::headers(1).response(204).eos()).await;
        /*
        .recv_frame(frames::data(1, "hello").eos())
        .send_frame(frames::window_update(1, 5))
        */
    };
    join(srv, h2).await;
}
fn test_node_multiple_rollback_merge() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.raft_store.right_derive_when_split = true;
    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(20);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    for i in 0..10 {
        cluster.must_put(format!("k{}", i).as_bytes(), b"v");
    }

    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");

    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    let left_peer_1 = find_peer(&left, 1).unwrap().to_owned();
    cluster.must_transfer_leader(left.get_id(), left_peer_1.clone());
    assert_eq!(left_peer_1.get_id(), 1001);

    let on_schedule_merge_fp = "on_schedule_merge";
    let on_check_merge_not_1001_fp = "on_check_merge_not_1001";

    let mut right_peer_1_id = find_peer(&right, 1).unwrap().get_id();

    for i in 0..3 {
        fail::cfg(on_schedule_merge_fp, "return()").unwrap();
        cluster.must_try_merge(left.get_id(), right.get_id());
        // Change the epoch of target region and the merge will fail
        pd_client.must_remove_peer(right.get_id(), new_peer(1, right_peer_1_id));
        right_peer_1_id += 100;
        pd_client.must_add_peer(right.get_id(), new_peer(1, right_peer_1_id));
        // Only the source leader is running `on_check_merge`
        fail::cfg(on_check_merge_not_1001_fp, "return()").unwrap();
        fail::remove(on_schedule_merge_fp);
        // In previous implementation, rollback merge proposal can be proposed by leader
        // itself So wait for the leader propose rollback merge if possible
        sleep_ms(100);
        // Check if the source region is still in merging mode.
        let mut l_r = pd_client.get_region(b"k1").unwrap();
        let req = new_request(
            l_r.get_id(),
            l_r.take_region_epoch(),
            vec![new_put_cf_cmd(
                "default",
                format!("k1{}", i).as_bytes(),
                b"vv",
            )],
            false,
        );
        let resp = cluster
            .call_command_on_leader(req, Duration::from_millis(100))
            .unwrap();
        if !resp
            .get_header()
            .get_error()
            .get_message()
            .contains("merging mode")
        {
            panic!("resp {:?} does not contain merging mode error", resp);
        }

        fail::remove(on_check_merge_not_1001_fp);
        // Write data for waiting the merge to rollback easily
        cluster.must_put(format!("k1{}", i).as_bytes(), b"vv");
        // Make sure source region is not merged to target region
        assert_eq!(pd_client.get_region(b"k1").unwrap().get_id(), left.get_id());
    }
}
fn stdin_format_jupyter() {
    let args = ["format", "--stdin-filename", "Jupyter.ipynb", "--isolated"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(args)
        .pass_stdin(r#"{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dccc687c-96e2-4604-b957-a8a89b5bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1b029-f516-4662-a9b9-623b93edac1a",
   "metadata": {},
   "source": [
    "Foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdce7b92-b0fb-4c02-86f6-e233b26fa84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def func():\n",
    "  pass\n",
    "print(1)\n",
    "import os"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
"#), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    {
     "cells": [
      {
       "cell_type": "code",
       "execution_count": null,
       "id": "dccc687c-96e2-4604-b957-a8a89b5bec06",
       "metadata": {},
       "outputs": [],
       "source": [
        "x = 1"
       ]
      },
      {
       "cell_type": "markdown",
       "id": "19e1b029-f516-4662-a9b9-623b93edac1a",
       "metadata": {},
       "source": [
        "Foo"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": null,
       "id": "cdce7b92-b0fb-4c02-86f6-e233b26fa84f",
       "metadata": {},
       "outputs": [],
       "source": [
        "def func():\n",
        "    pass\n",
        "\n",
        "\n",
        "print(1)\n",
        "import os"
       ]
      }
     ],
     "metadata": {
      "kernelspec": {
       "display_name": "Python 3 (ipykernel)",
       "language": "python",
       "name": "python3"
      },
      "language_info": {
       "codemirror_mode": {
        "name": "ipython",
        "version": 3
       },
       "file_extension": ".py",
       "mimetype": "text/x-python",
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
       "version": "3.10.13"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 5
    }

    ----- stderr -----
    "###);
}
fn imul_small_test() {
    // No overflow check, 1-int.
    let mut x = Bigint {
        data: from_u32(&[5]),
    };
    x.imul_small(7);
    assert_eq!(x.data, from_u32(&[35]));

    // No overflow check, 2-ints.
    let mut x = Bigint::from_u64(0x4000000040000);
    x.imul_small(5);
    assert_eq!(x.data, from_u32(&[0x00140000, 0x140000]));

    // Overflow, 1 carry.
    let mut x = Bigint {
        data: from_u32(&[0x33333334]),
    };
    x.imul_small(5);
    assert_eq!(x.data, from_u32(&[4, 1]));

    // Overflow, 1 carry, internal.
    let mut x = Bigint::from_u64(0x133333334);
    x.imul_small(5);
    assert_eq!(x.data, from_u32(&[4, 6]));

    // Overflow, 2 carries.
    let mut x = Bigint::from_u64(0x3333333333333334);
    x.imul_small(5);
    assert_eq!(x.data, from_u32(&[4, 0, 1]));
}
fn vec_var_width_value_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<u8, Vec<&str>> = TableDefinition::new("x");

    let value = vec!["hello", "world"];
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(0, &value).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(value, table.get(0).unwrap().unwrap().value());
}
fn test_something() {
    let data = [];
    if data.len() > 0 {
        match Utf8Char::from_slice_start(data) {
            Err(_) => assert!(std::str::from_utf8(data).is_err()),
            Ok((c, len)) => assert_eq!(c.as_str(), std::str::from_utf8(&data[..len]).unwrap()),
        }
    }
}
fn render_include_tag_missing() {
    let mut tera = Tera::default();
    tera.add_raw_template("hello", "<h1>Hello {% include \"world\" %}</h1>").unwrap();
    let result = tera.render("hello", &Context::new());
    assert!(result.is_err());

    let mut tera = Tera::default();
    tera.add_raw_template("hello", "<h1>Hello {% include \"world\" ignore missing %}</h1>")
        .unwrap();
    let result = tera.render("hello", &Context::new()).unwrap();
    assert_eq!(result, "<h1>Hello </h1>".to_owned());
}
fn test_ipv4_only_toml_startup() {
    named_test_harness("ipv4_only.toml", |_, tcp_port, _, _, _| {
        let mut io_loop = Runtime::new().unwrap();
        let addr: SocketAddr = SocketAddr::new(
            Ipv4Addr::new(127, 0, 0, 1).into(),
            tcp_port.expect("no tcp_port"),
        );
        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);
        let client = AsyncClient::new(Box::new(stream), sender, None);

        let (mut client, bg) = io_loop.block_on(client).expect("client failed to connect");
        hickory_proto::spawn_bg(&io_loop, bg);

        // ipv4 should succeed
        query_a(&mut io_loop, &mut client);

        let addr: SocketAddr = SocketAddr::new(
            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 1).into(),
            tcp_port.expect("no tcp_port"),
        );
        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);
        let client = AsyncClient::new(Box::new(stream), sender, None);

        assert!(io_loop.block_on(client).is_err());
        //let (client, bg) = io_loop.block_on(client).expect("client failed to connect");
        //hickory_proto::spawn_bg(&io_loop, bg);

        // ipv6 should fail
        // FIXME: probably need to send something for proper test... maybe use JoinHandle in tokio 0.2
        // assert!(io_loop.block_on(client).is_err());
    })
}
fn test_parse_meta_item_list_lit() {
    let input = "foo(5)";
    let (inner, meta) = (input, input);

    snapshot!(inner as MetaList, @r###"
    MetaList {
        path: Path {
            segments: [
                PathSegment {
                    ident: "foo",
                },
            ],
        },
        delimiter: MacroDelimiter::Paren,
        tokens: TokenStream(`5`),
    }
    "###);

    snapshot!(meta as Meta, @r###"
    Meta::List {
        path: Path {
            segments: [
                PathSegment {
                    ident: "foo",
                },
            ],
        },
        delimiter: MacroDelimiter::Paren,
        tokens: TokenStream(`5`),
    }
    "###);

    assert_eq!(meta, inner.into());
}
fn test_install_backup_short_custom_suffix() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_custom_suffix_file_a";
    let file_b = "test_install_backup_custom_suffix_file_b";
    let suffix = "super-suffix-of-the-century";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("-b")
        .arg(format!("--suffix={suffix}"))
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn test_indent_with_indented_first_line() {
    let teststring = String::from("test\ntest1\n\ntest2\n");
    assert_eq!(
        indent(teststring, 2, Some(true), None),
        String::from("  test\n  test1\n\n  test2")
    );
}
fn migration() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    pair.client.addr = SocketAddr::new(
        Ipv4Addr::new(127, 0, 0, 1).into(),
        CLIENT_PORTS.lock().unwrap().next().unwrap(),
    );
    pair.client_conn_mut(client_ch).ping();

    // Assert that just receiving the ping message is accounted into the servers
    // anti-amplification budget
    pair.drive_client();
    pair.drive_server();
    assert_ne!(pair.server_conn_mut(server_ch).total_recvd(), 0);

    pair.drive();
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert_eq!(
        pair.server_conn_mut(server_ch).remote_address(),
        pair.client.addr
    );
}
fn render_macros_in_child_templates_same_namespace() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("grandparent", "{% block hey %}hello{% endblock hey %}"),
        ("macros", "{% macro hello()%}Hello{% endmacro hello %}"),
        ("macros2", "{% macro hi()%}Hi{% endmacro hi %}"),
        ("parent", "{% extends \"grandparent\" %}{% import \"macros\" as macros %}{% block hey %}{{macros::hello()}}{% endblock hey %}"),
        ("child", "{% extends \"parent\" %}{% import \"macros2\" as macros %}{% block hey %}{{super()}}/{{macros::hi()}}{% endblock hey %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "Hello/Hi".to_string());
}
fn tuple4_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<(&str, u8, u16, u32), (u16, u32)> =
        TableDefinition::new("table");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(table_def).unwrap();
        table.insert(&("hello", 5, 6, 7), &(0, 123)).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(table_def).unwrap();
    assert_eq!(
        table.get(&("hello", 5, 6, 7)).unwrap().unwrap().value(),
        (0, 123)
    );
}
fn mixed_levels() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-select = ["B", "Q"]

[lint.flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .arg("--config")
        .arg(&ruff_toml)
        .arg("-")
        .pass_stdin(r#"a = "abcba".strip("aba")"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:5: Q000 [*] Double quotes found but single quotes preferred
    -:1:5: B005 Using `.strip()` with multi-character strings is misleading
    -:1:19: Q000 [*] Double quotes found but single quotes preferred
    Found 3 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
async fn recv_window_update_on_stream_closed_by_data_frame() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let h2 = async move {
        let (mut client, mut h2) = client::handshake(io).await.unwrap();
        let request = Request::builder()
            .method(Method::POST)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let (response, mut stream) = client.send_request(request, false).unwrap();

        // Wait for the response
        let response = h2.drive(response).await.unwrap();
        assert_eq!(response.status(), StatusCode::OK);

        // Send a data frame, this will also close the connection
        stream.send_data("hello".into(), true).unwrap();

        // keep `stream` from being dropped in order to prevent
        // it from sending an RST_STREAM frame.
        //
        // i know this is kind of evil, but it's necessary to
        // ensure that the stream is closed by the EOS frame,
        // and not by the RST_STREAM.
        std::mem::forget(stream);

        // Wait for the connection to close
        h2.await.unwrap();
    };
    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_default_settings!(settings);
        srv.recv_frame(frames::headers(1).request("POST", "https://http2.akamai.com/"))
            .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        srv.recv_frame(frames::data(1, "hello").eos()).await;
        srv.send_frame(frames::window_update(1, 5)).await;
    };
    join(srv, h2).await;
}
fn insert_overwrite() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        assert!(table.insert("hello", "world").unwrap().is_none());
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        let old_value = table.insert("hello", "replaced").unwrap();
        assert_eq!(old_value.unwrap().value(), "world");
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("replaced", table.get("hello").unwrap().unwrap().value());
}
fn test_split_by_bytes_short_concatenated_with_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_by_bytes_short_concatenated_with_value";
    RandomFile::new(&at, name).add_bytes(10000);
    ucmd.args(&["-b1000", name]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 10);
    for filename in glob.collect() {
        assert_eq!(glob.directory.metadata(&filename).len(), 1000);
    }
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_install_mode_numeric() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let dir = "dir1";
    let dir2 = "dir2";

    let file = "file";
    let mode_arg = "--mode=333";

    at.touch(file);
    at.mkdir(dir);
    scene
        .ucmd()
        .arg(file)
        .arg(dir)
        .arg(mode_arg)
        .succeeds()
        .no_stderr();

    let dest_file = &format!("{dir}/{file}");
    assert!(at.file_exists(file));
    assert!(at.file_exists(dest_file));
    let permissions = at.metadata(dest_file).permissions();
    assert_eq!(0o100_333_u32, PermissionsExt::mode(&permissions));

    let mode_arg = "-m 0333";
    at.mkdir(dir2);

    scene.ucmd().arg(mode_arg).arg(file).arg(dir2).succeeds();

    let dest_file = &format!("{dir2}/{file}");
    assert!(at.file_exists(file));
    assert!(at.file_exists(dest_file));
    let permissions = at.metadata(dest_file).permissions();
    assert_eq!(0o100_333_u32, PermissionsExt::mode(&permissions));
}
fn traps_without_address_map() -> Result<()> {
    let mut config = Config::new();
    config.generate_address_map(false);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, ());
    let wat = r#"
        (module $hello_mod
            (func (export "run") (call $hello))
            (func $hello (unreachable))
        )
    "#;

    let module = Module::new(store.engine(), wat)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();

    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 2);
    assert_eq!(trace[0].func_name(), Some("hello"));
    assert_eq!(trace[0].func_index(), 1);
    assert_eq!(trace[0].module_offset(), None);
    assert_eq!(trace[1].func_name(), None);
    assert_eq!(trace[1].func_index(), 0);
    assert_eq!(trace[1].module_offset(), None);
    Ok(())
}
pub fn test_alter_receiver_address() {
    let port = alloc_port();
    let mut test_suite = TestSuite::new(resource_metering::Config {
        receiver_address: format!("127.0.0.1:{}", port),
        report_receiver_interval: ReadableDuration::secs(3),
        max_resource_groups: 5000,
        precision: ReadableDuration::secs(1),
    });
    test_suite.start_receiver_at(port);

    // Workload
    // [req-1, req-2]
    test_suite.setup_workload(vec!["req-1", "req-2"]);

    // | Address |
    // |   o     |
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));

    // | Address |
    // |   !     |
    test_suite.cfg_receiver_address(format!("127.0.0.1:{}", port + 1));
    test_suite.flush_receiver();
    sleep(Duration::from_millis(3500));
    assert!(test_suite.nonblock_receiver_all().is_empty());

    // | Address |
    // |   o     |
    test_suite.cfg_receiver_address(format!("127.0.0.1:{}", port));
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));
}
fn test_rmdir_empty_directory_with_parents() {
    let (at, mut ucmd) = at_and_ucmd!();

    at.mkdir_all(NESTED_DIR);

    ucmd.arg("-p").arg(NESTED_DIR).succeeds().no_stderr();

    assert!(!at.dir_exists(NESTED_DIR));
    assert!(!at.dir_exists(DIR));
}
fn create_get_set_externref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::ExternRef, 10, None);
    let table = Table::new(
        &mut store,
        table_ty,
        Val::ExternRef(Some(ExternRef::new(42_usize))),
    )?;

    assert_eq!(
        *table
            .get(&mut store, 5)
            .unwrap()
            .unwrap_externref()
            .unwrap()
            .data()
            .downcast_ref::<usize>()
            .unwrap(),
        42
    );
    table.set(&mut store, 5, Val::ExternRef(None))?;
    assert!(table
        .get(&mut store, 5)
        .unwrap()
        .unwrap_externref()
        .is_none());

    Ok(())
}
fn test_handle_truncate() {
    use tidb_query_datatype::{FieldTypeAccessor, FieldTypeTp};
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &data);
    let cols = product.columns_info();
    let cases = vec![
        {
            // count > "2x"
            let mut col = Expr::default();
            col.set_tp(ExprType::ColumnRef);
            col.mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            let count_offset = offset_for_column(&cols, product["count"].id);
            col.mut_val().encode_i64(count_offset).unwrap();

            // "2x" will be truncated.
            let mut value = Expr::default();
            value
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::String);
            value.set_tp(ExprType::String);
            value.set_val(String::from("2x").into_bytes());

            let mut right = Expr::default();
            right
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            right.set_tp(ExprType::ScalarFunc);
            right.set_sig(ScalarFuncSig::CastStringAsInt);
            right.mut_children().push(value);

            let mut cond = Expr::default();
            cond.mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            cond.set_tp(ExprType::ScalarFunc);
            cond.set_sig(ScalarFuncSig::LtInt);
            cond.mut_children().push(col);
            cond.mut_children().push(right);
            cond
        },
        {
            // id
            let mut col_id = Expr::default();
            col_id
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            col_id.set_tp(ExprType::ColumnRef);
            let id_offset = offset_for_column(&cols, product["id"].id);
            col_id.mut_val().encode_i64(id_offset).unwrap();

            // "3x" will be truncated.
            let mut value = Expr::default();
            value
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::String);
            value.set_tp(ExprType::String);
            value.set_val(String::from("3x").into_bytes());

            let mut int_3 = Expr::default();
            int_3
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            int_3.set_tp(ExprType::ScalarFunc);
            int_3.set_sig(ScalarFuncSig::CastStringAsInt);
            int_3.mut_children().push(value);

            // count
            let mut col_count = Expr::default();
            col_count
                .mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            col_count.set_tp(ExprType::ColumnRef);
            let count_offset = offset_for_column(&cols, product["count"].id);
            col_count.mut_val().encode_i64(count_offset).unwrap();

            // "3x" + count
            let mut plus = Expr::default();
            plus.mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            plus.set_tp(ExprType::ScalarFunc);
            plus.set_sig(ScalarFuncSig::PlusInt);
            plus.mut_children().push(int_3);
            plus.mut_children().push(col_count);

            // id = "3x" + count
            let mut cond = Expr::default();
            cond.mut_field_type()
                .as_mut_accessor()
                .set_tp(FieldTypeTp::LongLong);
            cond.set_tp(ExprType::ScalarFunc);
            cond.set_sig(ScalarFuncSig::EqInt);
            cond.mut_children().push(col_id);
            cond.mut_children().push(plus);
            cond
        },
    ];

    for cond in cases {
        // Ignore truncate error.
        let req = DagSelect::from(&product)
            .where_expr(cond.clone())
            .build_with(Context::default(), &[FLAG_IGNORE_TRUNCATE]);
        let resp = handle_select(&endpoint, req);
        assert!(!resp.has_error());
        assert!(resp.get_warnings().is_empty());

        // truncate as warning
        let req = DagSelect::from(&product)
            .where_expr(cond.clone())
            .build_with(Context::default(), &[FLAG_TRUNCATE_AS_WARNING]);
        let mut resp = handle_select(&endpoint, req);
        assert!(!resp.has_error());
        assert!(!resp.get_warnings().is_empty());
        // check data
        let mut spliter = DagChunkSpliter::new(resp.take_chunks().into(), 3);
        let row = spliter.next().unwrap();
        let (id, name, cnt) = data[2];
        let name_datum = name.map(|s| s.as_bytes()).into();
        let expected_encoded = datum::encode_value(
            &mut EvalContext::default(),
            &[Datum::I64(id), name_datum, cnt.into()],
        )
        .unwrap();
        let result_encoded = datum::encode_value(&mut EvalContext::default(), &row).unwrap();
        assert_eq!(&*result_encoded, &*expected_encoded);
        assert_eq!(spliter.next().is_none(), true);

        // Do NOT ignore truncate error.
        let req = DagSelect::from(&product).where_expr(cond.clone()).build();
        let resp = handle_select(&endpoint, req);
        assert!(resp.has_error());
        assert!(resp.get_warnings().is_empty());
    }
}
fn floats() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "i32.reinterpret_f32") (param f32) (result i32)
                    local.get 0
                    i32.reinterpret_f32
                )
                (func (export "i64.reinterpret_f64") (param f64) (result i64)
                    local.get 0
                    i64.reinterpret_f64
                )
                (func (export "f32.reinterpret_i32") (param i32) (result f32)
                    local.get 0
                    f32.reinterpret_i32
                )
                (func (export "f64.reinterpret_i64") (param i64) (result f64)
                    local.get 0
                    f64.reinterpret_i64
                )
            )
            (core instance $i (instantiate $m))

            (func (export "f32-to-u32") (param "a" float32) (result u32)
                (canon lift (core func $i "i32.reinterpret_f32"))
            )
            (func (export "f64-to-u64") (param "a" float64) (result u64)
                (canon lift (core func $i "i64.reinterpret_f64"))
            )
            (func (export "u32-to-f32") (param "a" u32) (result float32)
                (canon lift (core func $i "f32.reinterpret_i32"))
            )
            (func (export "u64-to-f64") (param "a" u64) (result float64)
                (canon lift (core func $i "f64.reinterpret_i64"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let f32_to_u32 = instance.get_typed_func::<(f32,), (u32,)>(&mut store, "f32-to-u32")?;
    let f64_to_u64 = instance.get_typed_func::<(f64,), (u64,)>(&mut store, "f64-to-u64")?;
    let u32_to_f32 = instance.get_typed_func::<(u32,), (f32,)>(&mut store, "u32-to-f32")?;
    let u64_to_f64 = instance.get_typed_func::<(u64,), (f64,)>(&mut store, "u64-to-f64")?;

    assert_eq!(f32_to_u32.call(&mut store, (1.0,))?, (1.0f32.to_bits(),));
    f32_to_u32.post_return(&mut store)?;
    assert_eq!(f64_to_u64.call(&mut store, (2.0,))?, (2.0f64.to_bits(),));
    f64_to_u64.post_return(&mut store)?;
    assert_eq!(u32_to_f32.call(&mut store, (3.0f32.to_bits(),))?, (3.0,));
    u32_to_f32.post_return(&mut store)?;
    assert_eq!(u64_to_f64.call(&mut store, (4.0f64.to_bits(),))?, (4.0,));
    u64_to_f64.post_return(&mut store)?;

    assert_eq!(
        u32_to_f32
            .call(&mut store, (CANON_32BIT_NAN | 1,))?
            .0
            .to_bits(),
        CANON_32BIT_NAN
    );
    u32_to_f32.post_return(&mut store)?;
    assert_eq!(
        u64_to_f64
            .call(&mut store, (CANON_64BIT_NAN | 1,))?
            .0
            .to_bits(),
        CANON_64BIT_NAN,
    );
    u64_to_f64.post_return(&mut store)?;

    assert_eq!(
        f32_to_u32.call(&mut store, (f32::from_bits(CANON_32BIT_NAN | 1),))?,
        (CANON_32BIT_NAN,)
    );
    f32_to_u32.post_return(&mut store)?;
    assert_eq!(
        f64_to_u64.call(&mut store, (f64::from_bits(CANON_64BIT_NAN | 1),))?,
        (CANON_64BIT_NAN,)
    );
    f64_to_u64.post_return(&mut store)?;

    Ok(())
}
fn lateral_derived() {
    fn chk(lateral_in: bool) {
        let lateral_str = if lateral_in { "LATERAL " } else { "" };
        let sql = format!(
            "SELECT * FROM customer LEFT JOIN {lateral_str}\
             (SELECT * FROM order WHERE order.customer = customer.id LIMIT 3) AS order ON true"
        );
        let select = verified_only_select(&sql);
        let from = only(select.from);
        assert_eq!(from.joins.len(), 1);
        let join = &from.joins[0];
        assert_eq!(
            join.join_operator,
            JoinOperator::LeftOuter(JoinConstraint::On(Expr::Value(Value::Boolean(true))))
        );
        if let TableFactor::Derived {
            lateral,
            ref subquery,
            alias: Some(ref alias),
        } = join.relation
        {
            assert_eq!(lateral_in, lateral);
            assert_eq!(Ident::new("order"), alias.name);
            assert_eq!(
                subquery.to_string(),
                "SELECT * FROM order WHERE order.customer = customer.id LIMIT 3"
            );
        } else {
            unreachable!()
        }
    }
    chk(false);
    chk(true);

    let sql = "SELECT * FROM LATERAL UNNEST ([10,20,30]) as numbers WITH OFFSET;";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: WITH".to_string()),
        res.unwrap_err()
    );

    let sql = "SELECT * FROM a LEFT JOIN LATERAL (b CROSS JOIN c)";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError(
            "Expected SELECT, VALUES, or a subquery in the query body, found: b".to_string()
        ),
        res.unwrap_err()
    );
}
fn test_touch_set_cymdhm_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_cymdhm_time";

    ucmd.args(&["-t", "201501011234", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);
}
fn test_module_name() -> anyhow::Result<()> {
    let engine = Engine::default();
    let wat = r#"
        (module $from_name_section
        (func (export "run") (nop))
        )
    "#;

    let module = Module::new(&engine, wat)?;
    assert_eq!(module.name(), Some("from_name_section"));

    Ok(())
}
fn parse_multiple_statements() {
    fn test_with(sql1: &str, sql2_kw: &str, sql2_rest: &str) {
        // Check that a string consisting of two statements delimited by a semicolon
        // parses the same as both statements individually:
        let res = parse_sql_statements(&(sql1.to_owned() + ";" + sql2_kw + sql2_rest));
        assert_eq!(
            vec![
                one_statement_parses_to(sql1, ""),
                one_statement_parses_to(&(sql2_kw.to_owned() + sql2_rest), ""),
            ],
            res.unwrap()
        );
        // Check that extra semicolon at the end is stripped by normalization:
        one_statement_parses_to(&(sql1.to_owned() + ";"), sql1);
        // Check that forgetting the semicolon results in an error:
        let res = parse_sql_statements(&(sql1.to_owned() + " " + sql2_kw + sql2_rest));
        assert_eq!(
            ParserError::ParserError("Expected end of statement, found: ".to_string() + sql2_kw),
            res.unwrap_err()
        );
    }
    test_with("SELECT foo", "SELECT", " bar");
    // ensure that SELECT/WITH is not parsed as a table or column alias if ';'
    // separating the statements is omitted:
    test_with("SELECT foo FROM baz", "SELECT", " bar");
    test_with("SELECT foo", "WITH", " cte AS (SELECT 1 AS s) SELECT bar");
    test_with(
        "SELECT foo FROM baz",
        "WITH",
        " cte AS (SELECT 1 AS s) SELECT bar",
    );
    test_with("DELETE FROM foo", "SELECT", " bar");
    test_with("INSERT INTO foo VALUES (1)", "SELECT", " bar");
    test_with("CREATE TABLE foo (baz INT)", "SELECT", " bar");
    // Make sure that empty statements do not cause an error:
    let res = parse_sql_statements(";;");
    assert_eq!(0, res.unwrap().len());
}
fn test_trailing_comma_newtype_struct() {
    assert!(from_str::<Newtype>("(1)").is_ok());
    assert!(from_str::<Newtype>("(1,)").is_ok());
    assert!(from_str::<Newtype>("(1,,)").is_err());
}
fn can_fail_rendering_from_template() {
    let mut context = Context::new();
    context.insert("title", "hello");

    let res = render_template(
        r#"{{ throw(message="Error: " ~ title ~ " did not include a summary") }}"#,
        &context,
    );

    let err = res.expect_err("This should always fail to render");
    let source = err.source().expect("Must have a source");
    assert_eq!(source.to_string(), "Function call 'throw' failed");

    let source = source.source().expect("Should have a nested error");
    assert_eq!(source.to_string(), "Error: hello did not include a summary");
}
fn issue580() {
    #[derive(Debug, Deserialize, PartialEq, Eq)]
    struct Seq {
        #[serde(rename = "$value")]
        items: Vec<Wrapper>,
    }

    #[derive(Debug, Deserialize, PartialEq, Eq)]
    struct Wrapper(#[serde(deserialize_with = "Item::parse")] Item);

    #[derive(Debug, PartialEq, Eq)]
    struct Item;
    impl Item {
        fn parse<'de, D>(deserializer: D) -> Result<Self, D::Error>
        where
            D: Deserializer<'de>,
        {
            // We should consume something from the deserializer, otherwise this
            // leads to infinity loop
            IgnoredAny::deserialize(deserializer)?;
            Ok(Item)
        }
    }

    assert_eq!(
        from_str::<Seq>(
            r#"
        <Seq>
            <One/>
            <Two/>
        </Seq>"#
        )
        .unwrap(),
        Seq {
            items: vec![Wrapper(Item), Wrapper(Item)],
        }
    );
}
fn test_deny_non_finite_f64_key() {
    // We store float bits so that we can derive Ord, and other traits. In a
    // real context the code might involve a crate like ordered-float.

    #[derive(Eq, PartialEq, Ord, PartialOrd, Debug, Clone)]
    struct F64Bits(u64);
    impl Serialize for F64Bits {
        fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
        where
            S: Serializer,
        {
            serializer.serialize_f64(f64::from_bits(self.0))
        }
    }

    let map = treemap!(F64Bits(f64::INFINITY.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());

    let map = treemap!(F64Bits(f64::NEG_INFINITY.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());

    let map = treemap!(F64Bits(f64::NAN.to_bits()) => "x".to_owned());
    assert!(serde_json::to_string(&map).is_err());
    assert!(serde_json::to_value(map).is_err());
}
fn test_install_failing_omitting_directory() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let file1 = "file1";
    let dir1 = "dir1";
    let no_dir2 = "no-dir2";
    let dir3 = "dir3";

    at.mkdir(dir1);
    at.mkdir(dir3);
    at.touch(file1);

    // GNU install checks for existing target dir first before checking on source params
    scene
        .ucmd()
        .arg(file1)
        .arg(dir1)
        .arg(no_dir2)
        .fails()
        .stderr_contains("is not a directory");

    // file1 will be copied before install fails on dir1
    scene
        .ucmd()
        .arg(file1)
        .arg(dir1)
        .arg(dir3)
        .fails()
        .code_is(1)
        .stderr_contains("omitting directory");
    assert!(at.file_exists(format!("{dir3}/{file1}")));

    // install also fails, when only one source param is given
    scene
        .ucmd()
        .arg(dir1)
        .arg(dir3)
        .fails()
        .code_is(1)
        .stderr_contains("omitting directory");
}
fn valid_context_directory_recursive() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.mkdir("a");
    dir.symlink_dir("a", "la");

    let b_path = Path::new("a").join("b.txt");
    dir.touch(b_path.to_str().unwrap());

    let a_context = get_file_context(dir.plus("a")).unwrap();
    let b_context = get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap();

    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    // -P (default): do not traverse any symbolic links.
    cmd.args(&["--verbose", "--recursive", new_la_context])
        .arg(dir.plus("la"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("la")).unwrap().as_deref(),
        Some(new_la_context)
    );
    assert_eq!(get_file_context(dir.plus("a")).unwrap(), a_context);
    assert_eq!(
        get_file_context(dir.plus(b_path.to_str().unwrap())).unwrap(),
        b_context
    );
}
fn test_in() {
    assert_vis_parse!("pub(in foo::bar)", Ok(Visibility::Restricted(_)));
}
fn should_disable_a_rule_group() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(
        config_path.into(),
        CONFIG_LINTER_SUPPRESSED_GROUP.as_bytes(),
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, "(1 >= -0)");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_disable_a_rule_group",
        fs,
        console,
        result,
    ));
}
fn parse_alter_table_alter_column() {
    let alter_stmt = "ALTER TABLE tab";
    match alter_table_op(verified_stmt(&format!(
        "{alter_stmt} ALTER COLUMN is_active SET NOT NULL"
    ))) {
        AlterTableOperation::AlterColumn { column_name, op } => {
            assert_eq!("is_active", column_name.to_string());
            assert_eq!(op, AlterColumnOperation::SetNotNull {});
        }
        _ => unreachable!(),
    }

    one_statement_parses_to(
        "ALTER TABLE tab ALTER is_active DROP NOT NULL",
        "ALTER TABLE tab ALTER COLUMN is_active DROP NOT NULL",
    );

    match alter_table_op(verified_stmt(&format!(
        "{alter_stmt} ALTER COLUMN is_active SET DEFAULT false"
    ))) {
        AlterTableOperation::AlterColumn { column_name, op } => {
            assert_eq!("is_active", column_name.to_string());
            assert_eq!(
                op,
                AlterColumnOperation::SetDefault {
                    value: Expr::Value(Value::Boolean(false))
                }
            );
        }
        _ => unreachable!(),
    }

    match alter_table_op(verified_stmt(&format!(
        "{alter_stmt} ALTER COLUMN is_active DROP DEFAULT"
    ))) {
        AlterTableOperation::AlterColumn { column_name, op } => {
            assert_eq!("is_active", column_name.to_string());
            assert_eq!(op, AlterColumnOperation::DropDefault {});
        }
        _ => unreachable!(),
    }
}
fn parse_create_or_replace_view() {
    let sql = "CREATE OR REPLACE VIEW v AS SELECT 1";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            columns,
            or_replace,
            with_options,
            query,
            materialized,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("v", name.to_string());
            assert_eq!(columns, vec![]);
            assert_eq!(with_options, vec![]);
            assert_eq!("SELECT 1", query.to_string());
            assert!(!materialized);
            assert!(or_replace);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(!temporary);
        }
        _ => unreachable!(),
    }
}
fn test_serialize_unsized_value_to_raw_value() {
    assert_eq!(
        serde_json::value::to_raw_value("foobar").unwrap().get(),
        r#""foobar""#,
    );
}
fn check_filter_matching() {
    let requests = load_requests();

    let mut requests_checked = 0;

    assert!(requests.len() > 0, "List of parsed request info is empty");

    let opts = ParseOptions::default();

    for req in requests {
        for filter in req.filters {
            let network_filter_res = NetworkFilter::parse(&filter, true, opts);
            assert!(
                network_filter_res.is_ok(),
                "Could not parse filter {}",
                filter
            );
            let network_filter = network_filter_res.unwrap();

            let request_res = Request::new(&req.url, &req.sourceUrl, &req.r#type);
            // The dataset has cases where URL is set to just "http://" or "https://", which we do not support
            if request_res.is_ok() {
                let request = request_res.unwrap();
                assert!(
                    network_filter.matches(&request, &mut RegexManager::default()),
                    "Expected {} to match {} at {}, typed {}",
                    filter,
                    req.url,
                    req.sourceUrl,
                    req.r#type
                );
                requests_checked += 1;
            }
        }
    }

    assert_eq!(requests_checked, 9354); // A catch for regressions
}
fn test_install_backup_numbered_if_existing_backup_nil() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";
    let file_b_backup = "test_install_backup_numbering_file_b.~1~";

    at.touch(file_a);
    at.touch(file_b);
    at.touch(file_b_backup);
    scene
        .ucmd()
        .arg("--backup=nil")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(file_b_backup));
    assert!(at.file_exists(format!("{file_b}.~2~")));
}
async fn push_request() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        client
            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))
            .await;
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .eos(),
            )
            .await;
        client
            .recv_frame(
                frames::push_promise(1, 2).request("GET", "https://http2.akamai.com/style.css"),
            )
            .await;
        client
            .recv_frame(frames::headers(2).response(200).eos())
            .await;
        client
            .recv_frame(
                frames::push_promise(1, 4).request("GET", "https://http2.akamai.com/style2.css"),
            )
            .await;
        client
            .recv_frame(frames::headers(4).response(200).eos())
            .await;
        client
            .recv_frame(frames::headers(1).response(200).eos())
            .await;
    };

    let srv = async move {
        let mut srv = server::handshake(io).await.expect("handshake");
        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(req.method(), &http::Method::GET);

        // Promise stream 2
        let mut pushed_s2 = {
            let req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style.css")
                .body(())
                .unwrap();
            stream.push_request(req).unwrap()
        };

        // Promise stream 4 and push response headers
        {
            let req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style2.css")
                .body(())
                .unwrap();
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            stream
                .push_request(req)
                .unwrap()
                .send_response(rsp, true)
                .unwrap();
        }

        // Push response to stream 2
        {
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            pushed_s2.send_response(rsp, true).unwrap();
        }

        // Send response for stream 1
        let rsp = http::Response::builder().status(200).body(()).unwrap();
        stream.send_response(rsp, true).unwrap();

        assert!(srv.next().await.is_none());
    };

    join(client, srv).await;
}
fn test_new_xml_decl_full() {
    let mut writer = Writer::new(Vec::new());
    writer
        .write_event(Decl(BytesDecl::new("1.2", Some("utf-X"), Some("yo"))))
        .expect("writing xml decl should succeed");

    let result = writer.into_inner();
    assert_eq!(
        String::from_utf8(result).expect("utf-8 output"),
        "<?xml version=\"1.2\" encoding=\"utf-X\" standalone=\"yo\"?>",
        "writer output (LHS)"
    );
}
fn test_ingest_sst_region_not_found() {
    let (_cluster, mut ctx_not_found, _, import) = new_cluster_and_tikv_import_client();

    let temp_dir = Builder::new()
        .prefix("test_ingest_sst_errors")
        .tempdir()
        .unwrap();

    ctx_not_found.set_region_id(1 << 31); // A large region id that must no exists.
    let sst_path = temp_dir.path().join("test_split.sst");
    let sst_range = (0, 100);
    let (mut meta, _data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx_not_found.get_region_id());
    meta.set_region_epoch(ctx_not_found.get_region_epoch().clone());

    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx_not_found);
    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(resp.get_error().has_region_not_found());
}
fn test_parse_toml() {
    let config = Config::from_toml("listen_port = 2053").unwrap();
    assert_eq!(config.get_listen_port(), 2053);

    let config = Config::from_toml("listen_addrs_ipv4 = [\"0.0.0.0\"]").unwrap();
    assert_eq!(
        config.get_listen_addrs_ipv4(),
        Ok(vec![Ipv4Addr::new(0, 0, 0, 0)])
    );

    let config = Config::from_toml("listen_addrs_ipv4 = [\"0.0.0.0\", \"127.0.0.1\"]").unwrap();
    assert_eq!(
        config.get_listen_addrs_ipv4(),
        Ok(vec![Ipv4Addr::new(0, 0, 0, 0), Ipv4Addr::new(127, 0, 0, 1)])
    );

    let config = Config::from_toml("listen_addrs_ipv6 = [\"::0\"]").unwrap();
    assert_eq!(
        config.get_listen_addrs_ipv6(),
        Ok(vec![Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 0)])
    );

    let config = Config::from_toml("listen_addrs_ipv6 = [\"::0\", \"::1\"]").unwrap();
    assert_eq!(
        config.get_listen_addrs_ipv6(),
        Ok(vec![
            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 0),
            Ipv6Addr::new(0, 0, 0, 0, 0, 0, 0, 1),
        ])
    );

    let config = Config::from_toml("tcp_request_timeout = 25").unwrap();
    assert_eq!(config.get_tcp_request_timeout(), Duration::from_secs(25));

    let config = Config::from_toml("log_level = \"Debug\"").unwrap();
    assert_eq!(config.get_log_level(), tracing::Level::DEBUG);

    let config = Config::from_toml("directory = \"/dev/null\"").unwrap();
    assert_eq!(config.get_directory(), Path::new("/dev/null"));
}
fn compute_error32_test() {
    // These test near-halfway cases for single-precision floats.
    assert_eq!(compute_error32(0, 16777216), (111 + f32::INVALID_FP, 9223372036854775808));
    assert_eq!(compute_error32(0, 16777217), (111 + f32::INVALID_FP, 9223372586610589696));
    assert_eq!(compute_error32(0, 16777218), (111 + f32::INVALID_FP, 9223373136366403584));
    assert_eq!(compute_error32(0, 16777219), (111 + f32::INVALID_FP, 9223373686122217472));
    assert_eq!(compute_error32(0, 16777220), (111 + f32::INVALID_FP, 9223374235878031360));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(
        compute_error32(-10, 167772160000000000),
        (111 + f32::INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error32(-10, 167772170000000000),
        (111 + f32::INVALID_FP, 9223372586610589696)
    );
    assert_eq!(
        compute_error32(-10, 167772180000000000),
        (111 + f32::INVALID_FP, 9223373136366403584)
    );
    // Let's check the lines to see if anything is different in table...
    assert_eq!(
        compute_error32(-10, 167772190000000000),
        (111 + f32::INVALID_FP, 9223373686122217472)
    );
    assert_eq!(
        compute_error32(-10, 167772200000000000),
        (111 + f32::INVALID_FP, 9223374235878031360)
    );
}
fn test_mv_into_self_data() {
    let scene = TestScenario::new(util_name!());

    let at = &scene.fixtures;
    let sub_dir = "sub_folder";
    let file1 = "t1.test";
    let file2 = "sub_folder/t2.test";

    let file1_result_location = "sub_folder/t1.test";

    at.mkdir(sub_dir);
    at.touch(file1);
    at.touch(file2);

    let result = scene.ucmd().arg(file1).arg(sub_dir).arg(sub_dir).run();

    // sub_dir exists, file1 has been moved, file2 still exists.
    result.code_is(1);

    assert!(at.dir_exists(sub_dir));
    assert!(at.file_exists(file1_result_location));
    assert!(at.file_exists(file2));
    assert!(!at.file_exists(file1));
}
fn parse_comment_tag() {
    let ast = parse("{# hey #}").unwrap();
    assert!(ast.is_empty());
}
fn test_cdc_rawkv_resolved_ts() {
    let mut suite = TestSuite::new(1, ApiVersion::V2);
    let cluster = &suite.cluster;

    let region = cluster.get_region(b"");
    let region_id = region.get_id();
    let leader = region.get_peers()[0].clone();
    let node_id = leader.get_id();
    let ts_provider = cluster.sim.rl().get_causal_ts_provider(node_id).unwrap();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut req = suite.new_changedata_request(region_id);
    req.set_kv_api(ChangeDataRequestKvApi::RawKv);
    let (mut req_tx, _event_feed_wrap, receive_event) =
        new_event_feed(suite.get_region_cdc_client(region_id));
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();

    let event = receive_event(false);
    event
        .events
        .into_iter()
        .for_each(|e| match e.event.unwrap() {
            Event_oneof_event::Entries(es) => {
                assert!(es.entries.len() == 1, "{:?}", es);
                let e = &es.entries[0];
                assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
            }
            other => panic!("unknown event {:?}", other),
        });
    // Sleep a while to make sure the stream is registered.
    sleep_ms(1000);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);
    ctx.set_api_version(ApiVersion::V2);
    let mut put_req = RawPutRequest::default();
    put_req.set_context(ctx);
    put_req.key = b"rk3".to_vec();
    put_req.value = b"v3".to_vec();

    let pause_write_fp = "raftkv_async_write";
    fail::cfg(pause_write_fp, "pause").unwrap();
    let ts = block_on(ts_provider.async_get_ts()).unwrap();
    let handle = thread::spawn(move || {
        let _ = client.raw_put(&put_req).unwrap();
    });

    sleep_ms(100);

    let event = receive_event(true).resolved_ts.unwrap();
    assert!(
        ts.next() >= TimeStamp::from(event.ts),
        "{} {}",
        ts,
        TimeStamp::from(event.ts)
    );
    // Receive again to make sure resolved ts <= ongoing request's ts.
    let event = receive_event(true).resolved_ts.unwrap();
    assert!(
        ts.next() >= TimeStamp::from(event.ts),
        "{} {}",
        ts,
        TimeStamp::from(event.ts)
    );

    fail::remove(pause_write_fp);
    handle.join().unwrap();
}
fn test_convert_eh_frame() {
    // Convert existing section
    let eh_frame = read_section("eh_frame");
    let mut eh_frame = read::EhFrame::new(&eh_frame, LittleEndian);
    // The `.eh_frame` fixture data was created on a 64-bit machine.
    eh_frame.set_address_size(8);
    let frames = write::FrameTable::from(&eh_frame, &|address| Some(Address::Constant(address)))
        .expect("Should convert eh_frame information");
    assert_eq!(frames.cie_count(), 2);
    assert_eq!(frames.fde_count(), 3482);

    // Write to new section
    let mut write_eh_frame = write::EhFrame(EndianVec::new(LittleEndian));
    frames
        .write_eh_frame(&mut write_eh_frame)
        .expect("Should write eh_frame information");
    let eh_frame = write_eh_frame.slice();
    assert_eq!(eh_frame.len(), 147144);

    // Convert new section
    let mut eh_frame = read::EhFrame::new(&eh_frame, LittleEndian);
    eh_frame.set_address_size(8);
    let frames = write::FrameTable::from(&eh_frame, &|address| Some(Address::Constant(address)))
        .expect("Should convert eh_frame information");
    assert_eq!(frames.cie_count(), 2);
    assert_eq!(frames.fde_count(), 3482);
}
fn test_incompatible_version() {
    let incompatible = Arc::new(Incompatible);
    let server = MockServer::with_case(1, incompatible);
    let eps = server.bind_addrs();

    let mut client = new_client_v2(eps, None);

    let resp = block_on(client.ask_batch_split(metapb::Region::default(), 2));
    assert_eq!(
        resp.unwrap_err().to_string(),
        PdError::Incompatible.to_string()
    );
}
fn eph_ephemeron_test() {
    run_test(|| {
        let gc_value = Gc::new(3);

        {
            let cloned_gc = gc_value.clone();

            let ephemeron = Ephemeron::new(&cloned_gc, String::from("Hello World!"));

            assert_eq!(
                *ephemeron.value().expect("Ephemeron is live"),
                String::from("Hello World!")
            );
            drop(cloned_gc);
            force_collect();
            assert_eq!(
                *ephemeron.value().expect("Ephemeron is still live here"),
                String::from("Hello World!")
            );

            drop(gc_value);
            force_collect();

            assert!(ephemeron.value().is_none());
        }
    });
}
fn test_engine_leader_change_twice() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();

    let region = cluster.get_region(b"");
    let peers = region.get_peers();

    cluster.must_transfer_leader(region.get_id(), peers[0].clone());
    let engine = cluster.sim.rl().storages[&peers[0].get_id()].clone();

    let term = cluster
        .request(b"", vec![new_get_cmd(b"")], true, Duration::from_secs(5))
        .get_header()
        .get_current_term();

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(peers[0].clone());
    ctx.set_term(term);

    // Not leader.
    cluster.must_transfer_leader(region.get_id(), peers[1].clone());
    engine
        .put(&ctx, Key::from_raw(b"a"), b"a".to_vec())
        .unwrap_err();
    // Term not match.
    cluster.must_transfer_leader(region.get_id(), peers[0].clone());
    let res = engine.put(&ctx, Key::from_raw(b"a"), b"a".to_vec());
    if let KvError(box KvErrorInner::Request(ref e)) = *res.as_ref().err().unwrap() {
        assert!(e.has_stale_command());
    } else {
        panic!("expect stale command, but got {:?}", res);
    }
}
fn datagram_unsupported() {
    let _guard = subscribe();
    let server = ServerConfig {
        transport: Arc::new(TransportConfig {
            datagram_receive_buffer_size: None,
            ..TransportConfig::default()
        }),
        ..server_config()
    };
    let mut pair = Pair::new(Default::default(), server);
    let (client_ch, server_ch) = pair.connect();
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    assert_matches!(pair.client_datagrams(client_ch).max_size(), None);

    match pair.client_datagrams(client_ch).send(Bytes::new()) {
        Err(SendDatagramError::UnsupportedByPeer) => {}
        Err(e) => panic!("unexpected error: {e}"),
        Ok(_) => panic!("unexpected success"),
    }
}
fn test_parse_meta_name_value() {
    let input = "foo = 5";
    let (inner, meta) = (input, input);

    snapshot!(inner as MetaNameValue, @r###"
    MetaNameValue {
        path: Path {
            segments: [
                PathSegment {
                    ident: "foo",
                },
            ],
        },
        value: Expr::Lit {
            lit: 5,
        },
    }
    "###);

    snapshot!(meta as Meta, @r###"
    Meta::NameValue {
        path: Path {
            segments: [
                PathSegment {
                    ident: "foo",
                },
            ],
        },
        value: Expr::Lit {
            lit: 5,
        },
    }
    "###);

    assert_eq!(meta, inner.into());
}
fn test_buckets() {
    let product = ProductTable::new();
    let (mut cluster, raft_engine, ctx) = new_raft_engine(1, "");

    let (_, endpoint, _) =
        init_data_with_engine_and_commit(ctx.clone(), raft_engine, &product, &[], true);

    let req = DagSelect::from(&product).build_with(ctx, &[0]);
    let resp = handle_request(&endpoint, req.clone());
    assert_eq!(resp.get_latest_buckets_version(), 0);

    let mut bucket_key = product.get_record_range_all().get_start().to_owned();
    bucket_key.push(0);
    let region = cluster.get_region(&bucket_key);
    let bucket = Bucket {
        keys: vec![bucket_key],
        size: 1024,
    };
    cluster.refresh_region_bucket_keys(&region, vec![bucket], None, None);

    let wait_refresh_buckets = |old_buckets_ver| {
        let mut resp = Default::default();
        for _ in 0..10 {
            resp = handle_request(&endpoint, req.clone());
            if resp.get_latest_buckets_version() != old_buckets_ver {
                break;
            }
            thread::sleep(Duration::from_millis(100));
        }
        assert_ne!(resp.get_latest_buckets_version(), old_buckets_ver);
    };

    wait_refresh_buckets(0);
}
fn test_skip_iter_l() {
    // Test iterators that skip single, leading-only digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_leading_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"45_5");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"_45__5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".45_5");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"_.45__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"4_5_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4__5__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"4_5_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4__5__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"_45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"_45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"4_5_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"_4__5__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"4_5_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"_4__5__.56");
}
fn write_batch_is_empty() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    assert!(wb.is_empty());
    wb.put(b"a", b"").unwrap();
    assert!(!wb.is_empty());
    wb.write().unwrap();
    assert!(!wb.is_empty());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);

    assert!(wb.is_empty());
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    assert!(!wb.is_empty());
    wb.write().unwrap();
    assert!(!wb.is_empty());
}
fn delete() -> Result<()> {
    let tempdir = tempdir();
    let sst_path = tempdir
        .path()
        .join("test-data.sst")
        .to_string_lossy()
        .to_string();
    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();
    let mut sst_writer = sst_builder.build(&sst_path)?;

    sst_writer.delete(b"k1")?;
    sst_writer.finish()?;

    let sst_reader = <KvTestEngine as SstExt>::SstReader::open(&sst_path)?;
    let mut iter = sst_reader.iter(IterOptions::default()).unwrap();

    iter.seek_to_first()?;

    assert_eq!(iter.valid()?, false);

    iter.prev().unwrap_err();
    iter.next().unwrap_err();
    recover_safe(|| {
        iter.key();
    })
    .unwrap_err();
    recover_safe(|| {
        iter.value();
    })
    .unwrap_err();

    assert_eq!(iter.seek_to_first()?, false);
    assert_eq!(iter.seek_to_last()?, false);
    assert_eq!(iter.seek(b"foo")?, false);
    assert_eq!(iter.seek_for_prev(b"foo")?, false);

    Ok(())
}
fn respect_enforce_extension() {
    let f = super::fixture().join("extensions");

    let resolved = Resolver::new(ResolveOptions {
        enforce_extension: EnforceExtension::Disabled,
        extensions: vec![".ts".into(), String::new(), ".js".into()],
        ..ResolveOptions::default()
    })
    .resolve(&f, "./foo");
    assert_eq!(resolved.map(Resolution::into_path_buf), Ok(f.join("foo.ts")));
    // TODO: need to match missingDependencies returned from the resolve function
}
fn options_test() {
    let mut opts = Options::new();

    unsafe {
        opts.set_lossy(true);
        opts.set_exponent(b'^');
        opts.set_decimal_point(b',');
        opts.set_nan_string(Some(b"nan"));
        opts.set_inf_string(Some(b"Infinity"));
        opts.set_infinity_string(Some(b"Infiniiiiiity"));
    }

    assert_eq!(opts.lossy(), true);
    assert_eq!(opts.exponent(), b'^');
    assert_eq!(opts.decimal_point(), b',');
    assert_eq!(opts.nan_string(), Some("nan".as_bytes()));
    assert_eq!(opts.inf_string(), Some("Infinity".as_bytes()));
    assert_eq!(opts.infinity_string(), Some("Infiniiiiiity".as_bytes()));
    assert!(opts.is_valid());

    assert_eq!(Options::builder(), OptionsBuilder::new());
    assert_eq!(opts.rebuild().build(), Ok(opts));
}
fn u32_pow10_test() {
    let values: &[u32] = &[
        0, 1, 5, 9, 10, 11, 15, 99, 100, 101, 105, 999, 1000, 1001, 1005, 9999, 10000, 10001,
        10005, 99999, 100000, 100001, 100005, 999999, 1000000, 1000001, 1000005, 9999999, 10000000,
        10000001, 10000005, 99999999, 100000000, 100000001, 100000005, 999999999, 1000000000,
        1000000001, 1000000005,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn command_not_found() {
  let tmp = tempdir();

  fs::write(tmp.path().join("justfile"), "").unwrap();

  let output = Command::new(executable_path("just"))
    .args(["--command", "asdfasdfasdfasdfadfsadsfadsf", "bar"])
    .output()
    .unwrap();

  assert!(str::from_utf8(&output.stderr)
    .unwrap()
    .starts_with("error: Failed to invoke `asdfasdfasdfasdfadfsadsfadsf` `bar`:"));

  assert!(!output.status.success());
}
fn render_magic_variable_gets_all_contexts() {
    let mut context = Context::new();
    context.insert("html", &"<html>");
    context.insert("num", &1);
    context.insert("i", &10);

    let result = render_template(
        "{% set some_val = 1 %}{% for i in range(start=0, end=1) %}{% set for_val = i %}{{ __tera_context }}{% endfor %}",
        &context
    );

    assert_eq!(
        result.unwrap(),
        r#"{
  "for_val": 0,
  "html": "<html>",
  "i": 0,
  "num": 1,
  "some_val": 1
}"#
        .to_owned()
    );
}
async fn push_request_with_data() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        client
            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))
            .await;
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .eos(),
            )
            .await;
        client.recv_frame(frames::headers(1).response(200)).await;
        client
            .recv_frame(
                frames::push_promise(1, 2).request("GET", "https://http2.akamai.com/style.css"),
            )
            .await;
        client.recv_frame(frames::headers(2).response(200)).await;
        client.recv_frame(frames::data(1, &b""[..]).eos()).await;
        client.recv_frame(frames::data(2, &b"\x00"[..]).eos()).await;
    };

    let srv = async move {
        let mut srv = server::handshake(io).await.expect("handshake");
        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(req.method(), &http::Method::GET);

        // Start response to stream 1
        let mut s1_tx = {
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            stream.send_response(rsp, false).unwrap()
        };

        // Promise stream 2, push response headers and send data
        {
            let pushed_req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style.css")
                .body(())
                .unwrap();
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            let mut push_tx = stream
                .push_request(pushed_req)
                .unwrap()
                .send_response(rsp, false)
                .unwrap();
            // Make sure nothing can queue our pushed stream before we have the PushPromise sent
            push_tx.send_data(vec![0; 1].into(), true).unwrap();
            push_tx.reserve_capacity(1);
        }

        // End response for stream 1
        s1_tx.send_data(vec![0; 0].into(), true).unwrap();

        assert!(srv.next().await.is_none());
    };

    join(client, srv).await;
}
fn is_empty() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(STR_TABLE).unwrap();
    assert!(!table.is_empty().unwrap());
}
fn parse_set_tag_fn_call() {
    let ast = parse("{% set hello = utcnow() %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Set(
            WS::default(),
            Set {
                key: "hello".to_string(),
                value: Expr::new(ExprVal::FunctionCall(FunctionCall {
                    name: "utcnow".to_string(),
                    args: HashMap::new(),
                },)),
                global: false,
            },
        )
    );
}
fn test_split_separator_nul_number_r() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--number=r/3", "--separator=\\0", "separator_nul.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\x004\0");
    assert_eq!(file_read(&at, "xab"), "2\x005\0");
    assert_eq!(file_read(&at, "xac"), "3\0");
    assert!(!at.plus("xad").exists());
}
fn test_cname_lookup_preserve() {
    let resp_query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let cname_record = cname_record(
        Name::from_str("www.example.com.").unwrap(),
        Name::from_str("v4.example.com.").unwrap(),
    );
    let v4_record = v4_record(
        Name::from_str("v4.example.com.").unwrap(),
        Ipv4Addr::new(93, 184, 216, 34),
    );
    let message = message(
        resp_query,
        vec![cname_record.clone(), v4_record],
        vec![],
        vec![],
    );
    let client: MockClientHandle<_, ResolveError> =
        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, true),
    );

    let io_loop = Runtime::new().unwrap();
    let lookup = io_loop.block_on(lookup).unwrap();

    let mut iter = lookup.iter();
    assert_eq!(iter.next().unwrap(), cname_record.data().unwrap());
    assert_eq!(*iter.next().unwrap(), RData::A(A::new(93, 184, 216, 34)));
}
fn test_decimal_length9() {
    assert_eq!(1, decimal_length9(0));
    assert_eq!(1, decimal_length9(1));
    assert_eq!(1, decimal_length9(9));
    assert_eq!(2, decimal_length9(10));
    assert_eq!(2, decimal_length9(99));
    assert_eq!(3, decimal_length9(100));
    assert_eq!(3, decimal_length9(999));
    assert_eq!(9, decimal_length9(999999999));
}
fn roots() {
    let f = super::fixture();

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        alias: vec![("foo".into(), vec![AliasValue::Path("/fixtures".into())])],
        roots: vec![dirname(), f.clone()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("should respect roots option", "/fixtures/b.js", f.join("b.js")),
        ("should try another root option, if it exists", "/b.js", f.join("b.js")),
        ("should respect extension", "/fixtures/b", f.join("b.js")),
        ("should resolve in directory", "/fixtures/extensions/dir", f.join("extensions/dir/index.js")),
        ("should respect aliases", "foo/b", f.join("b.js")),
    ];

    for (comment, request, expected) in pass {
        let resolved_path = resolver.resolve(&f, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {request}");
    }

    #[rustfmt::skip]
    let fail = [
        ("should not work with relative path", "fixtures/b.js", ResolveError::NotFound(f.clone()))
    ];

    for (comment, request, expected) in fail {
        let resolution = resolver.resolve(&f, request);
        assert_eq!(resolution, Err(expected), "{comment} {request}");
    }
}
fn apply_suggested_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_suggested_error",
        fs,
        console,
        result,
    ));
}
fn no_lint_when_file_is_ignored() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_LINTER_IGNORED_FILES.as_bytes());

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_when_file_is_ignored",
        fs,
        console,
        result,
    ));
}
fn parse_text() {
    let ast = parse("hello world").unwrap();
    assert_eq!(ast[0], Node::Text("hello world".to_string()));
}
fn test_symlink_relative_dir() {
    let (at, mut ucmd) = at_and_ucmd!();

    let dir = "test_symlink_existing_dir";
    let link = "test_symlink_existing_dir_link";

    at.mkdir(dir);

    ucmd.args(&["-s", "-r", dir, link]).succeeds().no_stderr();
    assert!(at.dir_exists(dir));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), dir);
}
fn wasi_misaligned_pointer() -> Result<()> {
    let output = get_wasmtime_command()?
        .arg("./tests/all/cli_tests/wasi_misaligned_pointer.wat")
        .output()?;
    assert!(!output.status.success());
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("Pointer not aligned"),
        "bad stderr: {stderr}",
    );
    Ok(())
}
fn parse_create_schema_with_name_and_authorization() {
    let sql = "CREATE SCHEMA X AUTHORIZATION Y";

    match verified_stmt(sql) {
        Statement::CreateSchema { schema_name, .. } => {
            assert_eq!(schema_name.to_string(), "X AUTHORIZATION Y".to_owned())
        }
        _ => unreachable!(),
    }
}
fn parse_map_access_offset() {
    let sql = "SELECT d[offset(0)]";
    let _select = bigquery().verified_only_select(sql);
    assert_eq!(
        _select.projection[0],
        SelectItem::UnnamedExpr(Expr::MapAccess {
            column: Box::new(Expr::Identifier(Ident {
                value: "d".to_string(),
                quote_style: None,
            })),
            keys: vec![Expr::Function(Function {
                name: ObjectName(vec!["offset".into()]),
                args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::Value(
                    number("0")
                ))),],
                null_treatment: None,
                filter: None,
                over: None,
                distinct: false,
                special: false,
                order_by: vec![],
            })],
        })
    );

    // test other operators
    for sql in [
        "SELECT d[SAFE_OFFSET(0)]",
        "SELECT d[ORDINAL(0)]",
        "SELECT d[SAFE_ORDINAL(0)]",
    ] {
        bigquery().verified_only_select(sql);
    }
}
fn parse_null_in_select() {
    let sql = "SELECT NULL";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Value(Value::Null),
        expr_from_projection(only(&select.projection)),
    );
}
fn test_get_tombstone_store() {
    let eps_count = 1;
    let server = MockServer::new(eps_count);
    let eps = server.bind_addrs();
    let mut client = new_client_v2(eps, None);

    let mut all_stores = vec![];
    let store_id = client.alloc_id().unwrap();
    let mut store = metapb::Store::default();
    store.set_id(store_id);
    let region_id = client.alloc_id().unwrap();
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    client.bootstrap_cluster(store.clone(), region).unwrap();

    all_stores.push(store);
    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);
    let s = client.get_all_stores(false).unwrap();
    assert_eq!(s, all_stores);

    // Add tombstone store.
    let mut store99 = metapb::Store::default();
    store99.set_id(99);
    store99.set_state(metapb::StoreState::Tombstone);
    server.default_handler().add_store(store99.clone());

    let r = client.get_store(99);
    assert_eq!(r.unwrap_err().error_code(), error_code::pd::STORE_TOMBSTONE);
}
fn sqrtf_spec_test() {
    // Not Asserted: FE_INVALID exception is raised if argument is negative.
    assert!(libm::sqrtf(-1.0).is_nan());
    assert!(libm::sqrtf(f32::NAN).is_nan());
    for f in [0.0, -0.0, f32::INFINITY].iter().copied() {
        assert_eq!(libm::sqrtf(f), f);
    }
}
fn drop_host_twice() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))

                (core func $dtor (canon resource.drop $t))
                (func (export "dtor") (param "x" (own $t))
                    (canon lift (core func $dtor)))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
    let i = linker.instantiate(&mut store, &c)?;
    let dtor = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "dtor")?;

    let t = Resource::new_own(100);
    dtor.call(&mut store, (&t,))?;
    dtor.post_return(&mut store)?;

    assert_eq!(
        dtor.call(&mut store, (&t,)).unwrap_err().to_string(),
        "host resource already consumed"
    );

    Ok(())
}
fn output() {
  let tempdir = tempdir();

  let output = Command::new(executable_path("just"))
    .arg("--completions")
    .arg("bash")
    .current_dir(tempdir.path())
    .output()
    .unwrap();

  assert!(output.status.success());

  let text = String::from_utf8_lossy(&output.stdout);

  assert!(text.starts_with("_just() {"));
}
fn unit_struct_cache_key() {
    #[derive(CacheKey, Hash)]
    struct UnitStruct;

    let mut key = CacheKeyHasher::new();

    UnitStruct.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    UnitStruct.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn parse_bignumeric_keyword() {
    let sql = r#"SELECT BIGNUMERIC '0'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"0"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '0'");

    let sql = r#"SELECT BIGNUMERIC '123456'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"123456"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '123456'");

    let sql = r#"SELECT BIGNUMERIC '-3.14'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"-3.14"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '-3.14'");

    let sql = r#"SELECT BIGNUMERIC '-0.54321'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"-0.54321"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '-0.54321'");

    let sql = r#"SELECT BIGNUMERIC '1.23456e05'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"1.23456e05"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '1.23456e05'");

    let sql = r#"SELECT BIGNUMERIC '-9.876e-3'"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::BigNumeric(ExactNumberInfo::None),
            value: r#"-9.876e-3"#.into()
        },
        expr_from_projection(only(&select.projection)),
    );
    verified_stmt("SELECT BIGNUMERIC '-9.876e-3'");
}
fn table_growth_failure2() -> Result<()> {
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "-Wtrap-on-grow-failure",
            "tests/all/cli_tests/table-grow-failure2.wat",
        ])
        .output()?;
    assert!(!output.status.success());
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("forcing a table growth failure to be a trap"),
        "bad stderr: {stderr}"
    );
    Ok(())
}
async fn test_axfr_refused() {
    let mut test = create_test();
    test.set_allow_axfr(false);

    let origin = test.origin().clone();

    let mut catalog: Catalog = Catalog::new();
    catalog.upsert(origin.clone(), Box::new(Arc::new(test)));

    let mut query: Query = Query::new();
    query.set_name(origin.into());
    query.set_query_type(RecordType::AXFR);

    let mut question: Message = Message::new();
    question.add_query(query);

    // temp request
    let question_bytes = question.to_bytes().unwrap();
    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();
    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);

    let response_handler = TestResponseHandler::new();
    catalog
        .lookup(&question_req, None, response_handler.clone())
        .await;
    let result = response_handler.into_message().await;

    assert_eq!(result.response_code(), ResponseCode::Refused);
    assert!(result.answers().is_empty());
    assert!(result.name_servers().is_empty());
    assert!(result.additionals().is_empty());
}
fn var_access_by_square_brackets_errors() {
    let mut context = Context::new();
    context.insert("var", &Test { a: "hi".into(), b: "there".into(), c: vec![] });
    let t = Tera::one_off("{{var[csd]}}", &context, true);
    assert!(t.is_err(), "Access of csd should be impossible");
}
fn ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), FORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED);

    if console.out_buffer.len() != 1 {
        panic!("unexpected console content: {:#?}", console.out_buffer);
    }

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_ok",
        fs,
        console,
        result,
    ));
}
fn normal_cases() {
    assert_eq!(libm::powd(2.0, 20.0), (1 << 20) as f64);
    assert_eq!(libm::powd(-1.0, 9.0), -1.0);
    assert!(libm::powd(-1.0, 2.2).is_nan());
    assert!(libm::powd(-1.0, -1.14).is_nan());
}
fn read_icc_profile_seq_no_0() {
    let path = Path::new("tests")
        .join("icc")
        .join("icc_chunk_seq_no_0.jpeg");

    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    decoder.decode().unwrap();

    let profile = decoder.icc_profile();
    assert!(profile.is_none());
}
fn test_read_config() {
    let server_path = env::var("TDNS_WORKSPACE_ROOT").unwrap_or_else(|_| "../..".to_owned());
    let path: PathBuf =
        PathBuf::from(server_path).join("tests/test-data/test_configs/example.toml");

    if !path.exists() {
        panic!("can't locate example.toml and other configs: {:?}", path)
    }

    println!("reading config");
    let config: Config = Config::read_config(&path).unwrap();

    assert_eq!(config.get_listen_port(), 53);
    assert_eq!(config.get_listen_addrs_ipv4(), Ok(Vec::<Ipv4Addr>::new()));
    assert_eq!(config.get_listen_addrs_ipv6(), Ok(Vec::<Ipv6Addr>::new()));
    assert_eq!(config.get_tcp_request_timeout(), Duration::from_secs(5));
    assert_eq!(config.get_log_level(), tracing::Level::INFO);
    assert_eq!(config.get_directory(), Path::new("/var/named"));
    assert_eq!(
        config.get_zones(),
        [
            ZoneConfig::new(
                "localhost".into(),
                ZoneType::Primary,
                "default/localhost.zone".into(),
                None,
                None,
                None,
                vec![],
            ),
            ZoneConfig::new(
                "0.0.127.in-addr.arpa".into(),
                ZoneType::Primary,
                "default/127.0.0.1.zone".into(),
                None,
                None,
                None,
                vec![],
            ),
            ZoneConfig::new(
                "0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.\
                 ip6.arpa"
                    .into(),
                ZoneType::Primary,
                "default/ipv6_1.zone".into(),
                None,
                None,
                None,
                vec![],
            ),
            ZoneConfig::new(
                "255.in-addr.arpa".into(),
                ZoneType::Primary,
                "default/255.zone".into(),
                None,
                None,
                None,
                vec![],
            ),
            ZoneConfig::new(
                "0.in-addr.arpa".into(),
                ZoneType::Primary,
                "default/0.zone".into(),
                None,
                None,
                None,
                vec![],
            ),
            ZoneConfig::new(
                "example.com".into(),
                ZoneType::Primary,
                "example.com.zone".into(),
                None,
                None,
                None,
                vec![],
            )
        ]
    );
}
fn server_exposes_offered_sni_even_if_resolver_fails() {
    let kt = KeyType::Rsa;
    let resolver = rustls::server::ResolvesServerCertUsingSni::new();

    let mut server_config = make_server_config(kt);
    server_config.cert_resolver = Arc::new(resolver);
    let server_config = Arc::new(server_config);

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(kt, &[version]);
        let mut server = ServerConnection::new(Arc::clone(&server_config)).unwrap();
        let mut client =
            ClientConnection::new(Arc::new(client_config), dns_name("thisdoesNOTexist.com"))
                .unwrap();

        assert_eq!(None, server.server_name());
        transfer(&mut client, &mut server);
        assert_eq!(
            server.process_new_packets(),
            Err(Error::General(
                "no server certificate chain resolved".to_string()
            ))
        );
        assert_eq!(Some("thisdoesnotexist.com"), server.server_name());
    }
}
fn does_include_file_with_different_rules() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "overrides": [{ "include": ["special/**"], "linter": { "rules": {
    "suspicious": { "noDebugger": "off" }
  } } }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), DEBUGGER_BEFORE.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), DEBUGGER_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, DEBUGGER_BEFORE);
    assert_file_contents(&fs, test, DEBUGGER_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_rules",
        fs,
        console,
        result,
    ));
}
fn encoded_len_unpadded() {
    assert_eq!(0, encoded_len(0, false).unwrap());
    assert_eq!(2, encoded_len(1, false).unwrap());
    assert_eq!(3, encoded_len(2, false).unwrap());
    assert_eq!(4, encoded_len(3, false).unwrap());
    assert_eq!(6, encoded_len(4, false).unwrap());
    assert_eq!(7, encoded_len(5, false).unwrap());
    assert_eq!(8, encoded_len(6, false).unwrap());
    assert_eq!(10, encoded_len(7, false).unwrap());
}
fn test_async_host_func_pending() {
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    atoms::add_to_linker(&mut linker, |cx| cx).unwrap();
    let mut store = store(&engine);

    let shim_mod = shim_module(&engine);
    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();

    let result_location: i32 = 0;

    // This input triggers the host func pending forever
    let input: i32 = TRIGGER_PENDING as i32;
    let trap = shim_inst
        .get_func(&mut store, "double_int_return_float_shim")
        .unwrap()
        .call(
            &mut store,
            &[input.into(), result_location.into()],
            &mut [Val::I32(0)],
        )
        .unwrap_err();
    assert!(
        format!("{:?}", trap).contains("Cannot wait on pending future"),
        "expected get a pending future Trap from dummy executor, got: {}",
        trap
    );
}
fn handle_ws_for_if_nodes_with_else() {
    let end_ws = WS { left: true, right: true };
    let ast = vec![
        Node::Text("C ".to_string()),
        Node::If(
            If {
                conditions: vec![
                    (
                        WS { left: true, right: true },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                    (
                        WS { left: true, right: false },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                    (
                        WS { left: true, right: true },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                ],
                otherwise: Some((
                    WS { left: true, right: true },
                    vec![Node::Text(" a ".to_string())],
                )),
            },
            end_ws,
        ),
        Node::Text("  hey".to_string()),
    ];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![
            Node::Text("C".to_string()),
            Node::If(
                If {
                    conditions: vec![
                        (
                            WS { left: true, right: true },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text("a".to_string())],
                        ),
                        (
                            WS { left: true, right: false },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text(" a".to_string())],
                        ),
                        (
                            WS { left: true, right: true },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text("a".to_string())],
                        ),
                    ],
                    otherwise: Some((
                        WS { left: true, right: true },
                        vec![Node::Text("a".to_string())],
                    )),
                },
                end_ws,
            ),
            Node::Text("hey".to_string()),
        ]
    );
}
fn test_filter_with_non() {
    fn filter(value: Option<String>) -> String {
        format!("[{}]", value.unwrap_or_default())
    }

    let mut env = Environment::new();
    env.add_filter("filter", filter);
    let state = env.empty_state();

    let rv = state
        .apply_filter("filter", args!(Value::UNDEFINED))
        .unwrap();
    assert_eq!(rv, Value::from("[]"));

    let rv = state
        .apply_filter("filter", args!(Value::from(())))
        .unwrap();
    assert_eq!(rv, Value::from("[]"));

    let rv = state
        .apply_filter("filter", args!(Value::from("wat")))
        .unwrap();
    assert_eq!(rv, Value::from("[wat]"));
}
fn parse_named_argument_function() {
    let sql = "SELECT FUN(a => '1', b => '2') FROM foo";
    let select = verified_only_select(sql);

    assert_eq!(
        &Expr::Function(Function {
            name: ObjectName(vec![Ident::new("FUN")]),
            args: vec![
                FunctionArg::Named {
                    name: Ident::new("a"),
                    arg: FunctionArgExpr::Expr(Expr::Value(Value::SingleQuotedString(
                        "1".to_owned()
                    ))),
                },
                FunctionArg::Named {
                    name: Ident::new("b"),
                    arg: FunctionArgExpr::Expr(Expr::Value(Value::SingleQuotedString(
                        "2".to_owned()
                    ))),
                },
            ],
            null_treatment: None,
            filter: None,
            over: None,
            distinct: false,
            special: false,
            order_by: vec![],
        }),
        expr_from_projection(only(&select.projection))
    );
}
fn owning() -> Result<()> {
    wasmtime::component::bindgen!({
        inline: "
        package inline:inline;
        world test {
            export lists: interface {
                foo: func(a: list<list<string>>) -> list<list<string>>;
            }

            export thing-in: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                bar: func(a: thing);
            }

            export thing-in-and-out: interface {
                record thing {
                    name: string,
                    value: list<string>
                }

                baz: func(a: thing) -> thing;
            }
        }",
        ownership: Owning
    });

    impl PartialEq for exports::thing_in::Thing {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    impl PartialEq for exports::thing_in_and_out::Thing {
        fn eq(&self, other: &Self) -> bool {
            self.name == other.name && self.value == other.value
        }
    }

    let engine = engine();
    let component = Component::new(&engine, component())?;

    let linker = Linker::new(&engine);
    let mut store = Store::new(&engine, ());
    let (test, _) = Test::instantiate(&mut store, &component, &linker)?;

    let value = vec![vec!["a".to_owned(), "b".to_owned()]];
    assert_eq!(value, test.lists().call_foo(&mut store, &value)?);

    let value = exports::thing_in::Thing {
        name: "thing 1".to_owned(),
        value: vec!["some value".to_owned(), "another value".to_owned()],
    };
    test.thing_in().call_bar(&mut store, &value)?;

    let value = exports::thing_in_and_out::Thing {
        name: "thing 1".to_owned(),
        value: vec!["some value".to_owned(), "another value".to_owned()],
    };
    assert_eq!(value, test.thing_in_and_out().call_baz(&mut store, &value)?);

    Ok(())
}
fn render_variable_block_lit_expr() {
    let inputs = vec![
        ("{{ 1 }}", "1"),
        ("{{ 3.18 }}", "3.18"),
        ("{{ \"hey\" }}", "hey"),
        (r#"{{ "{{ hey }}" }}"#, "{{ hey }}"),
        ("{{ true }}", "true"),
        ("{{ false }}", "false"),
        ("{{ false and true or true }}", "true"),
        ("{{ 1 + 1 }}", "2"),
        ("{{ 1 + 1.1 }}", "2.1"),
        ("{{ 3 - 1 }}", "2"),
        ("{{ 3 - 1.1 }}", "1.9"),
        ("{{ 2 * 5 }}", "10"),
        ("{{ 10 / 5 }}", "2"),
        ("{{ 2.1 * 5 }}", "10.5"),
        ("{{ 2.1 * 5.05 }}", "10.605"),
        ("{{ 2 / 0.5 }}", "4"),
        ("{{ 2.1 / 0.5 }}", "4.2"),
        ("{{ 2 + 1 * 2 }}", "4"),
        ("{{ (2 + 1) * 2 }}", "6"),
        ("{{ 2 * 4 % 8 }}", "0"),
        ("{{ 2.8 * 2 | round }}", "6"),
        ("{{ 1 / 0 }}", "NaN"),
        ("{{ true and 10 }}", "true"),
        ("{{ true and not 10 }}", "false"),
        ("{{ not true }}", "false"),
        ("{{ [1, 2, 3] }}", "[1, 2, 3]"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &Context::new()).unwrap(), expected);
    }
}
fn test_existing_file_truncated() {
    // Set up test if needed (eg. after failure)
    let fname = "this-file-exists-truncated.txt";
    let fpath = fixture_path!(fname);
    match fpath.metadata() {
        Ok(m) if m.len() == 256 => {}
        _ => build_test_file!(&fpath, &vec![0; 256]),
    }

    let (fix, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["status=none", "if=null.txt", of!(fname)])
        .run()
        .no_stdout()
        .no_stderr()
        .success();

    assert_eq!(0, fix.metadata(fname).len());
}
fn test_kill_with_signal_name_old_form() {
    let mut target = Target::new();
    new_ucmd!()
        .arg("-KILL")
        .arg(format!("{}", target.pid()))
        .succeeds();
    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));
}
fn test_halfway_round_up() {
    // Halfway, round-up tests
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740994, false), (1076, 1));
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740995, false), (1076, 2));
    assert_eq!(compute_float64::<BINARY>(0, 9007199254740996, false), (1076, 2));

    assert_eq!(compute_float64::<BINARY>(0, 18014398509481988, false), (1077, 1));
    assert_eq!(compute_float64::<BINARY>(0, 18014398509481990, false), (1077, 2));
    assert_eq!(compute_float64::<BINARY>(0, 18014398509481992, false), (1077, 2));

    assert_eq!(compute_float64::<BINARY>(0, 9223372036854777856, false), (1086, 1));
    assert_eq!(compute_float64::<BINARY>(0, 9223372036854778880, false), (1086, 2));
    assert_eq!(compute_float64::<BINARY>(0, 9223372036854779904, false), (1086, 2));

    // Add a 0 but say we're truncated.
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854777856, true), (1076, 1));
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854778879, true), (1076, 1));
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854778880, true), (1076, 2));
    assert_eq!(compute_float64::<BINARY>(-10, 9223372036854779904, true), (1076, 2));

    // Check other bases.
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855904, false), (1076, 1));
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855920, false), (1076, 2));
    assert_eq!(compute_float64::<BASE4>(-2, 144115188075855936, false), (1076, 2));

    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423616, false), (1076, 1));
    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423680, false), (1076, 2));
    assert_eq!(compute_float64::<OCTAL>(-2, 576460752303423744, false), (1076, 2));

    assert_eq!(compute_float64::<HEX>(-1, 144115188075855904, false), (1076, 1));
    assert_eq!(compute_float64::<HEX>(-1, 144115188075855920, false), (1076, 2));
    assert_eq!(compute_float64::<HEX>(-1, 144115188075855936, false), (1076, 2));

    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711808, false), (1076, 1));
    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711840, false), (1076, 2));
    assert_eq!(compute_float64::<BASE32>(-1, 288230376151711872, false), (1076, 2));
}
fn old_cli_warn_if_ambiguous_flags() -> Result<()> {
    // This is accepted in the old CLI parser and the new but it's interpreted
    // differently so a warning should be printed.
    let output = get_wasmtime_command()?
        .args(&["tests/all/cli_tests/simple.wat", "--invoke", "get_f32"])
        .output()?;
    assert_eq!(String::from_utf8_lossy(&output.stdout), "100\n");
    assert_eq!(
        String::from_utf8_lossy(&output.stderr),
        "\
warning: this CLI invocation of Wasmtime will be parsed differently in future
         Wasmtime versions -- see this online issue for more information:
         https://github.com/bytecodealliance/wasmtime/issues/7384

         Wasmtime will now execute with the old (<= Wasmtime 13) CLI parsing,
         however this behavior can also be temporarily configured with an
         environment variable:

         - WASMTIME_NEW_CLI=0 to indicate old semantics are desired and silence this warning, or
         - WASMTIME_NEW_CLI=1 to indicate new semantics are desired and use the latest behavior
warning: using `--invoke` with a function that returns values is experimental and may break in the future
"
    );

    // Test disabling the warning
    let output = get_wasmtime_command()?
        .args(&["tests/all/cli_tests/simple.wat", "--invoke", "get_f32"])
        .env("WASMTIME_NEW_CLI", "0")
        .output()?;
    assert_eq!(String::from_utf8_lossy(&output.stdout), "100\n");
    assert_eq!(
        String::from_utf8_lossy(&output.stderr),
        "\
warning: using `--invoke` with a function that returns values is experimental and may break in the future
"
    );

    // Test forcing the new behavior where nothing happens because the file is
    // invoked with `--invoke` as its own argument.
    let output = get_wasmtime_command()?
        .args(&["tests/all/cli_tests/simple.wat", "--invoke", "get_f32"])
        .env("WASMTIME_NEW_CLI", "1")
        .output()?;
    assert_eq!(String::from_utf8_lossy(&output.stdout), "");
    assert_eq!(String::from_utf8_lossy(&output.stderr), "");

    // This is unambiguous
    let output = get_wasmtime_command()?
        .args(&["--invoke", "get_f32", "tests/all/cli_tests/simple.wat"])
        .output()?;
    assert_eq!(String::from_utf8_lossy(&output.stdout), "100\n");
    assert_eq!(
        String::from_utf8_lossy(&output.stderr),
        "\
warning: using `--invoke` with a function that returns values is experimental and may break in the future
"
    );

    // This fails to parse in the old but succeeds in the new, so it should run
    // under the new semantics with no warning.
    let output = get_wasmtime_command()?
        .args(&["run", "tests/all/cli_tests/print-arguments.wat", "--arg"])
        .output()?;
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "print-arguments.wat\n--arg\n"
    );
    assert_eq!(String::from_utf8_lossy(&output.stderr), "");

    // Old behavior can be forced however
    let output = get_wasmtime_command()?
        .args(&["run", "tests/all/cli_tests/print-arguments.wat", "--arg"])
        .env("WASMTIME_NEW_CLI", "0")
        .output()?;
    assert!(!output.status.success());

    // This works in both the old and the new, so no warnings
    let output = get_wasmtime_command()?
        .args(&["run", "tests/all/cli_tests/print-arguments.wat", "arg"])
        .output()?;
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "print-arguments.wat\narg\n"
    );
    assert_eq!(String::from_utf8_lossy(&output.stderr), "");

    // This works in both the old and the new, so no warnings
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "--",
            "tests/all/cli_tests/print-arguments.wat",
            "--arg",
        ])
        .output()?;
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "print-arguments.wat\n--arg\n"
    );
    assert_eq!(String::from_utf8_lossy(&output.stderr), "");

    // Old flags still work, but with a warning
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "--max-wasm-stack",
            "1000000",
            "tests/all/cli_tests/print-arguments.wat",
        ])
        .output()?;
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "print-arguments.wat\n"
    );
    assert_eq!(
        String::from_utf8_lossy(&output.stderr),
        "\
warning: this CLI invocation of Wasmtime is going to break in the future -- for
         more information see this issue online:
         https://github.com/bytecodealliance/wasmtime/issues/7384

         Wasmtime will now execute with the old (<= Wasmtime 13) CLI parsing,
         however this behavior can also be temporarily configured with an
         environment variable:

         - WASMTIME_NEW_CLI=0 to indicate old semantics are desired and silence this warning, or
         - WASMTIME_NEW_CLI=1 to indicate new semantics are desired and see the error
"
    );

    // Old flags warning is suppressible.
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "--max-wasm-stack",
            "1000000",
            "tests/all/cli_tests/print-arguments.wat",
        ])
        .env("WASMTIME_NEW_CLI", "0")
        .output()?;
    assert_eq!(
        String::from_utf8_lossy(&output.stdout),
        "print-arguments.wat\n"
    );
    assert_eq!(String::from_utf8_lossy(&output.stderr), "");

    Ok(())
}
fn closed_immediately() {
    let stream = "/**/".parse::<TokenStream>().unwrap();
    let tokens = stream.into_iter().collect::<Vec<_>>();
    assert!(tokens.is_empty(), "not empty -- {:?}", tokens);
}
fn test_split_str_prefixed_chunks_by_lines() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_str_prefixed_chunks_by_lines";
    RandomFile::new(&at, name).add_lines(10000);
    ucmd.args(&["-l", "1000", name, "d"]).succeeds();

    let glob = Glob::new(&at, ".", r"d[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 10);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn is_redirection() {
    assert!(status_code(300).is_redirection());
    assert!(status_code(399).is_redirection());

    assert!(!status_code(299).is_redirection());
    assert!(!status_code(400).is_redirection());
}
fn test_serialize_rejects_adt_keys() {
    let map = treemap!(
        Some("a") => 2,
        Some("b") => 4,
        None => 6,
    );

    let err = to_vec(&map).unwrap_err();
    assert_eq!(err.to_string(), "key must be a string");
}
fn same_module_multiple_stores() -> Result<()> {
    let _ = env_logger::try_init();

    let engine = Engine::default();

    let module = Module::new(
        &engine,
        r#"
            (module
                (import "" "f" (func $f))
                (import "" "call_ref" (func $call_ref (param funcref)))
                (global $g (mut i32) (i32.const 0))
                (func $a (export "a")
                    call $b
                )
                (func $b
                    call $c
                )
                (func $c
                    global.get $g
                    if
                        call $f
                    else
                        i32.const 1
                        global.set $g
                        ref.func $a
                        call $call_ref
                    end
                )
            )
        "#,
    )?;

    let stacks = Arc::new(Mutex::new(vec![]));

    let mut store3 = Store::new(&engine, ());
    let f3 = Func::new(&mut store3, FuncType::new([], []), {
        let stacks = stacks.clone();
        move |caller, _params, _results| {
            stacks
                .lock()
                .unwrap()
                .push(WasmBacktrace::force_capture(caller));
            Ok(())
        }
    });
    let call_ref3 = Func::wrap(&mut store3, |caller: Caller<'_, _>, f: Option<Func>| {
        f.unwrap().call(caller, &[], &mut [])
    });
    let instance3 = Instance::new(&mut store3, &module, &[f3.into(), call_ref3.into()])?;

    let mut store2 = Store::new(&engine, store3);
    let f2 = Func::new(&mut store2, FuncType::new([], []), {
        let stacks = stacks.clone();
        move |mut caller, _params, _results| {
            stacks
                .lock()
                .unwrap()
                .push(WasmBacktrace::force_capture(&mut caller));
            instance3
                .get_typed_func::<(), ()>(caller.data_mut(), "a")
                .unwrap()
                .call(caller.data_mut(), ())
                .unwrap();
            Ok(())
        }
    });
    let call_ref2 = Func::wrap(&mut store2, |caller: Caller<'_, _>, f: Option<Func>| {
        f.unwrap().call(caller, &[], &mut [])
    });
    let instance2 = Instance::new(&mut store2, &module, &[f2.into(), call_ref2.into()])?;

    let mut store1 = Store::new(&engine, store2);
    let f1 = Func::new(&mut store1, FuncType::new([], []), {
        let stacks = stacks.clone();
        move |mut caller, _params, _results| {
            stacks
                .lock()
                .unwrap()
                .push(WasmBacktrace::force_capture(&mut caller));
            instance2
                .get_typed_func::<(), ()>(caller.data_mut(), "a")
                .unwrap()
                .call(caller.data_mut(), ())
                .unwrap();
            Ok(())
        }
    });
    let call_ref1 = Func::wrap(&mut store1, |caller: Caller<'_, _>, f: Option<Func>| {
        f.unwrap().call(caller, &[], &mut [])
    });
    let instance1 = Instance::new(&mut store1, &module, &[f1.into(), call_ref1.into()])?;

    instance1
        .get_typed_func(&mut store1, "a")?
        .call(&mut store1, ())?;

    let expected_stacks = vec![
        // [f1, c1, b1, a1, call_ref1, c1, b1, a1]
        vec!["c", "b", "a", "c", "b", "a"],
        // [f2, c2, b2, a2, call_ref2, c2, b2, a2, f1, c1, b1, a1, call_ref1, c1, b1, a1]
        vec!["c", "b", "a", "c", "b", "a"],
        // [f3, c3, b3, a3, call_ref3, c3, b3, a3, f2, c2, b2, a2, call_ref2, c2, b2, a2, f1, c1, b1, a1, call_ref1, c1, b1, a1]
        vec!["c", "b", "a", "c", "b", "a"],
    ];
    eprintln!("expected = {expected_stacks:#?}");
    let actual_stacks = stacks.lock().unwrap();
    eprintln!("actaul = {actual_stacks:#?}");

    assert_eq!(actual_stacks.len(), expected_stacks.len());
    for (expected_stack, actual_stack) in expected_stacks.into_iter().zip(actual_stacks.iter()) {
        assert_eq!(expected_stack.len(), actual_stack.frames().len());
        for (expected_frame, actual_frame) in expected_stack.into_iter().zip(actual_stack.frames())
        {
            assert_eq!(actual_frame.func_name(), Some(expected_frame));
        }
    }

    Ok(())
}
fn take_till0_issue() {
    use winnow::token::take_till0;

    fn nothing(i: Partial<&[u8]>) -> IResult<Partial<&[u8]>, &[u8]> {
        take_till0(|_| true).parse_peek(i)
    }

    assert_eq!(
        nothing(Partial::new(b"")),
        Err(ErrMode::Incomplete(Needed::new(1)))
    );
    assert_eq!(
        nothing(Partial::new(b"abc")),
        Ok((Partial::new(&b"abc"[..]), &b""[..]))
    );
}
fn macro_can_access_global_context() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("parent", r#"{% import "macros" as macros %}{{ macros::test_global() }}"#),
        ("macros", r#"{% macro test_global() %}{% set_global value1 = "42" %}{% for i in range(end=1) %}{% set_global value2 = " is the truth." %}{% endfor %}{{ value1 }}{% endmacro test_global %}"#)
    ]).unwrap();

    let result = tera.render("parent", &Context::new());
    assert_eq!(result.unwrap(), "42".to_string());
}
fn test_fn_precedence_in_where_clause() {
    // This should parse as two separate bounds, `FnOnce() -> i32` and `Send` - not
    // `FnOnce() -> (i32 + Send)`.
    let input = quote! {
        fn f<G>()
        where
            G: FnOnce() -> i32 + Send,
        {
        }
    };

    snapshot!(input as ItemFn, @r###"
    ItemFn {
        vis: Visibility::Inherited,
        sig: Signature {
            ident: "f",
            generics: Generics {
                lt_token: Some,
                params: [
                    GenericParam::Type(TypeParam {
                        ident: "G",
                    }),
                ],
                gt_token: Some,
                where_clause: Some(WhereClause {
                    predicates: [
                        WherePredicate::Type(PredicateType {
                            bounded_ty: Type::Path {
                                path: Path {
                                    segments: [
                                        PathSegment {
                                            ident: "G",
                                        },
                                    ],
                                },
                            },
                            bounds: [
                                TypeParamBound::Trait(TraitBound {
                                    path: Path {
                                        segments: [
                                            PathSegment {
                                                ident: "FnOnce",
                                                arguments: PathArguments::Parenthesized {
                                                    output: ReturnType::Type(
                                                        Type::Path {
                                                            path: Path {
                                                                segments: [
                                                                    PathSegment {
                                                                        ident: "i32",
                                                                    },
                                                                ],
                                                            },
                                                        },
                                                    ),
                                                },
                                            },
                                        ],
                                    },
                                }),
                                TypeParamBound::Trait(TraitBound {
                                    path: Path {
                                        segments: [
                                            PathSegment {
                                                ident: "Send",
                                            },
                                        ],
                                    },
                                }),
                            ],
                        }),
                    ],
                }),
            },
            output: ReturnType::Default,
        },
        block: Block,
    }
    "###);

    let where_clause = input.sig.generics.where_clause.as_ref().unwrap();
    assert_eq!(where_clause.predicates.len(), 1);

    let predicate = match &where_clause.predicates[0] {
        WherePredicate::Type(pred) => pred,
        _ => panic!("wrong predicate kind"),
    };

    assert_eq!(predicate.bounds.len(), 2, "{:#?}", predicate.bounds);

    let first_bound = &predicate.bounds[0];
    assert_eq!(quote!(#first_bound).to_string(), "FnOnce () -> i32");

    let second_bound = &predicate.bounds[1];
    assert_eq!(quote!(#second_bound).to_string(), "Send");
}
fn check_extend_unsafe_fixes_conflict_with_extend_safe_fixes_by_specificity() -> Result<()> {
    // Adding a rule to one option with a more specific selector should override the other option
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
target-version = "py310"
[lint]
extend-unsafe-fixes = ["UP", "UP034"]
extend-safe-fixes = ["UP03"]
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["check", "--config"])
        .arg(&ruff_toml)
        .arg("-")
        .args([
            "--output-format",
            "text",
            "--no-cache",
            "--select",
            "F601,UP018,UP034,UP038",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\nprint(str('foo'))\nisinstance(x, (int, str))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    -:2:7: UP034 Avoid extraneous parentheses
    -:3:7: UP018 Unnecessary `str` call (rewrite as a literal)
    -:4:1: UP038 [*] Use `X | Y` in `isinstance` call instead of `(X, Y)`
    Found 4 errors.
    [*] 1 fixable with the `--fix` option (3 hidden fixes can be enabled with the `--unsafe-fixes` option).

    ----- stderr -----
    "###);

    Ok(())
}
fn parse_create_procedure() {
    let sql = "CREATE OR ALTER PROCEDURE test (@foo INT, @bar VARCHAR(256)) AS BEGIN SELECT 1 END";

    assert_eq!(
        ms().verified_stmt(sql),
        Statement::CreateProcedure {
            or_alter: true,
            body: vec![Statement::Query(Box::new(Query {
                with: None,
                limit: None,
                limit_by: vec![],
                offset: None,
                fetch: None,
                locks: vec![],
                order_by: vec![],
                body: Box::new(SetExpr::Select(Box::new(Select {
                    distinct: None,
                    top: None,
                    projection: vec![SelectItem::UnnamedExpr(Expr::Value(number("1")))],
                    into: None,
                    from: vec![],
                    lateral_views: vec![],
                    selection: None,
                    group_by: GroupByExpr::Expressions(vec![]),
                    cluster_by: vec![],
                    distribute_by: vec![],
                    sort_by: vec![],
                    having: None,
                    named_window: vec![],
                    qualify: None
                })))
            }))],
            params: Some(vec![
                ProcedureParam {
                    name: Ident {
                        value: "@foo".into(),
                        quote_style: None
                    },
                    data_type: DataType::Int(None)
                },
                ProcedureParam {
                    name: Ident {
                        value: "@bar".into(),
                        quote_style: None
                    },
                    data_type: DataType::Varchar(Some(CharacterLength {
                        length: 256,
                        unit: None
                    }))
                }
            ]),
            name: ObjectName(vec![Ident {
                value: "test".into(),
                quote_style: None
            }])
        }
    )
}
fn attributes_empty_ns_expanded() {
    let src = "<a att1='a' r:att2='b' xmlns:r='urn:example:r' />";

    let mut r = NsReader::from_str(src);
    r.trim_text(true).expand_empty_elements(true);
    {
        let e = match r.read_resolved_event() {
            Ok((Unbound, Start(e))) => e,
            e => panic!("Expecting Empty event, got {:?}", e),
        };

        let mut attrs = e
            .attributes()
            .map(|ar| ar.expect("Expecting attribute parsing to succeed."))
            // we don't care about xmlns attributes for this test
            .filter(|kv| kv.key.as_namespace_binding().is_none())
            .map(|Attribute { key: name, value }| {
                let (opt_ns, local_name) = r.resolve_attribute(name);
                (opt_ns, local_name.into_inner(), value)
            });
        assert_eq!(
            attrs.next(),
            Some((Unbound, &b"att1"[..], Cow::Borrowed(&b"a"[..])))
        );
        assert_eq!(
            attrs.next(),
            Some((
                Bound(Namespace(b"urn:example:r")),
                &b"att2"[..],
                Cow::Borrowed(&b"b"[..])
            ))
        );
        assert_eq!(attrs.next(), None);
    }

    match r.read_resolved_event() {
        Ok((Unbound, End(e))) => assert_eq!(e.name(), QName(b"a")),
        e => panic!("Expecting End event, got {:?}", e),
    }
}
fn test_output_multiple_occurrences() {
    let output = new_ucmd!()
        .args(&["--output=source", "--output=target"])
        .succeeds()
        .stdout_move_str();
    assert_eq!(
        output
            .lines()
            .next()
            .unwrap()
            .split_whitespace()
            .collect::<Vec<_>>(),
        vec!["Filesystem", "Mounted", "on"]
    );
}
fn test_datagram_fails_to_stream() {
    // Lookup to UDP should fail, and then the query should be retried on TCP because
    // `try_tcp_on_error` is set to true.

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));
    let udp_message: Result<DnsResponse, _> = Err(ResolveError::from("Forced Testing Error"));

    let tcp_message = message(query.clone(), vec![tcp_record.clone()], vec![], vec![]);

    let udp_nameserver = mock_nameserver(vec![udp_message], Default::default());
    let tcp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],
        Default::default(),
    );

    let mut options = ResolverOpts::default();
    options.try_tcp_on_error = true;
    let pool = mock_nameserver_pool(vec![udp_nameserver], vec![tcp_nameserver], None, options);

    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();
    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], tcp_record);
}
fn new_client_returns_initial_io_state() {
    let (mut client, _) = make_pair(KeyType::Rsa);
    let io_state = client.process_new_packets().unwrap();
    println!("IoState is Debug {:?}", io_state);
    assert_eq!(io_state.plaintext_bytes_to_read(), 0);
    assert!(!io_state.peer_has_closed());
    assert!(io_state.tls_bytes_to_write() > 200);
}
fn test_unsafe_recovery_wait_for_snapshot_apply() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(8);
    cluster.cfg.raft_store.merge_max_log_gap = 3;
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(10);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);
    cluster.stop_node(nodes[1]);
    let (raft_gc_triggered_tx, raft_gc_triggered_rx) = mpsc::bounded::<()>(1);
    let (raft_gc_finished_tx, raft_gc_finished_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("worker_gc_raft_log", move || {
        let _ = raft_gc_triggered_rx.recv();
    })
    .unwrap();
    fail::cfg_callback("worker_gc_raft_log_finished", move || {
        let _ = raft_gc_finished_tx.send(());
    })
    .unwrap();
    (0..10).for_each(|_| cluster.must_put(b"random_k", b"random_v"));
    // Unblock raft log GC.
    drop(raft_gc_triggered_tx);
    // Wait until logs are GCed.
    raft_gc_finished_rx
        .recv_timeout(Duration::from_secs(3))
        .unwrap();
    // Makes the group lose its quorum.
    cluster.stop_node(nodes[2]);

    // Blocks the raft snap apply process.
    let (apply_triggered_tx, apply_triggered_rx) = mpsc::bounded::<()>(1);
    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("region_apply_snap", move || {
        let _ = apply_triggered_tx.send(());
        let _ = apply_released_rx.recv();
    })
    .unwrap();

    cluster.run_node(nodes[1]).unwrap();

    apply_triggered_rx
        .recv_timeout(Duration::from_secs(1))
        .unwrap();

    // Triggers the unsafe recovery store reporting process.
    let plan = pdpb::RecoveryPlan::default();
    pd_client.must_set_unsafe_recovery_plan(nodes[1], plan);
    cluster.must_send_store_heartbeat(nodes[1]);

    // No store report is sent, since there are peers have unapplied entries.
    for _ in 0..20 {
        assert_eq!(pd_client.must_get_store_report(nodes[1]), None);
        sleep_ms(100);
    }

    // Unblocks the snap apply process.
    drop(apply_released_tx);

    // Store reports are sent once the entries are applied.
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[1]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);

    fail::remove("worker_gc_raft_log");
    fail::remove("worker_gc_raft_log_finished");
    fail::remove("region_apply_snap");
}
fn test_install_preserve_timestamps() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "source_file";
    let file2 = "target_file";
    at.touch(file1);

    ucmd.arg(file1).arg(file2).arg("-p").succeeds().no_stderr();

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));

    let file1_metadata = at.metadata(file1);
    let file2_metadata = at.metadata(file2);

    assert_eq!(
        file1_metadata.accessed().ok(),
        file2_metadata.accessed().ok()
    );
    assert_eq!(
        file1_metadata.modified().ok(),
        file2_metadata.modified().ok()
    );
}
fn test_region_collection_seek_region() {
    let mut cluster = new_node_cluster(0, 3);

    let (tx, rx) = channel();
    cluster
        .sim
        .wl()
        .post_create_coprocessor_host(Box::new(move |id, host| {
            let p = RegionInfoAccessor::new(host);
            tx.send((id, p)).unwrap()
        }));

    cluster.run();
    let region_info_providers: HashMap<_, _> = rx.try_iter().collect();
    assert_eq!(region_info_providers.len(), 3);
    let regions = prepare_cluster(&mut cluster);

    for node_id in cluster.get_node_ids() {
        let engine = &region_info_providers[&node_id];

        // Test traverse all regions
        let key = b"".to_vec();
        let (tx, rx) = channel();
        let tx_ = tx.clone();
        engine
            .seek_region(
                &key,
                Box::new(move |infos| {
                    tx_.send(infos.map(|i| i.region.clone()).collect()).unwrap();
                }),
            )
            .unwrap();
        let sought_regions: Vec<_> = rx.recv_timeout(Duration::from_secs(3)).unwrap();
        assert_eq!(sought_regions, regions);

        // Test end_key is exclusive
        let (tx, rx) = channel();
        let tx_ = tx.clone();
        engine
            .seek_region(
                b"k1",
                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),
            )
            .unwrap();
        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();
        assert_eq!(region, regions[1]);

        // Test seek from non-starting key
        let tx_ = tx.clone();
        engine
            .seek_region(
                b"k6\xff\xff\xff\xff\xff",
                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),
            )
            .unwrap();
        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();
        assert_eq!(region, regions[3]);
        let tx_ = tx.clone();
        engine
            .seek_region(
                b"\xff\xff\xff\xff\xff\xff\xff\xff",
                Box::new(move |infos| tx_.send(infos.next().unwrap().region.clone()).unwrap()),
            )
            .unwrap();
        let region = rx.recv_timeout(Duration::from_secs(3)).unwrap();
        assert_eq!(region, regions[5]);
    }

    for (_, p) in region_info_providers {
        p.stop();
    }
}
fn test_parse_self_debug_pubtypes() {
    let debug_info = read_section("debug_info");
    let debug_info = DebugInfo::new(&debug_info, LittleEndian);

    let debug_abbrev = read_section("debug_abbrev");
    let debug_abbrev = DebugAbbrev::new(&debug_abbrev, LittleEndian);

    let debug_pubtypes = read_section("debug_pubtypes");
    let debug_pubtypes = DebugPubTypes::new(&debug_pubtypes, LittleEndian);

    let mut units = HashMap::new();
    let mut abbrevs = HashMap::new();
    let mut pubtypes = debug_pubtypes.items();
    while let Some(entry) = pubtypes.next().expect("Should parse pubtype OK") {
        let unit_offset = entry.unit_header_offset();
        let unit = units.entry(unit_offset).or_insert_with(|| {
            debug_info
                .header_from_offset(unit_offset)
                .expect("Should parse unit header OK")
        });
        let abbrev_offset = unit.debug_abbrev_offset();
        let abbrevs = abbrevs.entry(abbrev_offset).or_insert_with(|| {
            debug_abbrev
                .abbreviations(abbrev_offset)
                .expect("Should parse abbreviations OK")
        });
        let mut cursor = unit
            .entries_at_offset(abbrevs, entry.die_offset())
            .expect("DIE offset should be valid");
        assert!(cursor.next_dfs().expect("Should parse DIE").is_some());
    }
}
fn pow32_test() {
    assert_eq!(algorithm::pow32(10, 1), 10);
    assert_eq!(algorithm::pow32(10, 2), 100);
}
fn inscribe_with_dry_run_flag() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);
  rpc_server.mine_blocks(1);

  CommandBuilder::new("wallet inscribe --dry-run --file degenerate.png --fee-rate 1")
    .write("degenerate.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  assert!(rpc_server.mempool().is_empty());

  CommandBuilder::new("wallet inscribe --file degenerate.png --fee-rate 1")
    .write("degenerate.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  assert_eq!(rpc_server.mempool().len(), 2);
}
fn test_ne() {
    assert_ne!(version("0.0.0"), version("0.0.1"));
    assert_ne!(version("0.0.0"), version("0.1.0"));
    assert_ne!(version("0.0.0"), version("1.0.0"));
    assert_ne!(version("1.2.3-alpha"), version("1.2.3-beta"));
    assert_ne!(version("1.2.3+23"), version("1.2.3+42"));
}
fn TinyVec_move_to_heap_and_shrink() {
  let mut tv: TinyVec<[i32; 4]> = Default::default();
  assert!(tv.is_inline());
  tv.move_to_the_heap();
  assert!(tv.is_heap());
  assert_eq!(tv.capacity(), 0);

  tv.push(1);
  tv.shrink_to_fit();
  assert!(tv.is_inline());
  assert_eq!(tv.capacity(), 4);

  tv.move_to_the_heap_and_reserve(3);
  assert!(tv.is_heap());
  assert_eq!(tv.capacity(), 4);
  tv.extend(2..=4);
  assert_eq!(tv.capacity(), 4);
  assert_eq!(tv.as_slice(), [1, 2, 3, 4]);
}
fn test_iterator() {
    let (mut record, journal) = create_test_journal();

    let mut iter = journal.iter();

    assert_eq!(
        record.set_data(Some(RData::A(A::from_str("127.0.0.1").unwrap()))),
        &iter.next().unwrap()
    );
    assert_eq!(
        record.set_data(Some(RData::A(A::from_str("127.0.1.1").unwrap()))),
        &iter.next().unwrap()
    );
    assert_eq!(None, iter.next());
}
fn test_random() {
    let n = if cfg!(miri) { 100 } else { 1000000 };
    let mut buffer = ryu::Buffer::new();
    for _ in 0..n {
        let f: f64 = rand::random();
        assert_eq!(f, buffer.format_finite(f).parse().unwrap());
    }
}
fn parse_select_into() {
    let sql = "SELECT * INTO table0 FROM table1";
    one_statement_parses_to(sql, "SELECT * INTO table0 FROM table1");
    let select = verified_only_select(sql);
    assert_eq!(
        &SelectInto {
            temporary: false,
            unlogged: false,
            table: false,
            name: ObjectName(vec![Ident::new("table0")]),
        },
        only(&select.into)
    );

    let sql = "SELECT * INTO TEMPORARY UNLOGGED TABLE table0 FROM table1";
    one_statement_parses_to(
        sql,
        "SELECT * INTO TEMPORARY UNLOGGED TABLE table0 FROM table1",
    );

    // Do not allow aliases here
    let sql = "SELECT * INTO table0 asdf FROM table1";
    let result = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: asdf".to_string()),
        result.unwrap_err()
    )
}
fn test_deadline_3() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = {
        let engine = tikv::storage::TestEngineBuilder::new().build().unwrap();
        let cfg = tikv::server::Config {
            end_point_request_max_handle_duration: tikv_util::config::ReadableDuration::secs(1),
            ..Default::default()
        };
        init_data_with_details(Context::default(), engine, &product, &data, true, &cfg)
    };
    let req = DagSelect::from(&product).build();

    fail::cfg("kv_cursor_seek", "sleep(2000)").unwrap();
    fail::cfg("copr_batch_initial_size", "return(1)").unwrap();
    let cop_resp = handle_request(&endpoint, req);
    let mut resp = SelectResponse::default();
    resp.merge_from_bytes(cop_resp.get_data()).unwrap();

    assert!(
        cop_resp.other_error.contains("exceeding the deadline")
            || resp
                .get_error()
                .get_msg()
                .contains("exceeding the deadline")
    );
}
fn is_server_error() {
    assert!(status_code(500).is_server_error());
    assert!(status_code(599).is_server_error());

    assert!(!status_code(499).is_server_error());
    assert!(!status_code(600).is_server_error());
}
fn errors_when_calling_macros_defined_in_file() {
    let mut tera = Tera::default();
    tera.add_raw_template(
        "tpl",
        r#"
{% macro path_item(path) %}
    <span class="path" title="{{ path }}">{{ path }}</span>
{% endmacro path_item %}

...

<td>{{ self::path_item(path=hello) }}</td>
        "#,
    )
    .unwrap();
    let mut context = Context::new();
    context.insert("hello", &true);
    let result = tera.render("tpl", &context);
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Invalid macro definition: `path_item`"
    );
}
fn test_get_tombstone_stores() {
    let eps_count = 1;
    let server = MockServer::new(eps_count);
    let eps = server.bind_addrs();
    let mut client = new_client_v2(eps, None);

    let mut all_stores = vec![];
    let store_id = client.alloc_id().unwrap();
    let mut store = metapb::Store::default();
    store.set_id(store_id);
    let region_id = client.alloc_id().unwrap();
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    client.bootstrap_cluster(store.clone(), region).unwrap();

    all_stores.push(store);
    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);
    let s = client.get_all_stores(false).unwrap();
    assert_eq!(s, all_stores);

    // Add tombstone store.
    let mut store99 = metapb::Store::default();
    store99.set_id(99);
    store99.set_state(metapb::StoreState::Tombstone);
    server.default_handler().add_store(store99.clone());

    // do not include tombstone.
    let s = client.get_all_stores(true).unwrap();
    assert_eq!(s, all_stores);

    all_stores.push(store99.clone());
    all_stores.sort_by_key(|a| a.get_id());
    // include tombstone, there should be 2 stores.
    let mut s = client.get_all_stores(false).unwrap();
    s.sort_by_key(|a| a.get_id());
    assert_eq!(s, all_stores);

    // Add another tombstone store.
    let mut store199 = store99;
    store199.set_id(199);
    server.default_handler().add_store(store199.clone());

    all_stores.push(store199);
    all_stores.sort_by_key(|a| a.get_id());
    let mut s = client.get_all_stores(false).unwrap();
    s.sort_by_key(|a| a.get_id());
    assert_eq!(s, all_stores);

    client.get_store(store_id).unwrap();
    client.get_store(99).unwrap_err();
    client.get_store(199).unwrap_err();
}
fn nursery_group_selector_preview_enabled() {
    // Only nursery rules should be detected e.g. E225 and a warning should be displayed
    let args = ["--select", "NURSERY", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: CPY001 Missing copyright notice at top of file
    -:1:2: E225 [*] Missing whitespace around operator
    Found 2 errors.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    warning: The `NURSERY` selector has been deprecated.
    "###);
}
fn test_client_close() {
    do_test(
        3014,
        |mut cli_sock| {
            cli_sock.send(Message::Text("Hello WebSocket".into())).unwrap();

            let message = cli_sock.read().unwrap(); // receive answer from server
            assert_eq!(message.into_data(), b"From Server");

            cli_sock.close(None).unwrap(); // send close to server

            let message = cli_sock.read().unwrap(); // receive acknowledgement from server
            assert!(message.is_close());

            let err = cli_sock.read().unwrap_err(); // now we should get ConnectionClosed
            match err {
                Error::ConnectionClosed => {}
                _ => panic!("unexpected error: {:?}", err),
            }
        },
        |mut srv_sock| {
            let message = srv_sock.read().unwrap();
            assert_eq!(message.into_data(), b"Hello WebSocket");

            srv_sock.send(Message::Text("From Server".into())).unwrap();

            let message = srv_sock.read().unwrap(); // receive close from client
            assert!(message.is_close());

            let err = srv_sock.read().unwrap_err(); // now we should get ConnectionClosed
            match err {
                Error::ConnectionClosed => {}
                _ => panic!("unexpected error: {:?}", err),
            }
        },
    );
}
fn is_special_eq_test() {
    const FORMAT: u128 = STANDARD;

    let digits = b"NaN";
    let byte = digits.bytes::<{ FORMAT }>();
    assert_eq!(parse::is_special_eq::<FORMAT>(byte.clone(), b"nan"), 3);

    let byte = digits.bytes::<{ FORMAT }>();
    assert_eq!(parse::is_special_eq::<FORMAT>(byte.clone(), b"NaN"), 3);

    let byte = digits.bytes::<{ FORMAT }>();
    assert_eq!(parse::is_special_eq::<FORMAT>(byte.clone(), b"inf"), 0);
}
fn parse_variable_tag_lit_math_expression() {
    let ast = parse("{{ count + 1 * 2.5 }}").unwrap();

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Math(MathExpr {
                lhs: Box::new(Expr::new(ExprVal::Ident("count".to_string()))),
                operator: MathOperator::Add,
                rhs: Box::new(Expr::new(ExprVal::Math(MathExpr {
                    lhs: Box::new(Expr::new(ExprVal::Int(1))),
                    operator: MathOperator::Mul,
                    rhs: Box::new(Expr::new(ExprVal::Float(2.5))),
                },))),
            },))
        ),
    );
}
fn parse_alter_table_alter_column() {
    pg().one_statement_parses_to(
        "ALTER TABLE tab ALTER COLUMN is_active TYPE TEXT USING 'text'",
        "ALTER TABLE tab ALTER COLUMN is_active SET DATA TYPE TEXT USING 'text'",
    );

    match alter_table_op(
        pg().verified_stmt(
            "ALTER TABLE tab ALTER COLUMN is_active SET DATA TYPE TEXT USING 'text'",
        ),
    ) {
        AlterTableOperation::AlterColumn { column_name, op } => {
            assert_eq!("is_active", column_name.to_string());
            let using_expr = Expr::Value(Value::SingleQuotedString("text".to_string()));
            assert_eq!(
                op,
                AlterColumnOperation::SetDataType {
                    data_type: DataType::Text,
                    using: Some(using_expr),
                }
            );
        }
        _ => unreachable!(),
    }
}
fn test_node_bootstrap_with_prepared_data() {
    // create a node
    let pd_client = Arc::new(TestPdClient::new(0, false));
    let cfg = new_tikv_config(0);

    let (_, system) = fsm::create_raft_batch_system(&cfg.raft_store, &None);
    let simulate_trans = SimulateTransport::new(ChannelTransport::new());
    let tmp_path = Builder::new().prefix("test_cluster").tempdir().unwrap();
    let engine =
        engine_rocks::util::new_engine(tmp_path.path().to_str().unwrap(), ALL_CFS).unwrap();
    let tmp_path_raft = tmp_path.path().join(Path::new("raft"));
    let raft_engine =
        engine_rocks::util::new_engine(tmp_path_raft.to_str().unwrap(), &[CF_DEFAULT]).unwrap();
    let engines = Engines::new(engine.clone(), raft_engine);
    let tmp_mgr = Builder::new().prefix("test_cluster").tempdir().unwrap();
    let bg_worker = WorkerBuilder::new("background").thread_count(2).create();
    let mut node = Node::new(
        system,
        &cfg.server,
        Arc::new(VersionTrack::new(cfg.raft_store.clone())),
        cfg.storage.api_version(),
        Arc::clone(&pd_client),
        Arc::default(),
        bg_worker,
        None,
        None,
    );
    let snap_mgr = SnapManager::new(tmp_mgr.path().to_str().unwrap());
    let pd_worker = LazyWorker::new("test-pd-worker");

    // assume there is a node has bootstrapped the cluster and add region in pd
    // successfully
    bootstrap_with_first_region(Arc::clone(&pd_client)).unwrap();

    // now another node at same time begin bootstrap node, but panic after prepared
    // bootstrap now rocksDB must have some prepare data
    bootstrap_store(&engines, 0, 1).unwrap();
    let region = node.prepare_bootstrap_cluster(&engines, 1).unwrap();
    assert!(
        engine
            .get_msg::<metapb::Region>(keys::PREPARE_BOOTSTRAP_KEY)
            .unwrap()
            .is_some()
    );
    let region_state_key = keys::region_state_key(region.get_id());
    assert!(
        engine
            .get_msg_cf::<RegionLocalState>(CF_RAFT, &region_state_key)
            .unwrap()
            .is_some()
    );

    // Create coprocessor.
    let coprocessor_host = CoprocessorHost::new(node.get_router(), cfg.coprocessor);

    let importer = {
        let dir = tmp_path.path().join("import-sst");
        Arc::new(SstImporter::new(&cfg.import, dir, None, cfg.storage.api_version()).unwrap())
    };
    let (split_check_scheduler, _) = dummy_scheduler();

    node.try_bootstrap_store(engines.clone()).unwrap();
    // try to restart this node, will clear the prepare data
    node.start(
        engines,
        simulate_trans,
        snap_mgr,
        pd_worker,
        Arc::new(Mutex::new(StoreMeta::new(0))),
        coprocessor_host,
        importer,
        split_check_scheduler,
        AutoSplitController::default(),
        ConcurrencyManager::new(1.into()),
        CollectorRegHandle::new_for_test(),
        None,
        Arc::new(AtomicU64::new(0)),
    )
    .unwrap();
    assert!(
        engine
            .get_msg::<metapb::Region>(keys::PREPARE_BOOTSTRAP_KEY)
            .unwrap()
            .is_none()
    );
    assert!(
        engine
            .get_msg_cf::<RegionLocalState>(CF_RAFT, &region_state_key)
            .unwrap()
            .is_none()
    );
    assert_eq!(pd_client.get_regions_number() as u32, 1);
    node.stop();
}
fn b_test() {
    assert_eq!(b(1e-45_f32), (1, -149));
    assert_eq!(b(5e-324_f64), (1, -1074));
    assert_eq!(b(1e-323_f64), (2, -1074));
    assert_eq!(b(2e-323_f64), (4, -1074));
    assert_eq!(b(3e-323_f64), (6, -1074));
    assert_eq!(b(4e-323_f64), (8, -1074));
    assert_eq!(b(5e-323_f64), (10, -1074));
    assert_eq!(b(6e-323_f64), (12, -1074));
    assert_eq!(b(7e-323_f64), (14, -1074));
    assert_eq!(b(8e-323_f64), (16, -1074));
    assert_eq!(b(9e-323_f64), (18, -1074));
    assert_eq!(b(1_f32), (8388608, -23));
    assert_eq!(b(1_f64), (4503599627370496, -52));
    assert_eq!(b(1e38_f32), (9860761, 103));
    assert_eq!(b(1e308_f64), (5010420900022432, 971));
}
fn test_resource_group() {
    let (control_tx, control_fsm) = Runner::new(10);
    let resource_manager = ResourceGroupManager::default();

    let get_group = |name: &str, read_tokens: u64, write_tokens: u64| -> ResourceGroup {
        let mut group = ResourceGroup::new();
        group.set_name(name.to_string());
        group.set_mode(GroupMode::RawMode);
        let mut resource_setting = GroupRawResourceSettings::new();
        resource_setting
            .mut_cpu()
            .mut_settings()
            .set_fill_rate(read_tokens);
        resource_setting
            .mut_io_write()
            .mut_settings()
            .set_fill_rate(write_tokens);
        group.set_raw_resource_settings(resource_setting);
        group
    };

    resource_manager.add_resource_group(get_group("group1", 10, 10));
    resource_manager.add_resource_group(get_group("group2", 100, 100));

    let mut cfg = Config::default();
    cfg.pool_size = 1;
    let (router, mut system) = batch_system::create_system(
        &cfg,
        control_tx,
        control_fsm,
        Some(resource_manager.derive_controller("test".to_string(), false)),
    );
    let builder = Builder::new();
    system.spawn("test".to_owned(), builder);
    let (tx, rx) = mpsc::unbounded();
    let tx_ = tx.clone();
    let r = router.clone();
    let state_cnt = Arc::new(AtomicUsize::new(0));
    router
        .send_control(Message::Callback(Box::new(
            move |_: &Handler, _: &mut Runner| {
                let (tx, runner) = Runner::new(10);
                r.register(1, BasicMailbox::new(tx, runner, state_cnt.clone()));
                let (tx2, runner2) = Runner::new(10);
                r.register(2, BasicMailbox::new(tx2, runner2, state_cnt));
                tx_.send(0).unwrap();
            },
        )))
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(0));

    let tx_ = tx.clone();
    let (tx1, rx1) = std::sync::mpsc::sync_channel(0);
    // block the thread
    router
        .send_control(Message::Callback(Box::new(
            move |_: &Handler, _: &mut Runner| {
                tx_.send(0).unwrap();
                tx1.send(0).unwrap();
            },
        )))
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(0));

    router
        .send(1, Message::Resource("group1".to_string(), 1))
        .unwrap();
    let tx_ = tx.clone();
    router
        .send(
            1,
            Message::Callback(Box::new(move |_: &Handler, _: &mut Runner| {
                tx_.send(1).unwrap();
            })),
        )
        .unwrap();

    router
        .send(2, Message::Resource("group2".to_string(), 1))
        .unwrap();
    router
        .send(
            2,
            Message::Callback(Box::new(move |_: &Handler, _: &mut Runner| {
                tx.send(2).unwrap();
            })),
        )
        .unwrap();

    // pause the blocking thread
    assert_eq!(rx1.recv_timeout(Duration::from_secs(3)), Ok(0));

    // should recv from group2 first, because group2 has more tokens and it would be
    // handled with higher priority.
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(2));
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(1));
}
fn parse_ceil_datetime() {
    let sql = "SELECT CEIL(d TO DAY)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Ceil {
            expr: Box::new(Expr::Identifier(Ident::new("d"))),
            field: DateTimeField::Day,
        },
        expr_from_projection(only(&select.projection)),
    );

    one_statement_parses_to("SELECT CEIL(d to day)", "SELECT CEIL(d TO DAY)");

    verified_stmt("SELECT CEIL(d TO HOUR) FROM df");
    verified_stmt("SELECT CEIL(d TO MINUTE) FROM df");
    verified_stmt("SELECT CEIL(d TO SECOND) FROM df");
    verified_stmt("SELECT CEIL(d TO MILLISECOND) FROM df");

    let res = parse_sql_statements("SELECT CEIL(d TO JIFFY) FROM df");
    assert_eq!(
        ParserError::ParserError("Expected date/time field, found: JIFFY".to_string()),
        res.unwrap_err()
    );
}
fn test_cp_arg_suffix() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg("-b")
        .arg("--suffix")
        .arg(".bak")
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}.bak")),
        "How are you?\n"
    );
}
fn parse_variable_tag_global_function_with_filter() {
    let ast = parse("{{ get_time(some=1) | round | upper }}").unwrap();
    let mut args = HashMap::new();
    args.insert("some".to_string(), Expr::new(ExprVal::Int(1)));

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::with_filters(
                ExprVal::FunctionCall(FunctionCall { name: "get_time".to_string(), args },),
                vec![
                    FunctionCall { name: "round".to_string(), args: HashMap::new() },
                    FunctionCall { name: "upper".to_string(), args: HashMap::new() },
                ],
            )
        )
    );
}
fn test_refresh_bucket() {
    let mut cluster = Cluster::default();
    let store_id = cluster.node(0).id();
    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();
    let router = &mut cluster.routers[0];

    let region_2 = 2;
    let region = router.region_detail(region_2);
    let peer = region.get_peers()[0].clone();
    router.wait_applied_to_current_term(region_2, Duration::from_secs(3));

    // Region 2 ["", ""]
    //   -> Region 2    ["", "k22"]
    //      Region 1000 ["k22", ""] peer(1, 10)
    let region_state = raft_engine
        .get_region_state(region_2, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);

    // to simulate the delay of set_apply_scheduler
    fail::cfg("delay_set_apply_scheduler", "sleep(1000)").unwrap();
    split_region_and_refresh_bucket(
        router,
        region,
        peer,
        1000,
        new_peer(store_id, 10),
        b"k22",
        false,
    );

    for _i in 1..100 {
        std::thread::sleep(Duration::from_millis(50));
        let meta = router
            .must_query_debug_info(1000, Duration::from_secs(1))
            .unwrap();
        if !meta.bucket_keys.is_empty() {
            assert_eq!(meta.bucket_keys.len(), 4); // include region start/end keys
            assert_eq!(meta.bucket_keys[1], b"1".to_vec());
            assert_eq!(meta.bucket_keys[2], b"2".to_vec());
            return;
        }
    }
    panic!("timeout for updating buckets"); // timeout
}
fn drain_drop_immediately() {
    // test mem::forgetting does not double-free

    let mut headers = HeaderMap::new();
    headers.insert("hello", "world".parse().unwrap());
    headers.insert("zomg", "bar".parse().unwrap());
    headers.append("hello", "world2".parse().unwrap());

    let iter = headers.drain();
    assert_eq!(iter.size_hint(), (2, Some(3)));
    // not consuming `iter`
}
fn lex_break_tag() {
    assert!(TeraParser::parse(Rule::break_tag, "{% break %}").is_ok());
}
fn parse_create_virtual_table() {
    let sql = "CREATE VIRTUAL TABLE IF NOT EXISTS t USING module_name (arg1, arg2)";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::CreateVirtualTable {
            name,
            if_not_exists: true,
            module_name,
            module_args,
        } => {
            let args = vec![Ident::new("arg1"), Ident::new("arg2")];
            assert_eq!("t", name.to_string());
            assert_eq!("module_name", module_name.to_string());
            assert_eq!(args, module_args);
        }
        _ => unreachable!(),
    }

    let sql = "CREATE VIRTUAL TABLE t USING module_name";
    sqlite_and_generic().verified_stmt(sql);
}
fn test_flashback() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.cfg.resolved_ts.advance_ts_interval = ReadableDuration::millis(50);
    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();

    let key = Key::from_raw(b"a");
    let region = suite.cluster.get_region(key.as_encoded());
    let region_id = region.get_id();
    let req = suite.new_changedata_request(region_id);
    let (mut req_tx, _, receive_event) = new_event_feed(suite.get_region_cdc_client(region_id));
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();
    let event = receive_event(false);
    event.events.into_iter().for_each(|e| {
        match e.event.unwrap() {
            // Even if there is no write,
            // it should always outputs an Initialized event.
            Event_oneof_event::Entries(es) => {
                assert!(es.entries.len() == 1, "{:?}", es);
                let e = &es.entries[0];
                assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
            }
            other => panic!("unknown event {:?}", other),
        }
    });
    // Sleep a while to make sure the stream is registered.
    sleep_ms(1000);
    let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
    for i in 0..2 {
        let (k, v) = (
            format!("key{}", i).as_bytes().to_vec(),
            format!("value{}", i).as_bytes().to_vec(),
        );
        // Prewrite
        let start_ts1 = block_on(suite.cluster.pd_client.get_tso()).unwrap();
        let mut mutation = Mutation::default();
        mutation.set_op(Op::Put);
        mutation.key = k.clone();
        mutation.value = v;
        suite.must_kv_prewrite(1, vec![mutation], k.clone(), start_ts1);
        // Commit
        let commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
        suite.must_kv_commit(1, vec![k.clone()], start_ts1, commit_ts);
    }
    let (start_key, end_key) = (b"key0".to_vec(), b"key2".to_vec());
    // Prepare flashback.
    let flashback_start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
    suite.must_kv_prepare_flashback(region_id, &start_key, &end_key, flashback_start_ts);
    // resolved ts should not be advanced anymore.
    let mut counter = 0;
    let mut last_resolved_ts = 0;
    loop {
        let event = receive_event(true);
        if let Some(resolved_ts) = event.resolved_ts.as_ref() {
            if resolved_ts.ts == last_resolved_ts {
                counter += 1;
            }
            last_resolved_ts = resolved_ts.ts;
        }
        if counter > 20 {
            break;
        }
        sleep_ms(50);
    }
    // Flashback.
    let flashback_commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
    suite.must_kv_flashback(
        region_id,
        &start_key,
        &end_key,
        flashback_start_ts,
        flashback_commit_ts,
        start_ts,
    );
    // Check the flashback event.
    let mut resolved_ts = 0;
    let mut event_counter = 0;
    loop {
        let mut cde = receive_event(true);
        if cde.get_resolved_ts().get_ts() > resolved_ts {
            resolved_ts = cde.get_resolved_ts().get_ts();
        }
        let events = cde.mut_events();
        if !events.is_empty() {
            assert_eq!(events.len(), 1);
            match events.pop().unwrap().event.unwrap() {
                Event_oneof_event::Entries(entries) => {
                    assert_eq!(entries.entries.len(), 1);
                    event_counter += 1;
                    let e = &entries.entries[0];
                    assert!(e.commit_ts > resolved_ts);
                    assert_eq!(e.get_op_type(), EventRowOpType::Delete);
                    match e.get_type() {
                        EventLogType::Committed => {
                            // First entry should be a 1PC flashback.
                            assert_eq!(e.get_key(), b"key1");
                            assert_eq!(event_counter, 1);
                        }
                        EventLogType::Commit => {
                            // Second entry should be a 2PC commit.
                            assert_eq!(e.get_key(), b"key0");
                            assert_eq!(event_counter, 2);
                            break;
                        }
                        _ => panic!("unknown event type {:?}", e.get_type()),
                    }
                }
                other => panic!("unknown event {:?}", other),
            }
        }
    }
}
fn wallet_creates_correct_test_network_taproot_descriptor() {
  let rpc_server = test_bitcoincore_rpc::builder()
    .network(Network::Signet)
    .build();

  CommandBuilder::new("--chain signet wallet create")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Output>();

  assert_eq!(rpc_server.descriptors().len(), 2);
  assert_regex_match!(
    &rpc_server.descriptors()[0],
    r"tr\(\[[[:xdigit:]]{8}/86'/1'/0'\]tprv[[:alnum:]]*/0/\*\)#[[:alnum:]]{8}"
  );
  assert_regex_match!(
    &rpc_server.descriptors()[1],
    r"tr\(\[[[:xdigit:]]{8}/86'/1'/0'\]tprv[[:alnum:]]*/1/\*\)#[[:alnum:]]{8}"
  );
}
fn cardinals() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  inscribe(&rpc_server);

  let all_outputs = CommandBuilder::new("wallet outputs")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<Output>>();

  let cardinal_outputs = CommandBuilder::new("wallet cardinals")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Vec<CardinalUtxo>>();

  assert_eq!(all_outputs.len() - cardinal_outputs.len(), 1);
}
fn lower_n_halfway_test() {
    assert_eq!(mask::lower_n_halfway(2), 0b10);
}
fn parse_create_schema_with_authorization() {
    let sql = "CREATE SCHEMA AUTHORIZATION Y";

    match verified_stmt(sql) {
        Statement::CreateSchema { schema_name, .. } => {
            assert_eq!(schema_name.to_string(), "AUTHORIZATION Y".to_owned())
        }
        _ => unreachable!(),
    }
}
fn issue_655() {
  use nom::character::streaming::{line_ending, not_line_ending};
  fn twolines(i: &str) -> IResult<&str, (&str, &str)> {
    let (i, l1) = not_line_ending(i)?;
    let (i, _) = line_ending(i)?;
    let (i, l2) = not_line_ending(i)?;
    let (i, _) = line_ending(i)?;

    Ok((i, (l1, l2)))
  }

  assert_eq!(twolines("foo\nbar\n"), Ok(("", ("foo", "bar"))));
  assert_eq!(twolines("fÃ©o\nbar\n"), Ok(("", ("fÃ©o", "bar"))));
  assert_eq!(twolines("foÃ©\nbar\n"), Ok(("", ("foÃ©", "bar"))));
  assert_eq!(twolines("foÃ©\r\nbar\n"), Ok(("", ("foÃ©", "bar"))));
}

#[cf
fn write_batch_delete_range_twice() {
    let db = default_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();

    let mut wb = db.engine.write_batch();

    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());

    let db = multi_batch_write_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();

    let mut wb = db.engine.write_batch_with_cap(1024);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }

    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())
        .unwrap();
    wb.delete_range(&1_usize.to_be_bytes(), &256_usize.to_be_bytes())
        .unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());
    assert!(
        db.engine
            .get_value(&0_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    for i in 1..256_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn test_kill_with_signal_number_old_form() {
    let mut target = Target::new();
    new_ucmd!()
        .arg("-9")
        .arg(format!("{}", target.pid()))
        .succeeds();
    assert_eq!(target.wait_for_signal(), Some(9));
}
fn ignore_vcs_ignored_file() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = r#"{
        "vcs": {
            "enabled": true,
            "clientKind": "git",
            "useIgnoreFile": true
        }
    }"#;

    let git_ignore = r#"
file2.js
"#;

    let code2 = r#"foo.call();


    bar.call();"#;
    let code1 = r#"array.map(sentence =>


    sentence.split(' ')).flat();"#;

    // ignored files
    let file_path1 = Path::new("file1.js");
    fs.insert(file_path1.into(), code1.as_bytes());
    let file_path2 = Path::new("file2.js");
    fs.insert(file_path2.into(), code2.as_bytes());

    // configuration
    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), rome_json.as_bytes());

    // git ignore file
    let ignore_file = Path::new(".gitignore");
    fs.insert(ignore_file.into(), git_ignore.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                file_path1.as_os_str().to_str().unwrap(),
                file_path2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ignore_vcs_ignored_file",
        fs,
        console,
        result,
    ));
}
fn test_split_overflow_bytes_size() {
    #[cfg(not(target_pointer_width = "128"))]
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "test_split_overflow_bytes_size";
    RandomFile::new(&at, name).add_bytes(1000);
    ucmd.args(&["-b", "1Y", name]).succeeds();
    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 1);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn var_access_by_loop_index_with_set() {
    let context = Context::new();
    let res = Tera::one_off(
        r#"
{% set ics = ["fa-rocket","fa-paper-plane","fa-diamond","fa-signal"] %}
{% for a in ics %}
    {% set i = loop.index - 1 %}
    {{ ics[i] }}
{% endfor %}
    "#,
        &context,
        true,
    );
    assert!(res.is_ok());
}
fn test_offset_err_comment() {
    let mut r = Reader::from_str("<a><!--b>");
    r.trim_text(true);

    next_eq!(r, Start, b"a");
    assert_eq!(r.buffer_position(), 3);

    match r.read_event() {
        // error at char 4: no closing --> tag found
        Err(e) => assert_eq!(
            r.buffer_position(),
            4,
            "expecting buf_pos = 4, found {}, err {:?}",
            r.buffer_position(),
            e
        ),
        e => panic!("expecting error, found {:?}", e),
    }
}
fn test_split_obs_lines_standalone() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "obs-lines-standalone";
    RandomFile::new(&at, name).add_lines(4);
    ucmd.args(&["-2", name]).succeeds().no_stderr().no_stdout();
    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_trailing_comma_list() {
    assert!(from_str::<Vec<i32>>("[1,2]").is_ok());
    assert!(from_str::<Vec<i32>>("[1,2,]").is_ok());
    assert!(from_str::<Vec<i32>>("[1,2,,]").is_err());
}
fn get_none() {
    let mut store = Store::<()>::default();
    let ty = TableType::new(ValType::FuncRef, 1, None);
    let table = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();
    match table.get(&mut store, 0) {
        Some(Val::FuncRef(None)) => {}
        _ => panic!(),
    }
    assert!(table.get(&mut store, 1).is_none());
}
fn parse_invalid_infix_not() {
    let res = parse_sql_statements("SELECT c FROM t WHERE c NOT (");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: NOT".to_string()),
        res.unwrap_err(),
    );
}
fn test_ingest_file_twice_and_conflict() {
    // test with tde
    let (_tmp_key_dir, _cluster, ctx, _tikv, import) = new_cluster_and_tikv_import_client_tde();

    let temp_dir = Builder::new()
        .prefix("test_ingest_file_twice_and_conflict")
        .tempdir()
        .unwrap();
    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());
    upload_sst(&import, &meta, &data).unwrap();
    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx);
    ingest.set_sst(meta);

    let latch_fp = "import::sst_service::ingest";
    let (tx1, rx1) = channel();
    let (tx2, rx2) = channel();
    let tx1 = Arc::new(Mutex::new(tx1));
    let rx2 = Arc::new(Mutex::new(rx2));
    fail::cfg_callback(latch_fp, move || {
        tx1.lock().unwrap().send(()).unwrap();
        rx2.lock().unwrap().recv().unwrap();
    })
    .unwrap();
    let resp_recv = import.ingest_async(&ingest).unwrap();

    // Make sure the before request has acquired lock.
    rx1.recv().unwrap();

    let resp = import.ingest(&ingest).unwrap();
    assert!(resp.has_error());
    assert_eq!("ingest file conflict", resp.get_error().get_message());
    tx2.send(()).unwrap();
    let resp = block_on(resp_recv).unwrap();
    assert!(!resp.has_error());

    fail::remove(latch_fp);
    let resp = import.ingest(&ingest).unwrap();
    assert!(resp.has_error());
    assert_eq!(
        "The file which would be ingested doest not exist.",
        resp.get_error().get_message()
    );
}
fn test_symlink_target_dir_from_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_ln_target_dir_dir";
    let from_dir = "test_ln_target_dir_from_dir";
    let filename_a = "test_ln_target_dir_file_a";
    let filename_b = "test_ln_target_dir_file_b";
    let file_a = &format!("{from_dir}/{filename_a}");
    let file_b = &format!("{from_dir}/{filename_b}");

    at.mkdir(from_dir);
    at.touch(file_a);
    at.touch(file_b);
    at.mkdir(dir);

    ucmd.args(&["-s", "-t", dir, file_a, file_b])
        .succeeds()
        .no_stderr();

    let file_a_link = &format!("{dir}/{filename_a}");
    assert!(at.is_symlink(file_a_link));
    assert_eq!(&at.resolve_link(file_a_link), file_a);

    let file_b_link = &format!("{dir}/{filename_b}");
    assert!(at.is_symlink(file_b_link));
    assert_eq!(&at.resolve_link(file_b_link), file_b);
}
pub fn test_max_resource_groups() {
    let port = alloc_port();
    let mut test_suite = TestSuite::new(resource_metering::Config {
        receiver_address: format!("127.0.0.1:{}", port),
        report_receiver_interval: ReadableDuration::secs(4),
        max_resource_groups: 5000,
        precision: ReadableDuration::secs(2),
    });
    test_suite.start_receiver_at(port);

    // Workload
    // [req-{1..3} * 6, req-{4..5} * 1]
    let mut wl = iter::repeat(1..=3)
        .take(6)
        .flatten()
        .chain(4..=5)
        .map(|n| format!("req-{}", n))
        .collect::<Vec<_>>();
    wl.shuffle(&mut rand::thread_rng());
    test_suite.setup_workload(wl);

    // | Max Resource Groups |
    // |       5000          |
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));
    assert!(res.contains_key("req-3"));
    assert!(res.contains_key("req-4"));
    assert!(res.contains_key("req-5"));

    // | Max Resource Groups |
    // |        3            |
    test_suite.cfg_max_resource_groups(3);
    test_suite.flush_receiver();
    let res = test_suite.block_receive_one();
    assert_eq!(res.len(), 4);
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));
    assert!(res.contains_key("req-3"));
    assert!(res.contains_key(""));
}
fn test_symlink_target_only() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_symlink_target_only";

    at.mkdir(dir);

    assert!(!ucmd
        .args(&["-s", "-t", dir])
        .fails()
        .stderr_str()
        .is_empty());
}
fn should_create_biome_json_file() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let configuration = r#"{ "linter": { "enabled": true } }"#;

    let configuration_path = Path::new("rome.json");
    fs.insert(configuration_path.into(), configuration.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("migrate"), "--write"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_create_biome_json_file",
        fs,
        console,
        result,
    ));
}
fn test_joint_consensus_conf_change() {
    let mut cluster = new_node_cluster(0, 4);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region_id = cluster.run_conf_change();

    cluster.must_put(b"k1", b"v1");
    assert_eq!(cluster.get(b"k1"), Some(b"v1".to_vec()));

    // add multiple nodes
    pd_client.must_joint_confchange(
        region_id,
        vec![
            (ConfChangeType::AddNode, new_peer(2, 2)),
            (ConfChangeType::AddNode, new_peer(3, 3)),
            (ConfChangeType::AddLearnerNode, new_learner_peer(4, 4)),
        ],
    );
    pd_client.must_leave_joint(region_id);
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    must_get_equal(&cluster.get_engine(4), b"k1", b"v1");

    // remove multiple nodes
    pd_client.must_joint_confchange(
        region_id,
        vec![
            (ConfChangeType::AddLearnerNode, new_learner_peer(3, 3)),
            (ConfChangeType::RemoveNode, new_learner_peer(4, 4)),
        ],
    );
    pd_client.must_leave_joint(region_id);
    assert_eq!(
        find_peer(&pd_client.get_region(b"").unwrap(), 3).unwrap(),
        &new_learner_peer(3, 3)
    );
    must_get_none(&cluster.get_engine(4), b"k1");

    // replace node
    pd_client.must_joint_confchange(
        region_id,
        vec![
            (ConfChangeType::RemoveNode, new_learner_peer(3, 3)),
            (ConfChangeType::AddNode, new_peer(4, 5)),
        ],
    );
    pd_client.must_leave_joint(region_id);
    must_get_none(&cluster.get_engine(3), b"k1");
    must_get_equal(&cluster.get_engine(4), b"k1", b"v1");
}
fn parens_test() {
  assert_eq!(expr(" (  2 )"), Ok(("", 2)));
  assert_eq!(expr(" 2* (  3 + 4 ) "), Ok(("", 14)));
  assert_eq!(expr("  2*2 / ( 5 - 1) + 3"), Ok(("", 4)));
}
fn test_trailing_comma_enum_tuple_variant() {
    assert!(from_str::<Enum>("Tuple(1,2)").is_ok());
    assert!(from_str::<Enum>("Tuple(1,2,)").is_ok());
    assert!(from_str::<Enum>("Tuple(1,2,,)").is_err());
}
fn test_mv_errors() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let dir = "test_mv_errors_dir";
    let file_a = "test_mv_errors_file_a";
    let file_b = "test_mv_errors_file_b";
    at.mkdir(dir);
    at.touch(file_a);
    at.touch(file_b);

    // $ mv -T -t a b
    // mv: cannot combine --target-directory (-t) and --no-target-directory (-T)
    scene
        .ucmd()
        .arg("-T")
        .arg("-t")
        .arg(dir)
        .arg(file_a)
        .arg(file_b)
        .fails()
        .stderr_contains("cannot be used with");

    // $ at.touch file && at.mkdir dir
    // $ mv -T file dir
    // err == mv: cannot overwrite directory 'dir' with non-directory
    scene
        .ucmd()
        .arg("-T")
        .arg(file_a)
        .arg(dir)
        .fails()
        .stderr_is(format!(
            "mv: cannot overwrite directory '{dir}' with non-directory\n"
        ));

    // $ at.mkdir dir && at.touch file
    // $ mv dir file
    // err == mv: cannot overwrite non-directory 'file' with directory 'dir'
    assert!(!scene
        .ucmd()
        .arg(dir)
        .arg(file_a)
        .fails()
        .stderr_str()
        .is_empty());
}
fn test_force_leader_on_healthy_region() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(30);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    // try to enter force leader, it can't succeed due to quorum isn't lost
    cluster.enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // make sure it leaves pre force leader state.
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 3,
    ));
    // put and get can propose successfully.
    assert_eq!(cluster.must_get(b"k1"), Some(b"v1".to_vec()));
    cluster.must_put(b"k2", b"v2");

    // try to exit force leader, it will be ignored silently as it's not in the
    // force leader state
    cluster.exit_force_leader(region.get_id(), 1);

    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn regression7() {
    let tmpfile = create_tempfile();

    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<u64, &[u8]> = TableDefinition::new("x");

    let tx = db.begin_write().unwrap();
    {
        let mut t = tx.open_table(table_def).unwrap();
        let big_value = vec![0u8; 4063];
        t.insert(&35723, big_value.as_slice()).unwrap();
        t.remove(&145278).unwrap();
        t.remove(&145227).unwrap();
    }
    tx.commit().unwrap();

    let mut tx = db.begin_write().unwrap();
    tx.set_durability(Durability::None);
    {
        let mut t = tx.open_table(table_def).unwrap();
        let v = vec![0u8; 47];
        t.insert(&66469, v.as_slice()).unwrap();
        let v = vec![0u8; 2414];
        t.insert(&146255, v.as_slice()).unwrap();
        let v = vec![0u8; 159];
        t.insert(&153701, v.as_slice()).unwrap();
        let v = vec![0u8; 1186];
        t.insert(&145227, v.as_slice()).unwrap();
        let v = vec![0u8; 223];
        t.insert(&118749, v.as_slice()).unwrap();

        t.remove(&145227).unwrap();

        let mut iter = t.range(138763..(138763 + 232359)).unwrap().rev();
        assert_eq!(iter.next().unwrap().unwrap().0.value(), 153701);
        assert_eq!(iter.next().unwrap().unwrap().0.value(), 146255);
        assert!(iter.next().is_none());
    }
    tx.commit().unwrap();
}
fn test_cp_arg_update_all() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("--update=all")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(
        at.read(TEST_HOW_ARE_YOU_SOURCE),
        at.read(TEST_HELLO_WORLD_SOURCE)
    );
}
fn stored_size() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    assert_eq!(write_txn.stats().unwrap().stored_bytes(), 10);
    assert!(write_txn.stats().unwrap().fragmented_bytes() > 0);
    assert!(write_txn.stats().unwrap().metadata_bytes() > 0);
    write_txn.abort().unwrap();
}
fn test_merge_pessimistic_locks_propose_fail() {
    let mut cluster = new_server_cluster(0, 2);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k2");
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k3");

    // Sending a TransferLeaeder message to make left region fail to propose.

    let snapshot = cluster.must_get_snapshot_of_region(left.id);
    let txn_ext = snapshot.ext().get_txn_ext().unwrap().clone();
    let lock = PessimisticLock {
        primary: b"k1".to_vec().into_boxed_slice(),
        start_ts: 10.into(),
        ttl: 3000,
        for_update_ts: 20.into(),
        min_commit_ts: 30.into(),
        last_change_ts: 15.into(),
        versions_to_last_change: 3,
    };
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(Key::from_raw(b"k1"), lock)])
        .unwrap();

    fail::cfg("raft_propose", "pause").unwrap();

    cluster.merge_region(left.id, right.id, Callback::None);
    thread::sleep(Duration::from_millis(500));
    assert_eq!(
        txn_ext.pessimistic_locks.read().status,
        LocksStatus::MergingRegion
    );

    // With the fail point set, we will fail to propose the locks or the
    // PrepareMerge request.
    fail::cfg("raft_propose", "return()").unwrap();

    // But after that, the pessimistic locks status should remain unchanged.
    for _ in 0..5 {
        thread::sleep(Duration::from_millis(500));
        if txn_ext.pessimistic_locks.read().status == LocksStatus::Normal {
            return;
        }
    }
    panic!(
        "pessimistic locks status should return to Normal, but got {:?}",
        txn_ext.pessimistic_locks.read().status
    );
}
fn test() -> io::Result<()> {
    let root = super::fixture_root().join("enhanced_resolve");
    let dirname = root.join("test");
    let temp_path = dirname.join("temp");
    if !temp_path.exists() {
        let is_admin = init(&dirname, &temp_path).is_ok();
        if !is_admin {
            return Ok(());
        }
        if let Err(err) = create_symlinks(&dirname, &temp_path) {
            cleanup_symlinks(&temp_path);
            return Err(err);
        }
    }

    let resolver_without_symlinks =
        Resolver::new(ResolveOptions { symlinks: false, ..ResolveOptions::default() });
    let resolver_with_symlinks = Resolver::default();

    #[rustfmt::skip]
    let pass = [
        ("with a symlink to a file", temp_path.clone(), "./index.js"),
        ("with a relative symlink to a file", temp_path.clone(), "./node.relative.js"),
        ("with a relative symlink to a symlink to a file", temp_path.clone(), "./node.relative.sym.js"),
        ("with a symlink to a directory 1", temp_path.clone(), "./lib/index.js"),
        ("with a symlink to a directory 2", temp_path.clone(), "./this/lib/index.js"),
        ("with multiple symlinks in the path 1", temp_path.clone(), "./this/test/temp/index.js"),
        ("with multiple symlinks in the path 2", temp_path.clone(), "./this/test/temp/lib/index.js"),
        ("with multiple symlinks in the path 3", temp_path.clone(), "./this/test/temp/this/lib/index.js"),
        ("with a symlink to a directory 2 (chained)", temp_path.clone(), "./that/lib/index.js"),
        ("with multiple symlinks in the path 1 (chained)", temp_path.clone(), "./that/test/temp/index.js"),
        ("with multiple symlinks in the path 2 (chained)", temp_path.clone(), "./that/test/temp/lib/index.js"),
        ("with multiple symlinks in the path 3 (chained)", temp_path.clone(), "./that/test/temp/that/lib/index.js"),
        ("with symlinked directory as context 1", temp_path.join( "lib"), "./index.js"),
        ("with symlinked directory as context 2", temp_path.join( "this"), "./lib/index.js"),
        ("with symlinked directory as context and in path", temp_path.join( "this"), "./test/temp/lib/index.js"),
        ("with symlinked directory in context path", temp_path.join( "this/lib"), "./index.js"),
        ("with symlinked directory in context path and symlinked file", temp_path.join( "this/test"), "./temp/index.js"),
        ("with symlinked directory in context path and symlinked directory", temp_path.join( "this/test"), "./temp/lib/index.js"),
        ("with symlinked directory as context 2 (chained)", temp_path.join( "that"), "./lib/index.js"),
        ("with symlinked directory as context and in path (chained)", temp_path.join( "that"), "./test/temp/lib/index.js"),
        ("with symlinked directory in context path (chained)", temp_path.join( "that/lib"), "./index.js"),
        ("with symlinked directory in context path and symlinked file (chained)", temp_path.join( "that/test"), "./temp/index.js"),
        ("with symlinked directory in context path and symlinked directory (chained)", temp_path.join( "that/test"), "./temp/lib/index.js")
    ];

    for (comment, path, request) in pass {
        let filename = resolver_with_symlinks.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(filename, Ok(root.join("lib/index.js")), "{comment:?}");

        let resolved_path =
            resolver_without_symlinks.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(path.join(request)));
    }

    Ok(())
}
pub fn test_commit() {
    let tag = "tag_commit";

    let (test_suite, mut store, _) = setup_test_suite();
    fail::cfg_callback("scheduler_process", || cpu_load(Duration::from_millis(100))).unwrap();
    defer!(fail::remove("scheduler_process"));

    let jh = test_suite
        .rt
        .spawn(require_cpu_time_not_zero(&test_suite, tag));

    let table = ProductTable::new();
    let insert = prepare_insert(&mut store, &table);
    insert.execute();

    let mut ctx = Context::default();
    ctx.set_resource_group_tag(tag.as_bytes().to_vec());
    store.commit_with_ctx(ctx);

    assert!(block_on(jh).unwrap());
}
fn can_remove_whitespace_inheritance() {
    let mut context = Context::new();
    context.insert("numbers", &vec![1, 2, 3]);

    let inputs = vec![
        (r#"{%- extends "base" -%} {% block content %}{{super()}}{% endblock %}"#, " Hey! "),
        (r#"{%- extends "base" -%} {% block content -%}{{super()}}{%- endblock %}"#, " Hey! "),
        (r#"{%- extends "base" %} {%- block content -%}{{super()}}{%- endblock -%} "#, " Hey! "),
    ];

    for (input, expected) in inputs {
        let mut tera = Tera::default();
        tera.add_raw_templates(vec![
            ("base", "{% block content %} Hey! {% endblock %}"),
            ("tpl", input),
        ])
        .unwrap();
        assert_eq!(tera.render("tpl", &context).unwrap(), expected);
    }
}
fn test_install_mode_failing() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "target_dir";
    let file = "source_file";
    let mode_arg = "--mode=999";

    at.touch(file);
    at.mkdir(dir);
    ucmd.arg(file)
        .arg(dir)
        .arg(mode_arg)
        .fails()
        .stderr_contains("Invalid mode string: invalid digit found in string");

    let dest_file = &format!("{dir}/{file}");
    assert!(at.file_exists(file));
    assert!(!at.file_exists(dest_file));
}
fn test_analyze_index() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, None, 4),
        (6, Some("name:1"), 1),
        (7, Some("name:1"), 1),
        (8, Some("name:1"), 1),
        (9, Some("name:2"), 1),
        (10, Some("name:2"), 1),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = init_data_with_commit(&product, &data, true);

    let req = new_analyze_index_req(&product, 3, product["name"].index, 4, 32, 2, 2);
    let resp = handle_request(&endpoint, req);
    assert!(!resp.get_data().is_empty());
    let mut analyze_resp = AnalyzeIndexResp::default();
    analyze_resp.merge_from_bytes(resp.get_data()).unwrap();
    let hist = analyze_resp.get_hist();
    assert_eq!(hist.get_ndv(), 6);
    assert_eq!(hist.get_buckets().len(), 2);
    assert_eq!(hist.get_buckets()[0].get_count(), 5);
    assert_eq!(hist.get_buckets()[0].get_ndv(), 3);
    assert_eq!(hist.get_buckets()[1].get_count(), 9);
    assert_eq!(hist.get_buckets()[1].get_ndv(), 3);
    let rows = analyze_resp.get_cms().get_rows();
    assert_eq!(rows.len(), 4);
    let sum: u32 = rows.first().unwrap().get_counters().iter().sum();
    assert_eq!(sum, 13);
    let top_n = analyze_resp.get_cms().get_top_n();
    let mut top_n_count = top_n
        .iter()
        .map(|data| data.get_count())
        .collect::<Vec<_>>();
    top_n_count.sort_unstable();
    assert_eq!(top_n_count, vec![2, 3]);
}
fn check_biome_json() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), "debugger".as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(
        config_path.into(),
        r#"{
  "linter": {
    "rules": {
        "recommended": true,
        "suspicious": {
            "noDebugger": "off"
        }
    }
  }
}"#
        .as_bytes(),
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, "debugger;\n");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "check_biome_json",
        fs,
        console,
        result,
    ));
}
fn server_exposes_offered_sni_smashed_to_lowercase() {
    // webpki actually does this for us in its DnsName type
    let kt = KeyType::Rsa;
    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(kt, &[version]);
        let mut client =
            ClientConnection::new(Arc::new(client_config), dns_name("SECOND.TESTServer.com"))
                .unwrap();
        let mut server = ServerConnection::new(Arc::new(make_server_config(kt))).unwrap();

        assert_eq!(None, server.server_name());
        do_handshake(&mut client, &mut server);
        assert_eq!(Some("second.testserver.com"), server.server_name());
    }
}
fn manual_edge_cases() {
    let mut config = Config::new();
    config.consume_fuel(true);
    let engine = Engine::new(&config).unwrap();
    let mut store = Store::new(&engine, ());
    store.add_fuel(u64::MAX).unwrap();
    assert_eq!(store.fuel_consumed(), Some(0));
    assert!(store.consume_fuel(u64::MAX).is_err());
    assert!(store.consume_fuel(i64::MAX as u64 + 1).is_err());
    assert_eq!(store.consume_fuel(i64::MAX as u64).unwrap(), 0);
}
fn ArrayVec_remove() {
  let mut av: ArrayVec<[i32; 10]> = Default::default();
  av.push(1);
  av.push(2);
  av.push(3);
  assert_eq!(av.remove(1), 2);
  assert_eq!(&av[..], &[1, 3][..]);
}
fn drain_entry() {
    let mut headers = HeaderMap::new();

    headers.insert(
        "hello".parse::<HeaderName>().unwrap(),
        "world".parse().unwrap(),
    );
    headers.insert(
        "zomg".parse::<HeaderName>().unwrap(),
        "foo".parse().unwrap(),
    );
    headers.append(
        "hello".parse::<HeaderName>().unwrap(),
        "world2".parse().unwrap(),
    );
    headers.insert(
        "more".parse::<HeaderName>().unwrap(),
        "words".parse().unwrap(),
    );
    headers.append(
        "more".parse::<HeaderName>().unwrap(),
        "insertions".parse().unwrap(),
    );
    assert_eq!(5, headers.len());

    // Using insert_mult
    {
        let mut e = match headers.entry("hello") {
            Entry::Occupied(e) => e,
            _ => panic!(),
        };

        let vals: Vec<_> = e.insert_mult("wat".parse().unwrap()).collect();
        assert_eq!(2, vals.len());
        assert_eq!(vals[0], "world");
        assert_eq!(vals[1], "world2");
    }

    assert_eq!(5-2+1, headers.len());
}
fn test_server_unknown_type() {
    let runtime = Runtime::new().expect("failed to create Tokio Runtime");
    let addr = SocketAddr::V4(SocketAddrV4::new(Ipv4Addr::new(127, 0, 0, 1), 0));
    let udp_socket = runtime.block_on(UdpSocket::bind(&addr)).unwrap();

    let ipaddr = udp_socket.local_addr().unwrap();
    println!("udp_socket on port: {ipaddr}");
    let server_continue = Arc::new(AtomicBool::new(true));
    let server_continue2 = server_continue.clone();

    let server_thread = thread::Builder::new()
        .name("test_server:udp:server".to_string())
        .spawn(move || server_thread_udp(runtime, udp_socket, server_continue2))
        .unwrap();

    let conn = UdpClientConnection::new(ipaddr).unwrap();
    let client = SyncClient::new(conn);
    let client_result = client
        .query(
            &Name::from_str("www.example.com.").unwrap(),
            DNSClass::IN,
            RecordType::Unknown(65535),
        )
        .expect("query failed for unknown");

    assert_eq!(client_result.response_code(), ResponseCode::NoError);
    assert_eq!(
        client_result.queries().first().unwrap().query_type(),
        RecordType::Unknown(65535)
    );
    assert!(client_result.answers().is_empty());
    assert!(!client_result.name_servers().is_empty());
    // SOA should be the first record in the response
    assert_eq!(
        client_result
            .name_servers()
            .first()
            .expect("no SOA present")
            .record_type(),
        RecordType::SOA
    );

    server_continue.store(false, Ordering::Relaxed);
    server_thread.join().unwrap();
}
fn wallet_balance_only_counts_cardinal_utxos() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  assert_eq!(
    CommandBuilder::new("wallet balance")
      .rpc_server(&rpc_server)
      .run_and_deserialize_output::<Output>()
      .cardinal,
    0
  );

  inscribe(&rpc_server);

  assert_eq!(
    CommandBuilder::new("wallet balance")
      .rpc_server(&rpc_server)
      .run_and_deserialize_output::<Output>()
      .cardinal,
    100 * COIN_VALUE - 10_000
  );
}
pub fn test_prewrite() {
    let tag = "tag_prewrite";

    let (test_suite, mut store, _) = setup_test_suite();
    fail::cfg_callback("scheduler_process", || cpu_load(Duration::from_millis(100))).unwrap();
    defer!(fail::remove("scheduler_process"));

    let jh = test_suite
        .rt
        .spawn(require_cpu_time_not_zero(&test_suite, tag));

    let mut ctx = Context::default();
    ctx.set_resource_group_tag(tag.as_bytes().to_vec());
    let table = ProductTable::new();
    let insert = prepare_insert(&mut store, &table);
    insert.execute_with_ctx(ctx);

    assert!(block_on(jh).unwrap());
}
fn test_stale_learner() {
    let mut cluster = new_server_cluster(0, 4);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.cfg.raft_store.max_leader_missing_duration = ReadableDuration::millis(150);
    cluster.cfg.raft_store.abnormal_leader_missing_duration = ReadableDuration::millis(100);
    cluster.cfg.raft_store.peer_stale_state_check_interval = ReadableDuration::millis(100);
    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let r1 = cluster.run_conf_change();
    pd_client.must_add_peer(r1, new_peer(2, 2));
    pd_client.must_add_peer(r1, new_learner_peer(3, 3));
    cluster.must_put(b"k1", b"v1");
    let engine3 = cluster.get_engine(3);
    must_get_equal(&engine3, b"k1", b"v1");

    // And then isolate peer on store 3 from leader.
    cluster.add_send_filter(IsolationFilterFactory::new(3));

    // Add a new peer to increase the conf version.
    pd_client.must_add_peer(r1, new_peer(4, 4));

    // It should not be deleted.
    thread::sleep(Duration::from_millis(200));
    must_get_equal(&engine3, b"k1", b"v1");

    // Promote the learner
    pd_client.must_add_peer(r1, new_peer(3, 3));

    // It should not be deleted.
    thread::sleep(Duration::from_millis(200));
    must_get_equal(&engine3, b"k1", b"v1");

    // Delete the learner
    pd_client.must_remove_peer(r1, new_peer(3, 3));

    // Check not leader should fail, all data should be removed.
    must_get_none(&engine3, b"k1");
    let state_key = keys::region_state_key(r1);
    let state: RegionLocalState = engine3.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();
    assert_eq!(state.get_state(), PeerState::Tombstone);
}
fn preview_disabled_does_not_warn_for_empty_ignore_selections() {
    // Does not warn that the selection is empty since the user is not trying to enable the rule
    let args = ["--ignore", "CPY"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    Found 1 error.

    ----- stderr -----
    "###);
}
fn user_role_range_type() {
    let (dir, mut cmd) = at_and_ucmd!();

    dir.touch("a.tmp");
    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    if a_context.is_none() {
        set_file_context(dir.plus("a.tmp"), "unconfined_u:object_r:user_tmp_t:s0").unwrap();
    }

    cmd.args(&[
        "--verbose",
        "--user=guest_u",
        "--role=object_r",
        "--type=etc_t",
        "--range=s0:c42",
    ])
    .arg(dir.plus("a.tmp"))
    .succeeds();

    assert_eq!(
        get_file_context(dir.plus("a.tmp")).unwrap().as_deref(),
        Some("guest_u:object_r:etc_t:s0:c42")
    );
}
fn repeated_request_response() {
    let _guard = subscribe();
    let server = ServerConfig {
        transport: Arc::new(TransportConfig {
            max_concurrent_bidi_streams: 1u32.into(),
            ..TransportConfig::default()
        }),
        ..server_config()
    };
    let mut pair = Pair::new(Default::default(), server);
    let (client_ch, server_ch) = pair.connect();
    const REQUEST: &[u8] = b"hello";
    const RESPONSE: &[u8] = b"world";
    for _ in 0..3 {
        let s = pair.client_streams(client_ch).open(Dir::Bi).unwrap();

        pair.client_send(client_ch, s).write(REQUEST).unwrap();
        pair.client_send(client_ch, s).finish().unwrap();

        pair.drive();

        assert_eq!(pair.server_streams(server_ch).accept(Dir::Bi), Some(s));
        let mut recv = pair.server_recv(server_ch, s);
        let mut chunks = recv.read(false).unwrap();
        assert_matches!(
            chunks.next(usize::MAX),
            Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == REQUEST
        );

        assert_matches!(chunks.next(usize::MAX), Ok(None));
        let _ = chunks.finalize();
        pair.server_send(server_ch, s).write(RESPONSE).unwrap();
        pair.server_send(server_ch, s).finish().unwrap();

        pair.drive();

        let mut recv = pair.client_recv(client_ch, s);
        let mut chunks = recv.read(false).unwrap();
        assert_matches!(
            chunks.next(usize::MAX),
            Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == RESPONSE
        );
        assert_matches!(chunks.next(usize::MAX), Ok(None));
        let _ = chunks.finalize();
    }
}
fn remove_entry_multi_3_others() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());
    headers.insert(VARY, "*".parse().unwrap());

    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 3);
    assert_eq!(headers.len(), 3);

    let vias = remove_all_values(&mut headers, VIA);
    assert_eq!(vias.len(), 2);
    assert_eq!(headers.len(), 1);

    let varies = remove_all_values(&mut headers, VARY);
    assert_eq!(varies.len(), 1);
    assert_eq!(headers.len(), 0);
}
fn parse_alter_table_add_columns() {
    match pg().verified_stmt("ALTER TABLE IF EXISTS ONLY tab ADD COLUMN a TEXT, ADD COLUMN b INT") {
        Statement::AlterTable {
            name,
            if_exists,
            only,
            operations,
        } => {
            assert_eq!(name.to_string(), "tab");
            assert!(if_exists);
            assert!(only);
            assert_eq!(
                operations,
                vec![
                    AlterTableOperation::AddColumn {
                        column_keyword: true,
                        if_not_exists: false,
                        column_def: ColumnDef {
                            name: "a".into(),
                            data_type: DataType::Text,
                            collation: None,
                            options: vec![],
                        },
                    },
                    AlterTableOperation::AddColumn {
                        column_keyword: true,
                        if_not_exists: false,
                        column_def: ColumnDef {
                            name: "b".into(),
                            data_type: DataType::Int(None),
                            collation: None,
                            options: vec![],
                        },
                    },
                ]
            );
        }
        _ => unreachable!(),
    }
}
fn read_isolation() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());

    let write_txn = db.begin_write().unwrap();
    {
        let mut write_table = write_txn.open_table(STR_TABLE).unwrap();
        write_table.remove("hello").unwrap();
        write_table.insert("hello2", "world2").unwrap();
        write_table.insert("hello3", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn2 = db.begin_read().unwrap();
    let table2 = read_txn2.open_table(STR_TABLE).unwrap();
    assert!(table2.get("hello").unwrap().is_none());
    assert_eq!("world2", table2.get("hello2").unwrap().unwrap().value());
    assert_eq!("world3", table2.get("hello3").unwrap().unwrap().value());
    assert_eq!(table2.len().unwrap(), 2);

    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    assert!(table.get("hello2").unwrap().is_none());
    assert!(table.get("hello3").unwrap().is_none());
    assert_eq!(table.len().unwrap(), 1);
}
fn compute_float_f32_test() {
    // These test near-halfway cases for single-precision floats.
    assert_eq!(compute_float32(0, 16777216), (151, 0));
    assert_eq!(compute_float32(0, 16777217), (111 + f32::INVALID_FP, 9223372586610589696));
    assert_eq!(compute_float32(0, 16777218), (151, 1));
    assert_eq!(compute_float32(0, 16777219), (111 + f32::INVALID_FP, 9223373686122217472));
    assert_eq!(compute_float32(0, 16777220), (151, 2));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float32(-10, 167772160000000000), (151, 0));
    assert_eq!(
        compute_float32(-10, 167772170000000000),
        (111 + f32::INVALID_FP, 9223372586610589696)
    );
    assert_eq!(compute_float32(-10, 167772180000000000), (151, 1));
    // Let's check the lines to see if anything is different in table...
    assert_eq!(
        compute_float32(-10, 167772190000000000),
        (111 + f32::INVALID_FP, 9223373686122217472)
    );
    assert_eq!(compute_float32(-10, 167772200000000000), (151, 2));
}
fn test_cp_sparse_never_empty() {
    let (at, mut ucmd) = at_and_ucmd!();

    const BUFFER_SIZE: usize = 4096 * 4;
    let buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];

    at.make_file("src_file1");
    at.write_bytes("src_file1", &buf);

    ucmd.args(&["--sparse=never", "src_file1", "dst_file_non_sparse"])
        .succeeds();
    assert_eq!(at.read_bytes("dst_file_non_sparse"), buf);
    assert_eq!(
        at.metadata("dst_file_non_sparse").blocks() * 512,
        buf.len() as u64
    );
}
fn range_lifetime() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: MultimapTableDefinition<&str, &str> = MultimapTableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(definition).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(definition).unwrap();

    let mut iter = {
        let start = "hello".to_string();
        table.range::<&str>(start.as_str()..).unwrap()
    };
    assert_eq!(
        iter.next()
            .unwrap()
            .unwrap()
            .1
            .next()
            .unwrap()
            .unwrap()
            .value(),
        "world"
    );
    assert!(iter.next().is_none());
}
fn test_split_lines_short_concatenated_with_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_num_prefixed_chunks_by_lines";
    RandomFile::new(&at, name).add_lines(10000);
    ucmd.args(&["-l1000", name]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 10);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn stop_opens_bidi() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    assert_eq!(pair.client_streams(client_ch).send_streams(), 0);
    let s = pair.client_streams(client_ch).open(Dir::Bi).unwrap();
    assert_eq!(pair.client_streams(client_ch).send_streams(), 1);
    const ERROR: VarInt = VarInt(42);
    pair.client
        .connections
        .get_mut(&server_ch)
        .unwrap()
        .recv_stream(s)
        .stop(ERROR)
        .unwrap();
    pair.drive();

    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Bi }))
    );
    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 0);
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Bi), Some(stream) if stream == s);
    assert_eq!(pair.server_conn_mut(client_ch).streams().send_streams(), 1);

    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(chunks.next(usize::MAX), Err(ReadError::Blocked));
    let _ = chunks.finalize();

    assert_matches!(
        pair.server_send(server_ch, s).write(b"foo"),
        Err(WriteError::Stopped(ERROR))
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Stopped {
            id: _,
            error_code: ERROR
        }))
    );
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
}
fn u8_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0u8.to_lexical(&mut buffer));
    assert_eq!(b"1", 1u8.to_lexical(&mut buffer));
    assert_eq!(b"5", 5u8.to_lexical(&mut buffer));
    assert_eq!(b"127", 127u8.to_lexical(&mut buffer));
    assert_eq!(b"128", 128u8.to_lexical(&mut buffer));
    assert_eq!(b"255", 255u8.to_lexical(&mut buffer));
    assert_eq!(b"255", (-1i8 as u8).to_lexical(&mut buffer));
}
fn test_append() {
    let catalog = Catalog::new();
    let (client, origin) = create_sig0_ready_client(catalog);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = client
        .append(record.clone(), origin.clone(), true)
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NXRRSet);

    // next append to a non-existent RRset
    let result = client
        .append(record.clone(), origin.clone(), false)
        .expect("append failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert_eq!(result.answers()[0], record);

    // will fail if already set and not the same value.
    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));

    let result = client
        .append(record.clone(), origin.clone(), true)
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);

    assert!(result
        .answers()
        .iter()
        .any(|rr| if let RData::A(ip) = *rr.data().unwrap() {
            ip == A::new(100, 10, 100, 10)
        } else {
            false
        }));
    assert!(result
        .answers()
        .iter()
        .any(|rr| if let RData::A(ip) = rr.data().unwrap() {
            *ip == A::new(101, 11, 101, 11)
        } else {
            false
        }));

    // show that appending the same thing again is ok, but doesn't add any records
    let result = client
        .append(record.clone(), origin, true)
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 2);
}
fn encoded_len_padded() {
    assert_eq!(0, encoded_len(0, true).unwrap());
    assert_eq!(4, encoded_len(1, true).unwrap());
    assert_eq!(4, encoded_len(2, true).unwrap());
    assert_eq!(4, encoded_len(3, true).unwrap());
    assert_eq!(8, encoded_len(4, true).unwrap());
    assert_eq!(8, encoded_len(5, true).unwrap());
    assert_eq!(8, encoded_len(6, true).unwrap());
    assert_eq!(12, encoded_len(7, true).unwrap());
}
fn i16_decimal_test() {
    assert_eq!(Ok(0), i16::from_lexical(b"0"));
    assert_eq!(Ok(32767), i16::from_lexical(b"32767"));
    assert_eq!(Err(Error::Overflow(4)), i16::from_lexical(b"32768"));
    assert_eq!(Err(Error::Overflow(4)), i16::from_lexical(b"65535"));
    assert_eq!(Ok(-1), i16::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), i16::from_lexical(b"1a"));
}
async fn send_recv_data() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        .write(&[
            // POST /
            0, 0, 16, 1, 4, 0, 0, 0, 1, 131, 135, 65, 139, 157, 41, 172, 75, 143, 168, 233, 25, 151,
            33, 233, 132,
        ])
        .write(&[
            // DATA
            0, 0, 5, 0, 1, 0, 0, 0, 1, 104, 101, 108, 108, 111,
        ])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[
            // HEADERS
            0, 0, 1, 1, 4, 0, 0, 0, 1, 136, // DATA
            0, 0, 5, 0, 1, 0, 0, 0, 1, 119, 111, 114, 108, 100,
        ])
        .build();

    let (mut client, mut h2) = client::Builder::new().handshake(mock).await.unwrap();

    let request = Request::builder()
        .method(Method::POST)
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, mut stream) = client.send_request(request, false).unwrap();

    // Reserve send capacity
    stream.reserve_capacity(5);

    assert_eq!(stream.capacity(), 5);

    // Send the data
    stream.send_data("hello".as_bytes(), true).unwrap();

    // Get the response
    let resp = h2.run(response).await.unwrap();
    assert_eq!(resp.status(), StatusCode::OK);

    // Take the body
    let (_, body) = resp.into_parts();

    // Wait for all the data frames to be received
    let bytes: Vec<_> = h2.run(body.try_collect()).await.unwrap();

    // One byte chunk
    assert_eq!(1, bytes.len());

    assert_eq!(bytes[0], &b"world"[..]);

    // The H2 connection is closed
    h2.await.unwrap();
}
fn fill_funcref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::FuncRef, 10, None);
    let table = Table::new(&mut store, table_ty, Val::FuncRef(None))?;

    for i in 0..10 {
        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_none());
    }

    let fill = Val::FuncRef(Some(Func::wrap(&mut store, || {})));
    table.fill(&mut store, 2, fill, 4)?;

    for i in (0..2).chain(7..10) {
        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_none());
    }
    for i in 2..6 {
        assert!(table.get(&mut store, i).unwrap().unwrap_funcref().is_some());
    }

    Ok(())
}
fn test_touch_default() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_default_file";

    ucmd.arg(file).succeeds().no_stderr();

    assert!(at.file_exists(file));
}
fn test_mktemp_tmpdir_one_arg() {
    let scene = TestScenario::new(util_name!());

    let result = scene
        .ucmd()
        .arg("--tmpdir")
        .arg("apt-key-gpghome.XXXXXXXXXX")
        .succeeds();
    result.no_stderr().stdout_contains("apt-key-gpghome.");
    assert!(PathBuf::from(result.stdout_str().trim()).is_file());
}
fn parse_in_list() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE segment {}IN ('HIGH', 'MED')",
            if negated { "NOT " } else { "" }
        );
        let select = verified_only_select(sql);
        assert_eq!(
            Expr::InList {
                expr: Box::new(Expr::Identifier(Ident::new("segment"))),
                list: vec![
                    Expr::Value(Value::SingleQuotedString("HIGH".to_string())),
                    Expr::Value(Value::SingleQuotedString("MED".to_string())),
                ],
                negated,
            },
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_serialize_nested_enum() {
    #[derive(Serialize, Debug)]
    enum Outer {
        Inner(Inner),
    }
    #[derive(Serialize, Debug)]
    enum Inner {
        Newtype(usize),
        Tuple(usize, usize),
        Struct { x: usize },
    }

    let expected = "serializing nested enums in YAML is not supported yet";

    let e = Outer::Inner(Inner::Newtype(0));
    let error = serde_yaml::to_string(&e).unwrap_err();
    assert_eq!(error.to_string(), expected);

    let e = Outer::Inner(Inner::Tuple(0, 0));
    let error = serde_yaml::to_string(&e).unwrap_err();
    assert_eq!(error.to_string(), expected);

    let e = Outer::Inner(Inner::Struct { x: 0 });
    let error = serde_yaml::to_string(&e).unwrap_err();
    assert_eq!(error.to_string(), expected);

    let e = Value::Tagged(Box::new(TaggedValue {
        tag: Tag::new("Outer"),
        value: Value::Tagged(Box::new(TaggedValue {
            tag: Tag::new("Inner"),
            value: Value::Null,
        })),
    }));
    let error = serde_yaml::to_string(&e).unwrap_err();
    assert_eq!(error.to_string(), expected);
}
fn test_nodata_where_name_exists() {
    named_test_harness("example.toml", |_, tcp_port, _, _, _| {
        let io_loop = Runtime::new().unwrap();
        let addr: SocketAddr = SocketAddr::new(
            Ipv4Addr::new(127, 0, 0, 1).into(),
            tcp_port.expect("no tcp_port"),
        );
        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);
        let client = AsyncClient::new(Box::new(stream), sender, None);
        let (mut client, bg) = io_loop.block_on(client).expect("client failed to connect");
        hickory_proto::spawn_bg(&io_loop, bg);

        let msg = io_loop
            .block_on(client.query(
                Name::from_str("www.example.com.").unwrap(),
                DNSClass::IN,
                RecordType::SRV,
            ))
            .unwrap();
        assert_eq!(msg.response_code(), ResponseCode::NoError);
        assert!(msg.answers().is_empty());
    })
}
fn search_directory() {
  let tmp = temptree! {
    sub: {
      ".git": {},
    },
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--init")
    .arg("sub/")
    .output()
    .unwrap();

  assert!(output.status.success());

  assert_eq!(
    fs::read_to_string(tmp.path().join("sub/justfile")).unwrap(),
    EXPECTED
  );
}
fn roundtrip() {
    let value = Struct {
        tuple: ((), NewType(0.5), TupleStruct(UnitStruct, -5)),
        vec: vec![None, Some(UnitStruct)],
        map: vec![
            (Key(5), Enum::Unit),
            (Key(6), Enum::Bool(false)),
            (Key(7), Enum::Bool(true)),
            (Key(9), Enum::Chars('x', "".to_string())),
        ]
        .into_iter()
        .collect(),
    };

    let serial = ron::ser::to_string(&value).unwrap();

    println!("Serialized: {}", serial);

    let deserial = ron::de::from_str(&serial);

    assert_eq!(Ok(value), deserial);
}
fn test_write_empty_element_attrs() -> Result<()> {
    let str_from = r#"<source attr="val"/>"#;
    let expected = r#"<source attr="val"/>"#;
    let mut reader = Reader::from_str(str_from);
    let mut writer = Writer::new(Cursor::new(Vec::new()));
    loop {
        match reader.read_event()? {
            Eof => break,
            e => assert!(writer.write_event(e).is_ok()),
        }
    }

    let result = writer.into_inner().into_inner();
    assert_eq!(String::from_utf8(result).unwrap(), expected);
    Ok(())
}
fn test_default_block_size_in_posix_portability_mode() {
    fn get_header(s: &str) -> String {
        s.lines()
            .next()
            .unwrap()
            .to_string()
            .split_whitespace()
            .nth(1)
            .unwrap()
            .trim()
            .to_string()
    }

    let output = new_ucmd!().arg("-P").succeeds().stdout_move_str();
    assert_eq!(get_header(&output), "1024-blocks");

    let output = new_ucmd!()
        .arg("-P")
        .env("POSIXLY_CORRECT", "1")
        .succeeds()
        .stdout_move_str();
    assert_eq!(get_header(&output), "512-blocks");
}
fn test_context_merge_custom() {
    struct X;
    impl StructObject for X {
        fn get_field(&self, name: &str) -> Option<Value> {
            match name {
                "a" => Some(Value::from(1)),
                "b" => Some(Value::from(2)),
                _ => None,
            }
        }
    }

    let x = Value::from_struct_object(X);
    let ctx = context! { a => 42, ..x };

    assert_eq!(ctx.get_attr("a").unwrap(), Value::from(42));
    assert_eq!(ctx.get_attr("b").unwrap(), Value::from(2));
}
fn fill_wrong() {
    let mut store = Store::<()>::default();
    let ty = TableType::new(ValType::FuncRef, 1, None);
    let table = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();
    assert_eq!(
        table
            .fill(&mut store, 0, Val::ExternRef(None), 1)
            .map_err(|e| e.to_string())
            .unwrap_err(),
        "value does not match table element type"
    );

    let ty = TableType::new(ValType::ExternRef, 1, None);
    let table = Table::new(&mut store, ty, Val::ExternRef(None)).unwrap();
    assert_eq!(
        table
            .fill(&mut store, 0, Val::FuncRef(None), 1)
            .map_err(|e| e.to_string())
            .unwrap_err(),
        "value does not match table element type"
    );
}
fn test_stale_read_future_ts_not_update_max_ts() {
    let (_cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));
    leader_client.ctx.set_stale_read(true);

    // Write `(key1, value1)`
    leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );

    // Perform stale read with a future ts should return error
    let read_ts = get_tso(&pd_client) + 10000000;
    let resp = leader_client.kv_read(b"key1".to_vec(), read_ts);
    assert!(resp.get_region_error().has_data_is_not_ready());

    // The `max_ts` should not updated by the stale read request, so we can prewrite
    // and commit `async_commit` transaction with a ts that smaller than the
    // `read_ts`
    let prewrite_ts = get_tso(&pd_client);
    assert!(prewrite_ts < read_ts);
    leader_client.must_kv_prewrite_async_commit(
        vec![new_mutation(Op::Put, &b"key2"[..], &b"value1"[..])],
        b"key2".to_vec(),
        prewrite_ts,
    );
    let commit_ts = get_tso(&pd_client);
    assert!(commit_ts < read_ts);
    leader_client.must_kv_commit(vec![b"key2".to_vec()], prewrite_ts, commit_ts);
    leader_client.must_kv_read_equal(b"key2".to_vec(), b"value1".to_vec(), get_tso(&pd_client));

    // Perform stale read with a future ts should return error
    let read_ts = get_tso(&pd_client) + 10000000;
    let resp = leader_client.kv_read(b"key1".to_vec(), read_ts);
    assert!(resp.get_region_error().has_data_is_not_ready());

    // The `max_ts` should not updated by the stale read request, so 1pc transaction
    // with a ts that smaller than the `read_ts` should not be fallbacked to 2pc
    let prewrite_ts = get_tso(&pd_client);
    assert!(prewrite_ts < read_ts);
    leader_client.must_kv_prewrite_one_pc(
        vec![new_mutation(Op::Put, &b"key3"[..], &b"value1"[..])],
        b"key3".to_vec(),
        prewrite_ts,
    );
    // `key3` is write as 1pc transaction so we can read `key3` without commit
    leader_client.must_kv_read_equal(b"key3".to_vec(), b"value1".to_vec(), get_tso(&pd_client));
}
fn test_copy_into_copy_options() {
    let sql = concat!(
        "COPY INTO my_company.emp_basic ",
        "FROM 'gcs://mybucket/./../a.csv' ",
        "FILES = ('file1.json', 'file2.json') ",
        "PATTERN = '.*employees0[1-5].csv.gz' ",
        "COPY_OPTIONS=(ON_ERROR=CONTINUE FORCE=TRUE)"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake { copy_options, .. } => {
            assert!(copy_options.options.contains(&DataLoadingOption {
                option_name: "ON_ERROR".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "CONTINUE".to_string()
            }));
            assert!(copy_options.options.contains(&DataLoadingOption {
                option_name: "FORCE".to_string(),
                option_type: DataLoadingOptionType::BOOLEAN,
                value: "TRUE".to_string()
            }));
        }
        _ => unreachable!(),
    };
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn config_builder_for_server_rejects_empty_kx_groups() {
    assert_eq!(
        ServerConfig::builder()
            .with_safe_default_cipher_suites()
            .with_kx_groups(&[])
            .with_safe_default_protocol_versions()
            .err(),
        Some(Error::General("no kx groups configured".into()))
    );
}
fn scalar_mul_test() {
    assert_eq!(bigint::scalar_mul(5, 5, 0), (25, 0));
    assert_eq!(bigint::scalar_mul(5, 5, 1), (26, 0));
    assert_eq!(bigint::scalar_mul(LIMB_MAX, 2, 0), (LIMB_MAX - 1, 1));
}
fn test_gc_removed_peer() {
    let mut cluster = test_raftstore::new_node_cluster(1, 2);
    cluster.cfg.raft_store.enable_v2_compatible_learner = true;
    cluster.pd_client.disable_default_operator();
    let region_id = cluster.run_conf_change();

    let (tx, rx) = channel();
    let tx = Mutex::new(tx);
    let factory = ForwardFactory {
        node_id: 1,
        chain_send: Arc::new(move |m| {
            if m.get_extra_msg().get_type() == ExtraMessageType::MsgGcPeerResponse {
                let _ = tx.lock().unwrap().send(m);
            }
        }),
        keep_msg: true,
    };
    cluster.add_send_filter(factory);

    let check_gc_peer = |to_peer: kvproto::metapb::Peer, timeout| -> bool {
        let epoch = cluster.get_region_epoch(region_id);
        let mut msg = RaftMessage::default();
        msg.set_is_tombstone(true);
        msg.set_region_id(region_id);
        msg.set_from_peer(new_peer(1, 1));
        msg.set_to_peer(to_peer.clone());
        msg.set_region_epoch(epoch.clone());
        let extra_msg = msg.mut_extra_msg();
        extra_msg.set_type(ExtraMessageType::MsgGcPeerRequest);
        let check_peer = extra_msg.mut_check_gc_peer();
        check_peer.set_from_region_id(region_id);
        check_peer.set_check_region_id(region_id);
        check_peer.set_check_peer(to_peer.clone());
        check_peer.set_check_region_epoch(epoch);

        cluster.sim.wl().send_raft_msg(msg.clone()).unwrap();
        let Ok(gc_resp) = rx.recv_timeout(timeout) else {
            return false;
        };
        assert_eq!(gc_resp.get_region_id(), region_id);
        assert_eq!(*gc_resp.get_from_peer(), to_peer);
        true
    };

    // Mock gc a peer that has been removed before creation.
    assert!(check_gc_peer(
        new_learner_peer(2, 5),
        Duration::from_secs(5)
    ));

    cluster
        .pd_client
        .must_add_peer(region_id, new_learner_peer(2, 4));
    // Make sure learner is created.
    cluster.wait_peer_state(region_id, 2, PeerState::Normal);

    cluster
        .pd_client
        .must_remove_peer(region_id, new_learner_peer(2, 4));
    // Make sure learner is removed.
    cluster.wait_peer_state(region_id, 2, PeerState::Tombstone);

    // Mock gc peer request. GC learner(2, 4).
    let start = Instant::now();
    loop {
        if check_gc_peer(new_learner_peer(2, 4), Duration::from_millis(200)) {
            return;
        }
        if start.saturating_elapsed() > Duration::from_secs(5) {
            break;
        }
    }
    assert!(check_gc_peer(
        new_learner_peer(2, 4),
        Duration::from_millis(200)
    ));
}
fn nth_bit_test() {
    assert_eq!(mask::nth_bit(2), 0b100);
}
fn does_include_file_with_different_overrides() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
    "overrides": [
        {
            "include": [
                "test.js"
            ],
            "linter": {
                "rules": {
                    "suspicious": {
                        "noDebugger": "off"
                    }
                }
            }
        },
        {
            "include": [
                "test2.js"
            ],
            "linter": {
                "rules": {
                    "complexity": {
                        "useSimpleNumberKeys": "error"
                    }
                }
            }
        }
    ]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), DEBUGGER_BEFORE.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), SIMPLE_NUMBERS_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test, DEBUGGER_BEFORE);
    assert_file_contents(&fs, test2, SIMPLE_NUMBERS_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_overrides",
        fs,
        console,
        result,
    ));
}
fn batch_in_same_output_with_non_default_postage() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet inscribe --fee-rate 1 --batch batch.yaml --postage 777sat")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      "mode: shared-output\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n"
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  let outpoint = output.inscriptions[0].location.outpoint;
  for (i, inscription) in output.inscriptions.iter().enumerate() {
    assert_eq!(
      inscription.location,
      SatPoint {
        outpoint,
        offset: u64::try_from(i).unwrap() * 777,
      }
    );
  }

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  let outpoint = output.inscriptions[0].location.outpoint;

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[1].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:777</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[2].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:1554</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/output/{}", output.inscriptions[0].location.outpoint),
    format!(r".*<a href=/inscription/{}>.*</a>.*<a href=/inscription/{}>.*</a>.*<a href=/inscription/{}>.*</a>.*", output.inscriptions[0].id, output.inscriptions[1].id, output.inscriptions[2].id),
  );
}
fn packet_loss_and_retry_too_low_mtu() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();

    pair.client_send(client_ch, s).write(b"hello").unwrap();
    pair.drive();

    // Nothing will get past this mtu
    pair.mtu = 10;
    pair.client_send(client_ch, s).write(b" world").unwrap();
    pair.drive_client();

    // The packet was dropped
    assert!(pair.client.outbound.is_empty());
    assert!(pair.server.inbound.is_empty());

    // Restore the default mtu, so future packets are properly transmitted
    pair.mtu = DEFAULT_MTU;

    // The lost packet is resent
    pair.drive();
    assert!(pair.client.outbound.is_empty());

    let recv = pair.server_recv(server_ch, s);
    let buf = stream_chunks(recv);

    assert_eq!(buf, b"hello world".as_slice());
}
fn test_dec() {
    assert_eq!(from_str("1461"), Ok(1461));
    assert_eq!(from_str("51"), Ok(51));
    assert_eq!(from_str("150700"), Ok(150700));

    assert_eq!(
        from_str::<i8>("-_1"),
        Err(SpannedError {
            code: Error::UnderscoreAtBeginning,
            position: Position { line: 1, col: 2 },
        })
    );
    assert_eq!(
        from_str::<u8>("256"),
        Err(SpannedError {
            code: Error::IntegerOutOfBounds,
            position: Position { line: 1, col: 4 },
        })
    );
}
fn extensions() {
    let f = super::fixture().join("extensions");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".ts".into(), ".js".into()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("should resolve according to order of provided extensions", "./foo", "foo.ts"),
        ("should resolve according to order of provided extensions (dir index)", "./dir", "dir/index.ts"),
        ("should resolve according to main field in module root", ".", "index.js"),
        // This is a core module
        // ("should resolve single file module before directory", "module", "node_modules/module.js"),
        ("should resolve trailing slash directory before single file", "module/", "node_modules/module/index.ts"),
    ];

    for (comment, request, expected_path) in pass {
        let resolved_path = resolver.resolve(&f, request).map(|r| r.full_path());
        let expected = f.join(expected_path);
        assert_eq!(resolved_path, Ok(expected), "{comment} {request} {expected_path}");
    }

    #[rustfmt::skip]
    let fail = [
        ("not resolve to file when request has a trailing slash (relative)", "./foo.js/", f.join("foo.js"))
    ];

    for (comment, request, expected_error) in fail {
        let resolution = resolver.resolve(&f, request);
        let error = ResolveError::NotFound(expected_error);
        assert_eq!(resolution, Err(error), "{comment} {request} {resolution:?}");
    }
}
fn test_chmod_file_symlink_after_non_existing_file() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let existing = "file";
    let test_existing_symlink = "file_symlink";

    let non_existing = "test_chmod_symlink_non_existing_file";
    let test_dangling_symlink = "test_chmod_symlink_non_existing_file_symlink";
    let expected_stdout = &format!(
        "failed to change mode of '{test_dangling_symlink}' from 0000 (---------) to 1500 (r-x-----T)"
    );
    let expected_stderr = &format!("cannot operate on dangling symlink '{test_dangling_symlink}'");

    at.touch(existing);
    set_permissions(at.plus(existing), Permissions::from_mode(0o664)).unwrap();
    at.symlink_file(non_existing, test_dangling_symlink);
    at.symlink_file(existing, test_existing_symlink);

    // this cannot succeed since the symbolic link dangles
    // but the metadata for the existing target should change
    scene
        .ucmd()
        .arg("u+x")
        .arg("-v")
        .arg(test_dangling_symlink)
        .arg(test_existing_symlink)
        .fails()
        .code_is(1)
        .stdout_contains(expected_stdout)
        .stderr_contains(expected_stderr);
    assert_eq!(
        at.metadata(test_existing_symlink).permissions().mode(),
        0o100_764
    );
}
fn remove_entry_3_others_b() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());
    headers.insert(VARY, "*".parse().unwrap());

    assert_eq!(headers.len(), 6);

    let vary = remove_values(&mut headers, VARY);
    assert_eq!(vary, Some("*".parse().unwrap()));
    assert_eq!(headers.len(), 5);

    let via = remove_values(&mut headers, VIA);
    assert_eq!(via, Some("1.1 example.com".parse().unwrap()));
    assert_eq!(headers.len(), 3);

    let cookie = remove_values(&mut headers, SET_COOKIE);
    assert_eq!(cookie, Some("cookie_1=value 1".parse().unwrap()));
    assert_eq!(headers.len(), 0);
}
fn use_name_section() {
    let data = wat::parse_str(
        r#"
        (module $module_name
            (func $func_name (local $loc_name i32)
            )
        )"#,
    )
    .unwrap();

    let mut dummy_environ = DummyEnvironment::new(TargetFrontendConfig {
        default_call_conv: CallConv::SystemV,
        pointer_width: PointerWidth::U32,
    });

    translate_module(data.as_ref(), &mut dummy_environ).unwrap();

    assert_eq!(
        dummy_environ.get_func_name(FuncIndex::from_u32(0)).unwrap(),
        "func_name"
    );
}
fn test_cp_arg_update_short_overwrite() {
    // same as --update=older
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_cp_arg_update_short_overwrite_file1";
    let new = "test_cp_arg_update_short_overwrite_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(new)
        .arg(old)
        .arg("-u")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(old), "new content\n");
}
fn prefer_relative() {
    let f = super::fixture();

    let resolver =
        Resolver::new(ResolveOptions { prefer_relative: true, ..ResolveOptions::default() });

    #[rustfmt::skip]
    let pass = [
        ("should correctly resolve with preferRelative 1", "main1.js", f.join("main1.js")),
        ("should correctly resolve with preferRelative 2", "m1/a.js", f.join("node_modules/m1/a.js")),
    ];

    for (comment, request, expected) in pass {
        let resolved_path = resolver.resolve(&f, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {request}");
    }
}
fn test_filter_basics() {
    fn test(a: u32, b: u32) -> Result<u32, Error> {
        Ok(a + b)
    }

    let mut env = Environment::new();
    env.add_filter("test", test);
    assert_eq!(
        env.empty_state()
            .apply_filter("test", args!(23, 42))
            .unwrap(),
        Value::from(65)
    );
}
fn test_snapshot_failed() {
    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    fail::cfg("rockskv_async_snapshot", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_other_error().contains("snapshot failed"));
}
fn parse_create_view_temporary_if_not_exists() {
    let sql = "CREATE TEMPORARY VIEW IF NOT EXISTS myschema.myview AS SELECT foo FROM bar";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::CreateView {
            name,
            columns,
            query,
            or_replace,
            materialized,
            with_options,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("myschema.myview", name.to_string());
            assert_eq!(Vec::<Ident>::new(), columns);
            assert_eq!("SELECT foo FROM bar", query.to_string());
            assert!(!materialized);
            assert!(!or_replace);
            assert_eq!(with_options, vec![]);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(if_not_exists);
            assert!(temporary);
        }
        _ => unreachable!(),
    }
}
fn test_decrease_pool() {
    let mut cluster = new_node_cluster(0, 1);
    cluster.pd_client.disable_default_operator();
    cluster.cfg.raft_store.store_batch_system.pool_size = 2;
    cluster.cfg.raft_store.apply_batch_system.pool_size = 2;
    let _ = cluster.run_conf_change();

    // Save current poller tids before shrinking
    let original_poller_tids = get_poller_thread_ids();

    // Request can be handled as usual
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");

    {
        let sim = cluster.sim.rl();
        let cfg_controller = sim.get_cfg_controller().unwrap();
        let change = {
            let mut change = HashMap::new();
            change.insert("raftstore.store_pool_size".to_owned(), "1".to_owned());
            change.insert("raftstore.apply-pool-size".to_owned(), "1".to_owned());
            change
        };

        // Update config, shrink from 2 to 1
        cfg_controller.update(change).unwrap();
        std::thread::sleep(std::time::Duration::from_secs(1));

        assert_eq!(
            cfg_controller
                .get_current()
                .raft_store
                .apply_batch_system
                .pool_size,
            1
        );
        assert_eq!(
            cfg_controller
                .get_current()
                .raft_store
                .store_batch_system
                .pool_size,
            1
        );
    }

    // Save current poller tids after scaling down
    let current_poller_tids = get_poller_thread_ids();
    // Compared with before shrinking, the thread num should be reduced by two
    assert_eq!(current_poller_tids.len(), original_poller_tids.len() - 2);
    // After shrinking, all the left tids must be there before
    for tid in current_poller_tids {
        assert!(original_poller_tids.contains(&tid));
    }

    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
}
fn test_install_backup_none() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=none")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(!at.file_exists(format!("{file_b}~")));
}
fn test_hibernate_feature_gate() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.pd_client.reset_version("4.0.0");
    configure_for_hibernate(&mut cluster.cfg);
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");

    // Wait for hibernation check.
    thread::sleep(
        cluster.cfg.raft_store.raft_base_tick_interval.0
            * 3
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,
    );

    // Ensure leader won't sleep if cluster version is small.
    let awakened = Arc::new(AtomicBool::new(false));
    let filter = Arc::new(AtomicBool::new(true));
    let a = awakened.clone();
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 1)
            .direction(Direction::Send)
            .set_msg_callback(Arc::new(move |_| {
                a.store(true, Ordering::SeqCst);
            }))
            .when(filter.clone()),
    ));
    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);
    assert!(awakened.load(Ordering::SeqCst));

    // Simulating all binaries are upgraded to 5.0.0.
    cluster.pd_client.reset_version("5.0.0");
    filter.store(false, Ordering::SeqCst);
    // Wait till leader peer goes to sleep.
    thread::sleep(
        cluster.cfg.raft_store.raft_base_tick_interval.0
            * 3
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32,
    );
    awakened.store(false, Ordering::SeqCst);
    filter.store(true, Ordering::SeqCst);
    thread::sleep(cluster.cfg.raft_store.raft_heartbeat_interval() * 2);
    // Leader can go to sleep as version requirement is met.
    assert!(!awakened.load(Ordering::SeqCst));
}
fn test_mv_move_file_into_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_mv_move_file_into_dir_dir";
    let file = "test_mv_move_file_into_dir_file";

    at.mkdir(dir);
    at.touch(file);

    ucmd.arg(file).arg(dir).succeeds().no_stderr();

    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn test_attribute_equal() {
    let src = "<a att1=\"a=b\"/>";
    let mut r = Reader::from_str(src);
    r.trim_text(true);
    match r.read_event() {
        Ok(Empty(e)) => {
            let mut attrs = e.attributes();
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"att1"),
                    value: Cow::Borrowed(b"a=b"),
                }))
            );
            assert_eq!(attrs.next(), None);
        }
        e => panic!("Expecting Empty event, got {:?}", e),
    }
}
fn to_f32_test() {
    // underflow
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -213,
    };
    assert_eq!(x.into_float::<f32>(), 0.0);

    // min value
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -212,
    };
    assert_eq!(x.into_float::<f32>(), 1e-45);

    // 1.0e-40
    let x = ExtendedFloat {
        mant: 10043308644012916736,
        exp: -196,
    };
    assert_eq!(x.into_float::<f32>(), 1e-40);

    // 1.0e-20
    let x = ExtendedFloat {
        mant: 13611294244890214400,
        exp: -130,
    };
    assert_eq!(x.into_float::<f32>(), 1e-20);

    // 1.0
    let x = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -63,
    };
    assert_eq!(x.into_float::<f32>(), 1.0);

    // 1e20
    let x = ExtendedFloat {
        mant: 12500000250510966784,
        exp: 3,
    };
    assert_eq!(x.into_float::<f32>(), 1e20);

    // max value
    let x = ExtendedFloat {
        mant: 18446740775174668288,
        exp: 64,
    };
    assert_eq!(x.into_float::<f32>(), 3.402823e38);

    // almost max, high exp
    let x = ExtendedFloat {
        mant: 1048575,
        exp: 108,
    };
    assert_eq!(x.into_float::<f32>(), 3.4028204e38);

    // max value + 1
    let x = ExtendedFloat {
        mant: 16777216,
        exp: 104,
    };
    assert_eq!(x.into_float::<f32>(), f32::INFINITY);

    // max value + 1
    let x = ExtendedFloat {
        mant: 1048576,
        exp: 108,
    };
    assert_eq!(x.into_float::<f32>(), f32::INFINITY);

    // 1e40
    let x = ExtendedFloat {
        mant: 16940658945086007296,
        exp: 69,
    };
    assert_eq!(x.into_float::<f32>(), f32::INFINITY);

    // Integers.
    for int in &INTEGERS {
        let fp = ExtendedFloat { mant: *int, exp: 0 };
        assert_eq!(fp.into_float::<f32>(), *int as f32, "{:?} as f32", *int);
    }
}
fn error_location_in_parent_in_macro() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 + true }}{% endmacro hello %}"),
        ("parent", "{% import \"macros\" as macros %}{{ macros::hello() }}{% block bob %}{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{ super() }}Hey{% endblock bob %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(
        result.unwrap_err().to_string(),
        "Failed to render \'child\': error while rendering macro `macros::hello` (error happened in \'parent\')."
    );
}
fn exports_not_browser_field2() {
    let f2 = super::fixture().join("exports-field2");

    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        extensions: vec![".js".into()],
        condition_names: vec!["node".into()],
        ..ResolveOptions::default()
    });

    let resolved_path = resolver.resolve(&f2, "exports-field/dist/main.js").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f2.join("node_modules/exports-field/lib/browser.js")));
}
fn test_raw_mvcc_filtered() {
    MVCC_VERSIONS_HISTOGRAM.reset();
    GC_COMPACTION_FILTERED.reset();

    let mut cfg = DbConfig::default();
    cfg.defaultcf.disable_auto_compactions = true;
    cfg.defaultcf.dynamic_level_bytes = false;

    let engine = TestEngineBuilder::new()
        .api_version(ApiVersion::V2)
        .build_with_cfg(&cfg)
        .unwrap();
    let raw_engine = engine.get_rocksdb();
    let mut gc_runner = TestGcRunner::new(0);

    let user_key = b"r\0aaaaaaaaaaa";

    let test_raws = vec![
        (user_key, 100, false),
        (user_key, 90, false),
        (user_key, 70, false),
    ];

    let modifies = test_raws
        .into_iter()
        .map(|(key, ts, is_delete)| {
            (
                make_key(key, ts),
                ApiV2::encode_raw_value(RawValue {
                    user_value: &[0; 10][..],
                    expire_ts: Some(TimeStamp::max().into_inner()),
                    is_delete,
                }),
            )
        })
        .map(|(k, v)| Modify::Put(CF_DEFAULT, Key::from_encoded_slice(k.as_slice()), v))
        .collect();

    let ctx = Context {
        api_version: ApiVersion::V2,
        ..Default::default()
    };
    let batch = WriteData::from_modifies(modifies);

    engine.write(&ctx, batch).unwrap();

    gc_runner.safe_point(80).gc_raw(&raw_engine);

    assert_eq!(
        MVCC_VERSIONS_HISTOGRAM
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get_sample_sum(),
        1_f64
    );
    assert_eq!(
        GC_COMPACTION_FILTERED
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );

    MVCC_VERSIONS_HISTOGRAM.reset();
    GC_COMPACTION_FILTERED.reset();
}
fn infinite_recursion() {
    let f = super::fixture();
    let resolver = Resolver::new(ResolveOptions {
        alias: vec![
            ("./a".into(), vec![AliasValue::Path("./b".into())]),
            ("./b".into(), vec![AliasValue::Path("./a".into())]),
        ],
        ..ResolveOptions::default()
    });
    let resolution = resolver.resolve(f, "./a");
    assert_eq!(resolution, Err(ResolveError::Recursion));
}
fn eph_finalizer() {
    #[derive(Clone, Trace)]
    struct S {
        #[unsafe_ignore_trace]
        inner: Rc<Cell<bool>>,
    }

    impl Finalize for S {
        fn finalize(&self) {
            self.inner.set(true);
        }
    }

    run_test(|| {
        let val = S {
            inner: Rc::new(Cell::new(false)),
        };

        let key = Gc::new(50u32);
        let eph = Ephemeron::new(&key, Gc::new(val.clone()));
        assert!(eph.has_value());
        // finalize hasn't been run
        assert!(!val.inner.get());

        drop(key);
        force_collect();
        assert!(!eph.has_value());
        // finalize ran when collecting
        assert!(val.inner.get());
    });
}
fn parse_mssql_top_percent() {
    let sql = "SELECT TOP (5) PERCENT * FROM foo";
    let select = ms_and_generic().verified_only_select(sql);
    let top = select.top.unwrap();
    assert_eq!(Some(Expr::Value(number("5"))), top.quantity);
    assert!(top.percent);
}
fn parse_like() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = clickhouse().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = clickhouse().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that LIKE and NOT LIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = clickhouse().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_non_existing_files() {
    let scenario = TestScenario::new(util_name!());

    let result = scenario
        .ucmd()
        .args(&["newer_file", "-nt", "regular_file"])
        .fails();
    assert!(result.stderr().is_empty());
}
fn bad_bmps() {
    let path: PathBuf = BASE_PATH
        .iter()
        .collect::<PathBuf>()
        .join(IMAGE_DIR)
        .join("bmp/images")
        .join("*.bad_bmp");

    let pattern = &*format!("{}", path.display());
    for path in glob::glob(pattern).unwrap().filter_map(Result::ok) {
        // Manually reading the file so we can use load() instead of open()
        // We have to use load() so we can override the format
        let im_file = BufReader::new(File::open(path).unwrap());
        let im = image::load(im_file, image::ImageFormat::Bmp);
        assert!(im.is_err());
    }
}
fn client_stateless_reset() {
    let _guard = subscribe();
    let mut reset_key = vec![0; 64];
    let mut rng = rand::thread_rng();
    rng.fill_bytes(&mut reset_key);
    let reset_key = hmac::Key::new(hmac::HMAC_SHA256, &reset_key);

    let endpoint_config = Arc::new(EndpointConfig::new(Arc::new(reset_key)));

    let mut pair = Pair::new(endpoint_config.clone(), server_config());
    let (_, server_ch) = pair.connect();
    pair.client.endpoint = Endpoint::new(endpoint_config, Some(Arc::new(server_config())), true);
    // Send something big enough to allow room for a smaller stateless reset.
    pair.server.connections.get_mut(&server_ch).unwrap().close(
        pair.time,
        VarInt(42),
        (&[0xab; 128][..]).into(),
    );
    info!("resetting");
    pair.drive();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::ConnectionLost {
            reason: ConnectionError::Reset
        })
    );
}
async fn reject_pseudo_protocol_on_non_connect_request() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;

        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));

        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "http://bread/baguette")
                    .protocol("the-bread-protocol"),
            )
            .await;

        client.recv_frame(frames::reset(1).protocol_error()).await;
    };

    let srv = async move {
        let mut builder = server::Builder::new();

        builder.enable_connect_protocol();

        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");

        assert!(srv.next().await.is_none());

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn idents() {
    assert_eq!(
        Ident::new("String", Span::call_site()).to_string(),
        "String"
    );
    assert_eq!(Ident::new("fn", Span::call_site()).to_string(), "fn");
    assert_eq!(Ident::new("_", Span::call_site()).to_string(), "_");
}
fn eph_self_referential_chain() {
    #[derive(Trace, Finalize, Clone)]
    struct TestCell {
        inner: Gc<GcRefCell<Option<Ephemeron<u8, TestCell>>>>,
    }
    run_test(|| {
        let root = Gc::new(GcRefCell::new(None));
        let root_size = std::mem::size_of::<GcBox<GcRefCell<Option<Ephemeron<u8, TestCell>>>>>();

        Harness::assert_exact_bytes_allocated(root_size);

        let watched = Gc::new(0);

        {
            // Generate a self-referential loop of weak and non-weak pointers
            let chain1 = TestCell {
                inner: Gc::new(GcRefCell::new(None)),
            };
            let chain2 = TestCell {
                inner: Gc::new(GcRefCell::new(None)),
            };

            let eph_start = Ephemeron::new(&watched, chain1.clone());
            let eph_chain2 = Ephemeron::new(&watched, chain2.clone());

            *chain1.inner.borrow_mut() = Some(eph_chain2.clone());
            *chain2.inner.borrow_mut() = Some(eph_start.clone());

            *root.borrow_mut() = Some(eph_start.clone());

            force_collect();

            assert!(eph_start.value().is_some());
            assert!(eph_chain2.value().is_some());
            Harness::assert_exact_bytes_allocated(240);
        }

        *root.borrow_mut() = None;

        force_collect();

        drop(watched);

        force_collect();

        Harness::assert_exact_bytes_allocated(root_size);
    });
}
fn test() {
    use crate::packages::gizmo;
    use crate::packages::DoIt;
    use prost::Message;

    let mut widget_factory = widget::factory::WidgetFactory::default();
    assert_eq!(0, widget_factory.encoded_len());

    widget_factory.inner = Some(widget::factory::widget_factory::Inner {});
    assert_eq!(2, widget_factory.encoded_len());

    widget_factory.root = Some(Root {});
    assert_eq!(4, widget_factory.encoded_len());

    widget_factory.root_inner = Some(root::Inner {});
    assert_eq!(6, widget_factory.encoded_len());

    widget_factory.widget = Some(widget::Widget {});
    assert_eq!(8, widget_factory.encoded_len());

    widget_factory.widget_inner = Some(widget::widget::Inner {});
    assert_eq!(10, widget_factory.encoded_len());

    widget_factory.gizmo = Some(gizmo::Gizmo {});
    assert_eq!(12, widget_factory.encoded_len());
    widget_factory.gizmo.as_ref().map(DoIt::do_it);

    widget_factory.gizmo_inner = Some(gizmo::gizmo::Inner {});
    assert_eq!(14, widget_factory.encoded_len());
}
fn test_untagged_enum() {
    // Note: Errors inside untagged enums are not bubbled up

    assert_eq!(
        ron::from_str::<TestEnumUntagged>("(a: true, a: false)"),
        Err(SpannedError {
            code: Error::Message(String::from(
                "data did not match any variant of untagged enum TestEnumUntagged"
            )),
            position: Position { line: 1, col: 20 },
        })
    );
}
fn test_no_leak() {
    let dropped = Arc::new(AtomicBool::new(false));

    struct X(Arc<AtomicBool>);

    impl StructObject for X {
        fn get_field(&self, _name: &str) -> Option<Value> {
            None
        }
    }

    impl Drop for X {
        fn drop(&mut self) {
            self.0.store(true, std::sync::atomic::Ordering::Relaxed);
        }
    }

    let ctx = context! {
        x => Value::from_struct_object(X(dropped.clone())),
    };
    let mut env = Environment::new();
    env.add_template("x", "{% macro meh() %}{{ x }}{{ meh }}{% endmacro %}")
        .unwrap();
    let rv = env
        .render_str(
            r#"
        {%- from 'x' import meh %}
        {{- meh() }}
        {%- set closure = x %}
        {%- macro foo() %}{{ foo }}{{ closure }}{% endmacro %}
        {{- foo() -}}

        {%- for y in range(3) %}
            {%- set closure = x %}
            {%- macro foo() %}{{ foo }}{{ closure }}{% endmacro %}
            {{- foo() -}}
        {%- endfor -%}
    "#,
            ctx,
        )
        .unwrap();

    assert!(dropped.load(std::sync::atomic::Ordering::Relaxed));
    assert_eq!(
        rv,
        "{}<macro meh><macro foo>{}<macro foo>{}<macro foo>{}<macro foo>{}"
    );
}
fn sqrtd_sanity_test() {
    assert_eq!(libm::sqrtd(100.0), 10.0);
    assert_eq!(libm::sqrtd(4.0), 2.0);
}
fn test_something() {
    let data = [];
    let mut set = HashSet::new();
    let mut nat = NatSet::new();
    for action in actions {
        match action {
            Action::Insert(value) => {
                let len = nat.len() + if nat.contains(&value) { 0 } else { 1 };
                nat.insert(value);
                set.insert(value);
                assert_eq!(len, set.len());
            }
            Action::Remove(value) => {
                let len = nat.len() - if nat.contains(&value) { 1 } else { 0 };
                nat.remove(&value);
                set.remove(&value);
                assert_eq!(len, set.len());
            }
        }
        assert_eq!(nat.len(), set.len());
        assert_eq!(HashSet::from(nat.clone()), set);
    }
}
fn test_cleanup_sst() {
    let (mut cluster, ctx, _, import) = new_cluster_and_tikv_import_client();

    let temp_dir = Builder::new().prefix("test_cleanup_sst").tempdir().unwrap();

    let sst_path = temp_dir.path().join("test_split.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());

    send_upload_sst(&import, &meta, &data).unwrap();

    // Can not upload the same file when it exists.
    assert_to_string_contains!(
        send_upload_sst(&import, &meta, &data).unwrap_err(),
        "FileExists"
    );

    // The uploaded SST should be deleted if the region split.
    let region = cluster.get_region(&[]);
    cluster.must_split(&region, &[100]);

    check_sst_deleted(&import, &meta, &data);

    let left = cluster.get_region(&[]);
    let right = cluster.get_region(&[100]);

    let sst_path = temp_dir.path().join("test_merge.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(left.get_id());
    meta.set_region_epoch(left.get_region_epoch().clone());

    send_upload_sst(&import, &meta, &data).unwrap();

    // The uploaded SST should be deleted if the region merged.
    cluster.pd_client.must_merge(left.get_id(), right.get_id());
    let res = block_on(cluster.pd_client.get_region_by_id(left.get_id()));
    assert_eq!(res.unwrap(), None);

    check_sst_deleted(&import, &meta, &data);
}
fn test_block_size_from_env() {
    fn get_header(env_var: &str, env_value: &str) -> String {
        let output = new_ucmd!()
            .arg("--output=size")
            .env(env_var, env_value)
            .succeeds()
            .stdout_move_str();
        output.lines().next().unwrap().trim().to_string()
    }

    assert_eq!(get_header("DF_BLOCK_SIZE", "111"), "111B-blocks");
    assert_eq!(get_header("BLOCK_SIZE", "222"), "222B-blocks");
    assert_eq!(get_header("BLOCKSIZE", "333"), "333B-blocks");
}
fn test_basic() {
    assert_eq!(0.0, s2d(b"0").unwrap());
    assert_eq!(-0.0, s2d(b"-0").unwrap());
    assert_eq!(1.0, s2d(b"1").unwrap());
    assert_eq!(2.0, s2d(b"2").unwrap());
    assert_eq!(123456789.0, s2d(b"123456789").unwrap());
    assert_eq!(123.456, s2d(b"123.456").unwrap());
    assert_eq!(123.456, s2d(b"123456e-3").unwrap());
    assert_eq!(123.456, s2d(b"1234.56e-1").unwrap());
    assert_eq!(1.453, s2d(b"1.453").unwrap());
    assert_eq!(1453.0, s2d(b"1.453e+3").unwrap());
    assert_eq!(0.0, s2d(b".0").unwrap());
    assert_eq!(1.0, s2d(b"1e0").unwrap());
    assert_eq!(1.0, s2d(b"1E0").unwrap());
    assert_eq!(1.0, s2d(b"000001.000000").unwrap());
    assert_eq!(0.2316419, s2d(b"0.2316419").unwrap());
}
fn dynamic_type() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t1" (type $t1 (sub resource)))
                (type $t2' (resource (rep i32)))
                (export $t2 "t2" (type $t2'))
                (core func $f (canon resource.drop $t2))

                (func (export "a") (param "x" (own $t1))
                    (canon lift (core func $f)))
                (func (export "b") (param "x" (tuple (own $t2)))
                    (canon lift (core func $f)))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t1", |_, _| Ok(()))?;
    let i = linker.instantiate(&mut store, &c)?;

    let a = i.get_func(&mut store, "a").unwrap();
    let b = i.get_func(&mut store, "b").unwrap();
    let t2 = i.get_resource(&mut store, "t2").unwrap();

    let a_params = a.params(&store);
    assert_eq!(a_params[0], Type::Own(ResourceType::host::<MyType>()));
    let b_params = b.params(&store);
    match &b_params[0] {
        Type::Tuple(t) => {
            assert_eq!(t.types().len(), 1);
            let t0 = t.types().next().unwrap();
            assert_eq!(t0, Type::Own(t2));
        }
        _ => unreachable!(),
    }

    Ok(())
}
fn escaping_happens_at_the_end() {
    let inputs = vec![
        #[cfg(feature = "builtins")]
        ("{{ url | urlencode | safe }}", "https%3A//www.example.org/apples-%26-oranges/"),
        ("{{ '<html>' }}", "&lt;html&gt;"),
        ("{{ '<html>' | safe }}", "<html>"),
        ("{{ 'hello' | safe | replace(from='h', to='&') }}", "&amp;ello"),
        ("{{ 'hello' | replace(from='h', to='&') | safe }}", "&ello"),
    ];

    for (input, expected) in inputs {
        let mut context = Context::new();
        context.insert("url", "https://www.example.org/apples-&-oranges/");
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn exercise_key_log_file_for_server() {
    serialized(|| {
        let mut server_config = make_server_config(KeyType::Rsa);

        env::set_var("SSLKEYLOGFILE", "./sslkeylogfile.txt");
        server_config.key_log = Arc::new(rustls::KeyLogFile::new());

        let server_config = Arc::new(server_config);

        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions(KeyType::Rsa, &[version]);
            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);

            assert_eq!(5, client.writer().write(b"hello").unwrap());

            do_handshake(&mut client, &mut server);
            transfer(&mut client, &mut server);
            server.process_new_packets().unwrap();
        }
    })
}
fn spread_in_arrow_function() {
    let s = r#"
    (...b) => {
        b
    }
    "#;

    let interner = &mut Interner::default();
    let b = interner.get_or_intern_static("b", utf16!("b"));
    let params = FormalParameterList::from(FormalParameter::new(
        Variable::from_identifier(b.into(), None),
        true,
    ));
    assert_eq!(params.flags(), FormalParameterListFlags::HAS_REST_PARAMETER);
    assert_eq!(params.length(), 0);
    check_script_parser(
        s,
        vec![Statement::Expression(Expression::from(ArrowFunction::new(
            None,
            params,
            FunctionBody::new(
                vec![Statement::Expression(Expression::from(Identifier::from(b))).into()].into(),
            ),
        )))
        .into()],
        interner,
    );
}
fn parse_select_distinct_two_fields() {
    let sql = "SELECT DISTINCT name, id FROM customer";
    let select = verified_only_select(sql);
    assert!(select.distinct.is_some());
    assert_eq!(
        &SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("name"))),
        &select.projection[0]
    );
    assert_eq!(
        &SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("id"))),
        &select.projection[1]
    );
}
fn test_float_to_bits() {
    assert_eq!(0, 0.0_f32.to_bits());
    assert_eq!(0x40490fda, 3.1415926_f32.to_bits());
}
fn test_parse_request_failed() {
    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    fail::cfg("coprocessor_parse_request", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_other_error().contains("unsupported tp"));
}
fn test_batch_get_memory_lock() {
    let (_cluster, client, ctx) = must_new_cluster_and_kv_client();

    let mut req = BatchGetRequest::default();
    req.set_context(ctx);
    req.set_keys(vec![b"a".to_vec(), b"b".to_vec()].into());
    req.version = 50;

    fail::cfg("raftkv_async_snapshot_err", "return").unwrap();
    let resp = client.kv_batch_get(&req).unwrap();
    // the injected error should be returned at both places for backward
    // compatibility.
    assert!(!resp.pairs[0].get_error().get_abort().is_empty());
    assert!(!resp.get_error().get_abort().is_empty());
    fail::remove("raftkv_async_snapshot_err");
}
fn test_split_separator_nl_number_r() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--number=r/3", "--separator", "\n", "fivelines.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\n4\n");
    assert_eq!(file_read(&at, "xab"), "2\n5\n");
    assert_eq!(file_read(&at, "xac"), "3\n");
    assert!(!at.plus("xad").exists());
}
fn render_macros_in_child_templates_different_namespace() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("grandparent", "{% block hey %}hello{% endblock hey %}"),
        ("macros", "{% macro hello()%}Hello{% endmacro hello %}"),
        ("macros2", "{% macro hi()%}Hi{% endmacro hi %}"),
        ("parent", "{% extends \"grandparent\" %}{% import \"macros\" as macros %}{% block hey %}{{macros::hello()}}{% endblock hey %}"),
        ("child", "{% extends \"parent\" %}{% import \"macros2\" as macros2 %}{% block hey %}{{super()}}/{{macros2::hi()}}{% endblock hey %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "Hello/Hi".to_string());
}
fn stream_id_limit() {
    let _guard = subscribe();
    let server = ServerConfig {
        transport: Arc::new(TransportConfig {
            max_concurrent_uni_streams: 1u32.into(),
            ..TransportConfig::default()
        }),
        ..server_config()
    };
    let mut pair = Pair::new(Default::default(), server);
    let (client_ch, server_ch) = pair.connect();

    let s = pair
        .client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .streams()
        .open(Dir::Uni)
        .expect("couldn't open first stream");
    assert_eq!(
        pair.client_streams(client_ch).open(Dir::Uni),
        None,
        "only one stream is permitted at a time"
    );
    // Generate some activity to allow the server to see the stream
    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.client_send(client_ch, s).finish().unwrap();
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Stream(StreamEvent::Finished { id })) if id == s
    );
    assert_eq!(
        pair.client_streams(client_ch).open(Dir::Uni),
        None,
        "server does not immediately grant additional credit"
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);

    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG
    );
    assert_eq!(chunks.next(usize::MAX), Ok(None));
    let _ = chunks.finalize();

    // Server will only send MAX_STREAM_ID now that the application's been notified
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Stream(StreamEvent::Available { dir: Dir::Uni }))
    );
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);

    // Try opening the second stream again, now that we've made room
    let s = pair
        .client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .streams()
        .open(Dir::Uni)
        .expect("didn't get stream id budget");
    pair.client_send(client_ch, s).finish().unwrap();
    pair.drive();
    // Make sure the server actually processes data on the newly-available stream
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);

    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(chunks.next(usize::MAX), Ok(None));
    let _ = chunks.finalize();
}
fn call_signature_mismatch() -> Result<()> {
    let mut store = Store::<()>::default();
    let binary = wat::parse_str(
        r#"
            (module $a
                (func $foo
                    i32.const 0
                    call_indirect)
                (func $bar (param i32))
                (start $foo)

                (table 1 anyfunc)
                (elem (i32.const 0) 1)
            )
        "#,
    )?;

    let module = Module::new(store.engine(), &binary)?;
    let err = Instance::new(&mut store, &module, &[])
        .err()
        .unwrap()
        .downcast::<Trap>()
        .unwrap();
    assert!(err
        .to_string()
        .contains("wasm trap: indirect call type mismatch"));
    Ok(())
}
fn test_accept_proposal_during_conf_change() {
    let mut cluster = new_node_cluster(0, 2);
    cluster.pd_client.disable_default_operator();
    let r = cluster.run_conf_change();
    cluster.must_put(b"a", b"v");

    let conf_change_fp = "apply_on_conf_change_all_1";
    fail::cfg(conf_change_fp, "pause").unwrap();
    let mut add_peer_rx = cluster.async_add_peer(r, new_peer(2, 2)).unwrap();
    add_peer_rx
        .recv_timeout(Duration::from_millis(100))
        .unwrap_err();

    // Conf change doesn't affect proposals.
    let write_req = make_write_req(&mut cluster, b"k");
    let (cb, mut cb_receivers) = make_cb(&write_req);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, write_req, cb)
        .unwrap();
    cb_receivers
        .committed
        .recv_timeout(Duration::from_millis(300))
        .unwrap();
    cb_receivers.proposed.try_recv().unwrap();

    fail::remove(conf_change_fp);
    assert!(
        !add_peer_rx
            .recv_timeout(Duration::from_secs(1))
            .unwrap()
            .get_header()
            .has_error()
    );
    assert!(
        !cb_receivers
            .applied
            .recv_timeout(Duration::from_secs(1))
            .unwrap()
            .get_header()
            .has_error()
    );
    must_get_equal(&cluster.get_engine(2), b"k", b"v");
}
fn test_instance_count_limit() {
    let limits = StoreLimitsBuilder::new().instances(0).build();
    assert!(Test::new(0x30, 100, limits).is_err());
}
fn math_test() {
    let mut x = VecType::try_from(&[0, 1, 9]).unwrap();
    assert_eq!(x.is_normalized(), true);
    x.try_push(0).unwrap();
    assert_eq!(&*x, &[0, 1, 9, 0]);
    assert_eq!(x.is_normalized(), false);
    x.normalize();
    assert_eq!(&*x, &[0, 1, 9]);
    assert_eq!(x.is_normalized(), true);

    x.add_small(1);
    assert_eq!(&*x, &[1, 1, 9]);
    x.add_small(LIMB_MAX);
    assert_eq!(&*x, &[0, 2, 9]);

    x.mul_small(3);
    assert_eq!(&*x, &[0, 6, 27]);
    x.mul_small(LIMB_MAX);
    let expected: VecType = if bigint::LIMB_BITS == 32 {
        vec_from_u32(&[0, 4294967290, 4294967274, 26])
    } else {
        vec_from_u32(&[0, 0, 4294967290, 4294967295, 4294967274, 4294967295, 26])
    };
    assert_eq!(&*x, &*expected);

    let mut x = VecType::from_u64(0xFFFFFFFF);
    let y = VecType::from_u64(5);
    x *= &y;
    let expected: VecType = vec_from_u32(&[0xFFFFFFFB, 0x4]);
    assert_eq!(&*x, &*expected);

    // Test with carry
    let mut x = VecType::from_u64(1);
    assert_eq!(&*x, &[1]);
    x.add_small(LIMB_MAX);
    assert_eq!(&*x, &[0, 1]);
}
fn compare_test() {
    // Simple
    let x = Bigint {
        data: from_u32(&[1]),
    };
    let y = Bigint {
        data: from_u32(&[2]),
    };
    assert_eq!(x.compare(&y), cmp::Ordering::Less);
    assert_eq!(x.compare(&x), cmp::Ordering::Equal);
    assert_eq!(y.compare(&x), cmp::Ordering::Greater);

    // Check asymmetric
    let x = Bigint {
        data: from_u32(&[5, 1]),
    };
    let y = Bigint {
        data: from_u32(&[2]),
    };
    assert_eq!(x.compare(&y), cmp::Ordering::Greater);
    assert_eq!(x.compare(&x), cmp::Ordering::Equal);
    assert_eq!(y.compare(&x), cmp::Ordering::Less);

    // Check when we use reverse ordering properly.
    let x = Bigint {
        data: from_u32(&[5, 1, 9]),
    };
    let y = Bigint {
        data: from_u32(&[6, 2, 8]),
    };
    assert_eq!(x.compare(&y), cmp::Ordering::Greater);
    assert_eq!(x.compare(&x), cmp::Ordering::Equal);
    assert_eq!(y.compare(&x), cmp::Ordering::Less);

    // Complex scenario, check it properly uses reverse ordering.
    let x = Bigint {
        data: from_u32(&[0, 1, 9]),
    };
    let y = Bigint {
        data: from_u32(&[4294967295, 0, 9]),
    };
    assert_eq!(x.compare(&y), cmp::Ordering::Greater);
    assert_eq!(x.compare(&x), cmp::Ordering::Equal);
    assert_eq!(y.compare(&x), cmp::Ordering::Less);
}
fn should_disable_a_rule() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), NO_DEBUGGER_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), CONFIG_LINTER_SUPPRESSED_RULE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, NO_DEBUGGER_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_disable_a_rule",
        fs,
        console,
        result,
    ));
}
fn static_many_params_works() {
    let (mut store, func) = setup_many_params();
    let typed_func = func.typed::<I32x16, ()>(&mut store).unwrap();
    let inputs = ascending_tuple();
    let result = typed_func.call(&mut store, inputs);
    assert_matches!(result, Ok(()));
}
fn test_parenthesized_name() {
    let source_code = r#"(x) + 1"#;
    let expr = parse_expression(source_code, "<filename>").unwrap();

    let bin_op = expr.as_bin_op_expr().unwrap();
    let name = bin_op.left.as_ref();

    let parenthesized = parenthesized_range(
        name.into(),
        bin_op.into(),
        &CommentRanges::default(),
        source_code,
    );
    assert_eq!(parenthesized, Some(TextRange::new(0.into(), 3.into())));
}
fn save_point_same_rollback_all() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"").unwrap();

    wb.set_save_point();
    wb.set_save_point();
    wb.set_save_point();

    wb.put(b"b", b"").unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    assert_engine_error(wb.pop_save_point());
    assert_engine_error(wb.rollback_to_save_point());

    wb.write().unwrap();

    let a = db.engine.get_value(b"a").unwrap();
    let b = db.engine.get_value(b"b").unwrap();

    assert!(a.is_some());
    assert!(b.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }
    wb.put(b"a", b"").unwrap();

    wb.set_save_point();
    wb.set_save_point();
    wb.set_save_point();

    wb.put(b"b", b"").unwrap();
    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }

    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    assert_engine_error(wb.pop_save_point());
    assert_engine_error(wb.rollback_to_save_point());

    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }

    assert!(db.engine.get_value(b"b").unwrap().is_none());
    for i in max_keys..2 * max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn thunks() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "thunk"))
                (func (export "thunk-trap") unreachable)
            )
            (core instance $i (instantiate $m))
            (func (export "thunk")
                (canon lift (core func $i "thunk"))
            )
            (func (export "thunk-trap")
                (canon lift (core func $i "thunk-trap"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    instance
        .get_typed_func::<(), ()>(&mut store, "thunk")?
        .call_and_post_return(&mut store, ())?;
    let err = instance
        .get_typed_func::<(), ()>(&mut store, "thunk-trap")?
        .call(&mut store, ())
        .unwrap_err();
    assert_eq!(err.downcast::<Trap>()?, Trap::UnreachableCodeReached);

    Ok(())
}
fn test_unsafe_recovery_rollback_merge() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.cfg.raft_store.merge_check_tick_interval = ReadableDuration::millis(20);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    for i in 0..10 {
        cluster.must_put(format!("k{}", i).as_bytes(), b"v");
    }

    // Block merge commit, let go of the merge prepare.
    fail::cfg("on_schedule_merge", "return()").unwrap();

    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");

    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    // Makes the leadership definite.
    let left_peer_2 = find_peer(&left, nodes[2]).unwrap().to_owned();
    let right_peer_2 = find_peer(&right, nodes[2]).unwrap().to_owned();
    cluster.must_transfer_leader(left.get_id(), left_peer_2);
    cluster.must_transfer_leader(right.get_id(), right_peer_2);
    cluster.must_try_merge(left.get_id(), right.get_id());

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    {
        let put = new_put_cmd(b"k2", b"v2");
        let req = new_request(
            region.get_id(),
            region.get_region_epoch().clone(),
            vec![put],
            true,
        );
        // marjority is lost, can't propose command successfully.
        cluster
            .call_command_on_leader(req, Duration::from_millis(10))
            .unwrap_err();
    }

    cluster.must_enter_force_leader(left.get_id(), nodes[0], vec![nodes[1], nodes[2]]);
    cluster.must_enter_force_leader(right.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    // Construct recovery plan.
    let mut plan = pdpb::RecoveryPlan::default();

    let left_demote_peers: Vec<metapb::Peer> = left
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut left_demote = pdpb::DemoteFailedVoters::default();
    left_demote.set_region_id(left.get_id());
    left_demote.set_failed_voters(left_demote_peers.into());
    let right_demote_peers: Vec<metapb::Peer> = right
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut right_demote = pdpb::DemoteFailedVoters::default();
    right_demote.set_region_id(right.get_id());
    right_demote.set_failed_voters(right_demote_peers.into());
    plan.mut_demotes().push(left_demote);
    plan.mut_demotes().push(right_demote);

    // Triggers the unsafe recovery plan execution.
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan.clone());
    cluster.must_send_store_heartbeat(nodes[0]);

    // Can't propose demotion as it's in merging mode
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    let has_force_leader = store_report
        .unwrap()
        .get_peer_reports()
        .iter()
        .any(|p| p.get_is_force_leader());
    // Force leader is not exited due to demotion failure
    assert!(has_force_leader);

    fail::remove("on_schedule_merge");
    fail::cfg("on_schedule_merge_ret_err", "return()").unwrap();

    // Make sure merge check is scheduled, and rollback merge is triggered
    sleep_ms(50);

    // Re-triggers the unsafe recovery plan execution.
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    // No force leader
    for peer_report in store_report.unwrap().get_peer_reports() {
        assert!(!peer_report.get_is_force_leader());
    }

    // Demotion is done
    let mut demoted = false;
    for _ in 0..10 {
        let new_left = block_on(pd_client.get_region_by_id(left.get_id()))
            .unwrap()
            .unwrap();
        let new_right = block_on(pd_client.get_region_by_id(right.get_id()))
            .unwrap()
            .unwrap();
        assert_eq!(new_left.get_peers().len(), 3);
        assert_eq!(new_right.get_peers().len(), 3);
        demoted = new_left
            .get_peers()
            .iter()
            .filter(|peer| peer.get_store_id() != nodes[0])
            .all(|peer| peer.get_role() == metapb::PeerRole::Learner)
            && new_right
                .get_peers()
                .iter()
                .filter(|peer| peer.get_store_id() != nodes[0])
                .all(|peer| peer.get_role() == metapb::PeerRole::Learner);
        if demoted {
            break;
        }
        sleep_ms(100);
    }
    assert_eq!(demoted, true);

    fail::remove("on_schedule_merge_ret_err");
}
fn test_compute_inv_pow5() {
    for (i, entry) in DOUBLE_POW5_INV_SPLIT[..292].iter().enumerate() {
        assert_eq!(*entry, unsafe { compute_inv_pow5(i as u32) }, "entry {}", i);
    }
}
fn test_split_multiple_obs_lines_standalone() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let name = "multiple-obs-lines";
    RandomFile::new(at, name).add_lines(400);

    scene
        .ucmd()
        .args(&["-3000", "-200", name])
        .succeeds()
        .no_stderr()
        .no_stdout();
    let glob = Glob::new(at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_cp_arg_backup() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("-b")
        .succeeds();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
fn test_split_separator_semicolon_lines() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--lines=2", "-t", ";", "separator_semicolon.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1;2;");
    assert_eq!(file_read(&at, "xab"), "3;4;");
    assert_eq!(file_read(&at, "xac"), "5;");
    assert!(!at.plus("xad").exists());
}
fn parse_block() {
    let ast = parse("{% block hello %}{{super()}} hey{%- endblock hello %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Block(
            start_ws,
            Block {
                name: "hello".to_string(),
                body: vec![Node::Super, Node::Text(" hey".to_string())],
            },
            end_ws,
        )
    );
}
fn bare_bones() -> Result<()> {
    let engine = super::engine();
    let component = Component::new(&engine, "(component)")?.serialize()?;
    assert_eq!(component, engine.precompile_component(b"(component)")?);

    let component = unsafe { Component::deserialize(&engine, &component)? };
    let mut store = Store::new(&engine, ());
    Linker::new(&engine).instantiate(&mut store, &component)?;

    Ok(())
}
fn stdin_fix_when_not_fixable_should_still_print_contents() {
    let args = ["--fix"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("import os\nimport sys\n\nif (1, 2):\n     print(sys.version)\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    import sys

    if (1, 2):
         print(sys.version)

    ----- stderr -----
    -:3:4: F634 If test is a tuple, which is always `True`
    Found 2 errors (1 fixed, 1 remaining).
    "###);
}
fn test_cdc_filter_key_range() {
    let mut suite = TestSuite::new(1, ApiVersion::V1);

    let req = suite.new_changedata_request(1);

    // Observe range [key1, key3).
    let mut req_1_3 = req.clone();
    req_1_3.request_id = 13;
    req_1_3.start_key = Key::from_raw(b"key1").into_encoded();
    req_1_3.end_key = Key::from_raw(b"key3").into_encoded();
    let (mut req_tx13, _event_feed_wrap13, receive_event13) =
        new_event_feed(suite.get_region_cdc_client(1));
    block_on(req_tx13.send((req_1_3, WriteFlags::default()))).unwrap();
    let event = receive_event13(false);
    event
        .events
        .into_iter()
        .for_each(|e| match e.event.unwrap() {
            Event_oneof_event::Entries(es) => {
                assert!(es.entries.len() == 1, "{:?}", es);
                let e = &es.entries[0];
                assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
            }
            other => panic!("unknown event {:?}", other),
        });

    let (mut req_tx24, _event_feed_wrap24, receive_event24) =
        new_event_feed(suite.get_region_cdc_client(1));
    let mut req_2_4 = req;
    req_2_4.request_id = 24;
    req_2_4.start_key = Key::from_raw(b"key2").into_encoded();
    req_2_4.end_key = Key::from_raw(b"key4").into_encoded();
    block_on(req_tx24.send((req_2_4, WriteFlags::default()))).unwrap();
    let event = receive_event24(false);
    event
        .events
        .into_iter()
        .for_each(|e| match e.event.unwrap() {
            Event_oneof_event::Entries(es) => {
                assert!(es.entries.len() == 1, "{:?}", es);
                let e = &es.entries[0];
                assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
            }
            other => panic!("unknown event {:?}", other),
        });

    // Sleep a while to make sure the stream is registered.
    sleep_ms(1000);

    let receive_and_check_events = |is13: bool, is24: bool| -> Vec<Event> {
        if is13 && is24 {
            let mut events = receive_event13(false).events.to_vec();
            let mut events24 = receive_event24(false).events.to_vec();
            events.append(&mut events24);
            events
        } else if is13 {
            let events = receive_event13(false).events.to_vec();
            let event = receive_event24(true);
            assert!(event.resolved_ts.is_some(), "{:?}", event);
            events
        } else if is24 {
            let events = receive_event24(false).events.to_vec();
            let event = receive_event13(true);
            assert!(event.resolved_ts.is_some(), "{:?}", event);
            events
        } else {
            let event = receive_event13(true);
            assert!(event.resolved_ts.is_some(), "{:?}", event);
            let event = receive_event24(true);
            assert!(event.resolved_ts.is_some(), "{:?}", event);
            vec![]
        }
    };
    for case in &[
        ("key1", true, false, true /* commit */),
        ("key1", true, false, false /* rollback */),
        ("key2", true, true, true),
        ("key3", false, true, true),
        ("key4", false, false, true),
    ] {
        let (k, v) = (case.0.to_owned(), "value".to_owned());
        // Prewrite
        let start_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
        let mut mutation = Mutation::default();
        mutation.set_op(Op::Put);
        mutation.key = k.clone().into_bytes();
        mutation.value = v.into_bytes();
        suite.must_kv_prewrite(1, vec![mutation], k.clone().into_bytes(), start_ts);
        let mut events = receive_and_check_events(case.1, case.2);
        while let Some(event) = events.pop() {
            match event.event.unwrap() {
                Event_oneof_event::Entries(entries) => {
                    assert_eq!(entries.entries.len(), 1);
                    assert_eq!(entries.entries[0].get_type(), EventLogType::Prewrite);
                }
                other => panic!("unknown event {:?}", other),
            }
        }

        if case.3 {
            // Commit
            let commit_ts = block_on(suite.cluster.pd_client.get_tso()).unwrap();
            suite.must_kv_commit(1, vec![k.into_bytes()], start_ts, commit_ts);
            let mut events = receive_and_check_events(case.1, case.2);
            while let Some(event) = events.pop() {
                match event.event.unwrap() {
                    Event_oneof_event::Entries(entries) => {
                        assert_eq!(entries.entries.len(), 1);
                        assert_eq!(entries.entries[0].get_type(), EventLogType::Commit);
                    }
                    other => panic!("unknown event {:?}", other),
                }
            }
        } else {
            // Rollback
            suite.must_kv_rollback(1, vec![k.into_bytes()], start_ts);
            let mut events = receive_and_check_events(case.1, case.2);
            while let Some(event) = events.pop() {
                match event.event.unwrap() {
                    Event_oneof_event::Entries(entries) => {
                        assert_eq!(entries.entries.len(), 1);
                        assert_eq!(entries.entries[0].get_type(), EventLogType::Rollback);
                    }
                    other => panic!("unknown event {:?}", other),
                }
            }
        }
    }

    suite.stop();
}
fn test_raft_storage_get_after_lease() {
    let (cluster, storage, ctx) = new_raft_storage();
    let key = b"key";
    let value = b"value";
    assert_eq!(
        storage
            .raw_get(ctx.clone(), "".to_string(), key.to_vec())
            .unwrap(),
        None
    );
    storage
        .raw_put(ctx.clone(), "".to_string(), key.to_vec(), value.to_vec())
        .unwrap();
    assert_eq!(
        storage
            .raw_get(ctx.clone(), "".to_string(), key.to_vec())
            .unwrap()
            .unwrap(),
        value.to_vec()
    );

    // Sleep until the leader lease is expired.
    thread::sleep(cluster.cfg.raft_store.raft_store_max_leader_lease.0);
    assert_eq!(
        storage
            .raw_get(ctx, "".to_string(), key.to_vec())
            .unwrap()
            .unwrap(),
        value.to_vec()
    );
}
fn test_pd_client_ok_when_cluster_not_ready() {
    let pd_client_cluster_id_zero = "cluster_id_is_not_ready";
    let server = MockServer::with_case(3, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();

    let client = new_client(eps, None);
    fail::cfg(pd_client_cluster_id_zero, "return()").unwrap();
    // wait 100ms to let client load member.
    thread::sleep(Duration::from_millis(101));
    assert_eq!(client.reconnect().is_err(), true);
    fail::remove(pd_client_cluster_id_zero);
}
fn test_touch_reference() {
    let scenario = TestScenario::new("touch");
    let (at, mut _ucmd) = (scenario.fixtures.clone(), scenario.ucmd());
    let file_a = "test_touch_reference_a";
    let file_b = "test_touch_reference_b";
    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");

    at.touch(file_a);
    set_file_times(&at, file_a, start_of_year, start_of_year);
    assert!(at.file_exists(file_a));
    for opt in ["-r", "--ref", "--reference"] {
        scenario
            .ccmd("touch")
            .args(&[opt, file_a, file_b])
            .succeeds()
            .no_stderr();

        assert!(at.file_exists(file_b));

        let (atime, mtime) = get_file_times(&at, file_b);
        assert_eq!(atime, mtime);
        assert_eq!(atime, start_of_year);
        assert_eq!(mtime, start_of_year);
        let _ = remove_file(file_b);
    }
}
fn test_skip_iter_ilc() {
    // Test iterators that skip multiple, internal or leading digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_leading_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"45__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"45__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"45__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"45__.56");
}
fn pass_moved_resource() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (core module $m
                    (func (export "f") (param i32 i32))
                )
                (core instance $i (instantiate $m))

                (func (export "f") (param "x" (own $t)) (param "y" (borrow $t))
                    (canon lift (core func $i "f")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
    let i = linker.instantiate(&mut store, &c)?;

    let f = i.get_typed_func::<(&Resource<MyType>, &Resource<MyType>), ()>(&mut store, "f")?;

    let resource = Resource::new_own(100);
    let err = f.call(&mut store, (&resource, &resource)).unwrap_err();
    assert!(
        format!("{err:?}").contains("host resource already consumed"),
        "bad error: {err:?}"
    );
    Ok(())
}
fn parse_f64_large_zeros_test() {
    // Test numbers with a massive number of 0s in the integer component.
    let parse = move |x| f64::from_lexical_partial(x);
    assert_eq!(Ok((71610528364411830000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.0, 308)), parse(b"71610528364411830000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"));
    assert_eq!(Ok((126769393745745060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.0, 309)), parse(b"126769393745745060000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"));
    assert_eq!(Ok((38652960461239320000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000.0, 308)), parse(b"38652960461239320000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000"));
}
fn test_mv_force_replace_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_force_replace_file_a";
    let file_b = "test_mv_force_replace_file_b";

    at.touch(file_a);
    at.touch(file_b);

    ucmd.arg("--force")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
}
fn test_format_created_time() {
    let args = ["-c", "%w", "/bin"];
    let ts = TestScenario::new(util_name!());
    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();
    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();
    println!("actual: {actual:?}");
    println!("expect: {expect:?}");
    // note: using a regex instead of `split_whitespace()` in order to detect whitespace differences
    let re = regex::Regex::new(r"\s").unwrap();
    let v_actual: Vec<&str> = re.split(&actual).collect();
    let v_expect: Vec<&str> = re.split(&expect).collect();
    assert!(!v_expect.is_empty());
    // * allow for inequality if `stat` (aka, expect) returns "-" (unknown value)
    assert!(
        expect == "-"
            || expect == "-\n"
            || v_actual
                .iter()
                .zip(v_expect.iter())
                .all(|(a, e)| a == e || *e == "-" || *e == "-\n")
    );
}
fn print_verbose() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--verbose"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "print_verbose",
        fs,
        console,
        result,
    ));
}
fn does_handle_included_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "ignore": ["test.js", "special/**"]
  },
  "overrides": [{ "include": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FORMATTED);
    assert_file_contents(&fs, test, UNFORMATTED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_included_file",
        fs,
        console,
        result,
    ));
}
fn explain_status_codes_f401() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME)).args(["--explain", "F401"]));
}
fn var_access_by_loop_index() {
    let context = Context::new();
    let res = Tera::one_off(
        r#"
{% set ics = ["fa-rocket","fa-paper-plane","fa-diamond","fa-signal"] %}
{% for a in ics %}
{{ ics[loop.index0] }}
{% endfor %}
    "#,
        &context,
        true,
    );
    assert!(res.is_ok());
}
fn test_v1_simple_write() {
    let mut cluster_v2 = test_raftstore_v2::new_node_cluster(1, 2);
    let mut cluster_v1 = test_raftstore::new_node_cluster(1, 2);
    cluster_v1.cfg.tikv.raft_store.enable_v2_compatible_learner = true;
    cluster_v1.pd_client.disable_default_operator();
    cluster_v2.pd_client.disable_default_operator();
    let r11 = cluster_v1.run_conf_change();
    let r21 = cluster_v2.run_conf_change();

    cluster_v1.must_put(b"k0", b"v0");
    cluster_v2.must_put(b"k0", b"v0");
    cluster_v1
        .pd_client
        .must_add_peer(r11, new_learner_peer(2, 10));
    cluster_v2
        .pd_client
        .must_add_peer(r21, new_learner_peer(2, 10));
    check_key_in_engine(&cluster_v1.get_engine(2), b"zk0", b"v0");
    check_key_in_engine(&cluster_v2.get_engine(2), b"zk0", b"v0");
    let trans1 = Mutex::new(cluster_v1.sim.read().unwrap().get_router(2).unwrap());
    let trans2 = Mutex::new(cluster_v2.sim.read().unwrap().get_router(1).unwrap());

    let factory1 = ForwardFactory {
        node_id: 1,
        chain_send: Arc::new(move |m| {
            info!("send to trans2"; "msg" => ?m);
            let _ = trans2.lock().unwrap().send_raft_message(Box::new(m));
        }),
    };
    cluster_v1.add_send_filter(factory1);
    let factory2 = ForwardFactory {
        node_id: 2,
        chain_send: Arc::new(move |m| {
            info!("send to trans1"; "msg" => ?m);
            let _ = trans1.lock().unwrap().send_raft_message(m);
        }),
    };
    cluster_v2.add_send_filter(factory2);
    let filter11 = Box::new(
        RegionPacketFilter::new(r11, 2)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend)
            .msg_type(MessageType::MsgAppendResponse)
            .msg_type(MessageType::MsgSnapshot)
            .msg_type(MessageType::MsgHeartbeat)
            .msg_type(MessageType::MsgHeartbeatResponse),
    );
    cluster_v1.add_recv_filter_on_node(2, filter11);

    cluster_v2.must_put(b"k1", b"v1");
    assert_eq!(
        cluster_v2.must_get(b"k1").unwrap(),
        "v1".as_bytes().to_vec()
    );
    check_key_in_engine(&cluster_v1.get_engine(2), b"zk1", b"v1");

    cluster_v1.shutdown();
    cluster_v2.shutdown();
}
fn fix_does_not_apply_display_only_fixes_with_unsafe_fixes_enabled() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "B006",
                "--fix",
                "--unsafe-fixes",
            ])
            .pass_stdin("def add_to_list(item, some_list=[]): ..."),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    def add_to_list(item, some_list=[]): ...
    ----- stderr -----
    -:1:33: B006 Do not use mutable data structures for argument defaults
    Found 1 error.
    "###);
}
fn render_variable_block_logic_expr() {
    let mut context = Context::new();
    context.insert("name", &"john");
    context.insert("malicious", &"<html>");
    context.insert("a", &2);
    context.insert("b", &3);
    context.insert("numbers", &vec![1, 2, 3]);
    context.insert("tuple_list", &vec![(1, 2, 3), (1, 2, 3)]);
    let mut hashmap = HashMap::new();
    hashmap.insert("a", 1);
    hashmap.insert("b", 10);
    hashmap.insert("john", 100);
    context.insert("object", &hashmap);
    context.insert("urls", &vec!["https://test"]);

    let inputs = vec![
        ("{{ (1.9 + a) | round > 10 }}", "false"),
        ("{{ (1.9 + a) | round > 10 or b > a }}", "true"),
        ("{{ 1.9 + a | round == 4 and numbers | length == 3}}", "true"),
        ("{{ numbers | length > 1 }}", "true"),
        ("{{ numbers | length == 1 }}", "false"),
        ("{{ numbers | length - 2 == 1 }}", "true"),
        ("{{ not name }}", "false"),
        ("{{ not true }}", "false"),
        ("{{ not undefined }}", "true"),
        ("{{ name == 'john' }}", "true"),
        ("{{ name != 'john' }}", "false"),
        ("{{ name == 'john' | capitalize }}", "false"),
        ("{{ name != 'john' | capitalize }}", "true"),
        ("{{ 1 in numbers }}", "true"),
        ("{{ 1 not in numbers }}", "false"),
        ("{{ 40 not in numbers }}", "true"),
        ("{{ 'e' in 'hello' }}", "true"),
        ("{{ 'e' not in 'hello' }}", "false"),
        ("{{ 'x' not in 'hello' }}", "true"),
        ("{{ name in 'hello john' }}", "true"),
        ("{{ name not in 'hello john' }}", "false"),
        ("{{ name not in 'hello' }}", "true"),
        ("{{ name in ['bob', 2, 'john'] }}", "true"),
        ("{{ a in ['bob', 2, 'john'] }}", "true"),
        ("{{ \"https://test\" in [\"https://test\"] }}", "true"),
        ("{{ \"https://test\" in urls }}", "true"),
        ("{{ 'n' in name }}", "true"),
        ("{{ '<' in malicious }}", "true"),
        ("{{ 'a' in object }}", "true"),
        ("{{ name in object }}", "true"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_rm_recursive_multiple() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_rm_recursive_directory";
    let file_a = "test_rm_recursive_directory/test_rm_recursive_file_a";
    let file_b = "test_rm_recursive_directory/test_rm_recursive_file_b";

    at.mkdir(dir);
    at.touch(file_a);
    at.touch(file_b);

    ucmd.arg("-r")
        .arg("-r")
        .arg("-r")
        .arg(dir)
        .succeeds()
        .no_stderr();

    assert!(!at.dir_exists(dir));
    assert!(!at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
}
fn tuple3_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: TableDefinition<(&str, u8, u16), (u16, u32)> = TableDefinition::new("table");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(table_def).unwrap();
        table.insert(&("hello", 5, 6), &(0, 123)).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(table_def).unwrap();
    assert_eq!(
        table.get(&("hello", 5, 6)).unwrap().unwrap().value(),
        (0, 123)
    );
}
fn test_mv_multiple_files() {
    let (at, mut ucmd) = at_and_ucmd!();
    let target_dir = "test_mv_multiple_files_dir";
    let file_a = "test_mv_multiple_file_a";
    let file_b = "test_mv_multiple_file_b";

    at.mkdir(target_dir);
    at.touch(file_a);
    at.touch(file_b);

    ucmd.arg(file_a)
        .arg(file_b)
        .arg(target_dir)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(format!("{target_dir}/{file_a}")));
    assert!(at.file_exists(format!("{target_dir}/{file_b}")));
}
fn missing_configuration_file() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("migrate")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "missing_configuration_file",
        fs,
        console,
        result,
    ));
}
fn datagram_send_recv() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    assert_matches!(pair.server_conn_mut(server_ch).poll(), None);
    assert_matches!(pair.client_datagrams(client_ch).max_size(), Some(x) if x > 0);

    const DATA: &[u8] = b"whee";
    pair.client_datagrams(client_ch).send(DATA.into()).unwrap();
    pair.drive();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::DatagramReceived)
    );
    assert_eq!(pair.server_datagrams(server_ch).recv().unwrap(), DATA);
    assert_matches!(pair.server_datagrams(server_ch).recv(), None);
}
fn test_tee_treat_minus_as_filename() {
    // Ensure tee treats '-' as the name of a file, as mandated by POSIX.

    let (at, mut ucmd) = at_and_ucmd!();
    let content = "tee_sample_content";
    let file = "-";

    ucmd.arg("-").pipe_in(content).succeeds().stdout_is(content);

    assert!(at.file_exists(file));
    assert_eq!(at.read(file), content);
}
fn scalar_add_test() {
    assert_eq!(bigint::scalar_add(5, 5), (10, false));
    assert_eq!(bigint::scalar_add(LIMB_MAX, 1), (0, true));
}
fn bad_tables() {
    let mut store = Store::<()>::default();

    // mismatched initializer
    let ty = TableType::new(ValType::FuncRef, 0, Some(1));
    assert!(Table::new(&mut store, ty.clone(), Val::I32(0)).is_err());

    // get out of bounds
    let ty = TableType::new(ValType::FuncRef, 0, Some(1));
    let t = Table::new(&mut store, ty.clone(), Val::FuncRef(None)).unwrap();
    assert!(t.get(&mut store, 0).is_none());
    assert!(t.get(&mut store, u32::max_value()).is_none());

    // set out of bounds or wrong type
    let ty = TableType::new(ValType::FuncRef, 1, Some(1));
    let t = Table::new(&mut store, ty.clone(), Val::FuncRef(None)).unwrap();
    assert!(t.set(&mut store, 0, Val::I32(0)).is_err());
    assert!(t.set(&mut store, 0, Val::FuncRef(None)).is_ok());
    assert!(t.set(&mut store, 1, Val::FuncRef(None)).is_err());

    // grow beyond max
    let ty = TableType::new(ValType::FuncRef, 1, Some(1));
    let t = Table::new(&mut store, ty.clone(), Val::FuncRef(None)).unwrap();
    assert!(t.grow(&mut store, 0, Val::FuncRef(None)).is_ok());
    assert!(t.grow(&mut store, 1, Val::FuncRef(None)).is_err());
    assert_eq!(t.size(&store), 1);

    // grow wrong type
    let ty = TableType::new(ValType::FuncRef, 1, Some(2));
    let t = Table::new(&mut store, ty.clone(), Val::FuncRef(None)).unwrap();
    assert!(t.grow(&mut store, 1, Val::I32(0)).is_err());
    assert_eq!(t.size(&store), 1);
}
fn test_error_info() {
    let mut c = CodeGenerator::new("hello.html", "");
    c.set_line(1);
    c.add(Instruction::EmitRaw("<h1>Hello</h1>\n"));
    c.set_line(2);
    c.add(Instruction::Lookup("a_string"));
    c.add(Instruction::Lookup("an_int"));
    c.add(Instruction::Add);

    let mut ctx = std::collections::BTreeMap::new();
    ctx.insert("a_string", Value::from("foo"));
    ctx.insert("an_int", Value::from(42));

    let err = simple_eval(&c.finish().0, ctx).unwrap_err();
    assert_eq!(err.name(), Some("hello.html"));
    assert_eq!(err.line(), Some(2));
}
fn wallet_creates_correct_mainnet_taproot_descriptor() {
  let rpc_server = test_bitcoincore_rpc::spawn();

  CommandBuilder::new("wallet create")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Output>();

  assert_eq!(rpc_server.descriptors().len(), 2);
  assert_regex_match!(
    &rpc_server.descriptors()[0],
    r"tr\(\[[[:xdigit:]]{8}/86'/0'/0'\]xprv[[:alnum:]]*/0/\*\)#[[:alnum:]]{8}"
  );
  assert_regex_match!(
    &rpc_server.descriptors()[1],
    r"tr\(\[[[:xdigit:]]{8}/86'/0'/0'\]xprv[[:alnum:]]*/1/\*\)#[[:alnum:]]{8}"
  );
}
fn test_install_backup_numbered_if_existing_backup_existing() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";
    let file_b_backup = "test_install_backup_numbering_file_b.~1~";

    at.touch(file_a);
    at.touch(file_b);
    at.touch(file_b_backup);
    scene
        .ucmd()
        .arg("--backup=existing")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(file_b_backup));
    assert!(at.file_exists(format!("{file_b}.~2~")));
}
fn test_values_in_vec() {
    fn upper(value: &str) -> String {
        value.to_uppercase()
    }

    fn sum(value: Vec<i64>) -> i64 {
        value.into_iter().sum::<i64>()
    }

    let mut env = Environment::new();
    env.add_filter("upper", upper);
    env.add_filter("sum", sum);
    let state = env.empty_state();

    assert_eq!(
        state.apply_filter("upper", args!("Hello World!")).unwrap(),
        Value::from("HELLO WORLD!")
    );

    assert_eq!(
        state.apply_filter("sum", args!(vec![1, 2])).unwrap(),
        Value::from(3)
    );
}
fn test_combined_file_set() {
    let out = new_ucmd!()
        .arg("-f")
        .arg("vars.conf.txt")
        .arg("FOO=bar.alt")
        .run()
        .stdout_move_str();

    assert_eq!(out.lines().filter(|&line| line == "FOO=bar.alt").count(), 1);
}
fn test_echo() {
    let result = new_ucmd!().arg("echo").arg("FOO-bar").succeeds();

    assert_eq!(result.stdout_str().trim(), "FOO-bar");
}
fn strip_inline_block_internal_text() {
    assert_eq!(
        "<u>a </u>b <u>c</u>",
        normalize_html(" <u> a </u> b <u> c </u> ")
    )
}
fn test_auto_gc() {
    let count = 3;
    let (mut cluster, first_leader_storage, ctx) =
        new_raft_storage_with_store_count::<ApiV1>(count, "");
    let pd_client = Arc::clone(&cluster.pd_client);

    // Used to wait for all storage's GC to finish
    let (finish_signal_tx, finish_signal_rx) = channel();

    // Create storage object for each store in the cluster
    let mut storages: HashMap<_, _> = cluster
        .sim
        .rl()
        .storages
        .iter()
        .map(|(id, engine)| {
            let mut config = GcConfig::default();
            // Do not skip GC
            config.ratio_threshold = 0.9;
            let storage = SyncTestStorageBuilderApiV1::from_engine(engine.clone())
                .gc_config(config)
                .build(*id)
                .unwrap();

            (*id, storage)
        })
        .collect();

    let mut region_info_accessors = cluster.sim.rl().region_info_accessors.clone();

    for (id, storage) in &mut storages {
        let tx = finish_signal_tx.clone();

        let mut cfg = AutoGcConfig::new_test_cfg(
            Arc::clone(&pd_client),
            region_info_accessors.remove(id).unwrap(),
            *id,
        );
        cfg.post_a_round_of_gc = Some(Box::new(move || tx.send(()).unwrap()));

        storage.start_auto_gc(cfg);
    }

    assert_eq!(storages.len(), count);

    // test_data will be wrote with ts < 50
    let test_data: Vec<_> = [
        (b"k1", b"v1"),
        (b"k2", b"v2"),
        (b"k3", b"v3"),
        (b"k4", b"v4"),
        (b"k5", b"v5"),
        (b"k6", b"v6"),
        (b"k7", b"v7"),
        (b"k8", b"v8"),
        (b"k9", b"v9"),
    ]
    .iter()
    .map(|(k, v)| (k.to_vec(), v.to_vec()))
    .collect();

    let test_data2: Vec<_> = test_data
        .iter()
        .map(|(k, v)| {
            let mut v = v.to_vec();
            v.push(b'1');
            (k.to_vec(), v)
        })
        .collect();

    let test_data3: Vec<_> = test_data
        .iter()
        .map(|(k, v)| {
            let mut v = v.to_vec();
            v.push(b'2');
            (k.to_vec(), v)
        })
        .collect();

    write_test_data(&first_leader_storage, &ctx, &test_data, 10);
    write_test_data(&first_leader_storage, &ctx, &test_data2, 100);
    write_test_data(&first_leader_storage, &ctx, &test_data3, 200);

    let split_keys: &[&[u8]] = &[b"k2", b"k4", b"k6", b"k8"];

    for k in split_keys {
        let region = cluster.get_region(k);
        cluster.must_split(&region, k);
    }

    check_data(&mut cluster, &storages, &test_data, 50, true);
    check_data(&mut cluster, &storages, &test_data2, 150, true);
    check_data(&mut cluster, &storages, &test_data3, 250, true);

    pd_client.set_gc_safe_point(150);

    for _ in 0..count {
        finish_signal_rx.recv().unwrap();
    }

    check_data(&mut cluster, &storages, &test_data, 50, false);
    check_data(&mut cluster, &storages, &test_data2, 150, true);
    check_data(&mut cluster, &storages, &test_data3, 250, true);

    // No more signals.
    finish_signal_rx
        .recv_timeout(Duration::from_millis(300))
        .unwrap_err();
}
fn remove_previous_ws_if_single_opening_tag_requires_it() {
    let ws = WS { left: true, right: false };
    let ast = vec![
        Node::Text("hey ".to_string()),
        Node::ImportMacro(ws, "hey ".to_string(), "ho".to_string()),
    ];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![
            Node::Text("hey".to_string()), // it removed the trailing space
            Node::ImportMacro(ws, "hey ".to_string(), "ho".to_string()),
        ]
    );
}
fn lower_n_halfway_test() {
    assert_eq!(mask::lower_n_halfway(2), 0b10);
}
fn zero_rtt_happypath() {
    let _guard = subscribe();
    let mut pair = Pair::new(
        Default::default(),
        ServerConfig {
            use_retry: true,
            ..server_config()
        },
    );
    let config = client_config();

    // Establish normal connection
    let client_ch = pair.begin_connect(config.clone());
    pair.drive();
    pair.server.assert_accept();
    pair.client
        .connections
        .get_mut(&client_ch)
        .unwrap()
        .close(pair.time, VarInt(0), [][..].into());
    pair.drive();

    pair.client.addr = SocketAddr::new(
        Ipv6Addr::LOCALHOST.into(),
        CLIENT_PORTS.lock().unwrap().next().unwrap(),
    );
    info!("resuming session");
    let client_ch = pair.begin_connect(config);
    assert!(pair.client_conn_mut(client_ch).has_0rtt());
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    const MSG: &[u8] = b"Hello, 0-RTT!";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive();

    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected)
    );

    assert!(pair.client_conn_mut(client_ch).accepted_0rtt());
    let server_ch = pair.server.assert_accept();

    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    // We don't currently preserve stream event order wrt. connection events
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Connected)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );

    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG
    );
    let _ = chunks.finalize();
    assert_eq!(pair.client_conn_mut(client_ch).lost_packets(), 0);
}
fn test_shred_remove() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_shred_remove_a";
    let file_b = "test_shred_remove_b";

    // Create file_a and file_b.
    at.touch(file_a);
    at.touch(file_b);

    // Shred file_a.
    scene.ucmd().arg("-u").arg(file_a).succeeds();

    // file_a was deleted, file_b exists.
    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
}
fn parse_key_value_test() {
  let ini_file = "parameter=value
key = value2";

  let ini_without_key_value = "key = value2";

  let res = key_value(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, (o1, o2))) => println!("i: {} | o: ({:?},{:?})", i, o1, o2),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_key_value, ("parameter", "value"))));
}
async fn reject_informational_status_header_in_request() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let _ = client.assert_server_handshake().await;

        let status_code = 128;
        assert!(StatusCode::from_u16(status_code)
            .unwrap()
            .is_informational());

        client
            .send_frame(frames::headers(1).response(status_code))
            .await;

        client.recv_frame(frames::reset(1).protocol_error()).await;
    };

    let srv = async move {
        let builder = server::Builder::new();
        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn table_growth_failure() -> Result<()> {
    let output = get_wasmtime_command()?
        .args(&[
            "run",
            "-Wtrap-on-grow-failure",
            "tests/all/cli_tests/table-grow-failure.wat",
        ])
        .output()?;
    assert!(!output.status.success());
    let stderr = String::from_utf8_lossy(&output.stderr);
    assert!(
        stderr.contains("forcing trap when growing table"),
        "bad stderr: {stderr}"
    );
    Ok(())
}
fn test_non_witness_replica_read() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // witness -> nonwitness
    fail::cfg("ignore request snapshot", "return").unwrap();
    cluster
        .pd_client
        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);
    std::thread::sleep(Duration::from_millis(100));
    // as we ignore request snapshot, so snapshot should still not applied yet

    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cmd(b"k0")],
        false,
    );
    request.mut_header().set_peer(peer_on_store3.clone());
    request.mut_header().set_replica_read(true);

    let resp = cluster
        .read(None, request, Duration::from_millis(100))
        .unwrap();
    assert_eq!(
        resp.get_header().get_error().get_is_witness(),
        &kvproto::errorpb::IsWitness {
            region_id: region.get_id(),
            ..Default::default()
        }
    );

    // start requesting snapshot and give enough time for applying snapshot to
    // complete
    fail::remove("ignore request snapshot");
    std::thread::sleep(Duration::from_millis(500));

    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cmd(b"k0")],
        false,
    );
    request.mut_header().set_peer(peer_on_store3);
    request.mut_header().set_replica_read(true);

    let resp = cluster
        .read(None, request, Duration::from_millis(100))
        .unwrap();
    assert_eq!(resp.get_header().has_error(), false);
}
pub fn test_reschedule_coprocessor() {
    let tag = "tag_coprocessor";

    let (test_suite, mut store, endpoint) = setup_test_suite();
    fail::cfg("copr_reschedule", "return").unwrap();
    fail::cfg_callback("scanner_next", || cpu_load(Duration::from_millis(100))).unwrap();
    defer!({
        fail::remove("scanner_next");
        fail::remove("copr_reschedule");
    });

    let jh = test_suite
        .rt
        .spawn(require_cpu_time_not_zero(&test_suite, tag));

    let table = ProductTable::new();
    let insert = prepare_insert(&mut store, &table);
    insert.execute();
    store.commit();

    let mut req = DagSelect::from(&table).build();
    let mut ctx = Context::default();
    ctx.set_resource_group_tag(tag.as_bytes().to_vec());
    req.set_context(ctx);
    assert!(
        !block_on(endpoint.parse_and_handle_unary_request(req, None))
            .consume()
            .get_data()
            .is_empty()
    );

    assert!(block_on(jh).unwrap());
}
fn read_icc_profile_chunk_count_mismatch() {
    let path = Path::new("tests")
        .join("icc")
        .join("icc_chunk_count_mismatch.jpeg");

    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    decoder.decode().unwrap();

    let profile = decoder.icc_profile();
    assert!(profile.is_none());
}
fn pragma_no_value() {
    let sql = "PRAGMA cache_size";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::Pragma {
            name,
            value: None,
            is_eq: false,
        } => {
            assert_eq!("cache_size", name.to_string());
        }
        _ => unreachable!(),
    }
}
fn f32_roundtrip_test() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let options = Options::builder().build().unwrap();
    for &float in F32_DATA.iter() {
        let count = unsafe { algorithm::write_float::<_, DECIMAL>(float, &mut buffer, &options) };
        let actual = unsafe { std::str::from_utf8_unchecked(&buffer[..count]) };
        let roundtrip = actual.parse::<f32>();
        assert_eq!(roundtrip, Ok(float));
    }
}
fn test_nested_implicit_some() {
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\n5"),
        Ok(Some(Some(Some(5))))
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\nNone"),
        Ok(None)
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\nSome(5)"),
        Ok(Some(Some(Some(5))))
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\nSome(None)"),
        Ok(Some(None))
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\nSome(Some(5))"),
        Ok(Some(Some(Some(5))))
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>("#![enable(implicit_some)]\nSome(Some(None))"),
        Ok(Some(Some(None)))
    );
    assert_eq!(
        ron::from_str::<Option<Option<Option<u32>>>>(
            "#![enable(implicit_some)]\nSome(Some(Some(5)))"
        ),
        Ok(Some(Some(Some(5))))
    );
}
fn test_strict_undefined() {
    let mut env = Environment::new();
    env.set_undefined_behavior(UndefinedBehavior::Strict);
    env.add_filter("test", |_state: &State, _value: String| -> String {
        panic!("filter must not be called");
    });

    assert_eq!(
        env.render_str("{{ true.missing_attribute }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(
        env.render_str("{{ undefined.missing_attribute }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(
        env.render_str("<{% for x in undefined %}...{% endfor %}>", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(
        env.render_str("<{{ undefined }}>", ()).unwrap_err().kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(render!(in env, "{{ undefined is undefined }}"), "true");
    assert_eq!(
        env.render_str("{{ undefined|list }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::InvalidOperation
    );
    assert_eq!(
        env.render_str("{{ undefined|test }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(
        env.render_str("{{ 42 in undefined }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
}
fn test_trailing_comma_tuple_struct() {
    assert!(from_str::<Tuple>("(1,2)").is_ok());
    assert!(from_str::<Tuple>("(1,2,)").is_ok());
    assert!(from_str::<Tuple>("(1,2,,)").is_err());
}
fn present_after_module_drop() -> Result<()> {
    let mut store = Store::<()>::default();
    let module = Module::new(store.engine(), r#"(func (export "foo") unreachable)"#)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let func = instance.get_typed_func::<(), ()>(&mut store, "foo")?;

    println!("asserting before we drop modules");
    assert_trap(func.call(&mut store, ()).unwrap_err());
    drop((instance, module));

    println!("asserting after drop");
    assert_trap(func.call(&mut store, ()).unwrap_err());
    return Ok(());

    fn assert_trap(t: Error) {
        println!("{:?}", t);
        let trace = t.downcast_ref::<WasmBacktrace>().unwrap().frames();
        assert_eq!(trace.len(), 1);
        assert_eq!(trace[0].func_index(), 0);
    }
}
fn test_conformance() {
    // Get the path to the proto-conformance binary. Adapted from
    // https://github.com/rust-lang/cargo/blob/19fdb308cdbb25faf4f1e25a71351d8d603fa447/tests/cargotest/support/mod.rs#L306.
    let proto_conformance = env::current_exe()
        .map(|mut path| {
            path.pop();
            if path.ends_with("deps") {
                path.pop();
            }
            path.join("conformance")
        })
        .unwrap();

    let status = Command::new(conformance::test_runner())
        .arg("--enforce_recommended")
        .arg("--failure_list")
        .arg("failing_tests.txt")
        .arg(proto_conformance)
        .status()
        .expect("failed to execute conformance-test-runner");

    assert!(status.success(), "proto conformance test failed");
}
fn test_nxdomain_where_no_name_exists() {
    named_test_harness("example.toml", |_, tcp_port, _, _, _| {
        let io_loop = Runtime::new().unwrap();
        let addr: SocketAddr = SocketAddr::new(
            Ipv4Addr::new(127, 0, 0, 1).into(),
            tcp_port.expect("no tcp_port"),
        );
        let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::new(addr);
        let client = AsyncClient::new(Box::new(stream), sender, None);
        let (mut client, bg) = io_loop.block_on(client).expect("client failed to connect");
        hickory_proto::spawn_bg(&io_loop, bg);

        let msg = io_loop
            .block_on(client.query(
                Name::from_str("nxdomain.example.com.").unwrap(),
                DNSClass::IN,
                RecordType::SRV,
            ))
            .unwrap();
        assert_eq!(msg.response_code(), ResponseCode::NXDomain);
        assert!(msg.answers().is_empty());
    })
}
fn parse_like() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that LIKE and NOT LIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = sqlite().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_du_basics_subdir() {
    let ts = TestScenario::new(util_name!());

    let result = ts.ucmd().arg(SUB_DIR).succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR]));
        if result_reference.succeeded() {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }
    _du_basics_subdir(result.stdout_str());
}
fn render_recursive_macro() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        (
            "macros",
            "{% macro factorial(n) %}{% if n > 1 %}{{ n }} - {{ self::factorial(n=n-1) }}{% else %}1{% endif %}{{ n }}{% endmacro factorial %}",
        ),
        ("hello.html", "{% import \"macros\" as macros %}{{macros::factorial(n=7)}}"),
    ]).unwrap();
    let result = tera.render("hello.html", &Context::new());

    assert_eq!(result.unwrap(), "7 - 6 - 5 - 4 - 3 - 2 - 11234567".to_string());
}
fn test_implicit_in_class() {
    let config = FileConfig {
        zone_file_path: "../../tests/test-data/test_configs/default/implicitclass.zone".to_string(),
    };

    let authority = FileAuthority::try_from_config(
        Name::from_str("example.com.").unwrap(),
        ZoneType::Primary,
        false,
        None,
        &config,
    );
    assert!(authority.is_ok());
}
async fn extended_connect_protocol_enabled_during_handshake() {
    h2_support::trace_init!();

    let (io, mut client) = mock::new();

    let client = async move {
        let settings = client.assert_server_handshake().await;

        assert_eq!(settings.is_extended_connect_protocol_enabled(), Some(true));

        client
            .send_frame(
                frames::headers(1)
                    .request("CONNECT", "http://bread/baguette")
                    .protocol("the-bread-protocol"),
            )
            .await;

        client.recv_frame(frames::headers(1).response(200)).await;
    };

    let srv = async move {
        let mut builder = server::Builder::new();

        builder.enable_connect_protocol();

        let mut srv = builder.handshake::<_, Bytes>(io).await.expect("handshake");

        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(
            req.extensions().get::<crate::ext::Protocol>(),
            Some(&crate::ext::Protocol::from_static("the-bread-protocol"))
        );

        let rsp = Response::new(());
        stream.send_response(rsp, false).unwrap();

        poll_fn(move |cx| srv.poll_closed(cx))
            .await
            .expect("server");
    };

    join(client, srv).await;
}
fn parse_alter_view() {
    let sql = "ALTER VIEW myschema.myview AS SELECT foo FROM bar";
    match verified_stmt(sql) {
        Statement::AlterView {
            name,
            columns,
            query,
            with_options,
        } => {
            assert_eq!("myschema.myview", name.to_string());
            assert_eq!(Vec::<Ident>::new(), columns);
            assert_eq!("SELECT foo FROM bar", query.to_string());
            assert_eq!(with_options, vec![]);
        }
        _ => unreachable!(),
    }
}
fn test_char() {
    let ch = '.';
    let yaml = indoc! {"
        '.'
    "};
    assert_eq!(yaml, serde_yaml::to_string(&ch).unwrap());

    let ch = '#';
    let yaml = indoc! {"
        '#'
    "};
    assert_eq!(yaml, serde_yaml::to_string(&ch).unwrap());

    let ch = '-';
    let yaml = indoc! {"
        '-'
    "};
    assert_eq!(yaml, serde_yaml::to_string(&ch).unwrap());
}
fn test_raw_put_deadline() {
    let deadline_fp = "deadline_check_fail";
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();
    let region = cluster.get_region(b"");
    let leader = region.get_peers()[0].clone();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let mut put_req = RawPutRequest::default();
    put_req.set_context(ctx);
    put_req.key = b"k3".to_vec();
    put_req.value = b"v3".to_vec();
    fail::cfg(deadline_fp, "return()").unwrap();
    let put_resp = client.raw_put(&put_req).unwrap();
    assert!(put_resp.has_region_error(), "{:?}", put_resp);
    must_get_none(&cluster.get_engine(1), b"k3");

    fail::remove(deadline_fp);
    let put_resp = client.raw_put(&put_req).unwrap();
    assert!(!put_resp.has_region_error(), "{:?}", put_resp);
    must_get_equal(&cluster.get_engine(1), b"k3", b"v3");
}
fn test_no_infix_error() {
    let dialects = TestedDialects {
        dialects: vec![Box::new(ClickHouseDialect {})],
        options: None,
    };

    let res = dialects.parse_sql_statements("ASSERT-URA<<");
    assert_eq!(
        ParserError::ParserError("No infix parser for token ShiftLeft".to_string()),
        res.unwrap_err()
    );
}
fn issue567() {
    #[derive(Debug, Deserialize, PartialEq)]
    struct Root {
        #[serde(rename = "$value")]
        items: Vec<Enum>,
    }

    #[derive(Debug, Deserialize, PartialEq)]
    enum Enum {
        List(Vec<()>),
    }

    assert_eq!(
        from_str::<Root>("<root><List/></root>").unwrap(),
        Root {
            items: vec![Enum::List(vec![])],
        }
    );
}
fn parse_create_schema() {
    let sql = "CREATE SCHEMA X";

    match verified_stmt(sql) {
        Statement::CreateSchema { schema_name, .. } => {
            assert_eq!(schema_name.to_string(), "X".to_owned())
        }
        _ => unreachable!(),
    }
}
fn test_touch_set_both_offset_date_and_reference() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ref_file = "test_touch_reference";
    let file = "test_touch_set_both_date_and_reference";

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501011234");
    let five_days_later = str_to_filetime("%Y%m%d%H%M", "201501061234");

    at.touch(ref_file);
    set_file_times(&at, ref_file, start_of_year, start_of_year);
    assert!(at.file_exists(ref_file));

    ucmd.args(&["-d", "+5 days", "-r", ref_file, file])
        .succeeds()
        .no_stderr();
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, five_days_later);
    assert_eq!(mtime, five_days_later);
}
fn client_can_override_certificate_verification_and_reject_tls12_signatures() {
    for kt in ALL_KEY_TYPES.iter() {
        let mut client_config = make_client_config_with_versions(*kt, &[&rustls::version::TLS12]);
        let verifier = Arc::new(MockServerVerifier::rejects_tls12_signatures(
            Error::InvalidMessage(InvalidMessage::HandshakePayloadTooLarge),
        ));

        client_config
            .dangerous()
            .set_certificate_verifier(verifier);

        let server_config = Arc::new(make_server_config(*kt));

        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        let errs = do_handshake_until_both_error(&mut client, &mut server);
        assert_eq!(
            errs,
            Err(vec![
                ErrorFromPeer::Client(Error::InvalidMessage(
                    InvalidMessage::HandshakePayloadTooLarge,
                )),
                ErrorFromPeer::Server(Error::AlertReceived(AlertDescription::HandshakeFailure)),
            ]),
        );
    }
}
fn dynamic_add3_works() {
    let (mut store, add3, add3_dyn) = setup_add3();
    for a in 0..5 {
        for b in 0..5 {
            for c in 0..5 {
                let params = [Value::I32(a), Value::I32(b), Value::I32(c)];
                let expected = a + b + c;
                let mut result = Value::I32(0);
                // Call to Func with statically typed closure.
                add3.call(&mut store, &params, slice::from_mut(&mut result))
                    .unwrap();
                assert_eq!(result.i32(), Some(expected));
                // Reset result before execution.
                result = Value::I32(0);
                // Call to Func with dynamically typed closure.
                add3_dyn
                    .call(&mut store, &params, slice::from_mut(&mut result))
                    .unwrap();
                assert_eq!(result.i32(), Some(expected));
            }
        }
    }
}
fn test_du_soft_link() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    at.symlink_file(SUB_FILE, SUB_LINK);

    let result = ts.ucmd().arg(SUB_DIR_LINKS).succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &[SUB_DIR_LINKS]));
        if result_reference.succeeded() {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }
    _du_soft_link(result.stdout_str());
}
fn test_validate_endpoints() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(Split::new()));
    let env = Arc::new(
        EnvBuilder::new()
            .cq_count(1)
            .name_prefix(thd_name!("test-pd"))
            .build(),
    );
    let eps = server.bind_addrs();

    let mgr = Arc::new(SecurityManager::new(&SecurityConfig::default()).unwrap());
    let connector = PdConnector::new(env, mgr);
    assert!(block_on(connector.validate_endpoints(&new_config(eps), true)).is_err());
}
fn TinyVec_std_io_write() {
  use std::io::Write;
  let mut tv: TinyVec<[u8; 3]> = TinyVec::new();

  tv.write_all(b"foo").ok();
  assert!(tv.is_inline());
  assert_eq!(tv, tiny_vec![b'f', b'o', b'o']);

  tv.write_all(b"bar").ok();
  assert!(tv.is_heap());
  assert_eq!(tv, tiny_vec![b'f', b'o', b'o', b'b', b'a', b'r']);
}
async fn send_recv_headers_only() {
    h2_support::trace_init!();

    let mock = mock_io::Builder::new()
        .handshake()
        // Write GET /
        .write(&[
            0, 0, 0x10, 1, 5, 0, 0, 0, 1, 0x82, 0x87, 0x41, 0x8B, 0x9D, 0x29, 0xAC, 0x4B, 0x8F,
            0xA8, 0xE9, 0x19, 0x97, 0x21, 0xE9, 0x84,
        ])
        .write(frames::SETTINGS_ACK)
        // Read response
        .read(&[0, 0, 1, 1, 5, 0, 0, 0, 1, 0x89])
        .build();

    let (mut client, mut h2) = client::handshake(mock).await.unwrap();

    // Send the request
    let request = Request::builder()
        .uri("https://http2.akamai.com/")
        .body(())
        .unwrap();

    tracing::info!("sending request");
    let (response, _) = client.send_request(request, true).unwrap();

    let resp = h2.run(response).await.unwrap();
    assert_eq!(resp.status(), StatusCode::NO_CONTENT);

    h2.await.unwrap();
}
fn test_cp_backup_simple_protect_source() {
    let (at, mut ucmd) = at_and_ucmd!();
    let source = format!("{TEST_HELLO_WORLD_SOURCE}~");
    at.touch(&source);
    ucmd.arg("--backup=simple")
        .arg(&source)
        .arg(TEST_HELLO_WORLD_SOURCE)
        .fails()
        .stderr_only(format!(
            "cp: backing up '{TEST_HELLO_WORLD_SOURCE}' might destroy source;  '{source}' not copied\n",
        ));

    assert_eq!(at.read(TEST_HELLO_WORLD_SOURCE), "Hello, World!\n");
    assert_eq!(at.read(&source), "");
}
fn test_touch_set_mdhm_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_mdhm_time";

    ucmd.args(&["-t", "01011234", file]).succeeds().no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime(
        "%Y%m%d%H%M",
        &format!("{}01010000", time::OffsetDateTime::now_utc().year()),
    );
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);
}
fn check_extend_safe_fixes() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
extend-safe-fixes = ["F601"]
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["check", "--config"])
        .arg(&ruff_toml)
        .arg("-")
        .args([
            "--output-format",
            "text",
            "--no-cache",
            "--select",
            "F601,UP034",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 [*] Dictionary key literal `'a'` repeated
    -:2:7: UP034 [*] Avoid extraneous parentheses
    Found 2 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);

    Ok(())
}
fn exit2_wasi_snapshot0() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit2_wasi_snapshot0.wat")?;
    let output = run_wasmtime_for_output(&["-Ccache=n", wasm.path().to_str().unwrap()], None)?;
    assert_eq!(output.status.code().unwrap(), 2);
    Ok(())
}
fn test_install_backup_long_no_args_file_to_dir() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file = "test_install_simple_backup_file_a";
    let dest_dir = "test_install_dest/";
    let expect = format!("{dest_dir}{file}");

    at.touch(file);
    at.mkdir(dest_dir);
    at.touch(&expect);
    scene
        .ucmd()
        .arg("--backup")
        .arg(file)
        .arg(dest_dir)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));
    assert!(at.file_exists(&expect));
    assert!(at.file_exists(format!("{expect}~")));
}
fn roundtrip_pretty() {
    let value = Struct {
        tuple: ((), NewType(0.5), TupleStruct(UnitStruct, -5)),
        vec: vec![None, Some(UnitStruct)],
        map: vec![
            (Key(5), Enum::Unit),
            (Key(6), Enum::Bool(false)),
            (Key(7), Enum::Bool(true)),
            (Key(9), Enum::Chars('x', "".to_string())),
        ]
        .into_iter()
        .collect(),
    };

    let pretty = ron::ser::PrettyConfig::new()
        .enumerate_arrays(true)
        .extensions(Extensions::IMPLICIT_SOME);
    let serial = ron::ser::to_string_pretty(&value, pretty).unwrap();

    println!("Serialized: {}", serial);

    let deserial = ron::de::from_str(&serial);

    assert_eq!(Ok(value), deserial);
}
fn test_unsafe_recovery_auto_promote_learner() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    let peer_on_store0 = find_peer(&region, nodes[0]).unwrap();
    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    // replace one peer with learner
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store0.clone());
    cluster.pd_client.must_add_peer(
        region.get_id(),
        new_learner_peer(nodes[0], peer_on_store0.get_id()),
    );
    // Sleep 100 ms to wait for the new learner to be initialized.
    sleep_ms(100);
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);

    confirm_quorum_is_lost(&mut cluster, &region);
    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    let to_be_removed: Vec<metapb::Peer> = region
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    let mut demoted = true;
    let mut promoted = false;
    for _ in 0..10 {
        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

        promoted = region
            .get_peers()
            .iter()
            .find(|peer| peer.get_store_id() == nodes[0])
            .unwrap()
            .get_role()
            == metapb::PeerRole::Voter;

        demoted = region
            .get_peers()
            .iter()
            .filter(|peer| peer.get_store_id() != nodes[0])
            .all(|peer| peer.get_role() == metapb::PeerRole::Learner);
        if demoted && promoted {
            break;
        }
        sleep_ms(100);
    }
    assert!(demoted);
    assert!(promoted);
}
fn extension_alias_3() {
    let f = super::fixture().join("exports-field-and-extension-alias");

    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into()],
        extension_alias: vec![(
            ".js".into(),
            vec![".foo".into(), ".baz".into(), ".baz".into(), ".ts".into(), ".js".into()],
        )],
        fully_specified: true,
        condition_names: vec!["webpack".into(), "default".into()],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("should resolve with the `extensionAlias` option #3", f.clone(), "pkg/string.js", f.join("node_modules/pkg/dist/string.js")),
    ];

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn test_get_tombstone_stores() {
    let eps_count = 1;
    let server = MockServer::new(eps_count);
    let eps = server.bind_addrs();
    let client = new_client(eps, None);

    let mut all_stores = vec![];
    let store_id = client.alloc_id().unwrap();
    let mut store = metapb::Store::default();
    store.set_id(store_id);
    let region_id = client.alloc_id().unwrap();
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    client.bootstrap_cluster(store.clone(), region).unwrap();

    all_stores.push(store);
    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);
    let s = client.get_all_stores(false).unwrap();
    assert_eq!(s, all_stores);

    // Add tombstone store.
    let mut store99 = metapb::Store::default();
    store99.set_id(99);
    store99.set_state(metapb::StoreState::Tombstone);
    server.default_handler().add_store(store99.clone());

    // do not include tombstone.
    let s = client.get_all_stores(true).unwrap();
    assert_eq!(s, all_stores);

    all_stores.push(store99.clone());
    all_stores.sort_by_key(|a| a.get_id());
    // include tombstone, there should be 2 stores.
    let mut s = client.get_all_stores(false).unwrap();
    s.sort_by_key(|a| a.get_id());
    assert_eq!(s, all_stores);

    // Add another tombstone store.
    let mut store199 = store99;
    store199.set_id(199);
    server.default_handler().add_store(store199.clone());

    all_stores.push(store199);
    all_stores.sort_by_key(|a| a.get_id());
    let mut s = client.get_all_stores(false).unwrap();
    s.sort_by_key(|a| a.get_id());
    assert_eq!(s, all_stores);

    client.get_store(store_id).unwrap();
    client.get_store(99).unwrap_err();
    client.get_store(199).unwrap_err();
}
fn test_unit_struct_name_mismatch() {
    assert_eq!(ron::from_str::<MyUnitStruct>("()"), Ok(MyUnitStruct),);
    assert_eq!(
        ron::from_str::<MyUnitStruct>("MyUnitStruct"),
        Ok(MyUnitStruct),
    );
    assert_eq!(
        ron::from_str::<MyUnitStruct>("MyUnit Struct"),
        Err(SpannedError {
            code: Error::ExpectedDifferentStructName {
                expected: "MyUnitStruct",
                found: String::from("MyUnit")
            },
            position: Position { line: 1, col: 7 }
        }),
    );
    assert_eq!(
        ron::from_str::<MyUnitStruct>("42"),
        Err(SpannedError {
            code: Error::ExpectedNamedStructLike("MyUnitStruct"),
            position: Position { line: 1, col: 1 }
        }),
    );
}
fn parse_collate_after_parens() {
    let sql = "SELECT (name) COLLATE \"de_DE\" FROM customer";
    assert_matches!(
        only(&all_dialects().verified_only_select(sql).projection),
        SelectItem::UnnamedExpr(Expr::Collate { .. })
    );
}
fn dtor_runs() {
    static HITS: AtomicUsize = AtomicUsize::new(0);

    struct A;

    impl Drop for A {
        fn drop(&mut self) {
            HITS.fetch_add(1, SeqCst);
        }
    }

    let mut store = Store::<()>::default();
    let a = A;
    assert_eq!(HITS.load(SeqCst), 0);
    Func::wrap(&mut store, move || {
        let _ = &a;
    });
    drop(store);
    assert_eq!(HITS.load(SeqCst), 1);
}
fn test_split_number_chunks_short_concatenated_with_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n3", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "a");
    assert_eq!(at.read("xab"), "b");
    assert_eq!(at.read("xac"), "c");
}
fn ignore_vcs_ignored_file() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = r#"{
        "vcs": {
            "enabled": true,
            "clientKind": "git",
            "useIgnoreFile": true
        }
    }"#;

    let git_ignore = r#"
file2.js
"#;

    let code2 = r#"foo.call(); bar.call();"#;
    let code1 = r#"array.map(sentence => sentence.split(' ')).flat();"#;

    // ignored files
    let file_path1 = Path::new("file1.js");
    fs.insert(file_path1.into(), code1.as_bytes());
    let file_path2 = Path::new("file2.js");
    fs.insert(file_path2.into(), code2.as_bytes());

    // configuration
    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), rome_json.as_bytes());

    // git ignore file
    let ignore_file = Path::new(".gitignore");
    fs.insert(ignore_file.into(), git_ignore.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                file_path1.as_os_str().to_str().unwrap(),
                file_path2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ignore_vcs_ignored_file",
        fs,
        console,
        result,
    ));
}
fn test_inf_and_nan() {
    assert_eq!(from_str("inf"), Ok(std::f64::INFINITY));
    assert_eq!(from_str("-inf"), Ok(std::f64::NEG_INFINITY));
    assert_eq!(from_str::<f64>("NaN").map(|n| n.is_nan()), Ok(true))
}
fn parse_filter_section_with_args() {
    let ast = parse("{% filter upper(attr=1) -%}A{%- endfilter %}").unwrap();
    let start_ws = WS { right: true, ..Default::default() };
    let end_ws = WS { left: true, ..Default::default() };

    let mut args = HashMap::new();
    args.insert("attr".to_string(), Expr::new(ExprVal::Int(1)));

    assert_eq!(
        ast[0],
        Node::FilterSection(
            start_ws,
            FilterSection {
                filter: FunctionCall { name: "upper".to_string(), args },
                body: vec![Node::Text("A".to_string())],
            },
            end_ws,
        )
    );
}
fn simple() -> Result<()> {
    let component = r#"
        (component
            (import "a" (func $log (param "a" string)))

            (core module $libc
                (memory (export "memory") 1)

                (func (export "realloc") (param i32 i32 i32 i32) (result i32)
                    unreachable)
            )
            (core instance $libc (instantiate $libc))
            (core func $log_lower
                (canon lower (func $log) (memory $libc "memory") (realloc (func $libc "realloc")))
            )
            (core module $m
                (import "libc" "memory" (memory 1))
                (import "host" "log" (func $log (param i32 i32)))

                (func (export "call")
                    i32.const 5
                    i32.const 11
                    call $log)

                (data (i32.const 5) "hello world")
            )
            (core instance $i (instantiate $m
                (with "libc" (instance $libc))
                (with "host" (instance (export "log" (func $log_lower))))
            ))
            (func (export "call")
                (canon lift (core func $i "call"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, None);
    assert!(store.data().is_none());

    // First, test the static API

    let mut linker = Linker::new(&engine);
    linker.root().func_wrap(
        "a",
        |mut store: StoreContextMut<'_, Option<String>>, (arg,): (WasmStr,)| -> Result<_> {
            let s = arg.to_str(&store)?.to_string();
            assert!(store.data().is_none());
            *store.data_mut() = Some(s);
            Ok(())
        },
    )?;
    let instance = linker.instantiate(&mut store, &component)?;
    instance
        .get_typed_func::<(), ()>(&mut store, "call")?
        .call(&mut store, ())?;
    assert_eq!(store.data().as_ref().unwrap(), "hello world");

    // Next, test the dynamic API

    *store.data_mut() = None;
    let mut linker = Linker::new(&engine);
    linker.root().func_new(
        &component,
        "a",
        |mut store: StoreContextMut<'_, Option<String>>, args, _results| {
            if let Val::String(s) = &args[0] {
                assert!(store.data().is_none());
                *store.data_mut() = Some(s.to_string());
                Ok(())
            } else {
                panic!()
            }
        },
    )?;
    let instance = linker.instantiate(&mut store, &component)?;
    instance
        .get_func(&mut store, "call")
        .unwrap()
        .call(&mut store, &[], &mut [])?;
    assert_eq!(store.data().as_ref().unwrap(), "hello world");

    Ok(())
}
fn test_chained_cname_lookup() {
    let resp_query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let cname_record = cname_record(
        Name::from_str("www.example.com.").unwrap(),
        Name::from_str("v4.example.com.").unwrap(),
    );
    let v4_record = v4_record(
        Name::from_str("v4.example.com.").unwrap(),
        Ipv4Addr::new(93, 184, 216, 34),
    );

    // The first response should be a cname, the second will be the actual record
    let message1 = message(resp_query.clone(), vec![cname_record], vec![], vec![]);
    let message2 = message(resp_query, vec![v4_record], vec![], vec![]);

    // the mock pops messages...
    let client: MockClientHandle<_, ResolveError> = MockClientHandle::mock(vec![
        Ok(DnsResponse::from_message(message2).unwrap()),
        Ok(DnsResponse::from_message(message1).unwrap()),
    ]);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, false),
    );

    let io_loop = Runtime::new().unwrap();
    let lookup = io_loop.block_on(lookup).unwrap();

    assert_eq!(
        *lookup.iter().next().unwrap(),
        RData::A(A::new(93, 184, 216, 34))
    );
}
fn test_mv_numbered_if_existing_backup_existing() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";
    let file_b_backup = "test_mv_backup_numbering_file_b.~1~";

    at.touch(file_a);
    at.touch(file_b);
    at.touch(file_b_backup);
    ucmd.arg("--backup=existing")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_b));
    assert!(at.file_exists(file_b_backup));
    assert!(at.file_exists(format!("{file_b}.~2~")));
}
fn instantiate() -> Result<(), Error> {
    let mut store = Store::<State>::default();
    store.call_hook(State::call_hook);

    let m = Module::new(store.engine(), "(module)")?;
    Instance::new(&mut store, &m, &[])?;
    assert_eq!(store.data().calls_into_wasm, 0);
    assert_eq!(store.data().calls_into_host, 0);

    let m = Module::new(store.engine(), "(module (func) (start 0))")?;
    Instance::new(&mut store, &m, &[])?;
    assert_eq!(store.data().calls_into_wasm, 1);
    assert_eq!(store.data().calls_into_host, 0);

    Ok(())
}
fn test_ingest_sst() {
    let mut cfg = TikvConfig::default();
    cfg.server.grpc_concurrency = 1;
    let (_cluster, ctx, _tikv, import) = open_cluster_and_tikv_import_client(Some(cfg));

    let temp_dir = Builder::new().prefix("test_ingest_sst").tempdir().unwrap();

    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);

    // No region id and epoch.
    send_upload_sst(&import, &meta, &data).unwrap();

    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.set_sst(meta.clone());
    let resp = import.ingest(&ingest).unwrap();
    assert!(resp.has_error());

    // Set region id and epoch.
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());
    send_upload_sst(&import, &meta, &data).unwrap();
    // Can't upload the same file again.
    assert_to_string_contains!(
        send_upload_sst(&import, &meta, &data).unwrap_err(),
        "FileExists"
    );

    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error(), "{:?}", resp.get_error());
}
fn parse_like() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that LIKE and NOT LIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn encode_all_bytes_url() {
    let bytes: Vec<u8> = (0..=255).collect();

    assert_eq!(
        "AAECAwQFBgcICQoLDA0ODxAREhMUFRYXGBkaGxwdHh8gISIjJCUmJygpKissLS4vMDEyMzQ1Njc4OTo7PD0\
         -P0BBQkNERUZHSElKS0xNTk9QUVJTVFVWV1hZWltcXV5fYGFiY2RlZmdoaWprbG1ub3BxcnN0dXZ3eHl6e3x9fn\
         -AgYKDhIWGh4iJiouMjY6PkJGSk5SVlpeYmZqbnJ2en6ChoqOkpaanqKmqq6ytrq\
         -wsbKztLW2t7i5uru8vb6_wMHCw8TFxsfIycrLzM3Oz9DR0tPU1dbX2Nna29zd3t_g4eLj5OXm5-jp6uvs7e7v8PHy\
         8_T19vf4-fr7_P3-_w==",
        &engine::GeneralPurpose::new(&URL_SAFE, PAD).encode(bytes)
    );
}
fn test_install_nested_paths_copy_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "source_file";
    let dir1 = "source_dir";
    let dir2 = "target_dir";

    at.mkdir(dir1);
    at.mkdir(dir2);
    at.touch(format!("{dir1}/{file1}"));

    ucmd.arg(format!("{dir1}/{file1}"))
        .arg(dir2)
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(format!("{dir2}/{file1}")));
}
fn test_reboot() {
    let eps_count = 1;
    let server = MockServer::with_case(eps_count, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();
    let mut client = new_client_v2(eps, None);

    assert!(!client.is_cluster_bootstrapped().unwrap());

    match client.bootstrap_cluster(metapb::Store::default(), metapb::Region::default()) {
        Err(PdError::ClusterBootstrapped(_)) => (),
        _ => {
            panic!("failed, should return ClusterBootstrapped");
        }
    }
}
fn valid_context_directory_recursive_follow_all_symlinks() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.mkdir("a");
    dir.symlink_dir("a", "la");

    let b_path = Path::new("a").join("b.txt");
    dir.touch(b_path.to_str().unwrap());

    let c_path = Path::new("a").join("c");
    dir.touch(c_path.to_str().unwrap());

    let lc_path = Path::new("a").join("lc");
    dir.symlink_dir(c_path.to_str().unwrap(), lc_path.to_str().unwrap());

    let la_context = get_file_context(dir.plus("la")).unwrap();
    let lc_context = get_file_context(dir.plus(lc_path.to_str().unwrap())).unwrap();

    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    // -L: traverse every symbolic link to a directory encountered.
    cmd.args(&["--verbose", "--recursive", "-L", new_la_context])
        .arg(dir.plus("la"))
        .succeeds();
    assert_eq!(get_file_context(dir.plus("la")).unwrap(), la_context);
    assert_eq!(
        get_file_context(dir.plus("a")).unwrap().as_deref(),
        Some(new_la_context)
    );
    assert_eq!(
        get_file_context(dir.plus(b_path.to_str().unwrap()))
            .unwrap()
            .as_deref(),
        Some(new_la_context)
    );
    assert_eq!(
        get_file_context(dir.plus(lc_path.to_str().unwrap())).unwrap(),
        lc_context
    );
    assert_eq!(
        get_file_context(dir.plus(c_path.to_str().unwrap()))
            .unwrap()
            .as_deref(),
        Some(new_la_context)
    );
}
fn TinyVec_try_move_to_heap_and_shrink() {
  let mut tv: TinyVec<[i32; 4]> = Default::default();
  assert!(tv.is_inline());
  assert!(tv.try_move_to_the_heap().is_ok());
  assert!(tv.is_heap());
  assert_eq!(tv.capacity(), 0);

  assert!(tv.try_reserve_exact(1).is_ok());
  assert_eq!(tv.capacity(), 1);
  tv.push(1);
  tv.shrink_to_fit();
  assert!(tv.is_inline());
  assert_eq!(tv.capacity(), 4);

  assert!(tv.try_move_to_the_heap_and_reserve(3).is_ok());
  assert!(tv.is_heap());
  assert_eq!(tv.capacity(), 4);
  tv.extend(2..=4);
  assert_eq!(tv.capacity(), 4);
  assert_eq!(tv.as_slice(), [1, 2, 3, 4]);
}
fn test_key_is_locked_for_index() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = init_data_with_commit(&product, &data, false);

    let req = DagSelect::from_index(&product, &product["name"]).build();
    let resp = handle_request(&endpoint, req);
    assert!(resp.get_data().is_empty(), "{:?}", resp);
    assert!(resp.has_locked(), "{:?}", resp);
}
fn fs_error_read_only() {
    let mut fs = MemoryFileSystem::new_read_only();
    let mut console = BufferConsole::default();

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), *b"content");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Do not store the content of the file in the snapshot
    fs.remove(file_path);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_read_only",
        fs,
        console,
        result,
    ));
}
fn handle_ws_for_if_nodes() {
    let end_ws = WS { left: false, right: true };
    let ast = vec![
        Node::Text("C ".to_string()),
        Node::If(
            If {
                conditions: vec![
                    (
                        WS { left: true, right: true },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                    (
                        WS { left: true, right: false },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                    (
                        WS { left: true, right: true },
                        Expr::new(ExprVal::Int(1)),
                        vec![Node::Text(" a ".to_string())],
                    ),
                ],
                otherwise: None,
            },
            end_ws,
        ),
        Node::Text("  hey".to_string()),
    ];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![
            Node::Text("C".to_string()),
            Node::If(
                If {
                    conditions: vec![
                        (
                            WS { left: true, right: true },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text("a".to_string())],
                        ),
                        (
                            WS { left: true, right: false },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text(" a".to_string())],
                        ),
                        (
                            WS { left: true, right: true },
                            Expr::new(ExprVal::Int(1)),
                            vec![Node::Text("a ".to_string())],
                        ),
                    ],
                    otherwise: None,
                },
                end_ws,
            ),
            Node::Text("hey".to_string()),
        ]
    );
}
fn test_create_stage_with_stage_params() {
    let sql = concat!(
        "CREATE OR REPLACE STAGE my_ext_stage ",
        "URL='s3://load/files/' ",
        "STORAGE_INTEGRATION=myint ",
        "ENDPOINT='<s3_api_compatible_endpoint>' ",
        "CREDENTIALS=(AWS_KEY_ID='1a2b3c' AWS_SECRET_KEY='4x5y6z') ",
        "ENCRYPTION=(MASTER_KEY='key' TYPE='AWS_SSE_KMS')"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CreateStage { stage_params, .. } => {
            assert_eq!("s3://load/files/", stage_params.url.unwrap());
            assert_eq!("myint", stage_params.storage_integration.unwrap());
            assert_eq!(
                "<s3_api_compatible_endpoint>",
                stage_params.endpoint.unwrap()
            );
            assert!(stage_params
                .credentials
                .options
                .contains(&DataLoadingOption {
                    option_name: "AWS_KEY_ID".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "1a2b3c".to_string()
                }));
            assert!(stage_params
                .credentials
                .options
                .contains(&DataLoadingOption {
                    option_name: "AWS_SECRET_KEY".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "4x5y6z".to_string()
                }));
            assert!(stage_params
                .encryption
                .options
                .contains(&DataLoadingOption {
                    option_name: "MASTER_KEY".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "key".to_string()
                }));
            assert!(stage_params
                .encryption
                .options
                .contains(&DataLoadingOption {
                    option_name: "TYPE".to_string(),
                    option_type: DataLoadingOptionType::STRING,
                    value: "AWS_SSE_KMS".to_string()
                }));
        }
        _ => unreachable!(),
    };

    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn weak_map_multiple() {
    run_test(|| {
        let key1 = Gc::new(String::from("key1"));
        let key2 = Gc::new(String::from("key2"));
        let key3 = Gc::new(String::from("key3"));

        assert!(!has_weak_maps());

        let mut map_1 = WeakMap::new();
        let mut map_2 = WeakMap::new();

        assert!(has_weak_maps());

        map_1.insert(&key1, ());
        map_1.insert(&key2, ());
        map_2.insert(&key3, ());

        force_collect();
        assert!(has_weak_maps());

        assert!(map_1.contains_key(&key1));
        assert!(map_1.contains_key(&key2));
        assert!(!map_1.contains_key(&key3));
        assert!(!map_2.contains_key(&key1));
        assert!(!map_2.contains_key(&key2));
        assert!(map_2.contains_key(&key3));

        force_collect();
        assert!(has_weak_maps());

        drop(key1);
        drop(key2);

        force_collect();
        assert!(has_weak_maps());

        assert!(!map_1.contains_key(&key3));
        assert!(map_2.contains_key(&key3));

        drop(key3);

        force_collect();
        assert!(has_weak_maps());

        drop(map_1);

        force_collect();
        assert!(has_weak_maps());

        drop(map_2);

        force_collect();
        assert!(!has_weak_maps());
    });
}
fn test_invalid_external_storage() {
    let mut suite = TestSuite::new(1, 144 * 1024 * 1024, ApiVersion::V1);
    // Put some data.
    suite.must_kv_put(3, 1);

    // Set backup directory read-only. TiKV fails to backup.
    let tmp = Builder::new().tempdir().unwrap();
    let f = File::open(tmp.path()).unwrap();
    let mut perms = f.metadata().unwrap().permissions();
    perms.set_readonly(true);
    f.set_permissions(perms.clone()).unwrap();

    let backup_ts = suite.alloc_ts();
    let storage_path = tmp.path();
    let rx = suite.backup(
        vec![],   // start
        vec![],   // end
        0.into(), // begin_ts
        backup_ts,
        storage_path,
    );

    // Wait util the backup request is handled.
    let resps = block_on(rx.collect::<Vec<_>>());
    assert!(resps[0].has_error());

    perms.set_readonly(false);
    f.set_permissions(perms).unwrap();

    suite.stop();
}
fn write_batch_write_twice_3() {
    let db = default_engine();

    let mut wb = db.engine.write_batch();

    wb.put(b"a", b"aa").unwrap();

    wb.write().unwrap();
    db.engine.put(b"a", b"b").unwrap();
    wb.put(b"b", b"bb").unwrap();
    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");
    assert_eq!(db.engine.get_value(b"b").unwrap().unwrap(), b"bb");

    let db = multi_batch_write_engine();

    let mut wb = db.engine.write_batch_with_cap(1024);

    for i in 0..128_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"aa").unwrap();

    wb.write().unwrap();
    for i in 0..128_usize {
        let k = i.to_be_bytes();
        let v = (2 * i + 1).to_be_bytes();
        db.engine.put(&k, &v).unwrap();
    }
    db.engine.put(b"a", b"b").unwrap();
    for i in 128..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"b", b"bb").unwrap();
    wb.write().unwrap();

    assert_eq!(db.engine.get_value(b"a").unwrap().unwrap(), b"aa");
    assert_eq!(db.engine.get_value(b"b").unwrap().unwrap(), b"bb");
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        assert_eq!(db.engine.get_value(&x).unwrap().unwrap(), &x);
    }
}
fn render_raw_tag() {
    let inputs = vec![
        ("{% raw %}hey{% endraw %}", "hey"),
        ("{% raw %}{{hey}}{% endraw %}", "{{hey}}"),
        ("{% raw %}{% if true %}{% endraw %}", "{% if true %}"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &Context::new()).unwrap(), expected);
    }
}
async fn call_linked_func_async() -> Result<(), Error> {
    let mut config = Config::new();
    config.async_support(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, State::default());
    store.call_hook(State::call_hook);

    let f = Func::wrap4_async(
        &mut store,
        |caller: Caller<State>, a: i32, b: i64, c: f32, d: f64| {
            Box::new(async move {
                // Calling this func will switch context into wasm, then back to host:
                assert_eq!(caller.data().context, vec![Context::Wasm, Context::Host]);

                assert_eq!(
                    caller.data().calls_into_host,
                    caller.data().returns_from_host + 1
                );
                assert_eq!(
                    caller.data().calls_into_wasm,
                    caller.data().returns_from_wasm + 1
                );
                assert_eq!(a, 1);
                assert_eq!(b, 2);
                assert_eq!(c, 3.0);
                assert_eq!(d, 4.0);
            })
        },
    );

    let mut linker = Linker::new(&engine);

    linker.define(&mut store, "host", "f", f)?;

    let wat = r#"
        (module
            (import "host" "f"
                (func $f (param i32) (param i64) (param f32) (param f64)))
            (func (export "export")
                (call $f (i32.const 1) (i64.const 2) (f32.const 3.0) (f64.const 4.0)))
        )
    "#;
    let module = Module::new(&engine, wat)?;

    let inst = linker.instantiate_async(&mut store, &module).await?;
    let export = inst
        .get_export(&mut store, "export")
        .expect("get export")
        .into_func()
        .expect("export is func");

    export.call_async(&mut store, &[], &mut []).await?;

    // One switch from vm to host to call f, another in return from f.
    assert_eq!(store.data().calls_into_host, 1);
    assert_eq!(store.data().returns_from_host, 1);
    assert_eq!(store.data().calls_into_wasm, 1);
    assert_eq!(store.data().returns_from_wasm, 1);

    export
        .typed::<(), ()>(&store)?
        .call_async(&mut store, ())
        .await?;

    assert_eq!(store.data().calls_into_host, 2);
    assert_eq!(store.data().returns_from_host, 2);
    assert_eq!(store.data().calls_into_wasm, 2);
    assert_eq!(store.data().returns_from_wasm, 2);

    Ok(())
}
fn test_read_after_peer_destroyed() {
    let mut cluster = new_node_cluster(0, 3);
    let pd_client = cluster.pd_client.clone();
    // Disable default max peer number check.
    pd_client.disable_default_operator();
    let r1 = cluster.run_conf_change();

    // Add 2 peers.
    for i in 2..4 {
        pd_client.must_add_peer(r1, new_peer(i, i));
    }

    // Make sure peer 1 leads the region.
    cluster.must_transfer_leader(r1, new_peer(1, 1));
    let (key, value) = (b"k1", b"v1");
    cluster.must_put(key, value);
    assert_eq!(cluster.get(key), Some(value.to_vec()));

    let destroy_peer_fp = "destroy_peer";
    fail::cfg(destroy_peer_fp, "pause").unwrap();
    pd_client.must_remove_peer(r1, new_peer(1, 1));
    sleep_ms(300);

    // Try writing k2 to peer3
    let mut request = new_request(
        r1,
        cluster.pd_client.get_region_epoch(r1),
        vec![new_get_cmd(b"k1")],
        false,
    );
    request.mut_header().set_peer(new_peer(1, 1));
    let (cb, mut rx) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, request, cb)
        .unwrap();
    // Wait for raftstore receives the read request.
    sleep_ms(200);
    fail::remove(destroy_peer_fp);

    let resp = rx.recv_timeout(Duration::from_millis(200)).unwrap();
    assert!(
        resp.get_header().get_error().has_region_not_found(),
        "{:?}",
        resp
    );
}
fn test_short_numeric_suffix_no_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-l", "9", "-d", "onehundredlines.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x00"), "00\n01\n02\n03\n04\n05\n06\n07\n08\n");
    assert_eq!(at.read("x01"), "09\n10\n11\n12\n13\n14\n15\n16\n17\n");
    assert_eq!(at.read("x02"), "18\n19\n20\n21\n22\n23\n24\n25\n26\n");
    assert_eq!(at.read("x03"), "27\n28\n29\n30\n31\n32\n33\n34\n35\n");
    assert_eq!(at.read("x04"), "36\n37\n38\n39\n40\n41\n42\n43\n44\n");
    assert_eq!(at.read("x05"), "45\n46\n47\n48\n49\n50\n51\n52\n53\n");
    assert_eq!(at.read("x06"), "54\n55\n56\n57\n58\n59\n60\n61\n62\n");
    assert_eq!(at.read("x07"), "63\n64\n65\n66\n67\n68\n69\n70\n71\n");
    assert_eq!(at.read("x08"), "72\n73\n74\n75\n76\n77\n78\n79\n80\n");
    assert_eq!(at.read("x09"), "81\n82\n83\n84\n85\n86\n87\n88\n89\n");
    assert_eq!(at.read("x10"), "90\n91\n92\n93\n94\n95\n96\n97\n98\n");
    assert_eq!(at.read("x11"), "99\n");
}
fn send_btc_with_fee_rate() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  rpc_server.mine_blocks(1);

  let output = CommandBuilder::new(
    "wallet send --fee-rate 13.3 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 1btc",
  )
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Output>();

  let tx = &rpc_server.mempool()[0];
  let mut fee = 0;
  for input in &tx.input {
    fee += rpc_server
      .get_utxo_amount(&input.previous_output)
      .unwrap()
      .to_sat();
  }
  for output in &tx.output {
    fee -= output.value;
  }

  let fee_rate = fee as f64 / tx.vsize() as f64;

  assert!(f64::abs(fee_rate - 13.3) < 0.1);

  assert_eq!(
    output.transaction,
    "0000000000000000000000000000000000000000000000000000000000000000"
      .parse()
      .unwrap()
  );

  assert_eq!(
    rpc_server.sent(),
    &[Sent {
      amount: 1.0,
      address: "bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4"
        .parse::<Address<NetworkUnchecked>>()
        .unwrap()
        .assume_checked(),
      locked: Vec::new(),
    }]
  );
}
fn test_gc_worker_config_update() {
    let (mut cfg, _dir) = TikvConfig::with_tmp().unwrap();
    cfg.validate().unwrap();
    let (gc_worker, cfg_controller) = setup_cfg_controller(cfg);
    let scheduler = gc_worker.scheduler();

    // update of other module's config should not effect gc worker config
    cfg_controller
        .update_config("raftstore.raft-log-gc-threshold", "2000")
        .unwrap();
    validate(&scheduler, move |cfg: &GcConfig, _| {
        assert_eq!(cfg, &GcConfig::default());
    });

    // Update gc worker config
    let change = {
        let mut change = std::collections::HashMap::new();
        change.insert("gc.ratio-threshold".to_owned(), "1.23".to_owned());
        change.insert("gc.batch-keys".to_owned(), "1234".to_owned());
        change.insert("gc.max-write-bytes-per-sec".to_owned(), "1KB".to_owned());
        change.insert("gc.enable-compaction-filter".to_owned(), "true".to_owned());
        change
    };
    cfg_controller.update(change).unwrap();
    validate(&scheduler, move |cfg: &GcConfig, _| {
        assert_eq!(cfg.ratio_threshold, 1.23);
        assert_eq!(cfg.batch_keys, 1234);
        assert_eq!(cfg.max_write_bytes_per_sec, ReadableSize::kb(1));
        assert!(cfg.enable_compaction_filter);
    });
}
fn test_mv_replace_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_replace_file_a";
    let file_b = "test_mv_replace_file_b";

    at.touch(file_a);
    at.touch(file_b);

    ucmd.arg(file_a).arg(file_b).succeeds().no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
}
fn test_destroy_uninitialized_peer_when_there_exists_old_peer() {
    // 4 stores cluster.
    let mut cluster = new_node_cluster(0, 4);
    cluster.cfg.raft_store.pd_store_heartbeat_tick_interval = ReadableDuration::millis(10);
    cluster.cfg.raft_store.hibernate_regions = false;

    let pd_client = cluster.pd_client.clone();
    // Disable default max peer count check.
    pd_client.disable_default_operator();

    let r1 = cluster.run_conf_change();

    // Now region 1 only has peer (1, 1);
    let (key, value) = (b"k1", b"v1");

    cluster.must_put(key, value);
    assert_eq!(cluster.get(key), Some(value.to_vec()));

    // add peer (2,2) to region 1.
    pd_client.must_add_peer(r1, new_peer(2, 2));

    // add peer (3, 3) to region 1.
    pd_client.must_add_peer(r1, new_peer(3, 3));

    let epoch = pd_client.get_region_epoch(r1);

    // Conf version must change.
    assert!(epoch.get_conf_ver() > 2);

    // Transfer leader to peer (2, 2).
    cluster.must_transfer_leader(r1, new_peer(2, 2));

    // Isolate node 1
    cluster.add_send_filter(IsolationFilterFactory::new(1));

    cluster.must_put(format!("k{}", 2).as_bytes(), b"v1");

    // Remove 3 and add 4
    pd_client.must_add_peer(r1, new_learner_peer(4, 4));
    pd_client.must_add_peer(r1, new_peer(4, 4));
    pd_client.must_remove_peer(r1, new_peer(3, 3));

    cluster.must_put(format!("k{}", 3).as_bytes(), b"v1");

    // Ensure 5 drops all snapshot
    let (notify_tx, _notify_rx) = mpsc::channel();
    cluster
        .sim
        .wl()
        .add_recv_filter(3, Box::new(DropSnapshotFilter::new(notify_tx)));

    // Add learner 5 on store 3
    pd_client.must_add_peer(r1, new_learner_peer(3, 5));

    cluster.must_put(format!("k{}", 4).as_bytes(), b"v1");

    // Remove and destroy the uninitialized 5
    let peer_5 = new_learner_peer(3, 5);
    pd_client.must_remove_peer(r1, peer_5.clone());
    cluster.must_gc_peer(r1, 3, peer_5);

    let region = block_on(pd_client.get_region_by_id(r1)).unwrap();
    must_region_cleared(&cluster.get_all_engines(3), &region.unwrap());

    // Unisolate 1 and try wakeup 3
    cluster.clear_send_filters();
    cluster.sim.wl().clear_recv_filters(3);
    cluster.partition(vec![1, 3], vec![2, 4]);

    sleep_until_election_triggered(&cluster.cfg);

    let region = block_on(pd_client.get_region_by_id(r1)).unwrap();
    must_region_cleared(&cluster.get_all_engines(3), &region.unwrap());
}
fn test_something() {
    let data = [];
    let mut set = OrdSet::new();
    let mut nat = NatSet::new();
    for action in actions {
        match action {
            Action::Insert(value) => {
                let len = nat.len() + if nat.contains(&value) { 0 } else { 1 };
                nat.insert(value);
                set.insert(value);
                assert_eq!(len, set.len());
            }
            Action::Remove(value) => {
                let len = nat.len() - if nat.contains(&value) { 1 } else { 0 };
                nat.remove(&value);
                set.remove(&value);
                assert_eq!(len, set.len());
            }
        }
        assert_eq!(nat.len(), set.len());
        assert_eq!(OrdSet::from(nat.clone()), set);
    }
}
fn leaves_necessary_whitespace_all_nested() {
    assert_eq!(
        "<u></u><u></u><u></u><u></u>",
        normalize_html("<u> </u><u> </u><u> </u><u> </u>")
    )
}
fn test_capitalize() {
    assert_eq!("Zbnmasd", "zbnmasd".capitalize()); // spell-checker:disable-line
    assert_eq!("Abnmasd", "Abnmasd".capitalize()); // spell-checker:disable-line
    assert_eq!("1masd", "1masd".capitalize()); // spell-checker:disable-line
    assert_eq!("", "".capitalize());
}
fn test_kwargs_error() {
    let kwargs = Kwargs::from_iter([("foo", Value::from(42))]);
    let bar = kwargs.get::<Value>("bar").unwrap_err();
    assert_eq!(bar.detail(), Some("missing keyword argument 'bar'"));
}
fn incorrect_description_file_1() {
    let f = super::fixture().join("incorrect-package");
    let resolution = Resolver::default().resolve(f.join("pack1"), ".");
    let error = ResolveError::JSON(JSONError {
        path: f.join("pack1/package.json"),
        message: String::from("EOF while parsing a value at line 3 column 0"),
        line: 3,
        column: 0,
    });
    assert_eq!(resolution, Err(error));
}
async fn request_with_connection_headers() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    // can't assert full handshake, since client never sends a request, and
    // thus never bothers to ack the settings...
    let srv = async move {
        srv.read_preface().await.unwrap();
        srv.recv_frame(frames::settings()).await;
        // goaway is required to make sure the connection closes because
        // of no active streams
        srv.recv_frame(frames::go_away(0)).await;
    };

    let headers = vec![
        ("connection", "foo"),
        ("keep-alive", "5"),
        ("proxy-connection", "bar"),
        ("transfer-encoding", "chunked"),
        ("upgrade", "HTTP/2"),
        ("te", "boom"),
    ];

    let client = async move {
        let (mut client, conn) = client::handshake(io).await.expect("handshake");

        for (name, val) in headers {
            let req = Request::builder()
                .uri("https://http2.akamai.com/")
                .header(name, val)
                .body(())
                .unwrap();
            let err = client.send_request(req, true).expect_err(name);
            assert_eq!(err.to_string(), "user error: malformed headers");
        }
        drop(client);
        conn.await.unwrap();
    };

    join(srv, client).await;
}
fn extends_should_raise_an_error_for_unresolved_configuration() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = Path::new("biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["formatTYPO.json", "linter.json"] }"#,
    );
    let format = Path::new("format.json");
    fs.insert(
        format.into(),
        r#"{ "javascript": { "formatter": { "quoteStyle": "single" } } }"#,
    );
    let lint = Path::new("linter.json");
    fs.insert(lint.into(), r#"{ "linter": { "enabled": false } }"#);

    let test_file = Path::new("test.js");
    fs.insert(test_file.into(), r#"debugger; console.log("string"); "#);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), test_file.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "extends_should_raise_an_error_for_unresolved_configuration",
        fs,
        console,
        result,
    ));
}
fn test_key_is_locked_for_primary() {
    let data = vec![
        (1, Some("name:0"), 2),
        (2, Some("name:4"), 3),
        (4, Some("name:3"), 1),
        (5, Some("name:1"), 4),
    ];

    let product = ProductTable::new();
    let (_, endpoint, _) = init_data_with_commit(&product, &data, false);

    let req = DagSelect::from(&product).build();
    let resp = handle_request(&endpoint, req);
    assert!(resp.get_data().is_empty(), "{:?}", resp);
    assert!(resp.has_locked(), "{:?}", resp);
}
fn genesis() {
  assert_eq!(
    CommandBuilder::new("subsidy 0").run_and_deserialize_output::<Output>(),
    Output {
      first: 0,
      subsidy: 5000000000,
      name: "nvtdijuwxlp".into(),
    }
  );
}
fn parse_interval() {
    let sql = "SELECT INTERVAL '1-1' YEAR TO MONTH";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from("1-1")))),
            leading_field: Some(DateTimeField::Year),
            leading_precision: None,
            last_field: Some(DateTimeField::Month),
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL '01:01.01' MINUTE (5) TO SECOND (5)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from(
                "01:01.01"
            )))),
            leading_field: Some(DateTimeField::Minute),
            leading_precision: Some(5),
            last_field: Some(DateTimeField::Second),
            fractional_seconds_precision: Some(5),
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL '1' SECOND (5, 4)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from("1")))),
            leading_field: Some(DateTimeField::Second),
            leading_precision: Some(5),
            last_field: None,
            fractional_seconds_precision: Some(4),
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL '10' HOUR";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from("10")))),
            leading_field: Some(DateTimeField::Hour),
            leading_precision: None,
            last_field: None,
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL 5 DAY";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(number("5"))),
            leading_field: Some(DateTimeField::Day),
            leading_precision: None,
            last_field: None,
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL 1 + 1 DAY";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::BinaryOp {
                left: Box::new(Expr::Value(number("1"))),
                op: BinaryOperator::Plus,
                right: Box::new(Expr::Value(number("1"))),
            }),
            leading_field: Some(DateTimeField::Day),
            leading_precision: None,
            last_field: None,
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL '10' HOUR (1)";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from("10")))),
            leading_field: Some(DateTimeField::Hour),
            leading_precision: Some(1),
            last_field: None,
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let sql = "SELECT INTERVAL '1 DAY'";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Interval(Interval {
            value: Box::new(Expr::Value(Value::SingleQuotedString(String::from(
                "1 DAY"
            )))),
            leading_field: None,
            leading_precision: None,
            last_field: None,
            fractional_seconds_precision: None,
        }),
        expr_from_projection(only(&select.projection)),
    );

    let result = parse_sql_statements("SELECT INTERVAL '1' SECOND TO SECOND");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: SECOND".to_string()),
        result.unwrap_err(),
    );

    let result = parse_sql_statements("SELECT INTERVAL '10' HOUR (1) TO HOUR (2)");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: (".to_string()),
        result.unwrap_err(),
    );

    verified_only_select("SELECT INTERVAL '1' YEAR");
    verified_only_select("SELECT INTERVAL '1' MONTH");
    verified_only_select("SELECT INTERVAL '1' DAY");
    verified_only_select("SELECT INTERVAL '1' HOUR");
    verified_only_select("SELECT INTERVAL '1' MINUTE");
    verified_only_select("SELECT INTERVAL '1' SECOND");
    verified_only_select("SELECT INTERVAL '1' YEAR TO MONTH");
    verified_only_select("SELECT INTERVAL '1' DAY TO HOUR");
    verified_only_select("SELECT INTERVAL '1' DAY TO MINUTE");
    verified_only_select("SELECT INTERVAL '1' DAY TO SECOND");
    verified_only_select("SELECT INTERVAL '1' HOUR TO MINUTE");
    verified_only_select("SELECT INTERVAL '1' HOUR TO SECOND");
    verified_only_select("SELECT INTERVAL '1' MINUTE TO SECOND");
    verified_only_select("SELECT INTERVAL '1 YEAR'");
    verified_only_select("SELECT INTERVAL '1 YEAR' AS one_year");
    one_statement_parses_to(
        "SELECT INTERVAL '1 YEAR' one_year",
        "SELECT INTERVAL '1 YEAR' AS one_year",
    );
}
fn roundtrip_decode_trailing_10_bytes() {
    // This is a special case because we decode 8 byte blocks of input at a time as much as we can,
    // ideally unrolled to 32 bytes at a time, in stages 1 and 2. Since we also write a u64's worth
    // of bytes (8) to the output, we always write 2 garbage bytes that then will be overwritten by
    // the NEXT block. However, if the next block only contains 2 bytes, it will decode to 1 byte,
    // and therefore be too short to cover up the trailing 2 garbage bytes. Thus, we have stage 3
    // to handle that case.

    for num_quads in 0..25 {
        let mut s: String = "ABCD".repeat(num_quads);
        s.push_str("EFGHIJKLZg");

        let engine = GeneralPurpose::new(&alphabet::STANDARD, NO_PAD);
        let decoded = engine.decode(&s).unwrap();
        assert_eq!(num_quads * 3 + 7, decoded.len());

        assert_eq!(s, engine.encode(&decoded));
    }
}
fn nursery_direct() {
    // `--select E225` should detect E225.
    let args = ["--select", "E225"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:2: E225 Missing whitespace around operator
    Found 1 error.

    ----- stderr -----
    warning: Selection of nursery rule `E225` without the `--preview` flag is deprecated.
    "###);
}
fn test_return_none() {
    let env = Environment::empty();
    let val = Value::from_function(|| -> Result<(), Error> { Ok(()) });
    let rv = val.call(&env.empty_state(), &[][..]).unwrap();
    assert!(rv.is_none());
    let val = Value::from_function(|| ());
    let rv = val.call(&env.empty_state(), &[][..]).unwrap();
    assert!(rv.is_none());
}
fn disallow_non_utf8() {
    assert!(regex::Regex::new(r"(?-u)\xFF").is_err());
    assert!(regex::Regex::new(r"(?-u).").is_err());
    assert!(regex::Regex::new(r"(?-u)[\xFF]").is_err());
    assert!(regex::Regex::new(r"(?-u)â˜ƒ").is_err());
}


fn exclude_stdin() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-select = ["B", "Q"]
ignore = ["Q000", "Q001", "Q002", "Q003"]

[format]
exclude = ["generated.py"]
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .args(["format", "--config", &ruff_toml.file_name().unwrap().to_string_lossy(), "--stdin-filename", "generated.py", "-"])
        .pass_stdin(r#"
from test import say_hy

if __name__ == '__main__':
    say_hy("dear Ruff contributor")
"#), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    from test import say_hy

    if __name__ == "__main__":
        say_hy("dear Ruff contributor")

    ----- stderr -----
    "###);
    Ok(())
}
fn test_raw_gc_keys_handled() {
    let store_id = 1;
    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();
    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();

    let engine = TestEngineBuilder::new()
        .api_version(ApiVersion::V2)
        .build()
        .unwrap();
    let prefixed_engine = PrefixedEngine(engine.clone());

    let (tx, _rx) = mpsc::channel();
    let feature_gate = FeatureGate::default();
    let mut gc_worker = GcWorker::new(
        prefixed_engine,
        tx,
        GcConfig::default(),
        feature_gate,
        Arc::new(MockRegionInfoProvider::new(vec![])),
    );
    gc_worker.start(store_id).unwrap();

    let mut r1 = Region::default();
    r1.set_id(1);
    r1.mut_region_epoch().set_version(1);
    r1.set_start_key(b"".to_vec());
    r1.set_end_key(b"".to_vec());
    r1.mut_peers().push(Peer::default());
    r1.mut_peers()[0].set_store_id(store_id);

    let sp_provider = MockSafePointProvider(200);
    let mut host = CoprocessorHost::<RocksEngine>::default();
    let ri_provider = RegionInfoAccessor::new(&mut host);
    let auto_gc_cfg = AutoGcConfig::new(sp_provider, ri_provider, store_id);
    let safe_point = Arc::new(AtomicU64::new(500));

    gc_worker.start_auto_gc(auto_gc_cfg, safe_point).unwrap();
    host.on_region_changed(&r1, RegionChangeEvent::Create, StateRole::Leader);

    let db = engine.kv_engine().unwrap().as_inner().clone();

    let user_key_del = b"r\0aaaaaaaaaaa";

    // If it's deleted, it will call async scheduler GcTask.
    let test_raws = vec![
        (user_key_del, 9, true),
        (user_key_del, 5, false),
        (user_key_del, 1, false),
    ];

    let modifies = test_raws
        .into_iter()
        .map(|(key, ts, is_delete)| {
            (
                make_key(key, ts),
                ApiV2::encode_raw_value(RawValue {
                    user_value: &[0; 10][..],
                    expire_ts: Some(TimeStamp::max().into_inner()),
                    is_delete,
                }),
            )
        })
        .map(|(k, v)| Modify::Put(CF_DEFAULT, Key::from_encoded_slice(k.as_slice()), v))
        .collect();

    let ctx = Context {
        api_version: ApiVersion::V2,
        ..Default::default()
    };

    let batch = WriteData::from_modifies(modifies);

    engine.write(&ctx, batch).unwrap();

    let cf = get_cf_handle(&db, CF_DEFAULT).unwrap();
    db.flush_cf(cf, true, false).unwrap();

    db.compact_range_cf(cf, None, None);

    thread::sleep(Duration::from_millis(100));

    assert_eq!(
        GC_COMPACTION_FILTER_MVCC_DELETION_MET
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );
    assert_eq!(
        GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED
            .with_label_values(&[STAT_RAW_KEYMODE])
            .get(),
        1
    );

    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();
    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();
}
fn test_all_lines_are_loaded() {
    let config = FileConfig {
        zone_file_path: "../../tests/test-data/test_configs/default/nonewline.zone".to_string(),
    };

    let mut authority = FileAuthority::try_from_config(
        Name::from_str("example.com.").unwrap(),
        ZoneType::Primary,
        false,
        None,
        &config,
    )
    .expect("failed to load");
    let rrkey = RrKey {
        record_type: RecordType::A,
        name: LowerName::from(Name::from_ascii("ensure.nonewline.").unwrap()),
    };
    assert!(authority.records_get_mut().get(&rrkey).is_some())
}
fn parse_create_table_if_not_exists() {
    let sql = "CREATE TABLE IF NOT EXISTS uk_cities ()";
    let ast = pg_and_generic().verified_stmt(sql);
    match ast {
        Statement::CreateTable {
            name,
            if_not_exists: true,
            ..
        } => {
            assert_eq!("uk_cities", name.to_string());
        }
        _ => unreachable!(),
    }
}
fn test_rm_descend_directory() {
    // This test descends into each directory and deletes the files and folders inside of them
    // This test will have the rm process asks 6 question and us answering Y to them will delete all the files and folders

    // Needed for talking with stdin on platforms where CRLF or LF matters
    const END_OF_LINE: &str = if cfg!(windows) { "\r\n" } else { "\n" };

    let yes = format!("y{END_OF_LINE}");

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_1 = "a/at.txt";
    let file_2 = "a/b/bt.txt";

    at.mkdir_all("a/b/");
    at.touch(file_1);
    at.touch(file_2);

    let mut child = scene
        .ucmd()
        .set_stdin(Stdio::piped())
        .arg("-ri")
        .arg("a")
        .run_no_wait();
    child.try_write_in(yes.as_bytes()).unwrap();
    child.try_write_in(yes.as_bytes()).unwrap();
    child.try_write_in(yes.as_bytes()).unwrap();
    child.try_write_in(yes.as_bytes()).unwrap();
    child.try_write_in(yes.as_bytes()).unwrap();
    child.try_write_in(yes.as_bytes()).unwrap();

    child.wait().unwrap();

    assert!(!at.dir_exists("a/b"));
    assert!(!at.dir_exists("a"));
    assert!(!at.file_exists(file_1));
    assert!(!at.file_exists(file_2));
}
fn test_cp_numbered_if_existing_backup_nil() {
    let (at, mut ucmd) = at_and_ucmd!();
    let existing_backup = &format!("{TEST_HOW_ARE_YOU_SOURCE}.~1~");

    at.touch(existing_backup);
    ucmd.arg("--backup=nil")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(TEST_HOW_ARE_YOU_SOURCE));
    assert!(at.file_exists(existing_backup));
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}.~2~")),
        "How are you?\n"
    );
}
fn test_delete_rrset() {
    let catalog = Catalog::new();
    let (client, origin) = create_sig0_ready_client(catalog);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = client
        .delete_rrset(record.clone(), origin.clone())
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));
    let result = client
        .append(record.clone(), origin.clone(), true)
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = client
        .delete_rrset(record.clone(), origin)
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);
}
fn test_rpc_client() {
    let rt = setup_runtime();
    let _g = rt.enter();
    let eps_count = 1;
    let server = MockServer::new(eps_count);
    let eps = server.bind_addrs();

    let mut client = new_client_v2(eps.clone(), None);
    assert_ne!(client.fetch_cluster_id().unwrap(), 0);

    let store_id = client.alloc_id().unwrap();
    let mut store = metapb::Store::default();
    store.set_id(store_id);
    debug!("bootstrap store {:?}", store);

    let peer_id = client.alloc_id().unwrap();
    let mut peer = metapb::Peer::default();
    peer.set_id(peer_id);
    peer.set_store_id(store_id);

    let region_id = client.alloc_id().unwrap();
    let mut region = metapb::Region::default();
    region.set_id(region_id);
    region.mut_peers().push(peer.clone());
    debug!("bootstrap region {:?}", region);

    client
        .bootstrap_cluster(store.clone(), region.clone())
        .unwrap();
    assert_eq!(client.is_cluster_bootstrapped().unwrap(), true);

    let tmp_stores = client.get_all_stores(false).unwrap();
    assert_eq!(tmp_stores.len(), 1);
    assert_eq!(tmp_stores[0], store);

    let tmp_store = client.get_store(store_id).unwrap();
    assert_eq!(tmp_store.get_id(), store.get_id());

    let region_key = region.get_start_key();
    let tmp_region = client.get_region(region_key).unwrap();
    assert_eq!(tmp_region.get_id(), region.get_id());

    let region_info = client.get_region_info(region_key).unwrap();
    assert_eq!(region_info.region, region);
    assert_eq!(region_info.leader, None);

    let tmp_region = block_on(client.get_region_by_id(region_id))
        .unwrap()
        .unwrap();
    assert_eq!(tmp_region.get_id(), region.get_id());

    let ts = must_get_tso(&mut client, 1);
    assert_ne!(ts, TimeStamp::zero());

    let ts100 = must_get_tso(&mut client, 100);
    assert_eq!(ts.logical() + 100, ts100.logical());

    let mut prev_id = 0;
    for _ in 0..10 {
        let mut client = new_client_v2(eps.clone(), None);
        let alloc_id = client.alloc_id().unwrap();
        assert!(alloc_id > prev_id);
        prev_id = alloc_id;
    }

    let (tx, mut responses) = client
        .create_region_heartbeat_stream(WakePolicy::Immediately)
        .unwrap();
    let mut req = pdpb::RegionHeartbeatRequest::default();
    req.set_region(region.clone());
    req.set_leader(peer.clone());
    tx.send(req).unwrap();
    block_on(tokio::time::timeout(
        Duration::from_secs(3),
        responses.next(),
    ))
    .unwrap();

    let region_info = client.get_region_info(region_key).unwrap();
    assert_eq!(region_info.region, region);
    assert_eq!(region_info.leader.unwrap(), peer);

    block_on(client.store_heartbeat(
        pdpb::StoreStats::default(),
        None, // store_report
        None,
    ))
    .unwrap();
    block_on(client.ask_batch_split(metapb::Region::default(), 1)).unwrap();
    block_on(client.report_batch_split(vec![metapb::Region::default(), metapb::Region::default()]))
        .unwrap();

    let region_info = client.get_region_info(region_key).unwrap();
    client.scatter_region(region_info).unwrap();
}
fn parse_logical_xor() {
    let sql = "SELECT true XOR true, false XOR false, true XOR false, false XOR true";
    let select = verified_only_select(sql);
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::BinaryOp {
            left: Box::new(Expr::Value(Value::Boolean(true))),
            op: BinaryOperator::Xor,
            right: Box::new(Expr::Value(Value::Boolean(true))),
        }),
        select.projection[0]
    );
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::BinaryOp {
            left: Box::new(Expr::Value(Value::Boolean(false))),
            op: BinaryOperator::Xor,
            right: Box::new(Expr::Value(Value::Boolean(false))),
        }),
        select.projection[1]
    );
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::BinaryOp {
            left: Box::new(Expr::Value(Value::Boolean(true))),
            op: BinaryOperator::Xor,
            right: Box::new(Expr::Value(Value::Boolean(false))),
        }),
        select.projection[2]
    );
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::BinaryOp {
            left: Box::new(Expr::Value(Value::Boolean(false))),
            op: BinaryOperator::Xor,
            right: Box::new(Expr::Value(Value::Boolean(true))),
        }),
        select.projection[3]
    );
}
async fn errors_if_recv_frame_exceeds_max_frame_size() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let h2 = async move {
        let (mut client, h2) = client::handshake(io).await.unwrap();
        let req = async move {
            let resp = client.get("https://example.com/").await.expect("response");
            assert_eq!(resp.status(), StatusCode::OK);
            let body = resp.into_parts().1;
            let res = util::concat(body).await;
            let err = res.unwrap_err();
            assert_eq!(
                err.to_string(),
                "connection error detected: frame with invalid size"
            );
        };

        // client should see a conn error
        let conn = async move {
            let err = h2.await.unwrap_err();
            assert_eq!(
                err.to_string(),
                "connection error detected: frame with invalid size"
            );
        };
        join(conn, req).await;
    };

    // a bad peer
    srv.codec_mut().set_max_send_frame_size(16_384 * 4);

    let srv = async move {
        let _ = srv.assert_client_handshake().await;
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://example.com/")
                .eos(),
        )
        .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        srv.send_frame(frames::data(1, vec![0; 16_385]).eos()).await;
        srv.recv_frame(frames::go_away(0).frame_size()).await;
    };

    join(srv, h2).await;
}
fn parse_similar_to() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = ms_and_generic().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = ms_and_generic().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that SIMILAR TO and NOT SIMILAR TO have the same precedence.
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = ms_and_generic().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn linter_biome_json() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), "debugger;\n".as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(
        config_path.into(),
        r#"{
  "linter": {
    "rules": {
        "recommended": true,
        "suspicious": {
            "noDebugger": "off"
        }
    }
  }
}"#
        .as_bytes(),
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, "debugger;\n");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "linter_biome_json",
        fs,
        console,
        result,
    ));
}
fn regression14() {
    let tmpfile = create_tempfile();

    let db = Database::create(tmpfile.path()).unwrap();

    let table_def: MultimapTableDefinition<u64, &[u8]> = MultimapTableDefinition::new("x");

    let mut tx = db.begin_write().unwrap();
    tx.set_durability(Durability::None);
    {
        let mut t = tx.open_multimap_table(table_def).unwrap();
        let value = vec![0; 1424];
        t.insert(&539749, value.as_slice()).unwrap();
    }
    tx.commit().unwrap();

    let mut tx = db.begin_write().unwrap();
    tx.set_durability(Durability::None);
    {
        let mut t = tx.open_multimap_table(table_def).unwrap();
        let value = vec![0; 2230];
        t.insert(&776971, value.as_slice()).unwrap();

        let mut iter = t.range(514043..(514043 + 514043)).unwrap().rev();
        {
            let (key, mut value_iter) = iter.next().unwrap().unwrap();
            assert_eq!(key.value(), 776971);
            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 2230]);
        }
        {
            let (key, mut value_iter) = iter.next().unwrap().unwrap();
            assert_eq!(key.value(), 539749);
            assert_eq!(value_iter.next().unwrap().unwrap().value(), &[0; 1424]);
        }
    }
    tx.abort().unwrap();
}
fn test_symlink_relative_path() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_symlink_existing_dir";
    let file_a = "test_symlink_relative_a";
    let link = "test_symlink_relative_link";
    let multi_dir =
        "test_symlink_existing_dir/../test_symlink_existing_dir/../test_symlink_existing_dir/../";
    let p = PathBuf::from(multi_dir).join(file_a);
    at.mkdir(dir);

    // relative symlink
    // Thanks to -r, all the ../ should be resolved to a single file
    ucmd.args(&["-r", "-s", "-v", &p.to_string_lossy(), link])
        .succeeds()
        .stdout_only(format!("'{link}' -> '{file_a}'\n"));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file_a);

    // Run the same command without -r to verify that we keep the full
    // crazy path
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-s", "-v", &p.to_string_lossy(), link])
        .succeeds()
        .stdout_only(format!("'{}' -> '{}'\n", link, &p.to_string_lossy()));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), p.to_string_lossy());
}
fn imul_test() {
    // Normalized (64-bit mantissa)
    let a = ExtendedFloat {
        mant: 13164036458569648128,
        exp: -213,
    };
    let b = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -62,
    };
    let c = ExtendedFloat {
        mant: 6582018229284824064,
        exp: -211,
    };
    check_imul(a, b, c);

    // Check with integers
    // 64-bit mantissa
    let mut a = ExtendedFloat { mant: 10, exp: 0 };
    let mut b = ExtendedFloat { mant: 10, exp: 0 };
    a.normalize();
    b.normalize();
    a.imul(&b);
    assert_eq!(a.into_float::<f64>(), 100.0);

    // Check both values need high bits set.
    let mut a = ExtendedFloat {
        mant: 1 << 32,
        exp: -31,
    };
    let b = ExtendedFloat {
        mant: 1 << 32,
        exp: -31,
    };
    a.imul(&b);
    assert_eq!(a.into_float::<f64>(), 4.0);

    // Check both values need high bits set.
    let mut a = ExtendedFloat {
        mant: 10 << 31,
        exp: -31,
    };
    let b = ExtendedFloat {
        mant: 10 << 31,
        exp: -31,
    };
    a.imul(&b);
    assert_eq!(a.into_float::<f64>(), 100.0);
}
fn test_prewrite_without_value() {
    let cluster = new_server_cluster(0, 2);
    cluster.pd_client.disable_default_operator();
    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();
    let rid = suite.cluster.get_region(&[]).id;
    let ctx = suite.get_context(rid);
    let client = suite.get_tikv_client(rid).clone();
    let large_value = vec![b'x'; 2 * txn_types::SHORT_VALUE_MAX_LEN];

    // Perform a pessimistic prewrite with a large value.
    let mut muts = vec![Mutation::default()];
    muts[0].set_op(Op::Put);
    muts[0].key = b"key".to_vec();
    muts[0].value = large_value.clone();
    try_kv_prewrite_pessimistic(&client, ctx.clone(), muts, b"key".to_vec(), 10);

    let req = suite.new_changedata_request(rid);
    let (mut req_tx, _, receive_event) = new_event_feed(suite.get_region_cdc_client(rid));
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();

    // The prewrite can be retrieved from incremental scan.
    let event = receive_event(false);
    assert_eq!(
        event.get_events()[0].get_entries().entries[0].value,
        large_value
    );

    // check_txn_status will put the lock again, but without value.
    must_check_txn_status(&client, ctx.clone(), b"key", 10, 12, 12);
    must_kv_commit(&client, ctx, vec![b"key".to_vec()], 10, 14, 14);
    // The lock without value shouldn't be retrieved.
    let event = receive_event(false);
    assert_eq!(event.get_events()[0].get_entries().entries[0].commit_ts, 14);
}
fn save_point_rollback_after_write() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();

    wb.write().unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_some());

    db.engine.delete(b"a").unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();

    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    wb.set_save_point();
    for i in 0..max_keys {
        wb.put(&i.to_be_bytes(), b"").unwrap();
    }
    wb.put(b"a", b"").unwrap();

    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }

    db.engine.delete(b"a").unwrap();
    for i in 0..max_keys {
        db.engine.delete(&i.to_be_bytes()).unwrap();
    }

    assert!(db.engine.get_value(b"a").unwrap().is_none());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_none());
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn does_handle_if_included_in_formatter() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": { "ignore": ["test.js"] }, "formatter": { "include": ["test.js"] }
}
"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--write"), test.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, FORMATTED);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_if_included_in_formatter",
        fs,
        console,
        result,
    ));
}
fn check_hints_hidden_unsafe_fixes_with_no_safe_fixes() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["-", "--output-format", "text", "--no-cache", "--isolated", "--select", "F601"])
        .pass_stdin("x = {'a': 1, 'a': 1}\n"),
        @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    Found 1 error.
    No fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).

    ----- stderr -----
    "###);
}
fn subexpression_with_multiple_args() {
    // https://github.com/googleprojectzero/weggli/issues/14

    // An unfortunate effect of our sub expression syntax _($x) is 
    // that people might wrongly use it as a wildcard function call
    // _($a, $b). This doesn't work (you want to use $fn($a,$b) instead).
    // As we don't support sub expressions with multiple arguments, we
    // can just transparently convert _(_, $b) to $something(_, $b) and
    // warn the user.

    let needle = "{$b = getenv(_); _(_, $b);}";

    let source = r#"
    void displayHelp()
    {
        char *c = getenv("HOME");
        int t;
        endwin();
        printf("%s\n",version);
        printf("  Located in %s/.davrc\n",c);
        printf("  Edit %s/.davrc to customize function key bindings\n",c);
        initscr();
        quit("");
    }"#;

    let results = parse_and_match_helper(needle, source, false);

    assert_eq!(results.len(), 2);
}
fn copy_wrong() {
    let mut store = Store::<()>::default();
    let ty = TableType::new(ValType::FuncRef, 1, None);
    let table1 = Table::new(&mut store, ty, Val::FuncRef(None)).unwrap();
    let ty = TableType::new(ValType::ExternRef, 1, None);
    let table2 = Table::new(&mut store, ty, Val::ExternRef(None)).unwrap();
    assert_eq!(
        Table::copy(&mut store, &table1, 0, &table2, 0, 1)
            .map_err(|e| e.to_string())
            .unwrap_err(),
        "tables do not have the same element type"
    );
}
fn no_lint_if_linter_is_disabled_when_run_apply() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_linter_is_disabled_when_run_apply",
        fs,
        console,
        result,
    ));
}
fn test_clone() {
    let mut env = Environment::new();
    env.add_template("test", "a").unwrap();
    let mut env2 = env.clone();
    assert_eq!(env2.get_template("test").unwrap().render(()).unwrap(), "a");
    env2.add_template("test", "b").unwrap();
    assert_eq!(env2.get_template("test").unwrap().render(()).unwrap(), "b");
    assert_eq!(env.get_template("test").unwrap().render(()).unwrap(), "a");
}
fn custom_index_path() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  let tempdir = TempDir::new().unwrap();

  let index_path = tempdir.path().join("foo.redb");

  CommandBuilder::new(format!("--index {} index update", index_path.display()))
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Empty>();

  assert!(index_path.is_file())
}
fn test_table_traps_on_limited_growth() -> Result<(), Error> {
    let limits = StoreLimitsBuilder::new()
        .table_elements(100)
        .trap_on_grow_failure(true)
        .build();
    let mut test = Test::new(0x20, 99, limits)?;
    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 99);
    // First table.grow doesn't hit the limit, so succeeds, returns previous size.
    assert_eq!(test.table_grow.call(&mut test.store, (1,))?, 99);
    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 100);
    // Second call goes past the limit, so fails to grow the table, and we've configured it to trap.
    assert!(matches!(
        test.table_grow
            .call(&mut test.store, (1,))
            .unwrap_err()
            .trap_code(),
        Some(TrapCode::GrowthOperationLimited)
    ));
    // Check table size is what we expect.
    assert_eq!(test.table_size.call(&mut test.store, ())?, 100);
    Ok(())
}
fn test_something() {
    let data = [];
    let engine = utils::random_engine(data);
    let encoded = engine.encode(data);
    let decoded = engine.decode(&encoded).unwrap();
    assert_eq!(data, decoded.as_slice());
}
fn gzip_encoder_empty_read() {
    let original: &[u8] = b"Lorem ipsum dolor sit amet.";
    let mut encoder = flate2::read::GzEncoder::new(original, flate2::Compression::default());
    assert_eq!(encoder.read(&mut []).unwrap(), 0);
    let mut encoded = Vec::new();
    encoder.read_to_end(&mut encoded).unwrap();
    let mut decoder = flate2::read::GzDecoder::new(encoded.as_slice());
    let mut decoded = Vec::new();
    decoder.read_to_end(&mut decoded).unwrap();
    assert_eq!(decoded.as_slice(), original);
}
fn i128_decimal_test() {
    assert_eq!(Ok(0), i128::from_lexical(b"0"));
    assert_eq!(
        Ok(170141183460469231731687303715884105727),
        i128::from_lexical(b"170141183460469231731687303715884105727")
    );
    assert_eq!(
        Err(Error::Overflow(38)),
        i128::from_lexical(b"170141183460469231731687303715884105728")
    );
    assert_eq!(
        Err(Error::Overflow(38)),
        i128::from_lexical(b"340282366920938463463374607431768211455")
    );
    assert_eq!(Ok(-1), i128::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), i128::from_lexical(b"1a"));
}
fn test_skip_iter_i() {
    // Test iterators that skip single, internal-only digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"__.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"_455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"__45_5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b"_.455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"__.45_5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4_5__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4_5__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"_45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"__45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"_45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"__45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"_45_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"__4_5__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"_45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"__4_5__.56");
}
fn eph_weak_gc_test() {
    run_test(|| {
        let gc_value = Gc::new(3);

        {
            let cloned_gc = gc_value.clone();

            let weak = WeakGc::new(&cloned_gc);

            assert_eq!(*weak.upgrade().expect("Is live currently"), 3);
            drop(cloned_gc);
            force_collect();
            assert_eq!(*weak.upgrade().expect("WeakGc is still live here"), 3);

            drop(gc_value);
            force_collect();

            assert!(weak.upgrade().is_none());
        }
    });
}
fn code_too_large_without_panic() -> Result<()> {
    const N: usize = 120000;

    // Build a module with a function whose body will allocate too many
    // temporaries for our current (Cranelift-based) compiler backend to
    // handle. This test ensures that we propagate the failure upward
    // and return it programmatically, rather than panic'ing. If we ever
    // improve our compiler backend to actually handle such a large
    // function body, we'll need to increase the limits here too!
    let mut s = String::new();
    s.push_str("(module\n");
    s.push_str("(table 1 1 funcref)\n");
    s.push_str("(func (export \"\") (result i32)\n");
    s.push_str("i32.const 0\n");
    for _ in 0..N {
        s.push_str("table.get 0\n");
        s.push_str("ref.is_null\n");
    }
    s.push_str("))\n");

    let store = Store::<()>::default();
    let result = Module::new(store.engine(), &s);
    match result {
        Err(e) => assert!(e
            .to_string()
            .starts_with("Compilation error: Code for function is too large")),
        Ok(_) => panic!("Please adjust limits to make the module too large to compile!"),
    }
    Ok(())
}
fn test_pd_client_ok_when_cluster_not_ready() {
    let pd_client_cluster_id_zero = "cluster_id_is_not_ready";
    let server = MockServer::with_case(3, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();

    let mut client = new_client_v2(eps, None);
    fail::cfg(pd_client_cluster_id_zero, "return()").unwrap();
    // wait 100ms to let client load member.
    thread::sleep(Duration::from_millis(101));
    assert_eq!(client.reconnect().is_err(), true);
    fail::remove(pd_client_cluster_id_zero);
}
fn test_kv_scan_memory_lock() {
    let (_cluster, client, ctx) = must_new_cluster_and_kv_client();

    let mut req = ScanRequest::default();
    req.set_context(ctx);
    req.set_start_key(b"a".to_vec());
    req.version = 50;

    fail::cfg("raftkv_async_snapshot_err", "return").unwrap();
    let resp = client.kv_scan(&req).unwrap();
    // the injected error should be returned at both places for backward
    // compatibility.
    assert!(!resp.pairs[0].get_error().get_abort().is_empty());
    assert!(!resp.get_error().get_abort().is_empty());
    fail::remove("raftkv_async_snapshot_err");
}
fn test_uname_kernel() {
    let (_, mut ucmd) = at_and_ucmd!();

    #[cfg(target_os = "linux")]
    {
        let result = ucmd.arg("-o").succeeds();
        assert!(result.stdout_str().to_lowercase().contains("linux"));
    }

    #[cfg(not(target_os = "linux"))]
    ucmd.arg("-o").succeeds();
}
fn test_retry_pending_prepare_merge_fail() {
    let mut cluster = new_server_cluster(0, 2);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k2");
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k3");

    cluster.must_transfer_leader(right.id, new_peer(2, 2));

    // Insert lock l1 into the left region
    let snapshot = cluster.must_get_snapshot_of_region(left.id);
    let txn_ext = snapshot.txn_ext.unwrap();
    let l1 = PessimisticLock {
        primary: b"k1".to_vec().into_boxed_slice(),
        start_ts: 10.into(),
        ttl: 3000,
        for_update_ts: 20.into(),
        min_commit_ts: 30.into(),
        last_change_ts: 15.into(),
        versions_to_last_change: 3,
    };
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(Key::from_raw(b"k1"), l1)])
        .unwrap();

    // Pause apply and write some data to the left region
    fail::cfg("on_handle_apply", "pause").unwrap();
    let (propose_tx, propose_rx) = mpsc::sync_channel(10);
    fail::cfg_callback("after_propose", move || propose_tx.send(()).unwrap()).unwrap();

    let mut rx = cluster.async_put(b"k1", b"v11").unwrap();
    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();
    rx.recv_timeout(Duration::from_millis(200)).unwrap_err();

    // Then, start merging. PrepareMerge should become pending because applied_index
    // is smaller than proposed_index.
    cluster.merge_region(left.id, right.id, Callback::None);
    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();
    thread::sleep(Duration::from_millis(200));
    assert!(txn_ext.pessimistic_locks.read().is_writable());

    // Set disk full error to let PrepareMerge fail. (Set both peer to full to avoid
    // transferring leader)
    fail::cfg("disk_already_full_peer_1", "return").unwrap();
    fail::cfg("disk_already_full_peer_2", "return").unwrap();
    fail::remove("on_handle_apply");
    let res = rx.recv_timeout(Duration::from_secs(1)).unwrap();
    assert!(!res.get_header().has_error(), "{:?}", res);

    propose_rx.recv_timeout(Duration::from_secs(2)).unwrap();
    fail::remove("disk_already_full_peer_1");
    fail::remove("disk_already_full_peer_2");

    // Merge should not succeed because the disk is full.
    thread::sleep(Duration::from_millis(300));
    cluster.reset_leader_of_region(left.id);
    assert_eq!(cluster.get_region(b"k1"), left);

    cluster.must_put(b"k1", b"v12");
}
fn parse_invalid_table_name() {
    let ast = all_dialects()
        .run_parser_method("db.public..customer", |parser| parser.parse_object_name());
    assert!(ast.is_err());
}
fn error_invalid_type_index_variable() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("tpl", "{{ arr[a] }}")]).unwrap();

    let mut context = Context::new();
    context.insert("arr", &[1, 2, 3]);
    context.insert("a", &true);

    let result = tera.render("tpl", &context);

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Only variables evaluating to String or Number can be used as index (`a` of `arr[a]`)"
    );
}
fn test_mv_backup_none() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=none")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(!at.file_exists(format!("{file_b}~")));
}
fn doesnt_error_if_no_files_were_processed() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), "--no-errors-on-unmatched", ("file.js")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "doesnt_error_if_no_files_were_processed",
        fs,
        console,
        result,
    ));
}
fn ignore_vcs_ignored_file_via_cli() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let git_ignore = r#"
file2.js
"#;

    let code2 = r#"foo.call();


    bar.call();"#;
    let code1 = r#"array.map(sentence => sentence.split(' ')).flat();"#;

    // ignored files
    let file_path1 = Path::new("file1.js");
    fs.insert(file_path1.into(), code1.as_bytes());
    let file_path2 = Path::new("file2.js");
    fs.insert(file_path2.into(), code2.as_bytes());

    // git folder
    let git_folder = Path::new("./.git");
    fs.insert(git_folder.into(), "".as_bytes());

    // git ignore file
    let ignore_file = Path::new("./.gitignore");
    fs.insert(ignore_file.into(), git_ignore.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                ("--vcs-enabled=true"),
                ("--vcs-client-kind=git"),
                ("--vcs-use-ignore-file=true"),
                ("--vcs-root=."),
                file_path1.as_os_str().to_str().unwrap(),
                file_path2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ignore_vcs_ignored_file_via_cli",
        fs,
        console,
        result,
    ));
}
fn test_prompt_write_protected_yes() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let file_1 = "test_rm_prompt_write_protected_1";

    at.touch(file_1);

    scene.ccmd("chmod").arg("0").arg(file_1).succeeds();

    scene.ucmd().arg(file_1).pipe_in("y").succeeds();
    assert!(!at.file_exists(file_1));
}
fn parse_binary_any() {
    let select = verified_only_select("SELECT a = ANY(b)");
    assert_eq!(
        SelectItem::UnnamedExpr(Expr::AnyOp {
            left: Box::new(Expr::Identifier(Ident::new("a"))),
            compare_op: BinaryOperator::Eq,
            right: Box::new(Expr::Identifier(Ident::new("b"))),
        }),
        select.projection[0]
    );
}
fn test_cp_with_dirs_t() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg("-t")
        .arg(TEST_COPY_TO_FOLDER)
        .arg(TEST_HELLO_WORLD_SOURCE)
        .succeeds();
    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), "Hello, World!\n");
}
fn trap_smoke() -> Result<()> {
    let engine = Engine::default();
    let mut linker = Linker::<()>::new(&engine);
    linker.func_wrap("", "", || -> Result<()> { bail!("test") })?;

    let mut store = Store::new(&engine, ());

    let f = linker.get(&mut store, "", "").unwrap().into_func().unwrap();

    let err = f.call(&mut store, &[], &mut []).unwrap_err();

    assert!(err.to_string().contains("test"));

    Ok(())
}
fn client_cert_resolve() {
    for kt in ALL_KEY_TYPES.iter() {
        let server_config = Arc::new(make_server_config_with_mandatory_client_auth(*kt));

        let expected_issuers = match *kt {
            KeyType::Rsa => vec![
                b"0,1*0(\x06\x03U\x04\x03\x0c!ponytown RSA level 2 intermediate".to_vec(),
                b"0\x1a1\x180\x16\x06\x03U\x04\x03\x0c\x0fponytown RSA CA".to_vec(),
            ],
            KeyType::Ecdsa => vec![
                b"0.1,0*\x06\x03U\x04\x03\x0c#ponytown ECDSA level 2 intermediate".to_vec(),
                b"0\x1c1\x1a0\x18\x06\x03U\x04\x03\x0c\x11ponytown ECDSA CA".to_vec(),
            ],
            KeyType::Ed25519 => vec![
                b"0.1,0*\x06\x03U\x04\x03\x0c#ponytown EdDSA level 2 intermediate".to_vec(),
                b"0\x1c1\x1a0\x18\x06\x03U\x04\x03\x0c\x11ponytown EdDSA CA".to_vec(),
            ],
        };

        for version in rustls::ALL_VERSIONS {
            let expected_sigschemes = match version.version {
                ProtocolVersion::TLSv1_2 => vec![
                    SignatureScheme::ECDSA_NISTP384_SHA384,
                    SignatureScheme::ECDSA_NISTP256_SHA256,
                    SignatureScheme::ED25519,
                    SignatureScheme::RSA_PSS_SHA512,
                    SignatureScheme::RSA_PSS_SHA384,
                    SignatureScheme::RSA_PSS_SHA256,
                    SignatureScheme::RSA_PKCS1_SHA512,
                    SignatureScheme::RSA_PKCS1_SHA384,
                    SignatureScheme::RSA_PKCS1_SHA256,
                ],
                ProtocolVersion::TLSv1_3 => vec![
                    SignatureScheme::ECDSA_NISTP384_SHA384,
                    SignatureScheme::ECDSA_NISTP256_SHA256,
                    SignatureScheme::ED25519,
                    SignatureScheme::RSA_PSS_SHA512,
                    SignatureScheme::RSA_PSS_SHA384,
                    SignatureScheme::RSA_PSS_SHA256,
                ],
                _ => unreachable!(),
            };

            println!("{:?} {:?}:", version.version, *kt);

            let mut client_config = make_client_config_with_versions(*kt, &[version]);
            client_config.client_auth_cert_resolver = Arc::new(ClientCheckCertResolve::new(
                1,
                expected_issuers.clone(),
                expected_sigschemes,
            ));

            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);

            assert_eq!(
                do_handshake_until_error(&mut client, &mut server),
                Err(ErrorFromPeer::Server(Error::NoCertificatesPresented))
            );
        }
    }
}
fn grow_externref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::ExternRef, 10, None);
    let table = Table::new(&mut store, table_ty, Val::ExternRef(None))?;

    assert_eq!(table.size(&store), 10);
    table.grow(&mut store, 3, Val::ExternRef(None))?;
    assert_eq!(table.size(&store), 13);

    Ok(())
}
fn is_valid_letter_test() {
    assert_eq!(ascii::is_valid_letter(b'\x00'), false);
    assert_eq!(ascii::is_valid_letter(b'\n'), false);
    assert_eq!(ascii::is_valid_letter(b'\r'), false);
    assert_eq!(ascii::is_valid_letter(b'\x1b'), false);
    assert_eq!(ascii::is_valid_letter(b' '), false);
    assert_eq!(ascii::is_valid_letter(b'0'), false);
    assert_eq!(ascii::is_valid_letter(b'9'), false);
    assert_eq!(ascii::is_valid_letter(b':'), false);
    assert_eq!(ascii::is_valid_letter(b'A'), true);
    assert_eq!(ascii::is_valid_letter(b'Z'), true);
    assert_eq!(ascii::is_valid_letter(b']'), false);
    assert_eq!(ascii::is_valid_letter(b'a'), true);
    assert_eq!(ascii::is_valid_letter(b'z'), true);
    assert_eq!(ascii::is_valid_letter(b'~'), false);
    assert_eq!(ascii::is_valid_letter(b'\x7f'), false);
}
fn hammer_client_concurrency() {
    // This reproduces issue #326.
    const N: usize = 5000;

    let server = Server::serve(|| Bytes::from_static(b"hello world!"));

    let addr = server.addr();
    let rsps = Arc::new(AtomicUsize::new(0));

    for i in 0..N {
        print!("sending {}", i);
        let rsps = rsps.clone();
        let tcp = TcpStream::connect(&addr);
        let tcp = tcp
            .then(|res| {
                let tcp = res.unwrap();
                client::handshake(tcp)
            })
            .then(move |res| {
                let rsps = rsps;
                let (mut client, h2) = res.unwrap();
                let request = Request::builder()
                    .uri("https://http2.akamai.com/")
                    .body(())
                    .unwrap();

                let (response, mut stream) = client.send_request(request, false).unwrap();
                stream.send_trailers(HeaderMap::new()).unwrap();

                tokio::spawn(async move {
                    h2.await.unwrap();
                });

                response
                    .and_then(|response| {
                        let mut body = response.into_body();

                        async move {
                            while let Some(res) = body.data().await {
                                res?;
                            }
                            body.trailers().await?;
                            Ok(())
                        }
                    })
                    .map_err(|e| {
                        panic!("client error: {:?}", e);
                    })
                    .map(move |_| {
                        rsps.fetch_add(1, Ordering::Release);
                    })
            });

        let rt = tokio::runtime::Runtime::new().unwrap();
        rt.block_on(tcp);
        println!("...done");
    }

    println!("all done");

    assert_eq!(N, rsps.load(Ordering::Acquire));
    assert_eq!(N, server.request_count());
}
fn ok_read_only() {
    let mut fs = MemoryFileSystem::new_read_only();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), FORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");
}
fn render_images() {
    process_images(|path| {
        let mut decoder = gif::DecodeOptions::new();
        decoder.set_color_output(gif::ColorOutput::RGBA);
        let file = File::open(path)?;
        let mut decoder = decoder.read_info(file)?;
        let mut crc = Crc32::new();
        while let Some(frame) = decoder.read_next_frame()? {
            // First sanity check:
            assert_eq!(
                frame.buffer.len(), 
                frame.width as usize
                * frame.height as usize
                * 4
            );
            crc.update(&*frame.buffer);
        }
        Ok(crc.checksum())
    })
}
fn no_lint_if_linter_is_disabled_when_run_apply() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, CHECK_FORMAT_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_linter_is_disabled_when_run_apply",
        fs,
        console,
        result,
    ));
}
fn dfa_handles_pathological_case() {
    fn ones_and_zeroes(count: usize) -> String {
        use rand::{Rng, thread_rng};

        let mut rng = thread_rng();
        let mut s = String::new();
        for _ in 0..count {
            if rng.gen() {
                s.push('1');
            } else {
                s.push('0');
            }
        }
        s
    }

    let re = regex!(r"[01]*1[01]{20}$");
    let text = {
        let mut pieces = ones_and_zeroes(100_000);
        pieces.push('1');
        pieces.push_str(&ones_and_zeroes(20));
        pieces
    };
    assert!(re.is_match(text!(&*text)));
}
fn render_simple_inheritance_super() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("top", "{% block main %}TOP{% endblock main %}"),
        ("bottom", "{% extends \"top\" %}{% block main %}{{ super() }}MAIN{% endblock %}"),
    ])
    .unwrap();
    let result = tera.render("bottom", &Context::new());

    assert_eq!(result.unwrap(), "TOPMAIN".to_string());
}
fn test_node_merge_restart() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.run();

    let pd_client = Arc::clone(&cluster.pd_client);
    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");
    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    cluster.must_try_merge(left.get_id(), right.get_id());
    let leader = cluster.leader_of_region(left.get_id()).unwrap();

    cluster.shutdown();
    let engine = cluster.get_engine(leader.get_store_id());
    let state_key = keys::region_state_key(left.get_id());
    let state: RegionLocalState = engine.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();
    assert_eq!(state.get_state(), PeerState::Merging, "{:?}", state);
    let state_key = keys::region_state_key(right.get_id());
    let state: RegionLocalState = engine.get_msg_cf(CF_RAFT, &state_key).unwrap().unwrap();
    assert_eq!(state.get_state(), PeerState::Normal, "{:?}", state);
    fail::remove(schedule_merge_fp);
    cluster.start().unwrap();

    // Wait till merge is finished.
    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));

    cluster.must_put(b"k4", b"v4");

    for i in 1..4 {
        must_get_equal(&cluster.get_engine(i), b"k4", b"v4");
        let state_key = keys::region_state_key(left.get_id());
        let state: RegionLocalState = cluster
            .get_engine(i)
            .get_msg_cf(CF_RAFT, &state_key)
            .unwrap()
            .unwrap();
        assert_eq!(state.get_state(), PeerState::Tombstone, "{:?}", state);
        let state_key = keys::region_state_key(right.get_id());
        let state: RegionLocalState = cluster
            .get_engine(i)
            .get_msg_cf(CF_RAFT, &state_key)
            .unwrap()
            .unwrap();
        assert_eq!(state.get_state(), PeerState::Normal, "{:?}", state);
        assert!(state.get_region().get_start_key().is_empty());
        assert!(state.get_region().get_end_key().is_empty());
    }

    // Now test if cluster works fine when it crash after merge is applied
    // but before notifying raftstore thread.
    let region = pd_client.get_region(b"k1").unwrap();
    let peer_on_store1 = find_peer(&region, 1).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    cluster.must_split(&region, b"k2");
    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();
    let peer_on_store1 = find_peer(&left, 1).unwrap().to_owned();
    cluster.must_transfer_leader(left.get_id(), peer_on_store1);
    cluster.must_put(b"k11", b"v11");
    must_get_equal(&cluster.get_engine(3), b"k11", b"v11");
    let skip_destroy_fp = "raft_store_skip_destroy_peer";
    fail::cfg(skip_destroy_fp, "return()").unwrap();
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    pd_client.must_merge(left.get_id(), right.get_id());
    let peer = find_peer(&right, 3).unwrap().to_owned();
    pd_client.must_remove_peer(right.get_id(), peer);
    cluster.shutdown();
    fail::remove(skip_destroy_fp);
    cluster.clear_send_filters();
    cluster.start().unwrap();
    must_get_none(&cluster.get_engine(3), b"k1");
    must_get_none(&cluster.get_engine(3), b"k3");
}
fn test_float_to_string() {
    assert_eq!(Value::from(42.4242f64).to_string(), "42.4242");
    assert_eq!(Value::from(42.0f32).to_string(), "42.0");
}
fn test_hard_logical() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "file1";
    let link = "symlink1";
    let target = "hard-to-a";
    let target2 = "hard-to-a2";
    at.touch(file_a);
    at.symlink_file(file_a, link);

    ucmd.args(&["-P", "-L", link, target]);
    assert!(!at.is_symlink(target));

    ucmd.args(&["-P", "-L", "-s", link, target2]);
    assert!(!at.is_symlink(target2));
}
fn host_borrow_as_resource_any() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (import "f" (func $f (param "f" (borrow $t))))

                (core func $f (canon lower (func $f)))

                (core module $m
                    (import "" "f" (func $f (param i32)))
                    (func (export "f2") (param i32)
                        (call $f (local.get 0))
                    )
                )
                (core instance $i (instantiate $m
                    (with "" (instance
                        (export "f" (func $f))
                    ))
                ))

                (func (export "f2") (param "x" (borrow $t))
                    (canon lift (core func $i "f2")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());

    // First test the above component where the host properly drops the argument
    {
        let mut linker = Linker::new(&engine);
        linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
        linker
            .root()
            .func_wrap("f", |mut cx, (r,): (ResourceAny,)| {
                r.resource_drop(&mut cx)?;
                Ok(())
            })?;
        let i = linker.instantiate(&mut store, &c)?;

        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f2")?;

        let resource = Resource::new_own(100);
        f.call(&mut store, (&resource,))?;
    }

    // Then also test the case where the host forgets a drop
    {
        let mut linker = Linker::new(&engine);
        linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
        linker.root().func_wrap("f", |_cx, (_r,): (ResourceAny,)| {
            // ... no drop here
            Ok(())
        })?;
        let i = linker.instantiate(&mut store, &c)?;

        let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f2")?;

        let resource = Resource::new_own(100);
        let err = f.call(&mut store, (&resource,)).unwrap_err();
        assert!(
            format!("{err:?}").contains("borrow handles still remain at the end of the call"),
            "bad error: {err:?}"
        );
    }
    Ok(())
}
fn valid_linter_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
select = ["ALL"]
ignore = ["D203", "D212", "COM812", "ISC001"]

[lint.isort]
lines-after-imports = 2
lines-between-types = 1
force-wrap-aliases = true
combine-as-imports = true
split-on-trailing-comma = true

[lint.flake8-quotes]
inline-quotes = "single"
docstring-quotes = "double"
multiline-quotes = "double"

[format]
skip-magic-trailing-comma = false
quote-style = "single"
"#,
    )?;

    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["format", "--no-cache", "--config"])
        .arg(&ruff_toml)
        .arg(test_path), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    1 file reformatted

    ----- stderr -----
    "###);
    Ok(())
}
fn test_context_merge() {
    let one = context!(a => 1);
    let two = context!(b => 2, a => 42);
    let ctx = context![..one, ..two];
    assert_eq!(ctx.get_attr("a").unwrap(), Value::from(1));
    assert_eq!(ctx.get_attr("b").unwrap(), Value::from(2));

    let two = context!(b => 2, a => 42);
    let ctx = context!(a => 1, ..two);
    assert_eq!(ctx.get_attr("a").unwrap(), Value::from(1));
    assert_eq!(ctx.get_attr("b").unwrap(), Value::from(2));
}
fn signatures_match() -> Result<()> {
    let engine = Engine::default();
    let mut linker = Linker::<()>::new(&engine);

    linker.func_wrap("", "f1", || {})?;
    linker.func_wrap("", "f2", || -> i32 { loop {} })?;
    linker.func_wrap("", "f3", || -> i64 { loop {} })?;
    linker.func_wrap("", "f4", || -> f32 { loop {} })?;
    linker.func_wrap("", "f5", || -> f64 { loop {} })?;
    linker.func_wrap(
        "",
        "f6",
        |_: f32, _: f64, _: i32, _: i64, _: i32, _: Option<ExternRef>, _: Option<Func>| -> f64 {
            loop {}
        },
    )?;

    let mut store = Store::new(&engine, ());

    let f = linker
        .get(&mut store, "", "f1")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[]);

    let f = linker
        .get(&mut store, "", "f2")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::I32]);

    let f = linker
        .get(&mut store, "", "f3")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::I64]);

    let f = linker
        .get(&mut store, "", "f4")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F32]);

    let f = linker
        .get(&mut store, "", "f5")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F64]);

    let f = linker
        .get(&mut store, "", "f6")
        .unwrap()
        .into_func()
        .unwrap();
    assert_eq!(
        f.ty(&store).params().collect::<Vec<_>>(),
        &[
            ValType::F32,
            ValType::F64,
            ValType::I32,
            ValType::I64,
            ValType::I32,
            ValType::ExternRef,
            ValType::FuncRef,
        ]
    );
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F64]);

    Ok(())
}
fn issue349() {
    #[derive(Debug, Deserialize, Serialize, PartialEq)]
    struct Entity {
        id: Id,
    }
    #[derive(Debug, Deserialize, Serialize, PartialEq)]
    struct Id {
        #[serde(rename = "$value")]
        content: Enum,
    }
    #[derive(Debug, Deserialize, Serialize, PartialEq)]
    #[serde(rename_all = "kebab-case")]
    enum Enum {
        A(String),
        B(String),
    }

    assert_eq!(
        from_str::<Entity>("<entity><id><a>Id</a></id></entity>").unwrap(),
        Entity {
            id: Id {
                content: Enum::A("Id".to_string()),
            }
        }
    );
}
fn manual_fuel() {
    let mut config = Config::new();
    config.consume_fuel(true);
    let engine = Engine::new(&config).unwrap();
    let mut store = Store::new(&engine, ());
    store.add_fuel(10_000).unwrap();
    assert_eq!(store.fuel_consumed(), Some(0));
    assert_eq!(store.fuel_remaining(), Some(10_000));
    assert_eq!(store.consume_fuel(1).unwrap(), 9_999);
    assert_eq!(store.fuel_consumed(), Some(1));
    assert_eq!(store.fuel_remaining(), Some(9_999));
    assert!(store.consume_fuel(10_000).is_err());
    assert_eq!(store.consume_fuel(999).unwrap(), 9_000);
    assert!(store.consume_fuel(10_000).is_err());
    assert_eq!(store.consume_fuel(8998).unwrap(), 2);
    assert!(store.consume_fuel(3).is_err());
    assert_eq!(store.consume_fuel(1).unwrap(), 1);
    assert_eq!(store.consume_fuel(1).unwrap(), 0);
    assert_eq!(store.consume_fuel(0).unwrap(), 0);
    assert_eq!(store.fuel_remaining(), Some(0));
}
fn pragma_funciton_style() {
    let sql = "PRAGMA cache_size(10)";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::Pragma {
            name,
            value: Some(val),
            is_eq: false,
        } => {
            assert_eq!("cache_size", name.to_string());
            assert_eq!("10", val.to_string());
        }
        _ => unreachable!(),
    }
}
fn parse_bitwise_ops() {
    let bitwise_ops = &[
        ("^", BinaryOperator::BitwiseXor, all_dialects_but_pg()),
        ("|", BinaryOperator::BitwiseOr, all_dialects()),
        ("&", BinaryOperator::BitwiseAnd, all_dialects()),
    ];

    for (str_op, op, dialects) in bitwise_ops {
        let select = dialects.verified_only_select(&format!("SELECT a {} b", &str_op));
        assert_eq!(
            SelectItem::UnnamedExpr(Expr::BinaryOp {
                left: Box::new(Expr::Identifier(Ident::new("a"))),
                op: op.clone(),
                right: Box::new(Expr::Identifier(Ident::new("b"))),
            }),
            select.projection[0]
        );
    }
}
fn guest_different_host_same() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t1" (type $t1 (sub resource)))
                (import "t2" (type $t2 (sub resource)))

                (import "f" (func $f (param "a" (borrow $t1)) (param "b" (borrow $t2))))

                (export $g1 "g1" (type $t1))
                (export $g2 "g2" (type $t2))

                (core func $f (canon lower (func $f)))
                (core func $drop1 (canon resource.drop $t1))
                (core func $drop2 (canon resource.drop $t2))

                (core module $m
                    (import "" "f" (func $f (param i32 i32)))
                    (import "" "drop1" (func $drop1 (param i32)))
                    (import "" "drop2" (func $drop2 (param i32)))

                    (func (export "f") (param i32 i32)
                        ;; separate tables both have initial index of 0
                        (if (i32.ne (local.get 0) (i32.const 0)) (then (unreachable)))
                        (if (i32.ne (local.get 1) (i32.const 0)) (then (unreachable)))

                        ;; host should end up getting the same resource
                        (call $f (local.get 0) (local.get 1))

                        ;; drop our borrows
                        (call $drop1 (local.get 0))
                        (call $drop2 (local.get 0))
                    )
                )
                (core instance $i (instantiate $m
                    (with "" (instance
                        (export "f" (func $f))
                        (export "drop1" (func $drop1))
                        (export "drop2" (func $drop2))
                    ))
                ))

                (func (export "f2") (param "a" (borrow $g1)) (param "b" (borrow $g2))
                    (canon lift (core func $i "f")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t1", |_, _| Ok(()))?;
    linker.root().resource::<MyType>("t2", |_, _| Ok(()))?;
    linker.root().func_wrap(
        "f",
        |_cx, (r1, r2): (Resource<MyType>, Resource<MyType>)| {
            assert!(!r1.owned());
            assert!(!r2.owned());
            assert_eq!(r1.rep(), 100);
            assert_eq!(r2.rep(), 100);
            Ok(())
        },
    )?;
    let i = linker.instantiate(&mut store, &c)?;
    let f = i.get_typed_func::<(&Resource<MyType>, &Resource<MyType>), ()>(&mut store, "f2")?;

    let t1 = i.get_resource(&mut store, "g1").unwrap();
    let t2 = i.get_resource(&mut store, "g2").unwrap();
    assert_eq!(t1, t2);
    assert_eq!(t1, ResourceType::host::<MyType>());

    let resource = Resource::new_own(100);
    f.call(&mut store, (&resource, &resource))?;
    f.post_return(&mut store)?;

    Ok(())
}
fn invalid_inf_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.inf_string(Some(b"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf"));
    assert!(!builder.is_valid());
    builder = builder.inf_string(Some(b"nan"));
    assert!(!builder.is_valid());
    builder = builder.inf_string(Some(b"in00f"));
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.inf_string(Some(b"inf"));
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
    builder = builder.inf_string(None);
    assert!(builder.is_valid());
}
fn bh_test() {
    assert_eq!(bh(1e-45_f32), (3, -150));
    assert_eq!(bh(5e-324_f64), (3, -1075));
    assert_eq!(bh(1_f32), (16777217, -24));
    assert_eq!(bh(1_f64), (9007199254740993, -53));
    assert_eq!(bh(1e38_f32), (19721523, 102));
    assert_eq!(bh(1e308_f64), (10020841800044865, 970));
}
fn test_kill_with_signal_name_new_form() {
    let mut target = Target::new();
    new_ucmd!()
        .arg("-s")
        .arg("KILL")
        .arg(format!("{}", target.pid()))
        .succeeds();
    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));
}
fn parse_cast() {
    let sql = "SELECT CAST(id AS BIGINT) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::BigInt(None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS TINYINT) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::TinyInt(None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    one_statement_parses_to(
        "SELECT CAST(id AS MEDIUMINT) FROM customer",
        "SELECT CAST(id AS MEDIUMINT) FROM customer",
    );

    one_statement_parses_to(
        "SELECT CAST(id AS BIGINT) FROM customer",
        "SELECT CAST(id AS BIGINT) FROM customer",
    );

    verified_stmt("SELECT CAST(id AS NUMERIC) FROM customer");

    verified_stmt("SELECT CAST(id AS DEC) FROM customer");

    verified_stmt("SELECT CAST(id AS DECIMAL) FROM customer");

    let sql = "SELECT CAST(id AS NVARCHAR(50)) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Nvarchar(Some(50)),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS CLOB) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Clob(None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS CLOB(50)) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Clob(Some(50)),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS BINARY(50)) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Binary(Some(50)),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS VARBINARY(50)) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Varbinary(Some(50)),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS BLOB) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Blob(None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );

    let sql = "SELECT CAST(id AS BLOB(50)) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Cast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::Blob(Some(50)),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );
}
fn parse_drop_index() {
    let sql = "DROP INDEX idx_a";
    match verified_stmt(sql) {
        Statement::Drop {
            names, object_type, ..
        } => {
            assert_eq!(
                vec!["idx_a"],
                names.iter().map(ToString::to_string).collect::<Vec<_>>()
            );
            assert_eq!(ObjectType::Index, object_type);
        }
        _ => unreachable!(),
    }
}
fn is_endpoint_test() {
    assert_eq!(algorithm::is_endpoint(5, 2, 10), true);
    assert_eq!(algorithm::is_endpoint(5, 6, 10), false);
}
fn test_validate_endpoints_retry() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(Split::new()));
    let env = Arc::new(
        EnvBuilder::new()
            .cq_count(1)
            .name_prefix(thd_name!("test-pd"))
            .build(),
    );
    let mut eps = server.bind_addrs();
    let mock_port = 65535;
    eps.insert(0, ("127.0.0.1".to_string(), mock_port));
    eps.pop();
    let mgr = Arc::new(SecurityManager::new(&SecurityConfig::default()).unwrap());
    let connector = PdConnector::new(env, mgr);
    assert!(block_on(connector.validate_endpoints(&new_config(eps), true)).is_err());
}
fn compute_float_f64_test() {
    // These test near-halfway cases for double-precision floats.
    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));
    assert_eq!(compute_float64(0, 9007199254740993), (1065 + f64::INVALID_FP, 9223372036854776832));
    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));
    assert_eq!(compute_float64(0, 9007199254740995), (1065 + f64::INVALID_FP, 9223372036854778880));
    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));
    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));
    assert_eq!(
        compute_float64(0, 18014398509481986),
        (1066 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));
    assert_eq!(
        compute_float64(0, 18014398509481990),
        (1066 + f64::INVALID_FP, 9223372036854778880)
    );
    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));
    assert_eq!(
        compute_float64(-3, 9007199254740993000),
        (1065 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));
    assert_eq!(
        compute_float64(-3, 9007199254740995000),
        (1065 + f64::INVALID_FP, 9223372036854778879)
    );
    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));
}
fn role_change() {
    let (dir, mut cmd) = at_and_ucmd!();

    dir.touch("a.tmp");
    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    let new_a_context = if let Some(a_context) = a_context {
        let mut components: Vec<_> = a_context.split(':').collect();
        components[1] = "system_r";
        components.join(":")
    } else {
        set_file_context(dir.plus("a.tmp"), "unconfined_u:object_r:user_tmp_t:s0").unwrap();
        String::from("unconfined_u:system_r:user_tmp_t:s0")
    };

    cmd.args(&["--verbose", "--role=system_r"])
        .arg(dir.plus("a.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("a.tmp")).unwrap(),
        Some(new_a_context)
    );
}
fn test_gnu_special_filenames() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let perms_before = Permissions::from_mode(0o100_640);
    let perms_after = Permissions::from_mode(0o100_440);

    make_file(&at.plus_as_string("--"), perms_before.mode());
    scene.ucmd().arg("-w").arg("--").arg("--").succeeds();
    assert_eq!(at.metadata("--").permissions(), perms_after);
    set_permissions(at.plus("--"), perms_before.clone()).unwrap();
    scene.ucmd().arg("--").arg("-w").arg("--").succeeds();
    assert_eq!(at.metadata("--").permissions(), perms_after);
    at.remove("--");

    make_file(&at.plus_as_string("-w"), perms_before.mode());
    scene.ucmd().arg("-w").arg("--").arg("-w").succeeds();
    assert_eq!(at.metadata("-w").permissions(), perms_after);
    set_permissions(at.plus("-w"), perms_before).unwrap();
    scene.ucmd().arg("--").arg("-w").arg("-w").succeeds();
    assert_eq!(at.metadata("-w").permissions(), perms_after);
}
fn test_update_resoved_ts_before_apply_index() {
    let (mut cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));
    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));
    leader_client.ctx.set_stale_read(true);
    follower_client2.ctx.set_stale_read(true);

    // Write `(key1, value1)`
    let commit_ts1 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), commit_ts1);

    // Return before handling `apply_res`, to stop the leader updating the apply
    // index
    let on_apply_res_fp = "on_apply_res";
    fail::cfg(on_apply_res_fp, "return()").unwrap();
    // Stop replicate data to follower 2
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 2)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend),
    ));

    // Write `(key1, value2)`
    let commit_ts2 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value2"[..])],
        b"key1".to_vec(),
    );

    // Wait `resolved_ts` be updated
    sleep_ms(100);

    // The leader can't handle stale read with `commit_ts2` because its `safe_ts`
    // can't update due to its `apply_index` not update
    let resp = leader_client.kv_read(b"key1".to_vec(), commit_ts2);
    assert!(resp.get_region_error().has_data_is_not_ready(),);
    // The follower can't handle stale read with `commit_ts2` because it don't
    // have enough data
    let resp = follower_client2.kv_read(b"key1".to_vec(), commit_ts2);
    assert!(resp.get_region_error().has_data_is_not_ready());

    fail::remove(on_apply_res_fp);
    cluster.clear_send_filters();

    leader_client.must_kv_read_equal(b"key1".to_vec(), b"value2".to_vec(), commit_ts2);
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value2".to_vec(), commit_ts2);
}
fn TinyVec_swap_remove() {
  let mut tv: TinyVec<[i32; 10]> = Default::default();
  tv.push(1);
  tv.push(2);
  tv.push(3);
  tv.push(4);
  assert_eq!(tv.swap_remove(3), 4);
  assert_eq!(&tv[..], &[1, 2, 3][..]);
  assert_eq!(tv.swap_remove(0), 1);
  assert_eq!(&tv[..], &[3, 2][..]);
  assert_eq!(tv.swap_remove(0), 3);
  assert_eq!(&tv[..], &[2][..]);
  assert_eq!(tv.swap_remove(0), 2);
  assert_eq!(&tv[..], &[][..]);
}
fn drain_filter_lifetime() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<&str, &str> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let txn = db.begin_write().unwrap();
    let mut table = txn.open_table(definition).unwrap();

    let mut iter = {
        let start = "hello".to_string();
        table.drain_filter(start.as_str().., |_, _| true).unwrap()
    };
    assert_eq!(iter.next().unwrap().unwrap().1.value(), "world");
    assert!(iter.next().is_none());
}
fn test_decrease_async_ios() {
    let mut cluster = new_node_cluster(0, 1);
    cluster.cfg.raft_store.store_io_pool_size = 4;
    cluster.pd_client.disable_default_operator();
    cluster.run();

    // Save current async-io tids before shrinking
    let org_writers_tids = get_async_writers_tids();
    assert_eq!(4, org_writers_tids.len());
    // Request can be handled as usual
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(1), b"k1", b"v1");

    // Update config, shrink from 4 to 1
    {
        let sim = cluster.sim.rl();
        let cfg_controller = sim.get_cfg_controller().unwrap();
        let change = {
            let mut change = HashMap::new();
            change.insert("raftstore.store-io-pool-size".to_owned(), "1".to_owned());
            change
        };

        cfg_controller.update(change).unwrap();
        assert_eq!(
            cfg_controller.get_current().raft_store.store_io_pool_size,
            1
        );
        // Wait for the completion of decreasing async-ios
        std::thread::sleep(std::time::Duration::from_secs(1));
    }

    // Save current async-io tids after scaling down, and compared with the
    // orginial one before shrinking. As the decreasing of async-ios won't
    // release asynchronous writers, the thread num should not be updated.
    let cur_writers_tids = get_async_writers_tids();
    assert_eq!(cur_writers_tids.len(), org_writers_tids.len());
    // After shrinking, all the left tids must be there before
    for tid in cur_writers_tids {
        assert!(org_writers_tids.contains(&tid));
    }
    // Request can be handled as usual
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
}
fn test_closing_bracket_in_double_quote_attr() {
    let mut r = Reader::from_str(r#"<a attr=">" check="2"></a>"#);
    r.trim_text(true);
    match r.read_event() {
        Ok(Start(e)) => {
            let mut attrs = e.attributes();
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"attr"),
                    value: Cow::Borrowed(b">"),
                }))
            );
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"check"),
                    value: Cow::Borrowed(b"2"),
                }))
            );
            assert_eq!(attrs.next(), None);
        }
        x => panic!("expected <a attr='>'>, got {:?}", x),
    }
    next_eq!(r, End, b"a");
}
fn test_skip_iter_ilt() {
    // Test iterators that skip single digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_leading_digit_separator(true)
        .integer_trailing_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"_45_5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"_.45_5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4_5_");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4_5_.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"_45_");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"_45_.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"_4_5_");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"45.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"_4_5_.56");
}
fn internal_n_mask_test() {
    assert_eq!(internal_n_mask(1u64, 0u64), 0b0);
    assert_eq!(internal_n_mask(1u64, 1u64), 0b1);
    assert_eq!(internal_n_mask(2u64, 1u64), 0b10);
    assert_eq!(internal_n_mask(4u64, 2u64), 0b1100);
    assert_eq!(internal_n_mask(10u64, 2u64), 0b1100000000);
    assert_eq!(internal_n_mask(10u64, 4u64), 0b1111000000);
    assert_eq!(
        internal_n_mask(32u64, 4u64),
        0b11110000000000000000000000000000
    );
}
fn test_no_timeout() {
    #[allow(deprecated)]
    let sequence =
        iter(vec![Ok(1), Err("error"), Ok(2)]).map_err(|e| io::Error::new(io::ErrorKind::Other, e));
    let core = Runtime::new().expect("could not get core");

    let timeout_stream = TimeoutStream::new(sequence, Duration::from_secs(360));

    let (val, timeout_stream) = core.block_on(timeout_stream.into_future());
    assert_eq!(val.expect("nothing in stream").ok(), Some(1));

    let (error, timeout_stream) = core.block_on(timeout_stream.into_future());
    assert!(error.expect("nothing in stream").is_err());

    let (val, timeout_stream) = core.block_on(timeout_stream.into_future());
    assert_eq!(val.expect("nothing in stream").ok(), Some(2));

    let (val, _) = core.block_on(timeout_stream.into_future());
    assert!(val.is_none())
}
fn test_indent_one_empty_line() {
    let teststring = String::from("\n");
    assert_eq!(indent(teststring, 2, None, None), String::from(""));
}
fn blackhole_after_mtu_change_repairs_itself() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    pair.mtu = 1500;
    let (client_ch, server_ch) = pair.connect();
    pair.drive();

    // Sanity check
    assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), 1452);
    assert_eq!(pair.server_conn_mut(server_ch).path_mtu(), 1452);

    // Back to the base MTU
    pair.mtu = 1200;

    // The payload will be sent in a single packet, because the detected MTU was 1444, but it will
    // be dropped because the link no longer supports that packet size!
    let payload = vec![42; 1300];
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    pair.client_send(client_ch, s).write(&payload).unwrap();
    let out_of_bounds = pair.drive_bounded();

    if out_of_bounds {
        panic!("Connections never reached an idle state");
    }

    let recv = pair.server_recv(server_ch, s);
    let buf = stream_chunks(recv);

    // The whole packet arrived in the end
    assert_eq!(buf.len(), 1300);

    // Sanity checks (black hole detected after 3 lost packets)
    let client_stats = pair.client_conn_mut(client_ch).stats();
    assert!(client_stats.path.lost_packets >= 3);
    assert!(client_stats.path.congestion_events >= 3);
    assert_eq!(client_stats.path.black_holes_detected, 1);
}
fn test_update_config() {
    let (mut cfg, _dir) = TikvConfig::with_tmp().unwrap();
    cfg.validate().unwrap();
    let cfg_controller = ConfigController::new(cfg);
    let mut cfg = cfg_controller.get_current();

    // normal update
    cfg_controller
        .update(change("raftstore.raft-log-gc-threshold", "2000"))
        .unwrap();
    cfg.raft_store.raft_log_gc_threshold = 2000;
    assert_eq!(cfg_controller.get_current(), cfg);

    // update not support config
    let res = cfg_controller.update(change("server.addr", "localhost:3000"));
    res.unwrap_err();
    assert_eq!(cfg_controller.get_current(), cfg);

    // update to invalid config
    let res = cfg_controller.update(change("raftstore.raft-log-gc-threshold", "0"));
    res.unwrap_err();
    assert_eq!(cfg_controller.get_current(), cfg);

    // bad update request
    let res = cfg_controller.update(change("xxx.yyy", "0"));
    res.unwrap_err();
    let res = cfg_controller.update(change("raftstore.xxx", "0"));
    res.unwrap_err();
    let res = cfg_controller.update(change("raftstore.raft-log-gc-threshold", "10MB"));
    res.unwrap_err();
    let res = cfg_controller.update(change("raft-log-gc-threshold", "10MB"));
    res.unwrap_err();
    assert_eq!(cfg_controller.get_current(), cfg);
}
fn test_du_inodes() {
    let ts = TestScenario::new(util_name!());

    ts.ucmd()
        .arg("--summarize")
        .arg("--inodes")
        .succeeds()
        .stdout_only("11\t.\n");

    let result = ts.ucmd().arg("--separate-dirs").arg("--inodes").succeeds();

    #[cfg(target_os = "windows")]
    result.stdout_contains("3\t.\\subdir\\links\n");
    #[cfg(not(target_os = "windows"))]
    result.stdout_contains("3\t./subdir/links\n");
    result.stdout_contains("3\t.\n");

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference =
            unwrap_or_return!(expected_result(&ts, &["--separate-dirs", "--inodes"]));
        assert_eq!(result.stdout_str(), result_reference.stdout_str());
    }
}
fn cannot_serialize_exported_module() -> Result<()> {
    let engine = super::engine();
    let component = Component::new(
        &engine,
        r#"(component
            (core module $m)
            (export "a" (core module $m))
        )"#,
    )?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let module = instance.get_module(&mut store, "a").unwrap();
    assert!(module.serialize().is_err());
    Ok(())
}
fn test_install_target_new_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "file";
    let dir = "target_dir";

    at.touch(file);
    at.mkdir(dir);
    ucmd.arg(file)
        .arg(format!("{dir}/{file}"))
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));
    assert!(at.file_exists(format!("{dir}/{file}")));
}
fn check_for_end_code_is_configurable() {
    // In this particular image, the image data of the 62nd frame has no end code.
    let image: &[u8] = include_bytes!(concat!(env!("CARGO_MANIFEST_DIR"), "/tests/samples/gifplayer-muybridge.gif"));

    {
        let options = DecodeOptions::new();
        let mut decoder = options.clone().read_info(&image[..]).unwrap();
        for _ in 0..61 {
            assert!(decoder.read_next_frame().is_ok());
        }
        assert!(decoder.read_next_frame().is_ok());
    }

    {
        let mut options = DecodeOptions::new();
        options.check_lzw_end_code(true);
        let mut decoder = options.clone().read_info(&image[..]).unwrap();
        for _ in 0..61 {
            assert!(decoder.read_next_frame().is_ok());
        }
        assert!(decoder.read_next_frame().is_err());
    }
}
fn instance_exports() -> Result<()> {
    let engine = super::engine();
    let component = r#"
        (component
            (import "a" (instance $i))
            (import "b" (instance $i2 (export "m" (core module))))

            (alias export $i2 "m" (core module $m))

            (component $c
                (component $c
                    (export "m" (core module $m))
                )
                (instance $c (instantiate $c))
                (export "i" (instance $c))
            )
            (instance $c (instantiate $c))
            (export "i" (instance $c))
            (export "r" (instance $i))
            (export "r2" (instance $i2))
        )
    "#;
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.instance("a")?;
    linker
        .instance("b")?
        .module("m", &Module::new(&engine, "(module)")?)?;
    let instance = linker.instantiate(&mut store, &component)?;

    let mut exports = instance.exports(&mut store);
    assert!(exports.instance("not an instance").is_none());
    let mut i = exports.instance("r").unwrap();
    assert!(i.func("x").is_none());
    drop(i);
    exports.root().instance("i").unwrap();
    let mut i2 = exports.instance("r2").unwrap();
    assert!(i2.func("m").is_none());
    assert!(i2.module("m").is_some());
    drop(i2);

    exports
        .instance("i")
        .unwrap()
        .instance("i")
        .unwrap()
        .module("m")
        .unwrap();

    Ok(())
}
fn attempt_to_reenter_during_host() -> Result<()> {
    let component = r#"
(component
  (import "thunk" (func $thunk))
  (core func $thunk_lower (canon lower (func $thunk)))

  (core module $m
    (import "host" "thunk" (func $thunk))

    (func $run (export "run")
      call $thunk)
  )
  (core instance $m (instantiate $m
    (with "host" (instance (export "thunk" (func $thunk_lower))))
  ))

  (func (export "run")
    (canon lift (core func $m "run"))
  )
)
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;

    // First, test the static API

    struct StaticState {
        func: Option<TypedFunc<(), ()>>,
    }

    let mut store = Store::new(&engine, StaticState { func: None });
    let mut linker = Linker::new(&engine);
    linker.root().func_wrap(
        "thunk",
        |mut store: StoreContextMut<'_, StaticState>, _: ()| -> Result<()> {
            let func = store.data_mut().func.take().unwrap();
            let trap = func.call(&mut store, ()).unwrap_err();
            assert_eq!(
                trap.downcast_ref(),
                Some(&Trap::CannotEnterComponent),
                "bad trap: {trap:?}",
            );
            Ok(())
        },
    )?;
    let instance = linker.instantiate(&mut store, &component)?;
    let func = instance.get_typed_func::<(), ()>(&mut store, "run")?;
    store.data_mut().func = Some(func);
    func.call(&mut store, ())?;

    // Next, test the dynamic API

    struct DynamicState {
        func: Option<Func>,
    }

    let mut store = Store::new(&engine, DynamicState { func: None });
    let mut linker = Linker::new(&engine);
    linker.root().func_new(
        &component,
        "thunk",
        |mut store: StoreContextMut<'_, DynamicState>, _, _| {
            let func = store.data_mut().func.take().unwrap();
            let trap = func.call(&mut store, &[], &mut []).unwrap_err();
            assert_eq!(
                trap.downcast_ref(),
                Some(&Trap::CannotEnterComponent),
                "bad trap: {trap:?}",
            );
            Ok(())
        },
    )?;
    let instance = linker.instantiate(&mut store, &component)?;
    let func = instance.get_func(&mut store, "run").unwrap();
    store.data_mut().func = Some(func);
    func.call(&mut store, &[], &mut [])?;

    Ok(())
}
fn test_change_directory() {
    let scene = TestScenario::new(util_name!());
    let temporary_directory = tempdir().unwrap();
    let temporary_path = std::fs::canonicalize(temporary_directory.path()).unwrap();
    assert_ne!(env::current_dir().unwrap(), temporary_path);

    // command to print out current working directory
    let pwd = "pwd";

    let out = scene
        .ucmd()
        .arg("--chdir")
        .arg(&temporary_path)
        .arg(pwd)
        .succeeds()
        .stdout_move_str();
    assert_eq!(out.trim(), temporary_path.as_os_str());
}
fn test_incompatible_version() {
    let incompatible = Arc::new(Incompatible);
    let server = MockServer::with_case(1, incompatible);
    let eps = server.bind_addrs();

    let client = new_client(eps, None);

    let resp = block_on(client.ask_batch_split(metapb::Region::default(), 2));
    assert_eq!(
        resp.unwrap_err().to_string(),
        PdError::Incompatible.to_string()
    );
}
fn test_basics() {
    assert_eq!(bool::deserialize(Value::from(true)).unwrap(), true);
    assert_eq!(bool::deserialize(Value::from(false)).unwrap(), false);
    assert_eq!(f32::deserialize(Value::from(1.0)).unwrap(), 1.0);
    assert_eq!(i32::deserialize(Value::from(2)).unwrap(), 2);
    assert_eq!(String::deserialize(Value::from("foo")).unwrap(), "foo");
    assert_eq!(Option::<i32>::deserialize(Value::from(2)).unwrap(), Some(2));
    assert_eq!(Option::<i32>::deserialize(Value::from(())).unwrap(), None);
}
fn regex_string() {
    assert_eq!(r"[a-zA-Z0-9]+", regex!(r"[a-zA-Z0-9]+").as_str());
    assert_eq!(r"[a-zA-Z0-9]+", &format!("{}", regex!(r"[a-zA-Z0-9]+")));
    assert_eq!(r"[a-zA-Z0-9]+", &format!("{:?}", regex!(r"[a-zA-Z0-9]+")));
}
fn parse_import_macro() {
    let ast = parse("\n{% import \"macros.html\" as macros -%}").unwrap();
    assert_eq!(
        ast[0],
        Node::ImportMacro(
            WS { left: false, right: true },
            "macros.html".to_string(),
            "macros".to_string(),
        ),
    );
}
fn render_magic_variable_macro_doesnt_leak() {
    let mut context = Context::new();
    context.insert("html", &"<html>");
    context.insert("num", &1);
    context.insert("i", &10);

    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello(arg=1) %}{{ __tera_context }}{% endmacro hello %}"),
        ("tpl", "{% import \"macros\" as macros %}{{macros::hello()}}"),
    ])
    .unwrap();
    let result = tera.render("tpl", &context);

    assert_eq!(
        result.unwrap(),
        r#"{
  "arg": 1
}"#
        .to_owned()
    );
}
fn parse_derived_tables() {
    let sql = "SELECT a.x, b.y FROM (SELECT x FROM foo) AS a CROSS JOIN (SELECT y FROM bar) AS b";
    let _ = verified_only_select(sql);
    //TODO: add assertions

    let sql = "SELECT a.x, b.y \
               FROM (SELECT x FROM foo) AS a (x) \
               CROSS JOIN (SELECT y FROM bar) AS b (y)";
    let _ = verified_only_select(sql);
    //TODO: add assertions

    let sql = "SELECT * FROM (((SELECT 1)))";
    let _ = verified_only_select(sql);
    // TODO: add assertions

    let sql = "SELECT * FROM t NATURAL JOIN (((SELECT 1)))";
    let _ = verified_only_select(sql);
    // TODO: add assertions

    let sql = "SELECT * FROM (((SELECT 1) UNION (SELECT 2)) AS t1 NATURAL JOIN t2)";
    let select = verified_only_select(sql);
    let from = only(select.from);
    assert_eq!(
        from.relation,
        TableFactor::NestedJoin {
            table_with_joins: Box::new(TableWithJoins {
                relation: TableFactor::Derived {
                    lateral: false,
                    subquery: Box::new(verified_query("(SELECT 1) UNION (SELECT 2)")),
                    alias: Some(TableAlias {
                        name: "t1".into(),
                        columns: vec![],
                    }),
                },
                joins: vec![Join {
                    relation: TableFactor::Table {
                        name: ObjectName(vec!["t2".into()]),
                        alias: None,
                        args: None,
                        with_hints: vec![],
                        version: None,
                        partitions: vec![],
                    },
                    join_operator: JoinOperator::Inner(JoinConstraint::Natural),
                }],
            }),
            alias: None,
        }
    );
}
fn test_simple() {
    assert_eq!(
        from_str(
            "/*
 * We got a hexadecimal number here!
 *
 */0x507"
        ),
        Ok(0x507)
    );
}
fn i64_decimal_test() {
    assert_eq!(Ok(0), i64::from_lexical(b"0"));
    assert_eq!(Ok(9223372036854775807), i64::from_lexical(b"9223372036854775807"));
    assert_eq!(Err(Error::Overflow(18)), i64::from_lexical(b"9223372036854775808"));
    assert_eq!(Err(Error::Overflow(19)), i64::from_lexical(b"18446744073709551615"));
    assert_eq!(Ok(-1), i64::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), i64::from_lexical(b"1a"));

    // Add tests discovered via fuzzing. This won't necessarily be the
    // proper index, since we use multi-digit parsing.
    assert!(i64::from_lexical(b"406260572150672006000066000000060060007667760000000000000000000+00000006766767766666767665670000000000000000000000666").err().unwrap().is_invalid_digit());
    assert!(i64::from_lexical(b"406260572150672006000066000000060060007667760000000000000000000")
        .err()
        .unwrap()
        .is_overflow());
}
fn parse_variable_tag_macro_call_with_array() {
    let ast = parse("{{ macros::get_time(some=[1, 2]) }}").unwrap();
    let mut args = HashMap::new();
    args.insert(
        "some".to_string(),
        Expr::new(ExprVal::Array(vec![Expr::new(ExprVal::Int(1)), Expr::new(ExprVal::Int(2))])),
    );

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::MacroCall(MacroCall {
                namespace: "macros".to_string(),
                name: "get_time".to_string(),
                args,
            },))
        )
    );
}
fn preview2_stdin() -> Result<()> {
    let test = "tests/all/cli_tests/count-stdin.wat";
    let cmd = || -> Result<_> {
        let mut cmd = get_wasmtime_command()?;
        cmd.arg("--invoke=count").arg("-Spreview2").arg(test);
        Ok(cmd)
    };

    // read empty pipe is ok
    let output = cmd()?.output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), "0\n");

    // read itself is ok
    let file = File::open(test)?;
    let size = file.metadata()?.len();
    let output = cmd()?.stdin(File::open(test)?).output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), format!("{size}\n"));

    // read piped input ok is ok
    let mut child = cmd()?
        .stdin(Stdio::piped())
        .stdout(Stdio::piped())
        .stderr(Stdio::piped())
        .spawn()?;
    let mut stdin = child.stdin.take().unwrap();
    std::thread::spawn(move || {
        stdin.write_all(b"hello").unwrap();
    });
    let output = child.wait_with_output()?;
    assert!(output.status.success());
    assert_eq!(String::from_utf8_lossy(&output.stdout), "5\n");

    let count_up_to = |n: usize| -> Result<_> {
        let mut child = get_wasmtime_command()?
            .arg("--invoke=count-up-to")
            .arg("-Spreview2")
            .arg(test)
            .arg(n.to_string())
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .stderr(Stdio::piped())
            .spawn()?;
        let mut stdin = child.stdin.take().unwrap();
        let t = std::thread::spawn(move || {
            let mut written = 0;
            let bytes = [0; 64 * 1024];
            loop {
                written += match stdin.write(&bytes) {
                    Ok(n) => n,
                    Err(_) => break written,
                };
            }
        });
        let output = child.wait_with_output()?;
        assert!(output.status.success());
        let written = t.join().unwrap();
        let read = String::from_utf8_lossy(&output.stdout)
            .trim()
            .parse::<usize>()
            .unwrap();
        // The test reads in 1000 byte chunks so make sure that it doesn't read
        // more than 1000 bytes than requested.
        assert!(read < n + 1000, "test read too much {read}");
        Ok(written)
    };

    // wasmtime shouldn't eat information that the guest never actually tried to
    // read.
    //
    // NB: this may be a bit flaky. Exactly how much we wrote in the above
    // helper thread depends on how much the OS buffers for us. For now give
    // some some slop and assume that OSes are unlikely to buffer more than
    // that.
    let slop = 256 * 1024;
    for amt in [0, 100, 100_000] {
        let written = count_up_to(amt)?;
        assert!(written < slop + amt, "wrote too much {written}");
    }
    Ok(())
}
fn lower_n_halfway_test() {
    assert_eq!(lower_n_halfway(0u64), 0b0);
    assert_eq!(lower_n_halfway(1u64), 0b1);
    assert_eq!(lower_n_halfway(2u64), 0b10);
    assert_eq!(lower_n_halfway(10u64), 0b1000000000);
    assert_eq!(lower_n_halfway(32u64), 0b10000000000000000000000000000000);
}
fn test_delete_all() {
    use hickory_proto::rr::rdata::AAAA;

    let io_loop = Runtime::new().unwrap();
    let ((mut client, bg), origin) = io_loop.block_on(create_sig0_ready_client());
    hickory_proto::spawn_bg(&io_loop, bg);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = io_loop
        .block_on(client.delete_all(record.name().clone(), origin.clone(), DNSClass::IN))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = io_loop
        .block_on(client.create(record.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    record.set_rr_type(RecordType::AAAA);
    record.set_data(Some(RData::AAAA(AAAA::new(1, 2, 3, 4, 5, 6, 7, 8))));
    let result = io_loop
        .block_on(client.create(record.clone(), origin.clone()))
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = io_loop
        .block_on(client.delete_all(record.name().clone(), origin, DNSClass::IN))
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = io_loop
        .block_on(client.query(record.name().clone(), record.dns_class(), RecordType::A))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);

    let result = io_loop
        .block_on(client.query(record.name().clone(), record.dns_class(), RecordType::AAAA))
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);
}
fn test_du_inodes_basic() {
    let ts = TestScenario::new(util_name!());
    let result = ts.ucmd().arg("--inodes").succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &["--inodes"]));
        assert_eq!(result.stdout_str(), result_reference.stdout_str());
    }

    #[cfg(not(any(target_os = "linux", target_os = "android")))]
    _du_inodes_basic(result.stdout_str());
}
fn intersect() {
    assert_eq!(range(1..2).intersect(range(2..3)), Some(range(2..2)));
    assert_eq!(range(1..5).intersect(range(2..3)), Some(range(2..3)));
    assert_eq!(range(1..2).intersect(range(3..4)), None);
}
fn ok_read_only() {
    let mut fs = MemoryFileSystem::new_read_only();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), FORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");
}
fn parse_create_or_replace_external_table() {
    // Supported by at least Snowflake
    // https://docs.snowflake.com/en/sql-reference/sql/create-external-table.html
    let sql = "CREATE OR REPLACE EXTERNAL TABLE uk_cities (\
               name VARCHAR(100) NOT NULL)\
               STORED AS TEXTFILE LOCATION '/tmp/example.csv'";
    let ast = one_statement_parses_to(
        sql,
        "CREATE OR REPLACE EXTERNAL TABLE uk_cities (\
         name VARCHAR(100) NOT NULL) \
         STORED AS TEXTFILE LOCATION '/tmp/example.csv'",
    );
    match ast {
        Statement::CreateTable {
            name,
            columns,
            constraints,
            with_options,
            if_not_exists,
            external,
            file_format,
            location,
            or_replace,
            ..
        } => {
            assert_eq!("uk_cities", name.to_string());
            assert_eq!(
                columns,
                vec![ColumnDef {
                    name: "name".into(),
                    data_type: DataType::Varchar(Some(CharacterLength {
                        length: 100,
                        unit: None,
                    })),
                    collation: None,
                    options: vec![ColumnOptionDef {
                        name: None,
                        option: ColumnOption::NotNull,
                    }],
                },]
            );
            assert!(constraints.is_empty());

            assert!(external);
            assert_eq!(FileFormat::TEXTFILE, file_format.unwrap());
            assert_eq!("/tmp/example.csv", location.unwrap());

            assert_eq!(with_options, vec![]);
            assert!(!if_not_exists);
            assert!(or_replace);
        }
        _ => unreachable!(),
    }
}
fn test_indent_with_all_indented() {
    let teststring = String::from("test\ntest1\n\ntest2\n");
    assert_eq!(
        indent(teststring, 2, Some(true), Some(true)),
        String::from("  test\n  test1\n  \n  test2")
    );
}
fn test_mv_arg_update_all_then_none() {
    // take last if multiple update args are supplied,
    // update=none wins in this case
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_mv_arg_update_all_then_none_file1";
    let new = "test_mv_arg_update_all_then_none_file2";
    let old_content = "old content\n";
    let new_content = "new content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(old)
        .arg(new)
        .arg("--update=all")
        .arg("--update=none")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(new), "new content\n");
}
fn inscribe_with_parent_inscription_and_fee_rate() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);
  rpc_server.mine_blocks(1);

  let parent_output = CommandBuilder::new("wallet inscribe --fee-rate 5.0 --file parent.png")
    .write("parent.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  assert_eq!(rpc_server.descriptors().len(), 3);
  let parent_id = parent_output.inscriptions[0].id;

  let commit_tx = &rpc_server.mempool()[0];
  let reveal_tx = &rpc_server.mempool()[1];

  assert_eq!(
    ord::FeeRate::try_from(5.0)
      .unwrap()
      .fee(commit_tx.vsize() + reveal_tx.vsize())
      .to_sat(),
    parent_output.total_fees
  );

  rpc_server.mine_blocks(1);

  let child_output = CommandBuilder::new(format!(
    "wallet inscribe --fee-rate 7.3 --parent {parent_id} --file child.png"
  ))
  .write("child.png", [1; 520])
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Inscribe>();

  assert_eq!(rpc_server.descriptors().len(), 4);
  assert_eq!(parent_id, child_output.parent.unwrap());

  let commit_tx = &rpc_server.mempool()[0];
  let reveal_tx = &rpc_server.mempool()[1];

  assert_eq!(
    ord::FeeRate::try_from(7.3)
      .unwrap()
      .fee(commit_tx.vsize() + reveal_tx.vsize())
      .to_sat(),
    child_output.total_fees
  );

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  ord_server.assert_response_regex(
    format!("/inscription/{}", child_output.parent.unwrap()),
    format!(
      ".*<dt>children</dt>.*<a href=/inscription/{}>.*",
      child_output.inscriptions[0].id
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", child_output.inscriptions[0].id),
    format!(
      ".*<dt>parent</dt>.*<a class=monospace href=/inscription/{}>.*",
      child_output.parent.unwrap()
    ),
  );
}
fn test_streamsafe_regression(){
    let input = "\u{342}".repeat(55) + &"\u{344}".repeat(3);
    let nfc_ss = input.chars().nfc().stream_safe().collect::<String>();

    // The result should be NFC:
    assert!(is_nfc(&nfc_ss));
    // and should be stream-safe:
    assert!(is_nfc_stream_safe(&nfc_ss))
}
fn create_with_different_name() {
  let rpc_server = test_bitcoincore_rpc::spawn();

  assert!(!rpc_server.wallets().contains("inscription-wallet"));

  CommandBuilder::new("--wallet inscription-wallet wallet create")
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Output>();

  assert!(rpc_server.wallets().contains("inscription-wallet"));
}
fn strip_inline_internal_text() {
    assert_eq!(
        "<u>a </u>b <u>c</u>",
        normalize_html("<u> a </u> b <u> c </u>")
    )
}
fn test_when_warmup_fail_and_its_timeout_is_too_long() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.max_entry_cache_warmup_duration = ReadableDuration::secs(1000);
    prevent_from_gc_raft_log(&mut cluster);
    run_cluster_for_test_warmup_entry_cache(&mut cluster);

    fail::cfg("worker_async_fetch_raft_log", "pause").unwrap();
    cluster.transfer_leader(1, new_peer(2, 2));
    // Theoretically, the leader transfer can't succeed unless it sleeps
    // max_entry_cache_warmup_duration.
    sleep_ms(50);
    let leader = cluster.leader_of_region(1).unwrap();
    assert_eq!(leader.get_id(), 1);
}
fn fast_path_complete_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::new();
    let string = b"1.2345e10";
    let result = parse::fast_path_complete::<f64, FORMAT>(string, &options);
    assert_eq!(result, Ok(1.2345e10));

    let string = b"1.2345e";
    let result = parse::fast_path_complete::<f64, FORMAT>(string, &options);
    assert!(result.is_err());

    let string = b"1.2345 ";
    let result = parse::fast_path_complete::<f64, FORMAT>(string, &options);
    assert!(result.is_err());
}
fn test_replication_mode_allowlist() {
    let mut cluster = prepare_cluster();
    run_cluster(&mut cluster);
    cluster
        .pd_client
        .switch_replication_mode(DrAutoSyncState::Async, vec![1]);
    thread::sleep(Duration::from_millis(100));

    // 2,3 are paused, so it should not be able to write.
    let region = cluster.get_region(b"k1");
    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_put_cf_cmd("default", b"k2", b"v2")],
        false,
    );
    request.mut_header().set_peer(new_peer(1, 1));
    let (cb, mut rx) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, request, cb)
        .unwrap();
    assert_eq!(
        rx.recv_timeout(Duration::from_millis(100)),
        Err(future::RecvTimeoutError::Timeout)
    );

    // clear allowlist.
    cluster
        .pd_client
        .switch_replication_mode(DrAutoSyncState::Async, vec![]);
    rx.recv_timeout(Duration::from_millis(100)).unwrap();
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
}
fn test_serde_default_config() {
    let cfg: TikvConfig = toml::from_str("").unwrap();
    assert_eq!(cfg, TikvConfig::default());

    let content = read_file_in_project_dir("integrations/config/test-default.toml");
    let cfg: TikvConfig = toml::from_str(&content).unwrap();
    assert_eq!(cfg, TikvConfig::default());
}
fn json_with_comments() {
    let f = super::fixture_root().join("parcel/tsconfig/trailing-comma");

    let resolver = Resolver::new(ResolveOptions {
        tsconfig: Some(TsconfigOptions {
            config_file: f.join("tsconfig.json"),
            references: TsconfigReferences::Auto,
        }),
        ..ResolveOptions::default()
    });

    let resolved_path = resolver.resolve(&f, "foo").map(|f| f.full_path());
    assert_eq!(resolved_path, Ok(f.join("bar.js")));
}
fn same_import_names_still_distinct() -> anyhow::Result<()> {
    const WAT: &str = r#"
(module
  (import "" "" (func $a (result i32)))
  (import "" "" (func $b (result f32)))
  (func (export "foo") (result i32)
    call $a
    call $b
    i32.trunc_f32_u
    i32.add)
)
    "#;

    let mut store = Store::<()>::default();
    let module = Module::new(store.engine(), WAT)?;

    let imports = [
        Func::new(
            &mut store,
            FuncType::new(None, Some(ValType::I32)),
            |_, params, results| {
                assert!(params.is_empty());
                assert_eq!(results.len(), 1);
                results[0] = 1i32.into();
                Ok(())
            },
        )
        .into(),
        Func::new(
            &mut store,
            FuncType::new(None, Some(ValType::F32)),
            |_, params, results| {
                assert!(params.is_empty());
                assert_eq!(results.len(), 1);
                results[0] = 2.0f32.into();
                Ok(())
            },
        )
        .into(),
    ];
    let instance = Instance::new(&mut store, &module, &imports)?;

    let func = instance.get_typed_func::<(), i32>(&mut store, "foo")?;
    let result = func.call(&mut store, ())?;
    assert_eq!(result, 3);
    Ok(())
}
fn parse_mod() {
    use self::Expr::*;
    let sql = "a % b";
    assert_eq!(
        BinaryOp {
            left: Box::new(Identifier(Ident::new("a"))),
            op: BinaryOperator::Modulo,
            right: Box::new(Identifier(Ident::new("b"))),
        },
        verified_expr(sql)
    );
}
fn test_proc_macro2_fallback_span_size_without_locations() {
    assert_eq!(mem::size_of::<proc_macro2::Span>(), 0);
    assert_eq!(mem::size_of::<Option<proc_macro2::Span>>(), 1);
}
fn test_install_twice_dir() {
    let dir = "dir";
    let scene = TestScenario::new(util_name!());

    scene.ucmd().arg("-d").arg(dir).succeeds();
    scene.ucmd().arg("-d").arg(dir).succeeds();
    let at = &scene.fixtures;

    assert!(at.dir_exists(dir));
}
fn test_dateformat_chrono_rs() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATE_FORMAT", "[year]-[month]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("d|dateformat(format=format)")
        .unwrap();

    let d = chrono::NaiveDate::from_num_days_from_ce_opt(739073);
    assert_eq!(
        expr.eval(context!(d, format => "short"))
            .unwrap()
            .to_string(),
        "2024-07-06"
    );

    assert_eq!(
        expr.eval(context!(d => "2024-07-06", format => "short"))
            .unwrap()
            .to_string(),
        "2024-07-06"
    );
}
fn test_region_heartbeat() {
    let region_id = 2;
    let cluster = Cluster::with_node_count(1, None);
    let router = &cluster.routers[0];

    // When there is only one peer, it should campaign immediately.
    let mut req = RaftCmdRequest::default();
    req.mut_header().set_peer(new_peer(1, 3));
    req.mut_status_request()
        .set_cmd_type(StatusCmdType::RegionLeader);
    let res = router.query(region_id, req.clone()).unwrap();
    let status_resp = res.response().unwrap().get_status_response();
    assert_eq!(
        *status_resp.get_region_leader().get_leader(),
        new_peer(1, 3)
    );

    for _ in 0..5 {
        let resp = block_on(
            cluster
                .node(0)
                .pd_client()
                .get_region_leader_by_id(region_id),
        )
        .unwrap();
        if let Some((region, peer)) = resp {
            assert_eq!(region.get_id(), region_id);
            assert_eq!(peer.get_id(), 3);
            assert_eq!(peer.get_store_id(), 1);
            return;
        }
        std::thread::sleep(std::time::Duration::from_millis(50));
    }
    panic!("failed to get region leader");
}
fn does_include_file_with_different_formatting() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "overrides": [{ "include": ["special/**"], "formatter": { "lineWidth": 20 } }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNFORMATTED_LINE_WIDTH.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FORMATTED_LINE_WIDTH_OVERRIDDEN);
    assert_file_contents(&fs, test, FORMATTED_LINE_WIDTH);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_formatting",
        fs,
        console,
        result,
    ));
}
fn f32_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<u8, f32> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(&0, &0.3).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(0.3, table.get(&0).unwrap().unwrap().value());
}
fn test_value_cmp() {
    assert_eq!(Value::from(&[1][..]), Value::from(&[1][..]));
    assert_ne!(Value::from(&[1][..]), Value::from(&[2][..]));
    assert_eq!(Value::UNDEFINED, Value::UNDEFINED);
}
fn test_basic() {
    check!(0.0);
    check!(-0.0);
    check!(1.0);
    check!(-1.0);
    assert_eq!(pretty(f64::NAN), "NaN");
    assert_eq!(pretty(f64::INFINITY), "inf");
    assert_eq!(pretty(f64::NEG_INFINITY), "-inf");
}
fn parse_joins_on() {
    fn join_with_constraint(
        relation: impl Into<String>,
        alias: Option<TableAlias>,
        f: impl Fn(JoinConstraint) -> JoinOperator,
    ) -> Join {
        Join {
            relation: TableFactor::Table {
                name: ObjectName(vec![Ident::new(relation.into())]),
                alias,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            join_operator: f(JoinConstraint::On(Expr::BinaryOp {
                left: Box::new(Expr::Identifier("c1".into())),
                op: BinaryOperator::Eq,
                right: Box::new(Expr::Identifier("c2".into())),
            })),
        }
    }
    // Test parsing of aliases
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 JOIN t2 AS foo ON c1 = c2").from).joins,
        vec![join_with_constraint(
            "t2",
            table_alias("foo"),
            JoinOperator::Inner,
        )]
    );
    one_statement_parses_to(
        "SELECT * FROM t1 JOIN t2 foo ON c1 = c2",
        "SELECT * FROM t1 JOIN t2 AS foo ON c1 = c2",
    );
    // Test parsing of different join operators
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::Inner)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftOuter)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightOuter)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT SEMI JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftSemi)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT SEMI JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightSemi)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 LEFT ANTI JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::LeftAnti)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 RIGHT ANTI JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::RightAnti)]
    );
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 FULL JOIN t2 ON c1 = c2").from).joins,
        vec![join_with_constraint("t2", None, JoinOperator::FullOuter)]
    );
}
fn test_value_object_interface() {
    let val = Value::from_seq_object(vec![1u32, 2, 3, 4]);
    let seq = val.as_seq().unwrap();
    assert_eq!(seq.item_count(), 4);

    let obj = val.as_object().unwrap();
    let seq2 = match obj.kind() {
        ObjectKind::Seq(s) => s,
        _ => panic!("did not expect this"),
    };
    assert_eq!(seq2.item_count(), 4);
    assert_eq!(obj.to_string(), "[1, 2, 3, 4]");
}
fn stop_stream() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive();

    info!("stopping stream");
    const ERROR: VarInt = VarInt(42);
    pair.server_recv(server_ch, s).stop(ERROR).unwrap();
    pair.drive();

    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);

    assert_matches!(
        pair.client_send(client_ch, s).write(b"foo"),
        Err(WriteError::Stopped(ERROR))
    );
    assert_matches!(
        pair.client_send(client_ch, s).finish(),
        Err(FinishError::Stopped(ERROR))
    );
}
fn compaction() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let definition: TableDefinition<u32, &[u8]> = TableDefinition::new("x");

    let big_value = vec![0u8; 100 * 1024];

    let txn = db.begin_write().unwrap();
    {
        let mut table = txn.open_table(definition).unwrap();
        // Insert 10MiB of data
        for i in 0..100 {
            table.insert(&i, big_value.as_slice()).unwrap();
        }
    }
    txn.commit().unwrap();

    let txn = db.begin_write().unwrap();
    {
        let mut table = txn.open_table(definition).unwrap();
        // Delete 90% of it
        for i in 0..90 {
            table.remove(&i).unwrap();
        }
    }
    txn.commit().unwrap();
    // Second commit to trigger dynamic compaction
    let txn = db.begin_write().unwrap();
    txn.commit().unwrap();

    // The values are > 1 page, so shouldn't get relocated. Therefore there should be a bunch of fragmented space,
    // since we left the last 100 values in the db.
    drop(db);
    let file_size = tmpfile.as_file().metadata().unwrap().len();
    let mut db = Database::open(tmpfile.path()).unwrap();

    assert!(db.compact().unwrap());
    drop(db);
    let file_size2 = tmpfile.as_file().metadata().unwrap().len();
    assert!(file_size2 < file_size);
}
fn test_fmt_group() {
    let ident = Ident::new("x", Span::call_site());
    let inner = TokenStream::from_iter(iter::once(TokenTree::Ident(ident)));
    let parens_empty = Group::new(Delimiter::Parenthesis, TokenStream::new());
    let parens_nonempty = Group::new(Delimiter::Parenthesis, inner.clone());
    let brackets_empty = Group::new(Delimiter::Bracket, TokenStream::new());
    let brackets_nonempty = Group::new(Delimiter::Bracket, inner.clone());
    let braces_empty = Group::new(Delimiter::Brace, TokenStream::new());
    let braces_nonempty = Group::new(Delimiter::Brace, inner.clone());
    let none_empty = Group::new(Delimiter::None, TokenStream::new());
    let none_nonempty = Group::new(Delimiter::None, inner);

    // Matches libproc_macro.
    assert_eq!("()", parens_empty.to_string());
    assert_eq!("(x)", parens_nonempty.to_string());
    assert_eq!("[]", brackets_empty.to_string());
    assert_eq!("[x]", brackets_nonempty.to_string());
    assert_eq!("{ }", braces_empty.to_string());
    assert_eq!("{ x }", braces_nonempty.to_string());
    assert_eq!("", none_empty.to_string());
    assert_eq!("x", none_nonempty.to_string());
}
fn stdin_error() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .pass_stdin("import os\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:8: F401 [*] `os` imported but unused
    Found 1 error.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn valid_context_on_valid_symlink() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.touch("a.tmp");
    dir.symlink_file("a.tmp", "la.tmp");

    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    cmd.args(&["--verbose", "--no-dereference", new_la_context])
        .arg(dir.plus("la.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("la.tmp")).unwrap().as_deref(),
        Some(new_la_context)
    );
    assert_eq!(get_file_context(dir.plus("a.tmp")).unwrap(), a_context);
}
fn parse_select_distinct() {
    let sql = "SELECT DISTINCT name FROM customer";
    let select = verified_only_select(sql);
    assert!(select.distinct.is_some());
    assert_eq!(
        &SelectItem::UnnamedExpr(Expr::Identifier(Ident::new("name"))),
        only(&select.projection)
    );
}
fn other_external_sst_info() -> Result<()> {
    let tempdir = tempdir();
    let sst_path = tempdir
        .path()
        .join("test-data.sst")
        .to_string_lossy()
        .to_string();
    let sst_builder = <KvTestEngine as SstExt>::SstWriterBuilder::new();
    let mut sst_writer = sst_builder.build(&sst_path)?;

    sst_writer.put(b"k1", b"v11")?;
    sst_writer.put(b"k9", b"v9")?;

    let info = sst_writer.finish()?;

    assert_eq!(b"k1", info.smallest_key());
    assert_eq!(b"k9", info.largest_key());
    assert_eq!(2, info.num_entries());

    let size = fs::metadata(&sst_path).unwrap().len();

    assert_eq!(size, info.file_size());

    Ok(())
}
fn test_pending_peers() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);

    let region_worker_fp = "region_apply_snap";

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer count check.
    pd_client.disable_default_operator();

    let region_id = cluster.run_conf_change();
    pd_client.must_add_peer(region_id, new_peer(2, 2));

    // To ensure peer 2 is not pending.
    cluster.must_put(b"k1", b"v1");
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");

    fail::cfg(region_worker_fp, "sleep(2000)").unwrap();
    pd_client.must_add_peer(region_id, new_peer(3, 3));
    sleep_ms(1000);
    let pending_peers = pd_client.get_pending_peers();
    // Region worker is not started, snapshot should not be applied yet.
    assert_eq!(pending_peers[&3], new_peer(3, 3));
    // But it will be applied finally.
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    sleep_ms(100);
    let pending_peers = pd_client.get_pending_peers();
    assert!(pending_peers.is_empty());
}
fn ArrayVec_append() {
  let mut av = array_vec!([i32; 8] => 1, 2, 3);
  let mut av2 = array_vec!([i32; 8] => 4, 5, 6);
  //
  av.append(&mut av2);
  assert_eq!(av.as_slice(), &[1_i32, 2, 3, 4, 5, 6]);
  assert_eq!(av2.as_slice(), &[]);
}
fn big_stack_works_ok() -> Result<()> {
    const N: usize = 10000;

    // Build a module with a function that uses a very large amount of stack space,
    // modeled here by calling an i64-returning-function many times followed by
    // adding them all into one i64.
    //
    // This should exercise the ability to consume multi-page stacks and
    // only touch a few internals of it at a time.
    let mut s = String::new();
    s.push_str("(module\n");
    s.push_str("(func (export \"\") (result i64)\n");
    s.push_str("i64.const 0\n");
    for _ in 0..N {
        s.push_str("call $get\n");
    }
    for _ in 0..N {
        s.push_str("i64.add\n");
    }
    s.push_str(")\n");
    s.push_str("(func $get (result i64) i64.const 0)\n");
    s.push_str(")\n");

    let mut store = Store::<()>::default();
    let module = Module::new(store.engine(), &s)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let func = instance.get_typed_func::<(), i64>(&mut store, "")?;
    assert_eq!(func.call(&mut store, ())?, 0);
    Ok(())
}
fn invalid_decimal_point_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.decimal_point(b'\x00');
    assert!(!builder.is_valid());
    builder = builder.decimal_point(b'\x7f');
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.decimal_point(b',');
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
}
fn client_mandatory_auth_revocation_works() {
    for kt in ALL_KEY_TYPES.iter() {
        // Create a server configuration that includes a CRL that specifies the client certificate
        // is revoked.
        let crls = vec![kt.client_crl()];
        let server_config = Arc::new(make_server_config_with_mandatory_client_auth_crls(
            *kt, crls,
        ));

        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions_with_auth(*kt, &[version]);
            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
            // Because the client certificate is revoked, the handshake should fail.
            let err = do_handshake_until_error(&mut client, &mut server);
            assert_eq!(
                err,
                Err(ErrorFromPeer::Server(Error::InvalidCertificate(
                    CertificateError::Revoked
                )))
            );
        }
    }
}
fn parse_typeless_struct_syntax() {
    // typeless struct syntax https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#typeless_struct_syntax
    // syntax: STRUCT( expr1 [AS field_name] [, ... ])
    let sql = "SELECT STRUCT(1, 2, 3), STRUCT('abc'), STRUCT(1, t.str_col), STRUCT(1 AS a, 'abc' AS b), STRUCT(str_col AS abc)";
    let select = bigquery().verified_only_select(sql);
    assert_eq!(5, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![
                Expr::Value(number("1")),
                Expr::Value(number("2")),
                Expr::Value(number("3")),
            ],
            fields: Default::default()
        },
        expr_from_projection(&select.projection[0])
    );

    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::SingleQuotedString("abc".to_string())),],
            fields: Default::default()
        },
        expr_from_projection(&select.projection[1])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![
                Expr::Value(number("1")),
                Expr::CompoundIdentifier(vec![Ident::from("t"), Ident::from("str_col")]),
            ],
            fields: Default::default()
        },
        expr_from_projection(&select.projection[2])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![
                Expr::Named {
                    expr: Expr::Value(number("1")).into(),
                    name: Ident::from("a")
                },
                Expr::Named {
                    expr: Expr::Value(Value::SingleQuotedString("abc".to_string())).into(),
                    name: Ident::from("b")
                },
            ],
            fields: Default::default()
        },
        expr_from_projection(&select.projection[3])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Named {
                expr: Expr::Identifier(Ident::from("str_col")).into(),
                name: Ident::from("abc")
            }],
            fields: Default::default()
        },
        expr_from_projection(&select.projection[4])
    );
}
fn ArrayVec_push_pop() {
  let mut av: ArrayVec<[i32; 4]> = Default::default();
  assert_eq!(av.len(), 0);
  assert_eq!(av.pop(), None);

  av.push(10_i32);
  assert_eq!(av.len(), 1);
  assert_eq!(av[0], 10);
  assert_eq!(av.pop(), Some(10));
  assert_eq!(av.len(), 0);
  assert_eq!(av.pop(), None);

  av.push(10);
  av.push(11);
  av.push(12);
  av.push(13);
  assert_eq!(av[0], 10);
  assert_eq!(av[1], 11);
  assert_eq!(av[2], 12);
  assert_eq!(av[3], 13);
  assert_eq!(av.len(), 4);
  assert_eq!(av.pop(), Some(13));
  assert_eq!(av.len(), 3);
  assert_eq!(av.pop(), Some(12));
  assert_eq!(av.len(), 2);
  assert_eq!(av.pop(), Some(11));
  assert_eq!(av.len(), 1);
  assert_eq!(av.pop(), Some(10));
  assert_eq!(av.len(), 0);
  assert_eq!(av.pop(), None);
}
fn server_respects_buffer_limit_pre_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    server.set_buffer_limit(Some(32));

    assert_eq!(
        server
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        20
    );
    assert_eq!(
        server
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        12
    );

    do_handshake(&mut client, &mut server);
    transfer(&mut server, &mut client);
    client.process_new_packets().unwrap();

    check_read(&mut client.reader(), b"01234567890123456789012345678901");
}
fn parse_similar_to() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that SIMILAR TO and NOT SIMILAR TO have the same precedence.
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = bigquery().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn compute_float_f64_test() {
    // These test near-halfway cases for double-precision floats.
    assert_eq!(compute_float64(0, 9007199254740992), (1076, 0));
    assert_eq!(compute_float64(0, 9007199254740993), (1065 + INVALID_FP, 9223372036854776832));
    assert_eq!(compute_float64(0, 9007199254740994), (1076, 1));
    assert_eq!(compute_float64(0, 9007199254740995), (1065 + INVALID_FP, 9223372036854778880));
    assert_eq!(compute_float64(0, 9007199254740996), (1076, 2));
    assert_eq!(compute_float64(0, 18014398509481984), (1077, 0));
    assert_eq!(compute_float64(0, 18014398509481986), (1066 + INVALID_FP, 9223372036854776832));
    assert_eq!(compute_float64(0, 18014398509481988), (1077, 1));
    assert_eq!(compute_float64(0, 18014398509481990), (1066 + INVALID_FP, 9223372036854778880));
    assert_eq!(compute_float64(0, 18014398509481992), (1077, 2));

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(compute_float64(-3, 9007199254740992000), (1076, 0));
    assert_eq!(compute_float64(-3, 9007199254740993000), (1065 + INVALID_FP, 9223372036854776832));
    assert_eq!(compute_float64(-3, 9007199254740994000), (1076, 1));
    assert_eq!(compute_float64(-3, 9007199254740995000), (1065 + INVALID_FP, 9223372036854778879));
    assert_eq!(compute_float64(-3, 9007199254740996000), (1076, 2));
}
fn non_durable_read_isolation() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let mut write_txn = db.begin_write().unwrap();
    write_txn.set_durability(Durability::None);
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let read_table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", read_table.get("hello").unwrap().unwrap().value());

    let mut write_txn = db.begin_write().unwrap();
    write_txn.set_durability(Durability::None);
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.remove("hello").unwrap();
        table.insert("hello2", "world2").unwrap();
        table.insert("hello3", "world3").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn2 = db.begin_read().unwrap();
    let read_table2 = read_txn2.open_table(STR_TABLE).unwrap();
    assert!(read_table2.get("hello").unwrap().is_none());
    assert_eq!(
        "world2",
        read_table2.get("hello2").unwrap().unwrap().value()
    );
    assert_eq!(
        "world3",
        read_table2.get("hello3").unwrap().unwrap().value()
    );
    assert_eq!(read_table2.len().unwrap(), 2);

    assert_eq!("world", read_table.get("hello").unwrap().unwrap().value());
    assert!(read_table.get("hello2").unwrap().is_none());
    assert!(read_table.get("hello3").unwrap().is_none());
    assert_eq!(read_table.len().unwrap(), 1);
}
fn fix_does_not_apply_display_only_fixes() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "B006",
                "--fix",
            ])
            .pass_stdin("def add_to_list(item, some_list=[]): ..."),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    def add_to_list(item, some_list=[]): ...
    ----- stderr -----
    -:1:33: B006 Do not use mutable data structures for argument defaults
    Found 1 error.
    "###);
}
fn parse_create_database() {
    let sql = "CREATE DATABASE mydb";
    match verified_stmt(sql) {
        Statement::CreateDatabase {
            db_name,
            if_not_exists,
            location,
            managed_location,
        } => {
            assert_eq!("mydb", db_name.to_string());
            assert!(!if_not_exists);
            assert_eq!(None, location);
            assert_eq!(None, managed_location);
        }
        _ => unreachable!(),
    }
}
fn test_mv_backup_never() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=never")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_struct_names() {
    let value = Point { x: 1.0, y: 2.0 };
    let struct_name = to_string_pretty(&value, PrettyConfig::default().struct_names(true));
    assert_eq!(
        struct_name,
        Ok("Point(\n    x: 1.0,\n    y: 2.0,\n)".to_string())
    );
    let no_struct_name = to_string(&value);
    assert_eq!(no_struct_name, Ok("(x:1.0,y:2.0)".to_string()));
}
fn test_proc_macro2_wrapper_span_size_without_locations() {
    assert_eq!(mem::size_of::<proc_macro2::Span>(), 4);
    assert_eq!(mem::size_of::<Option<proc_macro2::Span>>(), 8);
}
fn test_force_leader_multiple_election_rounds() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(30);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 5;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(40);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store5 = find_peer(&region, 5).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store5.clone());

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    cluster.add_send_filter(IsolationFilterFactory::new(1));
    cluster.add_send_filter(IsolationFilterFactory::new(2));

    // wait election timeout
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 2,
    ));
    cluster.enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // wait multiple election rounds
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 6,
    ));

    cluster.clear_send_filters();
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn test_node_merge_transfer_leader() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.raft_store.store_batch_system.max_batch_size = Some(1);
    cluster.cfg.raft_store.store_batch_system.pool_size = 2;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    // To ensure the region has applied to its current term so that later `split`
    // can success without any retries. Then, `left_peer_3` will must be `1003`.
    let region = pd_client.get_region(b"k1").unwrap();
    let peer_1 = find_peer(&region, 1).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), peer_1);
    let k = b"k1_for_apply_to_current_term";
    cluster.must_put(k, b"value");
    must_get_equal(&cluster.get_engine(1), k, b"value");

    cluster.must_split(&region, b"k2");

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k2").unwrap();

    let left_peer_1 = find_peer(&left, 1).unwrap().to_owned();
    cluster.must_transfer_leader(left.get_id(), left_peer_1.clone());

    let left_peer_3 = find_peer(&left, 3).unwrap().to_owned();
    assert_eq!(left_peer_3.get_id(), 1003);

    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return()").unwrap();

    cluster.must_try_merge(left.get_id(), right.get_id());

    // Prevent peer 1003 to handle ready when it's leader
    let before_handle_raft_ready_1003 = "before_handle_raft_ready_1003";
    fail::cfg(before_handle_raft_ready_1003, "pause").unwrap();

    let epoch = cluster.get_region_epoch(left.get_id());
    let mut transfer_leader_req =
        new_admin_request(left.get_id(), &epoch, new_transfer_leader_cmd(left_peer_3));
    transfer_leader_req.mut_header().set_peer(left_peer_1);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, transfer_leader_req, Callback::None)
        .unwrap();
    fail::remove(schedule_merge_fp);

    pd_client.check_merged_timeout(left.get_id(), Duration::from_secs(5));

    fail::remove(before_handle_raft_ready_1003);
    sleep_ms(100);
    cluster.must_put(b"k4", b"v4");
    must_get_equal(&cluster.get_engine(3), b"k4", b"v4");
}
fn test_du_d_flag() {
    let ts = TestScenario::new(util_name!());

    let result = ts.ucmd().arg("-d1").succeeds();

    #[cfg(any(target_os = "linux", target_os = "android"))]
    {
        let result_reference = unwrap_or_return!(expected_result(&ts, &["-d1"]));
        if result_reference.succeeded() {
            assert_eq!(result.stdout_str(), result_reference.stdout_str());
            return;
        }
    }
    _du_d_flag(result.stdout_str());
}
fn mutability() -> anyhow::Result<()> {
    let mut store = Store::<()>::default();
    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::I32, Mutability::Var),
        0.into(),
    )?;
    assert_eq!(g.get(&mut store).i32(), Some(0));
    g.set(&mut store, 1.into())?;
    assert_eq!(g.get(&mut store).i32(), Some(1));
    Ok(())
}
fn test_atomic_cas_lock_by_latch() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();

    let engine = cluster
        .sim
        .read()
        .unwrap()
        .storages
        .get(&1)
        .unwrap()
        .clone();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .build()
        .unwrap();

    let mut ctx = Context::default();
    ctx.set_region_id(1);
    ctx.set_region_epoch(cluster.get_region_epoch(1));
    ctx.set_peer(cluster.leader_of_region(1).unwrap());

    let latch_acquire_success_fp = "txn_scheduler_acquire_success";
    let latch_acquire_fail_fp = "txn_scheduler_acquire_fail";
    let pending_cas_fp = "txn_commands_compare_and_swap";
    let wakeup_latch_fp = "txn_scheduler_try_to_wake_up";
    let acquire_flag = Arc::new(AtomicBool::new(false));
    let acquire_flag1 = acquire_flag.clone();
    let acquire_flag_fail = Arc::new(AtomicBool::new(false));
    let acquire_flag_fail1 = acquire_flag_fail.clone();
    let wakeup_latch_flag = Arc::new(AtomicBool::new(false));
    let wakeup1 = wakeup_latch_flag.clone();

    fail::cfg(pending_cas_fp, "pause").unwrap();
    fail::cfg_callback(latch_acquire_success_fp, move || {
        acquire_flag1.store(true, Ordering::Release);
    })
    .unwrap();
    fail::cfg_callback(latch_acquire_fail_fp, move || {
        acquire_flag_fail1.store(true, Ordering::Release);
    })
    .unwrap();
    fail::cfg_callback(wakeup_latch_fp, move || {
        wakeup1.store(true, Ordering::Release);
    })
    .unwrap();
    let (cb, f1) = paired_future_callback();
    storage
        .raw_compare_and_swap_atomic(
            ctx.clone(),
            "".to_string(),
            b"key".to_vec(),
            None,
            b"v1".to_vec(),
            0,
            cb,
        )
        .unwrap();
    thread::sleep(Duration::from_secs(1));
    assert!(acquire_flag.load(Ordering::Acquire));
    assert!(!acquire_flag_fail.load(Ordering::Acquire));
    acquire_flag.store(false, Ordering::Release);
    let (cb, f2) = paired_future_callback();
    storage
        .raw_compare_and_swap_atomic(
            ctx.clone(),
            "".to_string(),
            b"key".to_vec(),
            Some(b"v1".to_vec()),
            b"v2".to_vec(),
            0,
            cb,
        )
        .unwrap();
    thread::sleep(Duration::from_secs(1));
    assert!(acquire_flag_fail.load(Ordering::Acquire));
    assert!(!acquire_flag.load(Ordering::Acquire));
    fail::remove(pending_cas_fp);
    let _ = block_on(f1).unwrap();
    let (prev_val, succeed) = block_on(f2).unwrap().unwrap();
    assert!(wakeup_latch_flag.load(Ordering::Acquire));
    assert!(succeed);
    assert_eq!(prev_val, Some(b"v1".to_vec()));
    let f = storage.raw_get(ctx, "".to_string(), b"key".to_vec());
    let ret = block_on(f).unwrap().unwrap();
    assert_eq!(b"v2".to_vec(), ret);
}
fn test() {
    let files = WalkDir::new("tests/terser/fixtures")
        .into_iter()
        .filter_map(Result::ok)
        .filter(|e| !e.file_type().is_dir())
        .collect::<Vec<_>>();
    assert!(!files.is_empty());
    for file in files {
        let path = file.path();
        let source_text = std::fs::read_to_string(path).unwrap();
        let source_type = SourceType::from_path(path).unwrap();
        let allocator = Allocator::default();
        let parser_return = Parser::new(&allocator, &source_text, source_type).parse();
        let program = allocator.alloc(parser_return.program);
        TestSuite::from_program(&source_text, program).execute_tests();
    }
}
fn parse_delete_statement() {
    let sql = "DELETE FROM \"table\"";
    match verified_stmt(sql) {
        Statement::Delete { from, .. } => {
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::with_quote('"', "table")]),
                    alias: None,
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                from[0].relation
            );
        }
        _ => unreachable!(),
    }
}
fn compute_error_scaled32_test() {
    // These are the same examples above, just using pre-computed scaled values.

    // These test near-halfway cases for single-precision floats.
    assert_eq!(
        compute_error_scaled32(0, 4611686018427387904, 39),
        (111 + INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686293305294848, 39),
        (111 + INVALID_FP, 9223372586610589696)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686568183201792, 39),
        (111 + INVALID_FP, 9223373136366403584)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686843061108736, 39),
        (111 + INVALID_FP, 9223373686122217472)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611687117939015680, 39),
        (111 + INVALID_FP, 9223374235878031360)
    );

    assert_eq!(
        compute_error_scaled32(-10, 9223372036854775808, 6),
        (111 + INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223372586610589696, 6),
        (111 + INVALID_FP, 9223372586610589696)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223373136366403584, 6),
        (111 + INVALID_FP, 9223373136366403584)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223373686122217472, 6),
        (111 + INVALID_FP, 9223373686122217472)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223374235878031360, 6),
        (111 + INVALID_FP, 9223374235878031360)
    );
}
fn with_reinscribe_flag_but_not_actually_a_reinscription() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  CommandBuilder::new("wallet inscribe --file tulip.png --fee-rate 5.0 ")
    .write("tulip.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  let coinbase = rpc_server.mine_blocks(1)[0].txdata[0].txid();

  CommandBuilder::new(format!(
    "wallet inscribe --file orchid.png --fee-rate 1.1 --reinscribe --satpoint {coinbase}:0:0"
  ))
  .write("orchid.png", [1; 520])
  .rpc_server(&rpc_server)
  .expected_exit_code(1)
  .stderr_regex("error: reinscribe flag set but this would not be a reinscription.*")
  .run_and_extract_stdout();
}
fn test_pending_snapshot() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_snapshot(&mut cluster.cfg);
    let election_timeout = configure_for_lease_read(&mut cluster.cfg, None, Some(15));
    let gc_limit = cluster.cfg.raft_store.raft_log_gc_count_limit();
    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(100);

    let handle_snapshot_fp = "apply_on_handle_snapshot_1_1";
    let handle_snapshot_finish_fp = "apply_on_handle_snapshot_finish_1_1";
    fail::cfg("apply_on_handle_snapshot_sync", "return").unwrap();

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer count check.
    pd_client.disable_default_operator();

    let region_id = cluster.run_conf_change();
    pd_client.must_add_peer(region_id, new_peer(2, 2));
    cluster.must_transfer_leader(region_id, new_peer(1, 1));
    cluster.must_put(b"k1", b"v1");

    fail::cfg(handle_snapshot_fp, "pause").unwrap();
    pd_client.must_add_peer(region_id, new_peer(3, 3));
    // Give some time for peer 3 to request snapshot.
    sleep_ms(100);

    // Isolate peer 1 from rest of the cluster.
    cluster.add_send_filter(IsolationFilterFactory::new(1));

    sleep_ms((election_timeout.as_millis() * 2) as _);
    cluster.reset_leader_of_region(region_id);
    // Compact logs to force requesting snapshot after clearing send filters.
    let state2 = cluster.truncated_state(1, 2);
    for i in 1..gc_limit * 10 {
        let k = i.to_string().into_bytes();
        cluster.must_put(&k, &k.clone());
    }
    cluster.wait_log_truncated(1, 2, state2.get_index() + 5 * gc_limit);

    // Make sure peer 1 has applied snapshot.
    cluster.clear_send_filters();
    let start = Instant::now();
    loop {
        if cluster.pd_client.get_pending_peers().get(&1).is_none()
            || start.saturating_elapsed() > election_timeout * 10
        {
            break;
        }
        sleep_ms(50);
    }
    let state1 = cluster.truncated_state(1, 1);

    // Peer 2 continues to handle snapshot.
    fail::cfg(handle_snapshot_finish_fp, "pause").unwrap();
    fail::remove(handle_snapshot_fp);
    sleep_ms(200);
    let state2 = cluster.truncated_state(1, 1);
    fail::remove(handle_snapshot_finish_fp);
    assert!(
        state1.get_term() <= state2.get_term(),
        "{:?} {:?}",
        state1,
        state2
    );
    assert!(
        state1.get_index() <= state2.get_index(),
        "{:?} {:?}",
        state1,
        state2
    );
}
fn extends_should_raise_an_error_for_unresolved_configuration_and_show_verbose() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = Path::new("biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["formatTYPO.json", "linter.json"] }"#,
    );
    let format = Path::new("format.json");
    fs.insert(
        format.into(),
        r#"{ "javascript": { "formatter": { "quoteStyle": "single" } } }"#,
    );
    let lint = Path::new("linter.json");
    fs.insert(lint.into(), r#"{ "linter": { "enabled": false } }"#);

    let test_file = Path::new("test.js");
    fs.insert(test_file.into(), r#"debugger; console.log("string"); "#);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                "--verbose",
                test_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "extends_should_raise_an_error_for_unresolved_configuration_and_show_verbose",
        fs,
        console,
        result,
    ));
}
fn parse_raw_literal() {
    let sql = r#"SELECT R'abc', R"abc", R'f\(abc,(.*),def\)', R"f\(abc,(.*),def\)""#;
    let stmt = bigquery().one_statement_parses_to(
        sql,
        r"SELECT R'abc', R'abc', R'f\(abc,(.*),def\)', R'f\(abc,(.*),def\)'",
    );
    if let Statement::Query(query) = stmt {
        if let SetExpr::Select(select) = *query.body {
            assert_eq!(4, select.projection.len());
            assert_eq!(
                &Expr::Value(Value::RawStringLiteral("abc".to_string())),
                expr_from_projection(&select.projection[0])
            );
            assert_eq!(
                &Expr::Value(Value::RawStringLiteral("abc".to_string())),
                expr_from_projection(&select.projection[1])
            );
            assert_eq!(
                &Expr::Value(Value::RawStringLiteral(r"f\(abc,(.*),def\)".to_string())),
                expr_from_projection(&select.projection[2])
            );
            assert_eq!(
                &Expr::Value(Value::RawStringLiteral(r"f\(abc,(.*),def\)".to_string())),
                expr_from_projection(&select.projection[3])
            );
            return;
        }
    }
    panic!("invalid query")
}
fn wasmer_init_works_1() {
    let wasmer_dir = TempDir::new().unwrap();
    let tempdir = tempfile::tempdir().unwrap();
    let path = tempdir.path().join("testfirstproject");
    std::fs::create_dir_all(&path).unwrap();

    Command::new(get_wasmer_path())
        .arg("init")
        .arg("--namespace=ciuser")
        .current_dir(&path)
        .env("WASMER_DIR", wasmer_dir.path())
        .assert()
        .success();

    assert_eq!(
        std::fs::read_to_string(path.join("wasmer.toml")).unwrap(),
        include_str!("./fixtures/init1.toml"),
    );
}
fn test_hostname() {
    let ls_default_res = new_ucmd!().succeeds();
    let ls_short_res = new_ucmd!().arg("-s").succeeds();
    let ls_domain_res = new_ucmd!().arg("-d").succeeds();

    assert!(ls_default_res.stdout().len() >= ls_short_res.stdout().len());
    assert!(ls_default_res.stdout().len() >= ls_domain_res.stdout().len());
}
fn test_cp_backup_nil() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=nil")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
fn test_mv_numbered_if_existing_backup_nil() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";
    let file_b_backup = "test_mv_backup_numbering_file_b.~1~";

    at.touch(file_a);
    at.touch(file_b);
    at.touch(file_b_backup);
    ucmd.arg("--backup=nil")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_b));
    assert!(at.file_exists(file_b_backup));
    assert!(at.file_exists(format!("{file_b}.~2~")));
}
fn invalid_inf_test() {
    let mut builder = OptionsBuilder::default();
    builder = builder.inf_string(Some(b"innnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnnf"));
    assert!(!builder.is_valid());
    builder = builder.inf_string(Some(b"nan"));
    assert!(!builder.is_valid());
    builder = builder.inf_string(Some(b"in00f"));
    assert!(!builder.is_valid());
    assert!(builder.build().is_err());
    builder = builder.inf_string(Some(b"i"));
    assert!(builder.is_valid());
    builder = builder.inf_string(Some(b"inf"));
    assert!(builder.is_valid());
    assert!(builder.build().is_ok());
    builder = builder.inf_string(None);
    assert!(builder.is_valid());
    builder = builder.infinity_string(None);
    assert!(builder.is_valid());
}
fn does_not_handle_included_files_if_overridden_by_organize_imports() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "formatter": { "enabled": false },
  "linter": { "enabled": false },
  "organizeImports": { "include": ["test.js", "test2.js"], "ignore": ["test.js"] }
}
"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNORGANIZED.as_bytes());

    let test2 = Path::new("test2.js");
    fs.insert(test2.into(), UNORGANIZED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(test2)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, ORGANIZED);

    drop(file);

    let mut file = fs
        .open(test)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNORGANIZED);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_included_files_if_overridden_by_organize_imports",
        fs,
        console,
        result,
    ));
}
fn test() {
    let x1 = serde_json::from_str::<Value>("18446744073709551615.");
    assert!(x1.is_err());
    let x2 = serde_json::from_str::<Value>("18446744073709551616.");
    assert!(x2.is_err());
}
fn parse_create_materialized_view() {
    let sql = "CREATE MATERIALIZED VIEW myschema.myview AS SELECT foo FROM bar";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            or_replace,
            columns,
            query,
            materialized,
            with_options,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("myschema.myview", name.to_string());
            assert_eq!(Vec::<Ident>::new(), columns);
            assert_eq!("SELECT foo FROM bar", query.to_string());
            assert!(materialized);
            assert_eq!(with_options, vec![]);
            assert!(!or_replace);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(!temporary);
        }
        _ => unreachable!(),
    }
}
fn test_combined_file_set_unset() {
    let out = new_ucmd!()
        .arg("-u")
        .arg("BAR")
        .arg("-f")
        .arg("vars.conf.txt")
        .arg("FOO=bar.alt")
        .succeeds()
        .stdout_move_str();

    assert_eq!(
        out.lines()
            .filter(|&line| line == "FOO=bar.alt" || line.starts_with("BAR="))
            .count(),
        1
    );
}
fn bools() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "pass") (param i32) (result i32) local.get 0)
            )
            (core instance $i (instantiate $m))

            (func (export "u32-to-bool") (param "a" u32) (result bool)
                (canon lift (core func $i "pass"))
            )
            (func (export "bool-to-u32") (param "a" bool) (result u32)
                (canon lift (core func $i "pass"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let u32_to_bool = instance.get_typed_func::<(u32,), (bool,)>(&mut store, "u32-to-bool")?;
    let bool_to_u32 = instance.get_typed_func::<(bool,), (u32,)>(&mut store, "bool-to-u32")?;

    assert_eq!(bool_to_u32.call(&mut store, (false,))?, (0,));
    bool_to_u32.post_return(&mut store)?;
    assert_eq!(bool_to_u32.call(&mut store, (true,))?, (1,));
    bool_to_u32.post_return(&mut store)?;
    assert_eq!(u32_to_bool.call(&mut store, (0,))?, (false,));
    u32_to_bool.post_return(&mut store)?;
    assert_eq!(u32_to_bool.call(&mut store, (1,))?, (true,));
    u32_to_bool.post_return(&mut store)?;
    assert_eq!(u32_to_bool.call(&mut store, (2,))?, (true,));
    u32_to_bool.post_return(&mut store)?;

    Ok(())
}
fn builtins() {
    let f = Path::new("/");

    let resolver =
        Resolver::new(ResolveOptions { builtin_modules: true, ..ResolveOptions::default() });

    let pass = [
        "_http_agent",
        "_http_client",
        "_http_common",
        "_http_incoming",
        "_http_outgoing",
        "_http_server",
        "_stream_duplex",
        "_stream_passthrough",
        "_stream_readable",
        "_stream_transform",
        "_stream_wrap",
        "_stream_writable",
        "_tls_common",
        "_tls_wrap",
        "assert",
        "assert/strict",
        "async_hooks",
        "buffer",
        "child_process",
        "cluster",
        "console",
        "constants",
        "crypto",
        "dgram",
        "diagnostics_channel",
        "dns",
        "dns/promises",
        "domain",
        "events",
        "fs",
        "fs/promises",
        "http",
        "http2",
        "https",
        "inspector",
        "module",
        "net",
        "os",
        "path",
        "path/posix",
        "path/win32",
        "perf_hooks",
        "process",
        "punycode",
        "querystring",
        "readline",
        "repl",
        "stream",
        "stream/consumers",
        "stream/promises",
        "stream/web",
        "string_decoder",
        "sys",
        "timers",
        "timers/promises",
        "tls",
        "trace_events",
        "tty",
        "url",
        "util",
        "util/types",
        "v8",
        "vm",
        "worker_threads",
        "zlib",
    ];

    for request in pass {
        let resolved_path = resolver.resolve(f, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Err(ResolveError::Builtin(request.to_string())), "{request}");
    }

    for request in pass {
        let request = format!("node:{request}");
        let resolved_path = resolver.resolve(f, &request).map(|r| r.full_path());
        assert_eq!(resolved_path, Err(ResolveError::Builtin(request.to_string())), "{request}");
    }
}
fn render_simple_inheritance() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("top", "{% block pre %}{% endblock pre %}{% block main %}{% endblock main %}"),
        ("bottom", "{% extends \"top\" %}{% block main %}MAIN{% endblock %}"),
    ])
    .unwrap();
    let result = tera.render("bottom", &Context::new());

    assert_eq!(result.unwrap(), "MAIN".to_string());
}
fn check_engine_matching() {
    let requests = load_requests();

    assert!(requests.len() > 0, "List of parsed request info is empty");

    for req in requests {
        if req.url == "http://" || req.url == "https://" {
            continue;
        }
        for filter in req.filters {
            let opts = ParseOptions::default();
            let mut engine = Engine::from_rules_debug(&[filter.clone()], opts);
            let resources = build_resources_from_filters(&[filter.clone()]);
            engine.use_resources(resources);

            let network_filter_res = NetworkFilter::parse(&filter, true, opts);
            assert!(
                network_filter_res.is_ok(),
                "Could not parse filter {}",
                filter
            );
            let network_filter = network_filter_res.unwrap();

            let request = Request::new(&req.url, &req.sourceUrl, &req.r#type).unwrap();
            let result = engine.check_network_request(&request);

            if network_filter.is_exception() {
                assert!(
                    !result.matched,
                    "Expected {} to NOT match {} at {}, typed {}",
                    filter, req.url, req.sourceUrl, req.r#type
                );
                // assert!(result.exception.is_some(), "Expected exception {} to match {} at {}, typed {}", filter, req.url, req.sourceUrl, req.r#type);
            } else {
                assert!(
                    result.matched,
                    "Expected {} to match {} at {}, typed {}",
                    filter, req.url, req.sourceUrl, req.r#type
                );
            }

            if network_filter.is_redirect() {
                assert!(
                    result.redirect.is_some(),
                    "Expected {} to trigger redirect rule {}",
                    req.url,
                    filter
                );
                let resource = result.redirect.unwrap();
                // each redirect resource is base64 encoded
                assert!(resource.contains("base64"));
            }
        }
    }
}
fn parse_create_table_constraints_only() {
    // Zero-column tables can also have constraints in PostgreSQL
    let sql = "CREATE TABLE t (CONSTRAINT positive CHECK (2 > 1))";
    let ast = pg_and_generic().verified_stmt(sql);
    match ast {
        Statement::CreateTable {
            name,
            columns,
            constraints,
            ..
        } => {
            assert_eq!("t", name.to_string());
            assert!(columns.is_empty());
            assert_eq!(
                only(constraints).to_string(),
                "CONSTRAINT positive CHECK (2 > 1)"
            );
        }
        _ => unreachable!(),
    };
}
fn ci_biome_json() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert(
        PathBuf::from("biome.json"),
        r#"{
  "formatter": {
    "enabled": false
  }
}
"#
        .as_bytes(),
    );

    let input_file = Path::new("file.js");

    fs.insert(input_file.into(), "  statement(  )  ".as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), input_file.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(input_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, "  statement(  )  ");

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_biome_json",
        fs,
        console,
        result,
    ));
}
fn leaves_nonempty_tbody() {
    let input = "<table><thead><tr><td>hi</td></tr></thead><tbody><tr></tr></tbody></table>";
    assert_eq!(input, normalize_html(input))
}
fn render_variable_block_ident() {
    let mut context = Context::new();
    context.insert("name", &"john");
    context.insert("malicious", &"<html>");
    context.insert("a", &2);
    context.insert("b", &3);
    context.insert("numbers", &vec![1, 2, 3]);
    context.insert("tuple_list", &vec![(1, 2, 3), (1, 2, 3)]);
    context.insert("review", &Review::new());
    context.insert("with_newline", &"Animal Alphabets\nB is for Bee-Eater");

    let inputs = vec![
        ("{{ name }}", "john"),
        ("{{ malicious }}", "&lt;html&gt;"),
        ("{{ \"<html>\" }}", "&lt;html&gt;"),
        ("{{ \" html \" | upper | trim }}", "HTML"),
        ("{{ 'html' }}", "html"),
        ("{{ `html` }}", "html"),
        // https://github.com/Keats/tera/issues/273
        (
            r#"{{ 'hangar new "Will Smoth <will_s@example.com>"' | safe }}"#,
            r#"hangar new "Will Smoth <will_s@example.com>""#,
        ),
        ("{{ malicious | safe }}", "<html>"),
        ("{{ malicious | upper }}", "&lt;HTML&gt;"),
        ("{{ malicious | upper | safe }}", "<HTML>"),
        ("{{ malicious | safe | upper }}", "&lt;HTML&gt;"),
        ("{{ review | length }}", "2"),
        ("{{ review.paragraphs.1 }}", "B"),
        ("{{ numbers }}", "[1, 2, 3]"),
        ("{{ numbers.0 }}", "1"),
        ("{{ tuple_list.1.1 }}", "2"),
        ("{{ name and true }}", "true"),
        ("{{ name | length }}", "4"),
        ("{{ name is defined }}", "true"),
        ("{{ not name is defined }}", "false"),
        ("{{ name is not defined }}", "false"),
        ("{{ not name is not defined }}", "true"),
        ("{{ a is odd }}", "false"),
        ("{{ a is odd or b is odd  }}", "true"),
        ("{{ range(start=1, end=4) }}", "[1, 2, 3]"),
        ("{{ a + b }}", "5"),
        ("{{ a + 1.5 }}", "3.5"),
        ("{{ 1 + 1 + 1 }}", "3"),
        ("{{ 2 - 2 - 1 }}", "-1"),
        ("{{ 1 - 1 + 1 }}", "1"),
        ("{{ 1 + get_number() }}", "11"),
        ("{{ get_number() + 1 }}", "11"),
        ("{{ (1.9 + a) | round }}", "4"),
        ("{{ 1.9 + a | round }}", "4"),
        ("{{ numbers | length - 1 }}", "2"),
        ("{{ 1.9 + a | round - 1 }}", "3"),
        ("{{ 1.9 + a | round - 1.8 + a | round }}", "0"),
        ("{{ 1.9 + a | round - 1.8 + a | round - 1 }}", "-1"),
        ("{{ 4 + 40 / (2 + 8) / 4 }}", "5"),
        ("{{ ( ( 2 ) + ( 2 ) ) }}", "4"),
        ("{{ ( ( 4 / 1 ) + ( 2 / 1 ) ) }}", "6"),
        ("{{ ( ( 4 + 2 ) / ( 2 + 1 ) ) }}", "2"),
        // https://github.com/Keats/tera/issues/435
        (
            "{{ with_newline | replace(from='\n', to='<br>') | safe }}",
            "Animal Alphabets<br>B is for Bee-Eater",
        ),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_custom_table_limiter() -> Result<()> {
    let engine = Engine::default();
    let linker = Linker::new(&engine);

    let module = Module::new(&engine, r#"(module (table (export "t") 0 anyfunc))"#)?;

    let context = TableContext {
        elements_used: 0,
        element_limit: 10,
        limit_exceeded: false,
    };

    let mut store = Store::new(&engine, context);
    store.limiter(|s| s as &mut dyn ResourceLimiter);
    let instance = linker.instantiate(&mut store, &module)?;
    let table = instance.get_table(&mut store, "t").unwrap();

    // Grow the table by 10 elements
    table.grow(&mut store, 3, Val::FuncRef(None))?;
    table.grow(&mut store, 5, Val::FuncRef(None))?;
    table.grow(&mut store, 2, Val::FuncRef(None))?;

    assert!(!store.data().limit_exceeded);

    // Table is at the maximum, but the limit hasn't been exceeded
    assert!(!store.data().limit_exceeded);

    // Try to grow the memory again
    assert_eq!(
        table
            .grow(&mut store, 1, Val::FuncRef(None))
            .map_err(|e| e.to_string())
            .unwrap_err(),
        "failed to grow table by `1`"
    );

    assert!(store.data().limit_exceeded);

    Ok(())
}
fn test_skip_iter_lc() {
    // Test iterators that skip multiple, leading digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_leading_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"45_5");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"45__5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".45_5");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b".45__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"4_5_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4__5__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"4_5_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4__5__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"4_5_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"4__5__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"4_5_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"4__5__.56");
}
fn hi64_test() {
    assert_eq!(Bigint::from_u64(0xA).hi64(), (0xA000000000000000, false));
    assert_eq!(Bigint::from_u64(0xAB).hi64(), (0xAB00000000000000, false));
    assert_eq!(
        Bigint::from_u64(0xAB00000000).hi64(),
        (0xAB00000000000000, false)
    );
    assert_eq!(
        Bigint::from_u64(0xA23456789A).hi64(),
        (0xA23456789A000000, false)
    );
}
pub fn test_basic() {
    let mut test_suite = TestSuite::new(resource_metering::Config {
        report_receiver_interval: ReadableDuration::secs(3),
        precision: ReadableDuration::secs(1),
        ..Default::default()
    });

    // Workload
    // [req-1, req-2]
    test_suite.setup_workload(vec!["req-1", "req-2"]);

    let (_client, stream) = test_suite.subscribe();
    let tags = stream.take(4).map(|record| {
        String::from_utf8_lossy(record.unwrap().get_record().get_resource_group_tag()).into_owned()
    });
    let res = block_on(tags.collect::<HashSet<_>>());

    assert!(res.contains("req-1"));
    assert!(res.contains("req-2"));
}
fn test_force_leader_with_uncommitted_conf_change() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(90);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store1 = find_peer(&region, 1).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    confirm_quorum_is_lost(&mut cluster, &region);

    // an uncommitted conf-change
    let cmd = new_change_peer_request(
        ConfChangeType::RemoveNode,
        find_peer(&region, 2).unwrap().clone(),
    );
    let req = new_admin_request(region.get_id(), region.get_region_epoch(), cmd);
    cluster
        .call_command_on_leader(req, Duration::from_millis(10))
        .unwrap_err();

    // wait election timeout
    std::thread::sleep(Duration::from_millis(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 2,
    ));
    cluster.must_enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);
    // the uncommitted conf-change is committed successfully after being force
    // leader
    cluster
        .pd_client
        .must_none_peer(region.get_id(), find_peer(&region, 2).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), Some(b"v2".to_vec()));
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn test_double_quotes_over_db_schema_table_name() {
    let select =
        redshift().verified_only_select("SELECT \"col1\" FROM \"test_schema\".\"test_table\"");
    assert_eq!(
        select.projection[0],
        SelectItem::UnnamedExpr(Expr::Identifier(Ident {
            value: "col1".to_string(),
            quote_style: Some('"')
        })),
    );
    assert_eq!(
        select.from[0],
        TableWithJoins {
            relation: TableFactor::Table {
                name: ObjectName(vec![
                    Ident {
                        value: "test_schema".to_string(),
                        quote_style: Some('"')
                    },
                    Ident {
                        value: "test_table".to_string(),
                        quote_style: Some('"')
                    }
                ]),
                alias: None,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            joins: vec![],
        }
    );
}
fn test_bigquery_trim() {
    let real_sql = r#"SELECT customer_id, TRIM(item_price_id, '"', "a") AS item_price_id FROM models_staging.subscriptions"#;
    assert_eq!(bigquery().verified_stmt(real_sql).to_string(), real_sql);

    let sql_only_select = "SELECT TRIM('xyz', 'a')";
    let select = bigquery().verified_only_select(sql_only_select);
    assert_eq!(
        &Expr::Trim {
            expr: Box::new(Expr::Value(Value::SingleQuotedString("xyz".to_owned()))),
            trim_where: None,
            trim_what: None,
            trim_characters: Some(vec![Expr::Value(Value::SingleQuotedString("a".to_owned()))]),
        },
        expr_from_projection(only(&select.projection))
    );

    // missing comma separation
    let error_sql = "SELECT TRIM('xyz' 'a')";
    assert_eq!(
        ParserError::ParserError("Expected ), found: 'a'".to_owned()),
        bigquery().parse_sql_statements(error_sql).unwrap_err()
    );
}
fn no_lint_if_files_are_listed_in_ignore_option() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_LINTER_AND_FILES_IGNORE.as_bytes());

    let file_path_test1 = Path::new("test1.js");
    fs.insert(file_path_test1.into(), FIX_BEFORE.as_bytes());

    let file_path_test2 = Path::new("test2.js");
    fs.insert(file_path_test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path_test1.as_os_str().to_str().unwrap(),
                file_path_test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path_test1)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    let mut buffer = String::new();
    fs.open(file_path_test2)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_files_are_listed_in_ignore_option",
        fs,
        console,
        result,
    ));
}
fn test_split_separator_semicolon_number_r() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--number=r/3", "--separator=;", "separator_semicolon.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1;4;");
    assert_eq!(file_read(&at, "xab"), "2;5;");
    assert_eq!(file_read(&at, "xac"), "3;");
    assert!(!at.plus("xad").exists());
}
fn send_on_mainnnet_works_with_wallet_named_ord() {
  let rpc_server = test_bitcoincore_rpc::builder().build();
  let txid = rpc_server.mine_blocks_with_subsidy(1, 1_000_000)[0].txdata[0].txid();
  create_wallet(&rpc_server);

  let output = CommandBuilder::new(format!(
    "wallet send --fee-rate 1 bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kv8f3t4 {txid}:0:0"
  ))
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Output>();

  assert_eq!(rpc_server.mempool()[0].txid(), output.transaction);
}
fn test_sync_host_func() {
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    integration::add_atoms_to_linker(&mut linker, |cx| cx).unwrap();
    let mut store = store(&engine);
    let shim_mod = shim_module(&engine);
    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();

    let mut results = [Val::I32(0)];
    shim_inst
        .get_func(&mut store, "int_float_args_shim")
        .unwrap()
        .call(&mut store, &[0i32.into(), 123.45f32.into()], &mut results)
        .unwrap();

    assert_eq!(
        results[0].unwrap_i32(),
        types::Errno::Ok as i32,
        "int_float_args errno"
    );
}
fn test_undeclared_variables() {
    let mut env = Environment::new();
    env.add_template(
        "demo",
        "{% set x = foo %}{{ x }}{{ bar.baz }}{{ bar.blub }}",
    )
    .unwrap();
    let tmpl = env.get_template("demo").unwrap();
    let undeclared = tmpl.undeclared_variables(false);
    assert_eq!(
        undeclared,
        ["foo", "bar"].into_iter().map(|x| x.to_string()).collect()
    );
    let undeclared = tmpl.undeclared_variables(true);
    dbg!(&undeclared);
    assert_eq!(
        undeclared,
        ["foo", "bar.baz", "bar.blub"]
            .into_iter()
            .map(|x| x.to_string())
            .collect()
    );
}
fn test_destroy_by_larger_id() {
    let mut cluster = Cluster::default();
    let router = &cluster.routers[0];
    let test_region_id = 4;
    let test_peer_id = 6;
    let init_term = 5;
    let mut msg = Box::<RaftMessage>::default();
    msg.set_region_id(test_region_id);
    msg.set_to_peer(new_peer(1, test_peer_id));
    msg.mut_region_epoch().set_conf_ver(1);
    msg.set_from_peer(new_peer(2, 8));
    let raft_message = msg.mut_message();
    raft_message.set_msg_type(MessageType::MsgHeartbeat);
    raft_message.set_from(6);
    raft_message.set_term(init_term);
    // Create the peer.
    router.send_raft_message(msg.clone()).unwrap();
    // There must be heartbeat response.
    let hb = cluster
        .receiver(0)
        .recv_timeout(Duration::from_millis(300))
        .unwrap();
    assert_eq!(
        hb.get_message().get_msg_type(),
        MessageType::MsgHeartbeatResponse
    );

    let timeout = Duration::from_secs(3);
    let meta = router
        .must_query_debug_info(test_region_id, timeout)
        .unwrap();
    assert_eq!(meta.raft_status.id, test_peer_id);

    // Smaller ID should be ignored.
    let mut smaller_id_msg = msg;
    smaller_id_msg.set_to_peer(new_peer(1, test_peer_id - 1));
    smaller_id_msg.mut_message().set_term(init_term + 1);
    router.send_raft_message(smaller_id_msg.clone()).unwrap();
    let meta = router
        .must_query_debug_info(test_region_id, timeout)
        .unwrap();
    assert_eq!(meta.raft_status.id, test_peer_id);
    assert_eq!(meta.raft_status.hard_state.term, init_term);
    cluster
        .receiver(0)
        .recv_timeout(Duration::from_millis(300))
        .unwrap_err();

    // Smaller ID tombstone message should trigger report.
    let mut smaller_id_tombstone_msg = smaller_id_msg.clone();
    smaller_id_tombstone_msg.set_is_tombstone(true);
    router.send_raft_message(smaller_id_tombstone_msg).unwrap();
    let report = cluster
        .receiver(0)
        .recv_timeout(Duration::from_millis(300))
        .unwrap();
    assert_valid_report(&report, test_region_id, test_peer_id - 1);

    // Larger ID should trigger destroy.
    let mut larger_id_msg = smaller_id_msg;
    larger_id_msg.set_to_peer(new_peer(1, test_peer_id + 1));
    router.send_raft_message(larger_id_msg).unwrap();
    assert_peer_not_exist(test_region_id, test_peer_id, router);
    let meta = router
        .must_query_debug_info(test_region_id, timeout)
        .unwrap();
    assert_eq!(meta.raft_status.id, test_peer_id + 1);
    assert_eq!(meta.raft_status.hard_state.term, init_term + 1);

    // New peer should survive restart.
    cluster.restart(0);
    let router = &cluster.routers[0];
    let meta = router
        .must_query_debug_info(test_region_id, timeout)
        .unwrap();
    assert_eq!(meta.raft_status.id, test_peer_id + 1);
    assert_eq!(meta.raft_status.hard_state.term, init_term + 1);
}
fn test_mv_arg_update_short_overwrite() {
    // same as --update=older
    let (at, mut ucmd) = at_and_ucmd!();

    let old = "test_mv_arg_update_none_file1";
    let new = "test_mv_arg_update_none_file2";
    let old_content = "file1 content\n";
    let new_content = "file2 content\n";

    at.write(old, old_content);

    sleep(Duration::from_secs(1));

    at.write(new, new_content);

    ucmd.arg(new)
        .arg(old)
        .arg("-u")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(old), new_content);
}
fn bindgen_test_layout_lol_html_str_t() {
    const UNINIT: ::std::mem::MaybeUninit<lol_html_str_t> = ::std::mem::MaybeUninit::uninit();
    let ptr = UNINIT.as_ptr();
    assert_eq!(
        ::std::mem::size_of::<lol_html_str_t>(),
        16usize,
        concat!("Size of: ", stringify!(lol_html_str_t))
    );
    assert_eq!(
        ::std::mem::align_of::<lol_html_str_t>(),
        8usize,
        concat!("Alignment of ", stringify!(lol_html_str_t))
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).data) as usize - ptr as usize },
        0usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_str_t),
            "::",
            stringify!(data)
        )
    );
    assert_eq!(
        unsafe { ::std::ptr::addr_of!((*ptr).len) as usize - ptr as usize },
        8usize,
        concat!(
            "Offset of field: ",
            stringify!(lol_html_str_t),
            "::",
            stringify!(len)
        )
    );
}
fn memory64_maximum_minimum() -> Result<()> {
    let mut config = Config::new();
    config.wasm_memory64(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, ());

    assert!(Memory::new(&mut store, MemoryType::new64(1 << 48, None)).is_err());

    let module = Module::new(
        &engine,
        &format!(
            r#"
                (module
                    (memory i64 {})
                )
            "#,
            1u64 << 48,
        ),
    )?;
    assert!(Instance::new(&mut store, &module, &[]).is_err());

    let module = Module::new(
        &engine,
        &format!(
            r#"
                (module
                    (memory i64 {})
                    (data (i64.const 0) "")
                )
            "#,
            1u64 << 48,
        ),
    )?;
    assert!(Instance::new(&mut store, &module, &[]).is_err());

    Ok(())
}
fn test_txn_gc_keys_handled() {
    let store_id = 1;
    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();
    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();

    let engine = TestEngineBuilder::new().build().unwrap();
    let mut prefixed_engine = PrefixedEngine(engine.clone());

    let (tx, _rx) = mpsc::channel();
    let feature_gate = FeatureGate::default();
    feature_gate.set_version("5.0.0").unwrap();
    let mut gc_worker = GcWorker::new(
        prefixed_engine.clone(),
        tx,
        GcConfig::default(),
        feature_gate,
        Arc::new(MockRegionInfoProvider::new(vec![])),
    );
    gc_worker.start(store_id).unwrap();

    let mut r1 = Region::default();
    r1.set_id(1);
    r1.mut_region_epoch().set_version(1);
    r1.set_start_key(b"".to_vec());
    r1.set_end_key(b"".to_vec());
    r1.mut_peers().push(Peer::default());
    r1.mut_peers()[0].set_store_id(store_id);

    let sp_provider = MockSafePointProvider(200);
    let mut host = CoprocessorHost::<RocksEngine>::default();
    let ri_provider = RegionInfoAccessor::new(&mut host);
    let auto_gc_cfg = AutoGcConfig::new(sp_provider, ri_provider, 1);
    let safe_point = Arc::new(AtomicU64::new(500));

    gc_worker.start_auto_gc(auto_gc_cfg, safe_point).unwrap();
    host.on_region_changed(&r1, RegionChangeEvent::Create, StateRole::Leader);

    let db = engine.kv_engine().unwrap().as_inner().clone();
    let cf = get_cf_handle(&db, CF_WRITE).unwrap();

    for i in 0..3 {
        let k = format!("k{:02}", i).into_bytes();
        must_prewrite_put(&mut prefixed_engine, &k, b"value", &k, 101);
        must_commit(&mut prefixed_engine, &k, 101, 102);
        must_prewrite_delete(&mut prefixed_engine, &k, &k, 151);
        must_commit(&mut prefixed_engine, &k, 151, 152);
    }

    db.flush_cf(cf, true, false).unwrap();

    db.compact_range_cf(cf, None, None);

    // This compaction can schedule gc task
    db.compact_range_cf(cf, None, None);
    thread::sleep(Duration::from_millis(100));

    assert_eq!(
        GC_COMPACTION_FILTER_MVCC_DELETION_MET
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get(),
        6
    );

    assert_eq!(
        GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get(),
        3
    );

    GC_COMPACTION_FILTER_MVCC_DELETION_MET.reset();
    GC_COMPACTION_FILTER_MVCC_DELETION_HANDLED.reset();
}
fn parse_unary_math_with_plus() {
    use self::Expr::*;
    let sql = "-a + -b";
    assert_eq!(
        BinaryOp {
            left: Box::new(UnaryOp {
                op: UnaryOperator::Minus,
                expr: Box::new(Identifier(Ident::new("a"))),
            }),
            op: BinaryOperator::Plus,
            right: Box::new(UnaryOp {
                op: UnaryOperator::Minus,
                expr: Box::new(Identifier(Ident::new("b"))),
            }),
        },
        verified_expr(sql)
    );
}
fn test_unsafe_recovery_demote_failed_voters() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    let peer_on_store2 = find_peer(&region, nodes[2]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store2.clone());
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);

    confirm_quorum_is_lost(&mut cluster, &region);

    cluster.must_enter_force_leader(region.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    let to_be_removed: Vec<metapb::Peer> = region
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    let mut demoted = true;
    for _ in 0..10 {
        let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

        demoted = true;
        for peer in region.get_peers() {
            if peer.get_id() != nodes[0] && peer.get_role() == metapb::PeerRole::Voter {
                demoted = false;
            }
        }
        if demoted {
            break;
        }
        sleep_ms(200);
    }
    assert!(demoted);
}
fn justfile_and_working_directory() {
  let tmp = temptree! {
    sub: {
      ".git": {},
    },
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path().join("sub"))
    .arg("--init")
    .arg("--justfile")
    .arg(tmp.path().join("justfile"))
    .arg("--working-directory")
    .arg("/")
    .output()
    .unwrap();

  assert!(output.status.success());

  assert_eq!(
    fs::read_to_string(tmp.path().join("justfile")).unwrap(),
    EXPECTED
  );
}
fn test_chown_no_change_to_user_group() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());
    let result = scene.cmd("id").arg("-ng").run();
    if skipping_test_is_okay(&result, "id: cannot find name for group ID") {
        return;
    }
    let group_name = String::from(result.stdout_str().trim());
    assert!(!group_name.is_empty());

    for (i, from) in ["42", ":42", "42:42"].iter().enumerate() {
        let file = i.to_string();
        at.touch(&file);
        scene
            .ucmd()
            .arg("-v")
            .arg(format!("--from={from}"))
            .arg("43:43")
            .arg(&file)
            .succeeds()
            .stdout_only(format!(
                "ownership of '{file}' retained as {user_name}:{group_name}\n"
            ));
    }
}
fn test_touch_set_ymdhm_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_ymdhm_time";

    ucmd.args(&["-t", "1501011234", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);
}
fn test_output_selects_columns() {
    let output = new_ucmd!()
        .args(&["--output=source"])
        .succeeds()
        .stdout_move_str();
    assert_eq!(output.lines().next().unwrap(), "Filesystem");

    let output = new_ucmd!()
        .args(&["--output=source,target"])
        .succeeds()
        .stdout_move_str();
    assert_eq!(
        output
            .lines()
            .next()
            .unwrap()
            .split_whitespace()
            .collect::<Vec<_>>(),
        vec!["Filesystem", "Mounted", "on"]
    );

    let output = new_ucmd!()
        .args(&["--output=source,target,used"])
        .succeeds()
        .stdout_move_str();
    assert_eq!(
        output
            .lines()
            .next()
            .unwrap()
            .split_whitespace()
            .collect::<Vec<_>>(),
        vec!["Filesystem", "Mounted", "on", "Used"]
    );
}
fn test_symlink_dangling_directory() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_symlink_dangling_dir";
    let link = "test_symlink_dangling_dir_link";

    ucmd.args(&["-s", dir, link]).succeeds().no_stderr();
    assert!(!at.dir_exists(dir));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), dir);
}
fn eph_basic_clone_test() {
    run_test(|| {
        let init_gc = Gc::new(String::from("bar"));

        let weak = WeakGc::new(&init_gc);

        let new_gc = weak.upgrade().expect("Weak is live");
        let new_weak = weak.clone();

        drop(weak);
        force_collect();

        assert_eq!(*new_gc, *new_weak.upgrade().expect("weak should be live"));
        assert_eq!(
            *init_gc,
            *new_weak.upgrade().expect("weak_should be live still")
        );
    });
}
async fn instantiate_async() -> Result<(), Error> {
    let mut config = Config::new();
    config.async_support(true);
    let engine = Engine::new(&config)?;
    let mut store = Store::new(&engine, State::default());
    store.call_hook(State::call_hook);

    let m = Module::new(store.engine(), "(module)")?;
    Instance::new_async(&mut store, &m, &[]).await?;
    assert_eq!(store.data().calls_into_wasm, 0);
    assert_eq!(store.data().calls_into_host, 0);

    let m = Module::new(store.engine(), "(module (func) (start 0))")?;
    Instance::new_async(&mut store, &m, &[]).await?;
    assert_eq!(store.data().calls_into_wasm, 1);
    assert_eq!(store.data().calls_into_host, 0);

    Ok(())
}
fn test_escape_basic() {
    assert_eq!(to_string(&"\x07").unwrap(), "\"\\u{7}\"");

    assert_eq!(from_str::<String>("\"\\x07\"").unwrap(), "\x07");
    assert_eq!(from_str::<String>("\"\\u{7}\"").unwrap(), "\x07");

    assert_eq!(from_str::<char>("\'\\x07\'").unwrap(), '\x07');
    assert_eq!(from_str::<char>("\'\\u{7}\'").unwrap(), '\x07');
}
fn null_invalid_type() {
    let err = serde_json::from_str::<String>("null").unwrap_err();
    assert_eq!(
        format!("{}", err),
        String::from("invalid type: null, expected a string at line 1 column 4")
    );
}
fn test_serving_status() {
    let mut cluster = new_server_cluster(0, 3);
    // A round is 30 ticks, set inspect interval to 20ms, so one round is 0.3s.
    cluster.cfg.raft_store.inspect_interval = ReadableDuration::millis(10);
    cluster.run();

    let service = cluster.sim.rl().health_services.get(&1).unwrap().clone();
    let builder =
        ServerBuilder::new(Arc::new(Environment::new(1))).register_service(create_health(service));
    let mut server = builder.bind("127.0.0.1", 0).build().unwrap();
    server.start();

    let (addr, port) = server.bind_addrs().next().unwrap();
    let ch =
        ChannelBuilder::new(Arc::new(Environment::new(1))).connect(&format!("{}:{}", addr, port));
    let client = HealthClient::new(ch);

    let check = || {
        let req = HealthCheckRequest {
            service: "".to_string(),
            ..Default::default()
        };
        let resp = client.check(&req).unwrap();
        resp.status
    };

    thread::sleep(Duration::from_millis(500));
    assert_eq!(check(), ServingStatus::Serving);

    fail::cfg("pause_on_peer_collect_message", "pause").unwrap();

    thread::sleep(Duration::from_secs(1));
    assert_eq!(check(), ServingStatus::ServiceUnknown);

    fail::remove("pause_on_peer_collect_message");

    // It should recover within one round.
    thread::sleep(Duration::from_millis(200));
    assert_eq!(check(), ServingStatus::Serving);
}
fn does_not_format_ignored_files() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_FORMATTER_IGNORED_FILES.as_bytes());

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("test.js"), ("--write")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_format_ignored_files",
        fs,
        console,
        result,
    ));
}
fn test_unsafe_recovery_during_merge() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);

    cluster.run();

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k2");

    let left = pd_client.get_region(b"k1").unwrap();
    let right = pd_client.get_region(b"k3").unwrap();

    let left_on_store1 = find_peer(&left, 1).unwrap();
    cluster.must_transfer_leader(left.get_id(), left_on_store1.clone());
    let right_on_store1 = find_peer(&right, 1).unwrap();
    cluster.must_transfer_leader(right.get_id(), right_on_store1.clone());

    // Blocks the replication of prepare merge message, so that the commit merge
    // back fills it in CatchUpLogs.
    let append_filter = Box::new(
        RegionPacketFilter::new(left.get_id(), 2)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend),
    );
    // Blocks the target region from receiving MsgAppendResponse, so that the commit
    // merge message will only be replicated but not committed.
    let commit_filter = Box::new(
        RegionPacketFilter::new(right.get_id(), 1)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppendResponse),
    );
    cluster.sim.wl().add_recv_filter(1, append_filter);
    cluster.sim.wl().add_recv_filter(1, commit_filter);

    pd_client.merge_region(left.get_id(), right.get_id());
    // Wait until the commit merge is proposed.
    sleep_ms(300);

    cluster.stop_node(1);
    cluster.stop_node(3);
    confirm_quorum_is_lost(&mut cluster, &region);

    let report = cluster.must_enter_force_leader(right.get_id(), 2, vec![1, 3]);
    assert_eq!(report.get_peer_reports().len(), 1);
    let peer_report = &report.get_peer_reports()[0];
    assert_eq!(peer_report.get_has_commit_merge(), false);
    let region = peer_report.get_region_state().get_region();
    assert_eq!(region.get_id(), right.get_id());
    assert_eq!(region.get_start_key().len(), 0);
    assert_eq!(region.get_end_key().len(), 0);

    let to_be_removed: Vec<metapb::Peer> = right
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != 2)
        .cloned()
        .collect();
    let mut plan = pdpb::RecoveryPlan::default();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(right.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);
    pd_client.must_set_unsafe_recovery_plan(2, plan);
    cluster.must_send_store_heartbeat(2);

    let mut demoted = true;
    for _ in 0..10 {
        let region = block_on(pd_client.get_region_by_id(right.get_id()))
            .unwrap()
            .unwrap();

        demoted = true;
        for peer in region.get_peers() {
            if peer.get_id() != 2 && peer.get_role() == metapb::PeerRole::Voter {
                demoted = false;
            }
        }
        if demoted {
            break;
        }
        sleep_ms(200);
    }
    assert!(demoted);
}
fn no_lint_if_linter_is_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_linter_is_disabled",
        fs,
        console,
        result,
    ));
}
fn test_flashback_for_local_read() {
    let mut cluster = new_node_cluster(0, 3);
    let election_timeout = configure_for_lease_read(&mut cluster.cfg, Some(50), None);
    // Avoid triggering the log compaction in this test case.
    cluster.cfg.raft_store.raft_log_gc_threshold = 100;
    cluster.run();
    cluster.must_put(TEST_KEY, TEST_VALUE);
    let mut region = cluster.get_region(TEST_KEY);
    let store_id = 3;
    let peer = new_peer(store_id, 3);
    cluster.must_transfer_leader(region.get_id(), peer);

    // Check local read before prepare flashback
    let state = cluster.raft_local_state(region.get_id(), store_id);
    let last_index = state.get_last_index();
    // Make sure the leader transfer procedure timeouts.
    sleep(election_timeout * 2);
    must_request_without_flashback_flag(&mut cluster, &mut region.clone(), new_get_cmd(TEST_KEY));
    // Check the leader does a local read.
    let state = cluster.raft_local_state(region.get_id(), store_id);
    assert_eq!(state.get_last_index(), last_index);

    // Prepare flashback.
    cluster.must_send_wait_flashback_msg(region.get_id(), AdminCmdType::PrepareFlashback);
    // Check the leader does a local read.
    let state = cluster.raft_local_state(region.get_id(), store_id);
    assert_eq!(state.get_last_index(), last_index + 1);
    // Wait for apply_res to set leader lease.
    sleep_ms(500);
    // Read should fail.
    must_get_flashback_in_progress_error(&mut cluster, &mut region.clone(), new_get_cmd(TEST_KEY));
    // Wait for the leader's lease to expire to ensure that a renew lease interval
    // has elapsed.
    sleep(election_timeout * 2);
    // Read should fail.
    must_get_flashback_in_progress_error(&mut cluster, &mut region.clone(), new_get_cmd(TEST_KEY));
    // Also check read by propose was blocked
    let state = cluster.raft_local_state(region.get_id(), store_id);
    assert_eq!(state.get_last_index(), last_index + 1);
    // Finish flashback.
    cluster.must_send_wait_flashback_msg(region.get_id(), AdminCmdType::FinishFlashback);
    let state = cluster.raft_local_state(region.get_id(), store_id);
    assert_eq!(state.get_last_index(), last_index + 2);

    // Check local read after finish flashback
    let state = cluster.raft_local_state(region.get_id(), store_id);
    let last_index = state.get_last_index();
    // Make sure the leader transfer procedure timeouts.
    sleep(election_timeout * 2);
    must_request_without_flashback_flag(&mut cluster, &mut region.clone(), new_get_cmd(TEST_KEY));
    // Check the leader does a local read.
    let state = cluster.raft_local_state(region.get_id(), store_id);
    assert_eq!(state.get_last_index(), last_index);
    // A local read with flashback flag will not be blocked since it won't have any
    // side effects.
    must_request_with_flashback_flag(&mut cluster, &mut region, new_get_cmd(TEST_KEY));
}
fn parse_dwarf_info() -> Result<()> {
    let wasm = rustc(
        "
            fn main() {
                panic!();
            }
        ",
    );
    let mut config = Config::new();
    config.wasm_backtrace_details(WasmBacktraceDetails::Enable);
    let engine = Engine::new(&config)?;
    let module = Module::new(&engine, &wasm)?;
    let mut linker = Linker::new(&engine);
    wasmtime_wasi::add_to_linker(&mut linker, |s| s)?;
    let mut store = Store::new(
        &engine,
        wasmtime_wasi::sync::WasiCtxBuilder::new()
            .inherit_stdio()
            .build(),
    );
    linker.module(&mut store, "", &module)?;
    let run = linker.get_default(&mut store, "")?;
    let trap = run.call(&mut store, &[], &mut []).unwrap_err();

    let mut found = false;
    let frames = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();
    for frame in frames {
        for symbol in frame.symbols() {
            if let Some(file) = symbol.file() {
                if file.ends_with("input.rs") {
                    found = true;
                    assert!(symbol.name().unwrap().contains("main"));
                    assert_eq!(symbol.line(), Some(3));
                }
            }
        }
    }
    assert!(found);
    Ok(())
}
fn parse_create_index() {
    let sql = "CREATE UNIQUE INDEX IF NOT EXISTS idx_name ON test(name,age DESC)";
    let indexed_columns = vec![
        OrderByExpr {
            expr: Expr::Identifier(Ident::new("name")),
            asc: None,
            nulls_first: None,
        },
        OrderByExpr {
            expr: Expr::Identifier(Ident::new("age")),
            asc: Some(false),
            nulls_first: None,
        },
    ];
    match verified_stmt(sql) {
        Statement::CreateIndex {
            name: Some(name),
            table_name,
            columns,
            unique,
            if_not_exists,
            ..
        } => {
            assert_eq!("idx_name", name.to_string());
            assert_eq!("test", table_name.to_string());
            assert_eq!(indexed_columns, columns);
            assert!(unique);
            assert!(if_not_exists)
        }
        _ => unreachable!(),
    }
}
fn encode_error_size() {
    #[cfg(any(feature = "std", feature = "alloc"))]
    assert_eq!(std::mem::size_of::<bincode::error::EncodeError>(), 32);

    #[cfg(not(any(feature = "std", feature = "alloc")))]
    assert_eq!(std::mem::size_of::<bincode::error::EncodeError>(), 24);
}
fn trapping() -> Result<(), Error> {
    const TRAP_IN_F: i32 = 0;
    const TRAP_NEXT_CALL_HOST: i32 = 1;
    const TRAP_NEXT_RETURN_HOST: i32 = 2;
    const TRAP_NEXT_CALL_WASM: i32 = 3;
    const TRAP_NEXT_RETURN_WASM: i32 = 4;

    let engine = Engine::default();

    let mut linker = Linker::new(&engine);

    linker.func_wrap(
        "host",
        "f",
        |mut caller: Caller<State>, action: i32, recur: i32| -> Result<()> {
            assert_eq!(caller.data().context.last(), Some(&Context::Host));
            assert_eq!(caller.data().calls_into_host, caller.data().calls_into_wasm);

            match action {
                TRAP_IN_F => bail!("trapping in f"),
                TRAP_NEXT_CALL_HOST => caller.data_mut().trap_next_call_host = true,
                TRAP_NEXT_RETURN_HOST => caller.data_mut().trap_next_return_host = true,
                TRAP_NEXT_CALL_WASM => caller.data_mut().trap_next_call_wasm = true,
                TRAP_NEXT_RETURN_WASM => caller.data_mut().trap_next_return_wasm = true,
                _ => {} // Do nothing
            }

            // recur so that we can trigger a next call.
            // propogate its trap, if it traps!
            if recur > 0 {
                let _ = caller
                    .get_export("export")
                    .expect("caller exports \"export\"")
                    .into_func()
                    .expect("export is a func")
                    .typed::<(i32, i32), ()>(&caller)
                    .expect("export typing")
                    .call(&mut caller, (action, 0))?;
            }

            Ok(())
        },
    )?;

    let wat = r#"
        (module
            (import "host" "f"
                (func $f (param i32) (param i32)))
            (func (export "export") (param i32) (param i32)
                (call $f (local.get 0) (local.get 1)))
        )
    "#;
    let module = Module::new(&engine, wat)?;

    let run = |action: i32, recur: bool| -> (State, Option<Error>) {
        let mut store = Store::new(&engine, State::default());
        store.call_hook(State::call_hook);
        let inst = linker
            .instantiate(&mut store, &module)
            .expect("instantiate");
        let export = inst
            .get_export(&mut store, "export")
            .expect("get export")
            .into_func()
            .expect("export is func");

        let r = export.call(
            &mut store,
            &[Val::I32(action), Val::I32(if recur { 1 } else { 0 })],
            &mut [],
        );
        (store.into_data(), r.err())
    };

    let (s, e) = run(TRAP_IN_F, false);
    assert!(format!("{:?}", e.unwrap()).contains("trapping in f"));
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 1);
    assert_eq!(s.returns_from_wasm, 1);

    // trap in next call to host. No calls after the bit is set, so this trap shouldn't happen
    let (s, e) = run(TRAP_NEXT_CALL_HOST, false);
    assert!(e.is_none());
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 1);
    assert_eq!(s.returns_from_wasm, 1);

    // trap in next call to host. recur, so the second call into host traps:
    let (s, e) = run(TRAP_NEXT_CALL_HOST, true);
    assert!(format!("{:?}", e.unwrap()).contains("call_hook: trapping on CallingHost"));
    assert_eq!(s.calls_into_host, 2);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 2);
    assert_eq!(s.returns_from_wasm, 2);

    // trap in the return from host. should trap right away, without recursion
    let (s, e) = run(TRAP_NEXT_RETURN_HOST, false);
    assert!(format!("{:?}", e.unwrap()).contains("call_hook: trapping on ReturningFromHost"));
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 1);
    assert_eq!(s.returns_from_wasm, 1);

    // trap in next call to wasm. No calls after the bit is set, so this trap shouldnt happen:
    let (s, e) = run(TRAP_NEXT_CALL_WASM, false);
    assert!(e.is_none());
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 1);
    assert_eq!(s.returns_from_wasm, 1);

    // trap in next call to wasm. recur, so the second call into wasm traps:
    let (s, e) = run(TRAP_NEXT_CALL_WASM, true);
    assert!(format!("{:?}", e.unwrap()).contains("call_hook: trapping on CallingWasm"));
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 2);
    assert_eq!(s.returns_from_wasm, 1);

    // trap in the return from wasm. should trap right away, without recursion
    let (s, e) = run(TRAP_NEXT_RETURN_WASM, false);
    assert!(format!("{:?}", e.unwrap()).contains("call_hook: trapping on ReturningFromWasm"));
    assert_eq!(s.calls_into_host, 1);
    assert_eq!(s.returns_from_host, 1);
    assert_eq!(s.calls_into_wasm, 1);
    assert_eq!(s.returns_from_wasm, 1);

    Ok(())
}
fn test_type_size() {
    assert_eq!(mem::size_of::<Type>(), 232);
}
fn test_dateformat() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATE_FORMAT", "[year]-[month]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("1687624642.5|dateformat(format=format)")
        .unwrap();

    assert_eq!(
        expr.eval(context!(format => "short")).unwrap().to_string(),
        "2023-06-24"
    );
    assert_eq!(
        expr.eval(context!(format => "medium")).unwrap().to_string(),
        "Jun 24 2023"
    );
    assert_eq!(
        expr.eval(context!(format => "long")).unwrap().to_string(),
        "June 24 2023"
    );
    assert_eq!(
        expr.eval(context!(format => "full")).unwrap().to_string(),
        "Saturday, June 24 2023"
    );

    let expr = env
        .compile_expression("1687624642|dateformat(tz='Europe/Moscow')")
        .unwrap();
    assert_eq!(expr.eval(()).unwrap().to_string(), "2023-06");
}
fn test_almost_and_already_full_behavior() {
    let mut cluster = new_server_cluster(0, 5);
    // To ensure the thread has full store disk usage infomation.
    cluster.cfg.raft_store.store_batch_system.pool_size = 1;
    cluster.pd_client.disable_default_operator();
    cluster.run();

    cluster.must_put(b"k1", b"v1");
    let region = cluster.get_region(b"k1");
    cluster.must_transfer_leader(region.get_id(), new_peer(1, 1));
    // To ensure followers have reported disk usages to the leader.
    for i in [2u64, 3] {
        fail::cfg(get_fp(DiskUsage::AlmostFull, i), "return").unwrap();
    }
    for i in [4u64, 5] {
        fail::cfg(get_fp(DiskUsage::AlreadyFull, i), "return").unwrap();
    }
    for i in 1..5 {
        ensure_disk_usage_is_reported(&mut cluster, i + 1, i + 1, &region);
    }

    let lead_client = PeerClient::new(&cluster, 1, new_peer(1, 1));
    let prewrite_ts = get_tso(&cluster.pd_client);
    let res = lead_client.try_kv_prewrite(
        vec![new_mutation(Op::Put, b"k2", b"v2")],
        b"k2".to_vec(),
        prewrite_ts,
        DiskFullOpt::AllowedOnAlmostFull,
    );
    assert!(!res.get_region_error().has_disk_full());
    lead_client.must_kv_commit(
        vec![b"k2".to_vec()],
        prewrite_ts,
        get_tso(&cluster.pd_client),
    );

    let index_1 = cluster.raft_local_state(1, 1).last_index;
    let index_2 = cluster.raft_local_state(1, 2).last_index;
    let index_3 = cluster.raft_local_state(1, 3).last_index;
    let index_4 = cluster.raft_local_state(1, 4).last_index;
    let index_5 = cluster.raft_local_state(1, 5).last_index;
    assert!(
        index_1 >= index_2
            && index_1 >= index_3
            && index_2 > index_4
            && index_2 > index_5
            && index_3 > index_4
            && index_3 > index_5
    );

    for i in [2u64, 3] {
        fail::remove(get_fp(DiskUsage::AlmostFull, i));
    }
    for i in [4u64, 5] {
        fail::remove(get_fp(DiskUsage::AlreadyFull, i));
    }
}
fn test_diff_stdin_formatted() {
    let args = ["format", "--isolated", "--diff", "-"];
    let fixtures = Path::new("resources").join("test").join("fixtures");
    let unformatted = fs::read(fixtures.join("formatted.py")).unwrap();
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME)).args(args).pass_stdin(unformatted),
        @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    "###);
}
fn expr_test() {
  assert_eq!(
    expr(" 1 + 2 *  3 ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("(1 + (2 * 3))")))
  );
  assert_eq!(
    expr(" 1 + 2 *  3 / 4 - 5 ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("((1 + ((2 * 3) / 4)) - 5)")))
  );
  assert_eq!(
    expr(" 72 / 2 / 3 ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("((72 / 2) / 3)")))
  );
}
fn client_can_override_certificate_verification_and_reject_certificate() {
    for kt in ALL_KEY_TYPES.iter() {
        let verifier = Arc::new(MockServerVerifier::rejects_certificate(
            Error::InvalidMessage(InvalidMessage::HandshakePayloadTooLarge),
        ));

        let server_config = Arc::new(make_server_config(*kt));

        for version in rustls::ALL_VERSIONS {
            let mut client_config = make_client_config_with_versions(*kt, &[version]);
            client_config
                .dangerous()
                .set_certificate_verifier(verifier.clone());

            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
            let errs = do_handshake_until_both_error(&mut client, &mut server);
            assert_eq!(
                errs,
                Err(vec![
                    ErrorFromPeer::Client(Error::InvalidMessage(
                        InvalidMessage::HandshakePayloadTooLarge,
                    )),
                    ErrorFromPeer::Server(Error::AlertReceived(AlertDescription::HandshakeFailure)),
                ]),
            );
        }
    }
}
fn redefining_loop_value_doesnt_break_loop() {
    let mut tera = Tera::default();
    tera.add_raw_template(
        "tpl",
        r#"
{%- set string = "abcdefghdijklm" | split(pat="d") -%}
{% for i in string -%}
    {%- set j = i ~ "lol" ~ " " -%}
    {{ j }}
{%- endfor -%}
        "#,
    )
    .unwrap();
    let context = Context::new();
    let result = tera.render("tpl", &context);

    assert_eq!(result.unwrap(), "abclol efghlol ijklmlol ");
}
fn test_missing_operand() {
    let result = new_ucmd!().fails();

    result.code_is(125);

    assert!(result
        .stderr_str()
        .starts_with("error: the following required arguments were not provided"));

    assert!(result.stderr_str().contains("<newroot>"));
}
fn test_destroy_clean_up_logs_with_log_gc() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(50);
    cluster.cfg.raft_store.raft_log_gc_threshold = 50;
    let pd_client = cluster.pd_client.clone();

    // Disable default max peer number check.
    pd_client.disable_default_operator();
    cluster.run();
    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k2", b"v2");
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    let raft_engine = cluster.engines[&3].raft.clone();
    let mut dest = vec![];
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(!dest.is_empty());

    pd_client.must_remove_peer(1, new_peer(3, 3));
    must_get_none(&cluster.get_engine(3), b"k1");
    dest.clear();
    // Normally destroy peer should cleanup all logs.
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(dest.is_empty(), "{:?}", dest);

    pd_client.must_add_peer(1, new_peer(3, 4));
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");
    must_get_equal(&cluster.get_engine(3), b"k3", b"v3");
    dest.clear();
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(!dest.is_empty());

    pd_client.must_remove_peer(1, new_peer(3, 4));
    must_get_none(&cluster.get_engine(3), b"k1");
    dest.clear();
    // Peer created by snapshot should also cleanup all logs.
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(dest.is_empty(), "{:?}", dest);

    pd_client.must_add_peer(1, new_peer(3, 5));
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    cluster.must_put(b"k4", b"v4");
    must_get_equal(&cluster.get_engine(3), b"k4", b"v4");
    dest.clear();
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(!dest.is_empty());

    let state = cluster.truncated_state(1, 3);
    for _ in 0..50 {
        cluster.must_put(b"k5", b"v5");
    }
    cluster.wait_log_truncated(1, 3, state.get_index() + 1);

    pd_client.must_remove_peer(1, new_peer(3, 5));
    must_get_none(&cluster.get_engine(3), b"k1");
    dest.clear();
    // Peer destroy after log gc should also cleanup all logs.
    raft_engine.get_all_entries_to(1, &mut dest).unwrap();
    assert!(dest.is_empty(), "{:?}", dest);
}
fn inscribe_creates_inscriptions() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let (inscription, _) = inscribe(&rpc_server);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let request =
    TestServer::spawn_with_args(&rpc_server, &[]).request(format!("/content/{inscription}"));

  assert_eq!(request.status(), 200);
  assert_eq!(
    request.headers().get("content-type").unwrap(),
    "text/plain;charset=utf-8"
  );
  assert_eq!(request.text().unwrap(), "FOO");
}
fn test_sync_recover_after_apply_snapshot() {
    let mut cluster = prepare_cluster();
    configure_for_snapshot(&mut cluster);
    run_cluster(&mut cluster);
    let region = cluster.get_region(b"k1");
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_put_cf_cmd("default", b"k2", b"v2")],
        false,
    );
    request.mut_header().set_peer(new_peer(1, 1));
    let (cb, mut rx) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, request, cb)
        .unwrap();
    assert_eq!(
        rx.recv_timeout(Duration::from_millis(100)),
        Err(future::RecvTimeoutError::Timeout)
    );
    must_get_none(&cluster.get_engine(1), b"k2");
    let state = cluster.pd_client.region_replication_status(region.get_id());
    assert_eq!(state.state_id, 1);
    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);

    // swith to async
    cluster
        .pd_client
        .switch_replication_mode(DrAutoSyncState::Async, vec![]);
    rx.recv_timeout(Duration::from_millis(100)).unwrap();
    must_get_equal(&cluster.get_engine(1), b"k2", b"v2");
    thread::sleep(Duration::from_millis(100));
    let state = cluster.pd_client.region_replication_status(region.get_id());
    assert_eq!(state.state_id, 2);
    assert_eq!(state.state, RegionReplicationState::SimpleMajority);

    // Write some data to trigger snapshot.
    for i in 10..110 {
        let key = format!("k{}", i);
        let value = format!("v{}", i);
        cluster.must_put_cf("default", key.as_bytes(), value.as_bytes());
    }

    cluster
        .pd_client
        .switch_replication_mode(DrAutoSyncState::SyncRecover, vec![]);
    thread::sleep(Duration::from_millis(100));
    // Add node 3 back, snapshot will apply
    cluster.clear_send_filters();
    cluster.must_transfer_leader(region.get_id(), new_peer(3, 3));
    must_get_equal(&cluster.get_engine(3), b"k100", b"v100");
    thread::sleep(Duration::from_millis(100));
    let state = cluster.pd_client.region_replication_status(region.get_id());
    assert_eq!(state.state_id, 3);
    assert_eq!(state.state, RegionReplicationState::IntegrityOverLabel);
}
fn drain_forget() {
    // test mem::forgetting does not double-free

    let mut headers = HeaderMap::<HeaderValue>::new();
    headers.insert("hello", "world".parse().unwrap());
    headers.insert("zomg", "bar".parse().unwrap());

    assert_eq!(headers.len(), 2);

    {
        let mut iter = headers.drain();
        assert_eq!(iter.size_hint(), (2, Some(2)));
        let _ = iter.next().unwrap();
        std::mem::forget(iter);
    }

    assert_eq!(headers.len(), 0);
}
fn server_cert_resolve_with_sni() {
    for kt in ALL_KEY_TYPES.iter() {
        let client_config = make_client_config(*kt);
        let mut server_config = make_server_config(*kt);

        server_config.cert_resolver = Arc::new(ServerCheckCertResolve {
            expected_sni: Some("the-value-from-sni".into()),
            ..Default::default()
        });

        let mut client =
            ClientConnection::new(Arc::new(client_config), dns_name("the-value-from-sni")).unwrap();
        let mut server = ServerConnection::new(Arc::new(server_config)).unwrap();

        let err = do_handshake_until_error(&mut client, &mut server);
        assert!(err.is_err());
    }
}
fn test_cp_no_deref() {
    let (at, mut ucmd) = at_and_ucmd!();

    #[cfg(not(windows))]
    let _r = fs::symlink(
        TEST_HELLO_WORLD_SOURCE,
        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),
    );
    #[cfg(windows)]
    let _r = symlink_file(
        TEST_HELLO_WORLD_SOURCE,
        at.subdir.join(TEST_HELLO_WORLD_SOURCE_SYMLINK),
    );
    //using -P option
    ucmd.arg("-P")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HELLO_WORLD_SOURCE_SYMLINK)
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    let path_to_new_symlink = at
        .subdir
        .join(TEST_COPY_TO_FOLDER)
        .join(TEST_HELLO_WORLD_SOURCE_SYMLINK);
    assert!(at.is_symlink(
        &path_to_new_symlink
            .clone()
            .into_os_string()
            .into_string()
            .unwrap()
    ));
    // Check the content of the destination file that was copied.
    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), "Hello, World!\n");
    let path_to_check = path_to_new_symlink.to_str().unwrap();
    assert_eq!(at.read(path_to_check), "Hello, World!\n");
}
fn test_skip_iter_il() {
    // Test iterators that skip single, internal or leading-only digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_leading_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"_45_5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"_.45_5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4_5__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4_5__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"_45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"_45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"_4_5__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"_4_5__.56");
}
fn test_grouping() {
    let tokens: TokenStream = TokenStream::from_iter(vec![
        TokenTree::Literal(Literal::i32_suffixed(1)),
        TokenTree::Punct(Punct::new('+', Spacing::Alone)),
        TokenTree::Group(Group::new(
            Delimiter::None,
            TokenStream::from_iter(vec![
                TokenTree::Literal(Literal::i32_suffixed(2)),
                TokenTree::Punct(Punct::new('+', Spacing::Alone)),
                TokenTree::Literal(Literal::i32_suffixed(3)),
            ]),
        )),
        TokenTree::Punct(Punct::new('*', Spacing::Alone)),
        TokenTree::Literal(Literal::i32_suffixed(4)),
    ]);

    assert_eq!(tokens.to_string(), "1i32 + 2i32 + 3i32 * 4i32");

    snapshot!(tokens as Expr, @r###"
    Expr::Binary {
        left: Expr::Lit {
            lit: 1i32,
        },
        op: BinOp::Add,
        right: Expr::Binary {
            left: Expr::Group {
                expr: Expr::Binary {
                    left: Expr::Lit {
                        lit: 2i32,
                    },
                    op: BinOp::Add,
                    right: Expr::Lit {
                        lit: 3i32,
                    },
                },
            },
            op: BinOp::Mul,
            right: Expr::Lit {
                lit: 4i32,
            },
        },
    }
    "###);
}
fn test_install_basic() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "target_dir";
    let file1 = "source_file1";
    let file2 = "source_file2";

    at.touch(file1);
    at.touch(file2);
    at.mkdir(dir);
    ucmd.arg(file1).arg(file2).arg(dir).succeeds().no_stderr();

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
    assert!(at.file_exists(format!("{dir}/{file1}")));
    assert!(at.file_exists(format!("{dir}/{file2}")));
}
fn migrate_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("migrate"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "migrate_help",
        fs,
        console,
        result,
    ));
}
fn test_invoke_func_via_table() -> Result<()> {
    let mut store = Store::<()>::default();

    let wat = r#"
      (module
        (func $f (result i64) (i64.const 42))

        (table (export "table") 1 1 anyfunc)
        (elem (i32.const 0) $f)
      )
    "#;
    let module = Module::new(store.engine(), wat).context("> Error compiling module!")?;
    let instance =
        Instance::new(&mut store, &module, &[]).context("> Error instantiating module!")?;

    let f = instance
        .get_table(&mut store, "table")
        .unwrap()
        .get(&mut store, 0)
        .unwrap()
        .funcref()
        .unwrap()
        .unwrap()
        .clone();
    let mut results = [Val::I32(0)];
    f.call(&mut store, &[], &mut results).unwrap();
    assert_eq!(results[0].unwrap_i64(), 42);
    Ok(())
}
fn abort() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "aborted").unwrap();
        assert_eq!("aborted", table.get("hello").unwrap().unwrap().value());
    }
    write_txn.abort().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE);
    assert!(table.is_err());

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    assert_eq!(table.len().unwrap(), 1);
}
fn with_configuration() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    fs.insert(
        Path::new("biome.json").to_path_buf(),
        r#"{
  "formatter": {
    "enabled": false
  }
}"#,
    );

    let result = run_rage(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("rage")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_rage_snapshot(SnapshotPayload::new(
        module_path!(),
        "with_configuration",
        fs,
        console,
        result,
    ));
}
fn test_output_mp_repeat() {
    let output1 = new_ucmd!().arg("/").arg("/").succeeds().stdout_move_str();
    let output1: Vec<String> = output1
        .lines()
        .map(|l| String::from(l.split_once(' ').unwrap().0))
        .collect();
    assert_eq!(3, output1.len());
    assert_eq!(output1[1], output1[2]);
}
fn signatures_match() {
    let mut store = Store::<()>::default();

    let f = Func::wrap(&mut store, || {});
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[]);

    let f = Func::wrap(&mut store, || -> i32 { loop {} });
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::I32]);

    let f = Func::wrap(&mut store, || -> i64 { loop {} });
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::I64]);

    let f = Func::wrap(&mut store, || -> f32 { loop {} });
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F32]);

    let f = Func::wrap(&mut store, || -> f64 { loop {} });
    assert_eq!(f.ty(&store).params().collect::<Vec<_>>(), &[]);
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F64]);

    let f = Func::wrap(
        &mut store,
        |_: f32, _: f64, _: i32, _: i64, _: i32, _: Option<ExternRef>, _: Option<Func>| -> f64 {
            loop {}
        },
    );
    assert_eq!(
        f.ty(&store).params().collect::<Vec<_>>(),
        &[
            ValType::F32,
            ValType::F64,
            ValType::I32,
            ValType::I64,
            ValType::I32,
            ValType::ExternRef,
            ValType::FuncRef,
        ]
    );
    assert_eq!(f.ty(&store).results().collect::<Vec<_>>(), &[ValType::F64]);
}
fn computef32_test() {
    // Halfway, round-down tests
    assert_eq!(compute_float32::<BINARY>(0, 16777216, false), (151, 0));
    assert_eq!(compute_float32::<BINARY>(0, 16777217, false), (151, 0));
    assert_eq!(compute_float32::<BINARY>(0, 16777218, false), (151, 1));

    assert_eq!(compute_float32::<BINARY>(0, 33554432, false), (152, 0));
    assert_eq!(compute_float32::<BINARY>(0, 33554434, false), (152, 0));
    assert_eq!(compute_float32::<BINARY>(0, 33554436, false), (152, 1));
}
fn pass_cross_store_arg() -> anyhow::Result<()> {
    let mut config = Config::new();
    config.wasm_reference_types(true);
    let engine = Engine::new(&config)?;

    let mut store1 = Store::new(&engine, ());
    let mut store2 = Store::new(&engine, ());

    let store1_func = Func::wrap(&mut store1, |_: Option<Func>| {});
    let store2_func = Func::wrap(&mut store2, || {});

    // Using regular `.call` fails with cross-Store arguments.
    assert!(store1_func
        .call(
            &mut store1,
            &[Val::FuncRef(Some(store2_func.clone()))],
            &mut []
        )
        .is_err());

    // And using `.get` followed by a function call also fails with cross-Store
    // arguments.
    let f = store1_func.typed::<Option<Func>, ()>(&store1)?;
    let result = f.call(&mut store1, Some(store2_func));
    assert!(result.is_err());
    assert!(result.unwrap_err().to_string().contains("cross-`Store`"));

    Ok(())
}
fn test_rm_interactive_once_recursive_prompt() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file1 = "test_rm_interactive_once_recursive_prompt_file1";

    at.touch(file1);

    ucmd.arg("--interactive=once")
        .arg("-r")
        .arg(file1)
        .pipe_in("y")
        .succeeds()
        .stderr_contains("remove 1 argument recursively?");

    assert!(!at.file_exists(file1));
}
fn extreme_default_values() {
    let pb = protobuf_unittest::TestExtremeDefaultValues::default();

    assert_eq!(
        b"\0\x01\x07\x08\x0C\n\r\t\x0B\\\'\"\xFE",
        pb.escaped_bytes()
    );

    assert_eq!(0xFFFFFFFF, pb.large_uint32());
    assert_eq!(0xFFFFFFFFFFFFFFFF, pb.large_uint64());
    assert_eq!(-0x7FFFFFFF, pb.small_int32());
    assert_eq!(-0x7FFFFFFFFFFFFFFF, pb.small_int64());
    assert_eq!(-0x80000000, pb.really_small_int32());
    assert_eq!(-0x8000000000000000, pb.really_small_int64());

    assert_eq!(pb.utf8_string(), "\u{1234}");

    assert_eq!(0.0, pb.zero_float());
    assert_eq!(1.0, pb.one_float());
    assert_eq!(1.5, pb.small_float());
    assert_eq!(-1.0, pb.negative_one_float());
    assert_eq!(-1.5, pb.negative_float());
    assert_eq!(2E8, pb.large_float());
    assert_eq!(-8e-28, pb.small_negative_float());

    assert_eq!(f64::INFINITY, pb.inf_double());
    assert_eq!(f64::NEG_INFINITY, pb.neg_inf_double());
    assert_ne!(pb.nan_double(), pb.nan_double());
    assert_eq!(f32::INFINITY, pb.inf_float());
    assert_eq!(f32::NEG_INFINITY, pb.neg_inf_float());
    assert_ne!(pb.nan_float(), pb.nan_float());

    assert_eq!("? ? ?? ?? ??? ??/ ??-", pb.cpp_trigraph());

    assert_eq!("hel\x00lo", pb.string_with_zero());
    assert_eq!(b"wor\x00ld", pb.bytes_with_zero());
    assert_eq!("ab\x00c", pb.string_piece_with_zero());
    assert_eq!("12\x003", pb.cord_with_zero());
    assert_eq!("${unknown}", pb.replacement_string());
}
fn render_filter_section_inheritance_no_override() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("top", "{% filter upper %}hello {% block main %}top{% endblock main %}{% endfilter %}"),
        ("bottom", "{% extends 'top' %}"),
    ])
    .unwrap();
    let result = tera.render("bottom", &Context::new());

    assert_eq!(result.unwrap(), "HELLO TOP".to_string());
}
fn implicit_open() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();
    let s1 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    let s2 = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    pair.client_send(client_ch, s2).write(b"hello").unwrap();
    pair.drive();
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), Some(s1));
    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), Some(s2));
    assert_eq!(pair.server_streams(server_ch).accept(Dir::Uni), None);
}
fn test_map_key_value() {
    struct Map;

    impl serde::Serialize for Map {
        fn serialize<S>(&self, serializer: S) -> Result<S::Ok, S::Error>
        where
            S: serde::Serializer,
        {
            // Test maps which do not serialize using serialize_entry.
            let mut map = serializer.serialize_map(Some(1))?;
            map.serialize_key("k")?;
            map.serialize_value("v")?;
            map.end()
        }
    }

    let yaml = indoc! {"
        k: v
    "};
    assert_eq!(yaml, serde_yaml::to_string(&Map).unwrap());
}
fn parse_try_cast() {
    let sql = "SELECT TRY_CAST(id AS BIGINT) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TryCast {
            expr: Box::new(Expr::Identifier(Ident::new("id"))),
            data_type: DataType::BigInt(None),
            format: None,
        },
        expr_from_projection(only(&select.projection))
    );
    verified_stmt("SELECT TRY_CAST(id AS BIGINT) FROM customer");

    verified_stmt("SELECT TRY_CAST(id AS NUMERIC) FROM customer");

    verified_stmt("SELECT TRY_CAST(id AS DEC) FROM customer");

    verified_stmt("SELECT TRY_CAST(id AS DECIMAL) FROM customer");
}
fn test_install_parent_directories() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ancestor1 = "ancestor1";
    let ancestor2 = "ancestor1/ancestor2";
    let target_dir = "ancestor1/ancestor2/target_dir";
    let directories_arg = "-d";

    // Here one of the ancestors already exist and only the target_dir and
    // its parent must be created.
    at.mkdir(ancestor1);

    ucmd.args(&[directories_arg, target_dir])
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(ancestor2));
    assert!(at.dir_exists(target_dir));
}
fn vec_fixed_width_value_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<u8, Vec<u64>> = TableDefinition::new("x");

    let value = vec![0, 1, 2, 3];
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert(0, &value).unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!(value, table.get(0).unwrap().unwrap().value());
}
fn test_safe_string_roundtrip() {
    let v = Value::from_safe_string("<b>HTML</b>".into());
    let v2 = Value::from_serializable(&v);
    assert!(v.is_safe());
    assert!(v2.is_safe());
    assert_eq!(v.to_string(), v2.to_string());
}
fn render_magic_variable_isnt_escaped() {
    let mut context = Context::new();
    context.insert("html", &"<html>");

    let result = render_template("{{ __tera_context }}", &context);

    assert_eq!(
        result.unwrap(),
        r#"{
  "html": "<html>"
}"#
        .to_owned()
    );
}
fn test_force_leader_trigger_snapshot() {
    let mut cluster = new_node_cluster(0, 5);
    cluster.cfg.raft_store.raft_base_tick_interval = ReadableDuration::millis(10);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 10;
    cluster.cfg.raft_store.raft_store_max_leader_lease = ReadableDuration::millis(90);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(8);
    cluster.cfg.raft_store.merge_max_log_gap = 3;
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(10);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store1 = find_peer(&region, 1).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // Isolate node 2
    cluster.add_send_filter(IsolationFilterFactory::new(2));

    // Compact logs to force requesting snapshot after clearing send filters.
    let state = cluster.truncated_state(region.get_id(), 1);
    // Write some data to trigger snapshot.
    for i in 100..150 {
        let key = format!("k{}", i);
        let value = format!("v{}", i);
        cluster.must_put(key.as_bytes(), value.as_bytes());
    }
    cluster.wait_log_truncated(region.get_id(), 1, state.get_index() + 40);

    cluster.stop_node(3);
    cluster.stop_node(4);
    cluster.stop_node(5);

    // Recover the isolation of 2, but still don't permit snapshot
    let recv_filter = Box::new(
        RegionPacketFilter::new(region.get_id(), 2)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgSnapshot),
    );
    cluster.sim.wl().add_recv_filter(2, recv_filter);
    cluster.clear_send_filters();

    // wait election timeout
    sleep_ms(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 5,
    );
    cluster.enter_force_leader(region.get_id(), 1, vec![3, 4, 5]);

    sleep_ms(
        cluster.cfg.raft_store.raft_election_timeout_ticks as u64
            * cluster.cfg.raft_store.raft_base_tick_interval.as_millis()
            * 3,
    );
    let cmd = new_change_peer_request(
        ConfChangeType::RemoveNode,
        find_peer(&region, 3).unwrap().clone(),
    );
    let req = new_admin_request(region.get_id(), region.get_region_epoch(), cmd);
    // Though it has a force leader now, but the command can't committed because the
    // log is not replicated to all the alive peers.
    assert!(
        cluster
            .call_command_on_leader(req, Duration::from_millis(1000))
            .unwrap()
            .get_header()
            .has_error() /* error "there is a pending conf change" indicating no committed log
                          * after being the leader */
    );

    // Permit snapshot message, snapshot should be applied and advance commit index
    // now.
    cluster.sim.wl().clear_recv_filters(2);
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 4).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 5).unwrap().clone());
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), None);
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
    cluster.must_transfer_leader(region.get_id(), find_peer(&region, 1).unwrap().clone());
}
fn test_region_heartbeat_timestamp() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();

    // transfer leader to (2, 2) first to make address resolve happen early.
    cluster.must_transfer_leader(1, new_peer(2, 2));
    let reported_ts = cluster.pd_client.get_region_last_report_ts(1).unwrap();
    assert_ne!(reported_ts, PdInstant::zero());

    sleep(Duration::from_millis(1000));
    cluster.must_transfer_leader(1, new_peer(1, 1));
    sleep(Duration::from_millis(1000));
    cluster.must_transfer_leader(1, new_peer(2, 2));
    for _ in 0..100 {
        sleep_ms(100);
        let reported_ts_now = cluster.pd_client.get_region_last_report_ts(1).unwrap();
        if reported_ts_now > reported_ts {
            return;
        }
    }
    panic!("reported ts should be updated");
}
fn large_initial() {
    let _guard = subscribe();
    let mut server_crypto = server_crypto();
    server_crypto.alpn_protocols = vec![vec![0, 0, 0, 42]];
    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));

    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);
    let mut client_crypto = client_crypto();
    let protocols = (0..1000u32)
        .map(|x| x.to_be_bytes().to_vec())
        .collect::<Vec<_>>();
    client_crypto.alpn_protocols = protocols;
    let cfg = ClientConfig::new(Arc::new(client_crypto));
    let client_ch = pair.begin_connect(cfg);
    pair.drive();
    let server_ch = pair.server.assert_accept();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected { .. })
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Connected { .. })
    );
}
fn should_apply_different_formatting() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let biome_json = Path::new("biome.json");
    fs.insert(
        biome_json.into(),
        r#"{
        "formatter": {
            "indentStyle": "space"
        },
        "javascript": {
            "formatter": {
                "lineWidth": 320,
                "indentSize": 8
            }
        },
        "json": {
            "formatter": {
                "lineWidth": 80,
                "indentSize": 2
            }
        }
    }"#,
    );

    let code = r#"
{
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let json_file = Path::new("input.json");
    fs.insert(json_file.into(), code.as_bytes());

    let code = r#"
const a = {
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let js_file = Path::new("input.js");
    fs.insert(js_file.into(), code.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                "--write",
                json_file.as_os_str().to_str().unwrap(),
                js_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_apply_different_formatting",
        fs,
        console,
        result,
    ));
}
fn test_error_in_parent_template_location() {
    let result = render_tpl("error-location/error_in_parent.html");

    assert!(result.is_err());
    let errs = result.unwrap_err();
    assert_eq!(
        errs.to_string(),
        "Failed to render 'error-location/error_in_parent.html' (error happened in a parent template)"
    );
}
fn test_integer_key() {
    // map with integer keys
    let map = treemap!(
        1 => 2,
        -1 => 6,
    );
    let j = r#"{"-1":6,"1":2}"#;
    test_encode_ok(&[(&map, j)]);
    test_parse_ok(vec![(j, map)]);

    test_parse_err::<BTreeMap<i32, ()>>(&[
        (
            r#"{"x":null}"#,
            "invalid value: expected key to be a number in quotes at line 1 column 2",
        ),
        (
            r#"{" 123":null}"#,
            "invalid value: expected key to be a number in quotes at line 1 column 2",
        ),
        (r#"{"123 ":null}"#, "expected `\"` at line 1 column 6"),
    ]);

    let err = from_value::<BTreeMap<i32, ()>>(json!({" 123":null})).unwrap_err();
    assert_eq!(
        err.to_string(),
        "invalid value: expected key to be a number in quotes",
    );

    let err = from_value::<BTreeMap<i32, ()>>(json!({"123 ":null})).unwrap_err();
    assert_eq!(
        err.to_string(),
        "invalid value: expected key to be a number in quotes",
    );
}
fn test_trailing_comma_tuple() {
    assert!(from_str::<(i32, i32)>("(1,2)").is_ok());
    assert!(from_str::<(i32, i32)>("(1,2,)").is_ok());
    assert!(from_str::<(i32, i32)>("(1,2,,)").is_err());
}
fn test_initial_memory_limits_exceeded() -> Result<()> {
    let engine = Engine::default();
    let module = Module::new(&engine, r#"(module (memory (export "m") 11))"#)?;

    let mut store = Store::new(
        &engine,
        StoreLimitsBuilder::new()
            .memory_size(10 * WASM_PAGE_SIZE)
            .build(),
    );
    store.limiter(|s| s as &mut dyn ResourceLimiter);

    match Instance::new(&mut store, &module, &[]) {
        Ok(_) => unreachable!(),
        Err(e) => assert_eq!(
            e.to_string(),
            "memory minimum size of 11 pages exceeds memory limits"
        ),
    }

    match Memory::new(&mut store, MemoryType::new(25, None)) {
        Ok(_) => unreachable!(),
        Err(e) => assert_eq!(
            e.to_string(),
            "memory minimum size of 25 pages exceeds memory limits"
        ),
    }

    Ok(())
}
fn exit126_wasi_snapshot1() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit126_wasi_snapshot1.wat")?;
    let output = run_wasmtime_for_output(&[wasm.path().to_str().unwrap(), "-Ccache=n"], None)?;
    assert_eq!(output.status.code().unwrap(), 1);
    assert!(output.stdout.is_empty());
    assert!(String::from_utf8_lossy(&output.stderr).contains("invalid exit status"));
    Ok(())
}
fn write_flush_behaviour() {
    const SEND_ME_LEN: usize = 10;
    const BATCH_ME_LEN: usize = 11;
    const WRITE_BUFFER_SIZE: usize = 600;

    let mut ws = WebSocket::from_raw_socket(
        MockWrite::default(),
        tungstenite::protocol::Role::Server,
        Some(WebSocketConfig { write_buffer_size: WRITE_BUFFER_SIZE, ..<_>::default() }),
    );

    assert_eq!(ws.get_ref().written_bytes, 0);
    assert_eq!(ws.get_ref().write_count, 0);
    assert_eq!(ws.get_ref().flush_count, 0);

    // `send` writes & flushes immediately
    ws.send(Message::Text("Send me!".into())).unwrap();
    assert_eq!(ws.get_ref().written_bytes, SEND_ME_LEN);
    assert_eq!(ws.get_ref().write_count, 1);
    assert_eq!(ws.get_ref().flush_count, 1);

    // send a batch of messages
    for msg in (0..100).map(|_| Message::Text("Batch me!".into())) {
        ws.write(msg).unwrap();
    }
    // after 55 writes the out_buffer will exceed write_buffer_size=600
    // and so do a single underlying write (not flushing).
    assert_eq!(ws.get_ref().written_bytes, 55 * BATCH_ME_LEN + SEND_ME_LEN);
    assert_eq!(ws.get_ref().write_count, 2);
    assert_eq!(ws.get_ref().flush_count, 1);

    // flushing will perform a single write for the remaining out_buffer & flush.
    ws.flush().unwrap();
    assert_eq!(ws.get_ref().written_bytes, 100 * BATCH_ME_LEN + SEND_ME_LEN);
    assert_eq!(ws.get_ref().write_count, 3);
    assert_eq!(ws.get_ref().flush_count, 2);
}
fn test_concurrent_write_after_transfer_leader_invalidates_locks() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));
    let txn_ext = cluster
        .must_get_snapshot_of_region(1)
        .ext()
        .get_txn_ext()
        .unwrap()
        .clone();

    let lock = PessimisticLock {
        primary: b"key".to_vec().into_boxed_slice(),
        start_ts: 10.into(),
        ttl: 3000,
        for_update_ts: 20.into(),
        min_commit_ts: 30.into(),
        last_change_ts: 5.into(),
        versions_to_last_change: 3,
    };
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(Key::from_raw(b"key"), lock.clone())])
        .unwrap();

    let region = cluster.get_region(b"");
    let leader = region.get_peers()[0].clone();
    fail::cfg("invalidate_locks_before_transfer_leader", "pause").unwrap();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let mut mutation = pb::Mutation::default();
    mutation.set_op(Op::Put);
    mutation.key = b"key".to_vec();
    let mut req = PrewriteRequest::default();
    req.set_context(ctx);
    req.set_mutations(vec![mutation].into());
    // Set a different start_ts. It should fail because the memory lock is still
    // visible.
    req.set_start_version(20);
    req.set_primary_lock(b"key".to_vec());

    // Prewrite should not be blocked because we have downgrade the write lock
    // to a read lock, and it should return a locked error because it encounters
    // the memory lock.
    let resp = client.kv_prewrite(&req).unwrap();
    assert_eq!(
        resp.get_errors()[0].get_locked(),
        &lock.into_lock().into_lock_info(b"key".to_vec())
    );
}
fn packet_splitting_with_default_mtu() {
    let _guard = subscribe();

    // The payload needs to be split in 2 in order to be sent, because it is higher than the max MTU
    let payload = vec![42; 1300];

    let mut pair = Pair::default();
    let (client_ch, _) = pair.connect();
    pair.drive();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();

    pair.client_send(client_ch, s).write(&payload).unwrap();
    pair.client.drive(pair.time, pair.server.addr);
    assert_eq!(pair.client.outbound.len(), 2);

    pair.drive_client();
    assert_eq!(pair.server.inbound.len(), 2);
}
fn client_complete_io_for_handshake_eof() {
    let (mut client, _) = make_pair(KeyType::Rsa);
    let mut input = io::Cursor::new(Vec::new());

    assert!(client.is_handshaking());
    let err = client
        .complete_io(&mut input)
        .unwrap_err();
    assert_eq!(io::ErrorKind::UnexpectedEof, err.kind());
}
fn can_do_string_concat() {
    let mut context = Context::new();
    context.insert("a_string", "hello");
    context.insert("another_string", "xXx");
    context.insert("an_int", &1);
    context.insert("a_float", &3.18);

    let inputs = vec![
        (r#"{{ "hello" ~ " world" }}"#, "hello world"),
        (r#"{{ "hello" ~ 1 }}"#, "hello1"),
        (r#"{{ "hello" ~ 3.18 }}"#, "hello3.18"),
        (r#"{{ 3.18 ~ "hello"}}"#, "3.18hello"),
        (r#"{{ "hello" ~ get_string() }}"#, "helloHello"),
        (r#"{{ get_string() ~ "hello" }}"#, "Hellohello"),
        (r#"{{ get_string() ~ 3.18 }}"#, "Hello3.18"),
        (r#"{{ a_string ~ " world" }}"#, "hello world"),
        (r#"{{ a_string ~ ' world ' ~ another_string }}"#, "hello world xXx"),
        (r#"{{ a_string ~ another_string }}"#, "helloxXx"),
        (r#"{{ a_string ~ an_int }}"#, "hello1"),
        (r#"{{ a_string ~ a_float }}"#, "hello3.18"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_something() {
    let data = [];
    let mut rdr = Reader::init(data);
    if let Ok(m) = OpaqueMessage::read(&mut rdr) {
        let msg = match Message::try_from(m.into_plain_message()) {
            Ok(msg) => msg,
            Err(_) => return,
        };
        let enc = PlainMessage::from(msg)
            .into_unencrypted_opaque()
            .encode();
        assert_eq!(enc, data[..rdr.used()]);
    }
}
fn test_i64_min() {
    assert_eq!(
        std::i64::MIN,
        from_str(&to_string(&std::i64::MIN).unwrap()).unwrap()
    );
}
fn parse_color() {
  assert_eq!(
    hex_color("#2F14DF"),
    Ok((
      "",
      Color {
        red: 47,
        green: 20,
        blue: 223,
      }
    ))
  );
}
fn run() {
  let rpc_server = test_bitcoincore_rpc::spawn();

  let port = TcpListener::bind("127.0.0.1:0")
    .unwrap()
    .local_addr()
    .unwrap()
    .port();

  let builder = CommandBuilder::new(format!("server --address 127.0.0.1 --http-port {port}"))
    .rpc_server(&rpc_server);

  let mut command = builder.command();

  let mut child = command.spawn().unwrap();

  for attempt in 0.. {
    if let Ok(response) = reqwest::blocking::get(format!("http://localhost:{port}/status")) {
      if response.status() == 200 {
        assert_eq!(response.text().unwrap(), "OK");
        break;
      }
    }

    if attempt == 100 {
      panic!("Server did not respond to status check",);
    }

    thread::sleep(Duration::from_millis(50));
  }

  child.kill().unwrap();
}
fn write_batch_delete_range_basic() {
    let db = default_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();

    let mut wb = db.engine.write_batch();

    wb.delete_range(b"b", b"e").unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());

    let db = multi_batch_write_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();
    db.engine.put(b"e", b"").unwrap();

    let mut wb = db.engine.write_batch_with_cap(1024);
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }

    wb.delete_range(b"b", b"e").unwrap();
    wb.delete_range(&32_usize.to_be_bytes(), &128_usize.to_be_bytes())
        .unwrap();
    wb.write().unwrap();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_none());
    assert!(db.engine.get_value(b"c").unwrap().is_none());
    assert!(db.engine.get_value(b"d").unwrap().is_none());
    assert!(db.engine.get_value(b"e").unwrap().is_some());
    for i in 0..32_usize {
        let x = i.to_be_bytes();
        assert!(db.engine.get_value(&x).unwrap().is_some());
    }
    for i in 32..128_usize {
        let x = i.to_be_bytes();
        assert!(db.engine.get_value(&x).unwrap().is_none());
    }
    for i in 128..256_usize {
        let x = i.to_be_bytes();
        assert!(db.engine.get_value(&x).unwrap().is_some());
    }
}
fn test_datetimeformat_time_rs() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATETIME_FORMAT", "[hour]:[minute]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("d|datetimeformat(format=format)")
        .unwrap();

    let d = time::OffsetDateTime::from_unix_timestamp(1687624642).unwrap();
    assert_eq!(
        expr.eval(context!(d, format => "short"))
            .unwrap()
            .to_string(),
        "2023-06-24 18:37"
    );
}
fn test_terse_normal_format() {
    // note: contains birth/creation date which increases test fragility
    // * results may vary due to built-in `stat` limitations as well as linux kernel and rust version capability variations
    let args = ["-t", "/"];
    let ts = TestScenario::new(util_name!());
    let actual = ts.ucmd().args(&args).succeeds().stdout_move_str();
    let expect = unwrap_or_return!(expected_result(&ts, &args)).stdout_move_str();
    println!("actual: {actual:?}");
    println!("expect: {expect:?}");
    let v_actual: Vec<&str> = actual.trim().split(' ').collect();
    let mut v_expect: Vec<&str> = expect.trim().split(' ').collect();
    assert!(!v_expect.is_empty());

    // uu_stat does not support selinux
    if v_actual.len() == v_expect.len() - 1 && v_expect[v_expect.len() - 1].contains(':') {
        // assume last element contains: `SELinux security context string`
        v_expect.pop();
    }

    // * allow for inequality if `stat` (aka, expect) returns "0" (unknown value)
    assert!(
        expect == "0"
            || expect == "0\n"
            || v_actual
                .iter()
                .zip(v_expect.iter())
                .all(|(a, e)| a == e || *e == "0" || *e == "0\n")
    );
}
fn mul_test() {
    // Normalized (64-bit mantissa)
    let a = ExtendedFloat {
        mant: 13164036458569648128,
        exp: -213,
    };
    let b = ExtendedFloat {
        mant: 9223372036854775808,
        exp: -62,
    };
    let c = ExtendedFloat {
        mant: 6582018229284824064,
        exp: -211,
    };
    check_mul(a, b, c);

    // Check with integers
    // 64-bit mantissa
    let mut a = ExtendedFloat { mant: 10, exp: 0 };
    let mut b = ExtendedFloat { mant: 10, exp: 0 };
    a.normalize();
    b.normalize();
    assert_eq!(a.mul(&b).into_float::<f64>(), 100.0);

    // Check both values need high bits set.
    let a = ExtendedFloat {
        mant: 1 << 32,
        exp: -31,
    };
    let b = ExtendedFloat {
        mant: 1 << 32,
        exp: -31,
    };
    assert_eq!(a.mul(&b).into_float::<f64>(), 4.0);

    // Check both values need high bits set.
    let a = ExtendedFloat {
        mant: 10 << 31,
        exp: -31,
    };
    let b = ExtendedFloat {
        mant: 10 << 31,
        exp: -31,
    };
    assert_eq!(a.mul(&b).into_float::<f64>(), 100.0);
}
fn test_cjk_compat_variants() {
    // These codepoints have singleton decompositions in the canonical
    // decomposition, and can use standardized variations.
    let s = "\u{2f999}\u{2f8a6}";

    // These codepoints have canonical decompositions.
    let mut nfd_iter = s.chars().nfd();
    assert_eq!(nfd_iter.next(), Some('\u{831d}'));
    assert_eq!(nfd_iter.next(), Some('\u{6148}'));
    assert_eq!(nfd_iter.next(), None);

    let mut nfkd_iter = s.chars().nfkd();
    assert_eq!(nfkd_iter.next(), Some('\u{831d}'));
    assert_eq!(nfkd_iter.next(), Some('\u{6148}'));
    assert_eq!(nfkd_iter.next(), None);

    let mut nfc_iter = s.chars().nfc();
    assert_eq!(nfc_iter.next(), Some('\u{831d}'));
    assert_eq!(nfc_iter.next(), Some('\u{6148}'));
    assert_eq!(nfc_iter.next(), None);

    let mut nfkc_iter = s.chars().nfkc();
    assert_eq!(nfkc_iter.next(), Some('\u{831d}'));
    assert_eq!(nfkc_iter.next(), Some('\u{6148}'));
    assert_eq!(nfkc_iter.next(), None);

    // However they also have standardized variants.
    let mut var_iter = s.chars().cjk_compat_variants();
    assert_eq!(var_iter.next(), Some('\u{831d}'));
    assert_eq!(var_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_iter.next(), Some('\u{6148}'));
    assert_eq!(var_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_iter.next(), None);

    // The standardized variants are normalization-stable.
    let mut var_nfc_iter = s.chars().cjk_compat_variants().nfc();
    assert_eq!(var_nfc_iter.next(), Some('\u{831d}'));
    assert_eq!(var_nfc_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfc_iter.next(), Some('\u{6148}'));
    assert_eq!(var_nfc_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfc_iter.next(), None);

    let mut var_nfd_iter = s.chars().cjk_compat_variants().nfd();
    assert_eq!(var_nfd_iter.next(), Some('\u{831d}'));
    assert_eq!(var_nfd_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfd_iter.next(), Some('\u{6148}'));
    assert_eq!(var_nfd_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfd_iter.next(), None);

    let mut var_nfkc_iter = s.chars().cjk_compat_variants().nfkc();
    assert_eq!(var_nfkc_iter.next(), Some('\u{831d}'));
    assert_eq!(var_nfkc_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfkc_iter.next(), Some('\u{6148}'));
    assert_eq!(var_nfkc_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfkc_iter.next(), None);

    let mut var_nfkd_iter = s.chars().cjk_compat_variants().nfkd();
    assert_eq!(var_nfkd_iter.next(), Some('\u{831d}'));
    assert_eq!(var_nfkd_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfkd_iter.next(), Some('\u{6148}'));
    assert_eq!(var_nfkd_iter.next(), Some('\u{fe00}'));
    assert_eq!(var_nfkd_iter.next(), None);
}
fn test_struct_enum_fields() {
    assert_eq!(
        ron::from_str::<TestEnum>("StructVariant(a: true, b: 'b', c: -42, d: \"gotcha\")"),
        Err(SpannedError {
            code: Error::NoSuchStructField {
                expected: &["a", "b", "c"],
                found: String::from("d"),
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 41 },
        })
    );

    assert_eq!(
        ron::from_str::<TestEnum>("StructVariant(a: true, c: -42)"),
        Err(SpannedError {
            code: Error::MissingStructField {
                field: "b",
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 30 },
        })
    );

    assert_eq!(
        ron::from_str::<TestEnum>("StructVariant(a: true, b: 'b', a: false, c: -42)"),
        Err(SpannedError {
            code: Error::DuplicateStructField {
                field: "a",
                outer: Some(String::from("StructVariant")),
            },
            position: Position { line: 1, col: 33 },
        })
    );
}
fn test_error_render_field_unknown() {
    let result = render_tpl("field_unknown.html");

    assert!(result.is_err());
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Variable `hey` not found in context while rendering \'field_unknown.html\'"
    );
}
fn test_notrunc_does_not_truncate() {
    // Set up test if needed (eg. after failure)
    let fname = "this-file-exists-notrunc.txt";
    let fpath = fixture_path!(fname);
    match fpath.metadata() {
        Ok(m) if m.len() == 256 => {}
        _ => build_test_file!(&fpath, &build_ascii_block(256)),
    }

    let (fix, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["status=none", "conv=notrunc", of!(&fname), "if=null.txt"])
        .run()
        .no_stdout()
        .no_stderr()
        .success();

    assert_eq!(256, fix.metadata(fname).len());
}
async fn request_stream_id_overflows() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let h2 = async move {
        let (mut client, mut h2) = client::Builder::new()
            .initial_stream_id(::std::u32::MAX >> 1)
            .handshake::<_, Bytes>(io)
            .await
            .unwrap();
        let request = Request::builder()
            .method(Method::GET)
            .uri("https://example.com/")
            .body(())
            .unwrap();

        // first request is allowed
        let (response, _) = client.send_request(request, true).unwrap();
        let _x = h2.drive(response).await.unwrap();

        let request = Request::builder()
            .method(Method::GET)
            .uri("https://example.com/")
            .body(())
            .unwrap();
        // second cannot use the next stream id, it's over
        let poll_err = poll_fn(|cx| client.poll_ready(cx)).await.unwrap_err();
        assert_eq!(poll_err.to_string(), "user error: stream ID overflowed");

        let err = client.send_request(request, true).unwrap_err();
        assert_eq!(err.to_string(), "user error: stream ID overflowed");

        h2.await.unwrap();
    };

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_default_settings!(settings);
        srv.recv_frame(
            frames::headers(::std::u32::MAX >> 1)
                .request("GET", "https://example.com/")
                .eos(),
        )
        .await;
        srv.send_frame(frames::headers(::std::u32::MAX >> 1).response(200).eos())
            .await;
        idle_ms(10).await;
    };

    join(srv, h2).await;
}
fn error_location_base_template() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("parent", "Hello {{ greeting + 1}} {% block bob %}{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}Hey{% endblock bob %}"),
    ])
    .unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(
        result.unwrap_err().to_string(),
        "Failed to render \'child\' (error happened in 'parent')."
    );
}
async fn configure_max_frame_size() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let h2 = async move {
        let (mut client, h2) = client::Builder::new()
            .max_frame_size(16_384 * 2)
            .handshake::<_, Bytes>(io)
            .await
            .expect("handshake");

        let req = async move {
            let resp = client.get("https://example.com/").await.expect("response");
            assert_eq!(resp.status(), StatusCode::OK);
            let body = resp.into_parts().1;
            let buf = util::concat(body).await.expect("body");
            assert_eq!(buf.len(), 16_385);
        };

        join(async move { h2.await.expect("client") }, req).await;
    };
    // a good peer
    srv.codec_mut().set_max_send_frame_size(16_384 * 2);

    let srv = async move {
        let _ = srv.assert_client_handshake().await;
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://example.com/")
                .eos(),
        )
        .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        srv.send_frame(frames::data(1, vec![0; 16_385]).eos()).await;
    };
    join(srv, h2).await;
}
fn test_parse_request_failed_2() {
    // It should not even take any snapshots when parse failed.
    let product = ProductTable::new();
    let (_, endpoint) = init_with_data(&product, &[]);
    let req = DagSelect::from(&product).build();

    fail::cfg("rockskv_async_snapshot", "panic").unwrap();
    fail::cfg("coprocessor_parse_request", "return()").unwrap();
    let resp = handle_request(&endpoint, req);

    assert!(resp.get_other_error().contains("unsupported tp"));
}
fn test_raw_value_in_map_key() {
    #[derive(RefCast)]
    #[repr(transparent)]
    struct RawMapKey(RawValue);

    impl<'de> Deserialize<'de> for &'de RawMapKey {
        fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
        where
            D: serde::Deserializer<'de>,
        {
            let raw_value = <&RawValue>::deserialize(deserializer)?;
            Ok(RawMapKey::ref_cast(raw_value))
        }
    }

    impl PartialEq for RawMapKey {
        fn eq(&self, other: &Self) -> bool {
            self.0.get() == other.0.get()
        }
    }

    impl Eq for RawMapKey {}

    impl Hash for RawMapKey {
        fn hash<H: Hasher>(&self, hasher: &mut H) {
            self.0.get().hash(hasher);
        }
    }

    let map_from_str: HashMap<&RawMapKey, &RawValue> =
        serde_json::from_str(r#" {"\\k":"\\v"} "#).unwrap();
    let (map_k, map_v) = map_from_str.into_iter().next().unwrap();
    assert_eq!("\"\\\\k\"", map_k.0.get());
    assert_eq!("\"\\\\v\"", map_v.get());
}
fn default_filter_works() {
    let mut context = Context::new();
    let i: Option<usize> = None;
    context.insert("existing", "hello");
    context.insert("null", &i);

    let inputs = vec![
        (r#"{{ existing | default(value="hey") }}"#, "hello"),
        (r#"{{ val | default(value=1) }}"#, "1"),
        (r#"{{ val | default(value="hey") | capitalize }}"#, "Hey"),
        (r#"{{ obj.val | default(value="hey") | capitalize }}"#, "Hey"),
        (r#"{{ obj.val | default(value="hey") | capitalize }}"#, "Hey"),
        (r#"{{ not admin | default(value=false) }}"#, "true"),
        (r#"{{ not admin | default(value=true) }}"#, "false"),
        (r#"{{ null | default(value=true) }}"#, "true"),
        (r#"{{ null | default(value="hey") | capitalize }}"#, "Hey"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_vec_primitive() {
    use pnet_macros::packet;
    use pnet_macros_support::types::u32be;

    #[packet]
    pub struct Test {
        #[length = "4"]
        pub v: Vec<u32be>,
        #[payload]
        #[length = "0"]
        pub payload: Vec<u8>,
    }

    let res = TestPacket::new(&[0x00, 0x00, 0x00, 0x00]).unwrap();
    assert_eq!(res.get_v(), vec![0]);
}
fn issue299() -> Result<(), Error> {
    let xml = r#"
<?xml version="1.0" encoding="utf8"?>
<MICEX_DOC xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance">
  <SECURITY SecurityId="PLZL" ISIN="RU000A0JNAA8" SecShortName="Short Name" PriceType="CASH">
    <RECORDS RecNo="1" TradeNo="1111" TradeDate="2021-07-08" TradeTime="15:00:00" BuySell="S" SettleCode="Y1Dt" Decimals="3" Price="13057.034" Quantity="766" Value="10001688.29" AccInt="0" Amount="10001688.29" Balance="766" TrdAccId="X0011" ClientDetails="2222" CPFirmId="3333" CPFirmShortName="Firm Short Name" Price2="13057.034" RepoPart="2" ReportTime="16:53:27" SettleTime="17:47:06" ClientCode="4444" DueDate="2021-07-09" EarlySettleStatus="N" RepoRate="5.45" RateType="FIX"/>
  </SECURITY>
</MICEX_DOC>
"#;
    let mut reader = Reader::from_str(xml);
    loop {
        match reader.read_event()? {
            Event::Start(e) | Event::Empty(e) => {
                let attr_count = match e.name().as_ref() {
                    b"MICEX_DOC" => 1,
                    b"SECURITY" => 4,
                    b"RECORDS" => 26,
                    _ => unreachable!(),
                };
                assert_eq!(
                    attr_count,
                    e.attributes().filter(Result::is_ok).count(),
                    "mismatch att count on '{:?}'",
                    reader.decoder().decode(e.name().as_ref())
                );
            }
            Event::Eof => break,
            _ => (),
        }
    }
    Ok(())
}
fn dynamic_duplicate_works() {
    let (mut store, duplicate, duplicate_dyn) = setup_duplicate();
    for input in 0..10 {
        let params = [Value::I32(input)];
        let expected = [Value::I32(input), Value::I32(input)];
        let mut results = [Value::I32(0), Value::I32(0)];
        // Call to Func with statically typed closure.
        duplicate.call(&mut store, &params, &mut results).unwrap();
        assert_eq!(results[0].i32(), expected[0].i32());
        assert_eq!(results[1].i32(), expected[1].i32());
        // Reset result before execution.
        results = [Value::I32(0), Value::I32(0)];
        // Call to Func with dynamically typed closure.
        duplicate_dyn
            .call(&mut store, &params, &mut results)
            .unwrap();
        assert_eq!(results[0].i32(), expected[0].i32());
        assert_eq!(results[1].i32(), expected[1].i32());
    }
}
fn no_dirty_reads() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(STR_TABLE).unwrap();
        table.insert("hello", "world").unwrap();
    }

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE);
    assert!(table.is_err());
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(STR_TABLE).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
}
fn does_not_format_if_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_DISABLED_FORMATTER.as_bytes());

    console
        .in_buffer
        .push("function f() {return{}}".to_string());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--stdin-file-path"), ("mock.js")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let message = console
        .out_buffer
        .get(0)
        .expect("Console should have written a message");

    let content = markup_to_string(markup! {
        {message.content}
    });

    assert_eq!(content, "function f() {return{}}".to_string());

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_format_if_disabled",
        fs,
        console,
        result,
    ));
}
fn test_mv_multiple_folders() {
    let (at, mut ucmd) = at_and_ucmd!();
    let target_dir = "test_mv_multiple_dirs_dir";
    let dir_a = "test_mv_multiple_dir_a";
    let dir_b = "test_mv_multiple_dir_b";

    at.mkdir(target_dir);
    at.mkdir(dir_a);
    at.mkdir(dir_b);

    ucmd.arg(dir_a)
        .arg(dir_b)
        .arg(target_dir)
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists(&format!("{target_dir}/{dir_a}")));
    assert!(at.dir_exists(&format!("{target_dir}/{dir_b}")));
}
fn test_something() {
    let data = [];
    if data.len() < 50 || data.len() > 300 {
        return;
    }
    let (split_byte, data) = data.split_first().unwrap();
    let (kmer_byte, data) = data.split_first().unwrap();
    let (window_byte, data) = data.split_first().unwrap();
    let (match_score_byte, data) = data.split_first().unwrap();
    let (mismatch_score_byte, data) = data.split_first().unwrap();
    let (gap_open_byte, data) = data.split_first().unwrap();
    let (gap_extend_byte, data) = data.split_first().unwrap();
    let (xclip_prefix_byte, data) = data.split_first().unwrap();
    let (xclip_suffix_byte, data) = data.split_first().unwrap();
    let (yclip_prefix_byte, data) = data.split_first().unwrap();
    let (yclip_suffix_byte, data) = data.split_first().unwrap();
    let alphabets = b"ACGT";
    let v: Vec<_> = data
        .iter()
        .map(|i| alphabets[(*i as usize) % alphabets.len()])
        .collect();
    let kmer_len: usize = 5 + (*kmer_byte as usize) % 10;
    let window_size: usize = 5 + (*window_byte as usize) % 10;
    let split_pos: usize = min(data.len() - 1, max(*split_byte as usize, 1));
    let match_score = 1 + (*match_score_byte as i32) % 5;
    let mismatch_score = -((*mismatch_score_byte as i32) % 10);
    let gap_open = -((*gap_open_byte as i32) % 20);
    let gap_extend = -((*gap_extend_byte as i32) % 10);
    let (x, y) = v.split_at(split_pos);
    println!(
        "x: {}, y: {}, k: {}, w: {}, scoring ({}, {}, {}, {})",
        String::from_utf8(x.to_vec()).unwrap(),
        String::from_utf8(y.to_vec()).unwrap(),
        kmer_len,
        window_size,
        gap_open,
        gap_extend,
        match_score,
        mismatch_score
    );
    let base_score = Scoring::from_scores(gap_open, gap_extend, match_score, mismatch_score);
    {
        println!(
            "Clip scores ({}, {}, {}, {})",
            xclip_prefix_byte, xclip_suffix_byte, yclip_prefix_byte, yclip_suffix_byte
        );
        let scoring = Scoring {
            xclip_prefix: -(*xclip_prefix_byte as i32),
            xclip_suffix: -(*xclip_suffix_byte as i32),
            yclip_prefix: -(*yclip_prefix_byte as i32),
            yclip_suffix: -(*yclip_suffix_byte as i32),
            ..base_score.clone()
        };
        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);
        let b_alignment = b_aligner.custom(x, y);
        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));
        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());
        let f_alignment = f_aligner.custom(x, y);
        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));
        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());
        assert_eq!(band_all_alignment.score, f_alignment.score);
    }
    {
        let scoring = Scoring {
            xclip_prefix: 0,
            xclip_suffix: 0,
            yclip_suffix: 0,
            ..base_score.clone()
        };
        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);
        let b_alignment = b_aligner.custom(x, y);
        assert_eq!(b_alignment.ystart, 0);
        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));
        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());
        let f_alignment = f_aligner.custom(x, y);
        assert_eq!(f_alignment.ystart, 0);
        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));
        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());
        assert_eq!(band_all_alignment.score, f_alignment.score);
    }
    {
        let scoring = Scoring {
            xclip_prefix: 0,
            xclip_suffix: 0,
            yclip_prefix: 0,
            ..base_score.clone()
        };
        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);
        let b_alignment = b_aligner.custom(x, y);
        assert_eq!(b_alignment.yend, b_alignment.ylen);
        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));
        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());
        let f_alignment = f_aligner.custom(x, y);
        assert_eq!(f_alignment.yend, f_alignment.ylen);
        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));
        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());
        assert_eq!(band_all_alignment.score, f_alignment.score);
    }
    {
        let scoring = Scoring {
            xclip_suffix: 0,
            yclip_prefix: 0,
            yclip_suffix: 0,
            ..base_score.clone()
        };
        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);
        let b_alignment = b_aligner.custom(x, y);
        assert_eq!(b_alignment.xstart, 0);
        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));
        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());
        let f_alignment = f_aligner.custom(x, y);
        assert_eq!(f_alignment.xstart, 0);
        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));
        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());
        assert_eq!(band_all_alignment.score, f_alignment.score);
    }
    {
        let scoring = Scoring {
            xclip_prefix: 0,
            yclip_prefix: 0,
            yclip_suffix: 0,
            ..base_score.clone()
        };
        let mut b_aligner = banded::Aligner::with_scoring(scoring.clone(), kmer_len, window_size);
        let b_alignment = b_aligner.custom(x, y);
        assert_eq!(b_alignment.xend, b_alignment.xlen);
        assert!(validate_alignment_score(&b_alignment, x, y, &scoring));
        let mut f_aligner = pairwise::Aligner::with_scoring(scoring.clone());
        let f_alignment = f_aligner.custom(x, y);
        assert_eq!(f_alignment.xend, f_alignment.xlen);
        assert!(validate_alignment_score(&f_alignment, x, y, &scoring));
        let band_all_alignment = b_aligner.custom_with_matches(x, y, &Vec::new());
        assert_eq!(band_all_alignment.score, f_alignment.score);
    }
    {
        let mut aligner = banded::Aligner::with_scoring(base_score.clone(), kmer_len, window_size);
        let alignment = aligner.local(x, y);
        assert!(alignment.score >= 0);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
        let alignment = aligner.semiglobal(x, y);
        assert_eq!(alignment.xstart, 0);
        assert_eq!(alignment.xend, alignment.xlen);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
        let alignment = aligner.global(x, y);
        assert_eq!(alignment.xstart, 0);
        assert_eq!(alignment.xend, alignment.xlen);
        assert_eq!(alignment.ystart, 0);
        assert_eq!(alignment.yend, alignment.ylen);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
    }
    {
        let mut aligner = pairwise::Aligner::with_scoring(base_score.clone());
        let alignment = aligner.local(x, y);
        assert!(alignment.score >= 0);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
        let alignment = aligner.semiglobal(x, y);
        assert_eq!(alignment.xstart, 0);
        assert_eq!(alignment.xend, alignment.xlen);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
        let alignment = aligner.global(x, y);
        assert_eq!(alignment.xstart, 0);
        assert_eq!(alignment.xend, alignment.xlen);
        assert_eq!(alignment.ystart, 0);
        assert_eq!(alignment.yend, alignment.ylen);
        assert!(validate_alignment_score(&alignment, x, y, &base_score));
    }
}
fn ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), FORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");
}
fn inscription_content() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  rpc_server.mine_blocks(1);

  let (inscription, _) = inscribe(&rpc_server);

  rpc_server.mine_blocks(1);

  let response =
    TestServer::spawn_with_args(&rpc_server, &[]).request(format!("/content/{inscription}"));

  assert_eq!(response.status(), StatusCode::OK);
  assert_eq!(
    response.headers().get("content-type").unwrap(),
    "text/plain;charset=utf-8"
  );
  assert_eq!(
    response
      .headers()
      .get_all("content-security-policy")
      .into_iter()
      .collect::<Vec<&http::HeaderValue>>(),
    &[
      "default-src 'self' 'unsafe-eval' 'unsafe-inline' data: blob:",
      "default-src *:*/content/ *:*/blockheight *:*/blockhash *:*/blockhash/ *:*/blocktime *:*/r/ 'unsafe-eval' 'unsafe-inline' data: blob:",
    ]
  );
  assert_eq!(response.bytes().unwrap(), "FOO");
}
async fn test_multiple_cname_additionals() {
    let example = create_example();
    let origin = example.origin().clone();

    let mut catalog: Catalog = Catalog::new();
    catalog.upsert(origin, Box::new(Arc::new(example)));

    let mut question: Message = Message::new();

    let mut query: Query = Query::new();
    query.set_name(Name::from_str("alias2.example.com.").unwrap());
    query.set_query_type(RecordType::A);

    question.add_query(query);

    // temp request
    let question_bytes = question.to_bytes().unwrap();
    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();
    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);

    let response_handler = TestResponseHandler::new();
    catalog
        .lookup(&question_req, None, response_handler.clone())
        .await;
    let result = response_handler.into_message().await;

    assert_eq!(result.message_type(), MessageType::Response);
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let answers: &[Record] = result.answers();
    assert_eq!(answers.len(), 1);
    assert_eq!(answers.first().unwrap().record_type(), RecordType::CNAME);
    assert_eq!(
        answers.first().unwrap().data().unwrap(),
        &RData::CNAME(CNAME(Name::from_str("alias.example.com.").unwrap()))
    );

    // we should have the intermediate record
    let additionals: &[Record] = result.additionals();
    assert!(!additionals.is_empty());
    assert_eq!(
        additionals.first().unwrap().record_type(),
        RecordType::CNAME
    );
    assert_eq!(
        additionals.first().unwrap().data().unwrap(),
        &RData::CNAME(CNAME(Name::from_str("www.example.com.").unwrap()))
    );

    // final record should be the actual
    let additionals: &[Record] = result.additionals();
    assert!(!additionals.is_empty());
    assert_eq!(additionals.last().unwrap().record_type(), RecordType::A);
    assert_eq!(
        additionals.last().unwrap().data().unwrap(),
        &RData::A(A::new(93, 184, 216, 34))
    );
}
fn parse_select_having() {
    let sql = "SELECT foo FROM bar GROUP BY foo HAVING COUNT(*) > 1";
    let select = verified_only_select(sql);
    assert_eq!(
        Some(Expr::BinaryOp {
            left: Box::new(Expr::Function(Function {
                name: ObjectName(vec![Ident::new("COUNT")]),
                args: vec![FunctionArg::Unnamed(FunctionArgExpr::Wildcard)],
                null_treatment: None,
                filter: None,
                over: None,
                distinct: false,
                special: false,
                order_by: vec![],
            })),
            op: BinaryOperator::Gt,
            right: Box::new(Expr::Value(number("1"))),
        }),
        select.having
    );

    let sql = "SELECT 'foo' HAVING 1 = 1";
    let select = verified_only_select(sql);
    assert!(select.having.is_some());
}
fn read_lines_test() {
  let res = Ok(("", vec!["Duck", "Dog", "Cow"]));

  assert_eq!(read_lines("Duck\nDog\nCow\n"), res);
  assert_eq!(read_lines("Duck\nDog\nCow"), res);
}
fn render_tests() {
    let mut context = Context::new();
    context.insert("is_true", &true);
    context.insert("is_false", &false);
    context.insert("age", &18);
    context.insert("name", &"john");
    let mut map = HashMap::new();
    map.insert(0, 1);
    context.insert("map", &map);
    context.insert("numbers", &vec![1, 2, 3]);
    context.insert::<Option<usize>, _>("maybe", &None);

    let inputs = vec![
        ("{% if is_true is defined %}Admin{% endif %}", "Admin"),
        ("{% if hello is undefined %}Admin{% endif %}", "Admin"),
        ("{% if name is string %}Admin{% endif %}", "Admin"),
        ("{% if age is number %}Admin{% endif %}", "Admin"),
        ("{% if age is even %}Admin{% endif %}", "Admin"),
        ("{% if age is odd %}Admin{%else%}even{% endif %}", "even"),
        ("{% if age is divisibleby(2) %}Admin{% endif %}", "Admin"),
        ("{% if numbers is iterable %}Admin{% endif %}", "Admin"),
        ("{% if map is iterable %}Admin{% endif %}", "Admin"),
        ("{% if map is object %}Admin{% endif %}", "Admin"),
        ("{% if name is starting_with('j') %}Admin{% endif %}", "Admin"),
        ("{% if name is ending_with('n') %}Admin{% endif %}", "Admin"),
        ("{% if numbers is containing(2) %}Admin{% endif %}", "Admin"),
        ("{% if name is matching('^j.*') %}Admin{% endif %}", "Admin"),
        ("{% if maybe is defined %}Admin{% endif %}", "Admin"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn macro_can_load_macro_from_macro_files() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("submacros", "{% macro emma() %}Emma{% endmacro emma %}"),
        ("macros", "{% import \"submacros\" as submacros %}{% macro hommage() %}{{ submacros::emma() }} was an amazing person!{% endmacro hommage %}"),
        ("parent", "{% block main %}Someone was a terrible person!{% endblock main %} Don't you think?"),
        ("child", "{% extends \"parent\" %}{% import \"macros\" as macros %}{% block main %}{{ macros::hommage() }}{% endblock main %}")
    ]).unwrap();

    let result = tera.render("child", &Context::new());
    //println!("{:#?}", result);
    assert_eq!(result.unwrap(), "Emma was an amazing person! Don't you think?".to_string());
}
fn apply_ok() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_ok",
        fs,
        console,
        result,
    ));
}
fn test_exhaustive() {
    const BATCH_SIZE: u32 = 1_000_000;
    let counter = Arc::new(AtomicUsize::new(0));
    let finished = Arc::new(AtomicUsize::new(0));

    let mut workers = Vec::new();
    for _ in 0..num_cpus::get() {
        let counter = counter.clone();
        let finished = finished.clone();
        workers.push(thread::spawn(move || loop {
            let batch = counter.fetch_add(1, Ordering::Relaxed) as u32;
            if batch > u32::max_value() / BATCH_SIZE {
                return;
            }

            let min = batch * BATCH_SIZE;
            let max = if batch == u32::max_value() / BATCH_SIZE {
                u32::max_value()
            } else {
                min + BATCH_SIZE - 1
            };

            let mut bytes = [0u8; 24];
            let mut buffer = ryu::Buffer::new();
            for u in min..=max {
                let f = f32::from_bits(u);
                if !f.is_finite() {
                    continue;
                }
                let n = unsafe { ryu::raw::format32(f, &mut bytes[0]) };
                assert_eq!(Ok(Ok(f)), str::from_utf8(&bytes[..n]).map(str::parse));
                assert_eq!(Ok(f), buffer.format_finite(f).parse());
            }

            let increment = (max - min + 1) as usize;
            let update = finished.fetch_add(increment, Ordering::Relaxed);
            println!("{}", update + increment);
        }));
    }

    for w in workers {
        w.join().unwrap();
    }
}
fn test_crate_path() {
    assert_vis_parse!(
        "pub(crate::A, crate::B)",
        Ok(Visibility::Public(_)) + "(crate::A, crate::B)"
    );
}
fn test_node_failed_merge_before_succeed_merge() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.raft_store.merge_max_log_gap = 30;
    cluster.cfg.raft_store.store_batch_system.max_batch_size = Some(1);
    cluster.cfg.raft_store.store_batch_system.pool_size = 2;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    for i in 0..10 {
        cluster.must_put(format!("k{}", i).as_bytes(), b"v1");
    }
    let region = pd_client.get_region(b"k1").unwrap();
    cluster.must_split(&region, b"k5");

    let left = pd_client.get_region(b"k1").unwrap();
    let mut right = pd_client.get_region(b"k5").unwrap();
    let left_peer_1 = find_peer(&left, 1).cloned().unwrap();
    cluster.must_transfer_leader(left.get_id(), left_peer_1);

    let left_peer_3 = find_peer(&left, 3).cloned().unwrap();
    assert_eq!(left_peer_3.get_id(), 1003);

    // Prevent sched_merge_tick to propose CommitMerge
    let schedule_merge_fp = "on_schedule_merge";
    fail::cfg(schedule_merge_fp, "return").unwrap();

    // To minimize peers log gap for merging
    cluster.must_put(b"k11", b"v2");
    must_get_equal(&cluster.get_engine(2), b"k11", b"v2");
    must_get_equal(&cluster.get_engine(3), b"k11", b"v2");
    // Make peer 1003 can't receive PrepareMerge and RollbackMerge log
    cluster.add_send_filter(IsolationFilterFactory::new(3));

    cluster.must_try_merge(left.get_id(), right.get_id());

    // Change right region's epoch to make this merge failed
    cluster.must_split(&right, b"k8");
    fail::remove(schedule_merge_fp);
    // Wait for left region to rollback merge
    cluster.must_put(b"k12", b"v2");
    // Prevent apply fsm applying the `PrepareMerge` and `RollbackMerge` log after
    // cleaning send filter.
    let before_handle_normal_1003_fp = "before_handle_normal_1003";
    fail::cfg(before_handle_normal_1003_fp, "return").unwrap();
    cluster.clear_send_filters();

    right = pd_client.get_region(b"k5").unwrap();
    let right_peer_1 = find_peer(&right, 1).cloned().unwrap();
    cluster.must_transfer_leader(right.get_id(), right_peer_1);
    // Add some data for checking data integrity check at a later time
    for i in 0..5 {
        cluster.must_put(format!("k2{}", i).as_bytes(), b"v3");
    }
    // Do a really succeed merge
    pd_client.must_merge(left.get_id(), right.get_id());
    // Wait right region to send CatchUpLogs to left region.
    sleep_ms(100);
    // After executing CatchUpLogs in source peer fsm, the committed log will send
    // to apply fsm in the end of this batch. So even the first
    // `on_ready_prepare_merge` is executed after CatchUplogs, the latter
    // committed logs is still sent to apply fsm if CatchUpLogs and
    // `on_ready_prepare_merge` is in different batch.
    //
    // In this case, the data is complete because the wrong up-to-date msg from the
    // first `on_ready_prepare_merge` is sent after all committed log.
    // Sleep a while to wait apply fsm to send `on_ready_prepare_merge` to peer fsm.
    let after_send_to_apply_1003_fp = "after_send_to_apply_1003";
    fail::cfg(after_send_to_apply_1003_fp, "sleep(300)").unwrap();

    fail::remove(before_handle_normal_1003_fp);
    // Wait `after_send_to_apply_1003` timeout
    sleep_ms(300);
    fail::remove(after_send_to_apply_1003_fp);
    // Check the data integrity
    for i in 0..5 {
        must_get_equal(&cluster.get_engine(3), format!("k2{}", i).as_bytes(), b"v3");
    }
}
fn test_tuple_multi_index() {
    let expected = snapshot!("tuple.0.0" as Expr, @r###"
    Expr::Field {
        base: Expr::Field {
            base: Expr::Path {
                path: Path {
                    segments: [
                        PathSegment {
                            ident: "tuple",
                        },
                    ],
                },
            },
            member: Member::Unnamed(Index {
                index: 0,
            }),
        },
        member: Member::Unnamed(Index {
            index: 0,
        }),
    }
    "###);

    for &input in &[
        "tuple .0.0",
        "tuple. 0.0",
        "tuple.0 .0",
        "tuple.0. 0",
        "tuple . 0 . 0",
    ] {
        assert_eq!(expected, syn::parse_str(input).unwrap());
    }

    for tokens in [
        quote!(tuple.0.0),
        quote!(tuple .0.0),
        quote!(tuple. 0.0),
        quote!(tuple.0 .0),
        quote!(tuple.0. 0),
        quote!(tuple . 0 . 0),
    ] {
        assert_eq!(expected, syn::parse2(tokens).unwrap());
    }
}
fn bool() {
    assert_eq!("true".parse(), Ok(Value::Bool(true)));
    assert_eq!("false".parse(), Ok(Value::Bool(false)));
}
fn error_location_in_parent_block() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("parent", "Hello {{ greeting }} {% block bob %}{{ 1 + true }}{% endblock bob %}"),
        ("child", "{% extends \"parent\" %}{% block bob %}{{ super() }}Hey{% endblock bob %}"),
    ])
    .unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(
        result.unwrap_err().to_string(),
        "Failed to render \'child\' (error happened in 'parent')."
    );
}
fn test_cp_backup_never() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=never")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
fn test_error_render_iterate_non_array() {
    let result = render_tpl("iterate_on_non_array.html");

    assert!(result.is_err());
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Tried to iterate on a container (`friend_reviewed`) that has a unsupported type"
    );
}
fn test_uname_output_for_invisible_chars() {
    // let re = regex::Regex::new("[^[[:print:]]]").unwrap(); // matches invisible (and emojis)
    let re = regex::Regex::new("[^[[:print:]]\\p{Other_Symbol}]").unwrap(); // matches invisible (not emojis)
    let result = new_ucmd!().arg("--all").succeeds();
    assert_eq!(re.find(result.stdout_str().trim_end()), None);
}
fn parse_kill() {
    let stmt = clickhouse().verified_stmt("KILL MUTATION 5");
    assert_eq!(
        stmt,
        Statement::Kill {
            modifier: Some(KillType::Mutation),
            id: 5,
        }
    );
}
fn test_uname_processor() {
    let result = new_ucmd!().arg("-p").succeeds();
    assert_eq!(result.stdout_str().trim_end(), "unknown");
}
fn error_gives_source_on_tests() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("tpl", "{% if a is undefined(1) %}-{% endif %}")]).unwrap();
    let result = tera.render("tpl", &Context::new());
    println!("{:?}", result);
    let err = result.unwrap_err();

    let source = err.source().unwrap();
    assert_eq!(source.to_string(), "Test call \'undefined\' failed");
    let source2 = source.source().unwrap();

    assert_eq!(
        source2.to_string(),
        "Tester `undefined` was called with some args but this test doesn\'t take args"
    );
}
fn apply_suggested() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply-unsafe"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, APPLY_SUGGESTED_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_suggested",
        fs,
        console,
        result,
    ));
}
fn check_token_integration() {
    assert_eq!(
        token(
            &[
                Token::KeySelector("a"),
                Token::GroupSeparator,
                Token::KeySelector("b")
            ],
            &json!({ "a": 1, "b": 2 })
        ),
        Ok(json!([1, 2]))
    );
}
fn test_stale_read_while_applying_snapshot() {
    let (mut cluster, pd_client, leader_client) =
        prepare_for_stale_read_before_run(new_peer(1, 1), Some(Box::new(configure_for_snapshot)));
    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));
    follower_client2.ctx.set_stale_read(true);

    let k1_commit_ts = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), k1_commit_ts);

    // Stop replicate data to follower 2
    cluster.add_send_filter(IsolationFilterFactory::new(2));

    // Prewrite on `key3` but not commit yet
    let k2_prewrite_ts = get_tso(&pd_client);
    leader_client.must_kv_prewrite(
        vec![new_mutation(Op::Put, &b"key2"[..], &b"value1"[..])],
        b"key2".to_vec(),
        k2_prewrite_ts,
    );

    // Compact logs to force requesting snapshot after clearing send filters.
    let gc_limit = cluster.cfg.raft_store.raft_log_gc_count_limit();
    for i in 1..gc_limit * 2 {
        let (k, v) = (
            format!("k{}", i).into_bytes(),
            format!("v{}", i).into_bytes(),
        );
        leader_client.must_kv_write(&pd_client, vec![new_mutation(Op::Put, &k, &v)], k);
    }
    let last_index_on_store_2 = cluster.raft_local_state(1, 2).last_index;
    cluster.wait_log_truncated(1, 1, last_index_on_store_2 + 1);

    // Pasuse before applying snapshot is finish
    let raft_before_applying_snap_finished = "raft_before_applying_snap_finished";
    fail::cfg(raft_before_applying_snap_finished, "pause").unwrap();
    cluster.clear_send_filters();

    // Wait follower 2 start applying snapshot
    cluster.wait_log_truncated(1, 2, last_index_on_store_2 + 1);
    sleep_ms(100);

    // We can't read while applying snapshot and the `safe_ts` should reset to 0
    let resp = follower_client2.kv_read(b"key1".to_vec(), k1_commit_ts);
    assert!(resp.get_region_error().has_data_is_not_ready());
    assert_eq!(
        0,
        resp.get_region_error()
            .get_data_is_not_ready()
            .get_safe_ts()
    );

    // Resume applying snapshot
    fail::remove(raft_before_applying_snap_finished);

    let last_index_on_store_1 = cluster.raft_local_state(1, 1).last_index;
    cluster.wait_last_index(1, 2, last_index_on_store_1, Duration::from_secs(3));

    // We can read `key1` after applied snapshot
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), k1_commit_ts);
    // There is still lock on the region, we can't read `key1` with the newest ts
    let resp = follower_client2.kv_read(b"key1".to_vec(), get_tso(&pd_client));
    assert!(resp.get_region_error().has_data_is_not_ready());

    // Commit `key2`
    leader_client.must_kv_commit(vec![b"key2".to_vec()], k2_prewrite_ts, get_tso(&pd_client));
    // We can read `key1` with the newest ts now
    follower_client2.must_kv_read_equal(b"key2".to_vec(), b"value1".to_vec(), get_tso(&pd_client));
}
fn test_seq_object_borrow() {
    fn connect(values: &dyn SeqObject) -> String {
        let mut rv = String::new();
        for item in values.iter() {
            rv.push_str(&item.to_string())
        }
        rv
    }

    let mut env = Environment::new();
    env.add_filter("connect", connect);
    let state = env.empty_state();
    assert_eq!(
        state
            .apply_filter(
                "connect",
                args!(vec![Value::from("HELLO"), Value::from(42)])
            )
            .unwrap(),
        Value::from("HELLO42")
    );
}
fn test_comma_end() {
    assert_eq!(ron::from_str::<(i32, i32)>("(0, 1)").unwrap(), (0, 1));
    assert_eq!(ron::from_str::<(i32, i32)>("(0, 1,)").unwrap(), (0, 1));
    assert_eq!(ron::from_str::<()>("()"), Ok(()));
}
fn test_remove_by_conf_change() {
    let cluster = Cluster::with_node_count(2, None);
    let (region_id, peer_id, offset_id) = (2, 10, 1);
    let mut req = add_learner(&cluster, offset_id, region_id, peer_id);

    // write one kv to make flow control replicated.
    let (key, val) = (b"key", b"value");
    write_kv(&cluster, region_id, key, val);

    let new_conf_ver = req.get_header().get_region_epoch().get_conf_ver() + 1;
    req.mut_header()
        .mut_region_epoch()
        .set_conf_ver(new_conf_ver);
    req.mut_admin_request()
        .mut_change_peer()
        .set_change_type(ConfChangeType::RemoveNode);
    let (admin_msg, admin_sub) = PeerMsg::admin_command(req.clone());
    // write one kv after removal
    let (key, val) = (b"key1", b"value");
    let header = Box::new(cluster.routers[0].new_request_for(region_id).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, key, val);
    let (msg, sub) = PeerMsg::simple_write(header, put.encode());
    // Send them at the same time so they will be all sent to learner.
    cluster.routers[0].send(region_id, admin_msg).unwrap();
    cluster.routers[0].send(region_id, msg).unwrap();
    let resp = block_on(admin_sub.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let resp = block_on(sub.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    // Dispatch messages so the learner will receive conf remove and write at the
    // same time.
    cluster.dispatch(region_id, vec![]);
    cluster.routers[1].wait_flush(region_id, Duration::from_millis(300));
    // Wait for apply.
    std::thread::sleep(Duration::from_millis(100));
    let raft_engine = &cluster.node(1).running_state().unwrap().raft_engine;
    let region_state = raft_engine
        .get_region_state(region_id, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_state(), PeerState::Tombstone);
    assert_eq!(raft_engine.get_raft_state(region_id).unwrap(), None);
}
fn test_something() {
    let data = [];
    if let Ok(s) = str::from_utf8(data) {
        if let Ok(d) = parse_http_date(s) {
            let o = fmt_http_date(d);
            assert!(!o.is_empty());
            assert_eq!(parse_http_date(&o).expect("formatting to round trip"), d);
        }
    }
}
fn test_short_combination() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-dxen", "4", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("x00"), "a");
    assert_eq!(at.read("x01"), "b");
    assert_eq!(at.read("x02"), "c");
    assert!(!at.file_exists("x03"));
}
fn test_scale_scheduler_pool() {
    let snapshot_fp = "scheduler_start_execute";
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();
    let origin_pool_size = cluster.cfg.storage.scheduler_worker_pool_size;

    let engine = cluster
        .sim
        .read()
        .unwrap()
        .storages
        .get(&1)
        .unwrap()
        .clone();
    let storage = TestStorageBuilderApiV1::from_engine_and_lock_mgr(engine, MockLockManager::new())
        .config(cluster.cfg.tikv.storage.clone())
        .build()
        .unwrap();

    let cfg = new_tikv_config(1);
    let kv_engine = storage.get_engine().kv_engine().unwrap();
    let (_tx, rx) = std::sync::mpsc::channel();
    let flow_controller = Arc::new(FlowController::Singleton(EngineFlowController::new(
        &cfg.storage.flow_control,
        kv_engine.clone(),
        rx,
    )));

    let cfg_controller = ConfigController::new(cfg);
    let (scheduler, _receiver) = dummy_scheduler();
    cfg_controller.register(
        Module::Storage,
        Box::new(StorageConfigManger::new(
            kv_engine,
            scheduler,
            flow_controller,
            storage.get_scheduler(),
        )),
    );
    let scheduler = storage.get_scheduler();

    let region = cluster.get_region(b"k1");
    let mut ctx = Context::default();
    ctx.set_region_id(region.id);
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(cluster.leader_of_region(region.id).unwrap());
    let do_prewrite = |key: &[u8], val: &[u8]| {
        // prewrite
        let (prewrite_tx, prewrite_rx) = channel();
        storage
            .sched_txn_command(
                commands::Prewrite::new(
                    vec![Mutation::make_put(Key::from_raw(key), val.to_vec())],
                    key.to_vec(),
                    10.into(),
                    100,
                    false,
                    2,
                    TimeStamp::default(),
                    TimeStamp::default(),
                    None,
                    false,
                    AssertionLevel::Off,
                    ctx.clone(),
                ),
                Box::new(move |res: storage::Result<_>| {
                    let _ = prewrite_tx.send(res);
                }),
            )
            .unwrap();
        prewrite_rx.recv_timeout(Duration::from_secs(2))
    };

    let scale_pool = |size: usize| {
        cfg_controller
            .update_config("storage.scheduler-worker-pool-size", &format!("{}", size))
            .unwrap();
        assert_eq!(
            scheduler.get_sched_pool().get_pool_size(CommandPri::Normal),
            size
        );
    };

    scale_pool(1);
    fail::cfg(snapshot_fp, "1*pause").unwrap();
    // propose one prewrite to block the only worker
    do_prewrite(b"k1", b"v1").unwrap_err();

    scale_pool(2);

    // do prewrite again, as we scale another worker, this request should success
    do_prewrite(b"k2", b"v2").unwrap().unwrap();

    // restore to original config.
    scale_pool(origin_pool_size);
    fail::remove(snapshot_fp);
}
fn zlib_decoder_empty_read() {
    let original: &[u8] = b"Lorem ipsum dolor sit amet.";
    let mut encoder = flate2::write::ZlibEncoder::new(Vec::new(), flate2::Compression::default());
    encoder.write_all(original).unwrap();
    let encoded: Vec<u8> = encoder.finish().unwrap();
    let mut decoder = flate2::read::ZlibDecoder::new(encoded.as_slice());
    assert_eq!(decoder.read(&mut []).unwrap(), 0);
    let mut decoded = Vec::new();
    decoder.read_to_end(&mut decoded).unwrap();
    assert_eq!(decoded.as_slice(), original);
}
fn test_witness_election_priority() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );
    cluster.must_put(b"k0", b"v0");

    // make sure logs are replicated to the witness
    std::thread::sleep(Duration::from_millis(100));

    for i in 1..10 {
        let node = cluster.leader_of_region(region.get_id()).unwrap().store_id;
        cluster.stop_node(node);
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
        // the witness can't be elected as the leader when there is no log gap
        assert_ne!(
            cluster.leader_of_region(region.get_id()).unwrap().store_id,
            nodes[2],
        );
        cluster.run_node(node).unwrap();
        // make sure logs are replicated to the restarted node
        std::thread::sleep(Duration::from_millis(100));
    }
}
fn test_cp_arg_target_directory() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg("-t")
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    assert_eq!(at.read(TEST_COPY_TO_FOLDER_FILE), "Hello, World!\n");
}
fn parse_listagg() {
    let sql = "SELECT LISTAGG(DISTINCT dateid, ', ' ON OVERFLOW TRUNCATE '%' WITHOUT COUNT) \
               WITHIN GROUP (ORDER BY id, username)";
    let select = verified_only_select(sql);

    verified_stmt("SELECT LISTAGG(sellerid) WITHIN GROUP (ORDER BY dateid)");
    verified_stmt("SELECT LISTAGG(dateid)");
    verified_stmt("SELECT LISTAGG(DISTINCT dateid)");
    verified_stmt("SELECT LISTAGG(dateid ON OVERFLOW ERROR)");
    verified_stmt("SELECT LISTAGG(dateid ON OVERFLOW TRUNCATE N'...' WITH COUNT)");
    verified_stmt("SELECT LISTAGG(dateid ON OVERFLOW TRUNCATE X'deadbeef' WITH COUNT)");

    let expr = Box::new(Expr::Identifier(Ident::new("dateid")));
    let on_overflow = Some(ListAggOnOverflow::Truncate {
        filler: Some(Box::new(Expr::Value(Value::SingleQuotedString(
            "%".to_string(),
        )))),
        with_count: false,
    });
    let within_group = vec![
        OrderByExpr {
            expr: Expr::Identifier(Ident {
                value: "id".to_string(),
                quote_style: None,
            }),
            asc: None,
            nulls_first: None,
        },
        OrderByExpr {
            expr: Expr::Identifier(Ident {
                value: "username".to_string(),
                quote_style: None,
            }),
            asc: None,
            nulls_first: None,
        },
    ];
    assert_eq!(
        &Expr::ListAgg(ListAgg {
            distinct: true,
            expr,
            separator: Some(Box::new(Expr::Value(Value::SingleQuotedString(
                ", ".to_string()
            )))),
            on_overflow,
            within_group,
        }),
        expr_from_projection(only(&select.projection))
    );
}
fn test_repeat() {
    let repeat_limit = 15000;
    let input_seq = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10];
    let input = input_seq
        .iter()
        .map(ToString::to_string)
        .collect::<Vec<String>>()
        .join("\n");

    let result = new_ucmd!()
        .arg("-r")
        .args(&["-n", &repeat_limit.to_string()])
        .pipe_in(input.as_bytes())
        .succeeds();
    result.no_stderr();

    let result_seq: Vec<i32> = result
        .stdout_str()
        .split('\n')
        .filter(|x| !x.is_empty())
        .map(|x| x.parse().unwrap())
        .collect();
    assert_eq!(
        result_seq.len(),
        repeat_limit,
        "Output is not repeating forever"
    );
    assert!(
        result_seq.iter().all(|x| input_seq.contains(x)),
        "Output includes element not from input: {:?}",
        result_seq
            .iter()
            .filter(|x| !input_seq.contains(x))
            .collect::<Vec<&i32>>()
    );
}
fn test_witness_raftlog_gc_lagged_follower() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(200));
    let mut before_states = HashMap::default();
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        before_states.insert(id, state.take_truncated_state());
    }

    // one follower is down
    cluster.stop_node(nodes[1]);

    // write some data to make log gap exceeds the gc limit
    for i in 1..1000 {
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
    }

    // the witness truncated index is not advanced
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        if id == 2 {
            assert_eq!(
                state.get_truncated_state().get_index() - before_states[&id].get_index(),
                0
            );
        } else {
            assert_ne!(
                900,
                state.get_truncated_state().get_index() - before_states[&id].get_index()
            );
        }
    }

    // the follower is back online
    cluster.run_node(nodes[1]).unwrap();
    cluster.must_put(b"k00", b"v00");
    must_get_equal(&cluster.get_engine(nodes[1]), b"k00", b"v00");
    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(300));

    // the truncated index is advanced now, as all the peers has replicated
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        assert_ne!(
            900,
            state.get_truncated_state().get_index() - before_states[&id].get_index()
        );
    }
}
fn server_stream_handshake_error() {
    let (client_config, server_config) = make_disjoint_suite_configs();
    let (mut client, mut server) = make_pair_for_configs(client_config, server_config);

    client
        .writer()
        .write_all(b"world")
        .unwrap();

    {
        let mut pipe = OtherSession::new_fails(&mut client);
        let mut server_stream = Stream::new(&mut server, &mut pipe);
        let mut bytes = [0u8; 5];
        let rc = server_stream.read(&mut bytes);
        assert!(rc.is_err());
        assert_eq!(
            format!("{:?}", rc),
            "Err(Custom { kind: InvalidData, error: PeerIncompatible(NoCipherSuitesInCommon) })"
        );
    }
}
fn test_escaped_content() {
    let mut r = Reader::from_str("<a>&lt;test&gt;</a>");
    r.trim_text(true);
    next_eq!(r, Start, b"a");
    match r.read_event() {
        Ok(Text(e)) => {
            assert_eq!(
                &*e,
                b"&lt;test&gt;",
                "content unexpected: expecting '&lt;test&gt;', got '{:?}'",
                from_utf8(&e)
            );
            match e.unescape() {
                Ok(c) => assert_eq!(c, "<test>"),
                Err(e) => panic!(
                    "cannot escape content at position {}: {:?}",
                    r.buffer_position(),
                    e
                ),
            }
        }
        Ok(e) => panic!("Expecting text event, got {:?}", e),
        Err(e) => panic!(
            "Cannot get next event at position {}: {:?}",
            r.buffer_position(),
            e
        ),
    }
    next_eq!(r, End, b"a");
}
fn exports_not_browser_field1() {
    let f = super::fixture().join("exports-field");

    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        condition_names: vec!["webpack".into()],
        extensions: vec![".js".into()],
        ..ResolveOptions::default()
    });

    let resolved_path = resolver.resolve(&f, "exports-field/dist/main.js").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f.join("node_modules/exports-field/lib/lib2/main.js")));
}
fn exclude_stdin() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
extend-select = ["B", "Q"]

[lint]
exclude = ["generated.py"]

[lint.flake8-quotes]
inline-quotes = "single"
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .current_dir(tempdir.path())
        .arg("check")
        .args(STDIN_BASE_OPTIONS)
        .args(["--config", &ruff_toml.file_name().unwrap().to_string_lossy()])
        .args(["--stdin-filename", "generated.py"])
        .arg("-")
        .pass_stdin(r#"
from test import say_hy

if __name__ == "__main__":
    say_hy("dear Ruff contributor")
"#), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    generated.py:4:16: Q000 [*] Double quotes found but single quotes preferred
    generated.py:5:12: Q000 [*] Double quotes found but single quotes preferred
    Found 2 errors.
    [*] 2 fixable with the `--fix` option.

    ----- stderr -----
    "###);
    Ok(())
}
fn drain_lifetime() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<&str, &str> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let txn = db.begin_write().unwrap();
    let mut table = txn.open_table(definition).unwrap();

    let mut iter = {
        let start = "hello".to_string();
        table.drain::<&str>(start.as_str()..).unwrap()
    };
    assert_eq!(iter.next().unwrap().unwrap().1.value(), "world");
    assert!(iter.next().is_none());
}
async fn read_push_promise() {
    let mut codec = raw_codec! {
        read => [
            0, 0, 0x5,
            0x5, 0x4,
            0, 0, 0, 0x1, // stream id
            0, 0, 0, 0x2, // promised id
            0x82, // HPACK :method="GET"
        ];
    };

    let pp = poll_frame!(PushPromise, codec);
    assert_eq!(pp.stream_id(), 1);
    assert_eq!(pp.promised_id(), 2);
    assert_eq!(pp.into_parts().0.method, Some(Method::GET));

    assert_closed!(codec);
}
fn alternate_marker() {
  let tmp = temptree! {
    "_darcs": {},
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--init")
    .output()
    .unwrap();

  assert!(output.status.success());

  assert_eq!(
    fs::read_to_string(tmp.path().join("justfile")).unwrap(),
    EXPECTED
  );
}
fn test_download_sst_blocking_sst_writer() {
    let (_cluster, ctx, tikv, import) = new_cluster_and_tikv_import_client();
    let temp_dir = Builder::new()
        .prefix("test_download_sst_blocking_sst_writer")
        .tempdir()
        .unwrap();

    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, _) = gen_sst_file(sst_path, sst_range);
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());

    // Sleep 20s, make sure it is large than grpc_keepalive_timeout (3s).
    let sst_writer_open_fp = "on_open_sst_writer";
    fail::cfg(sst_writer_open_fp, "sleep(20000)").unwrap();

    // Now perform a proper download.
    let mut download = DownloadRequest::default();
    download.set_sst(meta.clone());
    download.set_storage_backend(external_storage_export::make_local_backend(temp_dir.path()));
    download.set_name("test.sst".to_owned());
    download.mut_sst().mut_range().set_start(vec![sst_range.1]);
    download
        .mut_sst()
        .mut_range()
        .set_end(vec![sst_range.1 + 1]);
    download.mut_sst().mut_range().set_start(Vec::new());
    download.mut_sst().mut_range().set_end(Vec::new());
    let result = import.download(&download).unwrap();
    assert!(!result.get_is_empty());
    assert_eq!(result.get_range().get_start(), &[sst_range.0]);
    assert_eq!(result.get_range().get_end(), &[sst_range.1 - 1]);

    fail::remove(sst_writer_open_fp);

    // Do an ingest and verify the result is correct.
    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error());

    check_ingested_kvs(&tikv, &ctx, sst_range);
}
fn server_respects_buffer_limit_pre_handshake_with_vectored_write() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    server.set_buffer_limit(Some(32));

    assert_eq!(
        server
            .writer()
            .write_vectored(&[
                IoSlice::new(b"01234567890123456789"),
                IoSlice::new(b"01234567890123456789")
            ])
            .unwrap(),
        32
    );

    do_handshake(&mut client, &mut server);
    transfer(&mut server, &mut client);
    client.process_new_packets().unwrap();

    check_read(&mut client.reader(), b"01234567890123456789012345678901");
}
fn test_array_agg_func() {
    for sql in [
        "SELECT ARRAY_AGG(x) WITHIN GROUP (ORDER BY x) AS a FROM T",
        "SELECT ARRAY_AGG(DISTINCT x) WITHIN GROUP (ORDER BY x ASC) FROM tbl",
    ] {
        snowflake().verified_stmt(sql);
    }

    let sql = "select array_agg(x order by x) as a from T";
    let result = snowflake().parse_sql_statements(sql);
    assert_eq!(
        result,
        Err(ParserError::ParserError(String::from(
            "Expected ), found: order"
        )))
    )
}
fn lsp_proxy_help() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lsp-proxy"), "--help"].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "lsp_proxy_help",
        fs,
        console,
        result,
    ));
}
fn test_datetimeformat() {
    let mut env = minijinja::Environment::new();
    env.add_global("TIMEZONE", "Europe/Vienna");
    env.add_global("DATETIME_FORMAT", "[hour]:[minute]");
    minijinja_contrib::add_to_environment(&mut env);

    let expr = env
        .compile_expression("1687624642.5|datetimeformat(format=format)")
        .unwrap();

    assert_eq!(
        expr.eval(context!(format => "short")).unwrap().to_string(),
        "2023-06-24 18:37"
    );
    assert_eq!(
        expr.eval(context!(format => "medium")).unwrap().to_string(),
        "Jun 24 2023 18:37"
    );
    assert_eq!(
        expr.eval(context!(format => "long")).unwrap().to_string(),
        "June 24 2023 18:37:22"
    );
    assert_eq!(
        expr.eval(context!(format => "full")).unwrap().to_string(),
        "Saturday, June 24 2023 18:37:22.5"
    );
    assert_eq!(
        expr.eval(context!(format => "unix")).unwrap().to_string(),
        "1687624642"
    );
    assert_eq!(
        expr.eval(context!(format => "iso")).unwrap().to_string(),
        "2023-06-24T18:37:22+02:00"
    );

    let expr = env
        .compile_expression("1687624642|datetimeformat(tz='Europe/Moscow')")
        .unwrap();
    assert_eq!(expr.eval(()).unwrap().to_string(), "19:37");
}
fn test_chown_only_owner() {
    // test chown username file.txt

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let result = scene.cmd("whoami").run();
    if skipping_test_is_okay(&result, "whoami: cannot find name for user ID") {
        return;
    }
    let user_name = String::from(result.stdout_str().trim());
    assert!(!user_name.is_empty());

    let file1 = "test_chown_file1";
    at.touch(file1);

    // since only superuser can change owner, we have to change from ourself to ourself
    let result = scene
        .ucmd()
        .arg(user_name)
        .arg("--verbose")
        .arg(file1)
        .run();
    result.stderr_contains("retained as");

    // try to change to another existing user, e.g. 'root'
    scene
        .ucmd()
        .arg("root")
        .arg("--verbose")
        .arg(file1)
        .fails()
        .stderr_contains("failed to change");
}
fn parse_nested_data_types() {
    let sql = "CREATE TABLE table (x STRUCT<a ARRAY<INT64>, b BYTES(42)>, y ARRAY<STRUCT<INT64>>)";
    match bigquery().one_statement_parses_to(sql, sql) {
        Statement::CreateTable { name, columns, .. } => {
            assert_eq!(name, ObjectName(vec!["table".into()]));
            assert_eq!(
                columns,
                vec![
                    ColumnDef {
                        name: Ident::new("x"),
                        data_type: DataType::Struct(vec![
                            StructField {
                                field_name: Some("a".into()),
                                field_type: DataType::Array(ArrayElemTypeDef::AngleBracket(
                                    Box::new(DataType::Int64,)
                                ))
                            },
                            StructField {
                                field_name: Some("b".into()),
                                field_type: DataType::Bytes(Some(42))
                            },
                        ]),
                        collation: None,
                        options: vec![],
                    },
                    ColumnDef {
                        name: Ident::new("y"),
                        data_type: DataType::Array(ArrayElemTypeDef::AngleBracket(Box::new(
                            DataType::Struct(vec![StructField {
                                field_name: None,
                                field_type: DataType::Int64,
                            }]),
                        ))),
                        collation: None,
                        options: vec![],
                    },
                ]
            );
        }
        _ => unreachable!(),
    }
}
fn test_cp_arg_symlink() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg("--symbolic-link")
        .arg(TEST_HELLO_WORLD_DEST)
        .succeeds();

    assert!(at.is_symlink(TEST_HELLO_WORLD_DEST));
}
fn remove_entry_multi_0_others() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());

    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 0);
    assert_eq!(headers.len(), 2);
}
fn extends_config_ok_formatter_no_linter() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = Path::new("biome.json");
    fs.insert(
        rome_json.into(),
        r#"{ "extends": ["format.json", "linter.json"] }"#,
    );
    let format = Path::new("format.json");
    fs.insert(
        format.into(),
        r#"{ "javascript": { "formatter": { "quoteStyle": "single" } } }"#,
    );
    let lint = Path::new("linter.json");
    fs.insert(lint.into(), r#"{ "linter": { "enabled": false } }"#);

    let test_file = Path::new("test.js");
    fs.insert(test_file.into(), r#"debugger; console.log("string"); "#);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("check"), test_file.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "extends_config_ok_formatter_no_linter",
        fs,
        console,
        result,
    ));
}
fn parse_value_forloop() {
    let ast = parse("{% for item in items | reverse %}A{%- endfor %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Forloop(
            start_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::with_filters(
                    ExprVal::Ident("items".to_string()),
                    vec![FunctionCall { name: "reverse".to_string(), args: HashMap::new() },],
                ),
                body: vec![Node::Text("A".to_string())],
                empty_body: None,
            },
            end_ws,
        )
    );
}
fn parse_alter_table_drop_column() {
    check_one("DROP COLUMN IF EXISTS is_active CASCADE");
    one_statement_parses_to(
        "ALTER TABLE tab DROP IF EXISTS is_active CASCADE",
        "ALTER TABLE tab DROP COLUMN IF EXISTS is_active CASCADE",
    );
    one_statement_parses_to(
        "ALTER TABLE tab DROP is_active CASCADE",
        "ALTER TABLE tab DROP COLUMN is_active CASCADE",
    );

    fn check_one(constraint_text: &str) {
        match alter_table_op(verified_stmt(&format!("ALTER TABLE tab {constraint_text}"))) {
            AlterTableOperation::DropColumn {
                column_name,
                if_exists,
                cascade,
            } => {
                assert_eq!("is_active", column_name.to_string());
                assert!(if_exists);
                assert!(cascade);
            }
            _ => unreachable!(),
        }
    }
}
fn drops_empty_tbody() {
    assert_eq!(
        "<table><thead><tr><td>hi</td></tr></thead></table>",
        normalize_html("<table><thead><tr><td>hi</td></tr></thead><tbody>  </tbody></table>")
    )
}
fn no_metadata_appears_on_inscription_page_if_no_metadata_is_passed() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);
  rpc_server.mine_blocks(1);

  let Inscribe { inscriptions, .. } =
    CommandBuilder::new("wallet inscribe --fee-rate 1 --file content.png")
      .write("content.png", [1; 520])
      .rpc_server(&rpc_server)
      .run_and_deserialize_output();

  let inscription = inscriptions[0].id;

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  assert!(!ord_server
    .request(format!("/inscription/{inscription}"),)
    .text()
    .unwrap()
    .contains("metadata"));
}
fn test_timeout_query_tcp() {
    //env_logger::try_init().ok();
    let io_loop = Runtime::new().unwrap();

    // this is a test network, it should NOT be in use
    let addr: SocketAddr = ("203.0.113.0", 53)
        .to_socket_addrs()
        .unwrap()
        .next()
        .unwrap();

    let (stream, sender) = TcpClientStream::<AsyncIoTokioAsStd<TokioTcpStream>>::with_timeout(
        addr,
        std::time::Duration::from_millis(1),
    );
    let client = AsyncClient::with_timeout(
        Box::new(stream),
        sender,
        std::time::Duration::from_millis(1),
        None,
    );

    assert!(io_loop.block_on(client).is_err());
}
fn test_detect_deadlock_when_updating_wait_info() {
    use kvproto::kvrpcpb::PessimisticLockKeyResultType::*;
    let mut cluster = new_cluster_for_deadlock_test(3);

    let key1 = b"key1";
    let key2 = b"key2";
    let (client, ctx) = build_leader_client(&mut cluster, key1);
    let client = Arc::new(client);

    fn async_pessimistic_lock(
        client: Arc<TikvClient>,
        ctx: Context,
        key: &[u8],
        ts: u64,
    ) -> mpsc::Receiver<PessimisticLockResponse> {
        let (tx, rx) = mpsc::channel();
        let key = vec![key.to_vec()];
        thread::spawn(move || {
            let resp =
                kv_pessimistic_lock_resumable(&client, ctx, key, ts, ts, Some(1000), false, false);
            tx.send(resp).unwrap();
        });
        rx
    }

    // key1: txn 11 and 12 waits for 10
    // key2: txn 11 waits for 12
    let resp = kv_pessimistic_lock_resumable(
        &client,
        ctx.clone(),
        vec![key1.to_vec()],
        10,
        10,
        Some(1000),
        false,
        false,
    );
    assert!(resp.region_error.is_none());
    assert!(resp.errors.is_empty());
    assert_eq!(resp.results[0].get_type(), LockResultNormal);
    let resp = kv_pessimistic_lock_resumable(
        &client,
        ctx.clone(),
        vec![key2.to_vec()],
        12,
        12,
        Some(1000),
        false,
        false,
    );
    assert!(resp.region_error.is_none());
    assert!(resp.errors.is_empty());
    assert_eq!(resp.results[0].get_type(), LockResultNormal);
    let rx_txn11_k1 = async_pessimistic_lock(client.clone(), ctx.clone(), key1, 11);
    let rx_txn12_k1 = async_pessimistic_lock(client.clone(), ctx.clone(), key1, 12);
    let rx_txn11_k2 = async_pessimistic_lock(client.clone(), ctx.clone(), key2, 11);
    // All blocked.
    assert_eq!(
        rx_txn11_k1
            .recv_timeout(Duration::from_millis(50))
            .unwrap_err(),
        RecvTimeoutError::Timeout
    );
    assert_eq!(rx_txn12_k1.try_recv().unwrap_err(), TryRecvError::Empty);
    assert_eq!(rx_txn11_k2.try_recv().unwrap_err(), TryRecvError::Empty);

    // Release lock at ts=10 on key1 so that txn 11 will be granted the lock.
    must_kv_pessimistic_rollback(&client, ctx.clone(), key1.to_vec(), 10, 10);
    let resp = rx_txn11_k1
        .recv_timeout(Duration::from_millis(200))
        .unwrap();
    assert!(resp.region_error.is_none());
    assert!(resp.errors.is_empty());
    assert_eq!(resp.results[0].get_type(), LockResultNormal);
    // And then 12 waits for k1 on key1, which forms a deadlock.
    let resp = rx_txn12_k1
        .recv_timeout(Duration::from_millis(1000))
        .unwrap();
    assert!(resp.region_error.is_none());
    assert!(resp.errors[0].has_deadlock());
    assert_eq!(resp.results[0].get_type(), LockResultFailed);
    // Check correctness of the wait chain.
    let wait_chain = resp.errors[0].get_deadlock().get_wait_chain();
    assert_eq!(wait_chain[0].get_txn(), 11);
    assert_eq!(wait_chain[0].get_wait_for_txn(), 12);
    assert_eq!(wait_chain[0].get_key(), key2);
    assert_eq!(wait_chain[1].get_txn(), 12);
    assert_eq!(wait_chain[1].get_wait_for_txn(), 11);
    assert_eq!(wait_chain[1].get_key(), key1);

    // Clean up.
    must_kv_pessimistic_rollback(&client, ctx.clone(), key1.to_vec(), 11, 11);
    must_kv_pessimistic_rollback(&client, ctx.clone(), key2.to_vec(), 12, 12);
    let resp = rx_txn11_k2
        .recv_timeout(Duration::from_millis(500))
        .unwrap();
    assert!(resp.region_error.is_none());
    assert!(resp.errors.is_empty());
    assert_eq!(resp.results[0].get_type(), LockResultNormal);
    must_kv_pessimistic_rollback(&client, ctx, key2.to_vec(), 11, 11);
}
fn with_semicolons_options() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--semicolons=as-needed"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, "statement()\n");

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "with_semicolons_options",
        fs,
        console,
        result,
    ));
}
fn compute_error_scaled32_test() {
    // These are the same examples above, just using pre-computed scaled values.

    // These test near-halfway cases for single-precision floats.
    assert_eq!(
        compute_error_scaled32(0, 4611686018427387904, 39),
        (111 + f32::INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686293305294848, 39),
        (111 + f32::INVALID_FP, 9223372586610589696)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686568183201792, 39),
        (111 + f32::INVALID_FP, 9223373136366403584)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611686843061108736, 39),
        (111 + f32::INVALID_FP, 9223373686122217472)
    );
    assert_eq!(
        compute_error_scaled32(0, 4611687117939015680, 39),
        (111 + f32::INVALID_FP, 9223374235878031360)
    );

    assert_eq!(
        compute_error_scaled32(-10, 9223372036854775808, 6),
        (111 + f32::INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223372586610589696, 6),
        (111 + f32::INVALID_FP, 9223372586610589696)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223373136366403584, 6),
        (111 + f32::INVALID_FP, 9223373136366403584)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223373686122217472, 6),
        (111 + f32::INVALID_FP, 9223373686122217472)
    );
    assert_eq!(
        compute_error_scaled32(-10, 9223374235878031360, 6),
        (111 + f32::INVALID_FP, 9223374235878031360)
    );
}
fn handshake_anti_deadlock_probe() {
    let _guard = subscribe();

    let (cert, key) = big_cert_and_key();
    let server = server_config_with_cert(cert.clone(), key);
    let client = client_config_with_certs(vec![cert]);
    let mut pair = Pair::new(Default::default(), server);

    let client_ch = pair.begin_connect(client);
    // Client sends initial
    pair.drive_client();
    // Server sends first flight, gets blocked on anti-amplification
    pair.drive_server();
    // Client acks...
    pair.drive_client();
    // ...but it's lost, so the server doesn't get anti-amplification credit from it
    pair.server.inbound.clear();
    // Client sends an anti-deadlock probe, and the handshake completes as usual.
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::HandshakeDataReady)
    );
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::Connected { .. })
    );
}
fn parse_key_value_with_space_test() {
  let ini_file = "parameter = value
key = value2";

  let ini_without_key_value = "key = value2";

  let res = key_value(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, (o1, o2))) => println!("i: {} | o: ({:?},{:?})", i, o1, o2),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_key_value, ("parameter", "value"))));
}
fn check_parse_integration() {
    assert_eq!(
        parse(r#""this"[9,0]|>"some"<|"ok"..!"#),
        Ok(vec![
            Token::KeySelector("this"),
            Token::ArrayIndexSelector(vec![Index::new(9), Index::new(0)]),
            Token::PipeInOperator,
            Token::KeySelector("some"),
            Token::PipeOutOperator,
            Token::KeySelector("ok"),
            Token::FlattenOperator,
            Token::TruncateOperator
        ]),
    );
}
fn test_region_meta_endpoint() {
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();
    let region = cluster.get_region(b"");
    let region_id = region.get_id();
    let peer = region.get_peers().get(0);
    assert!(peer.is_some());
    let store_id = peer.unwrap().get_store_id();
    let router = cluster.raft_extension(store_id);
    let mut status_server = StatusServer::new(
        1,
        ConfigController::default(),
        Arc::new(SecurityConfig::default()),
        router,
        std::env::temp_dir(),
        None,
        GrpcServiceManager::dummy(),
    )
    .unwrap();
    let addr = format!("127.0.0.1:{}", test_util::alloc_port());
    status_server.start(addr).unwrap();
    let check_task = check(status_server.listening_addr(), region_id);
    let rt = tokio::runtime::Runtime::new().unwrap();
    if let Err(err) = rt.block_on(check_task) {
        panic!("{}", err);
    }
    status_server.stop();
}
fn lint_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("check.js");
    fs.insert(file_path.into(), LINT_ERROR.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "lint_error",
        fs,
        console,
        result,
    ));
}
fn test_deserialise_non_newtypes() {
    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] Unit"#).unwrap(),
        TestEnum::Unit,
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] PrimitiveNewtype("hi")"#)
            .unwrap(),
        TestEnum::PrimitiveNewtype(String::from("hi")),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] Tuple(4, false)"#).unwrap(),
        TestEnum::Tuple(4, false),
    );

    assert_eq!(
        from_str::<TestEnum>(r#"#![enable(unwrap_variant_newtypes)] Struct(a: 4, b: false)"#)
            .unwrap(),
        TestEnum::Struct { a: 4, b: false },
    );
}
fn read_icc_profile_missing_chunk() {
    let path = Path::new("tests")
        .join("icc")
        .join("icc_missing_chunk.jpeg");

    let mut decoder = jpeg::Decoder::new(File::open(&path).unwrap());
    decoder.decode().unwrap();

    let profile = decoder.icc_profile();
    assert!(profile.is_none());
}
fn wasmer_init_works_2() {
    let tempdir = tempfile::tempdir().unwrap();
    let path = tempdir.path();
    let path = path.join("testfirstproject");
    std::fs::create_dir_all(&path).unwrap();
    std::fs::write(
        path.join("Cargo.toml"),
        include_bytes!("./fixtures/init2.toml"),
    )
    .unwrap();
    std::fs::create_dir_all(path.join("src")).unwrap();
    std::fs::write(path.join("src").join("main.rs"), b"fn main() { }").unwrap();

    Command::new(get_wasmer_path())
        .arg("init")
        .arg("--namespace=ciuser")
        .current_dir(&path)
        .assert()
        .success();

    assert_eq!(
        std::fs::read_to_string(path.join("Cargo.toml")).unwrap(),
        include_str!("./fixtures/init2.toml")
    );
    assert_eq!(
        std::fs::read_to_string(path.join("wasmer.toml")).unwrap(),
        include_str!("./fixtures/init4.toml")
    );
}
fn carriage_return() {
    let stream = "///\r\n".parse::<TokenStream>().unwrap();
    let lit = lit_of_outer_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\"\"");

    let stream = "/**\r\n*/".parse::<TokenStream>().unwrap();
    let lit = lit_of_outer_doc_comment(&stream);
    assert_eq!(lit.to_string(), "\"\\r\\n\"");

    "///\r".parse::<TokenStream>().unwrap_err();
    "///\r \n".parse::<TokenStream>().unwrap_err();
    "/**\r \n*/".parse::<TokenStream>().unwrap_err();
}
fn no_lint_if_linter_is_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(config_path.into(), CONFIG_LINTER_DISABLED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_if_linter_is_disabled",
        fs,
        console,
        result,
    ));
}
fn weak_map_basic() {
    run_test(|| {
        let key1 = Gc::new(String::from("key1"));
        let key2 = Gc::new(String::from("key2"));
        let key3 = Gc::new(String::from("key3"));

        assert!(!has_weak_maps());

        let mut map = WeakMap::new();

        assert!(has_weak_maps());

        map.insert(&key1, ());
        map.insert(&key2, ());
        map.insert(&key3, ());

        force_collect();
        assert!(has_weak_maps());

        assert!(map.contains_key(&key1));
        assert!(map.contains_key(&key2));
        assert!(map.contains_key(&key3));

        drop(key1);

        force_collect();
        assert!(has_weak_maps());

        assert!(map.contains_key(&key2));
        assert!(map.contains_key(&key3));

        drop(key2);

        force_collect();
        assert!(has_weak_maps());

        assert!(map.contains_key(&key3));
        assert!(has_weak_maps());

        drop(key3);

        assert!(has_weak_maps());

        force_collect();
        assert!(has_weak_maps());

        drop(map);

        force_collect();
        assert!(!has_weak_maps());
    });
}
fn test_unsafe_recovery_execution_result_report() {
    let mut cluster = new_server_cluster(0, 3);
    // Prolong force leader time.
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();

    // Makes the leadership definite.
    let store2_peer = find_peer(&region, nodes[1]).unwrap().to_owned();
    cluster.must_transfer_leader(region.get_id(), store2_peer);
    cluster.put(b"random_key1", b"random_val1").unwrap();

    // Split the region into 2, and remove one of them, so that we can test both
    // region peer list update and region creation.
    pd_client.must_split_region(
        region,
        pdpb::CheckPolicy::Usekey,
        vec![b"random_key1".to_vec()],
    );
    let region1 = pd_client.get_region(b"random_key".as_ref()).unwrap();
    let region2 = pd_client.get_region(b"random_key1".as_ref()).unwrap();
    let region1_store0_peer = find_peer(&region1, nodes[0]).unwrap().to_owned();
    pd_client.must_remove_peer(region1.get_id(), region1_store0_peer);
    cluster.must_remove_region(nodes[0], region1.get_id());

    // Makes the group lose its quorum.
    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    {
        let put = new_put_cmd(b"k2", b"v2");
        let req = new_request(
            region2.get_id(),
            region2.get_region_epoch().clone(),
            vec![put],
            true,
        );
        // marjority is lost, can't propose command successfully.
        cluster
            .call_command_on_leader(req, Duration::from_millis(10))
            .unwrap_err();
    }

    cluster.must_enter_force_leader(region2.get_id(), nodes[0], vec![nodes[1], nodes[2]]);

    // Construct recovery plan.
    let mut plan = pdpb::RecoveryPlan::default();

    let to_be_removed: Vec<metapb::Peer> = region2
        .get_peers()
        .iter()
        .filter(|&peer| peer.get_store_id() != nodes[0])
        .cloned()
        .collect();
    let mut demote = pdpb::DemoteFailedVoters::default();
    demote.set_region_id(region2.get_id());
    demote.set_failed_voters(to_be_removed.into());
    plan.mut_demotes().push(demote);

    let mut create = metapb::Region::default();
    create.set_id(101);
    create.set_end_key(b"random_key1".to_vec());
    let mut peer = metapb::Peer::default();
    peer.set_id(102);
    peer.set_store_id(nodes[0]);
    create.mut_peers().push(peer);
    plan.mut_creates().push(create);

    // Blocks the raft apply process on store 1 entirely .
    let (apply_released_tx, apply_released_rx) = mpsc::bounded::<()>(1);
    fail::cfg_callback("on_handle_apply_store_1", move || {
        let _ = apply_released_rx.recv();
    })
    .unwrap();

    // Triggers the unsafe recovery plan execution.
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);

    // No store report is sent, since there are peers have unapplied entries.
    for _ in 0..20 {
        assert_eq!(pd_client.must_get_store_report(nodes[0]), None);
        sleep_ms(100);
    }

    // Unblocks the apply process.
    drop(apply_released_tx);

    // Store reports are sent once the entries are applied.
    let mut store_report = None;
    for _ in 0..20 {
        store_report = pd_client.must_get_store_report(nodes[0]);
        if store_report.is_some() {
            break;
        }
        sleep_ms(100);
    }
    assert_ne!(store_report, None);
    for peer_report in store_report.unwrap().get_peer_reports() {
        let region = peer_report.get_region_state().get_region();
        if region.get_id() == 101 {
            assert_eq!(region.get_end_key(), b"random_key1".to_vec());
        } else {
            assert_eq!(region.get_id(), region2.get_id());
            for peer in region.get_peers() {
                if peer.get_store_id() != nodes[0] {
                    assert_eq!(peer.get_role(), metapb::PeerRole::Learner);
                }
            }
        }
    }
    fail::remove("on_handle_apply_store_1");
}
fn lex_macro_definition() {
    let inputs = vec![
        "hello()",
        "hello(name, admin)",
        "hello(name, admin=1)",
        "hello(name=\"bob\", admin)",
        "hello(name=\"bob\",admin=true)",
    ];
    for i in inputs {
        // The () are not counted as tokens for some reasons so can't use the macro
        assert!(TeraParser::parse(Rule::macro_fn, i).is_ok());
    }
}
fn import_macros_into_other_macro_files() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("submacros", "{% macro test() %}Success!{% endmacro %}"),
        (
            "macros",
            r#"{% import "submacros" as sub %}{% macro test() %}{{ sub::test() }}{% endmacro %}"#,
        ),
        ("index", r#"{% import "macros" as macros %}{{ macros::test() }}"#),
    ])
    .unwrap();
    let result = tera.render("index", &Context::new());

    assert_eq!(result.unwrap(), "Success!".to_string());
}
fn test_cname_lookup() {
    let resp_query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let cname_record = cname_record(
        Name::from_str("www.example.com.").unwrap(),
        Name::from_str("v4.example.com.").unwrap(),
    );
    let v4_record = v4_record(
        Name::from_str("v4.example.com.").unwrap(),
        Ipv4Addr::new(93, 184, 216, 34),
    );
    let message = message(resp_query, vec![cname_record, v4_record], vec![], vec![]);
    let client: MockClientHandle<_, ResolveError> =
        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, false),
    );

    let io_loop = Runtime::new().unwrap();
    let lookup = io_loop.block_on(lookup).unwrap();

    assert_eq!(
        *lookup.iter().next().unwrap(),
        RData::A(A::new(93, 184, 216, 34))
    );
}
fn test_split_numeric_prefixed_chunks_by_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_num_prefixed_chunks_by_bytes";
    RandomFile::new(&at, name).add_bytes(10000);
    ucmd.args(&[
        "-d", // --numeric-suffixes
        "-b", // --bytes
        "1000", name, "a",
    ])
    .succeeds();

    let glob = Glob::new(&at, ".", r"a\d\d$");
    assert_eq!(glob.count(), 10);
    for filename in glob.collect() {
        assert_eq!(glob.directory.metadata(&filename).len(), 1000);
    }
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_split_default() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_default";
    RandomFile::new(&at, name).add_lines(2000);
    ucmd.args(&[name]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_mkdir_parent_mode() {
    let _guard = TEST_MUTEX.lock();
    let (at, mut ucmd) = at_and_ucmd!();

    let default_umask: mode_t = 0o160;
    let original_umask = unsafe { umask(default_umask) };

    ucmd.arg("-p").arg("a/b").succeeds().no_stderr().no_stdout();

    assert!(at.dir_exists("a"));
    // parents created by -p have permissions set to "=rwx,u+wx"
    assert_eq!(
        at.metadata("a").permissions().mode() as mode_t,
        ((!default_umask & 0o777) | 0o300) + 0o40000
    );
    assert!(at.dir_exists("a/b"));
    // sub directory's permission is determined only by the umask
    assert_eq!(
        at.metadata("a/b").permissions().mode() as mode_t,
        (!default_umask & 0o777) + 0o40000
    );

    unsafe {
        umask(original_umask);
    }
}
fn test_extract_failure() {
    let result = extract_file(Path::new("tests/corrupt-gz-file.bin"));
    assert_eq!(result.err().unwrap().kind(), io::ErrorKind::InvalidInput);
}
fn test_cp_strip_trailing_slashes() {
    let (at, mut ucmd) = at_and_ucmd!();

    //using --strip-trailing-slashes option
    ucmd.arg("--strip-trailing-slashes")
        .arg(format!("{TEST_HELLO_WORLD_SOURCE}/"))
        .arg(TEST_HELLO_WORLD_DEST)
        .succeeds();

    // Check the content of the destination file that was copied.
    assert_eq!(at.read(TEST_HELLO_WORLD_DEST), "Hello, World!\n");
}
fn can_remove_whitespace_include() {
    let mut context = Context::new();
    context.insert("numbers", &vec![1, 2, 3]);

    let inputs = vec![
        (r#"Hi {%- include "include" -%} "#, "HiIncluded"),
        (r#"Hi {% include "include" -%} "#, "Hi Included"),
        (r#"Hi {% include "include" %} "#, "Hi Included "),
    ];

    for (input, expected) in inputs {
        let mut tera = Tera::default();
        tera.add_raw_templates(vec![("include", "Included"), ("tpl", input)]).unwrap();
        assert_eq!(tera.render("tpl", &context).unwrap(), expected);
    }
}
fn test_unknown_peer() {
    let cluster = Cluster::with_node_count(1, None);

    let router = &cluster.routers[0];
    let header = router.new_request_for(2).take_header();

    // Create a fake message to see whether it's responded.
    let from_peer = new_peer(10, 10);
    let mut msg = Box::<RaftMessage>::default();
    msg.set_region_id(2);
    msg.set_to_peer(header.get_peer().clone());
    msg.set_region_epoch(header.get_region_epoch().clone());
    msg.set_from_peer(from_peer.clone());
    let raft_message = msg.mut_message();
    raft_message.set_msg_type(raft::prelude::MessageType::MsgHeartbeat);
    raft_message.set_from(10);
    raft_message.set_term(10);

    router.send_raft_message(msg).unwrap();
    router.wait_flush(2, Duration::from_secs(3));
    // If peer cache is updated correctly, it should be able to respond.
    let msg = cluster.receiver(0).try_recv().unwrap();
    assert_eq!(*msg.get_to_peer(), from_peer);
    assert_eq!(msg.get_from_peer(), header.get_peer());
    assert_eq!(
        msg.get_message().get_msg_type(),
        MessageType::MsgHeartbeatResponse
    );
}
fn parse_in_error() {
    // <expr> IN <expr> is no valid
    let sql = "SELECT * FROM customers WHERE segment in segment";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected (, found: segment".to_string()),
        res.unwrap_err()
    );
}
fn test_prewrite_before_max_ts_is_synced() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_heartbeat_ticks = 20;
    cluster.run();

    let addr = cluster.sim.rl().get_addr(1);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env).connect(&addr);
    let client = TikvClient::new(channel);

    let do_prewrite = |cluster: &mut Cluster<ServerCluster>| {
        let region_id = 1;
        let leader = cluster.leader_of_region(region_id).unwrap();
        let epoch = cluster.get_region_epoch(region_id);
        let mut ctx = Context::default();
        ctx.set_region_id(region_id);
        ctx.set_peer(leader);
        ctx.set_region_epoch(epoch);

        let mut req = PrewriteRequest::default();
        req.set_context(ctx);
        req.set_primary_lock(b"key".to_vec());
        let mut mutation = Mutation::default();
        mutation.set_op(Op::Put);
        mutation.set_key(b"key".to_vec());
        mutation.set_value(b"value".to_vec());
        req.mut_mutations().push(mutation);
        req.set_start_version(100);
        req.set_lock_ttl(20000);
        req.set_use_async_commit(true);
        client.kv_prewrite(&req).unwrap()
    };

    cluster.must_transfer_leader(1, new_peer(2, 2));
    fail::cfg("test_raftstore_get_tso", "return(50)").unwrap();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    let resp = do_prewrite(&mut cluster);
    assert!(resp.get_region_error().has_max_timestamp_not_synced());
    fail::remove("test_raftstore_get_tso");
    thread::sleep(Duration::from_millis(200));
    let resp = do_prewrite(&mut cluster);
    assert!(!resp.get_region_error().has_max_timestamp_not_synced());
}
fn u64toa_test() {
    let mut buffer = [b'\x00'; 32];
    unsafe {
        assert_eq!(5u64.decimal(&mut buffer), 1);
        assert_eq!(&buffer[..1], b"5");

        assert_eq!(11u64.decimal(&mut buffer), 2);
        assert_eq!(&buffer[..2], b"11");

        assert_eq!(99u64.decimal(&mut buffer), 2);
        assert_eq!(&buffer[..2], b"99");

        assert_eq!(101u64.decimal(&mut buffer), 3);
        assert_eq!(&buffer[..3], b"101");

        assert_eq!(999u64.decimal(&mut buffer), 3);
        assert_eq!(&buffer[..3], b"999");

        assert_eq!(1001u64.decimal(&mut buffer), 4);
        assert_eq!(&buffer[..4], b"1001");

        assert_eq!(9999u64.decimal(&mut buffer), 4);
        assert_eq!(&buffer[..4], b"9999");

        assert_eq!(10001u64.decimal(&mut buffer), 5);
        assert_eq!(&buffer[..5], b"10001");

        assert_eq!(65535u64.decimal(&mut buffer), 5);
        assert_eq!(&buffer[..5], b"65535");

        assert_eq!(99999u64.decimal(&mut buffer), 5);
        assert_eq!(&buffer[..5], b"99999");

        assert_eq!(100001u64.decimal(&mut buffer), 6);
        assert_eq!(&buffer[..6], b"100001");

        assert_eq!(999999u64.decimal(&mut buffer), 6);
        assert_eq!(&buffer[..6], b"999999");

        assert_eq!(1000001u64.decimal(&mut buffer), 7);
        assert_eq!(&buffer[..7], b"1000001");

        assert_eq!(9999999u64.decimal(&mut buffer), 7);
        assert_eq!(&buffer[..7], b"9999999");

        assert_eq!(10000001u64.decimal(&mut buffer), 8);
        assert_eq!(&buffer[..8], b"10000001");

        assert_eq!(99999999u64.decimal(&mut buffer), 8);
        assert_eq!(&buffer[..8], b"99999999");

        assert_eq!(100000001u64.decimal(&mut buffer), 9);
        assert_eq!(&buffer[..9], b"100000001");

        assert_eq!(999999999u64.decimal(&mut buffer), 9);
        assert_eq!(&buffer[..9], b"999999999");

        assert_eq!(1000000001u64.decimal(&mut buffer), 10);
        assert_eq!(&buffer[..10], b"1000000001");

        assert_eq!(9999999999u64.decimal(&mut buffer), 10);
        assert_eq!(&buffer[..10], b"9999999999");

        assert_eq!(10000000001u64.decimal(&mut buffer), 11);
        assert_eq!(&buffer[..11], b"10000000001");

        assert_eq!(99999999999u64.decimal(&mut buffer), 11);
        assert_eq!(&buffer[..11], b"99999999999");

        assert_eq!(100000000001u64.decimal(&mut buffer), 12);
        assert_eq!(&buffer[..12], b"100000000001");

        assert_eq!(999999999999u64.decimal(&mut buffer), 12);
        assert_eq!(&buffer[..12], b"999999999999");

        assert_eq!(1000000000001u64.decimal(&mut buffer), 13);
        assert_eq!(&buffer[..13], b"1000000000001");

        assert_eq!(9999999999999u64.decimal(&mut buffer), 13);
        assert_eq!(&buffer[..13], b"9999999999999");

        assert_eq!(10000000000001u64.decimal(&mut buffer), 14);
        assert_eq!(&buffer[..14], b"10000000000001");

        assert_eq!(99999999999999u64.decimal(&mut buffer), 14);
        assert_eq!(&buffer[..14], b"99999999999999");

        assert_eq!(100000000000001u64.decimal(&mut buffer), 15);
        assert_eq!(&buffer[..15], b"100000000000001");

        assert_eq!(999999999999999u64.decimal(&mut buffer), 15);
        assert_eq!(&buffer[..15], b"999999999999999");

        assert_eq!(1000000000000001u64.decimal(&mut buffer), 16);
        assert_eq!(&buffer[..16], b"1000000000000001");

        assert_eq!(9999999999999999u64.decimal(&mut buffer), 16);
        assert_eq!(&buffer[..16], b"9999999999999999");

        assert_eq!(10000000000000001u64.decimal(&mut buffer), 17);
        assert_eq!(&buffer[..17], b"10000000000000001");

        assert_eq!(99999999999999999u64.decimal(&mut buffer), 17);
        assert_eq!(&buffer[..17], b"99999999999999999");

        assert_eq!(100000000000000001u64.decimal(&mut buffer), 18);
        assert_eq!(&buffer[..18], b"100000000000000001");

        assert_eq!(999999999999999999u64.decimal(&mut buffer), 18);
        assert_eq!(&buffer[..18], b"999999999999999999");

        assert_eq!(1000000000000000001u64.decimal(&mut buffer), 19);
        assert_eq!(&buffer[..19], b"1000000000000000001");

        assert_eq!(9999999999999999999u64.decimal(&mut buffer), 19);
        assert_eq!(&buffer[..19], b"9999999999999999999");

        assert_eq!(10000000000000000001u64.decimal(&mut buffer), 20);
        assert_eq!(&buffer[..20], b"10000000000000000001");

        assert_eq!(18446744073709551615u64.decimal(&mut buffer), 20);
        assert_eq!(&buffer[..20], b"18446744073709551615");
    }
}
fn parse_create_table_with_defaults() {
    let sql = "CREATE TABLE public.customer (
            customer_id integer DEFAULT nextval(public.customer_customer_id_seq),
            store_id smallint NOT NULL,
            first_name character varying(45) NOT NULL,
            last_name character varying(45) COLLATE \"es_ES\" NOT NULL,
            email character varying(50),
            address_id smallint NOT NULL,
            activebool boolean DEFAULT true NOT NULL,
            create_date date DEFAULT now()::text NOT NULL,
            last_update timestamp without time zone DEFAULT now() NOT NULL,
            active int NOT NULL
    ) WITH (fillfactor = 20, user_catalog_table = true, autovacuum_vacuum_threshold = 100)";
    match pg_and_generic().one_statement_parses_to(sql, "") {
        Statement::CreateTable {
            name,
            columns,
            constraints,
            with_options,
            if_not_exists: false,
            external: false,
            file_format: None,
            location: None,
            ..
        } => {
            assert_eq!("public.customer", name.to_string());
            assert_eq!(
                columns,
                vec![
                    ColumnDef {
                        name: "customer_id".into(),
                        data_type: DataType::Integer(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::Default(
                                pg().verified_expr("nextval(public.customer_customer_id_seq)")
                            )
                        }],
                    },
                    ColumnDef {
                        name: "store_id".into(),
                        data_type: DataType::SmallInt(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull,
                        }],
                    },
                    ColumnDef {
                        name: "first_name".into(),
                        data_type: DataType::CharacterVarying(Some(CharacterLength {
                            length: 45,
                            unit: None
                        })),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull,
                        }],
                    },
                    ColumnDef {
                        name: "last_name".into(),
                        data_type: DataType::CharacterVarying(Some(CharacterLength {
                            length: 45,
                            unit: None
                        })),
                        collation: Some(ObjectName(vec![Ident::with_quote('"', "es_ES")])),
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull,
                        }],
                    },
                    ColumnDef {
                        name: "email".into(),
                        data_type: DataType::CharacterVarying(Some(CharacterLength {
                            length: 50,
                            unit: None
                        })),
                        collation: None,
                        options: vec![],
                    },
                    ColumnDef {
                        name: "address_id".into(),
                        data_type: DataType::SmallInt(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull
                        }],
                    },
                    ColumnDef {
                        name: "activebool".into(),
                        data_type: DataType::Boolean,
                        collation: None,
                        options: vec![
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Default(Expr::Value(Value::Boolean(true))),
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::NotNull,
                            }
                        ],
                    },
                    ColumnDef {
                        name: "create_date".into(),
                        data_type: DataType::Date,
                        collation: None,
                        options: vec![
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Default(
                                    pg().verified_expr("CAST(now() AS TEXT)")
                                )
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::NotNull,
                            }
                        ],
                    },
                    ColumnDef {
                        name: "last_update".into(),
                        data_type: DataType::Timestamp(None, TimezoneInfo::WithoutTimeZone),
                        collation: None,
                        options: vec![
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::Default(pg().verified_expr("now()")),
                            },
                            ColumnOptionDef {
                                name: None,
                                option: ColumnOption::NotNull,
                            }
                        ],
                    },
                    ColumnDef {
                        name: "active".into(),
                        data_type: DataType::Int(None),
                        collation: None,
                        options: vec![ColumnOptionDef {
                            name: None,
                            option: ColumnOption::NotNull
                        }],
                    },
                ]
            );
            assert!(constraints.is_empty());
            assert_eq!(
                with_options,
                vec![
                    SqlOption {
                        name: "fillfactor".into(),
                        value: number("20")
                    },
                    SqlOption {
                        name: "user_catalog_table".into(),
                        value: Value::Boolean(true)
                    },
                    SqlOption {
                        name: "autovacuum_vacuum_threshold".into(),
                        value: number("100")
                    },
                ]
            );
        }
        _ => unreachable!(),
    }
}
fn inverse_remainder_test() {
    assert_eq!(binary::inverse_remainder(0, 8), 0);
    assert_eq!(binary::inverse_remainder(1, 8), 7);
    assert_eq!(binary::inverse_remainder(2, 8), 6);
    assert_eq!(binary::inverse_remainder(3, 8), 5);
}
fn test_reboot() {
    let eps_count = 1;
    let server = MockServer::with_case(eps_count, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();
    let client = new_client(eps, None);

    assert!(!client.is_cluster_bootstrapped().unwrap());

    match client.bootstrap_cluster(metapb::Store::default(), metapb::Region::default()) {
        Err(PdError::ClusterBootstrapped(_)) => (),
        _ => {
            panic!("failed, should return ClusterBootstrapped");
        }
    }
}
fn mantissa_exponent_test() {
    assert_eq!(mantissa_exponent(10, 5, 0), 5);
    assert_eq!(mantissa_exponent(0, 5, 0), -5);
    assert_eq!(
        mantissa_exponent(i32::max_value(), 5, 0),
        i32::max_value() - 5
    );
    assert_eq!(mantissa_exponent(i32::max_value(), 0, 5), i32::max_value());
    assert_eq!(mantissa_exponent(i32::min_value(), 5, 0), i32::min_value());
    assert_eq!(
        mantissa_exponent(i32::min_value(), 0, 5),
        i32::min_value() + 5
    );
}
fn config_builder_for_server_rejects_empty_cipher_suites() {
    assert_eq!(
        ServerConfig::builder()
            .with_cipher_suites(&[])
            .with_safe_default_kx_groups()
            .with_safe_default_protocol_versions()
            .err(),
        Some(Error::General("no usable cipher suites configured".into()))
    );
}
fn test_float32() {
    let thing: f32 = 25.5;
    let yaml = indoc! {"
        25.5
    "};
    test_serde(&thing, yaml);

    let thing = f32::INFINITY;
    let yaml = indoc! {"
        .inf
    "};
    test_serde(&thing, yaml);

    let thing = f32::NEG_INFINITY;
    let yaml = indoc! {"
        -.inf
    "};
    test_serde(&thing, yaml);

    let single_float: f32 = serde_yaml::from_str(indoc! {"
        .nan
    "})
    .unwrap();
    assert!(single_float.is_nan());
}
fn test_split_suffix_length_short_concatenated_with_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_num_prefixed_chunks_by_lines";
    RandomFile::new(&at, name).add_lines(10000);
    ucmd.args(&["-a4", name]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]][[:alpha:]][[:alpha:]]$");
    assert_eq!(glob.count(), 10);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn fast_ceildiv_test() {
    assert_eq!(binary::fast_ceildiv(10, 4), 3);
    assert_eq!(binary::fast_ceildiv(10, 5), 2);
    assert_eq!(binary::fast_ceildiv(10, 6), 2);
    assert_eq!(binary::fast_ceildiv(0, 5), 0);
    assert_eq!(binary::fast_ceildiv(4, 5), 1);
    assert_eq!(binary::fast_ceildiv(5, 5), 1);
    assert_eq!(binary::fast_ceildiv(6, 5), 2);
    assert_eq!(binary::fast_ceildiv(9, 5), 2);
    assert_eq!(binary::fast_ceildiv(11, 5), 3);
}
fn truncate_and_round_test() {
    let truncate = Options::builder()
        .max_significant_digits(num::NonZeroUsize::new(4))
        .round_mode(RoundMode::Truncate)
        .build()
        .unwrap();
    let round = Options::builder()
        .max_significant_digits(num::NonZeroUsize::new(4))
        .round_mode(RoundMode::Round)
        .build()
        .unwrap();

    // Above halfway
    assert_eq!(binary::truncate_and_round(6602499140956772u64, 2, &round), (12, 53));
    assert_eq!(binary::truncate_and_round(6602499140956772u64, 2, &truncate), (11, 53));

    // At halfway
    assert_eq!(binary::truncate_and_round(6473924464345088u64, 2, &round), (12, 53));
    assert_eq!(binary::truncate_and_round(6473924464345088u64, 2, &truncate), (11, 53));

    // Below halfway.
    assert_eq!(binary::truncate_and_round(6473924464345087u64, 2, &round), (11, 53));
    assert_eq!(binary::truncate_and_round(6473924464345087u64, 2, &truncate), (11, 53));
}
fn passthrough_wrong_type() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (import "f" (func $f (param "a" (borrow $t)) (result (own $t))))

                (core func $f (canon lower (func $f)))

                (core module $m
                    (import "" "f" (func $f (param i32) (result i32)))
                    (func (export "f2") (param i32)
                        (drop (call $f (local.get 0)))
                    )
                )
                (core instance $i (instantiate $m
                    (with "" (instance
                        (export "f" (func $f))
                    ))
                ))

                (func (export "f2") (param "x" (borrow $t))
                    (canon lift (core func $i "f2")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
    linker
        .root()
        .func_wrap("f", |_cx, (r,): (Resource<MyType>,)| Ok((r,)))?;
    let i = linker.instantiate(&mut store, &c)?;

    let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f2")?;

    let resource = Resource::new_own(100);
    let err = f.call(&mut store, (&resource,)).unwrap_err();
    assert!(
        format!("{err:?}").contains("cannot lower a `borrow` resource into an `own`"),
        "bad error: {err:?}"
    );
    Ok(())
}
fn test_leader_drop_with_pessimistic_lock() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));

    let txn_ext = cluster
        .must_get_snapshot_of_region(1)
        .ext()
        .get_txn_ext()
        .unwrap()
        .clone();
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(
            Key::from_raw(b"k1"),
            PessimisticLock {
                primary: b"k1".to_vec().into_boxed_slice(),
                start_ts: 10.into(),
                ttl: 1000,
                for_update_ts: 10.into(),
                min_commit_ts: 10.into(),
                last_change_ts: 5.into(),
                versions_to_last_change: 3,
            },
        )])
        .unwrap();

    // Isolate node 1, leader should be transferred to another node.
    cluster.add_send_filter(IsolationFilterFactory::new(1));
    cluster.must_put(b"k1", b"v1");
    assert_ne!(cluster.leader_of_region(1).unwrap().id, 1);

    // When peer 1 becomes leader again, the pessimistic locks should be cleared
    // before.
    cluster.clear_send_filters();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    assert!(txn_ext.pessimistic_locks.read().is_empty());
}
fn test_split_separator_nul_line_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--line-bytes=4", "-t", "\\0", "separator_nul.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1\x002\0");
    assert_eq!(file_read(&at, "xab"), "3\x004\0");
    assert_eq!(file_read(&at, "xac"), "5\0");
    assert!(!at.plus("xad").exists());
}
async fn push_request_between_data() {
    h2_support::trace_init!();
    let (io, mut client) = mock::new();

    let client = async move {
        client
            .assert_server_handshake_with_settings(frames::settings().max_concurrent_streams(100))
            .await;
        client
            .send_frame(
                frames::headers(1)
                    .request("GET", "https://example.com/")
                    .eos(),
            )
            .await;
        client.recv_frame(frames::headers(1).response(200)).await;
        client.recv_frame(frames::data(1, &b""[..])).await;
        client
            .recv_frame(
                frames::push_promise(1, 2).request("GET", "https://http2.akamai.com/style.css"),
            )
            .await;
        client
            .recv_frame(frames::headers(2).response(200).eos())
            .await;
        client.recv_frame(frames::data(1, &b""[..]).eos()).await;
    };

    let srv = async move {
        let mut srv = server::handshake(io).await.expect("handshake");
        let (req, mut stream) = srv.next().await.unwrap().unwrap();

        assert_eq!(req.method(), &http::Method::GET);

        // Push response to stream 1 and send some data
        let mut s1_tx = {
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            let mut tx = stream.send_response(rsp, false).unwrap();
            tx.send_data(vec![0; 0].into(), false).unwrap();
            tx
        };

        // Promise stream 2 and push response headers
        {
            let pushed_req = http::Request::builder()
                .method("GET")
                .uri("https://http2.akamai.com/style.css")
                .body(())
                .unwrap();
            let rsp = http::Response::builder().status(200).body(()).unwrap();
            stream
                .push_request(pushed_req)
                .unwrap()
                .send_response(rsp, true)
                .unwrap();
        }

        // End response for stream 1
        s1_tx.send_data(vec![0; 0].into(), true).unwrap();

        assert!(srv.next().await.is_none());
    };

    join(client, srv).await;
}
fn fs_error_infinite_symlink_expansion_to_dirs() {
    let fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let root_path = temp_dir().join("lint_rome_test_infinite_symlink_expansion_to_dirs");
    let subdir1_path = root_path.join("prefix");
    let subdir2_path = root_path.join("foo").join("bar");

    let _ = remove_dir_all(&root_path);
    create_dir_all(&subdir1_path).unwrap();
    create_dir_all(&subdir2_path).unwrap();

    #[cfg(target_family = "unix")]
    {
        symlink(&subdir2_path, subdir1_path.join("symlink1")).unwrap();
        symlink(subdir1_path, subdir2_path.join("symlink2")).unwrap();
    }

    #[cfg(target_os = "windows")]
    {
        check_windows_symlink!(symlink_dir(&subdir2_path, &subdir1_path.join("symlink1")));
        check_windows_symlink!(symlink_dir(subdir1_path, subdir2_path.join("symlink2")));
    }

    let result = run_cli(
        DynRef::Owned(Box::new(OsFileSystem)),
        &mut console,
        Args::from([("lint"), (root_path.display().to_string().as_str())].as_slice()),
    );

    remove_dir_all(root_path).unwrap();

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_infinite_symlink_expansion_to_dirs",
        fs,
        console,
        result,
    ));
}
fn stdin_fix_when_no_issues_should_still_print_contents() {
    let args = ["--fix"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("import sys\n\nprint(sys.version)\n"), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    import sys

    print(sys.version)

    ----- stderr -----
    "###);
}
fn factor_test() {
  assert_eq!(
    factor("  3  ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("3")))
  );
}
fn parse_join_nesting() {
    let sql = "SELECT * FROM a NATURAL JOIN (b NATURAL JOIN (c NATURAL JOIN d NATURAL JOIN e)) \
               NATURAL JOIN (f NATURAL JOIN (g NATURAL JOIN h))";
    assert_eq!(
        only(&verified_only_select(sql).from).joins,
        vec![
            join(nest!(table("b"), nest!(table("c"), table("d"), table("e")))),
            join(nest!(table("f"), nest!(table("g"), table("h")))),
        ],
    );

    let sql = "SELECT * FROM (a NATURAL JOIN b) NATURAL JOIN c";
    let select = verified_only_select(sql);
    let from = only(select.from);
    assert_eq!(from.relation, nest!(table("a"), table("b")));
    assert_eq!(from.joins, vec![join(table("c"))]);

    let sql = "SELECT * FROM (((a NATURAL JOIN b)))";
    let select = verified_only_select(sql);
    let from = only(select.from);
    assert_eq!(from.relation, nest!(nest!(nest!(table("a"), table("b")))));
    assert_eq!(from.joins, vec![]);

    let sql = "SELECT * FROM a NATURAL JOIN (((b NATURAL JOIN c)))";
    let select = verified_only_select(sql);
    let from = only(select.from);
    assert_eq!(from.relation, table("a"));
    assert_eq!(
        from.joins,
        vec![join(nest!(nest!(nest!(table("b"), table("c")))))]
    );

    let sql = "SELECT * FROM (a NATURAL JOIN b) AS c";
    let select = verified_only_select(sql);
    let from = only(select.from);
    assert_eq!(
        from.relation,
        TableFactor::NestedJoin {
            table_with_joins: Box::new(TableWithJoins {
                relation: table("a"),
                joins: vec![join(table("b"))],
            }),
            alias: table_alias("c"),
        }
    );
    assert_eq!(from.joins, vec![]);
}
fn test_cjk_compat_variants_with_hangul() {
    assert_eq!(
        "ì¤‘êµ­ì–´ (í™ì½©)"
            .chars()
            .cjk_compat_variants()
            .collect::<String>(),
        "ì¤‘êµ­ì–´ (í™ì½©)"
    );
}

fn test_link_nonexistent_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_link_nonexistent_file";
    let link = "test_link_nonexistent_file_link";

    ucmd.args(&[file, link])
        .fails()
        .stderr_only("link: cannot create link 'test_link_nonexistent_file_link' to 'test_link_nonexistent_file': No such file or directory\n");
    assert!(!at.file_exists(file));
    assert!(!at.file_exists(link));
}
fn test_mantissa_rounding_overflow() {
    // This results in binary mantissa that is all ones and requires rounding up
    // because it is closer to 1 than to the next smaller float. This is a
    // regression test that the mantissa overflow is handled correctly by
    // increasing the exponent.
    assert_eq!(1.0, s2d(b"0.99999999999999999").unwrap());
    // This number overflows the mantissa *and* the IEEE exponent.
    assert_eq!(f64::INFINITY, s2d(b"1.7976931348623159e308").unwrap());
}
fn f64_roundtrip_test() {
    let mut buffer = [b'\x00'; BUFFER_SIZE];
    let options = Options::builder().build().unwrap();
    for &float in F64_DATA.iter() {
        let count = unsafe { algorithm::write_float::<_, DECIMAL>(float, &mut buffer, &options) };
        let actual = unsafe { std::str::from_utf8_unchecked(&buffer[..count]) };
        let roundtrip = actual.parse::<f64>();
        assert_eq!(roundtrip, Ok(float));
    }
}
fn parse_byte_literal() {
    let sql = r#"SELECT B'abc', B"abc""#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Value(Value::SingleQuotedByteStringLiteral("abc".to_string())),
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Value(Value::DoubleQuotedByteStringLiteral("abc".to_string())),
        expr_from_projection(&select.projection[1])
    );

    let sql = r#"SELECT b'abc', b"abc""#;
    bigquery().one_statement_parses_to(sql, r#"SELECT B'abc', B"abc""#);
}
fn bit_length_test() {
    let x: VecType = vec_from_u32(&[0, 0, 0, 1]);
    assert_eq!(bigint::bit_length(&x), 97);

    let x: VecType = vec_from_u32(&[0, 0, 0, 3]);
    assert_eq!(bigint::bit_length(&x), 98);

    let x = VecType::from_u64(1 << 31);
    assert_eq!(bigint::bit_length(&x), 32);
}
fn parse_variable_tag_math_with_filters_and_logic_expression() {
    let ast = parse("{{ count + 1 * 2.5 | round and admin }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Logic(LogicExpr {
                lhs: Box::new(Expr::with_filters(
                    ExprVal::Math(MathExpr {
                        lhs: Box::new(Expr::new(ExprVal::Ident("count".to_string()))),
                        operator: MathOperator::Add,
                        rhs: Box::new(Expr::new(ExprVal::Math(MathExpr {
                            lhs: Box::new(Expr::new(ExprVal::Int(1))),
                            operator: MathOperator::Mul,
                            rhs: Box::new(Expr::new(ExprVal::Float(2.5))),
                        },))),
                    },),
                    vec![FunctionCall { name: "round".to_string(), args: HashMap::new() },],
                )),
                operator: LogicOperator::And,
                rhs: Box::new(Expr::new(ExprVal::Ident("admin".to_string()))),
            },))
        )
    );
}
fn test_kill_with_signal_prefixed_name_old_form() {
    let mut target = Target::new();
    new_ucmd!()
        .arg("-SIGKILL")
        .arg(format!("{}", target.pid()))
        .succeeds();
    assert_eq!(target.wait_for_signal(), Some(libc::SIGKILL));
}
fn normal_cases() {
    assert_eq!(libm::powd(2.0, 20.0), (1 << 20) as f64);
    assert_eq!(libm::powd(-1.0, 9.0), -1.0);
    assert!(libm::powd(-1.0, 2.2).is_nan());
    assert!(libm::powd(-1.0, -1.14).is_nan());
}
fn ok_many_variable_blocks() {
    let mut context = Context::new();
    context.insert("username", &"bob");

    let mut tpl = String::new();
    for _ in 0..200 {
        tpl.push_str("{{ username }}")
    }
    let mut expected = String::new();
    for _ in 0..200 {
        expected.push_str("bob")
    }
    assert_eq!(render_template(&tpl, &context).unwrap(), expected);
}
fn test_region_split() {
    let cluster = new_server_cluster(1, 1);
    cluster.pd_client.disable_default_operator();
    let mut suite = TestSuiteBuilder::new().cluster(cluster).build();

    let region = suite.cluster.get_region(&[]);
    let mut req = suite.new_changedata_request(region.get_id());
    let (mut req_tx, event_feed_wrap, receive_event) =
        new_event_feed(suite.get_region_cdc_client(region.get_id()));
    block_on(req_tx.send((req.clone(), WriteFlags::default()))).unwrap();
    // Make sure region 1 is registered.
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1);
    match events.pop().unwrap().event.unwrap() {
        // Even if there is no write,
        // it should always outputs an Initialized event.
        Event_oneof_event::Entries(es) => {
            assert!(es.entries.len() == 1, "{:?}", es);
            let e = &es.entries[0];
            assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
        }
        other => panic!("unknown event {:?}", other),
    }
    // Split region.
    suite.cluster.must_split(&region, b"k0");
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1);
    match events.pop().unwrap().event.unwrap() {
        Event_oneof_event::Error(err) => {
            assert!(err.has_epoch_not_match(), "{:?}", err);
        }
        other => panic!("unknown event {:?}", other),
    }
    // Try to subscribe region again.
    let region = suite.cluster.get_region(b"k0");
    // Ensure it is the previous region.
    assert_eq!(req.get_region_id(), region.get_id());
    req.set_region_epoch(region.get_region_epoch().clone());
    block_on(req_tx.send((req.clone(), WriteFlags::default()))).unwrap();
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1);
    match events.pop().unwrap().event.unwrap() {
        Event_oneof_event::Entries(es) => {
            assert!(es.entries.len() == 1, "{:?}", es);
            let e = &es.entries[0];
            assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
        }
        other => panic!("unknown event {:?}", other),
    }

    // Try to subscribe region again.
    let region1 = suite.cluster.get_region(&[]);
    req.region_id = region1.get_id();
    req.set_region_epoch(region1.get_region_epoch().clone());
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();
    let mut events = receive_event(false).events.to_vec();
    assert_eq!(events.len(), 1);
    match events.pop().unwrap().event.unwrap() {
        Event_oneof_event::Entries(es) => {
            assert!(es.entries.len() == 1, "{:?}", es);
            let e = &es.entries[0];
            assert_eq!(e.get_type(), EventLogType::Initialized, "{:?}", es);
        }
        other => panic!("unknown event {:?}", other),
    }

    // Make sure resolved ts can be advanced normally.
    let mut counter = 0;
    let mut previous_ts = 0;
    loop {
        // Even if there is no write,
        // resolved ts should be advanced regularly.
        let event = receive_event(true);
        if let Some(resolved_ts) = event.resolved_ts.as_ref() {
            assert!(resolved_ts.ts >= previous_ts);
            assert!(
                resolved_ts.regions == vec![region.id, region1.id]
                    || resolved_ts.regions == vec![region1.id, region.id]
            );
            previous_ts = resolved_ts.ts;
            counter += 1;
        }
        if counter > 5 {
            break;
        }
    }

    event_feed_wrap.replace(None);
    suite.stop();
}
fn test_rm_prompts() {
    use std::io::Write;

    // Needed for talking with stdin on platforms where CRLF or LF matters
    const END_OF_LINE: &str = if cfg!(windows) { "\r\n" } else { "\n" };

    let mut answers = [
        "rm: descend into directory 'a'?",
        "rm: remove write-protected regular empty file 'a/empty-no-write'?",
        "rm: remove symbolic link 'a/slink'?",
        "rm: remove symbolic link 'a/slink-dot'?",
        "rm: remove write-protected regular file 'a/f-no-write'?",
        "rm: remove regular empty file 'a/empty'?",
        "rm: remove directory 'a/b'?",
        "rm: remove write-protected directory 'a/b-no-write'?",
        "rm: remove directory 'a'?",
    ];

    answers.sort();

    let yes = format!("y{END_OF_LINE}");

    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    at.mkdir("a/");

    let file_1 = "a/empty";
    let file_2 = "a/empty-no-write";
    let file_3 = "a/f-no-write";

    at.touch(file_1);
    at.touch(file_2);
    at.make_file(file_3)
        .write_all(b"not-empty")
        .expect("Couldn't write to a/f-no-write");

    at.symlink_dir("a/empty-f", "a/slink");
    at.symlink_dir(".", "a/slink-dot");

    let dir_1 = "a/b/";
    let dir_2 = "a/b-no-write/";

    at.mkdir(dir_1);
    at.mkdir(dir_2);

    scene
        .ccmd("chmod")
        .arg("u-w")
        .arg(file_3)
        .arg(dir_2)
        .arg(file_2)
        .succeeds();

    let mut child = scene
        .ucmd()
        .set_stdin(Stdio::piped())
        .arg("-ri")
        .arg("a")
        .run_no_wait();
    for _ in 0..9 {
        child.try_write_in(yes.as_bytes()).unwrap();
    }

    let result = child.wait().unwrap();

    let mut trimmed_output = Vec::new();
    for string in result.stderr_str().split("rm: ") {
        if !string.is_empty() {
            let trimmed_string = format!("rm: {string}").trim().to_string();
            trimmed_output.push(trimmed_string);
        }
    }

    trimmed_output.sort();

    assert_eq!(trimmed_output.len(), answers.len());

    for (i, checking_string) in trimmed_output.iter().enumerate() {
        assert_eq!(checking_string, answers[i]);
    }

    assert!(!at.dir_exists("a"));
}
fn fix_only_flag_applies_safe_fixes_by_default() {
    assert_cmd_snapshot!(
        Command::new(get_cargo_bin(BIN_NAME))
            .args([
                "-",
                "--output-format",
                "text",
                "--isolated",
                "--no-cache",
                "--select",
                "F601,UP034",
                "--fix-only",
            ])
            .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    x = {'a': 1, 'a': 1}
    print('foo')

    ----- stderr -----
    Fixed 1 error (1 additional fix available with `--unsafe-fixes`).
    "###);
}
fn does_not_handle_ignored_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "include": ["test.js", "special/**"]
  },
  "overrides": [{ "ignore": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNFORMATTED.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--write"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, UNFORMATTED);
    assert_file_contents(&fs, test, FORMATTED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_ignored_file",
        fs,
        console,
        result,
    ));
}
fn test_json_pointer() {
    // Test case taken from https://tools.ietf.org/html/rfc6901#page-5
    let data: Value = from_str(
        r#"{
        "foo": ["bar", "baz"],
        "": 0,
        "a/b": 1,
        "c%d": 2,
        "e^f": 3,
        "g|h": 4,
        "i\\j": 5,
        "k\"l": 6,
        " ": 7,
        "m~n": 8
    }"#,
    )
    .unwrap();
    assert_eq!(data.pointer("").unwrap(), &data);
    assert_eq!(data.pointer("/foo").unwrap(), &json!(["bar", "baz"]));
    assert_eq!(data.pointer("/foo/0").unwrap(), &json!("bar"));
    assert_eq!(data.pointer("/").unwrap(), &json!(0));
    assert_eq!(data.pointer("/a~1b").unwrap(), &json!(1));
    assert_eq!(data.pointer("/c%d").unwrap(), &json!(2));
    assert_eq!(data.pointer("/e^f").unwrap(), &json!(3));
    assert_eq!(data.pointer("/g|h").unwrap(), &json!(4));
    assert_eq!(data.pointer("/i\\j").unwrap(), &json!(5));
    assert_eq!(data.pointer("/k\"l").unwrap(), &json!(6));
    assert_eq!(data.pointer("/ ").unwrap(), &json!(7));
    assert_eq!(data.pointer("/m~0n").unwrap(), &json!(8));
    // Invalid pointers
    assert!(data.pointer("/unknown").is_none());
    assert!(data.pointer("/e^f/ertz").is_none());
    assert!(data.pointer("/foo/00").is_none());
    assert!(data.pointer("/foo/01").is_none());
}
fn test_error_in_child_template_location() {
    let result = render_tpl("error-location/error_in_child.html");

    assert!(result.is_err());
    let errs = result.unwrap_err();
    assert_eq!(errs.to_string(), "Failed to render 'error-location/error_in_child.html'");
}
fn test_read_lock_after_become_follower() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_heartbeat_ticks = 20;
    cluster.run();

    let region_id = 1;
    cluster.must_transfer_leader(1, new_peer(3, 3));

    let start_ts = block_on(cluster.pd_client.get_tso()).unwrap();

    // put kv after get start ts, then this commit will cause a
    // PessimisticLockNotFound if the pessimistic lock get missing.
    cluster.must_put(b"key", b"value");

    let leader = cluster.leader_of_region(region_id).unwrap();
    let snapshot = cluster.must_get_snapshot_of_region(region_id);
    let txn_ext = snapshot.txn_ext.unwrap();
    let for_update_ts = block_on(cluster.pd_client.get_tso()).unwrap();
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![(
            Key::from_raw(b"key"),
            PessimisticLock {
                primary: b"key".to_vec().into_boxed_slice(),
                start_ts,
                ttl: 1000,
                for_update_ts,
                min_commit_ts: for_update_ts,
                last_change_ts: start_ts.prev(),
                versions_to_last_change: 1,
            },
        )])
        .unwrap();

    let addr = cluster.sim.rl().get_addr(3);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env).connect(&addr);
    let client = TikvClient::new(channel);

    let mut req = PrewriteRequest::default();
    let mut ctx = Context::default();
    ctx.set_region_id(region_id);
    ctx.set_region_epoch(cluster.get_region_epoch(region_id));
    ctx.set_peer(leader);
    req.set_context(ctx);
    req.set_primary_lock(b"key".to_vec());
    let mut mutation = Mutation::default();
    mutation.set_op(Op::Put);
    mutation.set_key(b"key".to_vec());
    mutation.set_value(b"value2".to_vec());
    req.mut_mutations().push(mutation);
    req.set_start_version(start_ts.into_inner());
    req.set_lock_ttl(20000);

    // Pause the command before it executes prewrite.
    fail::cfg("txn_before_process_write", "pause").unwrap();
    let (tx, resp_rx) = mpsc::channel();
    thread::spawn(move || tx.send(client.kv_prewrite(&req).unwrap()).unwrap());

    thread::sleep(Duration::from_millis(200));
    resp_rx.try_recv().unwrap_err();

    // And pause applying the write on the leader.
    fail::cfg("on_apply_write_cmd", "pause").unwrap();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    thread::sleep(Duration::from_millis(200));

    // Transfer leader will not make the command fail.
    fail::remove("txn_before_process_write");
    let resp = resp_rx.recv().unwrap();
    // The term has changed, so we should get a stale command error instead a
    // PessimisticLockNotFound.
    assert!(resp.get_region_error().has_stale_command());
}
fn u16_pow2_test() {
    let values: &[u16] = &[
        0, 1, 2, 3, 4, 5, 7, 8, 9, 15, 16, 17, 31, 32, 33, 63, 64, 65, 127, 128, 129, 255, 256,
        257, 511, 512, 513, 1023, 1024, 1025, 2047, 2048, 2049, 4095, 4096, 4097, 8191, 8192, 8193,
        16383, 16384, 16385, 32767, 32768, 32769, 65535,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn nursery_group_selector() {
    // Only nursery rules should be detected e.g. E225 and a warning should be displayed
    let args = ["--select", "NURSERY"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: CPY001 Missing copyright notice at top of file
    -:1:2: E225 Missing whitespace around operator
    Found 2 errors.

    ----- stderr -----
    warning: The `NURSERY` selector has been deprecated. Use the `--preview` flag instead.
    "###);
}
fn can_set_variable_in_global_context_in_forloop() {
    let mut context = Context::new();
    context.insert("tags", &vec![1, 2, 3]);
    context.insert("default", &"default");

    let result = render_template(
        r#"
{%- for i in tags -%}
{%- set default = 1 -%}
{%- set_global global_val = i -%}
{%- endfor -%}
{{ default }}{{ global_val }}"#,
        &context,
    );

    assert_eq!(result.unwrap(), "default3");
}
fn parse_filter_section_preserves_ws() {
    let ast = parse("{% filter upper %}  {{a}}  B  {% endfilter %}").unwrap();

    assert_eq!(
        ast[0],
        Node::FilterSection(
            WS::default(),
            FilterSection {
                filter: FunctionCall { name: "upper".to_string(), args: HashMap::new() },
                body: vec![
                    Node::Text("  ".to_string()),
                    Node::VariableBlock(WS::default(), Expr::new(ExprVal::Ident("a".to_string()))),
                    Node::Text("  B  ".to_string())
                ]
            },
            WS::default(),
        )
    );
}
fn test_raw_invalid_utf8() {
    let j = &[b'"', b'\xCE', b'\xF8', b'"'];
    let value_err = serde_json::from_slice::<Value>(j).unwrap_err();
    let raw_value_err = serde_json::from_slice::<Box<RawValue>>(j).unwrap_err();

    assert_eq!(
        value_err.to_string(),
        "invalid unicode code point at line 1 column 4",
    );
    assert_eq!(
        raw_value_err.to_string(),
        "invalid unicode code point at line 1 column 4",
    );
}
fn handshake_1rtt_handling() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let client_ch = pair.begin_connect(client_config());
    pair.drive_client();
    pair.drive_server();
    let server_ch = pair.server.assert_accept();
    // Server now has 1-RTT keys, but remains in Handshake state until the TLS CFIN has
    // authenticated the client. Delay the final client handshake flight so that doesn't happen yet.
    pair.client.drive(pair.time, pair.server.addr);
    pair.client.delay_outbound();

    // Send some 1-RTT data which will be received first.
    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();
    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.client_send(client_ch, s).finish().unwrap();
    pair.client.drive(pair.time, pair.server.addr);

    // Add the handshake flight back on.
    pair.client.finish_delay();

    pair.drive();

    assert!(pair.client_conn_mut(client_ch).lost_packets() != 0);
    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(
        chunks.next(usize::MAX),
        Ok(Some(chunk)) if chunk.offset == 0 && chunk.bytes == MSG
    );
    let _ = chunks.finalize();
}
fn test_cp_sparse_always_non_empty() {
    let (at, mut ucmd) = at_and_ucmd!();

    const BUFFER_SIZE: usize = 4096 * 16 + 3;
    let mut buf: [u8; BUFFER_SIZE] = [0; BUFFER_SIZE];
    let blocks_to_touch = [buf.len() / 3, 2 * (buf.len() / 3)];

    for i in blocks_to_touch {
        buf[i] = b'x';
    }

    at.make_file("src_file1");
    at.write_bytes("src_file1", &buf);

    ucmd.args(&["--sparse=always", "src_file1", "dst_file_sparse"])
        .succeeds();

    let touched_block_count =
        blocks_to_touch.len() as u64 * at.metadata("dst_file_sparse").blksize() / 512;

    assert_eq!(at.read_bytes("dst_file_sparse"), buf);
    assert_eq!(at.metadata("dst_file_sparse").blocks(), touched_block_count);
}
fn handle_ws_both_sides_for_forloop_tag_and_remove_empty_node() {
    let start_ws = WS { left: true, right: true };
    let end_ws = WS { left: true, right: true };
    let ast = vec![
        Node::Forloop(
            start_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::new(ExprVal::Int(1)),
                // not valid but we don't care about it here
                body: vec![Node::Text("   ".to_string()), Node::Text("hey   ".to_string())],
                empty_body: None,
            },
            end_ws,
        ),
        Node::Text("  hey".to_string()),
    ];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![
            Node::Forloop(
                start_ws,
                Forloop {
                    key: None,
                    value: "item".to_string(),
                    container: Expr::new(ExprVal::Int(1)),
                    // not valid but we don't care about it here
                    body: vec![Node::Text("hey".to_string())],
                    empty_body: None,
                },
                end_ws,
            ),
            Node::Text("hey".to_string()),
        ]
    );
}
fn junk_is_other() {
  assert_eq!(stdout("refs/tags/asdf"), "::set-output name=value::other\n");
}
fn simple() {
    // mimic `enhanced-resolve/test/simple.test.js`
    let dirname = env::current_dir().unwrap().join("fixtures");
    let f = dirname.join("enhanced_resolve/test");

    let resolver = Resolver::default();

    let data = [
        ("direct", f.clone(), "../lib/index"),
        ("as directory", f, ".."),
        ("as module", dirname.clone(), "./enhanced_resolve"),
    ];

    for (comment, path, request) in data {
        let resolved_path = resolver.resolve(&path, request).map(|f| f.full_path());
        let expected = dirname.join("enhanced_resolve/lib/index.js");
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn safe_filter_works() {
    struct Safe;
    impl crate::Filter for Safe {
        fn filter(&self, value: &Value, _args: &HashMap<String, Value>) -> Result<Value> {
            Ok(Value::String(format!("<div>{}</div>", value.as_str().unwrap())))
        }

        fn is_safe(&self) -> bool {
            true
        }
    }

    let mut tera = Tera::default();
    tera.register_filter("safe_filter", Safe);
    tera.add_raw_template("test.html", r#"{{ "Hello" | safe_filter }}"#).unwrap();

    let res = tera.render("test.html", &Context::new());
    assert_eq!(res.unwrap(), "<div>Hello</div>");
}
fn test_split_num_prefixed_chunks_by_lines() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_num_prefixed_chunks_by_lines";
    RandomFile::new(&at, name).add_lines(10000);
    ucmd.args(&["-d", "-l", "1000", name, "c"]).succeeds();

    let glob = Glob::new(&at, ".", r"c\d\d$");
    assert_eq!(glob.count(), 10);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_expression() {
    let env = Environment::new();
    let expr = env.compile_expression("foo + bar").unwrap();
    let mut ctx = BTreeMap::new();
    ctx.insert("foo", 42);
    ctx.insert("bar", 23);
    assert_eq!(expr.eval(&ctx).unwrap(), Value::from(65));
}
fn test_pat_size() {
    assert_eq!(mem::size_of::<Pat>(), 184);
}
fn test_ignore_equal_var() {
    let scene = TestScenario::new(util_name!());
    // tested by gnu/tests/misc/printenv.sh
    let result = scene.ucmd().env("a=b", "c").arg("a=b").fails();

    assert!(result.stdout_str().is_empty());
}
fn fill_externref_tables_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    let table_ty = TableType::new(ValType::ExternRef, 10, None);
    let table = Table::new(&mut store, table_ty, Val::ExternRef(None))?;

    for i in 0..10 {
        assert!(table
            .get(&mut store, i)
            .unwrap()
            .unwrap_externref()
            .is_none());
    }

    table.fill(
        &mut store,
        2,
        Val::ExternRef(Some(ExternRef::new(42_usize))),
        4,
    )?;

    for i in (0..2).chain(7..10) {
        assert!(table
            .get(&mut store, i)
            .unwrap()
            .unwrap_externref()
            .is_none());
    }
    for i in 2..6 {
        assert_eq!(
            *table
                .get(&mut store, i)
                .unwrap()
                .unwrap_externref()
                .unwrap()
                .data()
                .downcast_ref::<usize>()
                .unwrap(),
            42
        );
    }

    Ok(())
}
fn parse_variable_tag_ident() {
    let ast = parse("{{ id }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(WS::default(), Expr::new(ExprVal::Ident("id".to_string()))),
    );
}
fn valid_version_with_lots_of_digits_is_release() {
  assert_eq!(
    stdout("refs/tags/01232132.098327498374.43268473849734"),
    "::set-output name=value::release\n"
  );
}
fn test_something() {
    let data = [];
    let len = data.buf.len();
    let supported_versions = DEFAULT_SUPPORTED_VERSIONS.to_vec();
    if let Ok(decoded) = PartialDecode::new(
        data.buf,
        data.local_cid_len,
        &supported_versions,
        data.grease_quic_bit,
    ) {
        match decoded.1 {
            Some(x) => assert_eq!(len, decoded.0.len() + x.len()),
            None => assert_eq!(len, decoded.0.len()),
        }
    }
}
fn test_keep_trailing_newlines() {
    let mut env = Environment::new();
    env.add_template("foo.txt", "blub\r\n").unwrap();
    assert_eq!(env.render_str("blub\r\n", ()).unwrap(), "blub");

    env.set_keep_trailing_newline(true);
    env.add_template("foo_keep.txt", "blub\r\n").unwrap();
    assert_eq!(
        env.get_template("foo.txt").unwrap().render(()).unwrap(),
        "blub"
    );
    assert_eq!(
        env.get_template("foo_keep.txt")
            .unwrap()
            .render(())
            .unwrap(),
        "blub\r\n"
    );
    assert_eq!(env.render_str("blub\r\n", ()).unwrap(), "blub\r\n");
}
fn last_block_with_subsidy() {
  assert_eq!(
    CommandBuilder::new("subsidy 6929999").run_and_deserialize_output::<Output>(),
    Output {
      first: 2099999997689999,
      subsidy: 1,
      name: "a".into(),
    }
  );
}
fn test_mv_custom_backup_suffix_hyphen_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_custom_backup_suffix_file_a";
    let file_b = "test_mv_custom_backup_suffix_file_b";
    let suffix = "-v";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("-b")
        .arg(format!("--suffix={suffix}"))
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn test_symlink_backup_numbering() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_backup_numbering";
    let link = "test_symlink_backup_numbering_link";

    at.touch(file);
    at.symlink_file(file, link);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    ucmd.args(&["-s", "--backup=t", file, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file));

    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let backup = &format!("{link}.~1~");
    assert!(at.is_symlink(backup));
    assert_eq!(at.resolve_link(backup), file);
}
fn unsigned_float_test() {
    assert_eq!(unsigned_float(&b"123.456;"[..]), Ok((&b";"[..], 123.456)));
    assert_eq!(unsigned_float(&b"0.123;"[..]), Ok((&b";"[..], 0.123)));
    assert_eq!(unsigned_float(&b"123.0;"[..]), Ok((&b";"[..], 123.0)));
    assert_eq!(unsigned_float(&b"123.;"[..]), Ok((&b";"[..], 123.0)));
    assert_eq!(unsigned_float(&b".123;"[..]), Ok((&b";"[..], 0.123)));
}
fn connect_detects_mtu() {
    let _guard = subscribe();
    let max_udp_payload_and_expected_mtu = &[(1200, 1200), (1400, 1389), (1500, 1452)];

    for &(pair_max_udp, expected_mtu) in max_udp_payload_and_expected_mtu {
        println!("Trying {pair_max_udp}");
        let mut pair = Pair::default();
        pair.mtu = pair_max_udp;
        let (client_ch, server_ch) = pair.connect();
        pair.drive();

        assert_eq!(pair.client_conn_mut(client_ch).path_mtu(), expected_mtu);
        assert_eq!(pair.server_conn_mut(server_ch).path_mtu(), expected_mtu);
    }
}
fn test_split_region_keep_records() {
    let mut cluster = test_raftstore_v2::new_node_cluster(0, 3);
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();
    let r1 = cluster.run_conf_change();
    cluster.must_put(b"k1", b"v1");
    pd_client.must_add_peer(r1, new_peer(2, 2));
    must_get_equal(&cluster.get_engine(2), b"k1", b"v1");
    pd_client.must_remove_peer(r1, new_peer(2, 2));

    let leader = cluster.leader_of_region(r1).unwrap();
    cluster.add_send_filter_on_node(
        leader.get_store_id(),
        Box::new(DropMessageFilter::new(Arc::new(|m: &RaftMessage| {
            // Drop all gc peer requests and responses.
            !(m.has_extra_msg()
                && (m.get_extra_msg().get_type() == ExtraMessageType::MsgGcPeerRequest
                    || m.get_extra_msg().get_type() == ExtraMessageType::MsgGcPeerResponse))
        }))),
    );

    // Make sure split has applied.
    let region = pd_client.get_region(b"").unwrap();
    cluster.must_split(&region, b"k1");
    cluster.must_put(b"k2", b"v2");
    cluster.must_put(b"k0", b"v0");

    let region_state = cluster.region_local_state(r1, leader.get_store_id());
    assert!(
        !region_state.get_removed_records().is_empty(),
        "{:?}",
        region_state
    );
}
fn test_mvcc_concurrent_commit_and_rollback_at_shutdown() {
    let (mut cluster, mut client, mut ctx) = must_new_cluster_and_kv_client_mul(3);
    let k = b"key".to_vec();
    // Use big value to force it in default cf.
    let v = vec![0; 10240];

    let mut ts = 0;

    // Prewrite
    ts += 1;
    let prewrite_start_version = ts;
    let mut mutation = kvrpcpb::Mutation::default();
    mutation.set_op(Op::Put);
    mutation.set_key(k.clone());
    mutation.set_value(v.clone());
    must_kv_prewrite(
        &client,
        ctx.clone(),
        vec![mutation],
        k.clone(),
        prewrite_start_version,
    );

    // So all following operation will not be committed by this leader.
    let leader_fp = "before_leader_handle_committed_entries";
    fail::cfg(leader_fp, "pause").unwrap();

    // Commit
    ts += 1;
    let commit_version = ts;
    let mut commit_req = CommitRequest::default();
    commit_req.set_context(ctx.clone());
    commit_req.start_version = prewrite_start_version;
    commit_req.mut_keys().push(k.clone());
    commit_req.commit_version = commit_version;
    let _commit_resp = client.kv_commit_async(&commit_req).unwrap();

    // Rollback
    let rollback_start_version = prewrite_start_version;
    let mut rollback_req = BatchRollbackRequest::default();
    rollback_req.set_context(ctx.clone());
    rollback_req.start_version = rollback_start_version;
    rollback_req.mut_keys().push(k.clone());
    let _rollback_resp = client.kv_batch_rollback_async(&rollback_req).unwrap();

    // Sleep some time to make sure both commit and rollback are queued in latch.
    thread::sleep(Duration::from_millis(100));
    let shutdown_fp = "after_shutdown_apply";
    fail::cfg_callback(shutdown_fp, move || {
        fail::remove(leader_fp);
        // Sleep some time to ensure all logs can be replicated.
        thread::sleep(Duration::from_millis(300));
    })
    .unwrap();
    let mut leader = cluster.leader_of_region(1).unwrap();
    cluster.stop_node(leader.get_store_id());

    // So a new leader should be elected.
    cluster.must_put(b"k2", b"v2");
    leader = cluster.leader_of_region(1).unwrap();
    ctx.set_peer(leader.clone());
    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    client = TikvClient::new(channel);

    // The first request is commit, the second is rollback, the first one should
    // succeed.
    ts += 1;
    let get_version = ts;
    let mut get_req = GetRequest::default();
    get_req.set_context(ctx);
    get_req.key = k;
    get_req.version = get_version;
    let get_resp = client.kv_get(&get_req).unwrap();
    assert!(
        !get_resp.has_region_error() && !get_resp.has_error(),
        "{:?}",
        get_resp
    );
    assert_eq!(get_resp.value, v);
}
fn test_struct_object() {
    struct X;

    impl StructObject for X {
        fn get_field(&self, name: &str) -> Option<Value> {
            match name {
                "a" => Some(Value::from(1)),
                "b" => Some(Value::from(2)),
                _ => None,
            }
        }
        fn static_fields(&self) -> Option<&'static [&'static str]> {
            Some(&["a", "b"])
        }
    }

    let v = BTreeMap::<String, i32>::deserialize(Value::from_struct_object(X)).unwrap();
    assert_eq!(
        v,
        BTreeMap::from_iter([("a".to_string(), 1), ("b".to_string(), 2)])
    );
}
fn f64_test() {
    assert_eq!(
        (184467440737095500000.0, b!("\x00\x00006")),
        parse_float::<f64>(b"000184467440737095516150\x00\x00006")
    );
}
fn test_ingest_sst_v2() {
    let mut cluster = test_raftstore_v2::new_server_cluster(1, 1);
    let (ctx, _tikv, import) = open_cluster_and_tikv_import_client_v2(None, &mut cluster);
    let temp_dir = Builder::new().prefix("test_ingest_sst").tempdir().unwrap();
    let sst_path = temp_dir.path().join("test.sst");
    let sst_range = (0, 100);
    let (mut meta, data) = gen_sst_file(sst_path, sst_range);

    // No region id and epoch.
    send_upload_sst(&import, &meta, &data).unwrap();
    let mut ingest = IngestRequest::default();
    ingest.set_context(ctx.clone());
    ingest.set_sst(meta.clone());
    meta.set_region_id(ctx.get_region_id());
    meta.set_region_epoch(ctx.get_region_epoch().clone());
    send_upload_sst(&import, &meta, &data).unwrap();
    ingest.set_sst(meta);
    let resp = import.ingest(&ingest).unwrap();
    assert!(!resp.has_error(), "{:?}", resp.get_error());
    fail::cfg("on_cleanup_import_sst", "return").unwrap();
    let (tx, rx) = channel::<()>();
    let tx = Arc::new(Mutex::new(tx));
    fail::cfg_callback("on_cleanup_import_sst_schedule", move || {
        tx.lock().unwrap().send(()).unwrap();
    })
    .unwrap();

    rx.recv_timeout(std::time::Duration::from_secs(20)).unwrap();
    let mut count = 0;
    for path in &cluster.paths {
        let sst_dir = path.path().join("import-sst");
        for entry in std::fs::read_dir(sst_dir).unwrap() {
            let entry = entry.unwrap();
            if entry.file_type().unwrap().is_file() {
                count += 1;
            }
        }
    }
    fail::remove("on_cleanup_import_sst");
    fail::remove("on_cleanup_import_sst_schedule");
    assert_ne!(0, count);
}
fn test_convert_debug_info() {
    // Convert existing sections
    let debug_abbrev = read_section("debug_abbrev");
    let debug_abbrev = read::DebugAbbrev::new(&debug_abbrev, LittleEndian);

    let debug_info = read_section("debug_info");
    let debug_info = read::DebugInfo::new(&debug_info, LittleEndian);

    let debug_line = read_section("debug_line");
    let debug_line = read::DebugLine::new(&debug_line, LittleEndian);

    let debug_str = read_section("debug_str");
    let debug_str = read::DebugStr::new(&debug_str, LittleEndian);

    let debug_ranges = read_section("debug_ranges");
    let debug_ranges = read::DebugRanges::new(&debug_ranges, LittleEndian);

    let debug_rnglists = read::DebugRngLists::new(&[], LittleEndian);

    let ranges = gimli::RangeLists::new(debug_ranges, debug_rnglists);

    let debug_loc = read_section("debug_loc");
    let debug_loc = read::DebugLoc::new(&debug_loc, LittleEndian);

    let debug_loclists = read::DebugLocLists::new(&[], LittleEndian);

    let locations = gimli::LocationLists::new(debug_loc, debug_loclists);

    let dwarf = read::Dwarf {
        debug_abbrev,
        debug_info,
        debug_line,
        debug_str,
        ranges,
        locations,
        ..Default::default()
    };

    let mut dwarf = write::Dwarf::from(&dwarf, &|address| Some(Address::Constant(address)))
        .expect("Should convert DWARF information");

    assert_eq!(dwarf.units.count(), 23);
    let entries: usize = (0..dwarf.units.count())
        .map(|i| dwarf.units.get(dwarf.units.id(i)).count())
        .sum();
    assert_eq!(entries, 29_560);
    assert_eq!(dwarf.line_strings.count(), 0);
    assert_eq!(dwarf.strings.count(), 3921);

    // Write to new sections
    let mut write_sections = write::Sections::new(EndianVec::new(LittleEndian));
    dwarf
        .write(&mut write_sections)
        .expect("Should write DWARF information");
    let debug_info_data = write_sections.debug_info.slice();
    let debug_abbrev_data = write_sections.debug_abbrev.slice();
    let debug_line_data = write_sections.debug_line.slice();
    let debug_ranges_data = write_sections.debug_ranges.slice();
    let debug_loc_data = write_sections.debug_loc.slice();
    let debug_str_data = write_sections.debug_str.slice();
    assert_eq!(debug_info_data.len(), 394_930);
    assert_eq!(debug_abbrev_data.len(), 9701);
    assert_eq!(debug_line_data.len(), 105_797);
    assert_eq!(debug_ranges_data.len(), 155_712);
    assert_eq!(debug_loc_data.len(), 245_168);
    assert_eq!(debug_str_data.len(), 144_731);

    // Convert new sections
    let debug_abbrev = read::DebugAbbrev::new(debug_abbrev_data, LittleEndian);
    let debug_info = read::DebugInfo::new(debug_info_data, LittleEndian);
    let debug_line = read::DebugLine::new(debug_line_data, LittleEndian);
    let debug_str = read::DebugStr::new(debug_str_data, LittleEndian);
    let debug_ranges = read::DebugRanges::new(debug_ranges_data, LittleEndian);
    let debug_rnglists = read::DebugRngLists::new(&[], LittleEndian);
    let debug_loc = read::DebugLoc::new(debug_loc_data, LittleEndian);
    let debug_loclists = read::DebugLocLists::new(&[], LittleEndian);

    let ranges = gimli::RangeLists::new(debug_ranges, debug_rnglists);
    let locations = gimli::LocationLists::new(debug_loc, debug_loclists);

    let dwarf = read::Dwarf {
        debug_abbrev,
        debug_info,
        debug_line,
        debug_str,
        ranges,
        locations,
        ..Default::default()
    };

    let dwarf = write::Dwarf::from(&dwarf, &|address| Some(Address::Constant(address)))
        .expect("Should convert DWARF information");

    assert_eq!(dwarf.units.count(), 23);
    let entries: usize = (0..dwarf.units.count())
        .map(|i| dwarf.units.get(dwarf.units.id(i)).count())
        .sum();
    assert_eq!(entries, 29_560);
    assert_eq!(dwarf.strings.count(), 3921);
}
fn restore_generates_same_descriptors() {
  let (mnemonic, descriptors) = {
    let rpc_server = test_bitcoincore_rpc::spawn();

    let create::Output { mnemonic, .. } = CommandBuilder::new("wallet create")
      .rpc_server(&rpc_server)
      .run_and_deserialize_output();

    (mnemonic, rpc_server.descriptors())
  };

  let rpc_server = test_bitcoincore_rpc::spawn();

  CommandBuilder::new(["wallet", "restore", &mnemonic.to_string()])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Empty>();

  assert_eq!(rpc_server.descriptors(), descriptors);
}
fn parse_value_forloop_empty() {
    let ast = parse("{% for item in [1,2,] %}A{% else %}B{%- endfor %}").unwrap();
    let start_ws = WS::default();
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(
        ast[0],
        Node::Forloop(
            start_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::new(ExprVal::Array(vec![
                    Expr::new(ExprVal::Int(1)),
                    Expr::new(ExprVal::Int(2)),
                ])),
                body: vec![Node::Text("A".to_string())],
                empty_body: Some(vec![Node::Text("B".to_string())]),
            },
            end_ws,
        )
    );
}
fn gc_basic_cell_allocation() {
    run_test(|| {
        let gc_cell = Gc::new(GcRefCell::new(16_u16));

        force_collect();
        Harness::assert_collections(1);
        Harness::assert_bytes_allocated();
        assert_eq!(*gc_cell.borrow_mut(), 16);
    });
}
fn file_too_large() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), "statement();\n".repeat(80660).as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Do not store the content of the file in the snapshot
    fs.remove(file_path);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "file_too_large",
        fs,
        console,
        result,
    ));
}
fn parse_bad_if_not_exists() {
    let res = pg().parse_sql_statements("CREATE TABLE NOT EXISTS uk_cities ()");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: EXISTS".to_string()),
        res.unwrap_err()
    );

    let res = pg().parse_sql_statements("CREATE TABLE IF EXISTS uk_cities ()");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: EXISTS".to_string()),
        res.unwrap_err()
    );

    let res = pg().parse_sql_statements("CREATE TABLE IF uk_cities ()");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: uk_cities".to_string()),
        res.unwrap_err()
    );

    let res = pg().parse_sql_statements("CREATE TABLE IF NOT uk_cities ()");
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: NOT".to_string()),
        res.unwrap_err()
    );
}
fn parse_extends() {
    let ast = parse("{% extends \"index.html\" -%}").unwrap();
    assert_eq!(ast[0], Node::Extends(WS { left: false, right: true }, "index.html".to_string(),),);
}
fn enum_named_fields_variant() {
    let mut key = CacheKeyHasher::new();

    let variant = Enum::NamedFields {
        a: "Hello".to_string(),
        b: "World".to_string(),
    };
    variant.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    variant.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn batch_in_same_output_but_different_satpoints() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  create_wallet(&rpc_server);

  let output = CommandBuilder::new("wallet inscribe --fee-rate 1 --batch batch.yaml")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      "mode: shared-output\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n"
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  let outpoint = output.inscriptions[0].location.outpoint;
  for (i, inscription) in output.inscriptions.iter().enumerate() {
    assert_eq!(
      inscription.location,
      SatPoint {
        outpoint,
        offset: u64::try_from(i).unwrap() * 10_000,
      }
    );
  }

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  let outpoint = output.inscriptions[0].location.outpoint;

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[1].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:10000</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[2].id),
    format!(
      r".*<dt>location</dt>.*<dd class=monospace>{}:20000</dd>.*",
      outpoint
    ),
  );

  ord_server.assert_response_regex(
    format!("/output/{}", output.inscriptions[0].location.outpoint),
    format!(r".*<a href=/inscription/{}>.*</a>.*<a href=/inscription/{}>.*</a>.*<a href=/inscription/{}>.*</a>.*", output.inscriptions[0].id, output.inscriptions[1].id, output.inscriptions[2].id),
  );
}
fn nth_bit_test() {
    assert_eq!(mask::nth_bit(2), 0b100);
}
fn parse_window_function_with_filter() {
    for func_name in [
        "row_number",
        "rank",
        "max",
        "count",
        "user_defined_function",
    ] {
        let sql = format!("SELECT {}(x) FILTER (WHERE y) OVER () FROM t", func_name);
        let select = sqlite().verified_only_select(&sql);
        assert_eq!(select.to_string(), sql);
        assert_eq!(
            select.projection,
            vec![SelectItem::UnnamedExpr(Expr::Function(Function {
                name: ObjectName(vec![Ident::new(func_name)]),
                args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(
                    Expr::Identifier(Ident::new("x"))
                ))],
                null_treatment: None,
                over: Some(WindowType::WindowSpec(WindowSpec {
                    partition_by: vec![],
                    order_by: vec![],
                    window_frame: None,
                })),
                filter: Some(Box::new(Expr::Identifier(Ident::new("y")))),
                distinct: false,
                special: false,
                order_by: vec![]
            }))]
        );
    }
}
fn default_ns_shadowing_empty() {
    let src = "<e xmlns='urn:example:o'><e att1='a' xmlns='urn:example:i' /></e>";

    let mut r = NsReader::from_str(src);
    r.trim_text(true);

    // <outer xmlns='urn:example:o'>
    {
        match r.read_resolved_event() {
            Ok((ns, Start(e))) => {
                assert_eq!(ns, Bound(Namespace(b"urn:example:o")));
                assert_eq!(e.name(), QName(b"e"));
            }
            e => panic!("Expected Start event (<outer>), got {:?}", e),
        }
    }

    // <inner att1='a' xmlns='urn:example:i' />
    {
        let e = match r.read_resolved_event() {
            Ok((ns, Empty(e))) => {
                assert_eq!(ns, Bound(Namespace(b"urn:example:i")));
                assert_eq!(e.name(), QName(b"e"));
                e
            }
            e => panic!("Expecting Empty event, got {:?}", e),
        };

        let mut attrs = e
            .attributes()
            .map(|ar| ar.expect("Expecting attribute parsing to succeed."))
            // we don't care about xmlns attributes for this test
            .filter(|kv| kv.key.as_namespace_binding().is_none())
            .map(|Attribute { key: name, value }| {
                let (opt_ns, local_name) = r.resolve_attribute(name);
                (opt_ns, local_name.into_inner(), value)
            });
        // the attribute should _not_ have a namespace name. The default namespace does not
        // apply to attributes.
        assert_eq!(
            attrs.next(),
            Some((Unbound, &b"att1"[..], Cow::Borrowed(&b"a"[..])))
        );
        assert_eq!(attrs.next(), None);
    }

    // </outer>
    match r.read_resolved_event() {
        Ok((ns, End(e))) => {
            assert_eq!(ns, Bound(Namespace(b"urn:example:o")));
            assert_eq!(e.name(), QName(b"e"));
        }
        e => panic!("Expected End event (<outer>), got {:?}", e),
    }
}
fn parse_mod_no_spaces() {
    use self::Expr::*;
    let canonical = "a1 % b1";
    let sqls = ["a1 % b1", "a1% b1", "a1 %b1", "a1%b1"];
    for sql in sqls {
        println!("Parsing {sql}");
        assert_eq!(
            BinaryOp {
                left: Box::new(Identifier(Ident::new("a1"))),
                op: BinaryOperator::Modulo,
                right: Box::new(Identifier(Ident::new("b1"))),
            },
            pg_and_generic().expr_parses_to(sql, canonical)
        );
    }
}
fn split_on_context_value() {
    let mut tera = Tera::default();
    tera.add_raw_template("split.html", r#"{{ body | split(pat="\n") }}"#).unwrap();
    let mut context = Context::new();
    context.insert("body", "multi\nple\nlines");
    let res = tera.render("split.html", &context);
    assert_eq!(res.unwrap(), "[multi, ple, lines]");
}
fn check_shows_unsafe_fixes_with_opt_in() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args([
            "-",
            "--output-format=text",
            "--isolated",
            "--select",
            "F601,UP034",
            "--no-cache",
            "--unsafe-fixes",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
        @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 [*] Dictionary key literal `'a'` repeated
    -:2:7: UP034 [*] Avoid extraneous parentheses
    Found 2 errors.
    [*] 2 fixable with the --fix option.

    ----- stderr -----
    "###);
}
fn test_expression_bug() {
    let env = Environment::new();
    assert!(env.compile_expression("42.blahadsf()").is_err());
}
fn test_gc_peer_response() {
    let cluster = Cluster::with_node_count(2, None);
    let region_id = 2;
    let mut req = cluster.routers[0].new_request_for(region_id);
    let admin_req = req.mut_admin_request();
    admin_req.set_cmd_type(AdminCmdType::ChangePeer);
    admin_req
        .mut_change_peer()
        .set_change_type(ConfChangeType::AddLearnerNode);
    let store_id = cluster.node(1).id();
    let new_peer = new_learner_peer(store_id, 10);
    admin_req.mut_change_peer().set_peer(new_peer.clone());
    let resp = cluster.routers[0].admin_command(2, req.clone()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    let raft_engine = &cluster.node(0).running_state().unwrap().raft_engine;
    let region_state = raft_engine
        .get_region_state(region_id, u64::MAX)
        .unwrap()
        .unwrap();
    assert!(region_state.get_removed_records().is_empty());

    let new_conf_ver = req.get_header().get_region_epoch().get_conf_ver() + 1;
    req.mut_header()
        .mut_region_epoch()
        .set_conf_ver(new_conf_ver);
    req.mut_admin_request()
        .mut_change_peer()
        .set_change_type(ConfChangeType::RemoveNode);
    let resp = cluster.routers[0]
        .admin_command(region_id, req.clone())
        .unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);
    cluster.routers[0].wait_flush(region_id, Duration::from_millis(300));
    // Drain all existing messages.
    while cluster.receiver(0).try_recv().is_ok() {}

    let mut msg = Box::<RaftMessage>::default();
    msg.set_region_id(region_id);
    msg.set_to_peer(req.get_header().get_peer().clone());
    msg.set_from_peer(new_peer);
    let receiver = &cluster.receiver(0);
    for ty in &[MessageType::MsgRequestVote, MessageType::MsgRequestPreVote] {
        msg.mut_message().set_msg_type(*ty);
        cluster.routers[0].send_raft_message(msg.clone()).unwrap();
        let tombstone_msg = match receiver.recv_timeout(Duration::from_millis(300)) {
            Ok(msg) => msg,
            Err(e) => panic!("failed to receive tombstone message {:?}: {:?}", ty, e),
        };
        assert_tombstone_msg(&tombstone_msg, region_id, 10);
    }
    // Non-vote message should not trigger tombstone.
    msg.mut_message().set_msg_type(MessageType::MsgHeartbeat);
    cluster.routers[0].send_raft_message(msg).unwrap();
    cluster
        .receiver(0)
        .recv_timeout(Duration::from_millis(300))
        .unwrap_err();

    // GcTick should also trigger tombstone.
    cluster.routers[0]
        .send(region_id, PeerMsg::Tick(PeerTick::GcPeer))
        .unwrap();
    let tombstone_msg = cluster
        .receiver(0)
        .recv_timeout(Duration::from_millis(300))
        .unwrap();
    assert_tombstone_msg(&tombstone_msg, region_id, 10);

    // First message to create the peer and destroy.
    cluster.routers[1]
        .send_raft_message(Box::new(tombstone_msg.clone()))
        .unwrap();
    cluster.routers[1].wait_flush(region_id, Duration::from_millis(300));
    cluster
        .receiver(1)
        .recv_timeout(Duration::from_millis(300))
        .unwrap_err();
    // Send message should trigger tombstone report.
    cluster.routers[1]
        .send_raft_message(Box::new(tombstone_msg))
        .unwrap();
    let report = cluster
        .receiver(1)
        .recv_timeout(Duration::from_millis(300))
        .unwrap();
    assert_valid_report(&report, region_id, 10);
    cluster.routers[0]
        .send_raft_message(Box::new(report))
        .unwrap();
    let raft_engine = &cluster.node(0).running_state().unwrap().raft_engine;
    let region_state = raft_engine
        .get_region_state(region_id, u64::MAX)
        .unwrap()
        .unwrap();
    assert_eq!(region_state.get_removed_records().len(), 1);
    // Tick should flush records gc.
    cluster.routers[0]
        .send(region_id, PeerMsg::Tick(PeerTick::GcPeer))
        .unwrap();
    // Trigger a write to make sure records gc is finished.
    let header = Box::new(cluster.routers[0].new_request_for(region_id).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");
    let (msg, sub) = PeerMsg::simple_write(header, put.encode());
    cluster.routers[0].send(region_id, msg).unwrap();
    block_on(sub.result()).unwrap();
    cluster.routers[0].wait_flush(region_id, Duration::from_millis(300));
    let region_state = raft_engine
        .get_region_state(region_id, u64::MAX)
        .unwrap()
        .unwrap();
    assert!(region_state.get_removed_records().is_empty());
}
fn global_init_no_leak() -> anyhow::Result<()> {
    let (mut store, module) = ref_types_module(
        false,
        r#"
            (module
                (import "" "" (global externref))
                (global externref (global.get 0))
            )
        "#,
    )?;

    let externref = ExternRef::new(());
    let global = Global::new(
        &mut store,
        GlobalType::new(ValType::ExternRef, Mutability::Const),
        externref.clone().into(),
    )?;
    Instance::new(&mut store, &module, &[global.into()])?;
    drop(store);
    assert_eq!(externref.strong_count(), 1);

    Ok(())
}
fn justfile() {
  let tmp = temptree! {
    sub: {
      ".git": {},
    },
  };

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path().join("sub"))
    .arg("--init")
    .arg("--justfile")
    .arg(tmp.path().join("justfile"))
    .output()
    .unwrap();

  assert!(output.status.success());

  assert_eq!(
    fs::read_to_string(tmp.path().join("justfile")).unwrap(),
    EXPECTED
  );
}
fn named_field_struct() {
    #[derive(CacheKey, Hash)]
    struct NamedFieldsStruct {
        a: String,
        b: String,
    }

    let mut key = CacheKeyHasher::new();

    let named_fields = NamedFieldsStruct {
        a: "Hello".into(),
        b: "World".into(),
    };

    named_fields.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    named_fields.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn parse_raw_tag() {
    let ast = parse("{% raw -%}{{hey}}{%- endraw %}").unwrap();
    let start_ws = WS { right: true, ..Default::default() };
    let end_ws = WS { left: true, ..Default::default() };

    assert_eq!(ast[0], Node::Raw(start_ws, "{{hey}}".to_string(), end_ws));
}
fn error_string_concat_math_logic() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("tpl", "{{ 'ho' ~ name < 10 }}")]).unwrap();
    let mut context = Context::new();
    context.insert("name", &"john");

    let result = tera.render("tpl", &context);

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Tried to do math with a string concatenation: 'ho' ~ name"
    );
}
fn field_name_path() {
    let f2 = super::fixture().join("exports-field2");
    let f3 = super::fixture().join("exports-field3");

    // field name path #1 #2 #3
    let exports_fields = [
        vec![vec!["exportsField".into(), "exports".into()]],
        vec![vec!["exportsField".into(), "exports".into()], vec!["exports".into()]],
        vec![vec!["exports".into()], vec!["exportsField".into(), "exports".into()]],
    ];

    for exports_fields in exports_fields {
        let resolver = Resolver::new(ResolveOptions {
            alias_fields: vec![vec!["browser".into()]],
            exports_fields,
            extensions: vec![".js".into()],
            ..ResolveOptions::default()
        });
        let resolved_path = resolver.resolve(&f3, "exports-field").map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(f3.join("node_modules/exports-field/main.js")));
    }

    // field name path #4
    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        exports_fields: vec![vec!["exports".into()]],
        extensions: vec![".js".into()],
        ..ResolveOptions::default()
    });
    let resolved_path = resolver.resolve(&f2, "exports-field").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f2.join("node_modules/exports-field/index.js")));

    // field name path #5
    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        exports_fields: vec![vec!["ex".into()], vec!["exports_field".into(), "exports".into()]],
        extensions: vec![".js".into()],
        ..ResolveOptions::default()
    });
    let resolved_path = resolver.resolve(&f3, "exports-field").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f3.join("node_modules/exports-field/index")));

    // non-compliant export targeting a directory
    let resolver = Resolver::new(ResolveOptions {
        exports_fields: vec![vec!["broken".into()]],
        extensions: vec![".js".into()],
        ..ResolveOptions::default()
    });
    let resolved_path = resolver.resolve(&f3, "exports-field").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f3.join("node_modules/exports-field/src/index.js")));
}
fn insert_all_std_headers() {
    let mut m = HeaderMap::new();

    for (i, hdr) in STD.iter().enumerate() {
        m.insert(hdr.clone(), hdr.as_str().parse().unwrap());

        for j in 0..(i + 1) {
            assert_eq!(m[&STD[j]], STD[j].as_str());
        }

        if i != 0 {
            for j in (i + 1)..STD.len() {
                assert!(
                    m.get(&STD[j]).is_none(),
                    "contained {}; j={}",
                    STD[j].as_str(),
                    j
                );
            }
        }
    }
}
fn test_witness_leader_down() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k0", b"v0");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);

    let peer_on_store2 = find_peer(&region, nodes[1]).unwrap().clone();
    // nonwitness -> witness
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store2.get_id()],
        vec![true],
    );

    // the other follower is isolated
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    for i in 1..10 {
        cluster.must_put(format!("k{}", i).as_bytes(), format!("v{}", i).as_bytes());
    }
    // the leader is down
    cluster.stop_node(1);

    // witness would help to replicate the logs
    cluster.clear_send_filters();

    // forbid writes
    let put = new_put_cmd(b"k3", b"v3");
    must_get_error_is_witness(&mut cluster, &region, put);
    // forbid reads
    let get = new_get_cmd(b"k1");
    must_get_error_is_witness(&mut cluster, &region, get);
    // forbid read index
    let read_index = new_read_index_cmd();
    must_get_error_is_witness(&mut cluster, &region, read_index);

    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store3);
    cluster.must_put(b"k1", b"v1");
    assert_eq!(
        cluster.leader_of_region(region.get_id()).unwrap().store_id,
        nodes[2],
    );
    assert_eq!(cluster.must_get(b"k9"), Some(b"v9".to_vec()));
}
fn test_xml_decl() {
    let mut r = Reader::from_str("<?xml version=\"1.0\" encoding='utf-8'?>");
    r.trim_text(true);
    match r.read_event().unwrap() {
        Decl(ref e) => {
            match e.version() {
                Ok(v) => assert_eq!(
                    &*v,
                    b"1.0",
                    "expecting version '1.0', got '{:?}",
                    from_utf8(&v)
                ),
                Err(e) => panic!("{:?}", e),
            }
            match e.encoding() {
                Some(Ok(v)) => assert_eq!(
                    &*v,
                    b"utf-8",
                    "expecting encoding 'utf-8', got '{:?}",
                    from_utf8(&v)
                ),
                Some(Err(e)) => panic!("{:?}", e),
                None => panic!("cannot find encoding"),
            }
            match e.standalone() {
                None => (),
                e => panic!("doesn't expect standalone, got {:?}", e),
            }
        }
        _ => panic!("unable to parse XmlDecl"),
    }
}
fn issue510() {
    #[derive(Debug, PartialEq, Serialize, Deserialize)]
    #[serde(rename = "ENTRY")]
    struct Entry {
        #[serde(rename = "CUE_V2")]
        cues: Option<Vec<Cue>>,
    }

    #[derive(Debug, PartialEq, Serialize, Deserialize)]
    // #[serde_with::serde_as]
    struct Cue {
        #[serde(rename = "@NAME")]
        name: String,
    }

    let data: Entry = from_str(
        "\
        <ENTRY>\
            <CUE_V2 NAME='foo'></CUE_V2>\
            <CUE_V2 NAME='bar'></CUE_V2>\
        </ENTRY>\
    ",
    )
    .unwrap();

    assert_eq!(
        data,
        Entry {
            cues: Some(vec![
                Cue {
                    name: "foo".to_string(),
                },
                Cue {
                    name: "bar".to_string(),
                },
            ]),
        }
    );
}
fn batch_in_separate_outputs_with_parent_and_non_default_postage() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let parent_output = CommandBuilder::new("wallet inscribe --fee-rate 5.0 --file parent.png")
    .write("parent.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let parent_id = parent_output.inscriptions[0].id;

  let output = CommandBuilder::new("wallet inscribe --fee-rate 1 --batch batch.yaml --postage 777sat")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      format!("parent: {parent_id}\nmode: separate-outputs\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n")
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  for inscription in &output.inscriptions {
    assert_eq!(inscription.location.offset, 0);
  }

  let mut outpoints = output
    .inscriptions
    .iter()
    .map(|inscription| inscription.location.outpoint)
    .collect::<Vec<OutPoint>>();
  outpoints.sort();
  outpoints.dedup();
  assert_eq!(outpoints.len(), output.inscriptions.len());

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  let output_1 = output.inscriptions[0].location.outpoint;
  let output_2 = output.inscriptions[1].location.outpoint;
  let output_3 = output.inscriptions[2].location.outpoint;

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_1
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[1].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_2
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[2].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>777</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_3
    ),
  );
}
fn test_ge() {
    assert!(version("1.2.3-alpha2") >= version("0.0.0"));
    assert!(version("1.2.3-alpha2") >= version("1.0.0"));
    assert!(version("1.2.3-alpha2") >= version("1.2.0"));
    assert!(version("1.2.3-alpha2") >= version("1.2.3-alpha1"));
    assert!(version("1.2.3-alpha2") >= version("1.2.3-alpha2"));
    assert!(!(version("1.2.3+23") >= version("1.2.3+42")));
}
fn test_line_bytes_no_empty_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-C", "1"])
        .pipe_in("1\n2222\n3\n4")
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "1");
    assert_eq!(at.read("xab"), "\n");
    assert_eq!(at.read("xac"), "2");
    assert_eq!(at.read("xad"), "2");
    assert_eq!(at.read("xae"), "2");
    assert_eq!(at.read("xaf"), "2");
    assert_eq!(at.read("xag"), "\n");
    assert_eq!(at.read("xah"), "3");
    assert_eq!(at.read("xai"), "\n");
    assert_eq!(at.read("xaj"), "4");
    assert!(!at.plus("xak").exists());
}
fn nth_bit_test() {
    assert_eq!(nth_bit(0u64), 0b1);
    assert_eq!(nth_bit(1u64), 0b10);
    assert_eq!(nth_bit(2u64), 0b100);
    assert_eq!(nth_bit(10u64), 0b10000000000);
    assert_eq!(nth_bit(31u64), 0b10000000000000000000000000000000);
}
fn test_cp_parents_with_permissions_copy_file() {
    let (at, mut ucmd) = at_and_ucmd!();

    let dir = "dir";
    let file = "p1/p2/file";

    at.mkdir(dir);
    at.mkdir_all("p1/p2");
    at.touch(file);

    #[cfg(unix)]
    {
        let p1_mode = 0o0777;
        let p2_mode = 0o0711;
        let file_mode = 0o0702;

        at.set_mode("p1", p1_mode);
        at.set_mode("p1/p2", p2_mode);
        at.set_mode(file, file_mode);
    }

    ucmd.arg("-p")
        .arg("--parents")
        .arg(file)
        .arg(dir)
        .succeeds();

    #[cfg(all(unix, not(target_os = "freebsd")))]
    {
        let p1_metadata = at.metadata("p1");
        let p2_metadata = at.metadata("p1/p2");
        let file_metadata = at.metadata(file);

        assert_metadata_eq!(p1_metadata, at.metadata("dir/p1"));
        assert_metadata_eq!(p2_metadata, at.metadata("dir/p1/p2"));
        assert_metadata_eq!(file_metadata, at.metadata("dir/p1/p2/file"));
    }
}
fn test_validate_endpoints() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(Split::new()));
    let env = Arc::new(
        EnvBuilder::new()
            .cq_count(1)
            .name_prefix(thd_name!("test-pd"))
            .build(),
    );
    let eps = server.bind_addrs();

    let mgr = Arc::new(SecurityManager::new(&SecurityConfig::default()).unwrap());
    let connector = PdConnector::new(env, mgr);
    assert!(block_on(connector.validate_endpoints(&new_config(eps), false)).is_err());
}
fn test_large_integer_to_float() {
    use ron::value::Float;
    let test_var = std::i64::MAX as u64 + 1;
    let expected = test_var as f64; // Is exactly representable by f64
    let test_ser = ron::ser::to_string(&test_var).unwrap();
    assert_eq!(test_ser, test_var.to_string());
    let test_deser = ron::de::from_str::<Value>(&test_ser);

    assert_eq!(
        test_deser.unwrap(),
        Value::Number(Number::Float(Float::new(expected))),
    );
}
fn leaves_necessary_whitespace_alone_weird() {
    assert_eq!(
        "<u>a </u>b <u>c</u>",
        normalize_html(" <u>a </u>b <u>c</u>")
    )
}
fn all_rules_default_options() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");

    fs::write(
        &ruff_toml,
        r#"
[lint]
select = ["ALL"]
"#,
    )?;

    let test_path = tempdir.path().join("test.py");
    fs::write(
        &test_path,
        r#"
def say_hy(name: str):
        print(f"Hy {name}")"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["format", "--no-cache", "--config"])
        .arg(&ruff_toml)
        .arg(test_path), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    1 file reformatted

    ----- stderr -----
    warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
    warning: `multi-line-summary-first-line` (D212) and `multi-line-summary-second-line` (D213) are incompatible. Ignoring `multi-line-summary-second-line`.
    warning: The following rules may cause conflicts when used with the formatter: `COM812`, `ISC001`. To avoid unexpected behavior, we recommend disabling these rules, either by removing them from the `select` or `extend-select` configuration, or adding them to the `ignore` configuration.
    "###);
    Ok(())
}
fn sqrtf_sanity_test() {
    assert_eq!(libm::sqrtf(100.0), 10.0);
    assert_eq!(libm::sqrtf(4.0), 2.0);
}
fn roundtrip() {
    for s in 100..1000 {
        let sstr = s.to_string();
        let status = StatusCode::from_bytes(sstr.as_bytes()).unwrap();
        assert_eq!(s, u16::from(status));
        assert_eq!(sstr, status.as_str());
    }
}
fn test_load_global_config() {
    let (mut _server, client) = new_test_server_and_client(ReadableDuration::millis(100));
    let global_items = vec![("test1", "val1"), ("test2", "val2"), ("test3", "val3")];
    let check_items = global_items.clone();
    if let Err(err) = futures::executor::block_on(
        client.store_global_config(
            String::from("global"),
            global_items
                .iter()
                .map(|(name, value)| {
                    let mut item = GlobalConfigItem::default();
                    item.set_name(name.to_string());
                    item.set_payload(value.as_bytes().into());
                    item
                })
                .collect::<Vec<GlobalConfigItem>>(),
        ),
    ) {
        panic!("error occur {:?}", err);
    }

    let (res, revision) =
        futures::executor::block_on(client.load_global_config(String::from("global"))).unwrap();
    assert!(
        res.iter()
            .zip(check_items)
            .all(|(item1, item2)| item1.name == item2.0 && item1.payload == item2.1.as_bytes())
    );
    assert_eq!(revision, 3);
}
fn gen_c_header_works() -> anyhow::Result<()> {
    let temp_dir = tempfile::tempdir()?;
    let operating_dir: PathBuf = temp_dir.path().to_owned();

    let wasm_path = operating_dir.join(fixtures::qjs());
    let out_path = temp_dir.path().join("header.h");

    let _ = Command::new(get_wasmer_path())
        .arg("gen-c-header")
        .arg(&wasm_path)
        .arg("-o")
        .arg(&out_path)
        .output()
        .unwrap();

    let file = std::fs::read_to_string(&out_path).expect("no header.h file");
    assert!(file.contains("wasmer_function_6f62a6bc5c8f8e3e12a54e2ecbc5674ccfe1c75f91d8e4dd6ebb3fec422a4d6c_0"), "no wasmer_function_6f62a6bc5c8f8e3e12a54e2ecbc5674ccfe1c75f91d8e4dd6ebb3fec422a4d6c_0 in file");

    let _ = Command::new(get_wasmer_path())
        .arg("gen-c-header")
        .arg(&wasm_path)
        .arg("-o")
        .arg(&out_path)
        .arg("--prefix")
        .arg("abc123")
        .output()
        .unwrap();

    let file = std::fs::read_to_string(&out_path).expect("no header.h file");
    assert!(
        file.contains("wasmer_function_abc123_0"),
        "no wasmer_function_abc123_0 in file"
    );

    Ok(())
}
fn test_create() {
    use hickory_client::rr::rdata::A;

    let (_process, port) = named_process();
    let socket = SocketAddr::new(IpAddr::V4(Ipv4Addr::new(127, 0, 0, 1)), port);
    let conn = UdpClientConnection::new(socket).unwrap();

    let client = create_tsig_ready_client(conn);
    let origin = Name::from_str("example.net.").unwrap();

    // create a record
    let mut record = Record::with(
        Name::from_str("new.example.net.").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    let result = client
        .query(record.name(), record.dns_class(), record.record_type())
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);
    assert_eq!(result.answers().len(), 1);
    assert_eq!(result.answers()[0], record);

    // trying to create again should error
    // TODO: it would be cool to make this
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);

    // will fail if already set and not the same value.
    record.set_data(Some(RData::A(A::new(101, 11, 101, 11))));

    let result = client.create(record, origin).expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::YXRRSet);
}
fn test_resolved_ts_with_learners() {
    let cluster = new_server_cluster(0, 2);
    cluster.pd_client.disable_default_operator();
    let mut suite = TestSuiteBuilder::new()
        .cluster(cluster)
        .build_with_cluster_runner(|cluster| {
            let r = cluster.run_conf_change();
            cluster.pd_client.must_add_peer(r, new_learner_peer(2, 2));
        });

    let rid = suite.cluster.get_region(&[]).id;
    let req = suite.new_changedata_request(rid);
    let (mut req_tx, _, receive_event) = new_event_feed(suite.get_region_cdc_client(rid));
    block_on(req_tx.send((req, WriteFlags::default()))).unwrap();

    for _ in 0..10 {
        let event = receive_event(true);
        if event.has_resolved_ts() {
            assert!(event.get_resolved_ts().regions == vec![rid]);
            drop(receive_event);
            suite.stop();
            return;
        }
    }
    panic!("resolved timestamp should be advanced correctly");
}
fn can_remove_whitespace_basic() {
    let mut context = Context::new();
    context.insert("numbers", &vec![1, 2, 3]);

    let inputs = vec![
        ("  {%- for n in numbers %}{{n}}{% endfor -%} ", "123"),
        ("{%- for n in numbers %} {{n}}{%- endfor -%} ", " 1 2 3"),
        ("{%- for n in numbers -%}\n {{n}}\n {%- endfor -%} ", "123"),
        ("{%- if true -%}\n {{numbers}}\n {%- endif -%} ", "[1, 2, 3]"),
        ("{%- if false -%}\n {{numbers}}\n {% else %} Nope{%- endif -%} ", " Nope"),
        ("  {%- if false -%}\n {{numbers}}\n {% else -%} Nope {%- endif -%} ", "Nope"),
        ("  {%- if false -%}\n {{numbers}}\n {% elif true -%} Nope {%- endif -%} ", "Nope"),
        ("  {%- if false -%}\n {{numbers}}\n {% elif false -%} Nope {% else %} else {%- endif -%} ", " else"),
        ("  {%- set var = 2 -%} {{var}}", "2"),
        ("  {% set var = 2 -%} {{var}}", "  2"),
        (" {% raw -%} {{2}} {% endraw -%} ", " {{2}} "),
        ("  {% filter upper -%} hey {%- endfilter -%} ", "  HEY"),
        ("  {{ \"hello\" -}} ", "  hello"),
        ("  {{- \"hello\" }} ", "hello "),
        ("  {{- \"hello\" -}} ", "hello"),
        // Comments are not rendered so it should be just whitespace if anything
        ("  {#- \"hello\" -#} ", ""),
        ("  {# \"hello\" -#} ", "  "),
        ("  {#- \"hello\" #} ", " "),
    ];

    for (input, expected) in inputs {
        let mut tera = Tera::default();
        tera.add_raw_template("tpl", input).unwrap();
        println!("{} -> {:?}", input, expected);
        assert_eq!(tera.render("tpl", &context).unwrap(), expected);
    }
}
fn eph_self_referential() {
    #[derive(Trace, Finalize, Clone)]
    struct InnerCell {
        inner: GcRefCell<Option<Ephemeron<InnerCell, TestCell>>>,
    }
    #[derive(Trace, Finalize, Clone)]
    struct TestCell {
        inner: Gc<InnerCell>,
    }
    run_test(|| {
        let root = TestCell {
            inner: Gc::new(InnerCell {
                inner: GcRefCell::new(None),
            }),
        };
        let root_size = std::mem::size_of::<GcBox<InnerCell>>();

        Harness::assert_exact_bytes_allocated(root_size);

        {
            // Generate a self-referential ephemeron
            let eph = Ephemeron::new(&root.inner, root.clone());
            *root.inner.inner.borrow_mut() = Some(eph.clone());

            assert!(eph.value().is_some());
            Harness::assert_exact_bytes_allocated(80);
        }

        *root.inner.inner.borrow_mut() = None;

        force_collect();

        Harness::assert_exact_bytes_allocated(root_size);
    });
}
fn test_touch_set_mdhms_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_mdhms_time";

    ucmd.args(&["-t", "01011234.56", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime(
        "%Y%m%d%H%M.%S",
        &format!("{}01010000.00", time::OffsetDateTime::now_utc().year()),
    );
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);
}
fn config_builder_for_client_rejects_incompatible_cipher_suites() {
    assert_eq!(
        ClientConfig::builder()
            .with_cipher_suites(&[rustls::cipher_suite::TLS13_AES_256_GCM_SHA384])
            .with_safe_default_kx_groups()
            .with_protocol_versions(&[&rustls::version::TLS12])
            .err(),
        Some(Error::General("no usable cipher suites configured".into()))
    );
}
fn preview_enabled_group_ignore() {
    // `--select E --ignore PREVIEW` should detect E741 and E225, which is in preview but "E" is more specific.
    let args = ["--select", "E", "--ignore", "PREVIEW", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 2
    ----- stdout -----

    ----- stderr -----
    error: invalid value 'PREVIEW' for '--ignore <RULE_CODE>'

    For more information, try '--help'.
    "###);
}
fn u8_decimal_test() {
    assert_eq!(Ok((0, 1)), u8::from_lexical_partial(b"0"));
    assert_eq!(Ok((127, 3)), u8::from_lexical_partial(b"127"));
    assert_eq!(Ok((128, 3)), u8::from_lexical_partial(b"128"));
    assert_eq!(Ok((255, 3)), u8::from_lexical_partial(b"255"));
    assert_eq!(Err(Error::InvalidDigit(0)), u8::from_lexical(b"-1"));
    assert_eq!(Ok((1, 1)), u8::from_lexical_partial(b"1a"));

    let options = Options::default();
    assert_eq!(Ok((0, 1)), u8::from_lexical_partial_with_options::<{ STANDARD }>(b"0", &options));
}
fn unstable_passed() {
  let tmp = tempdir();

  let justfile = tmp.path().join("justfile");

  fs::write(&justfile, "x    :=    'hello'   ").unwrap();

  let output = Command::new(executable_path("just"))
    .current_dir(tmp.path())
    .arg("--fmt")
    .arg("--unstable")
    .output()
    .unwrap();

  if !output.status.success() {
    eprintln!("{}", String::from_utf8_lossy(&output.stderr));
    eprintln!("{}", String::from_utf8_lossy(&output.stdout));
    panic!("justfile failed with status: {}", output.status);
  }

  assert_eq!(fs::read_to_string(&justfile).unwrap(), "x := 'hello'\n");
}
fn manually_destroy() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t1" (type $t1 (sub resource)))

                (core module $m
                  (global $drops (mut i32) i32.const 0)
                  (global $last-drop (mut i32) i32.const 0)

                  (func (export "dtor") (param i32)
                    (global.set $drops (i32.add (global.get $drops) (i32.const 1)))
                    (global.set $last-drop (local.get 0))
                  )
                  (func (export "drops") (result i32) global.get $drops)
                  (func (export "last-drop") (result i32) global.get $last-drop)
                  (func (export "pass") (param i32) (result i32) local.get 0)
                )
                (core instance $i (instantiate $m))
                (type $t2' (resource (rep i32) (dtor (func $i "dtor"))))
                (export $t2 "t2" (type $t2'))
                (core func $ctor (canon resource.new $t2))
                (func (export "[constructor]t2") (param "rep" u32) (result (own $t2))
                  (canon lift (core func $ctor)))
                (func (export "[static]t2.drops") (result u32)
                  (canon lift (core func $i "drops")))
                (func (export "[static]t2.last-drop") (result u32)
                  (canon lift (core func $i "last-drop")))

                (func (export "t1-pass") (param "t" (own $t1)) (result (own $t1))
                  (canon lift (core func $i "pass")))
            )
        "#,
    )?;

    struct MyType;

    #[derive(Default)]
    struct Data {
        drops: u32,
        last_drop: Option<u32>,
    }

    let mut store = Store::new(&engine, Data::default());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t1", |mut cx, rep| {
        let data: &mut Data = cx.data_mut();
        data.drops += 1;
        data.last_drop = Some(rep);
        Ok(())
    })?;
    let i = linker.instantiate(&mut store, &c)?;
    let t2_ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, "[constructor]t2")?;
    let t2_drops = i.get_typed_func::<(), (u32,)>(&mut store, "[static]t2.drops")?;
    let t2_last_drop = i.get_typed_func::<(), (u32,)>(&mut store, "[static]t2.last-drop")?;
    let t1_pass = i.get_typed_func::<(Resource<MyType>,), (ResourceAny,)>(&mut store, "t1-pass")?;

    // Host resources can be destroyed through `resource_drop`
    let t1 = Resource::new_own(100);
    let (t1,) = t1_pass.call(&mut store, (t1,))?;
    t1_pass.post_return(&mut store)?;
    assert_eq!(store.data().drops, 0);
    assert_eq!(store.data().last_drop, None);
    t1.resource_drop(&mut store)?;
    assert_eq!(store.data().drops, 1);
    assert_eq!(store.data().last_drop, Some(100));

    // Guest resources can be destroyed through `resource_drop`
    let (t2,) = t2_ctor.call(&mut store, (200,))?;
    t2_ctor.post_return(&mut store)?;
    assert_eq!(t2_drops.call(&mut store, ())?, (0,));
    t2_drops.post_return(&mut store)?;
    assert_eq!(t2_last_drop.call(&mut store, ())?, (0,));
    t2_last_drop.post_return(&mut store)?;
    t2.resource_drop(&mut store)?;
    assert_eq!(t2_drops.call(&mut store, ())?, (1,));
    t2_drops.post_return(&mut store)?;
    assert_eq!(t2_last_drop.call(&mut store, ())?, (200,));
    t2_last_drop.post_return(&mut store)?;

    // Wires weren't crossed to drop more resources
    assert_eq!(store.data().drops, 1);
    assert_eq!(store.data().last_drop, Some(100));

    Ok(())
}
fn test_args() {
    fn type_name_of_val<T: ?Sized>(_val: &T) -> &str {
        std::any::type_name::<T>()
    }

    let args = args!();
    assert_eq!(args.len(), 0);
    assert_eq!(type_name_of_val(args), "[minijinja::value::Value]");

    let args = args!(1, 2);
    assert_eq!(args[0], Value::from(1));
    assert_eq!(args[1], Value::from(2));
    assert_eq!(type_name_of_val(args), "[minijinja::value::Value]");

    let args = args!(1, 2,);
    assert_eq!(args[0], Value::from(1));
    assert_eq!(args[1], Value::from(2));

    let args = args!(1, 2, foo => 42, bar => 23);
    assert_eq!(args[0], Value::from(1));
    assert_eq!(args[1], Value::from(2));
    let kwargs = Kwargs::try_from(args[2].clone()).unwrap();
    assert_eq!(kwargs.get::<i32>("foo").unwrap(), 42);
    assert_eq!(kwargs.get::<i32>("bar").unwrap(), 23);

    let args = args!(1, 2, foo => 42, bar => 23,);
    assert_eq!(args[0], Value::from(1));
    assert_eq!(args[1], Value::from(2));
    let kwargs = Kwargs::try_from(args[2].clone()).unwrap();
    assert_eq!(kwargs.get::<i32>("foo").unwrap(), 42);
    assert_eq!(kwargs.get::<i32>("bar").unwrap(), 23);
    assert_eq!(type_name_of_val(args), "[minijinja::value::Value]");
}
fn test_unclosed() {
    assert_eq!(
        from_str::<String>(
            "/*
        /* quite * some * nesting * going * on * /* here /* (yeah, maybe a bit too much) */ */ */
    */
    // The actual value comes.. /*
    // very soon, these are just checks that */
    // multi-line comments don't trigger in line comments /*
/* Unfortunately, this comment won't get closed :(
\"THE VALUE (which is invalid)\"
"
        ),
        Err(RonErr {
            code: Error::UnclosedBlockComment,
            position: Position { col: 1, line: 9 }
        })
    );
}
fn checks_incompatible_target() -> Result<()> {
    let mut target = target_lexicon::Triple::host();
    target.operating_system = target_lexicon::OperatingSystem::Unknown;
    match Module::new(
        &Engine::new(Config::new().target(&target.to_string())?)?,
        "(module)",
    ) {
        Ok(_) => unreachable!(),
        Err(e) => assert!(
            format!("{:?}", e).contains("configuration does not match the host"),
            "bad error: {:?}",
            e
        ),
    }

    Ok(())
}
fn remove_entry_multi_2() {
    let mut headers = HeaderMap::new();
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());

    let cookies = remove_all_values(&mut headers, SET_COOKIE);
    assert_eq!(cookies.len(), 2);
    assert_eq!(headers.len(), 0);
}
fn manually_deserialize_dyn() {
    let ron = r#"SerializeDyn(
        type: "engine_utils::types::registry::tests::Player",
    )"#;

    let mut de = ron::Deserializer::from_bytes(ron.as_bytes()).unwrap();

    let result = de
        .deserialize_struct("SerializeDyn", &["type"], SerializeDynVisitor)
        .unwrap();

    assert_eq!(
        *result.downcast::<Option<(String, String)>>().unwrap(),
        Some((
            String::from("type"),
            String::from("engine_utils::types::registry::tests::Player")
        ))
    );
}
fn save_point_rollback_two() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    wb.put(b"b", b"").unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    let a = db.engine.get_value(b"a").unwrap();
    assert!(a.is_none());
    let b = db.engine.get_value(b"b").unwrap();
    assert!(b.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    wb.set_save_point();
    for i in 0..max_keys {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.set_save_point();
    for i in max_keys..2 * max_keys {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"b", b"").unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    let a = db.engine.get_value(b"a").unwrap();
    assert!(a.is_none());
    let b = db.engine.get_value(b"b").unwrap();
    assert!(b.is_none());
    for i in 0..2 * max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
}
fn can_set_variables_in_included_templates() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("world", r#"{% set a = "world" %}{{a}}"#),
        ("hello", "<h1>Hello {% include \"world\" %}</h1>"),
    ])
    .unwrap();
    let result = tera.render("hello", &Context::new()).unwrap();
    assert_eq!(result, "<h1>Hello world</h1>".to_owned());
}
fn fabsf_sanity_test() {
    assert_eq!(libm::fabsf(-1.0), 1.0);
    assert_eq!(libm::fabsf(2.8), 2.8);
}
fn test_deserialize_number_to_untagged_enum() {
    #[derive(Eq, PartialEq, Deserialize, Debug)]
    #[serde(untagged)]
    enum E {
        N(i64),
    }

    assert_eq!(E::N(0), E::deserialize(Number::from(0)).unwrap());
}
fn float_test() {
  assert_eq!(float(&b"123.456;"[..]), Ok((&b";"[..], 123.456)));
  assert_eq!(float(&b"+123.456;"[..]), Ok((&b";"[..], 123.456)));
  assert_eq!(float(&b"-123.456;"[..]), Ok((&b";"[..], -123.456)));
}
fn write_batch_delete_range_backward_range() {
    let db = default_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();

    let mut wb = db.engine.write_batch();

    wb.delete_range(b"c", b"a").unwrap();
    recover_safe(|| {
        wb.write().unwrap();
    })
    .unwrap_err();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_some());
    assert!(db.engine.get_value(b"c").unwrap().is_some());

    let db = multi_batch_write_engine();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"b", b"").unwrap();
    db.engine.put(b"c", b"").unwrap();

    for i in 0..256_usize {
        let x = i.to_be_bytes();
        db.engine.put(&x, &x).unwrap();
    }

    let mut wb = db.engine.write_batch_with_cap(1024);

    wb.delete_range(b"c", b"a").unwrap();
    wb.delete_range(&256_usize.to_be_bytes(), &0_usize.to_be_bytes())
        .unwrap();

    recover_safe(|| {
        wb.write().unwrap();
    })
    .unwrap_err();

    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"b").unwrap().is_some());
    assert!(db.engine.get_value(b"c").unwrap().is_some());
    for i in 0..256_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }
}
fn test_block_cache_backward_compatible() {
    let content = read_file_in_project_dir("integrations/config/test-cache-compatible.toml");
    let mut cfg: TikvConfig = toml::from_str(&content).unwrap();
    assert!(cfg.storage.block_cache.capacity.is_none());
    cfg.compatible_adjust();
    assert!(cfg.storage.block_cache.capacity.is_some());
    assert_eq!(
        cfg.storage.block_cache.capacity.unwrap().0,
        cfg.rocksdb.defaultcf.block_cache_size.0
            + cfg.rocksdb.writecf.block_cache_size.0
            + cfg.rocksdb.lockcf.block_cache_size.0
            + cfg.raftdb.defaultcf.block_cache_size.0
    );
}
fn test_rm_verbose_slash() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_rm_verbose_slash_directory";
    let file_a = &format!("{dir}/test_rm_verbose_slash_file_a");

    at.mkdir(dir);
    at.touch(file_a);

    let file_a_normalized = &format!(
        "{}{}test_rm_verbose_slash_file_a",
        dir,
        std::path::MAIN_SEPARATOR
    );

    ucmd.arg("-r")
        .arg("-f")
        .arg("-v")
        .arg(&format!("{dir}///"))
        .succeeds()
        .stdout_only(format!(
            "removed '{file_a_normalized}'\nremoved directory '{dir}'\n"
        ));

    assert!(!at.dir_exists(dir));
    assert!(!at.file_exists(file_a));
}
fn test_2files() {
    let temp = env::temp_dir();
    let tmpdir = Path::new(&temp);
    let file1 = tmpdir.join("test1");
    let file2 = tmpdir.join("test2");

    for (n, a) in [(1, "a"), (2, "b")] {
        println!("number: {n} letter:{a}");
    }

    // spell-checker:disable-next-line
    for (path, data) in [(&file1, "abcdefghijklmnop"), (&file2, "qrstuvwxyz\n")] {
        let mut f = File::create(path).unwrap();
        assert!(
            f.write_all(data.as_bytes()).is_ok(),
            "Test setup failed - could not write file"
        );
    }

    new_ucmd!()
        .arg("--endian=little")
        .arg(file1.as_os_str())
        .arg(file2.as_os_str())
        .succeeds()
        .no_stderr()
        .stdout_is(unindent(ALPHA_OUT));
    // TODO: Handle errors?
    let _ = remove_file(file1);
    let _ = remove_file(file2);
}
fn test_split_number_with_io_blksize() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_read = |f| {
        let mut s = String::new();
        at.open(f).read_to_string(&mut s).unwrap();
        s
    };
    ucmd.args(&["-n", "5", "asciilowercase.txt", "---io-blksize", "1024"])
        .succeeds();
    assert_eq!(file_read("xaa"), "abcde");
    assert_eq!(file_read("xab"), "fghij");
    assert_eq!(file_read("xac"), "klmno");
    assert_eq!(file_read("xad"), "pqrst");
    assert_eq!(file_read("xae"), "uvwxyz\n");
}
fn test_touch_set_ymdhms_time() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_ymdhms_time";

    ucmd.args(&["-t", "1501011234.56", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M.%S", "201501010000.00");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45296);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45296);
}
fn lex_import_macro_tag() {
    assert!(TeraParser::parse(Rule::import_macro_tag, "{% import \"macros.html\" as macros %}",)
        .is_ok());
}
fn test_install_backup_short_custom_suffix_hyphen_value() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_custom_suffix_file_a";
    let file_b = "test_install_backup_custom_suffix_file_b";
    let suffix = "-v";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("-b")
        .arg(format!("--suffix={suffix}"))
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}{suffix}")));
}
fn parse_in_subquery() {
    let sql = "SELECT * FROM customers WHERE segment IN (SELECT segm FROM bar)";
    let select = verified_only_select(sql);
    assert_eq!(
        Expr::InSubquery {
            expr: Box::new(Expr::Identifier(Ident::new("segment"))),
            subquery: Box::new(verified_query("SELECT segm FROM bar")),
            negated: false,
        },
        select.selection.unwrap()
    );
}
fn test_async_host_func() {
    let engine = Engine::default();
    let mut linker = Linker::new(&engine);
    atoms::add_to_linker(&mut linker, |cx| cx).unwrap();
    let mut store = store(&engine);

    let shim_mod = shim_module(&engine);
    let shim_inst = linker.instantiate(&mut store, &shim_mod).unwrap();

    let input: i32 = 123;
    let result_location: i32 = 0;

    let mut results = [Val::I32(0)];
    shim_inst
        .get_func(&mut store, "double_int_return_float_shim")
        .unwrap()
        .call(
            &mut store,
            &[input.into(), result_location.into()],
            &mut results,
        )
        .unwrap();

    assert_eq!(
        results[0].unwrap_i32(),
        types::Errno::Ok as i32,
        "double_int_return_float errno"
    );

    // The actual result is in memory:
    let mem = shim_inst.get_memory(&mut store, "memory").unwrap();
    let mut result_bytes: [u8; 4] = [0, 0, 0, 0];
    mem.read(&store, result_location as usize, &mut result_bytes)
        .unwrap();
    let result = f32::from_le_bytes(result_bytes);
    assert_eq!((input * 2) as f32, result);
}
fn attributes_empty_ns() {
    let src = "<a att1='a' r:att2='b' xmlns:r='urn:example:r' />";

    let mut r = NsReader::from_str(src);
    r.trim_text(true);

    let e = match r.read_resolved_event() {
        Ok((Unbound, Empty(e))) => e,
        e => panic!("Expecting Empty event, got {:?}", e),
    };

    let mut attrs = e
        .attributes()
        .map(|ar| ar.expect("Expecting attribute parsing to succeed."))
        // we don't care about xmlns attributes for this test
        .filter(|kv| kv.key.as_namespace_binding().is_none())
        .map(|Attribute { key: name, value }| {
            let (opt_ns, local_name) = r.resolve_attribute(name);
            (opt_ns, local_name.into_inner(), value)
        });
    assert_eq!(
        attrs.next(),
        Some((Unbound, &b"att1"[..], Cow::Borrowed(&b"a"[..])))
    );
    assert_eq!(
        attrs.next(),
        Some((
            Bound(Namespace(b"urn:example:r")),
            &b"att2"[..],
            Cow::Borrowed(&b"b"[..])
        ))
    );
    assert_eq!(attrs.next(), None);
}
fn test_i32_max() {
    assert_eq!(
        std::i32::MAX,
        from_str(&to_string(&std::i32::MAX).unwrap()).unwrap()
    );
}
fn stdin_fix_jupyter() {
    let args = ["--fix", "--stdin-filename", "Jupyter.ipynb"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin(r#"{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dccc687c-96e2-4604-b957-a8a89b5bec06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e1b029-f516-4662-a9b9-623b93edac1a",
   "metadata": {},
   "source": [
    "Foo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdce7b92-b0fb-4c02-86f6-e233b26fa84f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e40b33d2-7fe4-46c5-bdf0-8802f3052565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1899bc8-d46f-4ec0-b1d1-e1ca0f04bf60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}"#), @r###"
    success: true
    exit_code: 0
    ----- stdout -----
    {
     "cells": [
      {
       "cell_type": "code",
       "execution_count": 1,
       "id": "dccc687c-96e2-4604-b957-a8a89b5bec06",
       "metadata": {},
       "outputs": [],
       "source": []
      },
      {
       "cell_type": "markdown",
       "id": "19e1b029-f516-4662-a9b9-623b93edac1a",
       "metadata": {},
       "source": [
        "Foo"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": 2,
       "id": "cdce7b92-b0fb-4c02-86f6-e233b26fa84f",
       "metadata": {},
       "outputs": [],
       "source": []
      },
      {
       "cell_type": "code",
       "execution_count": 3,
       "id": "e40b33d2-7fe4-46c5-bdf0-8802f3052565",
       "metadata": {},
       "outputs": [
        {
         "name": "stdout",
         "output_type": "stream",
         "text": [
          "1\n"
         ]
        }
       ],
       "source": [
        "print(1)"
       ]
      },
      {
       "cell_type": "code",
       "execution_count": null,
       "id": "a1899bc8-d46f-4ec0-b1d1-e1ca0f04bf60",
       "metadata": {},
       "outputs": [],
       "source": []
      }
     ],
     "metadata": {
      "kernelspec": {
       "display_name": "Python 3 (ipykernel)",
       "language": "python",
       "name": "python3"
      },
      "language_info": {
       "codemirror_mode": {
        "name": "ipython",
        "version": 3
       },
       "file_extension": ".py",
       "mimetype": "text/x-python",
       "name": "python",
       "nbconvert_exporter": "python",
       "pygments_lexer": "ipython3",
       "version": "3.11.2"
      }
     },
     "nbformat": 4,
     "nbformat_minor": 5
    }
    ----- stderr -----
    Found 2 errors (2 fixed, 0 remaining).
    "###);
}
fn traits_command_prints_sat_traits() {
  assert_eq!(
    CommandBuilder::new("traits 0").run_and_deserialize_output::<Output>(),
    Output {
      number: 0,
      decimal: "0.0".into(),
      degree: "0Â°0â€²0â€³0â€´".into(),
      name: "nvtdijuwxlp".into(),
      height: 0,
      cycle: 0,
      epoch: 0,
      period: 0,
      offset: 0,
      rarity: Rarity::Mythic,
    }
  );
}
#[test
fn test_round_robin() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file_read = |f| {
        let mut s = String::new();
        at.open(f).read_to_string(&mut s).unwrap();
        s
    };

    ucmd.args(&["-n", "r/2", "fivelines.txt"]).succeeds();

    assert_eq!(file_read("xaa"), "1\n3\n5\n");
    assert_eq!(file_read("xab"), "2\n4\n");
}
fn test_mv_backup_numbered() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=numbered")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}.~1~")));
}
fn print() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("format.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "formatter_print",
        fs,
        console,
        result,
    ));
}
fn test_table_size_denormal() {
    assert_eq!(5e-324, s2d(b"4.9406564584124654e-324").unwrap());
}
fn test_create_stage_with_copy_options() {
    let sql = concat!(
        "CREATE OR REPLACE STAGE my_ext_stage ",
        "URL='s3://load/files/' ",
        "COPY_OPTIONS=(ON_ERROR=CONTINUE FORCE=TRUE)"
    );
    match snowflake().verified_stmt(sql) {
        Statement::CreateStage { copy_options, .. } => {
            assert!(copy_options.options.contains(&DataLoadingOption {
                option_name: "ON_ERROR".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "CONTINUE".to_string()
            }));
            assert!(copy_options.options.contains(&DataLoadingOption {
                option_name: "FORCE".to_string(),
                option_type: DataLoadingOptionType::BOOLEAN,
                value: "TRUE".to_string()
            }));
        }
        _ => unreachable!(),
    };
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn reject_self_signed_server_cert() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    info!("connecting");
    let client_ch = pair.begin_connect(client_config_with_certs(vec![]));
    pair.drive();
    assert_matches!(pair.client_conn_mut(client_ch).poll(),
                    Some(Event::ConnectionLost { reason: ConnectionError::TransportError(ref error)})
                    if error.code == TransportErrorCode::crypto(AlertDescription::UnknownCA.get_u8()));
}
fn test_error_in_compaction_filter() {
    let mut engine = TestEngineBuilder::new().build().unwrap();
    let raw_engine = engine.get_rocksdb();

    let large_value = vec![b'x'; 300];
    must_prewrite_put(&mut engine, b"zkey", &large_value, b"zkey", 101);
    must_commit(&mut engine, b"zkey", 101, 102);
    must_prewrite_put(&mut engine, b"zkey", &large_value, b"zkey", 103);
    must_commit(&mut engine, b"zkey", 103, 104);
    must_prewrite_delete(&mut engine, b"zkey", b"zkey", 105);
    must_commit(&mut engine, b"zkey", 105, 106);

    let fp = "write_compaction_filter_flush_write_batch";
    fail::cfg(fp, "return").unwrap();

    let mut gc_runner = TestGcRunner::new(200);
    gc_runner.gc(&raw_engine);

    match gc_runner.gc_receiver.recv().unwrap() {
        GcTask::OrphanVersions { wb, .. } => assert_eq!(wb.count(), 2),
        GcTask::GcKeys { .. } => {}
        _ => unreachable!(),
    }

    // Although versions on default CF is not cleaned, write CF is GCed correctly.
    must_get_none(&mut engine, b"zkey", 102);
    must_get_none(&mut engine, b"zkey", 104);

    fail::remove(fp);
}
fn drop_on_owned_resource() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (import "[constructor]t" (func $ctor (result (own $t))))
                (import "[method]t.foo" (func $foo (param "self" (borrow $t)) (result (list u8))))

                (core func $ctor (canon lower (func $ctor)))
                (core func $drop (canon resource.drop $t))

                (core module $m1
                    (import "" "drop" (func $drop (param i32)))
                    (memory (export "memory") 1)
                    (global $to-drop (export "to-drop") (mut i32) (i32.const 0))
                    (func (export "realloc") (param i32 i32 i32 i32) (result i32)
                        (call $drop (global.get $to-drop))
                        unreachable)
                )
                (core instance $i1 (instantiate $m1
                    (with "" (instance
                        (export "drop" (func $drop))
                    ))
                ))

                (core func $foo (canon lower (func $foo)
                    (memory $i1 "memory")
                    (realloc (func $i1 "realloc"))))

                (core module $m2
                    (import "" "ctor" (func $ctor (result i32)))
                    (import "" "foo" (func $foo (param i32 i32)))
                    (import "i1" "to-drop" (global $to-drop (mut i32)))

                    (func (export "f")
                        (local $r i32)
                        (local.set $r (call $ctor))
                        (global.set $to-drop (local.get $r))
                        (call $foo
                            (local.get $r)
                            (i32.const 200))
                    )
                )
                (core instance $i2 (instantiate $m2
                    (with "" (instance
                        (export "ctor" (func $ctor))
                        (export "foo" (func $foo))
                    ))
                    (with "i1" (instance $i1))
                ))
                (func (export "f") (canon lift (core func $i2 "f")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
    linker.root().func_wrap("[constructor]t", |_cx, ()| {
        Ok((Resource::<MyType>::new_own(300),))
    })?;
    linker
        .root()
        .func_wrap("[method]t.foo", |_cx, (r,): (Resource<MyType>,)| {
            assert!(!r.owned());
            Ok((vec![2u8],))
        })?;
    let i = linker.instantiate(&mut store, &c)?;
    let f = i.get_typed_func::<(), ()>(&mut store, "f")?;

    let err = f.call(&mut store, ()).unwrap_err();
    assert!(
        format!("{err:?}").contains("cannot remove owned resource while borrowed"),
        "bad error: {err:?}"
    );

    Ok(())
}
fn i64_test() {
    let mut buffer = [b'\x00'; 32];
    assert_eq!(b"0", 0i64.to_lexical(&mut buffer));
    assert_eq!(b"1", 1i64.to_lexical(&mut buffer));
    assert_eq!(b"5", 5i64.to_lexical(&mut buffer));
    assert_eq!(b"9223372036854775807", 9223372036854775807i64.to_lexical(&mut buffer));
    assert_eq!(b"-9223372036854775808", (9223372036854775808u64 as i64).to_lexical(&mut buffer));
    assert_eq!(b"-1", (18446744073709551615u64 as i64).to_lexical(&mut buffer));
    assert_eq!(b"-1", (-1i64).to_lexical(&mut buffer));
}
fn test_du_symlink_multiple_fail() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    at.symlink_file("non-existing.txt", "target.txt");
    let mut file1 = at.make_file("file1");
    file1.write_all(b"azeaze").unwrap();

    let result = ts.ucmd().arg("-L").arg("target.txt").arg("file1").fails();
    assert_eq!(result.code(), 1);
    result.stdout_contains("4\tfile1\n");
}
fn test_invalid_identifiers() {
    let ser = ron::ser::to_string_pretty(
        &InvalidStruct,
        ron::ser::PrettyConfig::default().struct_names(true),
    );
    assert_eq!(
        ser,
        Err(Error::InvalidIdentifier(String::from("Hello World")))
    );

    let ser = ron::ser::to_string_pretty(
        &EmptyStruct,
        ron::ser::PrettyConfig::default().struct_names(true),
    );
    assert_eq!(ser, Err(Error::InvalidIdentifier(String::from(""))));

    let de = ron::from_str::<InvalidStruct>("Hello World").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::ExpectedDifferentStructName {
                expected: "Hello World",
                found: String::from("Hello"),
            },
            position: Position { line: 1, col: 6 },
        }
    );

    let de = ron::from_str::<EmptyStruct>("").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::ExpectedUnit,
            position: Position { line: 1, col: 1 },
        }
    );

    let de = ron::from_str::<EmptyStruct>("r#").unwrap_err();
    assert_eq!(
        format!("{}", de),
        "1:1: Expected only opening `(`, no name, for un-nameable struct"
    );

    let de = ron::from_str::<RawStruct>("").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::ExpectedNamedStructLike("Hello+World"),
            position: Position { line: 1, col: 1 },
        },
    );

    let de = ron::from_str::<RawStruct>("r#").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::ExpectedNamedStructLike("Hello+World"),
            position: Position { line: 1, col: 1 },
        },
    );

    let de = ron::from_str::<RawStruct>("Hello+World").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::SuggestRawIdentifier(String::from("Hello+World")),
            position: Position { line: 1, col: 1 },
        }
    );

    let de = ron::from_str::<RawStruct>(
        "r#Hello+World(
        ab.cd-ef: true,
    )",
    )
    .unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::SuggestRawIdentifier(String::from("ab.cd-ef")),
            position: Position { line: 2, col: 9 },
        }
    );

    let de = ron::from_str::<RawStruct>(
        "r#Hello+World(
        r#ab.cd+ef: true,
    )",
    )
    .unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::NoSuchStructField {
                expected: &["ab.cd-ef"],
                found: String::from("ab.cd+ef"),
                outer: Some(String::from("Hello+World")),
            },
            position: Position { line: 2, col: 19 },
        }
    );

    let de = ron::from_str::<RawEnum>("Hello-World").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::SuggestRawIdentifier(String::from("Hello-World")),
            position: Position { line: 1, col: 1 },
        }
    );

    let de = ron::from_str::<RawEnum>("r#Hello+World").unwrap_err();
    assert_eq!(
        de,
        SpannedError {
            code: Error::NoSuchEnumVariant {
                expected: &["Hello-World"],
                found: String::from("Hello+World"),
                outer: Some(String::from("RawEnum")),
            },
            position: Position { line: 1, col: 14 },
        }
    );

    let de = ron::from_str::<EmptyStruct>("r#+").unwrap_err();
    assert_eq!(
        format!("{}", de),
        r#"1:4: Expected struct ""_[invalid identifier] but found `r#+`"#,
    );
}
fn parse_create_view_with_columns() {
    let sql = "CREATE VIEW v (has, cols) AS SELECT 1, 2";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            columns,
            or_replace,
            with_options,
            query,
            materialized,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("v", name.to_string());
            assert_eq!(columns, vec![Ident::new("has"), Ident::new("cols")]);
            assert_eq!(with_options, vec![]);
            assert_eq!("SELECT 1, 2", query.to_string());
            assert!(!materialized);
            assert!(!or_replace);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(!temporary);
        }
        _ => unreachable!(),
    }
}
fn drain_filter() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        for i in 0..10 {
            table.insert(&i, &i).unwrap();
        }
        // Test draining uncommitted data
        drop(table.drain_filter(0..10, |k, _| k < 5).unwrap());
        for i in 0..5 {
            table.insert(&i, &i).unwrap();
        }
        assert_eq!(table.len().unwrap(), 10);

        // Test matching on the value
        drop(table.drain_filter(0..10, |_, v| v < 5).unwrap());
        for i in 0..5 {
            table.insert(&i, &i).unwrap();
        }
        assert_eq!(table.len().unwrap(), 10);
    }
    write_txn.commit().unwrap();

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        assert_eq!(table.len().unwrap(), 10);
        for (i, item) in table.drain_filter(0.., |x, _| x < 5).unwrap().enumerate() {
            let (k, v) = item.unwrap();
            assert_eq!(i as u64, k.value());
            assert_eq!(i as u64, v.value());
        }
        assert_eq!(table.len().unwrap(), 5);
        let mut i = 5u64;
        for item in table.range(0..10).unwrap() {
            let (k, v) = item.unwrap();
            assert_eq!(i, k.value());
            assert_eq!(i, v.value());
            i += 1;
        }
    }
    write_txn.abort().unwrap();

    // Check that dropping the iter early works too
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(U64_TABLE).unwrap();
        assert_eq!(table.len().unwrap(), 10);
        drop(table.drain_filter(0.., |x, _| x < 5).unwrap());
        assert_eq!(table.len().unwrap(), 5);
    }
    write_txn.abort().unwrap();
}
fn parse_f32_lossy_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::builder().lossy(true).build().unwrap();
    let parse = move |x| f32::from_lexical_partial_with_options::<FORMAT>(x, &options);

    assert_eq!(Ok((1.2345, 6)), parse(b"1.2345"));
    assert_eq!(Ok((12.345, 6)), parse(b"12.345"));
    assert_eq!(Ok((12345.6789, 10)), parse(b"12345.6789"));
    assert_eq!(Ok((1.2345e10, 9)), parse(b"1.2345e10"));
}
fn test_du_exclude_several_components() {
    let ts = TestScenario::new(util_name!());
    let at = &ts.fixtures;

    at.mkdir_all("a/b/c");
    at.mkdir_all("a/x/y");
    at.mkdir_all("a/u/y");

    // Exact match
    let result = ts
        .ucmd()
        .arg("--exclude=a/u")
        .arg("--exclude=a/b")
        .arg("a")
        .succeeds();
    assert!(!result.stdout_str().contains("a/u"));
    assert!(!result.stdout_str().contains("a/b"));
}
fn test_skip_iter_t() {
    // Test iterators that skip single, trailing-only digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_trailing_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b".45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"4__5");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"_45_5");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"__45__5");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b".45_5");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"_.45__5");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"4_5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"4__5_");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"4_5.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"4__5_.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"__45_");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"_45.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"__45_.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"_4_5");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"__4__5_");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"_4_5.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"__4__5_.56");
}
fn test_random() {
    let n = if cfg!(miri) { 100 } else { 1000000 };
    let mut buffer = ryu::Buffer::new();
    for _ in 0..n {
        let f: f32 = rand::random();
        assert_eq!(f, buffer.format_finite(f).parse().unwrap());
    }
}
fn test_nested() {
    assert_eq!(
        from_str(
            "/*
        /* quite * some * nesting * going * on * /* here /* (yeah, maybe a bit too much) */ */ */
    */
    // The actual value comes.. /*
    // very soon, these are just checks that */
    // multi-line comments don't trigger in line comments /*
\"THE VALUE\" /* This is the value /* :) */ */
    "
        ),
        Ok("THE VALUE".to_owned())
    );
}
fn from_file() {
  assert_eq!(
    CommandBuilder::new("decode transaction.bin")
      .write("transaction.bin", transaction())
      .run_and_deserialize_output::<Output>(),
    Output {
      inscriptions: vec![Inscription {
        body: Some(vec![0, 1, 2, 3]),
        content_type: Some(b"text/plain;charset=utf-8".to_vec()),
        ..Default::default()
      }],
    }
  );
}
fn test_rm_interactive_missing_value() {
    // `--interactive` is equivalent to `--interactive=always` or `-i`
    let (at, mut ucmd) = at_and_ucmd!();

    let file1 = "test_rm_interactive_missing_value_file1";
    let file2 = "test_rm_interactive_missing_value_file2";

    at.touch(file1);
    at.touch(file2);

    ucmd.arg("--interactive")
        .arg(file1)
        .arg(file2)
        .pipe_in("y\ny")
        .succeeds();

    assert!(!at.file_exists(file1));
    assert!(!at.file_exists(file2));
}
fn inscription_metadata() {
  let metadata = r#"{"foo":"bar","baz":1}"#;
  let mut encoded_metadata = Vec::new();
  let cbor_map = ciborium::value::Value::Map(vec![
    (
      ciborium::value::Value::Text("foo".into()),
      ciborium::value::Value::Text("bar".into()),
    ),
    (
      ciborium::value::Value::Text("baz".into()),
      ciborium::value::Value::Integer(Integer::from(1)),
    ),
  ]);
  ciborium::ser::into_writer(&cbor_map, &mut encoded_metadata).unwrap();

  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  rpc_server.mine_blocks(1);

  let inscription_id = CommandBuilder::new(
    "wallet inscribe --fee-rate 1 --json-metadata metadata.json --file foo.txt",
  )
  .write("foo.txt", "FOO")
  .write("metadata.json", metadata)
  .rpc_server(&rpc_server)
  .run_and_deserialize_output::<Inscribe>()
  .inscriptions
  .get(0)
  .unwrap()
  .id;

  rpc_server.mine_blocks(1);

  let response =
    TestServer::spawn_with_args(&rpc_server, &[]).request(format!("/r/metadata/{inscription_id}"));

  assert_eq!(response.status(), StatusCode::OK);
  assert_eq!(
    response.headers().get("content-type").unwrap(),
    "application/json"
  );
  assert_eq!(
    response.text().unwrap(),
    format!("\"{}\"", hex::encode(encoded_metadata))
  );
}
fn error_out_of_range_index() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("tpl", "{{ arr[10] }}")]).unwrap();
    let mut context = Context::new();
    context.insert("arr", &[1, 2, 3]);

    let result = tera.render("tpl", &Context::new());

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Variable `arr[10]` not found in context while rendering \'tpl\': the evaluated version was `arr.10`. Maybe the index is out of bounds?"
    );
}
async fn test_cname_additionals() {
    let example = create_example();
    let origin = example.origin().clone();

    let mut catalog: Catalog = Catalog::new();
    catalog.upsert(origin, Box::new(Arc::new(example)));

    let mut question: Message = Message::new();

    let mut query: Query = Query::new();
    query.set_name(Name::from_str("alias.example.com.").unwrap());
    query.set_query_type(RecordType::A);

    question.add_query(query);

    // temp request
    let question_bytes = question.to_bytes().unwrap();
    let question_req = MessageRequest::from_bytes(&question_bytes).unwrap();
    let question_req = Request::new(question_req, ([127, 0, 0, 1], 5553).into(), Protocol::Udp);

    let response_handler = TestResponseHandler::new();
    catalog
        .lookup(&question_req, None, response_handler.clone())
        .await;
    let result = response_handler.into_message().await;

    assert_eq!(result.message_type(), MessageType::Response);
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let answers: &[Record] = result.answers();
    assert_eq!(answers.len(), 1);
    assert_eq!(answers.first().unwrap().record_type(), RecordType::CNAME);
    assert_eq!(
        answers.first().unwrap().data().unwrap(),
        &RData::CNAME(CNAME(Name::from_str("www.example.com.").unwrap()))
    );

    let additionals: &[Record] = result.additionals();
    assert!(!additionals.is_empty());
    assert_eq!(additionals.first().unwrap().record_type(), RecordType::A);
    assert_eq!(
        additionals.first().unwrap().data().unwrap(),
        &RData::A(A::new(93, 184, 216, 34))
    );
}
fn test_mv_rename_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "test_mv_rename_file";
    let file2 = "test_mv_rename_file2";

    at.touch(file1);

    ucmd.arg(file1).arg(file2).succeeds().no_stderr();
    assert!(at.file_exists(file2));
}
fn ignore_comments_error_when_allow_comments() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let config_json = r#"{
  "json": {
    "parser": { "allowComments": true }
  }
}

    "#;
    let biome_config = "biome.json";
    let code = r#"
/*test*/ [1, 2, 3]
    "#;
    let file_path = Path::new("tsconfig.json");
    fs.insert(file_path.into(), code.as_bytes());
    fs.insert(biome_config.into(), config_json);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ignore_comments_error_when_allow_comments",
        fs,
        console,
        result,
    ));
}
fn server_complete_io_for_handshake() {
    for kt in ALL_KEY_TYPES.iter() {
        let (mut client, mut server) = make_pair(*kt);

        assert!(server.is_handshaking());
        let (rdlen, wrlen) = server
            .complete_io(&mut OtherSession::new(&mut client))
            .unwrap();
        assert!(rdlen > 0 && wrlen > 0);
        assert!(!server.is_handshaking());
        assert!(!server.wants_write());
    }
}
async fn recv_data_overflows_stream_window() {
    // this tests for when streams have smaller windows than their connection
    h2_support::trace_init!();

    let (io, mut srv) = mock::new();

    let mock = async move {
        let _ = srv.assert_client_handshake().await;
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://http2.akamai.com/")
                .eos(),
        )
        .await;
        srv.send_frame(frames::headers(1).response(200)).await;
        // fill the whole window
        srv.send_frame(frames::data(1, vec![0u8; 16_384])).await;
        // this frame overflows the window!
        srv.send_frame(frames::data(1, &[0; 16][..]).eos()).await;
        srv.recv_frame(frames::reset(1).flow_control()).await;
    };

    let h2 = async move {
        let (mut client, conn) = client::Builder::new()
            .initial_window_size(16_384)
            .handshake::<_, Bytes>(io)
            .await
            .unwrap();
        let request = Request::builder()
            .method(Method::GET)
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let req = async move {
            let resp = client.send_request(request, true).unwrap().0.await.unwrap();
            assert_eq!(resp.status(), StatusCode::OK);
            let body = resp.into_parts().1;
            let res = util::concat(body).await;
            let err = res.unwrap_err();
            assert_eq!(
                err.to_string(),
                "stream error detected: flow-control protocol violated"
            );
        };

        join(async move { conn.await.unwrap() }, req).await;
    };
    join(mock, h2).await;
}
fn test_tee_processing_multiple_operands() {
    // POSIX says: "Processing of at least 13 file operands shall be supported."

    let content = "tee_sample_content";
    for n in [1, 2, 12, 13] {
        let files = (1..=n).map(|x| x.to_string()).collect::<Vec<_>>();
        let (at, mut ucmd) = at_and_ucmd!();

        ucmd.args(&files)
            .pipe_in(content)
            .succeeds()
            .stdout_is(content);

        for file in &files {
            assert!(at.file_exists(file));
            assert_eq!(at.read(file), content);
        }
    }
}
fn ci_formatter_linter_organize_imports() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let rome_json = r#"{
    "linter": {
        "enabled": true,
        "rules": {
            "recommended": true
        }
    },
    "organizeImports": {
        "enabled": true
    }
}"#;

    let input = r#"
import { B, C } from "b.js"
import A from "a.js"


something( )
    "#;

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), rome_json.as_bytes());

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), input.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("ci target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_formatter_linter_organize_imports",
        fs,
        console,
        result,
    ));
}
fn test_encrypted_checkpoint() {
    let dir = tempdir();
    let root_path = dir.path();

    let encryption_cfg = test_util::new_file_security_config(root_path);
    let key_manager = Arc::new(
        data_key_manager_from_config(&encryption_cfg, root_path.to_str().unwrap())
            .unwrap()
            .unwrap(),
    );

    let mut db_opts = DbOptions::default();
    db_opts.set_key_manager(Some(key_manager));
    let cf_opts: Vec<_> = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();

    let path1 = root_path.join("1").to_str().unwrap().to_owned();
    let db1 = KvTestEngine::new_kv_engine_opt(&path1, db_opts.clone(), cf_opts.clone()).unwrap();
    db1.put(b"foo", b"bar").unwrap();
    db1.sync().unwrap();

    let path2 = root_path.join("2");
    let mut checkpointer = db1.new_checkpointer().unwrap();
    checkpointer.create_at(&path2, None, 0).unwrap();
    let db2 =
        KvTestEngine::new_kv_engine_opt(path2.to_str().unwrap(), db_opts.clone(), cf_opts.clone())
            .unwrap();
    assert_eq!(
        db2.get_value_cf(CF_DEFAULT, b"foo").unwrap().unwrap(),
        b"bar"
    );
}
fn fabsf_sanity_test() {
    assert_eq!(libm::fabsf(-1.0), 1.0);
    assert_eq!(libm::fabsf(2.8), 2.8);
}
fn test_min_max() {
    assert_eq!(
        1.7976931348623157e308,
        s2d(b"1.7976931348623157e308").unwrap(),
    );
    assert_eq!(5E-324, s2d(b"5E-324").unwrap());
}
fn client_respects_buffer_limit_post_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    do_handshake(&mut client, &mut server);
    client.set_buffer_limit(Some(48));

    assert_eq!(
        client
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        20
    );
    assert_eq!(
        client
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        6
    );

    transfer(&mut client, &mut server);
    server.process_new_packets().unwrap();

    check_read(&mut server.reader(), b"01234567890123456789012345");
}
fn test_prewrite_before_max_ts_is_synced() {
    let mut cluster = new_server_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    cluster.run();

    // Transfer leader to node 1 first to ensure all operations happen on node 1
    cluster.must_transfer_leader(1, new_peer(1, 1));

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k2");
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k3");

    let addr = cluster.sim.rl().get_addr(1);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env).connect(&addr);
    let client = TikvClient::new(channel);

    let do_prewrite = |cluster: &mut Cluster<ServerCluster>| {
        let region_id = right.get_id();
        let leader = cluster.leader_of_region(region_id).unwrap();
        let epoch = cluster.get_region_epoch(region_id);
        let mut ctx = Context::default();
        ctx.set_region_id(region_id);
        ctx.set_peer(leader);
        ctx.set_region_epoch(epoch);

        let mut req = PrewriteRequest::default();
        req.set_context(ctx);
        req.set_primary_lock(b"key".to_vec());
        let mut mutation = Mutation::default();
        mutation.set_op(Op::Put);
        mutation.set_key(b"key".to_vec());
        mutation.set_value(b"value".to_vec());
        req.mut_mutations().push(mutation);
        req.set_start_version(100);
        req.set_lock_ttl(20000);
        req.set_use_async_commit(true);
        client.kv_prewrite(&req).unwrap()
    };

    fail::cfg("test_raftstore_get_tso", "return(50)").unwrap();
    cluster.pd_client.must_merge(left.get_id(), right.get_id());
    let resp = do_prewrite(&mut cluster);
    assert!(resp.get_region_error().has_max_timestamp_not_synced());
    fail::remove("test_raftstore_get_tso");
    thread::sleep(Duration::from_millis(200));
    let resp = do_prewrite(&mut cluster);
    assert!(!resp.get_region_error().has_max_timestamp_not_synced());
}
fn incorrect_description_file_3() {
    let f = super::fixture().join("incorrect-package");
    let resolution = Resolver::default().resolve(f.join("pack2"), ".");
    assert!(resolution.is_err());
}
fn strip_div_newline() {
    assert_eq!("<div></div>", normalize_html("<div>\n</div>"));
}
fn parse_is_distinct_from() {
    use self::Expr::*;
    let sql = "a IS DISTINCT FROM b";
    assert_eq!(
        IsDistinctFrom(
            Box::new(Identifier(Ident::new("a"))),
            Box::new(Identifier(Ident::new("b"))),
        ),
        verified_expr(sql)
    );
}
fn metered_i32_add() {
    let wasm = wat2wasm(
        r#"
        (module
            (func (export "test") (param $a i32) (param $b i32) (result i32)
                (i32.add
                    (local.get $a)
                    (local.get $b)
                )
            )
        )
    "#,
    );
    let (mut store, func) = default_test_setup(&wasm);
    let func = func.typed::<(i32, i32), i32>(&store).unwrap();
    // No fuel -> no success.
    assert_out_of_fuel(func.call(&mut store, (1, 2)));
    assert_eq!(store.fuel_consumed(), Some(0));
    // Now add too little fuel for a start, so still no success.
    store.add_fuel(1).unwrap();
    assert_out_of_fuel(func.call(&mut store, (1, 2)));
    assert_eq!(store.fuel_consumed(), Some(0));
    // Now add enough fuel, so execution should succeed.
    store.add_fuel(10).unwrap();
    assert_success(func.call(&mut store, (1, 2)));
    assert_eq!(store.fuel_consumed(), Some(5));
}
fn test_line_bytes_concatenated_with_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-C8", "letters.txt"]).succeeds();
    assert_eq!(at.read("xaa"), "aaaaaaaa");
    assert_eq!(at.read("xab"), "a\nbbbb\n");
    assert_eq!(at.read("xac"), "cccc\ndd\n");
    assert_eq!(at.read("xad"), "ee\n");
}
fn test_symlink_simple_backup() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_simple_backup";
    let link = "test_symlink_simple_backup_link";

    at.touch(file);
    at.symlink_file(file, link);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    ucmd.args(&["-b", "-s", file, link]).succeeds().no_stderr();

    assert!(at.file_exists(file));

    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let backup = &format!("{link}~");
    assert!(at.is_symlink(backup));
    assert_eq!(at.resolve_link(backup), file);
}
fn test_read_after_cleanup_range_for_snap() {
    let mut cluster = new_server_cluster(1, 3);
    configure_for_snapshot(&mut cluster.cfg);
    configure_for_lease_read(&mut cluster.cfg, Some(100), Some(10));
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    // Set region and peers
    let r1 = cluster.run_conf_change();
    let p1 = new_peer(1, 1);
    let p2 = new_peer(2, 2);
    cluster.pd_client.must_add_peer(r1, p2.clone());
    let p3 = new_peer(3, 3);
    cluster.pd_client.must_add_peer(r1, p3.clone());
    cluster.must_put(b"k0", b"v0");
    cluster.pd_client.must_none_pending_peer(p2);
    cluster.pd_client.must_none_pending_peer(p3.clone());
    let region = cluster.get_region(b"k0");
    assert_eq!(cluster.leader_of_region(region.get_id()).unwrap(), p1);
    must_get_equal(&cluster.get_engine(3), b"k0", b"v0");
    cluster.stop_node(3);
    let last_index = cluster.raft_local_state(r1, 1).last_index;
    (0..10).for_each(|_| cluster.must_put(b"k1", b"v1"));
    // Ensure logs are compacted, then node 1 will send a snapshot to node 3 later
    cluster.wait_log_truncated(r1, 1, last_index + 1);

    fail::cfg("send_snapshot", "pause").unwrap();
    cluster.run_node(3).unwrap();
    // Sleep for a while to ensure peer 3 receives a HeartBeat
    thread::sleep(Duration::from_millis(500));

    // Add filter for delaying ReadIndexResp and MsgSnapshot
    let (read_index_sx, read_index_rx) = channel::unbounded::<RaftMessage>();
    let (snap_sx, snap_rx) = channel::unbounded::<RaftMessage>();
    let recv_filter = Box::new(
        RegionPacketFilter::new(region.get_id(), 3)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgSnapshot)
            .set_msg_callback(Arc::new(move |msg: &RaftMessage| {
                snap_sx.send(msg.clone()).unwrap();
            })),
    );
    let send_read_index_filter = RegionPacketFilter::new(region.get_id(), 3)
        .direction(Direction::Recv)
        .msg_type(MessageType::MsgReadIndexResp)
        .set_msg_callback(Arc::new(move |msg: &RaftMessage| {
            read_index_sx.send(msg.clone()).unwrap();
        }));
    cluster.sim.wl().add_recv_filter(3, recv_filter);
    cluster.add_send_filter(CloneFilterFactory(send_read_index_filter));
    fail::remove("send_snapshot");
    let mut request = new_request(
        region.get_id(),
        region.get_region_epoch().clone(),
        vec![new_get_cf_cmd("default", b"k0")],
        false,
    );
    request.mut_header().set_peer(p3);
    request.mut_header().set_replica_read(true);
    // Send follower read request to peer 3
    let (cb1, mut rx1) = make_cb(&request);
    cluster
        .sim
        .rl()
        .async_command_on_node(3, request, cb1)
        .unwrap();
    let read_index_msg = read_index_rx.recv_timeout(Duration::from_secs(5)).unwrap();
    let snap_msg = snap_rx.recv_timeout(Duration::from_secs(5)).unwrap();

    fail::cfg("apply_snap_cleanup_range", "pause").unwrap();

    let router = cluster.sim.wl().get_router(3).unwrap();
    fail::cfg("pause_on_peer_collect_message", "pause").unwrap();
    cluster.sim.wl().clear_recv_filters(3);
    cluster.clear_send_filters();
    router.send_raft_message(snap_msg).unwrap();
    router.send_raft_message(read_index_msg).unwrap();
    cluster.add_send_filter(IsolationFilterFactory::new(3));
    fail::remove("pause_on_peer_collect_message");
    must_get_none(&cluster.get_engine(3), b"k0");
    // Should not receive resp
    rx1.recv_timeout(Duration::from_millis(500)).unwrap_err();
    fail::remove("apply_snap_cleanup_range");
    rx1.recv_timeout(Duration::from_secs(5)).unwrap();
}
fn resumable_call_smoldot_tail_01() {
    let (mut store, wasm_fn) = resumable_call_smoldot_common(
        r#"
        (module
            (import "env" "host_fn" (func $host_fn (result i32)))
            (func (export "test") (result i32)
                (return_call $host_fn)
            )
        )
        "#,
    );
    assert_eq!(
        wasm_fn
            .call_resumable(&mut store, ())
            .unwrap_err()
            .i32_exit_status(),
        Some(100),
    );
}
fn test_datagram_stream_upgrades_on_truncation() {
    // Lookup to UDP should return a truncated message, then we expect lookup on TCP.
    // This should occur even though `try_tcp_on_error` is set to false.

    let query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);

    let tcp_record = v4_record(query.name().clone(), Ipv4Addr::new(127, 0, 0, 2));

    let mut udp_message = message(query.clone(), vec![], vec![], vec![]);
    udp_message.set_truncated(true);

    let tcp_message = message(query.clone(), vec![tcp_record.clone()], vec![], vec![]);

    let udp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(udp_message).unwrap())],
        Default::default(),
    );
    let tcp_nameserver = mock_nameserver(
        vec![Ok(DnsResponse::from_message(tcp_message).unwrap())],
        Default::default(),
    );

    let pool = mock_nameserver_pool(
        vec![udp_nameserver],
        vec![tcp_nameserver],
        None,
        Default::default(),
    );

    // lookup on UDP succeeds, any other would fail
    let request = message(query, vec![], vec![], vec![]);
    let future = pool.send(request).first_answer();

    let response = block_on(future).unwrap();
    assert_eq!(response.answers()[0], tcp_record);
}
fn test_chained_cname_lookup_preserve() {
    let resp_query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let cname_record = cname_record(
        Name::from_str("www.example.com.").unwrap(),
        Name::from_str("v4.example.com.").unwrap(),
    );
    let v4_record = v4_record(
        Name::from_str("v4.example.com.").unwrap(),
        Ipv4Addr::new(93, 184, 216, 34),
    );

    // The first response should be a cname, the second will be the actual record
    let message1 = message(
        resp_query.clone(),
        vec![cname_record.clone()],
        vec![],
        vec![],
    );
    let message2 = message(resp_query, vec![v4_record], vec![], vec![]);

    // the mock pops messages...
    let client: MockClientHandle<_, ResolveError> = MockClientHandle::mock(vec![
        Ok(DnsResponse::from_message(message2).unwrap()),
        Ok(DnsResponse::from_message(message1).unwrap()),
    ]);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, true),
    );

    let io_loop = Runtime::new().unwrap();
    let lookup = io_loop.block_on(lookup).unwrap();

    let mut iter = lookup.iter();
    assert_eq!(iter.next().unwrap(), cname_record.data().unwrap());
    assert_eq!(*iter.next().unwrap(), RData::A(A::new(93, 184, 216, 34)));
}
fn compute_error64_test() {
    // These test near-halfway cases for double-precision floats.
    assert_eq!(compute_error64(0, 9007199254740992), (1065 + f64::INVALID_FP, 9223372036854775808));
    assert_eq!(compute_error64(0, 9007199254740993), (1065 + f64::INVALID_FP, 9223372036854776832));
    assert_eq!(compute_error64(0, 9007199254740994), (1065 + f64::INVALID_FP, 9223372036854777856));
    assert_eq!(compute_error64(0, 9007199254740995), (1065 + f64::INVALID_FP, 9223372036854778880));
    assert_eq!(compute_error64(0, 9007199254740996), (1065 + f64::INVALID_FP, 9223372036854779904));
    assert_eq!(
        compute_error64(0, 18014398509481984),
        (1066 + f64::INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error64(0, 18014398509481986),
        (1066 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error64(0, 18014398509481988),
        (1066 + f64::INVALID_FP, 9223372036854777856)
    );
    assert_eq!(
        compute_error64(0, 18014398509481990),
        (1066 + f64::INVALID_FP, 9223372036854778880)
    );
    assert_eq!(
        compute_error64(0, 18014398509481992),
        (1066 + f64::INVALID_FP, 9223372036854779904)
    );

    // Test a much closer set of examples.
    assert_eq!(
        compute_error64(0, 9007199254740991),
        (1064 + f64::INVALID_FP, 18446744073709549568)
    );
    assert_eq!(
        compute_error64(0, 9223372036854776831),
        (1075 + f64::INVALID_FP, 9223372036854776830)
    );
    assert_eq!(
        compute_error64(0, 9223372036854776832),
        (1075 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error64(0, 9223372036854776833),
        (1075 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error64(-42, 9123456727292927),
        (925 + f64::INVALID_FP, 13021432563531497894)
    );
    assert_eq!(
        compute_error64(-43, 91234567272929275),
        (925 + f64::INVALID_FP, 13021432563531498606)
    );
    assert_eq!(
        compute_error64(-42, 9123456727292928),
        (925 + f64::INVALID_FP, 13021432563531499320)
    );

    // These are examples of the above tests, with
    // digits from the exponent shifted to the mantissa.
    assert_eq!(
        compute_error64(-3, 9007199254740992000),
        (1065 + f64::INVALID_FP, 9223372036854775808)
    );
    assert_eq!(
        compute_error64(-3, 9007199254740993000),
        (1065 + f64::INVALID_FP, 9223372036854776832)
    );
    assert_eq!(
        compute_error64(-3, 9007199254740994000),
        (1065 + f64::INVALID_FP, 9223372036854777856)
    );
    assert_eq!(
        compute_error64(-3, 9007199254740995000),
        (1065 + f64::INVALID_FP, 9223372036854778880)
    );
    assert_eq!(
        compute_error64(-3, 9007199254740996000),
        (1065 + f64::INVALID_FP, 9223372036854779904)
    );

    // Test from errors in atof.
    assert_eq!(
        compute_error64(-18, 1000000178813934326),
        (1012 + f64::INVALID_FP, 9223373686122217470)
    );

    // Check edge-cases from previous errors.
    assert_eq!(
        compute_error64(-342, 2470328229206232720),
        (-64 + f64::INVALID_FP, 18446744073709551608)
    );
}
fn check_extend_unsafe_fixes() -> Result<()> {
    let tempdir = TempDir::new()?;
    let ruff_toml = tempdir.path().join("ruff.toml");
    fs::write(
        &ruff_toml,
        r#"
[lint]
extend-unsafe-fixes = ["UP034"]
"#,
    )?;

    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(["check", "--config"])
        .arg(&ruff_toml)
        .arg("-")
        .args([
            "--output-format",
            "text",
            "--no-cache",
            "--select",
            "F601,UP034",
        ])
        .pass_stdin("x = {'a': 1, 'a': 1}\nprint(('foo'))\n"),
            @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:14: F601 Dictionary key literal `'a'` repeated
    -:2:7: UP034 Avoid extraneous parentheses
    Found 2 errors.
    No fixes available (2 hidden fixes can be enabled with the `--unsafe-fixes` option).

    ----- stderr -----
    "###);

    Ok(())
}
fn version_negotiate_server() {
    let _guard = subscribe();
    let client_addr = "[::2]:7890".parse().unwrap();
    let mut server = Endpoint::new(Default::default(), Some(Arc::new(server_config())), true);
    let now = Instant::now();
    let event = server.handle(
        now,
        client_addr,
        None,
        None,
        // Long-header packet with reserved version number
        hex!("80 0a1a2a3a 04 00000000 04 00000000 00")[..].into(),
    );
    assert!(event.is_none());

    let io = server.poll_transmit();
    assert!(io.is_some());
    if let Some(Transmit { contents, .. }) = io {
        assert_ne!(contents[0] & 0x80, 0);
        assert_eq!(&contents[1..15], hex!("00000000 04 00000000 04 00000000"));
        assert!(contents[15..].chunks(4).any(|x| {
            DEFAULT_SUPPORTED_VERSIONS.contains(&u32::from_be_bytes(x.try_into().unwrap()))
        }));
    }
    assert_matches!(server.poll_transmit(), None);
}
fn f64_lossy_decimal_test() {
    const FORMAT: u128 = STANDARD;

    let options = Options::builder().lossy(true).build().unwrap();
    assert_eq!(
        Err(Error::EmptyMantissa(1)),
        f64::from_lexical_with_options::<FORMAT>(b".", &options)
    );
    assert_eq!(Err(Error::Empty(0)), f64::from_lexical_with_options::<FORMAT>(b"", &options));
    assert_eq!(Ok(0.0), f64::from_lexical_with_options::<FORMAT>(b"0.0", &options));
    assert_eq!(
        Err((Error::InvalidDigit(1)).into()),
        f64::from_lexical_with_options::<FORMAT>(b"1a", &options)
    );

    // Bug fix for Issue #8
    assert_eq!(
        Ok(5.002868148396374),
        f64::from_lexical_with_options::<FORMAT>(b"5.002868148396374", &options)
    );
}
fn str_type() {
    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();

    let definition: TableDefinition<&str, &str> = TableDefinition::new("x");

    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        table.insert("hello", "world").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());

    let mut iter = table.iter().unwrap();
    assert_eq!(iter.next().unwrap().unwrap().1.value(), "world");
    assert!(iter.next().is_none());

    let mut iter: Range<&str, &str> = table.range("a".."z").unwrap();
    assert_eq!(iter.next().unwrap().unwrap().1.value(), "world");
    assert!(iter.next().is_none());
}
fn parse_is_not_null() {
    use self::Expr::*;
    let sql = "a IS NOT NULL";
    assert_eq!(
        IsNotNull(Box::new(Identifier(Ident::new("a")))),
        verified_expr(sql)
    );
}
pub fn test_enable() {
    let mut test_suite = TestSuite::new(resource_metering::Config {
        receiver_address: "".to_string(),
        report_receiver_interval: ReadableDuration::millis(2500),
        max_resource_groups: 5000,
        precision: ReadableDuration::secs(1),
    });

    let port = alloc_port();
    test_suite.start_receiver_at(port);

    // Workload
    // [req-1, req-2]
    test_suite.setup_workload(vec!["req-1", "req-2"]);

    // | Address |
    // |   x     |
    sleep(Duration::from_millis(3000));
    assert!(test_suite.nonblock_receiver_all().is_empty());

    // | Address |
    // |   o     |
    test_suite.cfg_receiver_address(format!("127.0.0.1:{}", port));
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));

    // | Address |
    // |   x     |
    test_suite.cfg_receiver_address("");
    test_suite.flush_receiver();
    sleep(Duration::from_millis(3000));
    assert!(test_suite.nonblock_receiver_all().is_empty());

    // | Address |
    // |   o     |
    test_suite.cfg_receiver_address(format!("127.0.0.1:{}", port));
    let res = test_suite.block_receive_one();
    assert!(res.contains_key("req-1"));
    assert!(res.contains_key("req-2"));
}
fn error_loading_macro_from_unloaded_namespace() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 + true }}{% endmacro hello %}"),
        ("tpl", "{% import \"macros\" as macros %}{{ macro::hello() }}"),
    ])
    .unwrap();

    let result = tera.render("tpl", &Context::new());
    println!("{:#?}", result);
    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Macro namespace `macro` was not found in template `tpl`. Have you maybe forgotten to import it, or misspelled it?"
    );
}
fn parse_at_timezone() {
    let zero = Expr::Value(number("0"));
    let sql = "SELECT FROM_UNIXTIME(0) AT TIME ZONE 'UTC-06:00' FROM t";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::AtTimeZone {
            timestamp: Box::new(Expr::Function(Function {
                name: ObjectName(vec![Ident {
                    value: "FROM_UNIXTIME".to_string(),
                    quote_style: None,
                }]),
                args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(zero.clone()))],
                null_treatment: None,
                filter: None,
                over: None,
                distinct: false,
                special: false,
                order_by: vec![],
            })),
            time_zone: "UTC-06:00".to_string(),
        },
        expr_from_projection(only(&select.projection)),
    );

    let sql = r#"SELECT DATE_FORMAT(FROM_UNIXTIME(0) AT TIME ZONE 'UTC-06:00', '%Y-%m-%dT%H') AS "hour" FROM t"#;
    let select = verified_only_select(sql);
    assert_eq!(
        &SelectItem::ExprWithAlias {
            expr: Expr::Function(Function {
                name: ObjectName(vec![Ident {
                    value: "DATE_FORMAT".to_string(),
                    quote_style: None,
                },],),
                args: vec![
                    FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::AtTimeZone {
                        timestamp: Box::new(Expr::Function(Function {
                            name: ObjectName(vec![Ident {
                                value: "FROM_UNIXTIME".to_string(),
                                quote_style: None,
                            },],),
                            args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(zero))],
                            null_treatment: None,
                            filter: None,
                            over: None,
                            distinct: false,
                            special: false,
                            order_by: vec![],
                        },)),
                        time_zone: "UTC-06:00".to_string(),
                    },),),
                    FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::Value(
                        Value::SingleQuotedString("%Y-%m-%dT%H".to_string()),
                    ),),),
                ],
                null_treatment: None,
                filter: None,
                over: None,
                distinct: false,
                special: false,
                order_by: vec![],
            },),
            alias: Ident {
                value: "hour".to_string(),
                quote_style: Some('"'),
            },
        },
        only(&select.projection),
    );
}
fn filter_on_array_literal_works() {
    let mut context = Context::new();
    let i: Option<usize> = None;
    context.insert("existing", "hello");
    context.insert("null", &i);

    let inputs = vec![
        (r#"{{ [1, 2, 3] | length }}"#, "3"),
        (r#"{% set a = [1, 2, 3] | length %}{{ a }}"#, "3"),
        (r#"{% for a in [1, 2, 3] | slice(start=1) %}{{ a }}{% endfor %}"#, "23"),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn nested_many_instantiations() -> Result<()> {
    let component = r#"
(component
  (import "count" (func $count))
  (component $c1
    (import "count" (func $count))
    (core func $count_lower (canon lower (func $count)))
    (core module $m
        (import "" "" (func $count))
        (start $count)
    )
    (core instance (instantiate $m (with "" (instance (export "" (func $count_lower))))))
    (core instance (instantiate $m (with "" (instance (export "" (func $count_lower))))))
  )
  (component $c2
    (import "count" (func $count))
    (instance (instantiate $c1 (with "count" (func $count))))
    (instance (instantiate $c1 (with "count" (func $count))))
  )
  (component $c3
    (import "count" (func $count))
    (instance (instantiate $c2 (with "count" (func $count))))
    (instance (instantiate $c2 (with "count" (func $count))))
  )
  (component $c4
    (import "count" (func $count))
    (instance (instantiate $c3 (with "count" (func $count))))
    (instance (instantiate $c3 (with "count" (func $count))))
  )

  (instance (instantiate $c4 (with "count" (func $count))))
)
    "#;
    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, 0);
    let mut linker = Linker::new(&engine);
    linker
        .root()
        .func_wrap("count", |mut store: StoreContextMut<'_, u32>, _: ()| {
            *store.data_mut() += 1;
            Ok(())
        })?;
    linker.instantiate(&mut store, &component)?;
    assert_eq!(*store.data(), 16);
    Ok(())
}
fn test_effective_suffix_hex_last() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&[
        "-n",
        "4",
        "--hex-suffixes=7",
        "--numeric-suffixes=4",
        "-x",
        "-d",
        "--hex-suffixes=9",
        "threebytes.txt",
    ])
    .succeeds()
    .no_stdout()
    .no_stderr();
    assert_eq!(at.read("x09"), "a");
    assert_eq!(at.read("x0a"), "b");
    assert_eq!(at.read("x0b"), "c");
    assert_eq!(at.read("x0c"), "");
}
fn b_test() {
    assert_eq!(b(1e-45_f32), (1, -149));
    assert_eq!(b(5e-324_f64), (1, -1074));
    assert_eq!(b(1e-323_f64), (2, -1074));
    assert_eq!(b(2e-323_f64), (4, -1074));
    assert_eq!(b(3e-323_f64), (6, -1074));
    assert_eq!(b(4e-323_f64), (8, -1074));
    assert_eq!(b(5e-323_f64), (10, -1074));
    assert_eq!(b(6e-323_f64), (12, -1074));
    assert_eq!(b(7e-323_f64), (14, -1074));
    assert_eq!(b(8e-323_f64), (16, -1074));
    assert_eq!(b(9e-323_f64), (18, -1074));
    assert_eq!(b(1_f32), (8388608, -23));
    assert_eq!(b(1_f64), (4503599627370496, -52));
    assert_eq!(b(1e38_f32), (9860761, 103));
    assert_eq!(b(1e308_f64), (5010420900022432, 971));
}
fn parse_mssql_create_role() {
    let sql = "CREATE ROLE mssql AUTHORIZATION helena";
    match ms().verified_stmt(sql) {
        Statement::CreateRole {
            names,
            authorization_owner,
            ..
        } => {
            assert_eq_vec(&["mssql"], &names);
            assert_eq!(
                authorization_owner,
                Some(ObjectName(vec![Ident {
                    value: "helena".into(),
                    quote_style: None
                }]))
            );
        }
        _ => unreachable!(),
    }
}
fn test_parse_self_debug_pubnames() {
    let debug_info = read_section("debug_info");
    let debug_info = DebugInfo::new(&debug_info, LittleEndian);

    let debug_abbrev = read_section("debug_abbrev");
    let debug_abbrev = DebugAbbrev::new(&debug_abbrev, LittleEndian);

    let debug_pubnames = read_section("debug_pubnames");
    let debug_pubnames = DebugPubNames::new(&debug_pubnames, LittleEndian);

    let mut units = HashMap::new();
    let mut abbrevs = HashMap::new();
    let mut pubnames = debug_pubnames.items();
    while let Some(entry) = pubnames.next().expect("Should parse pubname OK") {
        let unit_offset = entry.unit_header_offset();
        let unit = units.entry(unit_offset).or_insert_with(|| {
            debug_info
                .header_from_offset(unit_offset)
                .expect("Should parse unit header OK")
        });
        let abbrev_offset = unit.debug_abbrev_offset();
        let abbrevs = abbrevs.entry(abbrev_offset).or_insert_with(|| {
            debug_abbrev
                .abbreviations(abbrev_offset)
                .expect("Should parse abbreviations OK")
        });
        let mut cursor = unit
            .entries_at_offset(abbrevs, entry.die_offset())
            .expect("DIE offset should be valid");
        assert!(cursor.next_dfs().expect("Should parse DIE").is_some());
    }
}
fn chars() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "pass") (param i32) (result i32) local.get 0)
            )
            (core instance $i (instantiate $m))

            (func (export "u32-to-char") (param "a" u32) (result char)
                (canon lift (core func $i "pass"))
            )
            (func (export "char-to-u32") (param "a" char) (result u32)
                (canon lift (core func $i "pass"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let u32_to_char = instance.get_typed_func::<(u32,), (char,)>(&mut store, "u32-to-char")?;
    let char_to_u32 = instance.get_typed_func::<(char,), (u32,)>(&mut store, "char-to-u32")?;

    let mut roundtrip = |x: char| -> Result<()> {
        assert_eq!(char_to_u32.call(&mut store, (x,))?, (x as u32,));
        char_to_u32.post_return(&mut store)?;
        assert_eq!(u32_to_char.call(&mut store, (x as u32,))?, (x,));
        u32_to_char.post_return(&mut store)?;
        Ok(())
    };

    roundtrip('x')?;
    roundtrip('a')?;
    roundtrip('\0')?;
    roundtrip('\n')?;
    roundtrip('ðŸ’')?;

    let u32_to_char = |store: &mut Store<()>| {
        Linker::new(&engine)
            .instantiate(&mut *store, &component)?
            .get_typed_func::<(u32,), (char,)>(&mut *store, "u32-to-char")
    };
    let err = u32_to_char(&mut store)?
        .call(&mut store, (0xd800,))
        .unwrap_err();
    assert!(err.to_string().contains("integer out of range"), "{}", err);
    let err = u32_to_char(&mut store)?
        .call(&mut store, (0xdfff,))
        .unwrap_err();
    assert!(err.to_string().contains("integer out of range"), "{}", err);
    let err = u32_to_char(&mut store)?
        .call(&mut store, (0x110000,))
        .unwrap_err();
    assert!(err.to_string().contains("integer out of range"), "{}", err);
    let err = u32_to_char(&mut store)?
        .call(&mut store, (u32::MAX,))
        .unwrap_err();
    assert!(err.to_string().contains("integer out of range"), "{}", err);

    Ok(())
}

#
fn test_stale_read_1pc_flow_replicate() {
    let (mut cluster, pd_client, mut leader_client) = prepare_for_stale_read(new_peer(1, 1));
    let mut follower_client2 = PeerClient::new(&cluster, 1, new_peer(2, 2));
    // Set the `stale_read` flag
    leader_client.ctx.set_stale_read(true);
    follower_client2.ctx.set_stale_read(true);

    let commit_ts1 = leader_client.must_kv_write(
        &pd_client,
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value1"[..])],
        b"key1".to_vec(),
    );

    // Can read `value1` with the newest ts
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), get_tso(&pd_client));

    // Stop replicate data to follower 2
    cluster.add_send_filter(CloneFilterFactory(
        RegionPacketFilter::new(1, 2)
            .direction(Direction::Recv)
            .msg_type(MessageType::MsgAppend),
    ));
    // Update `key1`
    leader_client.must_kv_prewrite_one_pc(
        vec![new_mutation(Op::Put, &b"key1"[..], &b"value2"[..])],
        b"key1".to_vec(),
        get_tso(&pd_client),
    );
    let read_ts = get_tso(&pd_client);
    // wait for advance_resolved_ts.
    sleep_ms(200);
    // Follower 2 can still read `value1`, but can not read `value2` due
    // to it don't have enough data
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value1".to_vec(), commit_ts1);
    let resp1 = follower_client2.kv_read(b"key1".to_vec(), read_ts);
    assert!(resp1.get_region_error().has_data_is_not_ready());

    // Leader have up to date data so it can read `value2`
    leader_client.must_kv_read_equal(b"key1".to_vec(), b"value2".to_vec(), get_tso(&pd_client));

    // clear the `MsgAppend` filter
    cluster.clear_send_filters();

    // Now we can read `value2` with the newest ts
    follower_client2.must_kv_read_equal(b"key1".to_vec(), b"value2".to_vec(), get_tso(&pd_client));
}
fn client_complete_io_for_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    assert!(client.is_handshaking());
    let (rdlen, wrlen) = client
        .complete_io(&mut OtherSession::new(&mut server))
        .unwrap();
    assert!(rdlen > 0 && wrlen > 0);
    assert!(!client.is_handshaking());
    assert!(!client.wants_write());
}
fn frame_consistency_is_configurable() {
    let image = create_image_with_oob_frames();

    {
        let options = DecodeOptions::new();
        let mut data = image.as_slice();
        let mut decoder = options.clone().read_info(&mut data).unwrap();
        assert!(decoder.read_next_frame().is_ok());
        assert!(decoder.read_next_frame().is_ok());
    }

    {
        let mut options = DecodeOptions::new();
        options.check_frame_consistency(true);
        let mut data = image.as_slice();
        let mut decoder = options.clone().read_info(&mut data).unwrap();
        assert!(decoder.read_next_frame().is_ok());
        assert!(decoder.read_next_frame().is_err());
    }

    {
        let mut options = DecodeOptions::new();
        options.check_frame_consistency(false);
        let mut data = image.as_slice();
        let mut decoder = options.clone().read_info(&mut data).unwrap();
        assert!(decoder.read_next_frame().is_ok());
        assert!(decoder.read_next_frame().is_ok());
    }
}
fn test_escaped() {
  assert_eq!(esc("abcd"), Err(Err::Error(("abcd", ErrorKind::Escaped))));
}
fn test_new_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let filename = "new_file_that_does_not_exist_yet";
    ucmd.args(&["-s", "8", filename])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert!(at.file_exists(filename));
    assert_eq!(at.read_bytes(filename), vec![b'\0'; 8]);
}
fn from_f64_test() {
    assert_eq!(
        compact::from_float(0.0f64),
        ExtendedFloat80 {
            mant: 0,
            exp: -1074
        }
    );
    assert_eq!(
        compact::from_float(-0.0f64),
        ExtendedFloat80 {
            mant: 0,
            exp: -1074
        }
    );
    assert_eq!(
        compact::from_float(5e-324f64),
        ExtendedFloat80 {
            mant: 1,
            exp: -1074
        }
    );
    assert_eq!(
        compact::from_float(1e-250f64),
        ExtendedFloat80 {
            mant: 6448907850777164,
            exp: -883
        }
    );
    assert_eq!(
        compact::from_float(1e-150f64),
        ExtendedFloat80 {
            mant: 7371020360979573,
            exp: -551
        }
    );
    assert_eq!(
        compact::from_float(1e-45f64),
        ExtendedFloat80 {
            mant: 6427752177035961,
            exp: -202
        }
    );
    assert_eq!(
        compact::from_float(1e-40f64),
        ExtendedFloat80 {
            mant: 4903985730770844,
            exp: -185
        }
    );
    assert_eq!(
        compact::from_float(2e-40f64),
        ExtendedFloat80 {
            mant: 4903985730770844,
            exp: -184
        }
    );
    assert_eq!(
        compact::from_float(1e-20f64),
        ExtendedFloat80 {
            mant: 6646139978924579,
            exp: -119
        }
    );
    assert_eq!(
        compact::from_float(2e-20f64),
        ExtendedFloat80 {
            mant: 6646139978924579,
            exp: -118
        }
    );
    assert_eq!(
        compact::from_float(1.0f64),
        ExtendedFloat80 {
            mant: 4503599627370496,
            exp: -52
        }
    );
    assert_eq!(
        compact::from_float(2.0f64),
        ExtendedFloat80 {
            mant: 4503599627370496,
            exp: -51
        }
    );
    assert_eq!(
        compact::from_float(1e20f64),
        ExtendedFloat80 {
            mant: 6103515625000000,
            exp: 14
        }
    );
    assert_eq!(
        compact::from_float(2e20f64),
        ExtendedFloat80 {
            mant: 6103515625000000,
            exp: 15
        }
    );
    assert_eq!(
        compact::from_float(1e40f64),
        ExtendedFloat80 {
            mant: 8271806125530277,
            exp: 80
        }
    );
    assert_eq!(
        compact::from_float(2e40f64),
        ExtendedFloat80 {
            mant: 8271806125530277,
            exp: 81
        }
    );
    assert_eq!(
        compact::from_float(1e150f64),
        ExtendedFloat80 {
            mant: 5503284107318959,
            exp: 446
        }
    );
    assert_eq!(
        compact::from_float(1e250f64),
        ExtendedFloat80 {
            mant: 6290184345309700,
            exp: 778
        }
    );
    assert_eq!(
        compact::from_float(1.7976931348623157e308),
        ExtendedFloat80 {
            mant: 9007199254740991,
            exp: 971
        }
    );
}
fn test_server_catching_api_error() {
    let raftkv_fp = "raftkv_early_error_report";
    let mut cluster = new_server_cluster(0, 1);
    cluster.run();
    let region = cluster.get_region(b"");
    let leader = region.get_peers()[0].clone();

    fail::cfg(raftkv_fp, "return").unwrap();

    let env = Arc::new(Environment::new(1));
    let channel =
        ChannelBuilder::new(env).connect(&cluster.sim.rl().get_addr(leader.get_store_id()));
    let client = TikvClient::new(channel);

    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let mut prewrite_req = PrewriteRequest::default();
    prewrite_req.set_context(ctx.clone());
    let mutation = kvrpcpb::Mutation {
        op: Op::Put,
        key: b"k3".to_vec(),
        value: b"v3".to_vec(),
        ..Default::default()
    };
    prewrite_req.set_mutations(vec![mutation].into_iter().collect());
    prewrite_req.primary_lock = b"k3".to_vec();
    prewrite_req.start_version = 1;
    prewrite_req.lock_ttl = prewrite_req.start_version + 1;
    let prewrite_resp = client.kv_prewrite(&prewrite_req).unwrap();
    assert!(prewrite_resp.has_region_error(), "{:?}", prewrite_resp);
    assert!(
        prewrite_resp.get_region_error().has_region_not_found(),
        "{:?}",
        prewrite_resp
    );
    must_get_none(&cluster.get_engine(1), b"k3");

    let mut put_req = RawPutRequest::default();
    put_req.set_context(ctx);
    put_req.key = b"k3".to_vec();
    put_req.value = b"v3".to_vec();
    let put_resp = client.raw_put(&put_req).unwrap();
    assert!(put_resp.has_region_error(), "{:?}", put_resp);
    assert!(
        put_resp.get_region_error().has_region_not_found(),
        "{:?}",
        put_resp
    );
    must_get_none(&cluster.get_engine(1), b"k3");

    fail::remove(raftkv_fp);
    let put_resp = client.raw_put(&put_req).unwrap();
    assert!(!put_resp.has_region_error(), "{:?}", put_resp);
    must_get_equal(&cluster.get_engine(1), b"k3", b"v3");
}
fn fs_error_dereferenced_symlink() {
    let fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let root_path = temp_dir().join("lint_rome_test_broken_symlink");
    let subdir_path = root_path.join("prefix");

    let _ = remove_dir_all(&root_path);
    create_dir(&root_path).unwrap();
    create_dir(subdir_path).unwrap();

    #[cfg(target_family = "unix")]
    {
        symlink(root_path.join("null"), root_path.join("broken_symlink")).unwrap();
    }

    #[cfg(target_os = "windows")]
    {
        check_windows_symlink!(symlink_file(
            root_path.join("null"),
            root_path.join("broken_symlink")
        ));
    }

    let result = run_cli(
        DynRef::Owned(Box::new(OsFileSystem)),
        &mut console,
        Args::from([("lint"), root_path.display().to_string().as_str()].as_slice()),
    );

    remove_dir_all(root_path).unwrap();

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_dereferenced_symlink",
        fs,
        console,
        result,
    ));
}
fn test_lookup_ipv4_like_fall_through() {
    let authority = create_ip_like_example();
    let mut catalog = Catalog::new();
    catalog.upsert(authority.origin().clone(), Box::new(Arc::new(authority)));

    let io_loop = Runtime::new().unwrap();
    let (stream, sender) = TestClientStream::new(Arc::new(StdMutex::new(catalog)));
    let dns_conn = DnsMultiplexer::new(stream, sender, NoopMessageFinalizer::new());

    let client = DnsExchange::connect::<_, _, TokioTime>(dns_conn);
    let (client, bg) = io_loop.block_on(client).expect("client connect failed");
    hickory_proto::spawn_bg(&io_loop, bg);

    let lookup = LookupIpFuture::lookup(
        vec![Name::from_str("198.51.100.35.example.com.").unwrap()],
        LookupIpStrategy::default(),
        CachingClient::new(0, client, false),
        Default::default(),
        Some(Arc::new(Hosts::default())),
        Some(RData::A(A::new(198, 51, 100, 35))),
    );
    let lookup = io_loop.block_on(lookup).unwrap();

    assert_eq!(
        lookup.iter().next().unwrap(),
        Ipv4Addr::new(198, 51, 100, 35)
    );
}
fn parse_is_null() {
    use self::Expr::*;
    let sql = "a IS NULL";
    assert_eq!(
        IsNull(Box::new(Identifier(Ident::new("a")))),
        verified_expr(sql)
    );
}
fn get_set_externref_globals_via_api() -> anyhow::Result<()> {
    let mut cfg = Config::new();
    cfg.wasm_reference_types(true);
    let engine = Engine::new(&cfg)?;
    let mut store = Store::new(&engine, ());

    // Initialize with a null externref.

    let global = Global::new(
        &mut store,
        GlobalType::new(ValType::ExternRef, Mutability::Var),
        Val::ExternRef(None),
    )?;
    assert!(global.get(&mut store).unwrap_externref().is_none());

    global.set(
        &mut store,
        Val::ExternRef(Some(ExternRef::new("hello".to_string()))),
    )?;
    let r = global.get(&mut store).unwrap_externref().unwrap();
    assert!(r.data().is::<String>());
    assert_eq!(r.data().downcast_ref::<String>().unwrap(), "hello");

    // Initialize with a non-null externref.

    let global = Global::new(
        &mut store,
        GlobalType::new(ValType::ExternRef, Mutability::Const),
        Val::ExternRef(Some(ExternRef::new(42_i32))),
    )?;
    let r = global.get(&mut store).unwrap_externref().unwrap();
    assert!(r.data().is::<i32>());
    assert_eq!(r.data().downcast_ref::<i32>().copied().unwrap(), 42);

    Ok(())
}
fn test_install_backup_short_no_args_file_to_dir() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file = "test_install_simple_backup_file_a";
    let dest_dir = "test_install_dest/";
    let expect = format!("{dest_dir}{file}");

    at.touch(file);
    at.mkdir(dest_dir);
    at.touch(&expect);
    scene
        .ucmd()
        .arg("-b")
        .arg(file)
        .arg(dest_dir)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));
    assert!(at.file_exists(&expect));
    assert!(at.file_exists(format!("{expect}~")));
}
fn options_test() {
    let mut buffer = [b'\x00'; 48];
    let options = Options::new();
    assert_eq!(b"0", 0u8.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0u16.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0u32.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0u64.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0u128.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0i8.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0i16.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0i32.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0i64.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
    assert_eq!(b"0", 0i128.to_lexical_with_options::<{ STANDARD }>(&mut buffer, &options));
}
fn from_stdin() {
  assert_eq!(
    CommandBuilder::new("decode")
      .stdin(transaction())
      .run_and_deserialize_output::<Output>(),
    Output {
      inscriptions: vec![Inscription {
        body: Some(vec![0, 1, 2, 3]),
        content_type: Some(b"text/plain;charset=utf-8".to_vec()),
        ..Default::default()
      }],
    }
  );
}
fn term_test() {
  assert_eq!(term(" 12 *2 /  3"), Ok(("", 8)));
  assert_eq!(term(" 2* 3  *2 *2 /  3"), Ok(("", 8)));
  assert_eq!(term(" 48 /  3/2"), Ok(("", 8)));
}
fn test_mv_arg_backup_arg_first() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_simple_backup_file_a";
    let file_b = "test_mv_simple_backup_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup").arg(file_a).arg(file_b).succeeds();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_line_bytes_no_eof() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-C", "3"])
        .pipe_in("1\n2222\n3\n4")
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "1\n");
    assert_eq!(at.read("xab"), "222");
    assert_eq!(at.read("xac"), "2\n");
    assert_eq!(at.read("xad"), "3\n");
    assert_eq!(at.read("xae"), "4");
    assert!(!at.plus("xaf").exists());
}
fn exit_with_saved_fprs() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit_with_saved_fprs.wat")?;
    let output = run_wasmtime_for_output(&["-Ccache=n", wasm.path().to_str().unwrap()], None)?;
    assert_eq!(output.status.code().unwrap(), 0);
    assert!(output.stdout.is_empty());
    Ok(())
}
fn u16_pow10_test() {
    let values: &[u16] = &[
        0, 1, 5, 9, 10, 11, 15, 99, 100, 101, 105, 999, 1000, 1001, 1005, 9999, 10000, 10001, 10005,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn test_bin() {
    assert_eq!(from_str("0b101"), Ok(0b101));
    assert_eq!(from_str("0b001"), Ok(0b001));
    assert_eq!(from_str("0b100100"), Ok(0b100100));

    assert_eq!(
        from_str::<u8>("0b"),
        Err(SpannedError {
            code: Error::ExpectedInteger,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0b_1"),
        Err(SpannedError {
            code: Error::UnderscoreAtBeginning,
            position: Position { line: 1, col: 3 },
        })
    );
    assert_eq!(
        from_str::<u8>("0b111111111"),
        Err(SpannedError {
            code: Error::IntegerOutOfBounds,
            position: Position { line: 1, col: 12 },
        })
    );
}
fn math_test() {
    let mut x = VecType::try_from(&[0, 1, 9]).unwrap();
    assert_eq!(x.is_normalized(), true);
    x.try_push(0).unwrap();
    assert_eq!(&*x, &[0, 1, 9, 0]);
    assert_eq!(x.is_normalized(), false);
    x.normalize();
    assert_eq!(&*x, &[0, 1, 9]);
    assert_eq!(x.is_normalized(), true);

    x.add_small(1);
    assert_eq!(&*x, &[1, 1, 9]);
    x.add_small(Limb::MAX);
    assert_eq!(&*x, &[0, 2, 9]);

    x.mul_small(3);
    assert_eq!(&*x, &[0, 6, 27]);
    x.mul_small(Limb::MAX);
    let expected: VecType = if LIMB_BITS == 32 {
        vec_from_u32(&[0, 4294967290, 4294967274, 26])
    } else {
        vec_from_u32(&[0, 0, 4294967290, 4294967295, 4294967274, 4294967295, 26])
    };
    assert_eq!(&*x, &*expected);

    #[cfg(feature = "radix")]
    {
        let mut x: VecType = vec_from_u32(&[0, 0, 0, 536870912]);
        let y: VecType = vec_from_u32(&[3358091099, 2770363594, 2782716766, 217327764]);
        assert_eq!(x.quorem(&y), 2);
        let expected: VecType = vec_from_u32(&[1873752394, 3049207402, 3024501058, 102215382]);
        assert_eq!(&*x, &*expected);
    }

    let mut x = VecType::from_u32(0xFFFFFFFF);
    let y = VecType::from_u32(5);
    x *= &y;
    let expected: VecType = vec_from_u32(&[0xFFFFFFFB, 0x4]);
    assert_eq!(&*x, &*expected);

    // Test with carry
    let mut x = VecType::from_u32(1);
    assert_eq!(&*x, &[1]);
    x.add_small(Limb::MAX);
    assert_eq!(&*x, &[0, 1]);
}
fn test_priority() {
    let (control_tx, control_fsm) = Runner::new(10);
    let (router, mut system) =
        batch_system::create_system(&Config::default(), control_tx, control_fsm, None);
    let builder = Builder::new();
    system.spawn("test".to_owned(), builder);
    let (tx, rx) = mpsc::unbounded();
    let tx_ = tx.clone();
    let r = router.clone();
    let state_cnt = Arc::new(AtomicUsize::new(0));
    router
        .send_control(Message::Callback(Box::new(
            move |_: &Handler, _: &mut Runner| {
                let (tx, runner) = Runner::new(10);
                r.register(1, BasicMailbox::new(tx, runner, state_cnt.clone()));
                let (tx2, mut runner2) = Runner::new(10);
                runner2.set_priority(Priority::Low);
                r.register(2, BasicMailbox::new(tx2, runner2, state_cnt));
                tx_.send(1).unwrap();
            },
        )))
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(1));

    let tx_ = tx.clone();
    router
        .send(
            1,
            Message::Callback(Box::new(move |h: &Handler, r: &mut Runner| {
                assert_eq!(h.get_priority(), Priority::Normal);
                assert_eq!(h.get_priority(), r.get_priority());
                tx_.send(2).unwrap();
            })),
        )
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(2));

    router
        .send(
            2,
            Message::Callback(Box::new(move |h: &Handler, r: &mut Runner| {
                assert_eq!(h.get_priority(), Priority::Low);
                assert_eq!(h.get_priority(), r.get_priority());
                tx.send(3).unwrap();
            })),
        )
        .unwrap();
    assert_eq!(rx.recv_timeout(Duration::from_secs(3)), Ok(3));
}
fn should_not_format_js_files_if_disabled() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let biome_json = Path::new("biome.json");
    fs.insert(
        biome_json.into(),
        r#"{
        "formatter": {
            "indentStyle": "space"
        },
        "javascript": {
            "formatter": {
                "enabled": false
            }
        },
        "json": {
            "formatter": {
                "lineWidth": 80,
                "indentSize": 2
            }
        }
    }"#,
    );

    let json_file_content = r#"
{
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let json_file = Path::new("input.json");
    fs.insert(json_file.into(), json_file_content.as_bytes());

    let js_file_content = r#"
const a = {
    "array": ["lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum", "lorem ipsum"]
}
    "#;
    let js_file = Path::new("input.js");
    fs.insert(js_file.into(), js_file_content.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                "--write",
                json_file.as_os_str().to_str().unwrap(),
                js_file.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(js_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, js_file_content);

    drop(file);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_not_format_js_files_if_disabled",
        fs,
        console,
        result,
    ));
}
fn v128() -> anyhow::Result<()> {
    let mut store = Store::<()>::default();
    let g = Global::new(
        &mut store,
        GlobalType::new(ValType::V128, Mutability::Var),
        0u128.into(),
    )?;
    assert_eq!(g.get(&mut store).v128(), Some(V128::from(0)));
    g.set(&mut store, 1u128.into())?;
    assert_eq!(g.get(&mut store).v128(), Some(V128::from(1)));
    Ok(())
}
fn client_verifier_no_schemes() {
    for kt in ALL_KEY_TYPES.iter() {
        let client_verifier = MockClientVerifier {
            verified: ver_ok,
            subjects: get_client_root_store(*kt)
                .roots
                .iter()
                .map(|r| r.subject().clone())
                .collect(),
            mandatory: true,
            offered_schemes: Some(vec![]),
        };

        let server_config = server_config_with_verifier(*kt, client_verifier);
        let server_config = Arc::new(server_config);

        for version in rustls::ALL_VERSIONS {
            let client_config = make_client_config_with_versions_with_auth(*kt, &[version]);
            let (mut client, mut server) =
                make_pair_for_arc_configs(&Arc::new(client_config.clone()), &server_config);
            let err = do_handshake_until_error(&mut client, &mut server);
            assert_eq!(
                err,
                Err(ErrorFromPeer::Client(Error::InvalidMessage(
                    InvalidMessage::NoSignatureSchemes,
                ))),
            );
        }
    }
}
fn test_cp_backup_off() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=off")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert!(!at.file_exists(format!("{TEST_HOW_ARE_YOU_SOURCE}~")));
}
fn test_ebkalderon_case() {
    let file = r#"BuildSystem(
    version: "1.0.0",
    flags: [
        "--enable-thing",
        "--enable-other-thing",
        If("some-conditional", ["--enable-third-thing"]),
    ]
)
"#;

    assert_eq!(
        from_str::<BuildSystem>(file).unwrap(),
        BuildSystem {
            version: "1.0.0".into(),
            flags: vec![
                Flag::Value("--enable-thing".into()),
                Flag::Value("--enable-other-thing".into()),
                Flag::If(
                    "some-conditional".into(),
                    vec!["--enable-third-thing".into()]
                )
            ]
        },
    );
}
fn wallet_balance() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  create_wallet(&rpc_server);

  assert_eq!(
    CommandBuilder::new("wallet balance")
      .rpc_server(&rpc_server)
      .run_and_deserialize_output::<Output>()
      .cardinal,
    0
  );

  rpc_server.mine_blocks(1);

  assert_eq!(
    CommandBuilder::new("wallet balance")
      .rpc_server(&rpc_server)
      .run_and_deserialize_output::<Output>()
      .cardinal,
    50 * COIN_VALUE
  );
}
fn u16_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0u16.to_lexical(&mut buffer));
    assert_eq!(b"1", 1u16.to_lexical(&mut buffer));
    assert_eq!(b"5", 5u16.to_lexical(&mut buffer));
    assert_eq!(b"32767", 32767u16.to_lexical(&mut buffer));
    assert_eq!(b"32768", 32768u16.to_lexical(&mut buffer));
    assert_eq!(b"65535", 65535u16.to_lexical(&mut buffer));
    assert_eq!(b"65535", (-1i16 as u16).to_lexical(&mut buffer));
}
fn test_install_copy_file() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file1 = "source_file";
    let file2 = "target_file";

    at.touch(file1);
    ucmd.arg(file1).arg(file2).succeeds().no_stderr();

    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
}
fn cap_two() {
    let db = default_engine();
    let mut wb = db.engine.write_batch_with_cap(2);
    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.put(b"f", b"").unwrap();
    wb.write().unwrap();
    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"f").unwrap().is_some());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(2);

    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.put(b"c", b"").unwrap();
    wb.put(b"d", b"").unwrap();
    wb.put(b"e", b"").unwrap();
    wb.put(b"f", b"").unwrap();
    wb.write().unwrap();
    assert!(
        db.engine
            .get_value(&0_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(
        db.engine
            .get_value(&123_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(
        db.engine
            .get_value(&255_usize.to_be_bytes())
            .unwrap()
            .is_some()
    );
    assert!(db.engine.get_value(b"a").unwrap().is_some());
    assert!(db.engine.get_value(b"f").unwrap().is_some());
}
fn stateful_global_fn() {
    fn make_tera() -> Tera {
        let mut tera = Tera::default();
        tera.add_raw_template(
            "fn.html",
            "<h1>{{ get_next() }}, {{ get_next_shared() }}, {{ get_next() }}...</h1>",
        )
        .unwrap();

        tera.register_function("get_next", Next(AtomicUsize::new(1)));
        tera.register_function("get_next_shared", NEXT_GLOBAL.clone());
        tera
    }

    assert_eq!(
        make_tera().render("fn.html", &Context::new()).unwrap(),
        "<h1>1, 1, 2...</h1>".to_owned()
    );
    assert_eq!(
        make_tera().render("fn.html", &Context::new()).unwrap(),
        "<h1>1, 2, 2...</h1>".to_owned()
    );
}
fn parse_key_value_test() {
  let ini_file = &b"parameter=value
key = value2"[..];

  let ini_without_key_value = &b"\nkey = value2"[..];

  let res = key_value(ini_file);
  println!("{:?}", res);
  match res {
    Ok((i, (o1, o2))) => println!("i: {:?} | o: ({:?},{:?})", str::from_utf8(i), o1, o2),
    _ => println!("error"),
  }

  assert_eq!(res, Ok((ini_without_key_value, ("parameter", "value"))));
}
fn parse_compound_expr_1() {
    use self::BinaryOperator::*;
    use self::Expr::*;
    let sql = "a + b * c";
    assert_eq!(
        BinaryOp {
            left: Box::new(Identifier(Ident::new("a"))),
            op: Plus,
            right: Box::new(BinaryOp {
                left: Box::new(Identifier(Ident::new("b"))),
                op: Multiply,
                right: Box::new(Identifier(Ident::new("c"))),
            }),
        },
        verified_expr(sql)
    );
}
fn scoped_packages() {
    let f = super::fixture().join("scoped");

    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let pass = [
        ("main field should work", f.clone(), "@scope/pack1", f.join("./node_modules/@scope/pack1/main.js")),
        ("browser field should work", f.clone(), "@scope/pack2", f.join("./node_modules/@scope/pack2/main.js")),
        ("folder request should work", f.clone(), "@scope/pack2/lib", f.join("./node_modules/@scope/pack2/lib/index.js"))
    ];

    for (comment, path, request, expected) in pass {
        let resolved_path = resolver.resolve(&f, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{comment} {path:?} {request}");
    }
}
fn save_point_all_commands() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    db.engine.put(b"a", b"").unwrap();
    db.engine.put(b"d", b"").unwrap();

    wb.set_save_point();
    wb.delete(b"a").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.delete_range(b"c", b"e").unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();

    let a = db.engine.get_value(b"a").unwrap();
    let b = db.engine.get_value(b"b").unwrap();
    let d = db.engine.get_value(b"d").unwrap();
    assert!(a.is_some());
    assert!(b.is_none());
    assert!(d.is_some());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);
    let max_keys = 256_usize;

    for i in 0..max_keys / 2 {
        db.engine.put(&i.to_be_bytes(), b"").unwrap();
    }
    db.engine.put(b"a", b"").unwrap();
    for i in max_keys / 2..max_keys {
        db.engine.put(&i.to_be_bytes(), b"").unwrap();
    }
    db.engine.put(b"d", b"").unwrap();

    wb.set_save_point();
    for i in 0..max_keys / 2 {
        wb.delete(&i.to_be_bytes()).unwrap();
    }
    wb.delete(b"a").unwrap();
    wb.put(b"b", b"").unwrap();
    wb.delete_range(b"c", b"e").unwrap();
    wb.delete_range(&(max_keys / 3).to_be_bytes(), &(2 * max_keys).to_be_bytes())
        .unwrap();

    wb.rollback_to_save_point().unwrap();
    wb.write().unwrap();

    let a = db.engine.get_value(b"a").unwrap();
    let b = db.engine.get_value(b"b").unwrap();
    let d = db.engine.get_value(b"d").unwrap();
    for i in 0..max_keys {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_some());
    }
    assert!(a.is_some());
    assert!(b.is_none());
    assert!(d.is_some());
}
fn test_alter_table_swap_with() {
    let sql = "ALTER TABLE tab1 SWAP WITH tab2";
    match alter_table_op_with_name(snowflake_and_generic().verified_stmt(sql), "tab1") {
        AlterTableOperation::SwapWith { table_name } => {
            assert_eq!("tab2", table_name.to_string());
        }
        _ => unreachable!(),
    };
}
fn test_request_snapshot_after_reboot() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.pd_heartbeat_tick_interval = ReadableDuration::millis(20);
    cluster.cfg.raft_store.check_request_snapshot_interval = ReadableDuration::millis(20);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    cluster.must_put(b"k1", b"v1");

    std::thread::sleep(Duration::from_millis(100));
    must_get_none(&cluster.get_engine(3), b"k1");

    // witness -> nonwitness
    let fp = "ignore request snapshot";
    fail::cfg(fp, "return").unwrap();
    cluster
        .pd_client
        .switch_witnesses(region.get_id(), vec![peer_on_store3.get_id()], vec![false]);
    std::thread::sleep(Duration::from_millis(500));
    // as we ignore request snapshot, so snapshot should still not applied yet
    assert_eq!(cluster.pd_client.get_pending_peers().len(), 1);
    must_get_none(&cluster.get_engine(3), b"k1");

    cluster.stop_node(nodes[2]);
    fail::remove(fp);
    std::thread::sleep(Duration::from_millis(100));
    // the PeerState is Unavailable, so it will request snapshot immediately after
    // start.
    cluster.run_node(nodes[2]).unwrap();
    must_get_none(&cluster.get_engine(3), b"k1");
    std::thread::sleep(Duration::from_millis(500));
    must_get_equal(&cluster.get_engine(3), b"k1", b"v1");
    assert_eq!(cluster.pd_client.get_pending_peers().len(), 0);
}
fn parse_create_table_on_cluster() {
    // Using single-quote literal to define current cluster
    let sql = "CREATE TABLE t ON CLUSTER '{cluster}' (a INT, b INT)";
    match verified_stmt(sql) {
        Statement::CreateTable { on_cluster, .. } => {
            assert_eq!(on_cluster.unwrap(), "{cluster}".to_string());
        }
        _ => unreachable!(),
    }

    // Using explicitly declared cluster name
    let sql = "CREATE TABLE t ON CLUSTER my_cluster (a INT, b INT)";
    match verified_stmt(sql) {
        Statement::CreateTable { on_cluster, .. } => {
            assert_eq!(on_cluster.unwrap(), "my_cluster".to_string());
        }
        _ => unreachable!(),
    }
}
fn test_witness_ignore_consistency_check() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_election_timeout_ticks = 50;
    // disable compact log to make test more stable.
    cluster.cfg.raft_store.raft_log_gc_threshold = 1000;
    cluster.cfg.raft_store.consistency_check_interval = ReadableDuration::secs(1);
    cluster.run();

    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k1", b"v1");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );

    // make sure the peer_on_store3 has completed applied to witness
    std::thread::sleep(Duration::from_millis(200));

    for i in 0..300 {
        cluster.must_put(
            format!("k{:06}", i).as_bytes(),
            format!("k{:06}", i).as_bytes(),
        );
        std::thread::sleep(Duration::from_millis(10));
    }
}
fn test_basic() {
    let env = create_env();
    let t = env.get_template("hello").unwrap();
    assert_eq!(t.render(()).unwrap(), "Hello World!");
}
fn test_basic_write() {
    let cluster = Cluster::default();
    let router = &cluster.routers[0];
    let header = Box::new(router.new_request_for(2).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");

    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    // Good proposal should be committed.
    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub.wait_proposed()));
    assert!(block_on(sub.wait_committed()));
    let resp = block_on(sub.result()).unwrap();
    assert!(!resp.get_header().has_error(), "{:?}", resp);

    // Store id should be checked.
    let mut invalid_header = header.clone();
    invalid_header.set_peer(new_peer(3, 3));
    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();
    assert!(
        resp.get_header().get_error().has_store_not_match(),
        "{:?}",
        resp
    );

    // Peer id should be checked.
    invalid_header = header.clone();
    invalid_header.set_peer(new_peer(1, 1));
    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();
    assert!(resp.get_header().has_error(), "{:?}", resp);

    // Epoch should be checked.
    invalid_header = header.clone();
    invalid_header
        .mut_region_epoch()
        .set_version(INIT_EPOCH_VER - 1);
    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();
    assert!(
        resp.get_header().get_error().has_epoch_not_match(),
        "{:?}",
        resp
    );

    // Term should be checked if set.
    invalid_header = header.clone();
    invalid_header.set_term(1);
    let resp = router.simple_write(2, invalid_header, put.clone()).unwrap();
    assert!(
        resp.get_header().get_error().has_stale_command(),
        "{:?}",
        resp
    );

    // Too large message can cause regression and should be rejected.
    let mut invalid_put = SimpleWriteEncoder::with_capacity(9 * 1024 * 1024);
    invalid_put.put(CF_DEFAULT, b"key", &vec![0; 8 * 1024 * 1024]);
    let resp = router.simple_write(2, header.clone(), invalid_put).unwrap();
    assert!(
        resp.get_header().get_error().has_raft_entry_too_large(),
        "{:?}",
        resp
    );

    // Make it step down and follower should reject write.
    let mut msg = Box::<RaftMessage>::default();
    msg.set_region_id(2);
    msg.set_to_peer(new_peer(1, 3));
    msg.mut_region_epoch().set_conf_ver(INIT_EPOCH_CONF_VER);
    msg.set_from_peer(new_peer(2, 4));
    let raft_message = msg.mut_message();
    raft_message.set_msg_type(raft::prelude::MessageType::MsgHeartbeat);
    raft_message.set_from(4);
    raft_message.set_term(8);
    router.send_raft_message(msg).unwrap();
    let resp = router.simple_write(2, header, put).unwrap();
    assert!(resp.get_header().get_error().has_not_leader(), "{:?}", resp);
}
fn unnamed_field_struct() {
    #[derive(CacheKey, Hash)]
    struct UnnamedFieldsStruct(String, String);

    let mut key = CacheKeyHasher::new();

    let unnamed_fields = UnnamedFieldsStruct("Hello".into(), "World".into());

    unnamed_fields.cache_key(&mut key);

    let mut hash = CacheKeyHasher::new();
    unnamed_fields.hash(&mut hash);

    assert_eq!(hash.finish(), key.finish());
}
fn parse_like() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that LIKE and NOT LIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = hive().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_mock_lookup() {
    let resp_query = Query::query(Name::from_str("www.example.com.").unwrap(), RecordType::A);
    let v4_record = v4_record(
        Name::from_str("www.example.com.").unwrap(),
        Ipv4Addr::new(93, 184, 216, 34),
    );
    let message = message(resp_query, vec![v4_record], vec![], vec![]);
    let client: MockClientHandle<_, ResolveError> =
        MockClientHandle::mock(vec![Ok(DnsResponse::from_message(message).unwrap())]);

    let lookup = LookupFuture::lookup(
        vec![Name::from_str("www.example.com.").unwrap()],
        RecordType::A,
        Default::default(),
        CachingClient::new(0, client, false),
    );

    let io_loop = Runtime::new().unwrap();
    let lookup = io_loop.block_on(lookup).unwrap();

    assert_eq!(
        *lookup.iter().next().unwrap(),
        RData::A(A::new(93, 184, 216, 34))
    );
}
fn hi64_test() {
    assert_eq!(VecType::from_u16(0xA).hi64(), (0xA000000000000000, false));
    assert_eq!(VecType::from_u32(0xAB).hi64(), (0xAB00000000000000, false));
    assert_eq!(VecType::from_u64(0xAB00000000).hi64(), (0xAB00000000000000, false));
    assert_eq!(VecType::from_u64(0xA23456789A).hi64(), (0xA23456789A000000, false));
}
fn f32_lossy_decimal_test() {
    const FORMAT: u128 = STANDARD;

    let options = Options::builder().lossy(true).build().unwrap();
    assert_eq!(
        Err(Error::EmptyMantissa(1)),
        f32::from_lexical_with_options::<FORMAT>(b".", &options)
    );
    assert_eq!(Err(Error::Empty(0)), f32::from_lexical_with_options::<FORMAT>(b"", &options));
    assert_eq!(Ok(0.0), f32::from_lexical_with_options::<FORMAT>(b"0.0", &options));
    assert_eq!(
        Err((Error::InvalidDigit(1)).into()),
        f32::from_lexical_with_options::<FORMAT>(b"1a", &options)
    );

    // Bug fix for Issue #8
    assert_eq!(
        Ok(5.002868148396374),
        f32::from_lexical_with_options::<FORMAT>(b"5.002868148396374", &options)
    );
}
fn fabsd_sanity_test() {
    assert_eq!(libm::fabsd(-1.0), 1.0);
    assert_eq!(libm::fabsd(2.8), 2.8);
}
fn client_respects_buffer_limit_pre_handshake() {
    let (mut client, mut server) = make_pair(KeyType::Rsa);

    client.set_buffer_limit(Some(32));

    assert_eq!(
        client
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        20
    );
    assert_eq!(
        client
            .writer()
            .write(b"01234567890123456789")
            .unwrap(),
        12
    );

    do_handshake(&mut client, &mut server);
    transfer(&mut client, &mut server);
    server.process_new_packets().unwrap();

    check_read(&mut server.reader(), b"01234567890123456789012345678901");
}
fn error_location_inside_macro() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}{{ 1 + true }}{% endmacro hello %}"),
        ("tpl", "{% import \"macros\" as macros %}{{ macros::hello() }}"),
    ])
    .unwrap();

    let result = tera.render("tpl", &Context::new());

    assert_eq!(
        result.unwrap_err().to_string(),
        "Failed to render \'tpl\': error while rendering macro `macros::hello`"
    );
}
fn remove_next_ws_if_single_opening_tag_requires_it() {
    let ws = WS { left: true, right: true };
    let ast = vec![
        Node::ImportMacro(ws, "hey ".to_string(), "ho".to_string()),
        Node::Text("  hey".to_string()),
    ];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![
            Node::ImportMacro(ws, "hey ".to_string(), "ho".to_string()),
            Node::Text("hey".to_string()), // it removed the leading space
        ]
    );
}
fn test_cp_arg_no_clobber() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("--no-clobber")
        .fails()
        .stderr_contains("not replacing");

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "How are you?\n");
}
fn is_valid_ascii_test() {
    assert_eq!(ascii::is_valid_ascii(b'\x00'), false);
    assert_eq!(ascii::is_valid_ascii(b'\n'), true);
    assert_eq!(ascii::is_valid_ascii(b'\r'), true);
    assert_eq!(ascii::is_valid_ascii(b'\x1b'), false);
    assert_eq!(ascii::is_valid_ascii(b' '), true);
    assert_eq!(ascii::is_valid_ascii(b'0'), true);
    assert_eq!(ascii::is_valid_ascii(b'9'), true);
    assert_eq!(ascii::is_valid_ascii(b':'), true);
    assert_eq!(ascii::is_valid_ascii(b'A'), true);
    assert_eq!(ascii::is_valid_ascii(b'Z'), true);
    assert_eq!(ascii::is_valid_ascii(b']'), true);
    assert_eq!(ascii::is_valid_ascii(b'a'), true);
    assert_eq!(ascii::is_valid_ascii(b'z'), true);
    assert_eq!(ascii::is_valid_ascii(b'~'), true);
    assert_eq!(ascii::is_valid_ascii(b'\x7f'), false);
}
fn test_merge() {
    let mut cluster = Cluster::default();
    let store_id = cluster.node(0).id();
    let raft_engine = cluster.node(0).running_state().unwrap().raft_engine.clone();
    let router = &mut cluster.routers[0];

    let do_split =
        |r: &mut TestRouter, region: Region, peer: &Peer, v: u64| -> (Region, Region, Peer) {
            let rid = region.get_id();
            let old_region_state = raft_engine
                .get_region_state(rid, u64::MAX)
                .unwrap()
                .unwrap();
            let new_peer = new_peer(store_id, peer.get_id() + 1);
            let (lhs, rhs) = split_region(
                r,
                region,
                peer.clone(),
                rid + 1,
                new_peer.clone(),
                Some(format!("k{}{}", rid, v).as_bytes()),
                Some(format!("k{}{}", rid + 1, v).as_bytes()),
                format!("k{}", rid + 1).as_bytes(),
                format!("k{}", rid + 1).as_bytes(),
                false,
            );
            let region_state = raft_engine
                .get_region_state(rid, u64::MAX)
                .unwrap()
                .unwrap();
            assert!(region_state.get_tablet_index() > old_region_state.get_tablet_index());
            assert_eq!(
                region_state.get_region().get_region_epoch().get_version(),
                old_region_state
                    .get_region()
                    .get_region_epoch()
                    .get_version()
                    + 1,
            );
            let region_state = raft_engine
                .get_region_state(rid + 1, u64::MAX)
                .unwrap()
                .unwrap();
            assert_eq!(region_state.get_tablet_index(), RAFT_INIT_LOG_INDEX);
            (lhs, rhs, new_peer)
        };

    let region_1 = router.region_detail(2);
    let peer_1 = region_1.get_peers()[0].clone();
    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    // Split into 6.
    let (region_1, region_2, peer_2) = do_split(router, region_1, &peer_1, 1);
    let (region_2, region_3, peer_3) = do_split(router, region_2, &peer_2, 2);
    let (region_3, region_4, peer_4) = do_split(router, region_3, &peer_3, 3);
    let (region_4, region_5, peer_5) = do_split(router, region_4, &peer_4, 4);
    let (region_5, region_6, peer_6) = do_split(router, region_5, &peer_5, 5);
    drop(raft_engine);
    // The last region version is smaller.
    for (i, v) in [1, 2, 3, 4, 5, 5].iter().enumerate() {
        let rid = region_1.get_id() + i as u64;
        let snapshot = router.stale_snapshot(rid);
        let key = format!("k{rid}{v}");
        assert!(
            snapshot.get_value(key.as_bytes()).unwrap().is_some(),
            "{} {:?}",
            rid,
            key
        );
    }

    let region_2 = merge_region(&cluster, 0, region_1.clone(), peer_1, region_2, true);
    {
        let snapshot = cluster.routers[0].stale_snapshot(region_2.get_id());
        let key = format!("k{}1", region_1.get_id());
        assert!(snapshot.get_value(key.as_bytes()).unwrap().is_some());
    }
    let region_5 = merge_region(&cluster, 0, region_6.clone(), peer_6, region_5, true);
    {
        let snapshot = cluster.routers[0].stale_snapshot(region_5.get_id());
        let key = format!("k{}5", region_6.get_id());
        assert!(snapshot.get_value(key.as_bytes()).unwrap().is_some());
    }
    let region_3 = merge_region(&cluster, 0, region_2, peer_2, region_3, true);
    let region_4 = merge_region(&cluster, 0, region_3, peer_3, region_4, true);
    let region_5 = merge_region(&cluster, 0, region_4, peer_4, region_5, true);

    cluster.restart(0);
    let snapshot = cluster.routers[0].stale_snapshot(region_5.get_id());
    for (i, v) in [1, 2, 3, 4, 5, 5].iter().enumerate() {
        let rid = region_1.get_id() + i as u64;
        let key = format!("k{rid}{v}");
        assert!(
            snapshot.get_value(key.as_bytes()).unwrap().is_some(),
            "{} {:?}",
            rid,
            key
        );
    }
}
fn formatting_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "formatting_error",
        fs,
        console,
        result,
    ));
}
fn parse_ctes() {
    let cte_sqls = vec!["SELECT 1 AS foo", "SELECT 2 AS bar"];
    let with = &format!(
        "WITH a AS ({}), b AS ({}) SELECT foo + bar FROM a, b",
        cte_sqls[0], cte_sqls[1]
    );

    fn assert_ctes_in_select(expected: &[&str], sel: &Query) {
        for (i, exp) in expected.iter().enumerate() {
            let Cte { alias, query, .. } = &sel.with.as_ref().unwrap().cte_tables[i];
            assert_eq!(*exp, query.to_string());
            assert_eq!(
                if i == 0 {
                    Ident::new("a")
                } else {
                    Ident::new("b")
                },
                alias.name
            );
            assert!(alias.columns.is_empty());
        }
    }

    // Top-level CTE
    assert_ctes_in_select(&cte_sqls, &verified_query(with));
    // CTE in a subquery
    let sql = &format!("SELECT ({with})");
    let select = verified_only_select(sql);
    match expr_from_projection(only(&select.projection)) {
        Expr::Subquery(ref subquery) => {
            assert_ctes_in_select(&cte_sqls, subquery.as_ref());
        }
        _ => panic!("Expected subquery"),
    }
    // CTE in a derived table
    let sql = &format!("SELECT * FROM ({with})");
    let select = verified_only_select(sql);
    match only(select.from).relation {
        TableFactor::Derived { subquery, .. } => {
            assert_ctes_in_select(&cte_sqls, subquery.as_ref())
        }
        _ => panic!("Expected derived table"),
    }
    // CTE in a view
    let sql = &format!("CREATE VIEW v AS {with}");
    match verified_stmt(sql) {
        Statement::CreateView { query, .. } => assert_ctes_in_select(&cte_sqls, &query),
        _ => panic!("Expected CREATE VIEW"),
    }
    // CTE in a CTE...
    let sql = &format!("WITH outer_cte AS ({with}) SELECT * FROM outer_cte");
    let select = verified_query(sql);
    assert_ctes_in_select(&cte_sqls, &only(&select.with.unwrap().cte_tables).query);
}
fn empty() {
  assert_eq!(
    CommandBuilder::new("epochs").run_and_deserialize_output::<Output>(),
    Output {
      starting_sats: vec![
        Sat(0),
        Sat(1050000000000000),
        Sat(1575000000000000),
        Sat(1837500000000000),
        Sat(1968750000000000),
        Sat(2034375000000000),
        Sat(2067187500000000),
        Sat(2083593750000000),
        Sat(2091796875000000),
        Sat(2095898437500000),
        Sat(2097949218750000),
        Sat(2098974609270000),
        Sat(2099487304530000),
        Sat(2099743652160000),
        Sat(2099871825870000),
        Sat(2099935912620000),
        Sat(2099967955890000),
        Sat(2099983977420000),
        Sat(2099991988080000),
        Sat(2099995993410000),
        Sat(2099997995970000),
        Sat(2099998997250000),
        Sat(2099999497890000),
        Sat(2099999748210000),
        Sat(2099999873370000),
        Sat(2099999935950000),
        Sat(2099999967240000),
        Sat(2099999982780000),
        Sat(2099999990550000),
        Sat(2099999994330000),
        Sat(2099999996220000),
        Sat(2099999997060000),
        Sat(2099999997480000),
        Sat(2099999997690000)
      ]
    }
  );
}
fn test_something() {
    let data = [];
    let encoded = STANDARD.encode(data);
    let decoded = STANDARD.decode(&encoded).unwrap();
    assert_eq!(data, decoded.as_slice());
}
fn parse_update() {
    let sql = "UPDATE t SET a = 1, b = 2, c = 3 WHERE d";
    match verified_stmt(sql) {
        Statement::Update {
            table,
            assignments,
            selection,
            ..
        } => {
            assert_eq!(table.to_string(), "t".to_string());
            assert_eq!(
                assignments,
                vec![
                    Assignment {
                        id: vec!["a".into()],
                        value: Expr::Value(number("1")),
                    },
                    Assignment {
                        id: vec!["b".into()],
                        value: Expr::Value(number("2")),
                    },
                    Assignment {
                        id: vec!["c".into()],
                        value: Expr::Value(number("3")),
                    },
                ]
            );
            assert_eq!(selection.unwrap(), Expr::Identifier("d".into()));
        }
        _ => unreachable!(),
    }

    verified_stmt("UPDATE t SET a = 1, a = 2, a = 3");

    let sql = "UPDATE t WHERE 1";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected SET, found: WHERE".to_string()),
        res.unwrap_err()
    );

    let sql = "UPDATE t SET a = 1 extrabadstuff";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Expected end of statement, found: extrabadstuff".to_string()),
        res.unwrap_err()
    );
}
fn test_encode_nonfinite_float_yields_null() {
    let v = to_value(::std::f64::NAN.copysign(1.0)).unwrap();
    assert!(v.is_null());

    let v = to_value(::std::f64::NAN.copysign(-1.0)).unwrap();
    assert!(v.is_null());

    let v = to_value(::std::f64::INFINITY).unwrap();
    assert!(v.is_null());

    let v = to_value(-::std::f64::INFINITY).unwrap();
    assert!(v.is_null());

    let v = to_value(::std::f32::NAN.copysign(1.0)).unwrap();
    assert!(v.is_null());

    let v = to_value(::std::f32::NAN.copysign(-1.0)).unwrap();
    assert!(v.is_null());

    let v = to_value(::std::f32::INFINITY).unwrap();
    assert!(v.is_null());

    let v = to_value(-::std::f32::INFINITY).unwrap();
    assert!(v.is_null());
}
fn fs_error_infinite_symlink_expansion_to_files() {
    let mut console = BufferConsole::default();

    let root_path = temp_dir().join("lint_rome_test_infinite_symlink_expansion_to_files");
    let subdir1_path = root_path.join("prefix");
    let subdir2_path = root_path.join("foo").join("bar");

    let _ = remove_dir_all(&root_path);
    create_dir_all(&subdir1_path).unwrap();
    create_dir_all(&subdir2_path).unwrap();

    let symlink1_path = subdir1_path.join("symlink1");
    let symlink2_path = subdir2_path.join("symlink2");

    #[cfg(target_family = "unix")]
    {
        symlink(&symlink2_path, &symlink1_path).unwrap();
        symlink(&symlink1_path, &symlink2_path).unwrap();
    }

    #[cfg(target_os = "windows")]
    {
        check_windows_symlink!(symlink_dir(&symlink2_path, &symlink1_path));
        check_windows_symlink!(symlink_dir(&symlink1_path, &symlink2_path));
    }

    let result = run_cli(
        DynRef::Owned(Box::new(OsFileSystem)),
        &mut console,
        Args::from([("lint"), (root_path.display().to_string().as_str())].as_slice()),
    );

    remove_dir_all(root_path).unwrap();

    assert!(result.is_err(), "run_cli returned {result:?}");

    // Don't use a snapshot here, since the diagnostics can be reported in
    // arbitrary order:
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains("Deeply nested symlink expansion")));
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains(&symlink1_path.display().to_string())));
    assert!(console
        .out_buffer
        .iter()
        .flat_map(|msg| msg.content.0.iter())
        .any(|node| node.content.contains(&symlink2_path.display().to_string())));
}
async fn recv_too_big_headers() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_frame_eq(settings, frames::settings().max_header_list_size(10));
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://http2.akamai.com/")
                .eos(),
        )
        .await;
        srv.recv_frame(
            frames::headers(3)
                .request("GET", "https://http2.akamai.com/")
                .eos(),
        )
        .await;
        srv.send_frame(frames::headers(1).response(200).eos()).await;
        srv.send_frame(frames::headers(3).response(200)).await;
        // no reset for 1, since it's closed anyway
        // but reset for 3, since server hasn't closed stream
        srv.recv_frame(frames::reset(3).refused()).await;
        idle_ms(10).await;
    };

    let client = async move {
        let (mut client, mut conn) = client::Builder::new()
            .max_header_list_size(10)
            .handshake::<_, Bytes>(io)
            .await
            .expect("handshake");

        let request = Request::builder()
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let req1 = client.send_request(request, true);
        let req1 = async move {
            let err = req1.expect("send_request").0.await.expect_err("response1");
            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));
        };

        let request = Request::builder()
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let req2 = client.send_request(request, true);
        let req2 = async move {
            let err = req2.expect("send_request").0.await.expect_err("response2");
            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));
        };

        conn.drive(join(req1, req2)).await;
        conn.await.expect("client");
    };
    join(srv, client).await;
}
fn test_split_separator_semicolon_line_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["--line-bytes=4", "-t", ";", "separator_semicolon.txt"])
        .succeeds();

    assert_eq!(file_read(&at, "xaa"), "1;2;");
    assert_eq!(file_read(&at, "xab"), "3;4;");
    assert_eq!(file_read(&at, "xac"), "5;");
    assert!(!at.plus("xad").exists());
}
fn test_multiple_name_value_pairs() {
    let out = new_ucmd!().arg("FOO=bar").arg("ABC=xyz").run();

    assert_eq!(
        out.stdout_str()
            .lines()
            .filter(|&line| line == "FOO=bar" || line == "ABC=xyz")
            .count(),
        2
    );
}
fn does_not_format_ignored_directories() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();

    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_FORMATTER_IGNORED_DIRECTORIES.as_bytes(),
    );

    const FILES: [(&str, bool); 9] = [
        ("test.js", true),
        ("test1.js", false),
        ("test2.js", false),
        ("test3/test.js", false),
        ("test4/test.js", true),
        ("test5/test.js", false),
        ("test6/test.js", false),
        ("test/test.test7.js", false),
        ("test.test7.js", false),
    ];

    for (file_path, _) in FILES {
        let file_path = Path::new(file_path);
        fs.insert(file_path.into(), UNFORMATTED.as_bytes());
    }

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("./"), ("--write")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    for (file_path, expect_formatted) in FILES {
        let mut file = fs
            .open(Path::new(file_path))
            .expect("formatting target file was removed by the CLI");

        let mut content = String::new();
        file.read_to_string(&mut content)
            .expect("failed to read file from memory FS");

        let expected = if expect_formatted {
            FORMATTED
        } else {
            UNFORMATTED
        };

        assert_eq!(
            content, expected,
            "content of {file_path} doesn't match the expected content"
        );
    }

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_format_ignored_directories",
        fs,
        console,
        result,
    ));
}
fn test_digits() {
    let num_string = serde_yaml::from_str::<Value>("01").unwrap();
    assert!(num_string.is_string());
}
fn render_include_tag() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("world", "world"),
        ("hello", "<h1>Hello {% include \"world\" %}</h1>"),
    ])
    .unwrap();
    let result = tera.render("hello", &Context::new()).unwrap();
    assert_eq!(result, "<h1>Hello world</h1>".to_owned());
}
fn test_version_flag() {
    let version_short = new_ucmd!().arg("-V").succeeds();
    let version_long = new_ucmd!().arg("--version").succeeds();

    assert_eq!(version_short.stdout_str(), version_long.stdout_str());
}
fn upgrade_severity() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        CONFIG_LINTER_UPGRADE_DIAGNOSTIC.as_bytes(),
    );

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), UPGRADE_SEVERITY_CODE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    let messages = &console.out_buffer;

    let error_count = messages
        .iter()
        .filter(|m| m.level == LogLevel::Error)
        .filter(|m| {
            let content = format!("{:?}", m.content);
            content.contains("style/noNegationElse")
        })
        .count();

    assert_eq!(
        error_count, 1,
        "expected 1 error-level message in console buffer, found {error_count:?}:\n{:?}",
        console.out_buffer
    );

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "upgrade_severity",
        fs,
        console,
        result,
    ));
}
fn test_initial_table_limits_exceeded() -> Result<()> {
    let engine = Engine::default();
    let module = Module::new(&engine, r#"(module (table (export "t") 23 anyfunc))"#)?;

    let mut store = Store::new(&engine, StoreLimitsBuilder::new().table_elements(4).build());
    store.limiter(|s| s as &mut dyn ResourceLimiter);

    match Instance::new(&mut store, &module, &[]) {
        Ok(_) => unreachable!(),
        Err(e) => assert_eq!(
            e.to_string(),
            "table minimum size of 23 elements exceeds table limits"
        ),
    }

    match Table::new(
        &mut store,
        TableType::new(ValType::FuncRef, 99, None),
        Val::FuncRef(None),
    ) {
        Ok(_) => unreachable!(),
        Err(e) => assert_eq!(
            e.to_string(),
            "table minimum size of 99 elements exceeds table limits"
        ),
    }

    Ok(())
}
fn seed_phrases_are_twelve_words_long() {
  let Output { mnemonic, .. } = CommandBuilder::new("wallet create")
    .rpc_server(&test_bitcoincore_rpc::spawn())
    .run_and_deserialize_output();

  assert_eq!(mnemonic.word_count(), 12);
}
fn batch_in_separate_outputs_with_parent() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 0);

  create_wallet(&rpc_server);

  let parent_output = CommandBuilder::new("wallet inscribe --fee-rate 5.0 --file parent.png")
    .write("parent.png", [1; 520])
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  rpc_server.mine_blocks(1);

  assert_eq!(rpc_server.descriptors().len(), 3);

  let parent_id = parent_output.inscriptions[0].id;

  let output = CommandBuilder::new("wallet inscribe --fee-rate 1 --batch batch.yaml")
    .write("inscription.txt", "Hello World")
    .write("tulip.png", [0; 555])
    .write("meow.wav", [0; 2048])
    .write(
      "batch.yaml",
      format!("parent: {parent_id}\nmode: separate-outputs\ninscriptions:\n- file: inscription.txt\n- file: tulip.png\n- file: meow.wav\n")
    )
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Inscribe>();

  for inscription in &output.inscriptions {
    assert_eq!(inscription.location.offset, 0);
  }
  let mut outpoints = output
    .inscriptions
    .iter()
    .map(|inscription| inscription.location.outpoint)
    .collect::<Vec<OutPoint>>();
  outpoints.sort();
  outpoints.dedup();
  assert_eq!(outpoints.len(), output.inscriptions.len());

  rpc_server.mine_blocks(1);

  let ord_server = TestServer::spawn_with_args(&rpc_server, &[]);

  let output_1 = output.inscriptions[0].location.outpoint;
  let output_2 = output.inscriptions[1].location.outpoint;
  let output_3 = output.inscriptions[2].location.outpoint;

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[0].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>10000</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_1
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[1].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>10000</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_2
    ),
  );

  ord_server.assert_response_regex(
    format!("/inscription/{}", output.inscriptions[2].id),
    format!(
      r".*<dt>parent</dt>\s*<dd>.*{parent_id}.*</dd>.*<dt>output value</dt>.*<dd>10000</dd>.*.*<dt>location</dt>.*<dd class=monospace>{}:0</dd>.*",
      output_3
    ),
  );
}
fn link_undefined() -> Result<()> {
    let mut store = Store::<()>::default();
    let linker = Linker::new(store.engine());
    let module = Module::new(store.engine(), r#"(module (import "" "" (func)))"#)?;
    assert!(linker.instantiate(&mut store, &module).is_err());
    let module = Module::new(store.engine(), r#"(module (import "" "" (global i32)))"#)?;
    assert!(linker.instantiate(&mut store, &module).is_err());
    let module = Module::new(store.engine(), r#"(module (import "" "" (memory 1)))"#)?;
    assert!(linker.instantiate(&mut store, &module).is_err());
    let module = Module::new(
        store.engine(),
        r#"(module (import "" "" (table 1 funcref)))"#,
    )?;
    assert!(linker.instantiate(&mut store, &module).is_err());
    Ok(())
}
fn test_select_failed() {
    let mut cluster = test_raftstore::new_server_cluster(0, 3);
    cluster.cfg.raft_store.check_leader_lease_interval = ReadableDuration::hours(10);
    cluster.run();
    // make sure leader has been elected.
    assert_eq!(cluster.must_get(b""), None);
    let region = cluster.get_region(b"");
    let leader = cluster.leader_of_region(region.get_id()).unwrap();
    let engine = cluster.sim.rl().storages[&leader.get_id()].clone();
    let mut ctx = Context::default();
    ctx.set_region_id(region.get_id());
    ctx.set_region_epoch(region.get_region_epoch().clone());
    ctx.set_peer(leader);

    let product = ProductTable::new();
    let (_, endpoint, _) =
        init_data_with_engine_and_commit(ctx.clone(), engine, &product, &[], true);

    // Sleep until the leader lease is expired.
    thread::sleep(
        cluster.cfg.raft_store.raft_heartbeat_interval()
            * cluster.cfg.raft_store.raft_election_timeout_ticks as u32
            * 2,
    );
    for id in 1..=3 {
        if id != ctx.get_peer().get_store_id() {
            cluster.stop_node(id);
        }
    }
    let req = DagSelect::from(&product).build_with(ctx.clone(), &[0]);
    let f = endpoint.parse_and_handle_unary_request(req, None);
    cluster.stop_node(ctx.get_peer().get_store_id());
    drop(cluster);
    let _ = futures::executor::block_on(f);
}
fn export_inscription_number_to_id_tsv() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  let temp_dir = TempDir::new().unwrap();
  create_wallet(&rpc_server);

  inscribe(&rpc_server);
  inscribe(&rpc_server);
  let (inscription, _) = inscribe(&rpc_server);

  rpc_server.mine_blocks(1);

  let tsv = CommandBuilder::new("index export --tsv foo.tsv")
    .rpc_server(&rpc_server)
    .temp_dir(temp_dir)
    .stdout_regex(r"\{\}\n")
    .run_and_extract_file("foo.tsv");

  let entries: std::collections::BTreeMap<i64, ord::Object> = tsv
    .lines()
    .filter(|line| !line.is_empty() && !line.starts_with('#'))
    .map(|line| {
      let value = line.split('\t').collect::<Vec<&str>>();
      let inscription_number = i64::from_str(value[0]).unwrap();
      let inscription_id = ord::Object::from_str(value[1]).unwrap();

      (inscription_number, inscription_id)
    })
    .collect();

  assert_eq!(
    entries.get(&2).unwrap(),
    &ord::Object::InscriptionId(inscription),
  );
}
fn test_delete_all() {
    use hickory_proto::rr::rdata::AAAA;

    let catalog = Catalog::new();
    let (client, origin) = create_sig0_ready_client(catalog);

    // append a record
    let mut record = Record::with(
        Name::from_str("new.example.com").unwrap(),
        RecordType::A,
        Duration::minutes(5).whole_seconds() as u32,
    );
    record.set_data(Some(RData::A(A::new(100, 10, 100, 10))));

    // first check the must_exist option
    let result = client
        .delete_all(record.name().clone(), origin.clone(), DNSClass::IN)
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // next create to a non-existent RRset
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    record.set_rr_type(RecordType::AAAA);
    record.set_data(Some(RData::AAAA(AAAA::new(1, 2, 3, 4, 5, 6, 7, 8))));
    let result = client
        .create(record.clone(), origin.clone())
        .expect("create failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    // verify record contents
    let result = client
        .delete_all(record.name().clone(), origin, DNSClass::IN)
        .expect("delete failed");
    assert_eq!(result.response_code(), ResponseCode::NoError);

    let result = client
        .query(record.name(), record.dns_class(), RecordType::A)
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);

    let result = client
        .query(record.name(), record.dns_class(), RecordType::AAAA)
        .expect("query failed");
    assert_eq!(result.response_code(), ResponseCode::NXDomain);
    assert_eq!(result.answers().len(), 0);
}
fn does_handle_included_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "ignore": ["test.js", "special/**"]
  },
  "overrides": [{ "include": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), FIX_BEFORE.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FIX_AFTER);
    assert_file_contents(&fs, test, FIX_BEFORE);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_included_file",
        fs,
        console,
        result,
    ));
}
fn float_fast_path_test() {
    // valid
    let mantissa = (1 << f32::MANTISSA_SIZE) - 1;
    let (min_exp, max_exp) = f32::exponent_limit();
    for exp in min_exp..=max_exp {
        let f = fast_path::<f32>(mantissa, exp);
        assert!(f.is_some(), "should be valid {:?}.", (mantissa, exp));
    }

    // Check slightly above valid exponents
    let f = fast_path::<f32>(123, 15);
    assert_eq!(f, Some(1.23e+17));

    // Exponent is 1 too high, pushes over the mantissa.
    let f = fast_path::<f32>(123, 16);
    assert!(f.is_none());

    // Mantissa is too large, checked_mul should overflow.
    let f = fast_path::<f32>(mantissa, 11);
    assert!(f.is_none());

    // invalid exponents
    let (min_exp, max_exp) = f32::exponent_limit();
    let f = fast_path::<f32>(mantissa, min_exp - 1);
    assert!(f.is_none(), "exponent under min_exp");

    let f = fast_path::<f32>(mantissa, max_exp + 1);
    assert!(f.is_none(), "exponent above max_exp");
}
fn invalid_api() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "thunk1"))
                (func (export "thunk2"))
            )
            (core instance $i (instantiate $m))
            (func (export "thunk1")
                (canon lift (core func $i "thunk1"))
            )
            (func (export "thunk2")
                (canon lift (core func $i "thunk2"))
            )
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let instance = Linker::new(&engine).instantiate(&mut store, &component)?;
    let thunk1 = instance.get_typed_func::<(), ()>(&mut store, "thunk1")?;
    let thunk2 = instance.get_typed_func::<(), ()>(&mut store, "thunk2")?;

    // Ensure that we can't call `post_return` before doing anything
    let msg = "post_return can only be called after a function has previously been called";
    assert_panics(|| drop(thunk1.post_return(&mut store)), msg);
    assert_panics(|| drop(thunk2.post_return(&mut store)), msg);

    // Schedule a "needs post return"
    thunk1.call(&mut store, ())?;

    // Ensure that we can't reenter the instance through either this function or
    // another one.
    let err = thunk1.call(&mut store, ()).unwrap_err();
    assert_eq!(
        err.downcast_ref(),
        Some(&Trap::CannotEnterComponent),
        "{err}",
    );
    let err = thunk2.call(&mut store, ()).unwrap_err();
    assert_eq!(
        err.downcast_ref(),
        Some(&Trap::CannotEnterComponent),
        "{err}",
    );

    // Calling post-return on the wrong function should panic
    assert_panics(
        || drop(thunk2.post_return(&mut store)),
        "calling post_return on wrong function",
    );

    // Actually execute the post-return
    thunk1.post_return(&mut store)?;

    // And now post-return should be invalid again.
    assert_panics(|| drop(thunk1.post_return(&mut store)), msg);
    assert_panics(|| drop(thunk2.post_return(&mut store)), msg);

    Ok(())
}
fn compute_nearest_shorter_test() {
    assert_eq!(compute_nearest_shorter(0.5), (5, -1));
    assert_eq!(compute_nearest_shorter(1.0), (1, 0));
    assert_eq!(compute_nearest_shorter(2.0), (2, 0));
}
fn insert_79_custom_std_headers() {
    let mut h = HeaderMap::new();
    let hdrs = custom_std(79);

    for (i, hdr) in hdrs.iter().enumerate() {
        h.insert(hdr.clone(), hdr.as_str().parse().unwrap());

        for j in 0..(i + 1) {
            assert_eq!(h[&hdrs[j]], hdrs[j].as_str());
        }

        for j in (i + 1)..hdrs.len() {
            assert!(h.get(&hdrs[j]).is_none());
        }
    }
}
fn test_split_additional_suffix_hyphen_value() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "split_additional_suffix";
    RandomFile::new(&at, name).add_lines(2000);
    ucmd.args(&["--additional-suffix", "-300", name]).succeeds();

    let glob = Glob::new(&at, ".", r"x[[:alpha:]][[:alpha:]]-300$");
    assert_eq!(glob.count(), 2);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
fn test_split_obs_lines_within_combined_shorts_tailing_suffix_length() {
    let (at, mut ucmd) = at_and_ucmd!();
    let name = "obs-lines-combined-shorts-tailing-suffix-length";
    RandomFile::new(&at, name).add_lines(1000);
    ucmd.args(&["-d200a4", name]).succeeds();

    let glob = Glob::new(&at, ".", r"x\d\d\d\d$");
    assert_eq!(glob.count(), 5);
    assert_eq!(glob.collate(), at.read_bytes(name));
}
async fn recv_push_promise_over_max_header_list_size() {
    h2_support::trace_init!();
    let (io, mut srv) = mock::new();

    let srv = async move {
        let settings = srv.assert_client_handshake().await;
        assert_frame_eq(settings, frames::settings().max_header_list_size(10));
        srv.recv_frame(
            frames::headers(1)
                .request("GET", "https://http2.akamai.com/")
                .eos(),
        )
        .await;
        srv.send_frame(
            frames::push_promise(1, 2).request("GET", "https://http2.akamai.com/style.css"),
        )
        .await;
        srv.recv_frame(frames::reset(2).refused()).await;
        srv.send_frame(frames::headers(1).response(200).eos()).await;
        idle_ms(10).await;
    };

    let client = async move {
        let (mut client, mut conn) = client::Builder::new()
            .max_header_list_size(10)
            .handshake::<_, Bytes>(io)
            .await
            .expect("handshake");
        let request = Request::builder()
            .uri("https://http2.akamai.com/")
            .body(())
            .unwrap();

        let req = async move {
            let err = client
                .send_request(request, true)
                .expect("send_request")
                .0
                .await
                .expect_err("response");
            assert_eq!(err.reason(), Some(Reason::REFUSED_STREAM));
        };

        conn.drive(req).await;
        conn.await.expect("client");
    };
    join(srv, client).await;
}
fn test_literal_mangling() {
    let code = "0_4";
    let parsed: Lit = syn::parse_str(code).unwrap();
    assert_eq!(code, quote!(#parsed).to_string());
}
async fn test_ttl_wilcard() {
    let config = FileConfig {
        zone_file_path: "../../tests/test-data/test_configs/default/test.local.zone".to_string(),
    };

    let zone_name = LowerName::from_str("test.local.").unwrap();
    let mut authority = FileAuthority::try_from_config(
        Name::from(zone_name.clone()),
        ZoneType::Primary,
        false,
        None,
        &config,
    )
    .unwrap();

    // This one pass.
    let rrkey = RrKey {
        record_type: RecordType::A,
        name: LowerName::from(Name::from_ascii("simple.test.local.").unwrap()),
    };
    assert_eq!(authority.records_get_mut().get(&rrkey).unwrap().ttl(), 120);
    // // This one related to a wildcard don't pass arround $TTL
    let name = LowerName::from(Name::from_ascii("x.wc.test.local.").unwrap());
    let rr = authority
        .lookup(&name, RecordType::A, LookupOptions::default())
        .await
        .unwrap();
    let data = rr
        .into_iter()
        .next()
        .expect("A record not found in authority");

    assert_eq!(data.record_type(), RecordType::A);
    assert_eq!(data.ttl(), 120);
}
fn parse_alter_view_with_columns() {
    let sql = "ALTER VIEW v (has, cols) AS SELECT 1, 2";
    match verified_stmt(sql) {
        Statement::AlterView {
            name,
            columns,
            query,
            with_options,
        } => {
            assert_eq!("v", name.to_string());
            assert_eq!(columns, vec![Ident::new("has"), Ident::new("cols")]);
            assert_eq!("SELECT 1, 2", query.to_string());
            assert_eq!(with_options, vec![]);
        }
        _ => unreachable!(),
    }
}
fn no_lint_when_file_is_ignored() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("biome.json");
    fs.insert(file_path.into(), CONFIG_LINTER_IGNORED_FILES.as_bytes());

    let file_path = Path::new("test.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, CHECK_FORMAT_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "no_lint_when_file_is_ignored",
        fs,
        console,
        result,
    ));
}
fn catch_trap_calling_across_stores() -> Result<()> {
    let _ = env_logger::try_init();

    let engine = Engine::default();

    let mut child_store = Store::new(&engine, ());
    let child_module = Module::new(
        child_store.engine(),
        r#"
            (module $child
              (func $trap (export "trap")
                unreachable
              )
            )
        "#,
    )?;
    let child_instance = Instance::new(&mut child_store, &child_module, &[])?;

    struct ParentCtx {
        child_store: Store<()>,
        child_instance: Instance,
    }

    let mut linker = Linker::new(&engine);
    linker.func_wrap(
        "host",
        "catch_child_trap",
        move |mut caller: Caller<'_, ParentCtx>| {
            let mut ctx = caller.as_context_mut();
            let data = ctx.data_mut();
            let func = data
                .child_instance
                .get_typed_func::<(), ()>(&mut data.child_store, "trap")
                .expect("trap function should be exported");

            let trap = func.call(&mut data.child_store, ()).unwrap_err();
            assert!(
                format!("{trap:?}").contains("unreachable"),
                "trap should contain 'unreachable', got: {trap:?}"
            );

            let trace = trap.downcast_ref::<WasmBacktrace>().unwrap().frames();

            assert_eq!(trace.len(), 1);
            assert_eq!(trace[0].func_name(), Some("trap"));
            // For now, we only get stack frames for Wasm in this store, not
            // across all stores.
            //
            // assert_eq!(trace[1].func_name(), Some("run"));

            Ok(())
        },
    )?;

    let mut store = Store::new(
        &engine,
        ParentCtx {
            child_store,
            child_instance,
        },
    );

    let parent_module = Module::new(
        store.engine(),
        r#"
            (module $parent
              (func $host.catch_child_trap (import "host" "catch_child_trap"))
              (func $run (export "run")
                call $host.catch_child_trap
              )
            )
        "#,
    )?;

    let parent_instance = linker.instantiate(&mut store, &parent_module)?;

    let func = parent_instance.get_typed_func::<(), ()>(&mut store, "run")?;
    func.call(store, ())?;

    Ok(())
}
fn format_json_when_allow_trailing_commas() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let config_json = r#"{
    "json": {
        "parser": { "allowTrailingCommas": true }
    }
}"#;
    let biome_config = "biome.json";
    let code = r#"{
    "array": [
        1,
    ],
}"#;
    let file_path = Path::new("file.json");
    fs.insert(file_path.into(), code.as_bytes());
    fs.insert(biome_config.into(), config_json);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_json_when_allow_trailing_commas",
        fs,
        console,
        result,
    ));
}
fn handle_ws_both_sides_for_macro_definitions() {
    let start_ws = WS { left: true, right: true };
    let end_ws = WS { left: true, right: true };
    let ast = vec![Node::MacroDefinition(
        start_ws,
        MacroDefinition {
            name: "something".to_string(),
            args: HashMap::new(),
            body: vec![
                Node::Text("\n  ".to_string()),
                Node::Text("hey".to_string()),
                Node::Text("  ".to_string()),
            ],
        },
        end_ws,
    )];

    assert_eq!(
        remove_whitespace(ast, None),
        vec![Node::MacroDefinition(
            start_ws,
            MacroDefinition {
                name: "something".to_string(),
                args: HashMap::new(),
                body: vec![Node::Text("hey".to_string())],
            },
            end_ws,
        ),]
    );
}
fn server_cert_resolve_with_alpn() {
    for kt in ALL_KEY_TYPES.iter() {
        let mut client_config = make_client_config(*kt);
        client_config.alpn_protocols = vec!["foo".into(), "bar".into()];

        let mut server_config = make_server_config(*kt);
        server_config.cert_resolver = Arc::new(ServerCheckCertResolve {
            expected_alpn: Some(vec![b"foo".to_vec(), b"bar".to_vec()]),
            ..Default::default()
        });

        let mut client =
            ClientConnection::new(Arc::new(client_config), dns_name("sni-value")).unwrap();
        let mut server = ServerConnection::new(Arc::new(server_config)).unwrap();

        let err = do_handshake_until_error(&mut client, &mut server);
        assert!(err.is_err());
    }
}
fn server_exposes_offered_sni() {
    let kt = KeyType::Rsa;
    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions(kt, &[version]);
        let mut client =
            ClientConnection::new(Arc::new(client_config), dns_name("second.testserver.com"))
                .unwrap();
        let mut server = ServerConnection::new(Arc::new(make_server_config(kt))).unwrap();

        assert_eq!(None, server.server_name());
        do_handshake(&mut client, &mut server);
        assert_eq!(Some("second.testserver.com"), server.server_name());
    }
}
fn test_tuple_struct_name_mismatch() {
    assert_eq!(
        ron::from_str::<MyTupleStruct>("(true, 42)"),
        Ok(MyTupleStruct(true, 42)),
    );
    assert_eq!(
        ron::from_str::<MyTupleStruct>("MyTupleStruct(true, 42)"),
        Ok(MyTupleStruct(true, 42)),
    );
    assert_eq!(
        ron::from_str::<MyTupleStruct>("MyTypleStruct(true, 42)"),
        Err(SpannedError {
            code: Error::ExpectedDifferentStructName {
                expected: "MyTupleStruct",
                found: String::from("MyTypleStruct")
            },
            position: Position { line: 1, col: 14 }
        }),
    );
    assert_eq!(
        ron::from_str::<MyTupleStruct>("42"),
        Err(SpannedError {
            code: Error::ExpectedNamedStructLike("MyTupleStruct"),
            position: Position { line: 1, col: 1 }
        }),
    );
}
fn cover_offset() {
    assert_eq!(range(1..3).cover_offset(size(0)), range(0..3));
    assert_eq!(range(1..3).cover_offset(size(1)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(2)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(3)), range(1..3));
    assert_eq!(range(1..3).cover_offset(size(4)), range(1..4));
}
fn test_relative_src_already_symlink() {
    let (at, mut ucmd) = at_and_ucmd!();
    at.touch("file1");
    at.symlink_file("file1", "file2");
    ucmd.arg("-sr").arg("file2").arg("file3").succeeds();
    assert!(at.resolve_link("file3").ends_with("file1"));
}
fn reset_stream() {
    let _guard = subscribe();
    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect();

    let s = pair.client_streams(client_ch).open(Dir::Uni).unwrap();

    const MSG: &[u8] = b"hello";
    pair.client_send(client_ch, s).write(MSG).unwrap();
    pair.drive();

    info!("resetting stream");
    const ERROR: VarInt = VarInt(42);
    pair.client_send(client_ch, s).reset(ERROR).unwrap();
    pair.drive();

    assert_matches!(
        pair.server_conn_mut(server_ch).poll(),
        Some(Event::Stream(StreamEvent::Opened { dir: Dir::Uni }))
    );
    assert_matches!(pair.server_streams(server_ch).accept(Dir::Uni), Some(stream) if stream == s);
    let mut recv = pair.server_recv(server_ch, s);
    let mut chunks = recv.read(false).unwrap();
    assert_matches!(chunks.next(usize::MAX), Err(ReadError::Reset(ERROR)));
    let _ = chunks.finalize();
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
}
fn test_line_bytes() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-C", "8", "letters.txt"]).succeeds();
    assert_eq!(at.read("xaa"), "aaaaaaaa");
    assert_eq!(at.read("xab"), "a\nbbbb\n");
    assert_eq!(at.read("xac"), "cccc\ndd\n");
    assert_eq!(at.read("xad"), "ee\n");
}
fn file_too_large_cli_limit() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("ci.js");
    fs.insert(file_path.into(), "statement1();\nstatement2();");

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("ci"),
                ("--files-max-size=16"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "file_too_large_cli_limit",
        fs,
        console,
        result,
    ));
}
fn test_mv_backup_existing() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_mv_backup_numbering_file_a";
    let file_b = "test_mv_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    ucmd.arg("--backup=existing")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(!at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn test_mv_backup_dir() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir_a = "test_mv_backup_dir_dir_a";
    let dir_b = "test_mv_backup_dir_dir_b";

    at.mkdir(dir_a);
    at.mkdir(dir_b);
    ucmd.arg("-vbT")
        .arg(dir_a)
        .arg(dir_b)
        .succeeds()
        .stdout_only(format!(
            "renamed '{dir_a}' -> '{dir_b}' (backup: '{dir_b}~')\n"
        ));

    assert!(!at.dir_exists(dir_a));
    assert!(at.dir_exists(dir_b));
    assert!(at.dir_exists(&format!("{dir_b}~")));
}
fn invocation_directory() {
  let tmp = temptree! {
    ".git": {},
  };

  let test = Test::with_tempdir(tmp);

  let justfile_path = test.justfile_path();

  let _tmp = test
    .no_justfile()
    .stderr_regex("Wrote justfile to `.*`\n")
    .arg("--init")
    .run();

  assert_eq!(fs::read_to_string(justfile_path).unwrap(), EXPECTED);
}
fn parse_number_test() {
    const FORMAT: u128 = STANDARD;
    let options = Options::new();
    let string = b"1.2345e10";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_number(byte, false, &options);
    assert!(result.is_ok());
    let num = result.unwrap();
    assert_eq!(num.mantissa, 12345);
    assert_eq!(num.exponent, 6);
    assert_eq!(num.many_digits, false);

    let string = b"1.2345e";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_number(byte, false, &options);
    assert!(result.is_err());

    let string = b"1.2345 ";
    let byte = string.bytes::<{ FORMAT }>();
    let result = parse::parse_number(byte, false, &options);
    assert!(result.is_err());
}
fn render_macros_in_parent_template_with_inheritance() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello()%}Hello{% endmacro hello %}"),
        ("grandparent", "{% import \"macros\" as macros %}{% block hey %}{{macros::hello()}}{% endblock hey %}"),
        ("child", "{% extends \"grandparent\" %}{% import \"macros\" as macros %}{% block hey %}{{super()}}/{{macros::hello()}}{% endblock hey %}"),
    ]).unwrap();

    let result = tera.render("child", &Context::new());

    assert_eq!(result.unwrap(), "Hello/Hello".to_string());
}
fn test_symlink_no_deref_file() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file1 = "foo";
    let file2 = "bar";
    let link = "baz";

    at.touch(file1);
    at.touch(file2);
    scene
        .ucmd()
        .args(&["-s", file2, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file2);

    // try the normal behavior
    scene
        .ucmd()
        .args(&["-sf", file1, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
    assert!(at.is_symlink("baz"));
    assert_eq!(at.resolve_link("baz"), file1);

    // Doesn't work without the force
    scene.ucmd().args(&["-sn", file1, link]).fails();

    // Try with the no-deref
    scene.ucmd().args(&["-sfn", file1, link]).succeeds();
    assert!(at.file_exists(file1));
    assert!(at.file_exists(file2));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file1);
}
fn test_file() {
    // TODO: Can this be replaced by AtPath?
    use std::env;
    let temp = env::temp_dir();
    let tmpdir = Path::new(&temp);
    let file = tmpdir.join("test");

    {
        let mut f = File::create(&file).unwrap();
        // spell-checker:disable-next-line
        assert!(
            f.write_all(b"abcdefghijklmnopqrstuvwxyz\n").is_ok(),
            "Test setup failed - could not write file"
        );
    }

    new_ucmd!()
        .arg("--endian=little")
        .arg(file.as_os_str())
        .succeeds()
        .no_stderr()
        .stdout_is(unindent(ALPHA_OUT));

    // Ensure that default format matches `-t o2`, and that `-t` does not absorb file argument
    new_ucmd!()
        .arg("--endian=little")
        .arg("-t")
        .arg("o2")
        .arg(file.as_os_str())
        .succeeds()
        .no_stderr()
        .stdout_is(unindent(ALPHA_OUT));

    let _ = remove_file(file);
}
fn stdin_success() {
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .pass_stdin(""), @r###"
    success: true
    exit_code: 0
    ----- stdout -----

    ----- stderr -----
    "###);
}
fn render_for() {
    let mut context = Context::new();
    let mut map = BTreeMap::new();
    map.insert("name", "bob");
    map.insert("age", "18");

    context.insert("data", &vec![1, 2, 3]);
    context.insert("notes", &vec![1, 2, 3]);
    context.insert("vectors", &vec![vec![0, 3, 6], vec![1, 4, 7]]);
    context.insert("vectors_some_empty", &vec![vec![0, 3, 6], vec![], vec![1, 4, 7]]);
    context.insert("map", &map);
    context.insert("truthy", &2);

    let inputs = vec![
        ("{% for i in data %}{{i}}{% endfor %}", "123"),
        ("{% for key, val in map %}{{key}}:{{val}} {% endfor %}", "age:18 name:bob "),
        (
            "{% for i in data %}{{loop.index}}{{loop.index0}}{{loop.first}}{{loop.last}}{% endfor %}",
            "10truefalse21falsefalse32falsetrue"
        ),
        (
            "{% for vector in vectors %}{% for j in vector %}{{ j }}{% endfor %}{% endfor %}",
            "036147"
        ),
        (
            "{% for vector in vectors_some_empty %}{% for j in vector %}{{ j }}{% endfor %}{% endfor %}",
            "036147"
        ),
        (
            "{% for val in data %}{% if val == truthy %}on{% else %}off{% endif %}{% endfor %}",
            "offonoff"
        ),
        ("{% for i in range(end=5) %}{{i}}{% endfor %}", "01234"),
        ("{% for i in range(end=5) | reverse %}{{i}}{% endfor %}", "43210"),
        (
            "{% set looped = 0 %}{% for i in range(end=5) %}{% set looped = i %}{{looped}}{% endfor%}{{looped}}",
            "012340"
        ),
        // https://github.com/Keats/tera/issues/184
        ("{% for note in notes %}{{ note }}{% endfor %}", "123"),
        ("{% for note in notes | reverse %}{{ note }}{% endfor %}", "321"),
        ("{% for v in vectors %}{{ v.0 }}{% endfor %}", "01"),
        // Loop control (`break` and `continue`)
        // https://github.com/Keats/tera/issues/267
        (
            "{% for i in data %}{{ i }}{% if i == 2 %}{% break %}{% endif %}{% endfor %}",
            "12"
        ),
        (
            "{% for i in data %}{% if i == 2 %}{% continue %}{% endif %}{{ i }}{% endfor %}",
            "13"
        ),
        (
            "{% for v in vectors %}{% for i in v %}{% if i == 3 %}{% break %}{% endif %}{{ i }}{% endfor %}{% endfor %}",
            "0147"
        ),
        (
            "{% for v in vectors %}{% for i in v %}{% if i == 3 %}{% continue %}{% endif %}{{ i }}{% endfor %}{% endfor %}",
            "06147"
        ),
        (
            "{% for a in [1, true, 1.1, 'hello'] %}{{a}}{% endfor %}",
            "1true1.1hello"
        ),
        // https://github.com/Keats/tera/issues/301
        (
            "{% set start = 0 %}{% set end = start + 3 %}{% for i in range(start=start, end=end) %}{{ i }}{% endfor%}",
            "012"
        ),
        // https://github.com/Keats/tera/issues/395
        (
            "{% for a in [] %}{{a}}{% else %}hello{% endfor %}",
            "hello"
        ),
        (
            "{% for a in undefined_variable | default(value=[]) %}{{a}}{% else %}hello{% endfor %}",
            "hello"
        ),
        (
            "{% for a in [] %}{{a}}{% else %}{% if 1 == 2 %}A{% else %}B{% endif %}{% endfor %}",
            "B"
        ),
    ];

    for (input, expected) in inputs {
        println!("{:?} -> {:?}", input, expected);
        assert_eq!(render_template(input, &context).unwrap(), expected);
    }
}
fn test_touch_set_date() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_date";

    ucmd.args(&["-d", "Thu Jan 01 12:34:00 2015", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501011234");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime, start_of_year);
    assert_eq!(mtime, start_of_year);
}
fn test_install_backup_simple() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;

    let file_a = "test_install_backup_numbering_file_a";
    let file_b = "test_install_backup_numbering_file_b";

    at.touch(file_a);
    at.touch(file_b);
    scene
        .ucmd()
        .arg("--backup=simple")
        .arg(file_a)
        .arg(file_b)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));
    assert!(at.file_exists(format!("{file_b}~")));
}
fn algorithm_test() {
    let parse_u32 = |digits: &[u8]| compact::algorithm_partial::<u32, u32, STANDARD>(digits);
    let parse_i32 = |digits: &[u8]| compact::algorithm_partial::<i32, u32, STANDARD>(digits);

    assert_eq!(parse_u32(b"12345"), Ok((12345, 5)));
    assert_eq!(parse_u32(b"+12345"), Ok((12345, 6)));
    // This just parses 0 digits, since it's an unsigned type.
    assert_eq!(parse_u32(b"-12345"), Ok((0, 0)));
    assert_eq!(parse_i32(b"12345"), Ok((12345, 5)));
    assert_eq!(parse_i32(b"-12345"), Ok((-12345, 6)));
    assert_eq!(parse_i32(b"+12345"), Ok((12345, 6)));
    assert_eq!(parse_i32(b"+123.45"), Ok((123, 4)));
}
fn issue238_resolve() {
    let f = super::fixture().join("issue-238");
    let resolver = Resolver::new(ResolveOptions {
        extensions: vec![".js".into(), ".jsx".into(), ".ts".into(), ".tsx".into()],
        modules: vec!["src/a".into(), "src/b".into(), "src/common".into(), "node_modules".into()],
        ..ResolveOptions::default()
    });
    let resolved_path =
        resolver.resolve(f.join("src/common"), "config/myObjectFile").map(|r| r.full_path());
    assert_eq!(resolved_path, Ok(f.join("src/common/config/myObjectFile.js")),);
}
fn test() {
    use prost::Message;

    let mut widget_factory = widget::factory::WidgetFactory::default();
    assert_eq!(0, widget_factory.encoded_len());

    widget_factory.inner = Some(widget::factory::widget_factory::Inner {});
    assert_eq!(2, widget_factory.encoded_len());

    widget_factory.root = Some(Root {});
    assert_eq!(4, widget_factory.encoded_len());

    widget_factory.root_inner = Some(root::Inner {});
    assert_eq!(6, widget_factory.encoded_len());

    widget_factory.widget = Some(widget::Widget {});
    assert_eq!(8, widget_factory.encoded_len());

    widget_factory.widget_inner = Some(widget::widget::Inner {});
    assert_eq!(10, widget_factory.encoded_len());

    widget_factory.gizmo = Some(gizmo::Gizmo {});
    assert_eq!(12, widget_factory.encoded_len());

    widget_factory.gizmo_inner = Some(gizmo::gizmo::Inner {});
    assert_eq!(14, widget_factory.encoded_len());
}
fn valid_context_on_broken_symlink() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.symlink_file("a.tmp", "la.tmp");

    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    cmd.args(&["--verbose", "--no-dereference", new_la_context])
        .arg(dir.plus("la.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("la.tmp")).unwrap().as_deref(),
        Some(new_la_context)
    );
}
fn preview_enabled_direct() {
    // E225 should be detected without warning
    let args = ["--select", "E225", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:2: E225 [*] Missing whitespace around operator
    Found 1 error.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    "###);
}
fn test_reject_proposal_during_region_merge() {
    let mut cluster = new_node_cluster(0, 3);
    configure_for_merge(&mut cluster.cfg);
    let pd_client = cluster.pd_client.clone();
    pd_client.disable_default_operator();
    cluster.run();
    cluster.must_transfer_leader(1, new_peer(1, 1));
    cluster.must_put(b"k", b"v");

    let r = cluster.get_region(b"");
    cluster.must_split(&r, b"k");
    // Let the new region catch up.
    cluster.must_put(b"a", b"v");
    cluster.must_put(b"k", b"v");

    let prepare_merge_fp = "apply_before_prepare_merge";
    let commit_merge_fp = "apply_before_commit_merge";

    // Pause on applying so that prepare-merge is not finished.
    fail::cfg(prepare_merge_fp, "pause").unwrap();
    // Try to merge region.
    let (merge_tx, merge_rx) = mpsc::channel();
    let cb = Callback::read(Box::new(move |resp: ReadResponse<RocksSnapshot>| {
        merge_tx.send(resp.response).unwrap()
    }));
    let source = cluster.get_region(b"");
    let target = cluster.get_region(b"k");
    cluster.merge_region(source.get_id(), target.get_id(), cb);
    merge_rx
        .recv_timeout(Duration::from_millis(100))
        .unwrap_err();

    // Try to put a key on the source region.
    let force_delay_propose_batch_raft_command_fp = "force_delay_propose_batch_raft_command";
    let mut receivers = vec![];
    for i in 0..2 {
        if i == 1 {
            // Test another path of calling proposed callback.
            fail::cfg(force_delay_propose_batch_raft_command_fp, "2*return").unwrap();
        }
        let write_req = make_write_req(&mut cluster, b"a");
        let (cb, mut cb_receivers) = make_cb(&write_req);
        cluster
            .sim
            .rl()
            .async_command_on_node(1, write_req, cb)
            .unwrap();
        // The write request should be blocked until prepare-merge is finished.
        cb_receivers.assert_not_ready();
        receivers.push(cb_receivers);
    }

    // Pause on the second phase of region merge.
    fail::cfg(commit_merge_fp, "pause").unwrap();

    // prepare-merge is finished.
    fail::remove(prepare_merge_fp);
    assert!(
        !merge_rx
            .recv_timeout(Duration::from_secs(5))
            .unwrap()
            .get_header()
            .has_error()
    );
    // The write request fails due to epoch not match.
    for mut r in receivers {
        r.assert_err();
    }

    // Write request is rejected because the source region is merging.
    // It's not handled by epoch checker now.
    for i in 0..2 {
        if i == 1 {
            // Test another path of calling proposed callback.
            fail::cfg(force_delay_propose_batch_raft_command_fp, "2*return").unwrap();
        }
        let write_req = make_write_req(&mut cluster, b"a");
        let (cb, mut cb_receivers) = make_cb(&write_req);
        cluster
            .sim
            .rl()
            .async_command_on_node(1, write_req, cb)
            .unwrap();
        cb_receivers.assert_err();
    }

    // Try to put a key on the target region.
    let mut receivers = vec![];
    for i in 0..2 {
        if i == 1 {
            // Test another path of calling proposed callback.
            fail::cfg(force_delay_propose_batch_raft_command_fp, "2*return").unwrap();
        }
        let write_req = make_write_req(&mut cluster, b"k");
        let (cb, mut cb_receivers) = make_cb(&write_req);
        cluster
            .sim
            .rl()
            .async_command_on_node(1, write_req, cb)
            .unwrap();
        // The write request should be blocked until commit-merge is finished.
        cb_receivers.assert_not_ready();
        receivers.push(cb_receivers);
    }

    // Wait for region merge done.
    fail::remove(commit_merge_fp);
    pd_client.check_merged_timeout(source.get_id(), Duration::from_secs(5));
    // The write request fails due to epoch not match.
    for mut r in receivers {
        r.assert_err();
    }

    // New write request can succeed.
    let write_req = make_write_req(&mut cluster, b"k");
    let (cb, mut cb_receivers) = make_cb(&write_req);
    cluster
        .sim
        .rl()
        .async_command_on_node(1, write_req, cb)
        .unwrap();
    cb_receivers.assert_ok();
}
fn does_not_handle_ignored_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "include": ["test.js", "special/**"]
  },
  "overrides": [{ "ignore": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNORGANIZED.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNORGANIZED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                "--formatter-enabled=false",
                "--linter-enabled=false",
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, UNORGANIZED);
    assert_file_contents(&fs, test, ORGANIZED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_ignored_file",
        fs,
        console,
        result,
    ));
}
fn test_min_max() {
    assert_eq!(1e-45, s2f(b"1e-45").unwrap());
    assert_eq!(f32::MIN_POSITIVE, s2f(b"1.1754944e-38").unwrap());
    assert_eq!(f32::MAX, s2f(b"3.4028235e+38").unwrap());
}
fn test_invalid_format_string() {
    let result = new_ucmd!().arg("+%!").fails();
    result.no_stdout();
    assert!(result.stderr_str().starts_with("date: invalid format "));
}
fn test_query_with_write_cmd() {
    let cluster = Cluster::default();
    let router = &cluster.routers[0];
    std::thread::sleep(std::time::Duration::from_millis(200));
    let region_id = 2;
    let mut req = router.new_request_for(2);

    for write_cmd in [
        CmdType::Prewrite,
        CmdType::Delete,
        CmdType::DeleteRange,
        CmdType::Put,
        CmdType::IngestSst,
    ] {
        let mut request_inner = Request::default();
        request_inner.set_cmd_type(write_cmd);
        req.mut_requests().push(request_inner);
        let res = router.query(region_id, req.clone()).unwrap();
        let resp = res.read();
        assert!(resp.is_none());
        let error_resp = res.response().unwrap();
        assert!(error_resp.get_header().has_error());
        req.clear_requests();
    }
}
fn test_witness_conf_change() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.must_put(b"k1", b"v1");

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1.clone());

    // can't switch witness by conf change
    let mut peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    let mut peer = peer_on_store3.clone();
    peer.set_is_witness(true);
    let mut cp = ChangePeerRequest::default();
    cp.set_change_type(ConfChangeType::AddLearnerNode);
    cp.set_peer(peer);
    let req = new_admin_request(
        region.get_id(),
        region.get_region_epoch(),
        new_change_peer_v2_request(vec![cp]),
    );
    let resp = cluster
        .call_command_on_leader(req, Duration::from_millis(100))
        .unwrap();
    assert!(resp.get_header().has_error());

    // add a new witness peer
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store3.clone());
    peer_on_store3.set_is_witness(true);
    let applied_index = cluster.apply_state(1, 2).applied_index;
    cluster
        .pd_client
        .must_add_peer(region.get_id(), peer_on_store3.clone());
    must_get_none(&cluster.get_engine(3), b"k1");
    let region = cluster.get_region(b"k1");
    cluster.wait_applied_index(region.get_id(), nodes[2], applied_index + 1);
    assert_eq!(
        cluster
            .region_local_state(region.get_id(), nodes[2])
            .get_region(),
        &region
    );

    // remove a witness peer
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), peer_on_store3);

    std::thread::sleep(Duration::from_millis(10));

    assert_eq!(
        cluster
            .region_local_state(region.get_id(), nodes[2])
            .get_state(),
        PeerState::Tombstone
    );
}
fn test_txn_mvcc_filtered() {
    MVCC_VERSIONS_HISTOGRAM.reset();
    GC_COMPACTION_FILTERED.reset();

    let mut engine = TestEngineBuilder::new().build().unwrap();
    let raw_engine = engine.get_rocksdb();
    let value = vec![b'v'; 512];
    let mut gc_runner = TestGcRunner::new(0);

    // GC can't delete keys after the given safe point.
    must_prewrite_put(&mut engine, b"zkey", &value, b"zkey", 100);
    must_commit(&mut engine, b"zkey", 100, 110);
    gc_runner.safe_point(50).gc(&raw_engine);
    must_get(&mut engine, b"zkey", 110, &value);

    // GC can't delete keys before the safe ponit if they are latest versions.
    gc_runner.safe_point(200).gc(&raw_engine);
    must_get(&mut engine, b"zkey", 110, &value);

    must_prewrite_put(&mut engine, b"zkey", &value, b"zkey", 120);
    must_commit(&mut engine, b"zkey", 120, 130);

    // GC can't delete the latest version before the safe ponit.
    gc_runner.safe_point(115).gc(&raw_engine);
    must_get(&mut engine, b"zkey", 110, &value);

    // GC a version will also delete the key on default CF.
    gc_runner.safe_point(200).gc(&raw_engine);
    assert_eq!(
        MVCC_VERSIONS_HISTOGRAM
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get_sample_sum(),
        4_f64
    );
    assert_eq!(
        GC_COMPACTION_FILTERED
            .with_label_values(&[STAT_TXN_KEYMODE])
            .get(),
        1
    );

    MVCC_VERSIONS_HISTOGRAM.reset();
    GC_COMPACTION_FILTERED.reset();
}
fn test_witness_raftlog_gc_lagged_witness() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let peer_on_store1 = find_peer(&region, nodes[0]).unwrap().clone();
    cluster.must_transfer_leader(region.get_id(), peer_on_store1);
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );
    cluster.must_put(b"k0", b"v0");

    // make sure raft log gc is triggered
    std::thread::sleep(Duration::from_millis(200));
    let mut before_states = HashMap::default();
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        before_states.insert(id, state.take_truncated_state());
    }

    // the witness is down
    cluster.stop_node(nodes[2]);

    // write some data to make log gap exceeds the gc limit
    for i in 1..1000 {
        let (k, v) = (format!("k{}", i), format!("v{}", i));
        let key = k.as_bytes();
        let value = v.as_bytes();
        cluster.must_put(key, value);
    }

    // the witness is back online
    cluster.run_node(nodes[2]).unwrap();

    cluster.must_put(b"k00", b"v00");
    std::thread::sleep(Duration::from_millis(200));

    // the truncated index is advanced
    for (&id, engines) in &cluster.engines {
        let state: RaftApplyState = get_raft_msg_or_default(engines, &keys::apply_state_key(1));
        assert_ne!(
            900,
            state.get_truncated_state().get_index() - before_states[&id].get_index()
        );
    }
}
fn test_touch_set_both_time_and_reference() {
    let (at, mut ucmd) = at_and_ucmd!();
    let ref_file = "test_touch_reference";
    let file = "test_touch_set_both_time_and_reference";

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");

    at.touch(ref_file);
    set_file_times(&at, ref_file, start_of_year, start_of_year);
    assert!(at.file_exists(ref_file));

    ucmd.args(&["-t", "2015010112342", "-r", ref_file, file])
        .fails();
}
fn range_change() {
    let (dir, mut cmd) = at_and_ucmd!();

    dir.touch("a.tmp");
    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    let new_a_context = if let Some(a_context) = a_context {
        a_context
            .split(':')
            .take(3)
            .chain(iter::once("s0:c42"))
            .collect::<Vec<_>>()
            .join(":")
    } else {
        set_file_context(dir.plus("a.tmp"), "unconfined_u:object_r:user_tmp_t:s0").unwrap();
        String::from("unconfined_u:object_r:user_tmp_t:s0:c42")
    };

    cmd.args(&["--verbose", "--range=s0:c42"])
        .arg(dir.plus("a.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("a.tmp")).unwrap(),
        Some(new_a_context)
    );
}
fn test_allow_empty_files() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-n", "4", "threebytes.txt"])
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "a");
    assert_eq!(at.read("xab"), "b");
    assert_eq!(at.read("xac"), "c");
    assert_eq!(at.read("xad"), "");
}
fn does_handle_included_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "ignore": ["test.js", "special/**"]
  },
  "overrides": [{ "include": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), UNORGANIZED.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), UNORGANIZED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                "--formatter-enabled=false",
                "--linter-enabled=false",
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, ORGANIZED);
    assert_file_contents(&fs, test, UNORGANIZED);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_handle_included_file",
        fs,
        console,
        result,
    ));
}
fn test_rmdir_ignore_nonempty_no_permissions() {
    let (at, mut ucmd) = at_and_ucmd!();

    // We make the *parent* dir read-only to prevent deleting the dir in it.
    at.mkdir_all("dir/ect/ory");
    at.touch("dir/ect/ory/file");
    at.set_mode("dir/ect", 0o555);

    // rmdir should now get a permissions error that it interprets as
    // a non-empty error.
    ucmd.arg("--ignore-fail-on-non-empty")
        .arg("dir/ect/ory")
        .succeeds()
        .no_stderr();

    assert!(at.dir_exists("dir/ect/ory"));

    // Politely restore permissions for cleanup
    at.set_mode("dir/ect", 0o755);
}
fn test_issue157() {
    assert_eq!(
        1.2999999999999999E+154,
        s2d(b"1.2999999999999999E+154").unwrap(),
    );
}
fn zero_write_is_error() {
    let mut buf = [0u8];
    let writer = flate2::write::DeflateEncoder::new(&mut buf[..], flate2::Compression::default());
    assert!(writer.finish().is_err());
}
fn test_declare_oxc_lint() {
    // Simple, multiline documentation
    assert_eq!(TestRule::documentation().unwrap(), "Dummy description\n# which is multiline\n");

    // Ensure structs with fields can be passed to the macro
    assert_eq!(TestRule2::documentation().unwrap(), "Dummy description2\n");

    // Auto-generated kebab-case name
    assert_eq!(TestRule::NAME, "test-rule");
}
fn test_tee_append() {
    let (at, mut ucmd) = at_and_ucmd!();
    let content = "tee_sample_content";
    let file = "tee_out";

    at.touch(file);
    at.write(file, content);
    assert_eq!(at.read(file), content);

    ucmd.arg("-a")
        .arg(file)
        .pipe_in(content)
        .succeeds()
        .stdout_is(content);
    assert!(at.file_exists(file));
    assert_eq!(at.read(file), content.repeat(2));
}
fn parse_typed_struct_syntax() {
    // typed struct syntax https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#typed_struct_syntax
    // syntax: STRUCT<[field_name] field_type, ...>( expr1 [, ... ])

    let sql = r#"SELECT STRUCT<INT64>(5), STRUCT<x INT64, y STRING>(1, t.str_col), STRUCT<arr ARRAY<FLOAT64>, str STRUCT<BOOL>>(nested_col)"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(3, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(number("5")),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Int64,
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![
                Expr::Value(number("1")),
                Expr::CompoundIdentifier(vec![
                    Ident {
                        value: "t".into(),
                        quote_style: None,
                    },
                    Ident {
                        value: "str_col".into(),
                        quote_style: None,
                    },
                ]),
            ],
            fields: vec![
                StructField {
                    field_name: Some(Ident {
                        value: "x".into(),
                        quote_style: None,
                    }),
                    field_type: DataType::Int64
                },
                StructField {
                    field_name: Some(Ident {
                        value: "y".into(),
                        quote_style: None,
                    }),
                    field_type: DataType::String(None)
                },
            ]
        },
        expr_from_projection(&select.projection[1])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Identifier(Ident {
                value: "nested_col".into(),
                quote_style: None,
            }),],
            fields: vec![
                StructField {
                    field_name: Some("arr".into()),
                    field_type: DataType::Array(ArrayElemTypeDef::AngleBracket(Box::new(
                        DataType::Float64
                    )))
                },
                StructField {
                    field_name: Some("str".into()),
                    field_type: DataType::Struct(vec![StructField {
                        field_name: None,
                        field_type: DataType::Bool
                    }])
                },
            ]
        },
        expr_from_projection(&select.projection[2])
    );

    let sql = r#"SELECT STRUCT<x STRUCT, y ARRAY<STRUCT>>(nested_col)"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(1, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Identifier(Ident {
                value: "nested_col".into(),
                quote_style: None,
            }),],
            fields: vec![
                StructField {
                    field_name: Some("x".into()),
                    field_type: DataType::Struct(Default::default())
                },
                StructField {
                    field_name: Some("y".into()),
                    field_type: DataType::Array(ArrayElemTypeDef::AngleBracket(Box::new(
                        DataType::Struct(Default::default())
                    )))
                },
            ]
        },
        expr_from_projection(&select.projection[0])
    );

    let sql = r#"SELECT STRUCT<BOOL>(true), STRUCT<BYTES(42)>(B'abc')"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::Boolean(true)),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Bool
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::SingleQuotedByteStringLiteral(
                "abc".into()
            )),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Bytes(Some(42))
            }]
        },
        expr_from_projection(&select.projection[1])
    );

    let sql = r#"SELECT STRUCT<DATE>("2011-05-05"), STRUCT<DATETIME>(DATETIME '1999-01-01 01:23:34.45'), STRUCT<FLOAT64>(5.0), STRUCT<INT64>(1)"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(4, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::DoubleQuotedString(
                "2011-05-05".to_string()
            )),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Date
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::Datetime(None),
                value: "1999-01-01 01:23:34.45".to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Datetime(None)
            }]
        },
        expr_from_projection(&select.projection[1])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(number("5.0")),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Float64
            }]
        },
        expr_from_projection(&select.projection[2])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(number("1")),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Int64
            }]
        },
        expr_from_projection(&select.projection[3])
    );

    let sql = r#"SELECT STRUCT<INTERVAL>(INTERVAL '1-2 3 4:5:6.789999'), STRUCT<JSON>(JSON '{"class" : {"students" : [{"name" : "Jane"}]}}')"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Interval(ast::Interval {
                value: Box::new(Expr::Value(Value::SingleQuotedString(
                    "1-2 3 4:5:6.789999".to_string()
                ))),
                leading_field: None,
                leading_precision: None,
                last_field: None,
                fractional_seconds_precision: None
            }),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Interval
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::JSON,
                value: r#"{"class" : {"students" : [{"name" : "Jane"}]}}"#.to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::JSON
            }]
        },
        expr_from_projection(&select.projection[1])
    );

    let sql = r#"SELECT STRUCT<STRING(42)>("foo"), STRUCT<TIMESTAMP>(TIMESTAMP '2008-12-25 15:30:00 America/Los_Angeles'), STRUCT<TIME>(TIME '15:30:00')"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(3, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::Value(Value::DoubleQuotedString("foo".to_string())),],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::String(Some(42))
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::Timestamp(None, TimezoneInfo::None),
                value: "2008-12-25 15:30:00 America/Los_Angeles".to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Timestamp(None, TimezoneInfo::None)
            }]
        },
        expr_from_projection(&select.projection[1])
    );

    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::Time(None, TimezoneInfo::None),
                value: "15:30:00".to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Time(None, TimezoneInfo::None)
            }]
        },
        expr_from_projection(&select.projection[2])
    );

    let sql = r#"SELECT STRUCT<NUMERIC>(NUMERIC '1'), STRUCT<BIGNUMERIC>(BIGNUMERIC '1')"#;
    let select = bigquery().verified_only_select(sql);
    assert_eq!(2, select.projection.len());
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::Numeric(ExactNumberInfo::None),
                value: "1".to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::Numeric(ExactNumberInfo::None)
            }]
        },
        expr_from_projection(&select.projection[0])
    );
    assert_eq!(
        &Expr::Struct {
            values: vec![Expr::TypedString {
                data_type: DataType::BigNumeric(ExactNumberInfo::None),
                value: "1".to_string()
            },],
            fields: vec![StructField {
                field_name: None,
                field_type: DataType::BigNumeric(ExactNumberInfo::None)
            }]
        },
        expr_from_projection(&select.projection[1])
    );
}
fn alpn_mismatch() {
    let _guard = subscribe();
    let mut server_crypto = server_crypto();
    server_crypto.alpn_protocols = vec!["foo".into(), "bar".into(), "baz".into()];
    let server_config = ServerConfig::with_crypto(Arc::new(server_crypto));
    let mut pair = Pair::new(Arc::new(EndpointConfig::default()), server_config);

    let mut client_crypto = client_crypto();
    client_crypto.alpn_protocols = vec!["quux".into(), "corge".into()];
    let client_config = ClientConfig::new(Arc::new(client_crypto));

    let client_ch = pair.begin_connect(client_config);
    pair.drive();
    assert_matches!(
        pair.client_conn_mut(client_ch).poll(),
        Some(Event::ConnectionLost { reason: ConnectionError::ConnectionClosed(err) }) if err.error_code == TransportErrorCode::crypto(0x78)
    );
}
fn i32_decimal_test() {
    assert_eq!(Ok(0), i32::from_lexical(b"0"));
    assert_eq!(Ok(2147483647), i32::from_lexical(b"2147483647"));
    assert_eq!(Err(Error::Overflow(9)), i32::from_lexical(b"2147483648"));
    assert_eq!(Err(Error::Overflow(9)), i32::from_lexical(b"4294967295"));
    assert_eq!(Ok(-1), i32::from_lexical(b"-1"));
    assert_eq!(Err(Error::InvalidDigit(1)), i32::from_lexical(b"1a"));
}
fn test_cp_parents_multiple_files() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--parents")
        .arg(TEST_COPY_FROM_FOLDER_FILE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg(TEST_COPY_TO_FOLDER)
        .succeeds();

    assert_eq!(
        at.read(&format!(
            "{TEST_COPY_TO_FOLDER}/{TEST_COPY_FROM_FOLDER_FILE}"
        )),
        "Hello, World!\n"
    );
    assert_eq!(
        at.read(&format!("{TEST_COPY_TO_FOLDER}/{TEST_HOW_ARE_YOU_SOURCE}")),
        "How are you?\n"
    );
}
fn test_bytes_ser() {
    let buf = vec![];
    let bytes = Bytes::new(&buf);
    assert_eq!(to_string(&bytes).unwrap(), "[]".to_string());

    let buf = vec![1, 2, 3];
    let bytes = Bytes::new(&buf);
    assert_eq!(to_string(&bytes).unwrap(), "[1,2,3]".to_string());
}
fn display_wrapper_matches_normal_encode() {
    let mut bytes = Vec::<u8>::with_capacity(256);

    for i in 0..255 {
        bytes.push(i);
    }
    bytes.push(255);

    assert_eq!(
        STANDARD.encode(&bytes),
        format!("{}", display::Base64Display::new(&bytes, &STANDARD))
    );
}
fn test_big_table_fails_to_instantiate() {
    let loose_limits = StoreLimitsBuilder::new().table_elements(100).build();
    let tight_limits = StoreLimitsBuilder::new().table_elements(99).build();
    assert!(Test::new(0x30, 100, loose_limits).is_ok());
    assert!(Test::new(0x30, 100, tight_limits).is_err());
}
fn test_bootstrap_half_way_failure() {
    let server = test_pd::Server::new(1);
    let eps = server.bind_addrs();
    let pd_client = test_pd::util::new_client(eps, None);
    let path = TempDir::new().unwrap();
    let engines = engine_test::new_temp_engine(&path);
    let bootstrap = || {
        let logger = slog_global::borrow_global().new(o!());
        let mut bootstrap = Bootstrap::new(&engines.raft, 0, &pd_client, logger);
        match bootstrap.bootstrap_store() {
            Ok(store_id) => {
                let mut store = Store::default();
                store.set_id(store_id);
                bootstrap.bootstrap_first_region(&store, store_id)
            }
            Err(e) => Err(e),
        }
    };

    // Try to start this node, return after persisted some keys.
    fail::cfg("node_after_bootstrap_store", "return").unwrap();
    let s = format!("{}", bootstrap().unwrap_err());
    assert!(s.contains("node_after_bootstrap_store"), "{}", s);
    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));

    let ident = engines.raft.get_store_ident().unwrap().unwrap();
    assert_ne!(ident.get_store_id(), 0);

    // Check whether it can bootstrap cluster successfully.
    fail::remove("node_after_bootstrap_store");
    fail::cfg("node_after_prepare_bootstrap_cluster", "return").unwrap();
    let s = format!("{}", bootstrap().unwrap_err());
    assert!(s.contains("node_after_prepare_bootstrap_cluster"), "{}", s);
    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));

    fail::remove("node_after_prepare_bootstrap_cluster");
    fail::cfg("node_after_bootstrap_cluster", "return").unwrap();
    let s = format!("{}", bootstrap().unwrap_err());
    assert!(s.contains("node_after_bootstrap_cluster"), "{}", s);
    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(Some(_)));

    // Although aborted by error, rebootstrap should continue.
    bootstrap().unwrap().unwrap();
    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));

    // Second bootstrap should be noop.
    assert_eq!(bootstrap().unwrap(), None);

    assert_matches!(engines.raft.get_prepare_bootstrap_region(), Ok(None));
}
fn parse_select_count_distinct() {
    let sql = "SELECT COUNT(DISTINCT +x) FROM customer";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::Function(Function {
            name: ObjectName(vec![Ident::new("COUNT")]),
            args: vec![FunctionArg::Unnamed(FunctionArgExpr::Expr(Expr::UnaryOp {
                op: UnaryOperator::Plus,
                expr: Box::new(Expr::Identifier(Ident::new("x"))),
            }))],
            null_treatment: None,
            filter: None,
            over: None,
            distinct: true,
            special: false,
            order_by: vec![],
        }),
        expr_from_projection(only(&select.projection))
    );

    one_statement_parses_to(
        "SELECT COUNT(ALL +x) FROM customer",
        "SELECT COUNT(+x) FROM customer",
    );

    let sql = "SELECT COUNT(ALL DISTINCT + x) FROM customer";
    let res = parse_sql_statements(sql);
    assert_eq!(
        ParserError::ParserError("Cannot specify both ALL and DISTINCT".to_string()),
        res.unwrap_err()
    );
}
fn multiple_tables() {
    let definition1: TableDefinition<&str, &str> = TableDefinition::new("1");
    let definition2: TableDefinition<&str, &str> = TableDefinition::new("2");

    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition1).unwrap();
        let mut table2 = write_txn.open_table(definition2).unwrap();

        table.insert("hello", "world").unwrap();
        table2.insert("hello", "world2").unwrap();
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition1).unwrap();
    let table2 = read_txn.open_table(definition2).unwrap();
    assert_eq!(table.len().unwrap(), 1);
    assert_eq!("world", table.get("hello").unwrap().unwrap().value());
    assert_eq!(table2.len().unwrap(), 1);
    assert_eq!("world2", table2.get("hello").unwrap().unwrap().value());
}
fn parse_create_view_temporary() {
    let sql = "CREATE TEMPORARY VIEW myschema.myview AS SELECT foo FROM bar";
    match verified_stmt(sql) {
        Statement::CreateView {
            name,
            columns,
            query,
            or_replace,
            materialized,
            with_options,
            cluster_by,
            with_no_schema_binding: late_binding,
            if_not_exists,
            temporary,
        } => {
            assert_eq!("myschema.myview", name.to_string());
            assert_eq!(Vec::<Ident>::new(), columns);
            assert_eq!("SELECT foo FROM bar", query.to_string());
            assert!(!materialized);
            assert!(!or_replace);
            assert_eq!(with_options, vec![]);
            assert_eq!(cluster_by, vec![]);
            assert!(!late_binding);
            assert!(!if_not_exists);
            assert!(temporary);
        }
        _ => unreachable!(),
    }
}
fn u32_test() {
    let mut buffer = [b'\x00'; 16];
    assert_eq!(b"0", 0u32.to_lexical(&mut buffer));
    assert_eq!(b"1", 1u32.to_lexical(&mut buffer));
    assert_eq!(b"5", 5u32.to_lexical(&mut buffer));
    assert_eq!(b"2147483647", 2147483647u32.to_lexical(&mut buffer));
    assert_eq!(b"2147483648", 2147483648u32.to_lexical(&mut buffer));
    assert_eq!(b"4294967295", 4294967295u32.to_lexical(&mut buffer));
    assert_eq!(b"4294967295", (-1i32 as u32).to_lexical(&mut buffer));
}
fn test_unsafe_recovery_create_region() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    // Disable default max peer number check.
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    let store0_peer = find_peer(&region, nodes[0]).unwrap().to_owned();

    // Removes the boostrap region, since it overlaps with any regions we create.
    pd_client.must_remove_peer(region.get_id(), store0_peer);
    cluster.must_remove_region(nodes[0], region.get_id());

    cluster.stop_node(nodes[1]);
    cluster.stop_node(nodes[2]);
    cluster.must_wait_for_leader_expire(nodes[0], region.get_id());

    let mut create = metapb::Region::default();
    create.set_id(101);
    create.set_start_key(b"anykey".to_vec());
    let mut peer = metapb::Peer::default();
    peer.set_id(102);
    peer.set_store_id(nodes[0]);
    create.mut_peers().push(peer);
    let mut plan = pdpb::RecoveryPlan::default();
    plan.mut_creates().push(create);
    pd_client.must_set_unsafe_recovery_plan(nodes[0], plan);
    cluster.must_send_store_heartbeat(nodes[0]);
    let mut created = false;
    for _ in 1..11 {
        let region = pd_client.get_region(b"anykey1").unwrap();
        if region.get_id() == 101 {
            created = true;
        }
        sleep_ms(200);
    }
    assert_eq!(created, true);
}
fn test_copy_into_file_format() {
    let sql = concat!(
        "COPY INTO my_company.emp_basic ",
        "FROM 'gcs://mybucket/./../a.csv' ",
        "FILES = ('file1.json', 'file2.json') ",
        "PATTERN = '.*employees0[1-5].csv.gz' ",
        "FILE_FORMAT=(COMPRESSION=AUTO BINARY_FORMAT=HEX ESCAPE='\\')"
    );

    match snowflake().verified_stmt(sql) {
        Statement::CopyIntoSnowflake { file_format, .. } => {
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "COMPRESSION".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "AUTO".to_string()
            }));
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "BINARY_FORMAT".to_string(),
                option_type: DataLoadingOptionType::ENUM,
                value: "HEX".to_string()
            }));
            assert!(file_format.options.contains(&DataLoadingOption {
                option_name: "ESCAPE".to_string(),
                option_type: DataLoadingOptionType::STRING,
                value: "\\".to_string()
            }));
        }
        _ => unreachable!(),
    }
    assert_eq!(snowflake().verified_stmt(sql).to_string(), sql);
}
fn test_raft_storage() {
    let (_cluster, storage, mut ctx) = new_raft_storage();
    let key = Key::from_raw(b"key");
    assert_eq!(storage.get(ctx.clone(), &key, 5).unwrap().0, None);
    storage
        .prewrite(
            ctx.clone(),
            vec![Mutation::make_put(key.clone(), b"value".to_vec())],
            b"key".to_vec(),
            10,
        )
        .unwrap();
    storage
        .commit(ctx.clone(), vec![key.clone()], 10, 15)
        .unwrap();
    assert_eq!(
        storage.get(ctx.clone(), &key, 20).unwrap().0.unwrap(),
        b"value".to_vec()
    );

    // Test wrong region id.
    let region_id = ctx.get_region_id();
    ctx.set_region_id(region_id + 1);
    storage.get(ctx.clone(), &key, 20).unwrap_err();
    storage
        .batch_get(ctx.clone(), &[key.clone()], 20)
        .unwrap_err();
    storage
        .scan(ctx.clone(), key, None, 1, false, 20)
        .unwrap_err();
    storage.scan_locks(ctx, 20, None, None, 100).unwrap_err();
}
fn simple_test() {
    let x = Bigint::new();
    assert_eq!(x.hi64(), (0, false));

    let x = Bigint::from_u32(1);
    assert_eq!(&*x.data, &[1]);

    let mut x = Bigint::from_u64(1);
    assert_eq!(&*x.data, &[1]);

    x.pow(10, 10);
    let expected = vec_from_u32(&[1410065408, 2]);
    assert!(x.data == expected, "failed");
    assert_eq!(x.bit_length(), 34);

    let y = Bigint::from_u64(5);
    x *= &y;
    let expected = vec_from_u32(&[2755359744, 11]);
    assert!(x.data == expected, "failed");
}
fn test_witness_split_merge() {
    let mut cluster = new_server_cluster(0, 3);
    cluster.run();
    let nodes = Vec::from_iter(cluster.get_node_ids());
    assert_eq!(nodes.len(), 3);

    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    let region = block_on(pd_client.get_region_by_id(1)).unwrap().unwrap();
    // nonwitness -> witness
    let peer_on_store3 = find_peer(&region, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        region.get_id(),
        vec![peer_on_store3.get_id()],
        vec![true],
    );
    let before = cluster
        .apply_state(region.get_id(), nodes[2])
        .get_applied_index();
    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k2", b"v2");
    cluster.must_split(&region, b"k2");
    must_get_none(&cluster.get_engine(3), b"k1");
    must_get_none(&cluster.get_engine(3), b"k2");
    // applied index of witness is updated
    let after = cluster
        .apply_state(region.get_id(), nodes[2])
        .get_applied_index();
    assert!(after - before >= 3);

    // the newly split peer should be witness as well
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k2");
    assert_ne!(left.get_id(), right.get_id());
    assert!(find_peer(&left, nodes[2]).unwrap().is_witness);
    assert!(find_peer(&right, nodes[2]).unwrap().is_witness);

    // merge
    pd_client.must_merge(left.get_id(), right.get_id());
    let after_merge = cluster.get_region(b"k1");
    assert!(find_peer(&after_merge, nodes[2]).unwrap().is_witness);
    must_get_none(&cluster.get_engine(3), b"k1");
    must_get_none(&cluster.get_engine(3), b"k2");
    // epoch of witness is updated
    assert_eq!(
        cluster
            .region_local_state(after_merge.get_id(), nodes[2])
            .get_region()
            .get_region_epoch(),
        after_merge.get_region_epoch()
    );

    // split again
    cluster.must_split(&after_merge, b"k2");
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k2");
    assert!(find_peer(&left, nodes[2]).unwrap().is_witness);
    assert!(find_peer(&right, nodes[2]).unwrap().is_witness);

    // can't merge with different witness location
    let peer_on_store3 = find_peer(&left, nodes[2]).unwrap().clone();
    cluster.pd_client.must_switch_witnesses(
        left.get_id(),
        vec![peer_on_store3.get_id()],
        vec![false],
    );
    let left = cluster.get_region(b"k1");
    let req = new_admin_request(
        left.get_id(),
        left.get_region_epoch(),
        new_prepare_merge(right),
    );
    let resp = cluster
        .call_command_on_leader(req, Duration::from_millis(100))
        .unwrap();
    assert!(
        resp.get_header()
            .get_error()
            .get_message()
            .contains("peers doesn't match")
    );
}
fn test_rm_non_empty_directory() {
    let (at, mut ucmd) = at_and_ucmd!();
    let dir = "test_rm_non_empty_dir";
    let file_a = &format!("{dir}/test_rm_non_empty_file_a");

    at.mkdir(dir);
    at.touch(file_a);

    ucmd.arg("-d")
        .arg(dir)
        .fails()
        .stderr_contains(&format!("cannot remove '{dir}': Directory not empty"));
    assert!(at.file_exists(file_a));
    assert!(at.dir_exists(dir));
}
fn max_diagnostics() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    for i in 0..60 {
        let file_path = PathBuf::from(format!("src/file_{i}.js"));
        fs.insert(file_path, UNFORMATTED.as_bytes());
    }

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), ("--max-diagnostics"), ("10"), ("src")].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut diagnostic_count = 0;
    let mut filtered_messages = Vec::new();

    for msg in console.out_buffer {
        let MarkupBuf(nodes) = &msg.content;
        let is_diagnostic = nodes.iter().any(|node| {
            node.content
                .contains("Formatter would have printed the following content")
        });

        if is_diagnostic {
            diagnostic_count += 1;
        } else {
            filtered_messages.push(msg);
        }
    }

    console.out_buffer = filtered_messages;

    for i in 0..60 {
        let file_path = format!("src/file_{i}.js");
        fs.remove(Path::new(&file_path));
    }

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "max_diagnostics",
        fs,
        console,
        result,
    ));

    assert_eq!(diagnostic_count, 10);
}
fn error_when_using_variable_set_in_included_templates_outside() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("included", r#"{{a}}{% set b = "hi" %}-{{b}}"#),
        ("base", r#"{{a}}{% include "included" %}{{b}}"#),
    ])
    .unwrap();
    let mut context = Context::new();
    context.insert("a", &10);
    let result = tera.render("base", &context);

    assert_eq!(
        result.unwrap_err().source().unwrap().to_string(),
        "Variable `b` not found in context while rendering \'base\'"
    );
}
fn should_disable_a_rule_group() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), FIX_BEFORE.as_bytes());

    let config_path = Path::new("biome.json");
    fs.insert(
        config_path.into(),
        CONFIG_LINTER_SUPPRESSED_GROUP.as_bytes(),
    );

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut buffer = String::new();
    fs.open(file_path)
        .unwrap()
        .read_to_string(&mut buffer)
        .unwrap();

    assert_eq!(buffer, "1 >= -0;\n");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "should_disable_a_rule_group",
        fs,
        console,
        result,
    ));
}
fn test_line_bytes_no_final_newline() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.args(&["-C", "2"])
        .pipe_in("1\n2222\n3\n4")
        .succeeds()
        .no_stdout()
        .no_stderr();
    assert_eq!(at.read("xaa"), "1\n");
    assert_eq!(at.read("xab"), "22");
    assert_eq!(at.read("xac"), "22");
    assert_eq!(at.read("xad"), "\n");
    assert_eq!(at.read("xae"), "3\n");
    assert_eq!(at.read("xaf"), "4");
}
fn test_trap_trace() -> Result<()> {
    let mut store = Store::<()>::default();
    let wat = r#"
        (module $hello_mod
            (func (export "run") (call $hello))
            (func $hello (unreachable))
        )
    "#;

    let module = Module::new(store.engine(), wat)?;
    let instance = Instance::new(&mut store, &module, &[])?;
    let run_func = instance.get_typed_func::<(), ()>(&mut store, "run")?;

    let e = run_func.call(&mut store, ()).unwrap_err();

    let trace = e.downcast_ref::<WasmBacktrace>().unwrap().frames();
    assert_eq!(trace.len(), 2);
    assert_eq!(trace[0].module().name().unwrap(), "hello_mod");
    assert_eq!(trace[0].func_index(), 1);
    assert_eq!(trace[0].func_name(), Some("hello"));
    assert_eq!(trace[0].func_offset(), Some(1));
    assert_eq!(trace[0].module_offset(), Some(0x26));
    assert_eq!(trace[1].module().name().unwrap(), "hello_mod");
    assert_eq!(trace[1].func_index(), 0);
    assert_eq!(trace[1].func_name(), None);
    assert_eq!(trace[1].func_offset(), Some(1));
    assert_eq!(trace[1].module_offset(), Some(0x21));
    assert_eq!(e.downcast::<Trap>()?, Trap::UnreachableCodeReached);

    Ok(())
}
fn error_location_basic() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![("tpl", "{{ 1 + true }}")]).unwrap();

    let result = tera.render("tpl", &Context::new());

    assert_eq!(result.unwrap_err().to_string(), "Failed to render \'tpl\'");
}
fn sni_resolver_works() {
    let kt = KeyType::Rsa;
    let mut resolver = rustls::server::ResolvesServerCertUsingSni::new();
    let signing_key = sign::RsaSigningKey::new(&kt.get_key()).unwrap();
    let signing_key: Arc<dyn sign::SigningKey> = Arc::new(signing_key);
    resolver
        .add(
            "localhost",
            sign::CertifiedKey::new(kt.get_chain(), signing_key.clone()),
        )
        .unwrap();

    let mut server_config = make_server_config(kt);
    server_config.cert_resolver = Arc::new(resolver);
    let server_config = Arc::new(server_config);

    let mut server1 = ServerConnection::new(Arc::clone(&server_config)).unwrap();
    let mut client1 =
        ClientConnection::new(Arc::new(make_client_config(kt)), dns_name("localhost")).unwrap();
    let err = do_handshake_until_error(&mut client1, &mut server1);
    assert_eq!(err, Ok(()));

    let mut server2 = ServerConnection::new(Arc::clone(&server_config)).unwrap();
    let mut client2 =
        ClientConnection::new(Arc::new(make_client_config(kt)), dns_name("notlocalhost")).unwrap();
    let err = do_handshake_until_error(&mut client2, &mut server2);
    assert_eq!(
        err,
        Err(ErrorFromPeer::Server(Error::General(
            "no server certificate chain resolved".into()
        )))
    );
}
fn test_symlink_relative() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file_a = "test_symlink_relative_a";
    let link = "test_symlink_relative_link";

    at.touch(file_a);

    // relative symlink
    ucmd.args(&["-r", "-s", file_a, link]).succeeds();
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file_a);
}
fn test_render_to_write_state() {
    let env = Environment::new();
    let tmpl = env
        .template_from_str("{% set foo = 42 %}{% macro bar() %}x{% endmacro %}root")
        .unwrap();
    let mut out = Vec::<u8>::new();
    let state = tmpl.render_to_write((), &mut out).unwrap();
    assert_eq!(String::from_utf8_lossy(&out), "root");
    assert_eq!(state.lookup("foo"), Some(Value::from(42)));
    assert_eq!(state.call_macro("bar", &[]).ok().as_deref(), Some("x"));
}
fn mismatch_resource_types() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (type $t' (resource (rep i32)))
                (type $u' (resource (rep i32)))

                (export $t "t" (type $t'))
                (export $u "u" (type $u'))

                (core func $t_ctor (canon resource.new $t))
                (func (export "ctor") (param "x" u32) (result (own $t))
                    (canon lift (core func $t_ctor)))

                (core func $u_dtor (canon resource.drop $u))
                (func (export "dtor") (param "x" (own $u))
                    (canon lift (core func $u_dtor)))
            )
        "#,
    )?;

    let mut store = Store::new(&engine, ());
    let i = Linker::new(&engine).instantiate(&mut store, &c)?;
    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, "ctor")?;
    let dtor = i.get_typed_func::<(ResourceAny,), ()>(&mut store, "dtor")?;

    let (t,) = ctor.call(&mut store, (100,))?;
    ctor.post_return(&mut store)?;
    assert_eq!(
        dtor.call(&mut store, (t,)).unwrap_err().to_string(),
        "mismatched resource types"
    );

    Ok(())
}
fn render_macros_expression_arg() {
    let mut context = Context::new();
    context.insert("pages", &vec![1, 2, 3, 4, 5]);
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros", "{% macro hello(val)%}{{val}}{% endmacro hello %}"),
        ("tpl", "{% import \"macros\" as macros %}{{macros::hello(val=pages|last)}}"),
    ])
    .unwrap();

    let result = tera.render("tpl", &context);

    assert_eq!(result.unwrap(), "5".to_string());
}
fn u64_pow10_test() {
    let values: &[u64] = &[
        0,
        1,
        5,
        9,
        10,
        11,
        15,
        99,
        100,
        101,
        105,
        999,
        1000,
        1001,
        1005,
        9999,
        10000,
        10001,
        10005,
        99999,
        100000,
        100001,
        100005,
        999999,
        1000000,
        1000001,
        1000005,
        9999999,
        10000000,
        10000001,
        10000005,
        99999999,
        100000000,
        100000001,
        100000005,
        999999999,
        1000000000,
        1000000001,
        1000000005,
        9999999999,
        10000000000,
        10000000001,
        10000000005,
        99999999999,
        100000000000,
        100000000001,
        100000000005,
        999999999999,
        1000000000000,
        1000000000001,
        1000000000005,
        9999999999999,
        10000000000000,
        10000000000001,
        10000000000005,
        99999999999999,
        100000000000000,
        100000000000001,
        100000000000005,
        999999999999999,
        1000000000000000,
        1000000000000001,
        1000000000000005,
        9999999999999999,
        10000000000000000,
        10000000000000001,
        10000000000000005,
        99999999999999999,
        100000000000000000,
        100000000000000001,
        100000000000000005,
        999999999999999999,
        1000000000000000000,
        1000000000000000001,
        1000000000000000005,
    ];
    for &i in values.iter() {
        assert_eq!(i, roundtrip(i));
    }
}
fn test_force_leader_three_nodes() {
    let mut cluster = new_node_cluster(0, 3);
    cluster.pd_client.disable_default_operator();

    cluster.run();
    cluster.must_put(b"k1", b"v1");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k9");
    let region = cluster.get_region(b"k2");
    let peer_on_store3 = find_peer(&region, 3).unwrap();
    cluster.must_transfer_leader(region.get_id(), peer_on_store3.clone());

    cluster.stop_node(2);
    cluster.stop_node(3);

    // quorum is lost, can't propose command successfully.
    confirm_quorum_is_lost(&mut cluster, &region);

    cluster.must_enter_force_leader(region.get_id(), 1, vec![2, 3]);
    // remove the peers on failed nodes
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 2).unwrap().clone());
    cluster
        .pd_client
        .must_remove_peer(region.get_id(), find_peer(&region, 3).unwrap().clone());
    // forbid writes in force leader state
    let put = new_put_cmd(b"k3", b"v3");
    must_get_error_recovery_in_progress(&mut cluster, &region, put);
    // forbid reads in force leader state
    let get = new_get_cmd(b"k1");
    must_get_error_recovery_in_progress(&mut cluster, &region, get);
    // forbid read index in force leader state
    let read_index = new_read_index_cmd();
    must_get_error_recovery_in_progress(&mut cluster, &region, read_index);
    cluster.exit_force_leader(region.get_id(), 1);

    // quorum is formed, can propose command successfully now
    cluster.must_put(b"k4", b"v4");
    assert_eq!(cluster.must_get(b"k2"), None);
    assert_eq!(cluster.must_get(b"k3"), None);
    assert_eq!(cluster.must_get(b"k4"), Some(b"v4".to_vec()));
}
fn parse_alter_index() {
    let rename_index = "ALTER INDEX idx RENAME TO new_idx";
    match verified_stmt(rename_index) {
        Statement::AlterIndex {
            name,
            operation: AlterIndexOperation::RenameIndex { index_name },
        } => {
            assert_eq!("idx", name.to_string());
            assert_eq!("new_idx", index_name.to_string())
        }
        _ => unreachable!(),
    };
}
fn test_proc_macro2_wrapper_span_size_with_locations() {
    assert_eq!(mem::size_of::<proc_macro2::Span>(), 12);
    assert_eq!(mem::size_of::<Option<proc_macro2::Span>>(), 12);
}
fn parse_natural_join() {
    fn natural_join(f: impl Fn(JoinConstraint) -> JoinOperator, alias: Option<TableAlias>) -> Join {
        Join {
            relation: TableFactor::Table {
                name: ObjectName(vec![Ident::new("t2")]),
                alias,
                args: None,
                with_hints: vec![],
                version: None,
                partitions: vec![],
            },
            join_operator: f(JoinConstraint::Natural),
        }
    }

    // if not specified, inner join as default
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 NATURAL JOIN t2").from).joins,
        vec![natural_join(JoinOperator::Inner, None)]
    );
    // left join explicitly
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 NATURAL LEFT JOIN t2").from).joins,
        vec![natural_join(JoinOperator::LeftOuter, None)]
    );

    // right join explicitly
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 NATURAL RIGHT JOIN t2").from).joins,
        vec![natural_join(JoinOperator::RightOuter, None)]
    );

    // full join explicitly
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 NATURAL FULL JOIN t2").from).joins,
        vec![natural_join(JoinOperator::FullOuter, None)]
    );

    // natural join another table with alias
    assert_eq!(
        only(&verified_only_select("SELECT * FROM t1 NATURAL JOIN t2 AS t3").from).joins,
        vec![natural_join(JoinOperator::Inner, table_alias("t3"))]
    );

    let sql = "SELECT * FROM t1 natural";
    assert_eq!(
        ParserError::ParserError("Expected a join type after NATURAL, found: EOF".to_string()),
        parse_sql_statements(sql).unwrap_err(),
    );
}
fn draft_version_compat() {
    let _guard = subscribe();

    let mut client_config = client_config();
    client_config.version(0xff00_0020);

    let mut pair = Pair::default();
    let (client_ch, server_ch) = pair.connect_with(client_config);

    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert!(pair.client_conn_mut(client_ch).using_ecn());
    assert!(pair.server_conn_mut(server_ch).using_ecn());

    const REASON: &[u8] = b"whee";
    info!("closing");
    pair.client.connections.get_mut(&client_ch).unwrap().close(
        pair.time,
        VarInt(42),
        REASON.into(),
    );
    pair.drive();
    assert_matches!(pair.server_conn_mut(server_ch).poll(),
                    Some(Event::ConnectionLost { reason: ConnectionError::ApplicationClosed(
                        ApplicationClose { error_code: VarInt(42), ref reason }
                    )}) if reason == REASON);
    assert_matches!(pair.client_conn_mut(client_ch).poll(), None);
    assert_eq!(pair.client.known_connections(), 0);
    assert_eq!(pair.client.known_cids(), 0);
    assert_eq!(pair.server.known_connections(), 0);
    assert_eq!(pair.server.known_cids(), 0);
}
fn parse_include_tag() {
    let ast = parse("{% include \"index.html\" -%}").unwrap();
    assert_eq!(
        ast[0],
        Node::Include(WS { left: false, right: true }, vec!["index.html".to_string()], false,),
    );
    let ast =
        parse("{% include [\"custom/index.html\", \"index.html\"] ignore missing %}").unwrap();
    assert_eq!(
        ast[0],
        Node::Include(
            WS { left: false, right: false },
            vec!["custom/index.html".to_string(), "index.html".to_string()],
            true,
        ),
    );
}
fn test_read_execution_tracking() {
    let (_cluster, client, ctx) = must_new_cluster_and_kv_client();
    let (k1, v1) = (b"k1".to_vec(), b"v1".to_vec());
    let (k2, v2) = (b"k2".to_vec(), b"v2".to_vec());

    // write entries
    let mut mutation1 = Mutation::default();
    mutation1.set_op(Op::Put);
    mutation1.set_key(k1.clone());
    mutation1.set_value(v1);

    let mut mutation2 = Mutation::default();
    mutation2.set_op(Op::Put);
    mutation2.set_key(k2.clone());
    mutation2.set_value(v2);

    must_kv_prewrite(
        &client,
        ctx.clone(),
        vec![mutation1, mutation2],
        k1.clone(),
        10,
    );
    must_kv_commit(
        &client,
        ctx.clone(),
        vec![k1.clone(), k2.clone()],
        10,
        30,
        30,
    );

    let lease_read_checker = |scan_detail: &ScanDetailV2| {
        assert!(
            scan_detail.get_read_index_propose_wait_nanos() == 0,
            "resp lease read propose wait time={:?}",
            scan_detail.get_read_index_propose_wait_nanos()
        );

        assert!(
            scan_detail.get_read_index_confirm_wait_nanos() == 0,
            "resp lease read confirm wait time={:?}",
            scan_detail.get_read_index_confirm_wait_nanos()
        );

        assert!(
            scan_detail.get_read_pool_schedule_wait_nanos() > 0,
            "resp read pool scheduling wait time={:?}",
            scan_detail.get_read_pool_schedule_wait_nanos()
        );
    };

    fail::cfg("perform_read_local", "return()").unwrap();

    // should perform lease read
    let resp = kv_read(&client, ctx.clone(), k1.clone(), 100);

    lease_read_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    // should perform lease read
    let resp = kv_batch_read(&client, ctx.clone(), vec![k1.clone(), k2.clone()], 100);

    lease_read_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    let product = ProductTable::new();
    init_with_data(&product, &[(1, Some("name:0"), 2)]);
    let mut coprocessor_request = DagSelect::from(&product).build();
    coprocessor_request.set_context(ctx.clone());
    coprocessor_request.set_start_ts(100);

    // should perform lease read
    let resp = client.coprocessor(&coprocessor_request).unwrap();

    lease_read_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    fail::remove("perform_read_local");

    let read_index_checker = |scan_detail: &ScanDetailV2| {
        assert!(
            scan_detail.get_read_index_propose_wait_nanos() > 0,
            "resp lease read propose wait time={:?}",
            scan_detail.get_read_index_propose_wait_nanos()
        );

        assert!(
            scan_detail.get_read_index_confirm_wait_nanos() > 0,
            "resp lease read confirm wait time={:?}",
            scan_detail.get_read_index_confirm_wait_nanos()
        );

        assert!(
            scan_detail.get_read_pool_schedule_wait_nanos() > 0,
            "resp read pool scheduling wait time={:?}",
            scan_detail.get_read_pool_schedule_wait_nanos()
        );
    };

    fail::cfg("perform_read_index", "return()").unwrap();

    // should perform read index
    let resp = kv_read(&client, ctx.clone(), k1.clone(), 100);

    read_index_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    // should perform read index
    let resp = kv_batch_read(&client, ctx, vec![k1, k2], 100);

    read_index_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    // should perform read index
    let resp = client.coprocessor(&coprocessor_request).unwrap();

    read_index_checker(resp.get_exec_details_v2().get_scan_detail_v2());

    fail::remove("perform_read_index");
}
fn test_change_leader_async() {
    let eps_count = 3;
    let server = MockServer::with_case(eps_count, Arc::new(LeaderChange::new()));
    let eps = server.bind_addrs();

    let counter = Arc::new(AtomicUsize::new(0));
    let client = new_client(eps, None);
    let counter1 = Arc::clone(&counter);
    client.handle_reconnect(move || {
        counter1.fetch_add(1, Ordering::SeqCst);
    });
    let leader = client.get_leader();

    for _ in 0..5 {
        let region = block_on(client.get_region_by_id(1));
        region.ok();

        let new = client.get_leader();
        if new != leader {
            assert!(counter.load(Ordering::SeqCst) >= 1);
            return;
        }
        thread::sleep(LeaderChange::get_leader_interval());
    }

    panic!("failed, leader should changed");
}
fn client_close_notify() {
    let kt = KeyType::Rsa;
    let server_config = Arc::new(make_server_config_with_mandatory_client_auth(kt));

    for version in rustls::ALL_VERSIONS {
        let client_config = make_client_config_with_versions_with_auth(kt, &[version]);
        let (mut client, mut server) =
            make_pair_for_arc_configs(&Arc::new(client_config), &server_config);
        do_handshake(&mut client, &mut server);

        // check that alerts don't overtake appdata
        assert_eq!(
            12,
            server
                .writer()
                .write(b"from-server!")
                .unwrap()
        );
        assert_eq!(
            12,
            client
                .writer()
                .write(b"from-client!")
                .unwrap()
        );
        client.send_close_notify();

        transfer(&mut client, &mut server);
        let io_state = server.process_new_packets().unwrap();
        assert!(io_state.peer_has_closed());
        check_read_and_close(&mut server.reader(), b"from-client!");

        transfer(&mut server, &mut client);
        client.process_new_packets().unwrap();
        check_read(&mut client.reader(), b"from-server!");
    }
}
fn parse_create_table_without_rowid() {
    let sql = "CREATE TABLE t (a INT) WITHOUT ROWID";
    match sqlite_and_generic().verified_stmt(sql) {
        Statement::CreateTable {
            name,
            without_rowid: true,
            ..
        } => {
            assert_eq!("t", name.to_string());
        }
        _ => unreachable!(),
    }
}
fn test_nan() {
    let pos_nan = serde_yaml::from_str::<Value>(".nan").unwrap();
    assert!(pos_nan.is_f64());
    assert_eq!(pos_nan, pos_nan);

    let neg_fake_nan = serde_yaml::from_str::<Value>("-.nan").unwrap();
    assert!(neg_fake_nan.is_string());

    let significand_mask = 0xF_FFFF_FFFF_FFFF;
    let bits = (f64::NAN.copysign(1.0).to_bits() ^ significand_mask) | 1;
    let different_pos_nan = Value::Number(Number::from(f64::from_bits(bits)));
    assert_eq!(pos_nan, different_pos_nan);
}
fn module_component_mismatch() -> Result<()> {
    let engine = super::engine();
    let module = Module::new(&engine, "(module)")?.serialize()?;
    let component = Component::new(&engine, "(component)")?.serialize()?;

    unsafe {
        assert!(Module::deserialize(&engine, &component).is_err());
        assert!(Component::deserialize(&engine, &module).is_err());
    }

    Ok(())
}
fn cmp_test() {
    // Simple
    let x = VecType::from_u32(1);
    let y = VecType::from_u32(2);
    assert_eq!(x.partial_cmp(&x), Some(cmp::Ordering::Equal));
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Less);

    // Check asymmetric
    let x = VecType::try_from(&[5, 1]).unwrap();
    let y = VecType::from_u32(2);
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);

    // Check when we use reverse ordering properly.
    let x = VecType::try_from(&[5, 1, 9]).unwrap();
    let y = VecType::try_from(&[6, 2, 8]).unwrap();
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);

    // Complex scenario, check it properly uses reverse ordering.
    let x = VecType::try_from(&[0, 1, 9]).unwrap();
    let y = VecType::try_from(&[4294967295, 0, 9]).unwrap();
    assert_eq!(x.cmp(&x), cmp::Ordering::Equal);
    assert_eq!(x.cmp(&y), cmp::Ordering::Greater);
}
fn keep_alive() {
    let _guard = subscribe();
    const IDLE_TIMEOUT: u64 = 10;
    let server = ServerConfig {
        transport: Arc::new(TransportConfig {
            keep_alive_interval: Some(Duration::from_millis(IDLE_TIMEOUT / 2)),
            max_idle_timeout: Some(VarInt(IDLE_TIMEOUT)),
            ..TransportConfig::default()
        }),
        ..server_config()
    };
    let mut pair = Pair::new(Default::default(), server);
    let (client_ch, server_ch) = pair.connect();
    // Run a good while longer than the idle timeout
    let end = pair.time + Duration::from_millis(20 * IDLE_TIMEOUT);
    while pair.time < end {
        if !pair.step() {
            if let Some(time) = min_opt(pair.client.next_wakeup(), pair.server.next_wakeup()) {
                pair.time = time;
            }
        }
        assert!(!pair.client_conn_mut(client_ch).is_closed());
        assert!(!pair.server_conn_mut(server_ch).is_closed());
    }
}
fn parse_similar_to() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = redshift().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = redshift().verified_only_select(sql);
        assert_eq!(
            Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that SIMILAR TO and NOT SIMILAR TO have the same precedence.
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}SIMILAR TO '%a' ESCAPE '\\' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = redshift().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::SimilarTo {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn sqrtf_spec_test() {
    // Not Asserted: FE_INVALID exception is raised if argument is negative.
    assert!(libm::sqrtf(-1.0).is_nan());
    assert!(libm::sqrtf(f32::NAN).is_nan());
    for f in [0.0, -0.0, f32::INFINITY].iter().copied() {
        assert_eq!(libm::sqrtf(f), f);
    }
}
fn trap_smoke() -> Result<()> {
    let mut store = Store::<()>::default();
    let f = Func::wrap(&mut store, || -> Result<()> { bail!("test") });
    let err = f.call(&mut store, &[], &mut []).unwrap_err();
    assert!(err.to_string().contains("test"));
    Ok(())
}
fn test_destroy_by_larger_id_while_applying() {
    let fp = "APPLY_COMMITTED_ENTRIES";
    let mut cluster = Cluster::default();
    let router = &cluster.routers[0];
    router.wait_applied_to_current_term(2, Duration::from_secs(3));

    fail::cfg(fp, "pause").unwrap();

    let header = Box::new(router.new_request_for(2).take_header());
    let mut put = SimpleWriteEncoder::with_capacity(64);
    put.put(CF_DEFAULT, b"key", b"value");
    let (msg, mut sub) = PeerMsg::simple_write(header.clone(), put.clone().encode());
    router.send(2, msg).unwrap();
    assert!(block_on(sub.wait_committed()));

    let mut larger_id_msg = Box::<RaftMessage>::default();
    larger_id_msg.set_region_id(2);
    let mut target_peer = header.get_peer().clone();
    target_peer.set_id(target_peer.get_id() + 1);
    larger_id_msg.set_to_peer(target_peer.clone());
    larger_id_msg.set_region_epoch(header.get_region_epoch().clone());
    larger_id_msg
        .mut_region_epoch()
        .set_conf_ver(header.get_region_epoch().get_conf_ver() + 1);
    larger_id_msg.set_from_peer(new_peer(2, 8));
    let raft_message = larger_id_msg.mut_message();
    raft_message.set_msg_type(MessageType::MsgHeartbeat);
    raft_message.set_from(8);
    raft_message.set_to(target_peer.get_id());
    raft_message.set_term(10);

    // Larger ID should trigger destroy.
    router.send_raft_message(larger_id_msg).unwrap();
    fail::remove(fp);
    assert_peer_not_exist(2, header.get_peer().get_id(), router);
    let meta = router
        .must_query_debug_info(2, Duration::from_secs(3))
        .unwrap();
    assert_eq!(meta.raft_status.id, target_peer.get_id());
    assert_eq!(meta.raft_status.hard_state.term, 10);

    std::thread::sleep(Duration::from_millis(10));

    // New peer should survive restart.
    cluster.restart(0);
    let router = &cluster.routers[0];
    let meta = router
        .must_query_debug_info(2, Duration::from_secs(3))
        .unwrap();
    assert_eq!(meta.raft_status.id, target_peer.get_id());
    assert_eq!(meta.raft_status.hard_state.term, 10);
}
fn new_engine_opt_renamed_dir() {
    use std::sync::Arc;
    let dir = tempdir();
    let root_path = dir.path();

    let encryption_cfg = test_util::new_file_security_config(root_path);
    let key_manager = Arc::new(
        data_key_manager_from_config(&encryption_cfg, root_path.to_str().unwrap())
            .unwrap()
            .unwrap(),
    );

    let mut db_opts = DbOptions::default();
    db_opts.set_key_manager(Some(key_manager.clone()));
    let cf_opts: Vec<_> = ALL_CFS.iter().map(|cf| (*cf, CfOptions::new())).collect();

    let path = root_path.join("missing").to_str().unwrap().to_owned();
    {
        let db = KvTestEngine::new_kv_engine_opt(&path, db_opts.clone(), cf_opts.clone()).unwrap();
        db.put(b"foo", b"bar").unwrap();
        db.sync().unwrap();
    }
    let new_path = root_path.join("new").to_str().unwrap().to_owned();
    key_manager.link_file(&path, &new_path).unwrap();
    fs::rename(&path, &new_path).unwrap();
    key_manager.delete_file(&path).unwrap();
    {
        let db =
            KvTestEngine::new_kv_engine_opt(&new_path, db_opts.clone(), cf_opts.clone()).unwrap();
        assert_eq!(
            db.get_value_cf(CF_DEFAULT, b"foo").unwrap().unwrap(),
            b"bar"
        );
    }
}
fn apply_suggested_error() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("fix.js");
    fs.insert(file_path.into(), APPLY_SUGGESTED_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("check"),
                ("--apply-unsafe"),
                ("--apply"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "apply_suggested_error",
        fs,
        console,
        result,
    ));
}
fn new_server_returns_initial_io_state() {
    let (_, mut server) = make_pair(KeyType::Rsa);
    let io_state = server.process_new_packets().unwrap();
    println!("IoState is Debug {:?}", io_state);
    assert_eq!(io_state.plaintext_bytes_to_read(), 0);
    assert!(!io_state.peer_has_closed());
    assert_eq!(io_state.tls_bytes_to_write(), 0);
}
fn test_cp_backup_none() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg("--backup=none")
        .arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .succeeds()
        .no_stderr();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert!(!at.file_exists(format!("{TEST_HOW_ARE_YOU_SOURCE}~")));
}
fn test_raw_de_lone_surrogate() {
    use serde_json::value::RawValue;

    assert!(from_str::<Box<RawValue>>(r#""\ud83c""#).is_ok());
    assert!(from_str::<Box<RawValue>>(r#""\ud83c\n""#).is_ok());
    assert!(from_str::<Box<RawValue>>(r#""\ud83c ""#).is_ok());
    assert!(from_str::<Box<RawValue>>(r#""\udc01 ""#).is_ok());
    assert!(from_str::<Box<RawValue>>(r#""\udc01\!""#).is_err());
    assert!(from_str::<Box<RawValue>>(r#""\udc01\u""#).is_err());
    assert!(from_str::<Box<RawValue>>(r#""\ud83c\ud83c""#).is_ok());
}
fn ci_does_not_run_formatter() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert(
        PathBuf::from("biome.json"),
        CONFIG_DISABLED_FORMATTER.as_bytes(),
    );

    let input_file = Path::new("file.js");

    fs.insert(input_file.into(), UNFORMATTED.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("ci"), input_file.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(input_file)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, UNFORMATTED);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "ci_does_not_run_formatter",
        fs,
        console,
        result,
    ));
}
fn parse_continue() {
    let ast = parse("{% for item in items %}{% continue -%}{% endfor %}").unwrap();
    let for_ws = WS::default();
    assert_eq!(
        ast[0],
        Node::Forloop(
            for_ws,
            Forloop {
                key: None,
                value: "item".to_string(),
                container: Expr::new(ExprVal::Ident("items".to_string())),
                body: vec![Node::Continue(WS { left: false, right: true }),],
                empty_body: None,
            },
            for_ws,
        )
    );
}
fn test_mv_arg_update_none() {
    let (at, mut ucmd) = at_and_ucmd!();

    let file1 = "test_mv_arg_update_none_file1";
    let file2 = "test_mv_arg_update_none_file2";
    let file1_content = "file1 content\n";
    let file2_content = "file2 content\n";

    at.write(file1, file1_content);
    at.write(file2, file2_content);

    ucmd.arg(file1)
        .arg(file2)
        .arg("--update=none")
        .succeeds()
        .no_stderr()
        .no_stdout();

    assert_eq!(at.read(file2), file2_content);
}
fn valid_context_with_prior_xattributes() {
    let (dir, mut cmd) = at_and_ucmd!();
    dir.touch("a.tmp");

    let a_context = get_file_context(dir.plus("a.tmp")).unwrap();
    if a_context.is_none() {
        set_file_context(dir.plus("a.tmp"), "unconfined_u:object_r:user_tmp_t:s0").unwrap();
    }
    let new_la_context = "guest_u:object_r:etc_t:s0:c42";

    cmd.args(&["--verbose", new_la_context])
        .arg(dir.plus("a.tmp"))
        .succeeds();
    assert_eq!(
        get_file_context(dir.plus("a.tmp")).unwrap().as_deref(),
        Some(new_la_context)
    );
}
fn fs_error_infinite_symlink_expansion_to_dirs() {
    let fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let root_path = temp_dir().join("check_rome_test_infinite_symlink_expansion_to_dirs");
    let subdir1_path = root_path.join("prefix");
    let subdir2_path = root_path.join("foo").join("bar");

    let _ = remove_dir_all(&root_path);
    create_dir_all(&subdir1_path).unwrap();
    create_dir_all(&subdir2_path).unwrap();

    #[cfg(target_family = "unix")]
    {
        symlink(&subdir2_path, subdir1_path.join("symlink1")).unwrap();
        symlink(subdir1_path, subdir2_path.join("symlink2")).unwrap();
    }

    #[cfg(target_os = "windows")]
    {
        check_windows_symlink!(symlink_dir(&subdir2_path, &subdir1_path.join("symlink1")));
        check_windows_symlink!(symlink_dir(subdir1_path, subdir2_path.join("symlink2")));
    }

    let result = run_cli(
        DynRef::Owned(Box::new(OsFileSystem)),
        &mut console,
        Args::from([("check"), (root_path.display().to_string().as_str())].as_slice()),
    );

    remove_dir_all(root_path).unwrap();

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_infinite_symlink_expansion_to_dirs",
        fs,
        console,
        result,
    ));
}
fn exit125_wasi_snapshot0() -> Result<()> {
    let wasm = build_wasm("tests/all/cli_tests/exit125_wasi_snapshot0.wat")?;
    let output = run_wasmtime_for_output(&["-Ccache=n", wasm.path().to_str().unwrap()], None)?;
    if cfg!(windows) {
        assert_eq!(output.status.code().unwrap(), 1);
    } else {
        assert_eq!(output.status.code().unwrap(), 125);
    }
    Ok(())
}
fn parse_literal_timestamp_with_time_zone() {
    let sql = "SELECT TIMESTAMPTZ '1999-01-01 01:23:34Z'";
    let select = verified_only_select(sql);
    assert_eq!(
        &Expr::TypedString {
            data_type: DataType::Timestamp(None, TimezoneInfo::Tz),
            value: "1999-01-01 01:23:34Z".into(),
        },
        expr_from_projection(only(&select.projection)),
    );

    one_statement_parses_to("SELECT TIMESTAMPTZ '1999-01-01 01:23:34Z'", sql);
}
fn test_gt() {
    assert!(version("1.2.3-alpha2") > version("0.0.0"));
    assert!(version("1.2.3-alpha2") > version("1.0.0"));
    assert!(version("1.2.3-alpha2") > version("1.2.0"));
    assert!(version("1.2.3-alpha2") > version("1.2.3-alpha1"));
    assert!(version("1.2.3") > version("1.2.3-alpha2"));
    assert!(!(version("1.2.3-alpha2") > version("1.2.3-alpha2")));
    assert!(!(version("1.2.3+23") > version("1.2.3+42")));
}
fn test_parse_self_debug_line() {
    let debug_info = read_section("debug_info");
    let debug_info = DebugInfo::new(&debug_info, LittleEndian);

    let debug_abbrev = read_section("debug_abbrev");
    let debug_abbrev = DebugAbbrev::new(&debug_abbrev, LittleEndian);

    let debug_line = read_section("debug_line");
    let debug_line = DebugLine::new(&debug_line, LittleEndian);

    let debug_str = read_section("debug_str");
    let debug_str = DebugStr::new(&debug_str, LittleEndian);

    let mut iter = debug_info.units();
    while let Some(unit) = iter.next().expect("Should parse compilation unit") {
        let abbrevs = unit
            .abbreviations(&debug_abbrev)
            .expect("Should parse abbreviations");

        let mut cursor = unit.entries(&abbrevs);
        cursor.next_dfs().expect("Should parse next dfs");

        let unit_entry = cursor.current().expect("Should have a root entry");

        let comp_dir = unit_entry
            .attr_value(gimli::DW_AT_comp_dir)
            .expect("Should parse comp_dir attribute")
            .and_then(|val| val.string_value(&debug_str));
        let comp_name = unit_entry
            .attr_value(gimli::DW_AT_name)
            .expect("Should parse name attribute")
            .and_then(|val| val.string_value(&debug_str));

        if let Some(AttributeValue::DebugLineRef(offset)) = unit_entry
            .attr_value(gimli::DW_AT_stmt_list)
            .expect("Should parse stmt_list")
        {
            let program = debug_line
                .program(offset, unit.address_size(), comp_dir, comp_name)
                .expect("should parse line number program header");

            let mut results = Vec::new();
            let mut rows = program.rows();
            while let Some((_, row)) = rows
                .next_row()
                .expect("Should parse and execute all rows in the line number program")
            {
                results.push(*row);
            }
            results.reverse();

            let program = debug_line
                .program(offset, unit.address_size(), comp_dir, comp_name)
                .expect("should parse line number program header");
            let (program, sequences) = program
                .sequences()
                .expect("should parse and execute the entire line number program");
            assert!(!sequences.is_empty()); // Should be at least one sequence.
            for sequence in sequences {
                let mut rows = program.resume_from(&sequence);
                while let Some((_, row)) = rows
                    .next_row()
                    .expect("Should parse and execute all rows after resuming")
                {
                    let other_row = results.pop().unwrap();
                    assert!(row.address() >= sequence.start);
                    assert!(row.address() <= sequence.end);
                    assert_eq!(row.address(), other_row.address());
                    assert_eq!(row.line(), other_row.line());
                }
            }
            assert!(results.is_empty());
        }
    }
}
fn test_symlink_interactive() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let file = "test_symlink_interactive_file";
    let link = "test_symlink_interactive_file_link";

    at.touch(file);
    at.touch(link);

    scene
        .ucmd()
        .args(&["-i", "-s", file, link])
        .pipe_in("n")
        .fails()
        .no_stdout();

    assert!(at.file_exists(file));
    assert!(!at.is_symlink(link));

    scene
        .ucmd()
        .args(&["-i", "-s", file, link])
        .pipe_in("Yesh") // spell-checker:disable-line
        .succeeds()
        .no_stdout();

    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);
}
fn does_not_handle_ignored_file() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
  "files": {
    "include": ["test.js", "special/**"]
  },
  "overrides": [{ "ignore": ["special/**"] }]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), FIX_BEFORE.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), FIX_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, FIX_BEFORE);
    assert_file_contents(&fs, test, FIX_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_not_handle_ignored_file",
        fs,
        console,
        result,
    ));
}
fn custom_ordering() {
    #[derive(Debug)]
    struct ReverseKey(Vec<u8>);

    impl RedbValue for ReverseKey {
        type SelfType<'a> = ReverseKey
        where
        Self: 'a;
        type AsBytes<'a> = &'a [u8]
        where
        Self: 'a;

        fn fixed_width() -> Option<usize> {
            None
        }

        fn from_bytes<'a>(data: &'a [u8]) -> ReverseKey
        where
            Self: 'a,
        {
            ReverseKey(data.to_vec())
        }

        fn as_bytes<'a, 'b: 'a>(value: &'a Self::SelfType<'b>) -> &'a [u8]
        where
            Self: 'a,
            Self: 'b,
        {
            &value.0
        }

        fn type_name() -> TypeName {
            TypeName::new("test::ReverseKey")
        }
    }

    impl RedbKey for ReverseKey {
        fn compare(data1: &[u8], data2: &[u8]) -> Ordering {
            data2.cmp(data1)
        }
    }

    let definition: TableDefinition<ReverseKey, &str> = TableDefinition::new("x");

    let tmpfile = create_tempfile();
    let db = Database::create(tmpfile.path()).unwrap();
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_table(definition).unwrap();
        for i in 0..10u8 {
            let key = vec![i];
            table.insert(&ReverseKey(key), "value").unwrap();
        }
    }
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_table(definition).unwrap();
    let start = ReverseKey(vec![7u8]); // ReverseKey is used, so 7 < 3
    let end = ReverseKey(vec![3u8]);
    let mut iter = table.range(start..=end).unwrap();
    for i in (3..=7u8).rev() {
        let (key, value) = iter.next().unwrap().unwrap();
        assert_eq!(&[i], key.value().0.as_slice());
        assert_eq!("value", value.value());
    }
    assert!(iter.next().is_none());
}
fn render_images_alpha() {
    process_images("results_alpha.txt", &TEST_SUITES, |path| {
        let mut decoder = png::Decoder::new(File::open(&path)?);
        decoder.set_transformations(png::Transformations::ALPHA);
        let mut reader = decoder.read_info()?;
        let mut img_data = vec![0; reader.output_buffer_size()];
        let info = reader.next_frame(&mut img_data)?;
        let bits =
            ((info.width as usize * info.color_type.samples() * info.bit_depth as usize + 7) & !7)
                * info.height as usize;
        // First sanity check:
        assert_eq!(
            img_data.len() * 8,
            bits,
            "path: {} info: {:?} bits: {}",
            path.display(),
            info,
            bits
        );
        let mut crc = Crc32::new();
        crc.update(&img_data);
        Ok(crc.finalize())
    })
}
fn client_stream_handshake_error() {
    let (client_config, server_config) = make_disjoint_suite_configs();
    let (mut client, mut server) = make_pair_for_configs(client_config, server_config);

    {
        let mut pipe = OtherSession::new_fails(&mut server);
        let mut client_stream = Stream::new(&mut client, &mut pipe);
        let rc = client_stream.write(b"hello");
        assert!(rc.is_err());
        assert_eq!(
            format!("{:?}", rc),
            "Err(Custom { kind: InvalidData, error: AlertReceived(HandshakeFailure) })"
        );
        let rc = client_stream.write(b"hello");
        assert!(rc.is_err());
        assert_eq!(
            format!("{:?}", rc),
            "Err(Custom { kind: InvalidData, error: AlertReceived(HandshakeFailure) })"
        );
    }
}
fn test_mv_update_option() {
    let scene = TestScenario::new(util_name!());
    let at = &scene.fixtures;
    let file_a = "test_mv_update_option_file_a";
    let file_b = "test_mv_update_option_file_b";

    at.touch(file_a);
    at.touch(file_b);
    let ts = time::OffsetDateTime::now_utc();
    let now = FileTime::from_unix_time(ts.unix_timestamp(), ts.nanosecond());
    let later = FileTime::from_unix_time(ts.unix_timestamp() + 3600, ts.nanosecond());
    filetime::set_file_times(at.plus_as_string(file_a), now, now).unwrap();
    filetime::set_file_times(at.plus_as_string(file_b), now, later).unwrap();

    scene.ucmd().arg("--update").arg(file_a).arg(file_b).run();

    assert!(at.file_exists(file_a));
    assert!(at.file_exists(file_b));

    scene
        .ucmd()
        .arg("--update")
        .arg(file_b)
        .arg(file_a)
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file_a));
    assert!(!at.file_exists(file_b));
}
fn standalone_backtrace() -> Result<()> {
    let engine = Engine::default();
    let mut store = Store::new(&engine, ());
    let trace = WasmBacktrace::capture(&store);
    assert!(trace.frames().is_empty());
    let module = Module::new(
        &engine,
        r#"
            (module
                (import "" "" (func $host))
                (func $foo (export "f") call $bar)
                (func $bar call $host)
            )
        "#,
    )?;
    let func = Func::wrap(&mut store, |cx: Caller<'_, ()>| {
        let trace = WasmBacktrace::capture(&cx);
        assert_eq!(trace.frames().len(), 2);
        let frame1 = &trace.frames()[0];
        let frame2 = &trace.frames()[1];
        assert_eq!(frame1.func_index(), 2);
        assert_eq!(frame1.func_name(), Some("bar"));
        assert_eq!(frame2.func_index(), 1);
        assert_eq!(frame2.func_name(), Some("foo"));
    });
    let instance = Instance::new(&mut store, &module, &[func.into()])?;
    let f = instance.get_typed_func::<(), ()>(&mut store, "f")?;
    f.call(&mut store, ())?;
    Ok(())
}
fn test_merge_pessimistic_locks_with_concurrent_prewrite() {
    let mut cluster = new_server_cluster(0, 2);
    configure_for_merge(&mut cluster.cfg);
    cluster.cfg.pessimistic_txn.pipelined = true;
    cluster.cfg.pessimistic_txn.in_memory = true;
    let pd_client = Arc::clone(&cluster.pd_client);
    pd_client.disable_default_operator();

    cluster.run();

    cluster.must_transfer_leader(1, new_peer(1, 1));

    cluster.must_put(b"k1", b"v1");
    cluster.must_put(b"k3", b"v3");

    let region = cluster.get_region(b"k1");
    cluster.must_split(&region, b"k2");
    let left = cluster.get_region(b"k1");
    let right = cluster.get_region(b"k3");

    cluster.must_transfer_leader(right.id, new_peer(2, 2));

    let addr = cluster.sim.rl().get_addr(1);
    let env = Arc::new(Environment::new(1));
    let channel = ChannelBuilder::new(env).connect(&addr);
    let client = TikvClient::new(channel);

    let snapshot = cluster.must_get_snapshot_of_region(left.id);
    let txn_ext = snapshot.txn_ext.unwrap();
    let lock = PessimisticLock {
        primary: b"k0".to_vec().into_boxed_slice(),
        start_ts: 10.into(),
        ttl: 3000,
        for_update_ts: 20.into(),
        min_commit_ts: 30.into(),
        last_change_ts: 15.into(),
        versions_to_last_change: 3,
    };
    txn_ext
        .pessimistic_locks
        .write()
        .insert(vec![
            (Key::from_raw(b"k0"), lock.clone()),
            (Key::from_raw(b"k1"), lock),
        ])
        .unwrap();

    let mut mutation = Mutation::default();
    mutation.set_op(Op::Put);
    mutation.set_key(b"k0".to_vec());
    mutation.set_value(b"v".to_vec());
    let mut req = PrewriteRequest::default();
    req.set_context(cluster.get_ctx(b"k0"));
    req.set_mutations(vec![mutation].into());
    req.set_pessimistic_actions(vec![DoPessimisticCheck]);
    req.set_start_version(10);
    req.set_for_update_ts(40);
    req.set_primary_lock(b"k0".to_vec());

    // First, pause apply and prewrite.
    fail::cfg("on_handle_apply", "pause").unwrap();
    let req2 = req.clone();
    let client2 = client.clone();
    let resp = thread::spawn(move || client2.kv_prewrite(&req2).unwrap());
    thread::sleep(Duration::from_millis(500));

    // Then, start merging. PrepareMerge should wait until prewrite is done.
    cluster.merge_region(left.id, right.id, Callback::None);
    thread::sleep(Duration::from_millis(500));
    assert!(txn_ext.pessimistic_locks.read().is_writable());

    // But a later prewrite request should fail because we have already banned all
    // later proposals.
    req.mut_mutations()[0].set_key(b"k1".to_vec());
    let resp2 = thread::spawn(move || client.kv_prewrite(&req).unwrap());

    fail::remove("on_handle_apply");
    let resp = resp.join().unwrap();
    assert!(!resp.has_region_error(), "{:?}", resp);

    let resp2 = resp2.join().unwrap();
    assert!(resp2.has_region_error());
}
fn mismatch_intrinsics() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (type $t' (resource (rep i32)))
                (type $u' (resource (rep i32)))

                (export $t "t" (type $t'))
                (export $u "u" (type $u'))

                ;; note the mismatch where this is an intrinsic for `u` but
                ;; we're typing it as `t`
                (core func $t_ctor (canon resource.new $u))

                (func (export "ctor") (param "x" u32) (result (own $t))
                    (canon lift (core func $t_ctor)))
            )
        "#,
    )?;

    let mut store = Store::new(&engine, ());
    let i = Linker::new(&engine).instantiate(&mut store, &c)?;
    let ctor = i.get_typed_func::<(u32,), (ResourceAny,)>(&mut store, "ctor")?;
    assert_eq!(
        ctor.call(&mut store, (100,)).unwrap_err().to_string(),
        "unknown handle index 0"
    );

    Ok(())
}
fn reserved_name() {
    // Name "xmlns-something" is reserved according to spec, because started with "xml"
    let mut r =
        NsReader::from_str(r#"<a xmlns-something="reserved attribute name" xmlns="www1"/>"#);
    r.trim_text(true);

    // <a />
    match r.read_resolved_event() {
        Ok((ns, Empty(_))) => assert_eq!(ns, Bound(Namespace(b"www1"))),
        e => panic!(
            "Expected empty element bound to namespace 'www1', got {:?}",
            e
        ),
    }
}
fn test_twice_parenthesized_name() {
    let source_code = r#"((x)) + 1"#;
    let expr = parse_expression(source_code, "<filename>").unwrap();

    let bin_op = expr.as_bin_op_expr().unwrap();
    let name = bin_op.left.as_ref();

    let parenthesized = parenthesized_range(
        name.into(),
        bin_op.into(),
        &CommentRanges::default(),
        source_code,
    );
    assert_eq!(parenthesized, Some(TextRange::new(0.into(), 5.into())));
}
fn test_cp_arg_backup_with_other_args() {
    let (at, mut ucmd) = at_and_ucmd!();

    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("-vbL")
        .succeeds();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "Hello, World!\n");
    assert_eq!(
        at.read(&format!("{TEST_HOW_ARE_YOU_SOURCE}~")),
        "How are you?\n"
    );
}
async fn update_max_frame_len_at_rest() {
    use futures::StreamExt;
    use tokio::io::AsyncReadExt;

    h2_support::trace_init!();
    // TODO: add test for updating max frame length in flight as well?
    let mut codec = raw_codec! {
        read => [
            0, 0, 5, 0, 0, 0, 0, 0, 1,
            "hello",
            0, 64, 1, 0, 0, 0, 0, 0, 1,
            vec![0; 16_385],
        ];
    };

    assert_eq!(poll_frame!(Data, codec).payload(), &b"hello"[..]);

    codec.set_max_recv_frame_size(16_384);

    assert_eq!(codec.max_recv_frame_size(), 16_384);
    assert_eq!(
        codec.next().await.unwrap().unwrap_err().to_string(),
        "frame with invalid size"
    );

    // drain codec buffer
    let mut buf = Vec::new();
    codec.get_mut().read_to_end(&mut buf).await.unwrap();
}
fn parse_between_with_expr() {
    use self::BinaryOperator::*;
    let sql = "SELECT * FROM t WHERE 1 BETWEEN 1 + 2 AND 3 + 4 IS NULL";
    let select = verified_only_select(sql);
    assert_eq!(
        Expr::IsNull(Box::new(Expr::Between {
            expr: Box::new(Expr::Value(number("1"))),
            low: Box::new(Expr::BinaryOp {
                left: Box::new(Expr::Value(number("1"))),
                op: Plus,
                right: Box::new(Expr::Value(number("2"))),
            }),
            high: Box::new(Expr::BinaryOp {
                left: Box::new(Expr::Value(number("3"))),
                op: Plus,
                right: Box::new(Expr::Value(number("4"))),
            }),
            negated: false,
        })),
        select.selection.unwrap()
    );

    let sql = "SELECT * FROM t WHERE 1 = 1 AND 1 + x BETWEEN 1 AND 2";
    let select = verified_only_select(sql);
    assert_eq!(
        Expr::BinaryOp {
            left: Box::new(Expr::BinaryOp {
                left: Box::new(Expr::Value(number("1"))),
                op: BinaryOperator::Eq,
                right: Box::new(Expr::Value(number("1"))),
            }),
            op: BinaryOperator::And,
            right: Box::new(Expr::Between {
                expr: Box::new(Expr::BinaryOp {
                    left: Box::new(Expr::Value(number("1"))),
                    op: BinaryOperator::Plus,
                    right: Box::new(Expr::Identifier(Ident::new("x"))),
                }),
                low: Box::new(Expr::Value(number("1"))),
                high: Box::new(Expr::Value(number("2"))),
                negated: false,
            }),
        },
        select.selection.unwrap(),
    )
}
fn thread_through_borrow() -> Result<()> {
    let engine = super::engine();
    let c = Component::new(
        &engine,
        r#"
            (component
                (import "t" (type $t (sub resource)))
                (import "f" (func $f (param "x" (borrow $t))))

                (core func $f (canon lower (func $f)))
                (core func $drop (canon resource.drop $t))

                (core module $m
                    (import "" "f" (func $f (param i32)))
                    (import "" "drop" (func $drop (param i32)))
                    (func (export "f2") (param i32)
                        (call $f (local.get 0))
                        (call $f (local.get 0))
                        (call $drop (local.get 0))
                    )
                )
                (core instance $i (instantiate $m
                    (with "" (instance
                        (export "f" (func $f))
                        (export "drop" (func $drop))
                    ))
                ))

                (func (export "f2") (param "x" (borrow $t))
                    (canon lift (core func $i "f2")))
            )
        "#,
    )?;

    struct MyType;

    let mut store = Store::new(&engine, ());
    let mut linker = Linker::new(&engine);
    linker.root().resource::<MyType>("t", |_, _| Ok(()))?;
    linker
        .root()
        .func_wrap("f", |_cx, (r,): (Resource<MyType>,)| {
            assert!(!r.owned());
            assert_eq!(r.rep(), 100);
            Ok(())
        })?;
    let i = linker.instantiate(&mut store, &c)?;

    let f = i.get_typed_func::<(&Resource<MyType>,), ()>(&mut store, "f2")?;

    let resource = Resource::new_own(100);
    f.call(&mut store, (&resource,))?;
    f.post_return(&mut store)?;
    Ok(())
}
fn re_opening_database_does_not_trigger_schema_check() {
  let rpc_server = test_bitcoincore_rpc::spawn();
  rpc_server.mine_blocks(1);

  let tempdir = TempDir::new().unwrap();

  let index_path = tempdir.path().join("foo.redb");

  CommandBuilder::new(format!("--index {} index update", index_path.display()))
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Empty>();

  assert!(index_path.is_file());

  CommandBuilder::new(format!("--index {} index update", index_path.display()))
    .rpc_server(&rpc_server)
    .run_and_deserialize_output::<Empty>();
}
fn format_jsonc_files() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let code = r#"
/*test*/ [

/* some other comment*/1, 2, 3]
    "#;
    let file_path = Path::new("file.jsonc");
    fs.insert(file_path.into(), code.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("format"), file_path.as_os_str().to_str().unwrap()].as_slice()),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "format_jsonc_files",
        fs,
        console,
        result,
    ));
}
fn drop_externref_global_during_module_init() -> Result<()> {
    struct Limiter;

    impl ResourceLimiter for Limiter {
        fn memory_growing(&mut self, _: usize, _: usize, _: Option<usize>) -> Result<bool> {
            Ok(false)
        }

        fn table_growing(&mut self, _: u32, _: u32, _: Option<u32>) -> Result<bool> {
            Ok(false)
        }
    }

    let pool = crate::small_pool_config();
    let mut config = Config::new();
    config.wasm_reference_types(true);
    config.allocation_strategy(InstanceAllocationStrategy::Pooling(pool));

    let engine = Engine::new(&config)?;

    let module = Module::new(
        &engine,
        r#"
            (module
                (global i32 (i32.const 1))
                (global i32 (i32.const 2))
                (global i32 (i32.const 3))
                (global i32 (i32.const 4))
                (global i32 (i32.const 5))
            )
        "#,
    )?;

    let mut store = Store::new(&engine, Limiter);
    Instance::new(&mut store, &module, &[])?;
    drop(store);

    let module = Module::new(
        &engine,
        r#"
            (module
                (memory 1)
                (global (mut externref) (ref.null extern))
            )
        "#,
    )?;

    let mut store = Store::new(&engine, Limiter);
    store.limiter(|s| s);
    assert!(Instance::new(&mut store, &module, &[]).is_err());

    Ok(())
}
fn broken() {
    let f = super::fixture();

    let resolver = Resolver::new(ResolveOptions {
        alias_fields: vec![vec!["browser".into()]],
        ..ResolveOptions::default()
    });

    #[rustfmt::skip]
    let data = [
        // The browser field string value should be ignored
        (f.clone(), "browser-module-broken", f.join("node_modules/browser-module-broken/main.js")),
    ];

    for (path, request, expected) in data {
        let resolved_path = resolver.resolve(&path, request).map(|r| r.full_path());
        assert_eq!(resolved_path, Ok(expected), "{path:?} {request}");
    }
}
fn preview_enabled_all() {
    let args = ["--select", "ALL", "--preview"];
    assert_cmd_snapshot!(Command::new(get_cargo_bin(BIN_NAME))
        .args(STDIN_BASE_OPTIONS)
        .args(args)
        .pass_stdin("I=42\n"), @r###"
    success: false
    exit_code: 1
    ----- stdout -----
    -:1:1: E741 Ambiguous variable name: `I`
    -:1:1: D100 Missing docstring in public module
    -:1:1: CPY001 Missing copyright notice at top of file
    -:1:2: E225 [*] Missing whitespace around operator
    Found 4 errors.
    [*] 1 fixable with the `--fix` option.

    ----- stderr -----
    warning: `one-blank-line-before-class` (D203) and `no-blank-line-before-class` (D211) are incompatible. Ignoring `one-blank-line-before-class`.
    warning: `multi-line-summary-first-line` (D212) and `multi-line-summary-second-line` (D213) are incompatible. Ignoring `multi-line-summary-second-line`.
    "###);
}
fn test_touch_no_create_file_absent() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_no_create_file_absent";

    ucmd.arg("-c").arg(file).succeeds().no_stderr();

    assert!(!at.file_exists(file));
}
fn save_point_rollback_one() {
    let db = default_engine();
    let mut wb = db.engine.write_batch();

    wb.set_save_point();
    wb.put(b"a", b"").unwrap();

    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());

    let db = multi_batch_write_engine();
    let mut wb = db.engine.write_batch_with_cap(1024);

    wb.set_save_point();
    for i in 0..256_usize {
        let x = i.to_be_bytes();
        wb.put(&x, &x).unwrap();
    }
    wb.put(b"a", b"").unwrap();

    wb.rollback_to_save_point().unwrap();

    let err = wb.rollback_to_save_point();
    assert_engine_error(err);
    let err = wb.pop_save_point();
    assert_engine_error(err);
    wb.write().unwrap();
    for i in 0..256_usize {
        assert!(db.engine.get_value(&i.to_be_bytes()).unwrap().is_none());
    }
    let val = db.engine.get_value(b"a").unwrap();
    assert!(val.is_none());
}
fn u64_digit_count_test() {
    assert_eq!(u64::digit_count(0), 1);
    assert_eq!(u64::digit_count(1), 1);
    assert_eq!(u64::digit_count(9), 1);
    assert_eq!(u64::digit_count(10), 2);
    assert_eq!(u64::digit_count(11), 2);

    assert_eq!(u64::digit_count((1 << 16) - 1), 5);
    assert_eq!(u64::digit_count(1 << 16), 5);
    assert_eq!(u64::digit_count((1 << 16) + 1), 5);

    assert_eq!(u64::digit_count(u32::MAX as u64), 10);
    assert_eq!(u64::digit_count(u64::MAX), 20);
}
fn remove_multiple_b() {
    let mut headers = HeaderMap::new();
    headers.insert(VIA, "1.1 example.com".parse().unwrap());
    headers.insert(SET_COOKIE, "cookie_1=value 1".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_2=value 2".parse().unwrap());
    headers.append(VIA, "1.1 other.com".parse().unwrap());
    headers.append(SET_COOKIE, "cookie_3=value 3".parse().unwrap());
    headers.insert(VARY, "*".parse().unwrap());

    assert_eq!(headers.len(), 6);

    let vary = headers.remove(VARY);
    assert_eq!(vary, Some("*".parse().unwrap()));
    assert_eq!(headers.len(), 5);

    let via = headers.remove(VIA);
    assert_eq!(via, Some("1.1 example.com".parse().unwrap()));
    assert_eq!(headers.len(), 3);

    let cookie = headers.remove(SET_COOKIE);
    assert_eq!(cookie, Some("cookie_1=value 1".parse().unwrap()));
    assert_eq!(headers.len(), 0);
}
fn test_touch_set_both() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_touch_set_both";

    ucmd.args(&["-t", "201501011234", "-a", "-m", file])
        .succeeds()
        .no_stderr();

    assert!(at.file_exists(file));

    let start_of_year = str_to_filetime("%Y%m%d%H%M", "201501010000");
    let (atime, mtime) = get_file_times(&at, file);
    assert_eq!(atime, mtime);
    assert_eq!(atime.unix_seconds() - start_of_year.unix_seconds(), 45240);
    assert_eq!(mtime.unix_seconds() - start_of_year.unix_seconds(), 45240);
}
fn integers() -> Result<()> {
    let component = r#"
        (component
            (core module $m
                (func (export "take-i32-100") (param i32)
                    local.get 0
                    i32.const 100
                    i32.eq
                    br_if 0
                    unreachable
                )
                (func (export "take-i64-100") (param i64)
                    local.get 0
                    i64.const 100
                    i64.eq
                    br_if 0
                    unreachable
                )
                (func (export "ret-i32-0") (result i32) i32.const 0)
                (func (export "ret-i64-0") (result i64) i64.const 0)
                (func (export "ret-i32-minus-1") (result i32) i32.const -1)
                (func (export "ret-i64-minus-1") (result i64) i64.const -1)
                (func (export "ret-i32-100000") (result i32) i32.const 100000)
            )
            (core instance $i (instantiate (module $m)))
            (func (export "take-u8") (param "a" u8) (canon lift (core func $i "take-i32-100")))
            (func (export "take-s8") (param "a" s8) (canon lift (core func $i "take-i32-100")))
            (func (export "take-u16") (param "a" u16) (canon lift (core func $i "take-i32-100")))
            (func (export "take-s16") (param "a" s16) (canon lift (core func $i "take-i32-100")))
            (func (export "take-u32") (param "a" u32) (canon lift (core func $i "take-i32-100")))
            (func (export "take-s32") (param "a" s32) (canon lift (core func $i "take-i32-100")))
            (func (export "take-u64") (param "a" u64) (canon lift (core func $i "take-i64-100")))
            (func (export "take-s64") (param "a" s64) (canon lift (core func $i "take-i64-100")))

            (func (export "ret-u8") (result u8) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-s8") (result s8) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-u16") (result u16) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-s16") (result s16) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-u32") (result u32) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-s32") (result s32) (canon lift (core func $i "ret-i32-0")))
            (func (export "ret-u64") (result u64) (canon lift (core func $i "ret-i64-0")))
            (func (export "ret-s64") (result s64) (canon lift (core func $i "ret-i64-0")))

            (func (export "retm1-u8") (result u8) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-s8") (result s8) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-u16") (result u16) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-s16") (result s16) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-u32") (result u32) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-s32") (result s32) (canon lift (core func $i "ret-i32-minus-1")))
            (func (export "retm1-u64") (result u64) (canon lift (core func $i "ret-i64-minus-1")))
            (func (export "retm1-s64") (result s64) (canon lift (core func $i "ret-i64-minus-1")))

            (func (export "retbig-u8") (result u8) (canon lift (core func $i "ret-i32-100000")))
            (func (export "retbig-s8") (result s8) (canon lift (core func $i "ret-i32-100000")))
            (func (export "retbig-u16") (result u16) (canon lift (core func $i "ret-i32-100000")))
            (func (export "retbig-s16") (result s16) (canon lift (core func $i "ret-i32-100000")))
            (func (export "retbig-u32") (result u32) (canon lift (core func $i "ret-i32-100000")))
            (func (export "retbig-s32") (result s32) (canon lift (core func $i "ret-i32-100000")))
        )
    "#;

    let engine = super::engine();
    let component = Component::new(&engine, component)?;
    let mut store = Store::new(&engine, ());
    let new_instance = |store: &mut Store<()>| Linker::new(&engine).instantiate(store, &component);
    let instance = new_instance(&mut store)?;

    // Passing in 100 is valid for all primitives
    instance
        .get_typed_func::<(u8,), ()>(&mut store, "take-u8")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(i8,), ()>(&mut store, "take-s8")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(u16,), ()>(&mut store, "take-u16")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(i16,), ()>(&mut store, "take-s16")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(u32,), ()>(&mut store, "take-u32")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(i32,), ()>(&mut store, "take-s32")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(u64,), ()>(&mut store, "take-u64")?
        .call_and_post_return(&mut store, (100,))?;
    instance
        .get_typed_func::<(i64,), ()>(&mut store, "take-s64")?
        .call_and_post_return(&mut store, (100,))?;

    // This specific wasm instance traps if any value other than 100 is passed
    new_instance(&mut store)?
        .get_typed_func::<(u8,), ()>(&mut store, "take-u8")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(i8,), ()>(&mut store, "take-s8")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(u16,), ()>(&mut store, "take-u16")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(i16,), ()>(&mut store, "take-s16")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(u32,), ()>(&mut store, "take-u32")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(i32,), ()>(&mut store, "take-s32")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(u64,), ()>(&mut store, "take-u64")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;
    new_instance(&mut store)?
        .get_typed_func::<(i64,), ()>(&mut store, "take-s64")?
        .call(&mut store, (101,))
        .unwrap_err()
        .downcast::<Trap>()?;

    // Zero can be returned as any integer
    assert_eq!(
        instance
            .get_typed_func::<(), (u8,)>(&mut store, "ret-u8")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i8,)>(&mut store, "ret-s8")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u16,)>(&mut store, "ret-u16")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i16,)>(&mut store, "ret-s16")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u32,)>(&mut store, "ret-u32")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i32,)>(&mut store, "ret-s32")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u64,)>(&mut store, "ret-u64")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i64,)>(&mut store, "ret-s64")?
            .call_and_post_return(&mut store, ())?,
        (0,)
    );

    // Returning -1 should reinterpret the bytes as defined by each type.
    assert_eq!(
        instance
            .get_typed_func::<(), (u8,)>(&mut store, "retm1-u8")?
            .call_and_post_return(&mut store, ())?,
        (0xff,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i8,)>(&mut store, "retm1-s8")?
            .call_and_post_return(&mut store, ())?,
        (-1,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u16,)>(&mut store, "retm1-u16")?
            .call_and_post_return(&mut store, ())?,
        (0xffff,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i16,)>(&mut store, "retm1-s16")?
            .call_and_post_return(&mut store, ())?,
        (-1,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u32,)>(&mut store, "retm1-u32")?
            .call_and_post_return(&mut store, ())?,
        (0xffffffff,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i32,)>(&mut store, "retm1-s32")?
            .call_and_post_return(&mut store, ())?,
        (-1,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u64,)>(&mut store, "retm1-u64")?
            .call_and_post_return(&mut store, ())?,
        (0xffffffff_ffffffff,)
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i64,)>(&mut store, "retm1-s64")?
            .call_and_post_return(&mut store, ())?,
        (-1,)
    );

    // Returning 100000 should chop off bytes as necessary
    let ret: u32 = 100000;
    assert_eq!(
        instance
            .get_typed_func::<(), (u8,)>(&mut store, "retbig-u8")?
            .call_and_post_return(&mut store, ())?,
        (ret as u8,),
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i8,)>(&mut store, "retbig-s8")?
            .call_and_post_return(&mut store, ())?,
        (ret as i8,),
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u16,)>(&mut store, "retbig-u16")?
            .call_and_post_return(&mut store, ())?,
        (ret as u16,),
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i16,)>(&mut store, "retbig-s16")?
            .call_and_post_return(&mut store, ())?,
        (ret as i16,),
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (u32,)>(&mut store, "retbig-u32")?
            .call_and_post_return(&mut store, ())?,
        (ret,),
    );
    assert_eq!(
        instance
            .get_typed_func::<(), (i32,)>(&mut store, "retbig-s32")?
            .call_and_post_return(&mut store, ())?,
        (ret as i32,),
    );

    Ok(())
}
fn test_symlink_custom_backup_suffix() {
    let (at, mut ucmd) = at_and_ucmd!();
    let file = "test_symlink_custom_backup_suffix";
    let link = "test_symlink_custom_backup_suffix_link";
    let suffix = "super-suffix-of-the-century";

    at.touch(file);
    at.symlink_file(file, link);
    assert!(at.file_exists(file));
    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let arg = &format!("--suffix={suffix}");
    ucmd.args(&["-b", arg, "-s", file, link])
        .succeeds()
        .no_stderr();
    assert!(at.file_exists(file));

    assert!(at.is_symlink(link));
    assert_eq!(at.resolve_link(link), file);

    let backup = &format!("{link}{suffix}");
    assert!(at.is_symlink(backup));
    assert_eq!(at.resolve_link(backup), file);
}
fn parse_variable_tag_ident_with_simple_filters() {
    let ast = parse("{{ arr | first | join(n=2) }}").unwrap();
    let mut join_args = HashMap::new();
    join_args.insert("n".to_string(), Expr::new(ExprVal::Int(2)));

    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::with_filters(
                ExprVal::Ident("arr".to_string()),
                vec![
                    FunctionCall { name: "first".to_string(), args: HashMap::new() },
                    FunctionCall { name: "join".to_string(), args: join_args },
                ],
            )
        )
    );
}
fn test_skip_iter_ic() {
    // Test iterators that skip multiple, internal digit separators.
    pub const FORMAT: u128 = NumberFormatBuilder::new()
        .digit_separator(num::NonZeroU8::new(b'_'))
        .integer_internal_digit_separator(true)
        .integer_consecutive_digit_separator(true)
        .build();
    const_assert!(NumberFormat::<{ FORMAT }> {}.is_valid());

    skip_iter_eq::<{ FORMAT }>(b"123.45", b"123.45");
    skip_iter_eq::<{ FORMAT }>(b"1e45", b"1e45");
    skip_iter_eq::<{ FORMAT }>(b"1e", b"1e");
    skip_iter_eq::<{ FORMAT }>(b"1", b"1");
    skip_iter_eq::<{ FORMAT }>(b"_45", b"_45");
    skip_iter_eq::<{ FORMAT }>(b"__45", b"__45");
    skip_iter_eq::<{ FORMAT }>(b"_.45", b"_.45");
    skip_iter_eq::<{ FORMAT }>(b"__.45", b"__.45");
    skip_iter_eq::<{ FORMAT }>(b"4_5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4__5", b"45");
    skip_iter_eq::<{ FORMAT }>(b"4_", b"4_");
    skip_iter_eq::<{ FORMAT }>(b"4__", b"4__");
    skip_iter_eq::<{ FORMAT }>(b"4_.", b"4_.");
    skip_iter_eq::<{ FORMAT }>(b"4__.", b"4__.");
    skip_iter_eq::<{ FORMAT }>(b"_45_5", b"_455");
    skip_iter_eq::<{ FORMAT }>(b"__45__5", b"__455");
    skip_iter_eq::<{ FORMAT }>(b"_.45_5", b"_.455");
    skip_iter_eq::<{ FORMAT }>(b"__.45__5", b"__.455");
    skip_iter_eq::<{ FORMAT }>(b"4_5_", b"45_");
    skip_iter_eq::<{ FORMAT }>(b"4__5__", b"45__");
    skip_iter_eq::<{ FORMAT }>(b"4_5_.5", b"45_.5");
    skip_iter_eq::<{ FORMAT }>(b"4__5__.5", b"45__.5");
    skip_iter_eq::<{ FORMAT }>(b"_45_", b"_45_");
    skip_iter_eq::<{ FORMAT }>(b"__45__", b"__45__");
    skip_iter_eq::<{ FORMAT }>(b"_45_.56", b"_45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__45__.56", b"__45__.56");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_", b"_45_");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__", b"__45__");
    skip_iter_eq::<{ FORMAT }>(b"_4_5_.56", b"_45_.56");
    skip_iter_eq::<{ FORMAT }>(b"__4__5__.56", b"__45__.56");
}
fn test_pub_self() {
    assert_vis_parse!("pub(self)", Ok(Visibility::Restricted(_)));
}
fn parse_mssql_top_percent_with_ties() {
    let sql = "SELECT TOP (10) PERCENT WITH TIES * FROM foo";
    let select = ms_and_generic().verified_only_select(sql);
    let top = select.top.unwrap();
    assert_eq!(Some(Expr::Value(number("10"))), top.quantity);
    assert!(top.percent);
}
fn test_attributes_empty() {
    let src = "<a att1='a' att2='b'/>";
    let mut r = Reader::from_str(src);
    r.trim_text(true);
    match r.read_event() {
        Ok(Empty(e)) => {
            let mut attrs = e.attributes();
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"att1"),
                    value: Cow::Borrowed(b"a"),
                }))
            );
            assert_eq!(
                attrs.next(),
                Some(Ok(Attribute {
                    key: QName(b"att2"),
                    value: Cow::Borrowed(b"b"),
                }))
            );
            assert_eq!(attrs.next(), None);
        }
        e => panic!("Expecting Empty event, got {:?}", e),
    }
}
fn as_f32_test() {
    assert_eq!(bf16::from_bits(1).as_f32(), 9.18355e-41f32);
    assert_eq!(bf16::ZERO.as_f32(), 0.0f32);
    assert_eq!(bf16::ZERO.to_bits(), 0);
    assert_eq!(bf16::ONE.as_f32(), 1.0f32);
    assert_eq!(bf16::ONE.to_bits(), (127 << 7));
    assert_eq!(bf16::TWO.as_f32(), 2.0f32);
    assert_eq!(bf16::TWO.to_bits(), (128 << 7));
    assert_eq!(bf16::from_bits(126 << 7).as_f32(), 0.5f32);
    assert!(bf16::NAN.as_f32().is_nan());
    assert!(bf16::INFINITY.as_f32().is_inf());
    assert!(bf16::NEG_INFINITY.as_f32().is_inf());
}
fn macro_param_arent_escaped() {
    let mut tera = Tera::default();
    tera.add_raw_templates(vec![
        ("macros.html", r#"{% macro print(val) %}{{val|safe}}{% endmacro print %}"#),
        ("hello.html", r#"{% import "macros.html" as macros %}{{ macros::print(val=my_var)}}"#),
    ])
    .unwrap();
    let mut context = Context::new();
    context.insert("my_var", &"&");
    let result = tera.render("hello.html", &context);

    assert_eq!(result.unwrap(), "&".to_string());
}
fn parse_like() {
    fn chk(negated: bool) {
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a'",
            if negated { "NOT " } else { "" }
        );
        let select = snowflake().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            },
            select.selection.unwrap()
        );

        // Test with escape char
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' ESCAPE '\\'",
            if negated { "NOT " } else { "" }
        );
        let select = snowflake().verified_only_select(sql);
        assert_eq!(
            Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: Some('\\'),
            },
            select.selection.unwrap()
        );

        // This statement tests that LIKE and NOT LIKE have the same precedence.
        // This was previously mishandled (#81).
        let sql = &format!(
            "SELECT * FROM customers WHERE name {}LIKE '%a' IS NULL",
            if negated { "NOT " } else { "" }
        );
        let select = snowflake().verified_only_select(sql);
        assert_eq!(
            Expr::IsNull(Box::new(Expr::Like {
                expr: Box::new(Expr::Identifier(Ident::new("name"))),
                negated,
                pattern: Box::new(Expr::Value(Value::SingleQuotedString("%a".to_string()))),
                escape_char: None,
            })),
            select.selection.unwrap()
        );
    }
    chk(false);
    chk(true);
}
fn test_min_and_max() {
    assert_eq!(f32::from_bits(0x7f7fffff), 3.4028235e38);
    check!(3.4028235e38);
    assert_eq!(f32::from_bits(1), 1e-45);
    check!(1e-45);
}
fn test_error_in_macro_location() {
    let result = render_tpl("error-location/error_in_macro.html");

    assert!(result.is_err());
    let errs = result.unwrap_err();
    assert_eq!(
        errs.to_string(),
        "Failed to render 'error-location/error_in_macro.html': error while rendering macro `macros::cause_error`"
    );
}
fn test_cp_arg_no_clobber_inferred_arg() {
    let (at, mut ucmd) = at_and_ucmd!();
    ucmd.arg(TEST_HELLO_WORLD_SOURCE)
        .arg(TEST_HOW_ARE_YOU_SOURCE)
        .arg("--no-clob")
        .fails();

    assert_eq!(at.read(TEST_HOW_ARE_YOU_SOURCE), "How are you?\n");
}
fn applies_custom_arrow_parentheses() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    let file_path = Path::new("file.js");
    fs.insert(file_path.into(), APPLY_ARROW_PARENTHESES_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("format"),
                ("--arrow-parentheses"),
                ("as-needed"),
                ("--write"),
                file_path.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    let mut file = fs
        .open(file_path)
        .expect("formatting target file was removed by the CLI");

    let mut content = String::new();
    file.read_to_string(&mut content)
        .expect("failed to read file from memory FS");

    assert_eq!(content, APPLY_ARROW_PARENTHESES_AFTER);

    drop(file);
    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "applies_custom_arrow_parentheses",
        fs,
        console,
        result,
    ));
}
fn parens_test() {
  assert_eq!(
    expr(" ( 1 + 2 ) *  3 ").map(|(i, x)| (i, format!("{:?}", x))),
    Ok(("", String::from("([(1 + 2)] * 3)")))
  );
}
fn parse_alter_role() {
    let sql = "ALTER ROLE old_name WITH NAME = new_name";
    assert_eq!(
        ms().parse_sql_statements(sql).unwrap(),
        [Statement::AlterRole {
            name: Ident {
                value: "old_name".into(),
                quote_style: None
            },
            operation: AlterRoleOperation::RenameRole {
                role_name: Ident {
                    value: "new_name".into(),
                    quote_style: None
                }
            },
        }]
    );

    let sql = "ALTER ROLE role_name ADD MEMBER new_member";
    assert_eq!(
        ms().verified_stmt(sql),
        Statement::AlterRole {
            name: Ident {
                value: "role_name".into(),
                quote_style: None
            },
            operation: AlterRoleOperation::AddMember {
                member_name: Ident {
                    value: "new_member".into(),
                    quote_style: None
                }
            },
        }
    );

    let sql = "ALTER ROLE role_name DROP MEMBER old_member";
    assert_eq!(
        ms().verified_stmt(sql),
        Statement::AlterRole {
            name: Ident {
                value: "role_name".into(),
                quote_style: None
            },
            operation: AlterRoleOperation::DropMember {
                member_name: Ident {
                    value: "old_member".into(),
                    quote_style: None
                }
            },
        }
    );
}
fn does_render_owned_for_loop_with_objects_string_keys() {
    let mut context = Context::new();
    let data = json!([
        {"id": 1, "group": "a"},
        {"id": 2, "group": "b"},
        {"id": 3, "group": "c"},
        {"id": 4, "group": "a"},
        {"id": 5, "group": "b"},
        {"id": 6, "group": "c"},
        {"id": 7, "group": "a"},
        {"id": 8},
        {"id": 9, "year": null},
    ]);
    context.insert("something", &data);

    let tpl = r#"{% for group, things in something | group_by(attribute="group") %}{{group}},{% endfor %}"#;
    let expected = "a,b,c,";
    assert_eq!(render_template(tpl, &context).unwrap(), expected);
}
fn test_lenient_undefined() {
    let mut env = Environment::new();
    env.add_filter("test", |state: &State, value: String| -> String {
        assert_eq!(state.undefined_behavior(), UndefinedBehavior::Lenient);
        assert_eq!(value, "");
        value
    });

    assert_eq!(env.undefined_behavior(), UndefinedBehavior::Lenient);
    assert_eq!(render!(in env, "<{{ true.missing_attribute }}>"), "<>");
    assert_eq!(
        env.render_str("{{ undefined.missing_attribute }}", ())
            .unwrap_err()
            .kind(),
        ErrorKind::UndefinedError
    );
    assert_eq!(
        render!(in env, "<{% for x in undefined %}...{% endfor %}>"),
        "<>"
    );
    assert_eq!(render!(in env, "<{{ undefined }}>"), "<>");
    assert_eq!(render!(in env, "{{ undefined is undefined }}"), "true");
    assert_eq!(render!(in env, "{{ undefined|list }}"), "[]");
    assert_eq!(render!(in env, "<{{ undefined|test }}>"), "<>");
    assert_eq!(render!(in env, "{{ 42 in undefined }}"), "false");
}
fn efficient_storage() {
    let tmpfile = create_tempfile();
    let expected_max_size = 1024 * 1024;
    // Write enough values that big_key.len() * entries > db_size to check that duplicate key data is not stored
    // and entries * sizeof(u32) > page_size to validate that large numbers of values can be stored per key
    let entries = 10000;
    let db = Database::create(tmpfile.path()).unwrap();
    let table_def: MultimapTableDefinition<&[u8], u32> = MultimapTableDefinition::new("x");
    let write_txn = db.begin_write().unwrap();
    {
        let mut table = write_txn.open_multimap_table(table_def).unwrap();
        let big_key = [0u8; 1000];
        for i in 0..entries {
            table.insert(big_key.as_slice(), &i).unwrap();
        }
    }
    assert!(write_txn.stats().unwrap().stored_bytes() <= expected_max_size);
    write_txn.commit().unwrap();

    let read_txn = db.begin_read().unwrap();
    let table = read_txn.open_multimap_table(table_def).unwrap();
    assert_eq!(table.len().unwrap(), entries as u64);
}
fn does_include_file_with_different_linting_and_applies_all_of_them() {
    let mut console = BufferConsole::default();
    let mut fs = MemoryFileSystem::default();
    let file_path = Path::new("biome.json");
    fs.insert(
        file_path.into(),
        r#"{
    "overrides": [
        {
            "include": [
                "special/**"
            ],
            "linter": {
                "rules": {
                    "suspicious": {
                        "noDebugger": "off"
                    }
                }
            }
        },
        {
            "include": [
                "special/**"
            ],
            "linter": {
                "rules": {
                    "suspicious": {
                        "noDebugger": "error"
                    }
                }
            }
        }
    ]
}

"#
        .as_bytes(),
    );

    let test = Path::new("test.js");
    fs.insert(test.into(), DEBUGGER_BEFORE.as_bytes());

    let test2 = Path::new("special/test2.js");
    fs.insert(test2.into(), DEBUGGER_BEFORE.as_bytes());

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from(
            [
                ("lint"),
                ("--apply-unsafe"),
                test.as_os_str().to_str().unwrap(),
                test2.as_os_str().to_str().unwrap(),
            ]
            .as_slice(),
        ),
    );

    assert!(result.is_ok(), "run_cli returned {result:?}");

    assert_file_contents(&fs, test2, DEBUGGER_AFTER);
    assert_file_contents(&fs, test, DEBUGGER_AFTER);

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "does_include_file_with_different_linting_and_applies_all_of_them",
        fs,
        console,
        result,
    ));
}
fn test_pd_client_heartbeat_send_failed() {
    let rt = setup_runtime();
    let _g = rt.enter();
    let pd_client_send_fail_fp = "region_heartbeat_send_failed";
    fail::cfg(pd_client_send_fail_fp, "return()").unwrap();
    let server = MockServer::with_case(1, Arc::new(AlreadyBootstrapped));
    let eps = server.bind_addrs();

    let mut client = new_client_v2(eps, None);

    let (tx, mut responses) = client
        .create_region_heartbeat_stream(WakePolicy::Immediately)
        .unwrap();

    let mut heartbeat_send_fail = |ok| {
        let mut region = metapb::Region::default();
        region.set_id(1);
        let mut req = pdpb::RegionHeartbeatRequest::default();
        req.set_region(region);
        tx.send(req).unwrap();

        let rsp = block_on(tokio::time::timeout(
            Duration::from_millis(100),
            responses.next(),
        ));
        if ok {
            assert!(rsp.is_ok());
            assert_eq!(rsp.unwrap().unwrap().unwrap().get_region_id(), 1);
        } else {
            rsp.unwrap_err();
        }

        let region = block_on(client.get_region_by_id(1));
        if ok {
            assert!(region.is_ok());
            let r = region.unwrap();
            assert!(r.is_some());
            assert_eq!(1, r.unwrap().get_id());
        } else {
            region.unwrap_err();
        }
    };
    // send fail if network is block.
    heartbeat_send_fail(false);
    fail::remove(pd_client_send_fail_fp);
    // send success after network recovered.
    heartbeat_send_fail(true);
}
fn pair_int_and_ptr_offsets() {
    assert_eq!(types::PairIntAndPtr::offset_of_first(), 0);
    assert_eq!(types::PairIntAndPtr::offset_of_second(), 4);
}
fn ceil_divmod_test() {
    use lexical_util::num::Integer;

    assert_eq!(5usize.ceil_divmod(7), (1, -2));
    assert_eq!(0usize.ceil_divmod(7), (0, 0));
    assert_eq!(35usize.ceil_divmod(7), (5, 0));
    assert_eq!(36usize.ceil_divmod(7), (6, -6));
}
fn parse_where_delete_with_alias_statement() {
    use self::BinaryOperator::*;

    let sql = "DELETE FROM basket AS a USING basket AS b WHERE a.id < b.id";
    match verified_stmt(sql) {
        Statement::Delete {
            tables: _,
            from,
            using,
            selection,
            returning,
            ..
        } => {
            assert_eq!(
                TableFactor::Table {
                    name: ObjectName(vec![Ident::new("basket")]),
                    alias: Some(TableAlias {
                        name: Ident::new("a"),
                        columns: vec![],
                    }),
                    args: None,
                    with_hints: vec![],
                    version: None,
                    partitions: vec![],
                },
                from[0].relation,
            );
            assert_eq!(
                Some(vec![TableWithJoins {
                    relation: TableFactor::Table {
                        name: ObjectName(vec![Ident::new("basket")]),
                        alias: Some(TableAlias {
                            name: Ident::new("b"),
                            columns: vec![],
                        }),
                        args: None,
                        with_hints: vec![],
                        version: None,
                        partitions: vec![],
                    },
                    joins: vec![],
                }]),
                using
            );
            assert_eq!(
                Expr::BinaryOp {
                    left: Box::new(Expr::CompoundIdentifier(vec![
                        Ident::new("a"),
                        Ident::new("id"),
                    ])),
                    op: Lt,
                    right: Box::new(Expr::CompoundIdentifier(vec![
                        Ident::new("b"),
                        Ident::new("id"),
                    ])),
                },
                selection.unwrap(),
            );
            assert_eq!(None, returning);
        }
        _ => unreachable!(),
    }
}
fn fs_error_unknown() {
    let mut fs = MemoryFileSystem::default();
    let mut console = BufferConsole::default();

    fs.insert_error(PathBuf::from("prefix/ci.js"), ErrorEntry::UnknownFileType);

    let result = run_cli(
        DynRef::Borrowed(&mut fs),
        &mut console,
        Args::from([("lint"), ("prefix")].as_slice()),
    );

    assert!(result.is_err(), "run_cli returned {result:?}");

    assert_cli_snapshot(SnapshotPayload::new(
        module_path!(),
        "fs_error_unknown",
        fs,
        console,
        result,
    ));
}
fn parse_variable_tag_negated_expr() {
    let ast = parse("{{ not id and not true and not 1 + 1 }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(
            WS::default(),
            Expr::new(ExprVal::Logic(LogicExpr {
                lhs: Box::new(Expr::new(ExprVal::Logic(LogicExpr {
                    lhs: Box::new(Expr::new_negated(ExprVal::Ident("id".to_string()))),
                    operator: LogicOperator::And,
                    rhs: Box::new(Expr::new_negated(ExprVal::Bool(true))),
                },))),
                operator: LogicOperator::And,
                rhs: Box::new(Expr::new_negated(ExprVal::Math(MathExpr {
                    lhs: Box::new(Expr::new(ExprVal::Int(1))),
                    operator: MathOperator::Add,
                    rhs: Box::new(Expr::new(ExprVal::Int(1))),
                },))),
            },))
        )
    );
}
fn parse_string_concat_can_merge() {
    let ast = parse("{{ `hello` ~ 'hey' }}").unwrap();
    assert_eq!(
        ast[0],
        Node::VariableBlock(WS::default(), Expr::new(ExprVal::String("hellohey".to_string()))),
    );
}
async fn read_data_end_stream() {
    let mut codec = raw_codec! {
        read => [
            0, 0, 5, 0, 1, 0, 0, 0, 1,
            "hello",
        ];
    };

    let data = poll_frame!(Data, codec);
    assert_eq!(data.stream_id(), 1);
    assert_eq!(data.payload(), &b"hello"[..]);
    assert!(data.is_end_stream());
    assert_closed!(codec);
}
fn test_node_async_fetch() {
    let count = 3;
    let mut cluster = new_node_cluster(0, count);

    cluster.cfg.raft_store.raft_log_gc_count_limit = Some(100000);
    cluster.cfg.raft_store.raft_log_gc_threshold = 50;
    cluster.cfg.raft_store.raft_log_gc_size_limit = Some(ReadableSize::mb(20));
    cluster.cfg.raft_store.raft_log_gc_tick_interval = ReadableDuration::millis(100);
    cluster.cfg.raft_store.raft_log_reserve_max_ticks = 2;
    cluster.cfg.raft_store.raft_entry_cache_life_time = ReadableDuration::millis(100);
    cluster.run();

    cluster.must_put(b"k1", b"v1");

    let mut before_states = HashMap::default();

    for (&id, engines) in &cluster.engines {
        must_get_equal(&engines.kv, b"k1", b"v1");
        let mut state: RaftApplyState = engines
            .kv
            .get_msg_cf(CF_RAFT, &keys::apply_state_key(1))
            .unwrap()
            .unwrap_or_default();
        let state = state.take_truncated_state();
        // compact should not start
        assert_eq!(RAFT_INIT_LOG_INDEX, state.get_index());
        assert_eq!(RAFT_INIT_LOG_TERM, state.get_term());
        before_states.insert(id, state);
    }

    cluster.stop_node(1);

    for i in 1..60u32 {
        let k = i.to_string().into_bytes();
        let v = k.clone();
        cluster.must_put(&k, &v);
    }

    // wait log gc.
    sleep_ms(500);

    let (sender, receiver) = mpsc::channel();
    let sync_sender = Mutex::new(sender);
    fail::cfg_callback("on_async_fetch_return", move || {
        let sender = sync_sender.lock().unwrap();
        sender.send(true).unwrap();
    })
    .unwrap();
    cluster.run_node(1).unwrap();

    // limit has not reached, should not gc.
    for (&id, engines) in &cluster.engines {
        let mut state: RaftApplyState = engines
            .kv
            .get_msg_cf(CF_RAFT, &keys::apply_state_key(1))
            .unwrap()
            .unwrap_or_default();
        let after_state = state.take_truncated_state();

        let before_state = &before_states[&id];
        let idx = after_state.get_index();
        assert_eq!(idx, before_state.get_index());
    }

    assert_eq!(
        receiver.recv_timeout(Duration::from_millis(500)).unwrap(),
        true
    );

    // logs should be replicated to node 1 successfully.
    for i in 1..60u32 {
        let k = i.to_string().into_bytes();
        let v = k.clone();
        must_get_equal(&cluster.engines[&1].kv, &k, &v);
    }

    for i in 60..500u32 {
        let k = i.to_string().into_bytes();
        let v = k.clone();
        cluster.must_put(&k, &v);
        let v2 = cluster.get(&k);
        assert_eq!(v2, Some(v));

        if i > 100
            && check_compacted(
                &cluster.engines,
                &before_states,
                1,
                false, // must_compacted
            )
        {
            return;
        }
    }
    check_compacted(
        &cluster.engines,
        &before_states,
        1,
        true, // must_compacted
    );
}
